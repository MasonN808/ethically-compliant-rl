wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20240213_210829-1vjpjg9h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glowing-bao-30
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/ent-coefficient-ppol
wandb: üöÄ View run at https://wandb.ai/ecrl/ent-coefficient-ppol/runs/1vjpjg9h
Using cpu device
------------------------------------
| avg_speed          | 0.313       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.313       |
| reward             | -0.78667814 |
| rollout/           |             |
|    ep_len_mean     | 1e+03       |
|    ep_rew_mean     | -1.93e+03   |
| time/              |             |
|    fps             | 96          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 2048        |
------------------------------------
------------------------------------------
| avg_speed                | 1.47        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.47        |
| reward                   | -1.0949063  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.8e+03    |
| time/                    |             |
|    fps                   | 93          |
|    iterations            | 2           |
|    time_elapsed          | 43          |
|    total_timesteps       | 4096        |
| train/                   |             |
|    approx_kl             | 0.005152328 |
|    clip_fraction         | 0.0537      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.175       |
|    cost_value_loss       | 0.12        |
|    cost_values           | 0.0845      |
|    entropy               | -2.85       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.000638    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 605         |
|    n_updates             | 10          |
|    policy_gradient_loss  | -0.00582    |
|    std                   | 1.01        |
|    value_loss            | 1.26e+03    |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.91         |
| reward                   | -1.0249299   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.7e+03     |
| time/                    |              |
|    fps                   | 87           |
|    iterations            | 3            |
|    time_elapsed          | 70           |
|    total_timesteps       | 6144         |
| train/                   |              |
|    approx_kl             | 0.0037204328 |
|    clip_fraction         | 0.0399       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.207        |
|    cost_value_loss       | 0.483        |
|    cost_values           | 0.0658       |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0984       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 432          |
|    n_updates             | 20           |
|    policy_gradient_loss  | -0.00385     |
|    std                   | 1.01         |
|    value_loss            | 876          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.21        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.21        |
| reward                   | -1.3488972  |
| rollout/                 |             |
|    ep_len_mean           | 900         |
|    ep_rew_mean           | -1.5e+03    |
| time/                    |             |
|    fps                   | 80          |
|    iterations            | 4           |
|    time_elapsed          | 102         |
|    total_timesteps       | 8192        |
| train/                   |             |
|    approx_kl             | 0.004586345 |
|    clip_fraction         | 0.0283      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.0989      |
|    cost_value_loss       | 0.0101      |
|    cost_values           | 0.12        |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.00942     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 299         |
|    n_updates             | 30          |
|    policy_gradient_loss  | -0.00384    |
|    std                   | 1.01        |
|    value_loss            | 648         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.557        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.557        |
| reward                   | -0.63032174  |
| rollout/                 |              |
|    ep_len_mean           | 927          |
|    ep_rew_mean           | -1.41e+03    |
| time/                    |              |
|    fps                   | 75           |
|    iterations            | 5            |
|    time_elapsed          | 134          |
|    total_timesteps       | 10240        |
| train/                   |              |
|    approx_kl             | 0.0032476909 |
|    clip_fraction         | 0.0263       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.35         |
|    cost_value_loss       | 1.12         |
|    cost_values           | 0.176        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.172        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 210          |
|    n_updates             | 40           |
|    policy_gradient_loss  | -0.00372     |
|    std                   | 1.01         |
|    value_loss            | 463          |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.88        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.88        |
| reward                   | -0.9232267  |
| rollout/                 |             |
|    ep_len_mean           | 939         |
|    ep_rew_mean           | -1.42e+03   |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 6           |
|    time_elapsed          | 167         |
|    total_timesteps       | 12288       |
| train/                   |             |
|    approx_kl             | 0.006454256 |
|    clip_fraction         | 0.038       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.205       |
|    cost_value_loss       | 0.00528     |
|    cost_values           | 0.233       |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.0373      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 213         |
|    n_updates             | 50          |
|    policy_gradient_loss  | -0.0036     |
|    std                   | 1.01        |
|    value_loss            | 470         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.756        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.756        |
| reward                   | -0.39317706  |
| rollout/                 |              |
|    ep_len_mean           | 947          |
|    ep_rew_mean           | -1.42e+03    |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 7            |
|    time_elapsed          | 199          |
|    total_timesteps       | 14336        |
| train/                   |              |
|    approx_kl             | 0.0070497785 |
|    clip_fraction         | 0.0623       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.11         |
|    cost_value_loss       | 0.0384       |
|    cost_values           | 0.086        |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | -1.09        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 284          |
|    n_updates             | 60           |
|    policy_gradient_loss  | -0.00535     |
|    std                   | 1.01         |
|    value_loss            | 631          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0674       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0674       |
| reward                   | -0.8107486   |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -1.37e+03    |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 8            |
|    time_elapsed          | 230          |
|    total_timesteps       | 16384        |
| train/                   |              |
|    approx_kl             | 0.0031164587 |
|    clip_fraction         | 0.0203       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.333        |
|    cost_value_loss       | 1.58         |
|    cost_values           | 0.191        |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | -0.894       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 221          |
|    n_updates             | 70           |
|    policy_gradient_loss  | -0.00256     |
|    std                   | 1.01         |
|    value_loss            | 501          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.592        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.592        |
| reward                   | -0.479981    |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -1.35e+03    |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 9            |
|    time_elapsed          | 263          |
|    total_timesteps       | 18432        |
| train/                   |              |
|    approx_kl             | 0.0030361107 |
|    clip_fraction         | 0.00527      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.662        |
|    cost_value_loss       | 1.3          |
|    cost_values           | 0.604        |
|    entropy               | -2.88        |
|    entropy_loss          | -2.87        |
|    explained_variance    | -0.0907      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 127          |
|    n_updates             | 80           |
|    policy_gradient_loss  | -0.00179     |
|    std                   | 1.02         |
|    value_loss            | 291          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.237        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.237        |
| reward                   | -0.8196657   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -1.32e+03    |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 10           |
|    time_elapsed          | 295          |
|    total_timesteps       | 20480        |
| train/                   |              |
|    approx_kl             | 0.0030617793 |
|    clip_fraction         | 0.0128       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.53         |
|    cost_value_loss       | 0.00554      |
|    cost_values           | 0.54         |
|    entropy               | -2.88        |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.193        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 156          |
|    n_updates             | 90           |
|    policy_gradient_loss  | -0.00305     |
|    std                   | 1.02         |
|    value_loss            | 331          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.733       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.733       |
| reward                   | -0.9567683  |
| rollout/                 |             |
|    ep_len_mean           | 966         |
|    ep_rew_mean           | -1.3e+03    |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 11          |
|    time_elapsed          | 328         |
|    total_timesteps       | 22528       |
| train/                   |             |
|    approx_kl             | 0.003667852 |
|    clip_fraction         | 0.0113      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.374       |
|    cost_value_loss       | 0.00409     |
|    cost_values           | 0.388       |
|    entropy               | -2.89       |
|    entropy_loss          | -2.89       |
|    explained_variance    | -0.212      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 100         |
|    n_updates             | 100         |
|    policy_gradient_loss  | -0.00219    |
|    std                   | 1.03        |
|    value_loss            | 227         |
------------------------------------------
------------------------------------------
| avg_speed                | 2.56        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.56        |
| reward                   | -1.2504451  |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -1.29e+03   |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 12          |
|    time_elapsed          | 361         |
|    total_timesteps       | 24576       |
| train/                   |             |
|    approx_kl             | 0.004430686 |
|    clip_fraction         | 0.0405      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.47        |
|    cost_value_loss       | 1.38        |
|    cost_values           | 0.47        |
|    entropy               | -2.9        |
|    entropy_loss          | -2.89       |
|    explained_variance    | -0.786      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 126         |
|    n_updates             | 110         |
|    policy_gradient_loss  | -0.00552    |
|    std                   | 1.03        |
|    value_loss            | 288         |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.77         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.77         |
| reward                   | -2.4595993   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -1.29e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 13           |
|    time_elapsed          | 389          |
|    total_timesteps       | 26624        |
| train/                   |              |
|    approx_kl             | 0.0035124407 |
|    clip_fraction         | 0.00786      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.33         |
|    cost_value_loss       | 10.3         |
|    cost_values           | 0.744        |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | -0.323       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 177          |
|    n_updates             | 120          |
|    policy_gradient_loss  | -0.00191     |
|    std                   | 1.03         |
|    value_loss            | 372          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.294        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.294        |
| reward                   | -0.8228143   |
| rollout/                 |              |
|    ep_len_mean           | 973          |
|    ep_rew_mean           | -1.32e+03    |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 14           |
|    time_elapsed          | 411          |
|    total_timesteps       | 28672        |
| train/                   |              |
|    approx_kl             | 0.0059977444 |
|    clip_fraction         | 0.0325       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.559        |
|    cost_value_loss       | 0.475        |
|    cost_values           | 0.374        |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | -0.843       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 208          |
|    n_updates             | 130          |
|    policy_gradient_loss  | -0.00506     |
|    std                   | 1.04         |
|    value_loss            | 514          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.495        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.495        |
| reward                   | -0.8928818   |
| rollout/                 |              |
|    ep_len_mean           | 975          |
|    ep_rew_mean           | -1.29e+03    |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 15           |
|    time_elapsed          | 434          |
|    total_timesteps       | 30720        |
| train/                   |              |
|    approx_kl             | 0.0037650312 |
|    clip_fraction         | 0.0239       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.523        |
|    cost_value_loss       | 0.975        |
|    cost_values           | 0.44         |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.105        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 361          |
|    n_updates             | 140          |
|    policy_gradient_loss  | -0.00241     |
|    std                   | 1.04         |
|    value_loss            | 755          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.76         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.76         |
| reward                   | -2.0180166   |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 16           |
|    time_elapsed          | 461          |
|    total_timesteps       | 32768        |
| train/                   |              |
|    approx_kl             | 0.0052989195 |
|    clip_fraction         | 0.0263       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.2          |
|    cost_value_loss       | 7.16         |
|    cost_values           | 0.636        |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.246        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 69.9         |
|    n_updates             | 150          |
|    policy_gradient_loss  | -0.0036      |
|    std                   | 1.04         |
|    value_loss            | 163          |
-------------------------------------------
-----------------------------------------
| avg_speed                | 2.05       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 2.05       |
| reward                   | -1.6854295 |
| rollout/                 |            |
|    ep_len_mean           | 978        |
|    ep_rew_mean           | -1.3e+03   |
| time/                    |            |
|    fps                   | 70         |
|    iterations            | 17         |
|    time_elapsed          | 491        |
|    total_timesteps       | 34816      |
| train/                   |            |
|    approx_kl             | 0.00444257 |
|    clip_fraction         | 0.0241     |
|    clip_range            | 0.2        |
|    cost_returns          | 0.463      |
|    cost_value_loss       | 0.0482     |
|    cost_values           | 0.543      |
|    entropy               | -2.91      |
|    entropy_loss          | -2.91      |
|    explained_variance    | -1.5       |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 85         |
|    n_updates             | 160        |
|    policy_gradient_loss  | -0.00431   |
|    std                   | 1.04       |
|    value_loss            | 249        |
-----------------------------------------
--------------------------------------------
| avg_speed                | 3.83          |
| cost                     | 1             |
| is_success               | 0             |
| max_speed                | 3.83          |
| reward                   | -0.5213847    |
| rollout/                 |               |
|    ep_len_mean           | 979           |
|    ep_rew_mean           | -1.32e+03     |
| time/                    |               |
|    fps                   | 70            |
|    iterations            | 18            |
|    time_elapsed          | 519           |
|    total_timesteps       | 36864         |
| train/                   |               |
|    approx_kl             | 0.00052984676 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.303         |
|    cost_value_loss       | 0.0601        |
|    cost_values           | 0.507         |
|    entropy               | -2.91         |
|    entropy_loss          | -2.91         |
|    explained_variance    | -1.96         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 177           |
|    n_updates             | 170           |
|    policy_gradient_loss  | -0.00053      |
|    std                   | 1.04          |
|    value_loss            | 527           |
--------------------------------------------
------------------------------------------
| avg_speed                | 0.244       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.244       |
| reward                   | -1.0778655  |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -1.33e+03   |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 19          |
|    time_elapsed          | 556         |
|    total_timesteps       | 38912       |
| train/                   |             |
|    approx_kl             | 0.005015506 |
|    clip_fraction         | 0.0124      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.462       |
|    cost_value_loss       | 0.0118      |
|    cost_values           | 0.527       |
|    entropy               | -2.91       |
|    entropy_loss          | -2.91       |
|    explained_variance    | -0.156      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 269         |
|    n_updates             | 180         |
|    policy_gradient_loss  | -0.00249    |
|    std                   | 1.04        |
|    value_loss            | 596         |
------------------------------------------
------------------------------------------
| avg_speed                | 6.11        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.11        |
| reward                   | -0.8648082  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.33e+03   |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 20          |
|    time_elapsed          | 596         |
|    total_timesteps       | 40960       |
| train/                   |             |
|    approx_kl             | 0.006737493 |
|    clip_fraction         | 0.034       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.426       |
|    cost_value_loss       | 0.0184      |
|    cost_values           | 0.487       |
|    entropy               | -2.92       |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.0429      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 233         |
|    n_updates             | 190         |
|    policy_gradient_loss  | -0.00486    |
|    std                   | 1.04        |
|    value_loss            | 487         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.008        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.008        |
| reward                   | -1.5437622   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -1.34e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 21           |
|    time_elapsed          | 635          |
|    total_timesteps       | 43008        |
| train/                   |              |
|    approx_kl             | 0.0065449625 |
|    clip_fraction         | 0.0362       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.375        |
|    cost_value_loss       | 0.00483      |
|    cost_values           | 0.433        |
|    entropy               | -2.91        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.00231      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 268          |
|    n_updates             | 200          |
|    policy_gradient_loss  | -0.00469     |
|    std                   | 1.04         |
|    value_loss            | 573          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.69         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.69         |
| reward                   | -1.5705484   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -1.33e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 22           |
|    time_elapsed          | 667          |
|    total_timesteps       | 45056        |
| train/                   |              |
|    approx_kl             | 0.0031079908 |
|    clip_fraction         | 0.0063       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.331        |
|    cost_value_loss       | 0.0035       |
|    cost_values           | 0.381        |
|    entropy               | -2.9         |
|    entropy_loss          | -2.91        |
|    explained_variance    | -0.0078      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 204          |
|    n_updates             | 210          |
|    policy_gradient_loss  | -0.00202     |
|    std                   | 1.03         |
|    value_loss            | 432          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.39         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.39         |
| reward                   | -2.8319874   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -1.33e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 23           |
|    time_elapsed          | 706          |
|    total_timesteps       | 47104        |
| train/                   |              |
|    approx_kl             | 0.0029854754 |
|    clip_fraction         | 0.00498      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.316        |
|    cost_value_loss       | 0.0374       |
|    cost_values           | 0.344        |
|    entropy               | -2.91        |
|    entropy_loss          | -2.9         |
|    explained_variance    | -0.0806      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 132          |
|    n_updates             | 220          |
|    policy_gradient_loss  | -0.00202     |
|    std                   | 1.04         |
|    value_loss            | 290          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.36         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.36         |
| reward                   | -1.5115314   |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -1.34e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 24           |
|    time_elapsed          | 740          |
|    total_timesteps       | 49152        |
| train/                   |              |
|    approx_kl             | 0.0068442067 |
|    clip_fraction         | 0.0427       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.277        |
|    cost_value_loss       | 0.0028       |
|    cost_values           | 0.32         |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.0712       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 252          |
|    n_updates             | 230          |
|    policy_gradient_loss  | -0.00545     |
|    std                   | 1.04         |
|    value_loss            | 552          |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8.02       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.02       |
| reward                   | -2.8390293 |
| rollout/                 |            |
|    ep_len_mean           | 985        |
|    ep_rew_mean           | -1.33e+03  |
| time/                    |            |
|    fps                   | 66         |
|    iterations            | 25         |
|    time_elapsed          | 771        |
|    total_timesteps       | 51200      |
| train/                   |            |
|    approx_kl             | 0.00469343 |
|    clip_fraction         | 0.0234     |
|    clip_range            | 0.2        |
|    cost_returns          | 0.246      |
|    cost_value_loss       | 0.00161    |
|    cost_values           | 0.276      |
|    entropy               | -2.93      |
|    entropy_loss          | -2.92      |
|    explained_variance    | 0.0465     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 156        |
|    n_updates             | 240        |
|    policy_gradient_loss  | -0.00436   |
|    std                   | 1.05       |
|    value_loss            | 340        |
-----------------------------------------
-------------------------------------------
| avg_speed                | 0.299        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.299        |
| reward                   | -0.6867485   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -1.33e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 26           |
|    time_elapsed          | 794          |
|    total_timesteps       | 53248        |
| train/                   |              |
|    approx_kl             | 0.0043807942 |
|    clip_fraction         | 0.0151       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.21         |
|    cost_value_loss       | 0.00127      |
|    cost_values           | 0.237        |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.0692       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 221          |
|    n_updates             | 250          |
|    policy_gradient_loss  | -0.00263     |
|    std                   | 1.06         |
|    value_loss            | 472          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0388       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0388       |
| reward                   | -0.6796636   |
| rollout/                 |              |
|    ep_len_mean           | 986          |
|    ep_rew_mean           | -1.35e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 27           |
|    time_elapsed          | 818          |
|    total_timesteps       | 55296        |
| train/                   |              |
|    approx_kl             | 0.0037176649 |
|    clip_fraction         | 0.0128       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.177        |
|    cost_value_loss       | 0.00101      |
|    cost_values           | 0.199        |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.0289       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 143          |
|    n_updates             | 260          |
|    policy_gradient_loss  | -0.00263     |
|    std                   | 1.05         |
|    value_loss            | 313          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.37         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.37         |
| reward                   | -0.7587034   |
| rollout/                 |              |
|    ep_len_mean           | 987          |
|    ep_rew_mean           | -1.36e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 28           |
|    time_elapsed          | 855          |
|    total_timesteps       | 57344        |
| train/                   |              |
|    approx_kl             | 0.0039904634 |
|    clip_fraction         | 0.00913      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.222        |
|    cost_value_loss       | 0.246        |
|    cost_values           | 0.191        |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.0157       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 311          |
|    n_updates             | 270          |
|    policy_gradient_loss  | -0.00225     |
|    std                   | 1.05         |
|    value_loss            | 647          |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.64        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.64        |
| reward                   | -1.0209097  |
| rollout/                 |             |
|    ep_len_mean           | 987         |
|    ep_rew_mean           | -1.37e+03   |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 29          |
|    time_elapsed          | 892         |
|    total_timesteps       | 59392       |
| train/                   |             |
|    approx_kl             | 0.004261166 |
|    clip_fraction         | 0.0237      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.168       |
|    cost_value_loss       | 0.00112     |
|    cost_values           | 0.197       |
|    entropy               | -2.94       |
|    entropy_loss          | -2.94       |
|    explained_variance    | 0.0208      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 287         |
|    n_updates             | 280         |
|    policy_gradient_loss  | -0.00356    |
|    std                   | 1.05        |
|    value_loss            | 586         |
------------------------------------------
------------------------------------------
| avg_speed                | 3.56        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.56        |
| reward                   | -0.99053186 |
| rollout/                 |             |
|    ep_len_mean           | 988         |
|    ep_rew_mean           | -1.36e+03   |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 30          |
|    time_elapsed          | 921         |
|    total_timesteps       | 61440       |
| train/                   |             |
|    approx_kl             | 0.002911429 |
|    clip_fraction         | 0.00474     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.149       |
|    cost_value_loss       | 0.000638    |
|    cost_values           | 0.169       |
|    entropy               | -2.94       |
|    entropy_loss          | -2.94       |
|    explained_variance    | 0.0156      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 352         |
|    n_updates             | 290         |
|    policy_gradient_loss  | -0.00174    |
|    std                   | 1.05        |
|    value_loss            | 734         |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.03         |
| reward                   | -1.061647    |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -1.37e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 31           |
|    time_elapsed          | 950          |
|    total_timesteps       | 63488        |
| train/                   |              |
|    approx_kl             | 0.0045440407 |
|    clip_fraction         | 0.0218       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.368        |
|    cost_value_loss       | 0.979        |
|    cost_values           | 0.252        |
|    entropy               | -2.95        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.0214       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 129          |
|    n_updates             | 300          |
|    policy_gradient_loss  | -0.00344     |
|    std                   | 1.06         |
|    value_loss            | 262          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.23         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.23         |
| reward                   | -1.0193247   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -1.38e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 32           |
|    time_elapsed          | 980          |
|    total_timesteps       | 65536        |
| train/                   |              |
|    approx_kl             | 0.0044048764 |
|    clip_fraction         | 0.0289       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.286        |
|    cost_value_loss       | 0.00363      |
|    cost_values           | 0.337        |
|    entropy               | -2.96        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.0232       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 232          |
|    n_updates             | 310          |
|    policy_gradient_loss  | -0.00389     |
|    std                   | 1.06         |
|    value_loss            | 458          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.3          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.3          |
| reward                   | -0.6347425   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -1.37e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 33           |
|    time_elapsed          | 1013         |
|    total_timesteps       | 67584        |
| train/                   |              |
|    approx_kl             | 0.0035456435 |
|    clip_fraction         | 0.0165       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.293        |
|    cost_value_loss       | 0.125        |
|    cost_values           | 0.295        |
|    entropy               | -2.96        |
|    entropy_loss          | -2.96        |
|    explained_variance    | -0.196       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 291          |
|    n_updates             | 320          |
|    policy_gradient_loss  | -0.00235     |
|    std                   | 1.06         |
|    value_loss            | 612          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.219        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.219        |
| reward                   | -0.8800005   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -1.35e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 34           |
|    time_elapsed          | 1053         |
|    total_timesteps       | 69632        |
| train/                   |              |
|    approx_kl             | 0.0038335891 |
|    clip_fraction         | 0.0324       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.307        |
|    cost_value_loss       | 0.202        |
|    cost_values           | 0.3          |
|    entropy               | -2.95        |
|    entropy_loss          | -2.96        |
|    explained_variance    | -0.0219      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 88.7         |
|    n_updates             | 330          |
|    policy_gradient_loss  | -0.00577     |
|    std                   | 1.06         |
|    value_loss            | 188          |
-------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.97625774 |
| rollout/                 |             |
|    ep_len_mean           | 990         |
|    ep_rew_mean           | -1.35e+03   |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 35          |
|    time_elapsed          | 1090        |
|    total_timesteps       | 71680       |
| train/                   |             |
|    approx_kl             | 0.006733202 |
|    clip_fraction         | 0.0632      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.488       |
|    cost_value_loss       | 0.825       |
|    cost_values           | 0.426       |
|    entropy               | -2.94       |
|    entropy_loss          | -2.95       |
|    explained_variance    | -0.0268     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 61.4        |
|    n_updates             | 340         |
|    policy_gradient_loss  | -0.00597    |
|    std                   | 1.05        |
|    value_loss            | 131         |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.34         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.34         |
| reward                   | -1.1582232   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.34e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 36           |
|    time_elapsed          | 1117         |
|    total_timesteps       | 73728        |
| train/                   |              |
|    approx_kl             | 0.0039181574 |
|    clip_fraction         | 0.0169       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.662        |
|    cost_value_loss       | 0.693        |
|    cost_values           | 0.584        |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.0546       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 151          |
|    n_updates             | 350          |
|    policy_gradient_loss  | -0.00265     |
|    std                   | 1.05         |
|    value_loss            | 312          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.46         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.46         |
| reward                   | -0.7291913   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.33e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 37           |
|    time_elapsed          | 1147         |
|    total_timesteps       | 75776        |
| train/                   |              |
|    approx_kl             | 0.0074497946 |
|    clip_fraction         | 0.0527       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.61         |
|    cost_value_loss       | 0.351        |
|    cost_values           | 0.645        |
|    entropy               | -2.95        |
|    entropy_loss          | -2.94        |
|    explained_variance    | -0.652       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 66.8         |
|    n_updates             | 360          |
|    policy_gradient_loss  | -0.0072      |
|    std                   | 1.06         |
|    value_loss            | 159          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.26         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.26         |
| reward                   | -1.005414    |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.33e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 38           |
|    time_elapsed          | 1169         |
|    total_timesteps       | 77824        |
| train/                   |              |
|    approx_kl             | 0.0026836998 |
|    clip_fraction         | 0.0183       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.15         |
|    cost_value_loss       | 3.5          |
|    cost_values           | 0.845        |
|    entropy               | -2.96        |
|    entropy_loss          | -2.95        |
|    explained_variance    | -0.0787      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 47.4         |
|    n_updates             | 370          |
|    policy_gradient_loss  | -0.00289     |
|    std                   | 1.06         |
|    value_loss            | 94.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.25         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.25         |
| reward                   | -1.0550554   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.33e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 39           |
|    time_elapsed          | 1192         |
|    total_timesteps       | 79872        |
| train/                   |              |
|    approx_kl             | 0.0049606827 |
|    clip_fraction         | 0.0385       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.878        |
|    cost_value_loss       | 0.462        |
|    cost_values           | 0.931        |
|    entropy               | -2.96        |
|    entropy_loss          | -2.96        |
|    explained_variance    | -0.0159      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 157          |
|    n_updates             | 380          |
|    policy_gradient_loss  | -0.00556     |
|    std                   | 1.06         |
|    value_loss            | 320          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.515        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.515        |
| reward                   | -0.7627396   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.32e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 40           |
|    time_elapsed          | 1214         |
|    total_timesteps       | 81920        |
| train/                   |              |
|    approx_kl             | 0.0036411276 |
|    clip_fraction         | 0.0191       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.818        |
|    cost_value_loss       | 0.157        |
|    cost_values           | 0.876        |
|    entropy               | -2.97        |
|    entropy_loss          | -2.96        |
|    explained_variance    | -0.00226     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 94.9         |
|    n_updates             | 390          |
|    policy_gradient_loss  | -0.00289     |
|    std                   | 1.07         |
|    value_loss            | 206          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.88         |
| reward                   | -1.9442499   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.31e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 41           |
|    time_elapsed          | 1246         |
|    total_timesteps       | 83968        |
| train/                   |              |
|    approx_kl             | 0.0060239094 |
|    clip_fraction         | 0.0454       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.801        |
|    cost_value_loss       | 0.38         |
|    cost_values           | 0.814        |
|    entropy               | -2.98        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.00228      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 56.2         |
|    n_updates             | 400          |
|    policy_gradient_loss  | -0.00609     |
|    std                   | 1.07         |
|    value_loss            | 105          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.832        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.832        |
| reward                   | -1.4027356   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.31e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 42           |
|    time_elapsed          | 1282         |
|    total_timesteps       | 86016        |
| train/                   |              |
|    approx_kl             | 0.0047507863 |
|    clip_fraction         | 0.0407       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.2          |
|    cost_value_loss       | 5.37         |
|    cost_values           | 0.894        |
|    entropy               | -2.99        |
|    entropy_loss          | -2.98        |
|    explained_variance    | -0.126       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 113          |
|    n_updates             | 410          |
|    policy_gradient_loss  | -0.0048      |
|    std                   | 1.08         |
|    value_loss            | 242          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.17         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.17         |
| reward                   | -1.1116947   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.31e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 43           |
|    time_elapsed          | 1321         |
|    total_timesteps       | 88064        |
| train/                   |              |
|    approx_kl             | 0.0084785465 |
|    clip_fraction         | 0.06         |
|    clip_range            | 0.2          |
|    cost_returns          | 0.751        |
|    cost_value_loss       | 0.0924       |
|    cost_values           | 0.826        |
|    entropy               | -2.99        |
|    entropy_loss          | -2.99        |
|    explained_variance    | -0.0325      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 163          |
|    n_updates             | 420          |
|    policy_gradient_loss  | -0.00575     |
|    std                   | 1.08         |
|    value_loss            | 331          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -1.5046722   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.31e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 44           |
|    time_elapsed          | 1357         |
|    total_timesteps       | 90112        |
| train/                   |              |
|    approx_kl             | 0.0039706887 |
|    clip_fraction         | 0.00806      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.647        |
|    cost_value_loss       | 0.0137       |
|    cost_values           | 0.743        |
|    entropy               | -2.99        |
|    entropy_loss          | -2.99        |
|    explained_variance    | -0.00691     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 155          |
|    n_updates             | 430          |
|    policy_gradient_loss  | -0.0026      |
|    std                   | 1.08         |
|    value_loss            | 325          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.71         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.71         |
| reward                   | -2.00479     |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.31e+03    |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 45           |
|    time_elapsed          | 1396         |
|    total_timesteps       | 92160        |
| train/                   |              |
|    approx_kl             | 0.0041584196 |
|    clip_fraction         | 0.0217       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.726        |
|    cost_value_loss       | 0.483        |
|    cost_values           | 0.697        |
|    entropy               | -2.99        |
|    entropy_loss          | -2.99        |
|    explained_variance    | 0.000531     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 111          |
|    n_updates             | 440          |
|    policy_gradient_loss  | -0.00336     |
|    std                   | 1.08         |
|    value_loss            | 239          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.03         |
| reward                   | -1.2915444   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.31e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 46           |
|    time_elapsed          | 1427         |
|    total_timesteps       | 94208        |
| train/                   |              |
|    approx_kl             | 0.0034949325 |
|    clip_fraction         | 0.00747      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.582        |
|    cost_value_loss       | 0.0123       |
|    cost_values           | 0.675        |
|    entropy               | -3           |
|    entropy_loss          | -2.99        |
|    explained_variance    | -0.0146      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 144          |
|    n_updates             | 450          |
|    policy_gradient_loss  | -0.00281     |
|    std                   | 1.09         |
|    value_loss            | 286          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.06        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.06        |
| reward                   | -1.0585833  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -1.31e+03   |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 47          |
|    time_elapsed          | 1456        |
|    total_timesteps       | 96256       |
| train/                   |             |
|    approx_kl             | 0.006070678 |
|    clip_fraction         | 0.0472      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.573       |
|    cost_value_loss       | 0.182       |
|    cost_values           | 0.6         |
|    entropy               | -3.02       |
|    entropy_loss          | -3.01       |
|    explained_variance    | 0.00822     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 111         |
|    n_updates             | 460         |
|    policy_gradient_loss  | -0.00539    |
|    std                   | 1.09        |
|    value_loss            | 227         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.519       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.519       |
| reward                   | -0.6182843  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -1.32e+03   |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 48          |
|    time_elapsed          | 1492        |
|    total_timesteps       | 98304       |
| train/                   |             |
|    approx_kl             | 0.004417913 |
|    clip_fraction         | 0.0327      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.672       |
|    cost_value_loss       | 1.42        |
|    cost_values           | 0.603       |
|    entropy               | -3.02       |
|    entropy_loss          | -3.02       |
|    explained_variance    | 0.00146     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 196         |
|    n_updates             | 470         |
|    policy_gradient_loss  | -0.00325    |
|    std                   | 1.1         |
|    value_loss            | 421         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.492        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.492        |
| reward                   | -0.5645285   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.32e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 49           |
|    time_elapsed          | 1517         |
|    total_timesteps       | 100352       |
| train/                   |              |
|    approx_kl             | 0.0038815616 |
|    clip_fraction         | 0.0288       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.728        |
|    cost_value_loss       | 0.924        |
|    cost_values           | 0.672        |
|    entropy               | -3.03        |
|    entropy_loss          | -3.02        |
|    explained_variance    | 0.000341     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 124          |
|    n_updates             | 480          |
|    policy_gradient_loss  | -0.00345     |
|    std                   | 1.1          |
|    value_loss            | 273          |
-------------------------------------------
Directory created: tests/PPOL_New/models/ent-coefficient-ppol/1vjpjg9h
------------------------------------
| avg_speed          | 0.812       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.812       |
| reward             | -0.58067775 |
| rollout/           |             |
|    ep_len_mean     | 993         |
|    ep_rew_mean     | -1.3e+03    |
| time/              |             |
|    fps             | 96          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 102400      |
------------------------------------
-------------------------------------------
| avg_speed                | 2.73         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.73         |
| reward                   | -0.8311217   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 80           |
|    iterations            | 2            |
|    time_elapsed          | 51           |
|    total_timesteps       | 104448       |
| train/                   |              |
|    approx_kl             | 0.0057981964 |
|    clip_fraction         | 0.0327       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.538        |
|    cost_value_loss       | 0.0514       |
|    cost_values           | 0.569        |
|    entropy               | -3.03        |
|    entropy_loss          | -3.03        |
|    explained_variance    | -0.000264    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 48.1         |
|    n_updates             | 500          |
|    policy_gradient_loss  | -0.00273     |
|    std                   | 1.1          |
|    value_loss            | 102          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.31         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.31         |
| reward                   | -1.3055291   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.3e+03     |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 3            |
|    time_elapsed          | 86           |
|    total_timesteps       | 106496       |
| train/                   |              |
|    approx_kl             | 0.0051475437 |
|    clip_fraction         | 0.0564       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.497        |
|    cost_value_loss       | 0.0908       |
|    cost_values           | 0.517        |
|    entropy               | -3.04        |
|    entropy_loss          | -3.03        |
|    explained_variance    | 0.00351      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 85.3         |
|    n_updates             | 510          |
|    policy_gradient_loss  | -0.00574     |
|    std                   | 1.1          |
|    value_loss            | 177          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.04         |
| reward                   | -0.8012554   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.3e+03     |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 4            |
|    time_elapsed          | 118          |
|    total_timesteps       | 108544       |
| train/                   |              |
|    approx_kl             | 0.0056114146 |
|    clip_fraction         | 0.0312       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.427        |
|    cost_value_loss       | 0.0203       |
|    cost_values           | 0.474        |
|    entropy               | -3.03        |
|    entropy_loss          | -3.04        |
|    explained_variance    | 0.00595      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 163          |
|    n_updates             | 520          |
|    policy_gradient_loss  | -0.00341     |
|    std                   | 1.1          |
|    value_loss            | 331          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.08         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.08         |
| reward                   | -1.3841687   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.3e+03     |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 5            |
|    time_elapsed          | 149          |
|    total_timesteps       | 110592       |
| train/                   |              |
|    approx_kl             | 0.0034617006 |
|    clip_fraction         | 0.0329       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.571        |
|    cost_value_loss       | 0.82         |
|    cost_values           | 0.49         |
|    entropy               | -3.03        |
|    entropy_loss          | -3.03        |
|    explained_variance    | 0.00107      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 140          |
|    n_updates             | 530          |
|    policy_gradient_loss  | -0.00391     |
|    std                   | 1.1          |
|    value_loss            | 292          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.21         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.21         |
| reward                   | -1.4814593   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.29e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 6            |
|    time_elapsed          | 180          |
|    total_timesteps       | 112640       |
| train/                   |              |
|    approx_kl             | 0.0036370663 |
|    clip_fraction         | 0.0122       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.707        |
|    cost_value_loss       | 1.09         |
|    cost_values           | 0.616        |
|    entropy               | -3.02        |
|    entropy_loss          | -3.03        |
|    explained_variance    | -0.0414      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 120          |
|    n_updates             | 540          |
|    policy_gradient_loss  | -0.00298     |
|    std                   | 1.1          |
|    value_loss            | 255          |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.86        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.86        |
| reward                   | -1.4703182  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.29e+03   |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 7           |
|    time_elapsed          | 207         |
|    total_timesteps       | 114688      |
| train/                   |             |
|    approx_kl             | 0.004892586 |
|    clip_fraction         | 0.0391      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.585       |
|    cost_value_loss       | 0.043       |
|    cost_values           | 0.643       |
|    entropy               | -3.02       |
|    entropy_loss          | -3.02       |
|    explained_variance    | 0.00148     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 64.7        |
|    n_updates             | 550         |
|    policy_gradient_loss  | -0.00484    |
|    std                   | 1.1         |
|    value_loss            | 141         |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.92         |
| reward                   | -1.4021647   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.3e+03     |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 8            |
|    time_elapsed          | 237          |
|    total_timesteps       | 116736       |
| train/                   |              |
|    approx_kl             | 0.0035893968 |
|    clip_fraction         | 0.0246       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.485        |
|    cost_value_loss       | 0.00601      |
|    cost_values           | 0.54         |
|    entropy               | -3.02        |
|    entropy_loss          | -3.02        |
|    explained_variance    | 0.00454      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 111          |
|    n_updates             | 560          |
|    policy_gradient_loss  | -0.00271     |
|    std                   | 1.1          |
|    value_loss            | 235          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.89         |
| reward                   | -1.3093736   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.3e+03     |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 9            |
|    time_elapsed          | 271          |
|    total_timesteps       | 118784       |
| train/                   |              |
|    approx_kl             | 0.0043565724 |
|    clip_fraction         | 0.029        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.431        |
|    cost_value_loss       | 0.0387       |
|    cost_values           | 0.465        |
|    entropy               | -3.03        |
|    entropy_loss          | -3.02        |
|    explained_variance    | 3.24e-05     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 147          |
|    n_updates             | 570          |
|    policy_gradient_loss  | -0.00364     |
|    std                   | 1.1          |
|    value_loss            | 306          |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.93        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.93        |
| reward                   | -2.0213182  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.3e+03    |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 10          |
|    time_elapsed          | 302         |
|    total_timesteps       | 120832      |
| train/                   |             |
|    approx_kl             | 0.004888047 |
|    clip_fraction         | 0.0411      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.434       |
|    cost_value_loss       | 0.245       |
|    cost_values           | 0.434       |
|    entropy               | -3.03       |
|    entropy_loss          | -3.03       |
|    explained_variance    | 0.00168     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 79.5        |
|    n_updates             | 580         |
|    policy_gradient_loss  | -0.00467    |
|    std                   | 1.1         |
|    value_loss            | 172         |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.02         |
| reward                   | -1.2024722   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.31e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 11           |
|    time_elapsed          | 333          |
|    total_timesteps       | 122880       |
| train/                   |              |
|    approx_kl             | 0.0033569555 |
|    clip_fraction         | 0.0307       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.453        |
|    cost_value_loss       | 0.243        |
|    cost_values           | 0.443        |
|    entropy               | -3.01        |
|    entropy_loss          | -3.02        |
|    explained_variance    | 0.00172      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 63.2         |
|    n_updates             | 590          |
|    policy_gradient_loss  | -0.00408     |
|    std                   | 1.09         |
|    value_loss            | 139          |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.05        |
| reward                   | -1.8391076  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.31e+03   |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 12          |
|    time_elapsed          | 366         |
|    total_timesteps       | 124928      |
| train/                   |             |
|    approx_kl             | 0.003954193 |
|    clip_fraction         | 0.013       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.519       |
|    cost_value_loss       | 0.695       |
|    cost_values           | 0.48        |
|    entropy               | -3.01       |
|    entropy_loss          | -3.01       |
|    explained_variance    | -0.0027     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 165         |
|    n_updates             | 600         |
|    policy_gradient_loss  | -0.00187    |
|    std                   | 1.09        |
|    value_loss            | 343         |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.42         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.42         |
| reward                   | -1.2757548   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.3e+03     |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 13           |
|    time_elapsed          | 393          |
|    total_timesteps       | 126976       |
| train/                   |              |
|    approx_kl             | 0.0042420924 |
|    clip_fraction         | 0.047        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.466        |
|    cost_value_loss       | 0.0796       |
|    cost_values           | 0.489        |
|    entropy               | -3           |
|    entropy_loss          | -3           |
|    explained_variance    | -0.000792    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 71.9         |
|    n_updates             | 610          |
|    policy_gradient_loss  | -0.00517     |
|    std                   | 1.09         |
|    value_loss            | 159          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.38         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.38         |
| reward                   | -1.1871134   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.29e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 14           |
|    time_elapsed          | 417          |
|    total_timesteps       | 129024       |
| train/                   |              |
|    approx_kl             | 0.0056109177 |
|    clip_fraction         | 0.0304       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.628        |
|    cost_value_loss       | 0.828        |
|    cost_values           | 0.563        |
|    entropy               | -3           |
|    entropy_loss          | -3           |
|    explained_variance    | 0.00312      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 53.1         |
|    n_updates             | 620          |
|    policy_gradient_loss  | -0.00455     |
|    std                   | 1.08         |
|    value_loss            | 106          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.78         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.78         |
| reward                   | -2.130632    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.29e+03    |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 15           |
|    time_elapsed          | 440          |
|    total_timesteps       | 131072       |
| train/                   |              |
|    approx_kl             | 0.0064829676 |
|    clip_fraction         | 0.0468       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.994        |
|    cost_value_loss       | 3.34         |
|    cost_values           | 0.831        |
|    entropy               | -3.01        |
|    entropy_loss          | -3           |
|    explained_variance    | 0.00397      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 26.5         |
|    n_updates             | 630          |
|    policy_gradient_loss  | -0.0059      |
|    std                   | 1.09         |
|    value_loss            | 56.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.58927965 |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -1.28e+03   |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 16          |
|    time_elapsed          | 463         |
|    total_timesteps       | 133120      |
| train/                   |             |
|    approx_kl             | 0.003947679 |
|    clip_fraction         | 0.0309      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.703       |
|    cost_value_loss       | 0.124       |
|    cost_values           | 0.774       |
|    entropy               | -3.02       |
|    entropy_loss          | -3.01       |
|    explained_variance    | 0.00927     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 73.7        |
|    n_updates             | 640         |
|    policy_gradient_loss  | -0.00336    |
|    std                   | 1.09        |
|    value_loss            | 155         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.791        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.791        |
| reward                   | -1.6551328   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 17           |
|    time_elapsed          | 491          |
|    total_timesteps       | 135168       |
| train/                   |              |
|    approx_kl             | 0.0053730425 |
|    clip_fraction         | 0.0581       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.924        |
|    cost_value_loss       | 1.52         |
|    cost_values           | 0.824        |
|    entropy               | -3.02        |
|    entropy_loss          | -3.02        |
|    explained_variance    | 0.00473      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 59.8         |
|    n_updates             | 650          |
|    policy_gradient_loss  | -0.00723     |
|    std                   | 1.09         |
|    value_loss            | 119          |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.75        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.75        |
| reward                   | -1.734077   |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -1.26e+03   |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 18          |
|    time_elapsed          | 530         |
|    total_timesteps       | 137216      |
| train/                   |             |
|    approx_kl             | 0.004618253 |
|    clip_fraction         | 0.0327      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.06        |
|    cost_value_loss       | 1.41        |
|    cost_values           | 0.914       |
|    entropy               | -3.01       |
|    entropy_loss          | -3.01       |
|    explained_variance    | 0.0028      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 45.6        |
|    n_updates             | 660         |
|    policy_gradient_loss  | -0.00362    |
|    std                   | 1.09        |
|    value_loss            | 90.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.771        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.771        |
| reward                   | -1.4211862   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 19           |
|    time_elapsed          | 569          |
|    total_timesteps       | 139264       |
| train/                   |              |
|    approx_kl             | 0.0031070583 |
|    clip_fraction         | 0.0117       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.46         |
|    cost_value_loss       | 5.72         |
|    cost_values           | 0.961        |
|    entropy               | -3           |
|    entropy_loss          | -3.01        |
|    explained_variance    | 0.00268      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 41.4         |
|    n_updates             | 670          |
|    policy_gradient_loss  | -0.00307     |
|    std                   | 1.08         |
|    value_loss            | 86.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.76         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.76         |
| reward                   | -0.9513186   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.24e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 20           |
|    time_elapsed          | 606          |
|    total_timesteps       | 141312       |
| train/                   |              |
|    approx_kl             | 0.0032084472 |
|    clip_fraction         | 0.032        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.998        |
|    cost_value_loss       | 0.589        |
|    cost_values           | 0.928        |
|    entropy               | -2.99        |
|    entropy_loss          | -2.99        |
|    explained_variance    | 0.0057       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 50.9         |
|    n_updates             | 680          |
|    policy_gradient_loss  | -0.0041      |
|    std                   | 1.08         |
|    value_loss            | 108          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.952       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.952       |
| reward                   | -0.7505074  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -1.24e+03   |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 21          |
|    time_elapsed          | 643         |
|    total_timesteps       | 143360      |
| train/                   |             |
|    approx_kl             | 0.004453362 |
|    clip_fraction         | 0.0308      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.946       |
|    cost_value_loss       | 0.484       |
|    cost_values           | 0.948       |
|    entropy               | -2.99       |
|    entropy_loss          | -2.99       |
|    explained_variance    | 0.00164     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 24.4        |
|    n_updates             | 690         |
|    policy_gradient_loss  | -0.00362    |
|    std                   | 1.08        |
|    value_loss            | 50.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.926       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.926       |
| reward                   | -1.2795881  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -1.23e+03   |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 22          |
|    time_elapsed          | 683         |
|    total_timesteps       | 145408      |
| train/                   |             |
|    approx_kl             | 0.003146799 |
|    clip_fraction         | 0.0201      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.18        |
|    cost_value_loss       | 2.45        |
|    cost_values           | 0.961       |
|    entropy               | -2.98       |
|    entropy_loss          | -2.99       |
|    explained_variance    | 0.00356     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 26          |
|    n_updates             | 700         |
|    policy_gradient_loss  | -0.00396    |
|    std                   | 1.07        |
|    value_loss            | 52.9        |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.44       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.44       |
| reward                   | -0.7572197 |
| rollout/                 |            |
|    ep_len_mean           | 993        |
|    ep_rew_mean           | -1.21e+03  |
| time/                    |            |
|    fps                   | 65         |
|    iterations            | 23         |
|    time_elapsed          | 723        |
|    total_timesteps       | 147456     |
| train/                   |            |
|    approx_kl             | 0.00423138 |
|    clip_fraction         | 0.0309     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.04       |
|    cost_value_loss       | 1.08       |
|    cost_values           | 0.947      |
|    entropy               | -3         |
|    entropy_loss          | -2.98      |
|    explained_variance    | 0.00159    |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 32.3       |
|    n_updates             | 710        |
|    policy_gradient_loss  | -0.00338   |
|    std                   | 1.08       |
|    value_loss            | 70.1       |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.544       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.544       |
| reward                   | -1.1285928  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -1.21e+03   |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 24          |
|    time_elapsed          | 751         |
|    total_timesteps       | 149504      |
| train/                   |             |
|    approx_kl             | 0.005366772 |
|    clip_fraction         | 0.0489      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.916       |
|    cost_value_loss       | 0.44        |
|    cost_values           | 0.938       |
|    entropy               | -3.02       |
|    entropy_loss          | -3.01       |
|    explained_variance    | -0.00371    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.94        |
|    n_updates             | 720         |
|    policy_gradient_loss  | -0.00924    |
|    std                   | 1.09        |
|    value_loss            | 8.37        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.1         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.1         |
| reward                   | -0.6668331  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -1.2e+03    |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 25          |
|    time_elapsed          | 774         |
|    total_timesteps       | 151552      |
| train/                   |             |
|    approx_kl             | 0.003873099 |
|    clip_fraction         | 0.0318      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.04        |
|    cost_value_loss       | 1.59        |
|    cost_values           | 0.956       |
|    entropy               | -3.01       |
|    entropy_loss          | -3.01       |
|    explained_variance    | 0.00934     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.8        |
|    n_updates             | 730         |
|    policy_gradient_loss  | -0.00599    |
|    std                   | 1.09        |
|    value_loss            | 32.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0196       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0196       |
| reward                   | -0.6800968   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.19e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 26           |
|    time_elapsed          | 797          |
|    total_timesteps       | 153600       |
| train/                   |              |
|    approx_kl             | 0.0025668684 |
|    clip_fraction         | 0.0221       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.04         |
|    cost_value_loss       | 1.1          |
|    cost_values           | 0.963        |
|    entropy               | -3           |
|    entropy_loss          | -3           |
|    explained_variance    | 0.00124      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.7         |
|    n_updates             | 740          |
|    policy_gradient_loss  | -0.00304     |
|    std                   | 1.08         |
|    value_loss            | 41.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.71        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.71        |
| reward                   | -0.77251285 |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -1.17e+03   |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 27          |
|    time_elapsed          | 820         |
|    total_timesteps       | 155648      |
| train/                   |             |
|    approx_kl             | 0.005081265 |
|    clip_fraction         | 0.0304      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.04        |
|    cost_value_loss       | 1.37        |
|    cost_values           | 0.946       |
|    entropy               | -2.99       |
|    entropy_loss          | -2.99       |
|    explained_variance    | 0.000116    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17.4        |
|    n_updates             | 750         |
|    policy_gradient_loss  | -0.00365    |
|    std                   | 1.08        |
|    value_loss            | 33.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.01         |
| reward                   | -1.0252686   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.16e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 28           |
|    time_elapsed          | 844          |
|    total_timesteps       | 157696       |
| train/                   |              |
|    approx_kl             | 0.0046835775 |
|    clip_fraction         | 0.0453       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.972        |
|    cost_value_loss       | 1.22         |
|    cost_values           | 0.983        |
|    entropy               | -2.98        |
|    entropy_loss          | -2.99        |
|    explained_variance    | 0.00226      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 16.5         |
|    n_updates             | 760          |
|    policy_gradient_loss  | -0.00485     |
|    std                   | 1.07         |
|    value_loss            | 34.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.06         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.06         |
| reward                   | -0.8035469   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.16e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 29           |
|    time_elapsed          | 868          |
|    total_timesteps       | 159744       |
| train/                   |              |
|    approx_kl             | 0.0054082423 |
|    clip_fraction         | 0.0261       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.966        |
|    cost_value_loss       | 0.931        |
|    cost_values           | 0.973        |
|    entropy               | -2.98        |
|    entropy_loss          | -2.98        |
|    explained_variance    | 4.39e-05     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 65.3         |
|    n_updates             | 770          |
|    policy_gradient_loss  | -0.00305     |
|    std                   | 1.07         |
|    value_loss            | 139          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.151        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.151        |
| reward                   | -0.7468671   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.15e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 30           |
|    time_elapsed          | 904          |
|    total_timesteps       | 161792       |
| train/                   |              |
|    approx_kl             | 0.0036708065 |
|    clip_fraction         | 0.0222       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.946        |
|    cost_value_loss       | 0.417        |
|    cost_values           | 0.961        |
|    entropy               | -2.98        |
|    entropy_loss          | -2.98        |
|    explained_variance    | -0.00826     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 99.2         |
|    n_updates             | 780          |
|    policy_gradient_loss  | -0.003       |
|    std                   | 1.07         |
|    value_loss            | 200          |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.02        |
| reward                   | -0.44980112 |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -1.13e+03   |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 31          |
|    time_elapsed          | 945         |
|    total_timesteps       | 163840      |
| train/                   |             |
|    approx_kl             | 0.004930347 |
|    clip_fraction         | 0.0434      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.01        |
|    cost_value_loss       | 1.2         |
|    cost_values           | 0.964       |
|    entropy               | -2.98       |
|    entropy_loss          | -2.98       |
|    explained_variance    | 0.00112     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 20.5        |
|    n_updates             | 790         |
|    policy_gradient_loss  | -0.00387    |
|    std                   | 1.07        |
|    value_loss            | 43.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.477        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.477        |
| reward                   | -0.5839144   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.12e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 32           |
|    time_elapsed          | 986          |
|    total_timesteps       | 165888       |
| train/                   |              |
|    approx_kl             | 0.0042172605 |
|    clip_fraction         | 0.0343       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.843        |
|    cost_value_loss       | 0.364        |
|    cost_values           | 0.848        |
|    entropy               | -2.98        |
|    entropy_loss          | -2.98        |
|    explained_variance    | -0.00297     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.6          |
|    n_updates             | 800          |
|    policy_gradient_loss  | -0.00243     |
|    std                   | 1.08         |
|    value_loss            | 3.19         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.389        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.389        |
| reward                   | -1.1914159   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.12e+03    |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 33           |
|    time_elapsed          | 1025         |
|    total_timesteps       | 167936       |
| train/                   |              |
|    approx_kl             | 0.0042386553 |
|    clip_fraction         | 0.0487       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.8          |
|    cost_value_loss       | 9.08         |
|    cost_values           | 1.13         |
|    entropy               | -2.98        |
|    entropy_loss          | -2.98        |
|    explained_variance    | -0.000246    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 23.2         |
|    n_updates             | 810          |
|    policy_gradient_loss  | -0.00342     |
|    std                   | 1.07         |
|    value_loss            | 38.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.861       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.861       |
| reward                   | -1.0189425  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -1.12e+03   |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 34          |
|    time_elapsed          | 1064        |
|    total_timesteps       | 169984      |
| train/                   |             |
|    approx_kl             | 0.002365564 |
|    clip_fraction         | 0.00361     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.06        |
|    cost_value_loss       | 0.331       |
|    cost_values           | 0.93        |
|    entropy               | -2.98       |
|    entropy_loss          | -2.98       |
|    explained_variance    | -0.000793   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 45.6        |
|    n_updates             | 820         |
|    policy_gradient_loss  | -0.00175    |
|    std                   | 1.07        |
|    value_loss            | 88.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.14         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.14         |
| reward                   | -1.1382864   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.12e+03    |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 35           |
|    time_elapsed          | 1100         |
|    total_timesteps       | 172032       |
| train/                   |              |
|    approx_kl             | 0.0046038944 |
|    clip_fraction         | 0.0373       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.663        |
|    cost_value_loss       | 0.0141       |
|    cost_values           | 0.754        |
|    entropy               | -2.98        |
|    entropy_loss          | -2.98        |
|    explained_variance    | 0.000883     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.22         |
|    n_updates             | 830          |
|    policy_gradient_loss  | -0.00381     |
|    std                   | 1.07         |
|    value_loss            | 19           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0777       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0777       |
| reward                   | -0.6897509   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.12e+03    |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 36           |
|    time_elapsed          | 1135         |
|    total_timesteps       | 174080       |
| train/                   |              |
|    approx_kl             | 0.0025161575 |
|    clip_fraction         | 0.0107       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.81         |
|    cost_value_loss       | 1.77         |
|    cost_values           | 0.689        |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 8.26e-05     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 56.5         |
|    n_updates             | 840          |
|    policy_gradient_loss  | -0.0017      |
|    std                   | 1.07         |
|    value_loss            | 115          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0429       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0429       |
| reward                   | -1.6184932   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.13e+03    |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 37           |
|    time_elapsed          | 1171         |
|    total_timesteps       | 176128       |
| train/                   |              |
|    approx_kl             | 0.0011862011 |
|    clip_fraction         | 0.00132      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.59         |
|    cost_value_loss       | 0.0163       |
|    cost_values           | 0.704        |
|    entropy               | -2.98        |
|    entropy_loss          | -2.98        |
|    explained_variance    | 0.00178      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 41.4         |
|    n_updates             | 850          |
|    policy_gradient_loss  | -0.00173     |
|    std                   | 1.07         |
|    value_loss            | 92.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.3          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.3          |
| reward                   | -1.2227256   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.13e+03    |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 38           |
|    time_elapsed          | 1202         |
|    total_timesteps       | 178176       |
| train/                   |              |
|    approx_kl             | 0.0025628132 |
|    clip_fraction         | 0.00591      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.55         |
|    cost_value_loss       | 0.0117       |
|    cost_values           | 0.644        |
|    entropy               | -2.98        |
|    entropy_loss          | -2.98        |
|    explained_variance    | -0.00154     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 151          |
|    n_updates             | 860          |
|    policy_gradient_loss  | -0.00258     |
|    std                   | 1.07         |
|    value_loss            | 287          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.827        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.827        |
| reward                   | -1.9505725   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.15e+03    |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 39           |
|    time_elapsed          | 1225         |
|    total_timesteps       | 180224       |
| train/                   |              |
|    approx_kl             | 0.0031282804 |
|    clip_fraction         | 0.0312       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.508        |
|    cost_value_loss       | 0.00955      |
|    cost_values           | 0.592        |
|    entropy               | -2.98        |
|    entropy_loss          | -2.98        |
|    explained_variance    | 0.00216      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 44.9         |
|    n_updates             | 870          |
|    policy_gradient_loss  | -0.00408     |
|    std                   | 1.07         |
|    value_loss            | 91.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.338       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.338       |
| reward                   | -1.5434537  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -1.16e+03   |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 40          |
|    time_elapsed          | 1248        |
|    total_timesteps       | 182272      |
| train/                   |             |
|    approx_kl             | 0.003154308 |
|    clip_fraction         | 0.0215      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.55        |
|    cost_value_loss       | 0.331       |
|    cost_values           | 0.554       |
|    entropy               | -2.98       |
|    entropy_loss          | -2.98       |
|    explained_variance    | -0.00706    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 438         |
|    n_updates             | 880         |
|    policy_gradient_loss  | -0.00295    |
|    std                   | 1.08        |
|    value_loss            | 832         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.426        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.426        |
| reward                   | -1.200776    |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 41           |
|    time_elapsed          | 1271         |
|    total_timesteps       | 184320       |
| train/                   |              |
|    approx_kl             | 0.0020636774 |
|    clip_fraction         | 0.0218       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.483        |
|    cost_value_loss       | 0.0669       |
|    cost_values           | 0.537        |
|    entropy               | -2.98        |
|    entropy_loss          | -2.98        |
|    explained_variance    | 0.000792     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 56.3         |
|    n_updates             | 890          |
|    policy_gradient_loss  | -0.00394     |
|    std                   | 1.08         |
|    value_loss            | 120          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.769        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.769        |
| reward                   | -1.067509    |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 42           |
|    time_elapsed          | 1294         |
|    total_timesteps       | 186368       |
| train/                   |              |
|    approx_kl             | 0.0033213352 |
|    clip_fraction         | 0.0136       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.425        |
|    cost_value_loss       | 0.00765      |
|    cost_values           | 0.502        |
|    entropy               | -2.99        |
|    entropy_loss          | -2.99        |
|    explained_variance    | 0.00092      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 185          |
|    n_updates             | 900          |
|    policy_gradient_loss  | -0.00578     |
|    std                   | 1.08         |
|    value_loss            | 390          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.653       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.653       |
| reward                   | -1.5633959  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -1.17e+03   |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 43          |
|    time_elapsed          | 1321        |
|    total_timesteps       | 188416      |
| train/                   |             |
|    approx_kl             | 0.004398739 |
|    clip_fraction         | 0.0212      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.399       |
|    cost_value_loss       | 0.00637     |
|    cost_values           | 0.469       |
|    entropy               | -2.99       |
|    entropy_loss          | -2.99       |
|    explained_variance    | 0.00222     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 78.1        |
|    n_updates             | 910         |
|    policy_gradient_loss  | -0.00194    |
|    std                   | 1.08        |
|    value_loss            | 168         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.35         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.35         |
| reward                   | -1.767904    |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.19e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 44           |
|    time_elapsed          | 1347         |
|    total_timesteps       | 190464       |
| train/                   |              |
|    approx_kl             | 0.0036527338 |
|    clip_fraction         | 0.00571      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.401        |
|    cost_value_loss       | 0.0551       |
|    cost_values           | 0.437        |
|    entropy               | -2.99        |
|    entropy_loss          | -2.99        |
|    explained_variance    | 0.00522      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 83.1         |
|    n_updates             | 920          |
|    policy_gradient_loss  | -0.0014      |
|    std                   | 1.08         |
|    value_loss            | 176          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.03         |
| reward                   | -1.5629073   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.19e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 45           |
|    time_elapsed          | 1371         |
|    total_timesteps       | 192512       |
| train/                   |              |
|    approx_kl             | 0.0016427037 |
|    clip_fraction         | 0.00132      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.35         |
|    cost_value_loss       | 0.00564      |
|    cost_values           | 0.417        |
|    entropy               | -2.99        |
|    entropy_loss          | -2.99        |
|    explained_variance    | 0.000831     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 363          |
|    n_updates             | 930          |
|    policy_gradient_loss  | -0.00192     |
|    std                   | 1.08         |
|    value_loss            | 751          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.58         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.58         |
| reward                   | -1.0488814   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.19e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 46           |
|    time_elapsed          | 1395         |
|    total_timesteps       | 194560       |
| train/                   |              |
|    approx_kl             | 0.0055812076 |
|    clip_fraction         | 0.0524       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.423        |
|    cost_value_loss       | 0.248        |
|    cost_values           | 0.408        |
|    entropy               | -2.98        |
|    entropy_loss          | -2.98        |
|    explained_variance    | 0.00369      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 44.6         |
|    n_updates             | 940          |
|    policy_gradient_loss  | -0.00494     |
|    std                   | 1.08         |
|    value_loss            | 98.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.05         |
| reward                   | -0.59205073  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.19e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 47           |
|    time_elapsed          | 1419         |
|    total_timesteps       | 196608       |
| train/                   |              |
|    approx_kl             | 0.0034413654 |
|    clip_fraction         | 0.0232       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.338        |
|    cost_value_loss       | 0.00437      |
|    cost_values           | 0.394        |
|    entropy               | -2.99        |
|    entropy_loss          | -2.99        |
|    explained_variance    | 0.000909     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 69.4         |
|    n_updates             | 950          |
|    policy_gradient_loss  | -0.00417     |
|    std                   | 1.08         |
|    value_loss            | 156          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.71         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.71         |
| reward                   | -0.7994438   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.19e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 48           |
|    time_elapsed          | 1442         |
|    total_timesteps       | 198656       |
| train/                   |              |
|    approx_kl             | 0.0024638788 |
|    clip_fraction         | 0.00239      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.303        |
|    cost_value_loss       | 0.00344      |
|    cost_values           | 0.351        |
|    entropy               | -3           |
|    entropy_loss          | -3           |
|    explained_variance    | 0.00461      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 65           |
|    n_updates             | 960          |
|    policy_gradient_loss  | -0.000826    |
|    std                   | 1.08         |
|    value_loss            | 131          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.89         |
| reward                   | -0.8625228   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.21e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 49           |
|    time_elapsed          | 1467         |
|    total_timesteps       | 200704       |
| train/                   |              |
|    approx_kl             | 0.0038398288 |
|    clip_fraction         | 0.0293       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.296        |
|    cost_value_loss       | 0.037        |
|    cost_values           | 0.324        |
|    entropy               | -3           |
|    entropy_loss          | -3           |
|    explained_variance    | 0.000815     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 230          |
|    n_updates             | 970          |
|    policy_gradient_loss  | -0.00369     |
|    std                   | 1.08         |
|    value_loss            | 466          |
-------------------------------------------
-----------------------------------
| avg_speed          | 1.58       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 1.58       |
| reward             | -1.0253948 |
| rollout/           |            |
|    ep_len_mean     | 993        |
|    ep_rew_mean     | -1.2e+03   |
| time/              |            |
|    fps             | 79         |
|    iterations      | 1          |
|    time_elapsed    | 25         |
|    total_timesteps | 202752     |
-----------------------------------
-------------------------------------------
| avg_speed                | 0.964        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.964        |
| reward                   | -1.1225542   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 74           |
|    iterations            | 2            |
|    time_elapsed          | 54           |
|    total_timesteps       | 204800       |
| train/                   |              |
|    approx_kl             | 0.0066498816 |
|    clip_fraction         | 0.0547       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.576        |
|    cost_value_loss       | 2.64         |
|    cost_values           | 0.507        |
|    entropy               | -2.99        |
|    entropy_loss          | -3           |
|    explained_variance    | 0.00104      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.7         |
|    n_updates             | 990          |
|    policy_gradient_loss  | -0.0036      |
|    std                   | 1.08         |
|    value_loss            | 36.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.655       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.655       |
| reward                   | -0.98855716 |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -1.2e+03    |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 3           |
|    time_elapsed          | 84          |
|    total_timesteps       | 206848      |
| train/                   |             |
|    approx_kl             | 0.004276634 |
|    clip_fraction         | 0.0464      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.535       |
|    cost_value_loss       | 0.0659      |
|    cost_values           | 0.563       |
|    entropy               | -2.98       |
|    entropy_loss          | -2.99       |
|    explained_variance    | 0.00537     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.23        |
|    n_updates             | 1000        |
|    policy_gradient_loss  | -0.00447    |
|    std                   | 1.08        |
|    value_loss            | 19.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.298        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.298        |
| reward                   | -1.0572339   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 4            |
|    time_elapsed          | 117          |
|    total_timesteps       | 208896       |
| train/                   |              |
|    approx_kl             | 0.0054240804 |
|    clip_fraction         | 0.0368       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.467        |
|    cost_value_loss       | 0.0979       |
|    cost_values           | 0.516        |
|    entropy               | -2.98        |
|    entropy_loss          | -2.98        |
|    explained_variance    | -0.983       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 58.6         |
|    n_updates             | 1010         |
|    policy_gradient_loss  | -0.00479     |
|    std                   | 1.08         |
|    value_loss            | 135          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.41        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.41        |
| reward                   | -1.3529277  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -1.2e+03    |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 5           |
|    time_elapsed          | 148         |
|    total_timesteps       | 210944      |
| train/                   |             |
|    approx_kl             | 0.004577211 |
|    clip_fraction         | 0.042       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.439       |
|    cost_value_loss       | 0.0578      |
|    cost_values           | 0.471       |
|    entropy               | -2.99       |
|    entropy_loss          | -2.99       |
|    explained_variance    | 0.00126     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 50.1        |
|    n_updates             | 1020        |
|    policy_gradient_loss  | -0.00566    |
|    std                   | 1.08        |
|    value_loss            | 96.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.608        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.608        |
| reward                   | -1.1037333   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 6            |
|    time_elapsed          | 182          |
|    total_timesteps       | 212992       |
| train/                   |              |
|    approx_kl             | 0.0023037568 |
|    clip_fraction         | 0.0104       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.434        |
|    cost_value_loss       | 0.23         |
|    cost_values           | 0.443        |
|    entropy               | -2.99        |
|    entropy_loss          | -2.99        |
|    explained_variance    | 0.00114      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 170          |
|    n_updates             | 1030         |
|    policy_gradient_loss  | -0.00214     |
|    std                   | 1.08         |
|    value_loss            | 335          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.01         |
| reward                   | -1.0694484   |
| rollout/                 |              |
|    ep_len_mean           | 985          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 7            |
|    time_elapsed          | 215          |
|    total_timesteps       | 215040       |
| train/                   |              |
|    approx_kl             | 0.0040083867 |
|    clip_fraction         | 0.0184       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.508        |
|    cost_value_loss       | 0.81         |
|    cost_values           | 0.468        |
|    entropy               | -3           |
|    entropy_loss          | -3           |
|    explained_variance    | 0.00128      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.4         |
|    n_updates             | 1040         |
|    policy_gradient_loss  | -0.00261     |
|    std                   | 1.09         |
|    value_loss            | 43.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.842        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.842        |
| reward                   | -0.78458303  |
| rollout/                 |              |
|    ep_len_mean           | 976          |
|    ep_rew_mean           | -1.19e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 8            |
|    time_elapsed          | 246          |
|    total_timesteps       | 217088       |
| train/                   |              |
|    approx_kl             | 0.0043183817 |
|    clip_fraction         | 0.0401       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.617        |
|    cost_value_loss       | 0.775        |
|    cost_values           | 0.536        |
|    entropy               | -3.01        |
|    entropy_loss          | -3.01        |
|    explained_variance    | 0.000907     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 183          |
|    n_updates             | 1050         |
|    policy_gradient_loss  | -0.00514     |
|    std                   | 1.09         |
|    value_loss            | 346          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.05         |
| reward                   | -0.72217613  |
| rollout/                 |              |
|    ep_len_mean           | 968          |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 9            |
|    time_elapsed          | 279          |
|    total_timesteps       | 219136       |
| train/                   |              |
|    approx_kl             | 0.0044133468 |
|    clip_fraction         | 0.0413       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.07         |
|    cost_value_loss       | 3.42         |
|    cost_values           | 0.73         |
|    entropy               | -3.01        |
|    entropy_loss          | -3.01        |
|    explained_variance    | 0.000582     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 164          |
|    n_updates             | 1060         |
|    policy_gradient_loss  | -0.00561     |
|    std                   | 1.09         |
|    value_loss            | 329          |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.05        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.05        |
| reward                   | -0.5061904  |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -1.16e+03   |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 10          |
|    time_elapsed          | 310         |
|    total_timesteps       | 221184      |
| train/                   |             |
|    approx_kl             | 0.004631155 |
|    clip_fraction         | 0.0454      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.49        |
|    cost_value_loss       | 11.6        |
|    cost_values           | 1.73        |
|    entropy               | -3.05       |
|    entropy_loss          | -3.03       |
|    explained_variance    | 9.54e-07    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 50          |
|    n_updates             | 1070        |
|    policy_gradient_loss  | -0.00258    |
|    std                   | 1.12        |
|    value_loss            | 82.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.359       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.359       |
| reward                   | -0.76428676 |
| rollout/                 |             |
|    ep_len_mean           | 968         |
|    ep_rew_mean           | -1.15e+03   |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 11          |
|    time_elapsed          | 342         |
|    total_timesteps       | 223232      |
| train/                   |             |
|    approx_kl             | 0.002634008 |
|    clip_fraction         | 0.013       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.48        |
|    cost_value_loss       | 2.6         |
|    cost_values           | 2.19        |
|    entropy               | -3.07       |
|    entropy_loss          | -3.07       |
|    explained_variance    | 0.000683    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.67        |
|    n_updates             | 1080        |
|    policy_gradient_loss  | -0.00274    |
|    std                   | 1.12        |
|    value_loss            | 16.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.74         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.74         |
| reward                   | -0.78968734  |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -1.15e+03    |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 12           |
|    time_elapsed          | 374          |
|    total_timesteps       | 225280       |
| train/                   |              |
|    approx_kl             | 0.0033154052 |
|    clip_fraction         | 0.0188       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.7          |
|    cost_value_loss       | 0.354        |
|    cost_values           | 1.61         |
|    entropy               | -3.06        |
|    entropy_loss          | -3.07        |
|    explained_variance    | 0.00756      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.98         |
|    n_updates             | 1090         |
|    policy_gradient_loss  | -0.00317     |
|    std                   | 1.12         |
|    value_loss            | 16.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.178        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.178        |
| reward                   | -1.0903023   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -1.14e+03    |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 13           |
|    time_elapsed          | 406          |
|    total_timesteps       | 227328       |
| train/                   |              |
|    approx_kl             | 0.0074976515 |
|    clip_fraction         | 0.0512       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.15         |
|    cost_value_loss       | 0.358        |
|    cost_values           | 1.07         |
|    entropy               | -3.06        |
|    entropy_loss          | -3.06        |
|    explained_variance    | -0.000219    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 23.4         |
|    n_updates             | 1100         |
|    policy_gradient_loss  | -0.00299     |
|    std                   | 1.12         |
|    value_loss            | 46.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.8          |
| reward                   | -1.1559811   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -1.14e+03    |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 14           |
|    time_elapsed          | 439          |
|    total_timesteps       | 229376       |
| train/                   |              |
|    approx_kl             | 0.0035622462 |
|    clip_fraction         | 0.03         |
|    clip_range            | 0.2          |
|    cost_returns          | 0.956        |
|    cost_value_loss       | 0.387        |
|    cost_values           | 0.95         |
|    entropy               | -3.07        |
|    entropy_loss          | -3.06        |
|    explained_variance    | 0.00209      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.44         |
|    n_updates             | 1110         |
|    policy_gradient_loss  | -0.003       |
|    std                   | 1.12         |
|    value_loss            | 15.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0854       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0854       |
| reward                   | -0.9542647   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.14e+03    |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 15           |
|    time_elapsed          | 473          |
|    total_timesteps       | 231424       |
| train/                   |              |
|    approx_kl             | 0.0046250536 |
|    clip_fraction         | 0.0233       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.07         |
|    cost_value_loss       | 1.03         |
|    cost_values           | 0.981        |
|    entropy               | -3.07        |
|    entropy_loss          | -3.07        |
|    explained_variance    | -0.00116     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.46         |
|    n_updates             | 1120         |
|    policy_gradient_loss  | -0.00313     |
|    std                   | 1.12         |
|    value_loss            | 13.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.142       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.142       |
| reward                   | -0.82258064 |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -1.14e+03   |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 16          |
|    time_elapsed          | 507         |
|    total_timesteps       | 233472      |
| train/                   |             |
|    approx_kl             | 0.00762355  |
|    clip_fraction         | 0.0641      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.02        |
|    cost_value_loss       | 0.637       |
|    cost_values           | 0.995       |
|    entropy               | -3.08       |
|    entropy_loss          | -3.07       |
|    explained_variance    | 0.00175     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.02        |
|    n_updates             | 1130        |
|    policy_gradient_loss  | -0.00608    |
|    std                   | 1.13        |
|    value_loss            | 13.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.846       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.846       |
| reward                   | -0.880568   |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -1.13e+03   |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 17          |
|    time_elapsed          | 536         |
|    total_timesteps       | 235520      |
| train/                   |             |
|    approx_kl             | 0.004753934 |
|    clip_fraction         | 0.0566      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.29        |
|    cost_value_loss       | 2.96        |
|    cost_values           | 1           |
|    entropy               | -3.08       |
|    entropy_loss          | -3.08       |
|    explained_variance    | 0.0041      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.86        |
|    n_updates             | 1140        |
|    policy_gradient_loss  | -0.000336   |
|    std                   | 1.13        |
|    value_loss            | 17.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.48         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.48         |
| reward                   | -0.8161209   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.12e+03    |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 18           |
|    time_elapsed          | 568          |
|    total_timesteps       | 237568       |
| train/                   |              |
|    approx_kl             | 0.0036681183 |
|    clip_fraction         | 0.00693      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.64         |
|    cost_value_loss       | 4.82         |
|    cost_values           | 1            |
|    entropy               | -3.08        |
|    entropy_loss          | -3.08        |
|    explained_variance    | -0.0102      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.5         |
|    n_updates             | 1150         |
|    policy_gradient_loss  | -0.002       |
|    std                   | 1.13         |
|    value_loss            | 20.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.481        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.481        |
| reward                   | -0.8682143   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.12e+03    |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 19           |
|    time_elapsed          | 596          |
|    total_timesteps       | 239616       |
| train/                   |              |
|    approx_kl             | 0.0052267755 |
|    clip_fraction         | 0.0214       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.48         |
|    cost_value_loss       | 4.1          |
|    cost_values           | 1.04         |
|    entropy               | -3.08        |
|    entropy_loss          | -3.08        |
|    explained_variance    | -1.37        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.42         |
|    n_updates             | 1160         |
|    policy_gradient_loss  | -0.00322     |
|    std                   | 1.13         |
|    value_loss            | 6.56         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.62         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.62         |
| reward                   | -0.6244906   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.11e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 20           |
|    time_elapsed          | 619          |
|    total_timesteps       | 241664       |
| train/                   |              |
|    approx_kl             | 0.0041396376 |
|    clip_fraction         | 0.0102       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.81         |
|    cost_value_loss       | 17.6         |
|    cost_values           | 1.24         |
|    entropy               | -3.09        |
|    entropy_loss          | -3.09        |
|    explained_variance    | -0.0244      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.1         |
|    n_updates             | 1170         |
|    policy_gradient_loss  | -0.00246     |
|    std                   | 1.13         |
|    value_loss            | 20.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.451        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.451        |
| reward                   | -0.7625739   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 21           |
|    time_elapsed          | 642          |
|    total_timesteps       | 243712       |
| train/                   |              |
|    approx_kl             | 0.0060588582 |
|    clip_fraction         | 0.0158       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.48         |
|    cost_value_loss       | 2.04         |
|    cost_values           | 1.23         |
|    entropy               | -3.08        |
|    entropy_loss          | -3.09        |
|    explained_variance    | -0.0703      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.49         |
|    n_updates             | 1180         |
|    policy_gradient_loss  | -0.00274     |
|    std                   | 1.13         |
|    value_loss            | 16.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.26         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.26         |
| reward                   | -0.85160774  |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 22           |
|    time_elapsed          | 664          |
|    total_timesteps       | 245760       |
| train/                   |              |
|    approx_kl             | 0.0015799103 |
|    clip_fraction         | 0.00176      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.42         |
|    cost_value_loss       | 13.8         |
|    cost_values           | 1.06         |
|    entropy               | -3.08        |
|    entropy_loss          | -3.08        |
|    explained_variance    | -0.00652     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.5         |
|    n_updates             | 1190         |
|    policy_gradient_loss  | -0.00224     |
|    std                   | 1.13         |
|    value_loss            | 19.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.89         |
| reward                   | -0.7288269   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 23           |
|    time_elapsed          | 687          |
|    total_timesteps       | 247808       |
| train/                   |              |
|    approx_kl             | 0.0033048964 |
|    clip_fraction         | 0.0265       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.11         |
|    cost_value_loss       | 0.725        |
|    cost_values           | 1.03         |
|    entropy               | -3.07        |
|    entropy_loss          | -3.08        |
|    explained_variance    | 0.0253       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.3         |
|    n_updates             | 1200         |
|    policy_gradient_loss  | -0.00373     |
|    std                   | 1.13         |
|    value_loss            | 28.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.434        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.434        |
| reward                   | -1.1353631   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 24           |
|    time_elapsed          | 715          |
|    total_timesteps       | 249856       |
| train/                   |              |
|    approx_kl             | 0.0016124233 |
|    clip_fraction         | 0.00396      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.918        |
|    cost_value_loss       | 0.712        |
|    cost_values           | 0.931        |
|    entropy               | -3.07        |
|    entropy_loss          | -3.07        |
|    explained_variance    | -1.07        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 25.9         |
|    n_updates             | 1210         |
|    policy_gradient_loss  | -0.00174     |
|    std                   | 1.12         |
|    value_loss            | 66.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0798       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0798       |
| reward                   | -0.80835414  |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 25           |
|    time_elapsed          | 743          |
|    total_timesteps       | 251904       |
| train/                   |              |
|    approx_kl             | 0.0032496864 |
|    clip_fraction         | 0.0107       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.13         |
|    cost_value_loss       | 3.29         |
|    cost_values           | 0.939        |
|    entropy               | -3.07        |
|    entropy_loss          | -3.07        |
|    explained_variance    | -2.77        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.8         |
|    n_updates             | 1220         |
|    policy_gradient_loss  | -0.00349     |
|    std                   | 1.12         |
|    value_loss            | 62.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.07         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.07         |
| reward                   | -1.3932029   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 26           |
|    time_elapsed          | 772          |
|    total_timesteps       | 253952       |
| train/                   |              |
|    approx_kl             | 0.0042711757 |
|    clip_fraction         | 0.0312       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.975        |
|    cost_value_loss       | 0.401        |
|    cost_values           | 0.951        |
|    entropy               | -3.07        |
|    entropy_loss          | -3.07        |
|    explained_variance    | 0.169        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.01         |
|    n_updates             | 1230         |
|    policy_gradient_loss  | -0.00366     |
|    std                   | 1.12         |
|    value_loss            | 13.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.942       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.942       |
| reward                   | -0.91056615 |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -1.09e+03   |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 27          |
|    time_elapsed          | 797         |
|    total_timesteps       | 256000      |
| train/                   |             |
|    approx_kl             | 0.006450883 |
|    clip_fraction         | 0.0269      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.833       |
|    cost_value_loss       | 0.221       |
|    cost_values           | 0.899       |
|    entropy               | -3.07       |
|    entropy_loss          | -3.07       |
|    explained_variance    | 0.15        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 20.6        |
|    n_updates             | 1240        |
|    policy_gradient_loss  | -0.0039     |
|    std                   | 1.12        |
|    value_loss            | 45.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.198        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.198        |
| reward                   | -1.102731    |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -1.09e+03    |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 28           |
|    time_elapsed          | 823          |
|    total_timesteps       | 258048       |
| train/                   |              |
|    approx_kl             | 0.0039163395 |
|    clip_fraction         | 0.0171       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.819        |
|    cost_value_loss       | 0.19         |
|    cost_values           | 0.86         |
|    entropy               | -3.08        |
|    entropy_loss          | -3.07        |
|    explained_variance    | 0.217        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.8         |
|    n_updates             | 1250         |
|    policy_gradient_loss  | -0.00318     |
|    std                   | 1.13         |
|    value_loss            | 27.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.453        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.453        |
| reward                   | -1.0661384   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -1.09e+03    |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 29           |
|    time_elapsed          | 852          |
|    total_timesteps       | 260096       |
| train/                   |              |
|    approx_kl             | 0.0065919305 |
|    clip_fraction         | 0.044        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.919        |
|    cost_value_loss       | 0.917        |
|    cost_values           | 0.891        |
|    entropy               | -3.07        |
|    entropy_loss          | -3.08        |
|    explained_variance    | 0.143        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.41         |
|    n_updates             | 1260         |
|    policy_gradient_loss  | -0.00484     |
|    std                   | 1.12         |
|    value_loss            | 10.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.82         |
| reward                   | -0.48152167  |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 30           |
|    time_elapsed          | 886          |
|    total_timesteps       | 262144       |
| train/                   |              |
|    approx_kl             | 0.0058034696 |
|    clip_fraction         | 0.0391       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.04         |
|    cost_value_loss       | 0.842        |
|    cost_values           | 0.904        |
|    entropy               | -3.08        |
|    entropy_loss          | -3.07        |
|    explained_variance    | 0.253        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.61         |
|    n_updates             | 1270         |
|    policy_gradient_loss  | -0.00562     |
|    std                   | 1.13         |
|    value_loss            | 9.97         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.976        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.976        |
| reward                   | -1.3202724   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -1.09e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 31           |
|    time_elapsed          | 926          |
|    total_timesteps       | 264192       |
| train/                   |              |
|    approx_kl             | 0.0021299399 |
|    clip_fraction         | 0.00908      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.18         |
|    cost_value_loss       | 1.1          |
|    cost_values           | 0.912        |
|    entropy               | -3.08        |
|    entropy_loss          | -3.08        |
|    explained_variance    | 0.304        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.6          |
|    n_updates             | 1280         |
|    policy_gradient_loss  | -0.00255     |
|    std                   | 1.13         |
|    value_loss            | 20.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.79        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.79        |
| reward                   | -1.615936   |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -1.1e+03    |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 32          |
|    time_elapsed          | 962         |
|    total_timesteps       | 266240      |
| train/                   |             |
|    approx_kl             | 0.005395707 |
|    clip_fraction         | 0.0424      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.01        |
|    cost_value_loss       | 0.696       |
|    cost_values           | 0.917       |
|    entropy               | -3.08       |
|    entropy_loss          | -3.08       |
|    explained_variance    | 0.595       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.31        |
|    n_updates             | 1290        |
|    policy_gradient_loss  | -0.00453    |
|    std                   | 1.13        |
|    value_loss            | 12.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.239       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.239       |
| reward                   | -1.3575201  |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -1.1e+03    |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 33          |
|    time_elapsed          | 998         |
|    total_timesteps       | 268288      |
| train/                   |             |
|    approx_kl             | 0.003910938 |
|    clip_fraction         | 0.0106      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.01        |
|    cost_value_loss       | 0.624       |
|    cost_values           | 0.923       |
|    entropy               | -3.08       |
|    entropy_loss          | -3.08       |
|    explained_variance    | -0.982      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.8        |
|    n_updates             | 1300        |
|    policy_gradient_loss  | -0.00188    |
|    std                   | 1.13        |
|    value_loss            | 50.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0585      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0585      |
| reward                   | -0.8195866  |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -1.09e+03   |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 34          |
|    time_elapsed          | 1031        |
|    total_timesteps       | 270336      |
| train/                   |             |
|    approx_kl             | 0.006023515 |
|    clip_fraction         | 0.0335      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.08        |
|    cost_value_loss       | 0.988       |
|    cost_values           | 0.953       |
|    entropy               | -3.08       |
|    entropy_loss          | -3.08       |
|    explained_variance    | 0.136       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 22.5        |
|    n_updates             | 1310        |
|    policy_gradient_loss  | -0.00517    |
|    std                   | 1.13        |
|    value_loss            | 48.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.105       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.105       |
| reward                   | -0.71314037 |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -1.08e+03   |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 35          |
|    time_elapsed          | 1056        |
|    total_timesteps       | 272384      |
| train/                   |             |
|    approx_kl             | 0.005532347 |
|    clip_fraction         | 0.0565      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.932       |
|    cost_value_loss       | 0.235       |
|    cost_values           | 0.955       |
|    entropy               | -3.08       |
|    entropy_loss          | -3.08       |
|    explained_variance    | 0.026       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.87        |
|    n_updates             | 1320        |
|    policy_gradient_loss  | -0.00698    |
|    std                   | 1.13        |
|    value_loss            | 17          |
------------------------------------------
------------------------------------------
| avg_speed                | 0.137       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.137       |
| reward                   | -0.7640873  |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -1.08e+03   |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 36          |
|    time_elapsed          | 1080        |
|    total_timesteps       | 274432      |
| train/                   |             |
|    approx_kl             | 0.010270732 |
|    clip_fraction         | 0.0743      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.875       |
|    cost_value_loss       | 0.354       |
|    cost_values           | 0.883       |
|    entropy               | -3.07       |
|    entropy_loss          | -3.08       |
|    explained_variance    | 0.279       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.11        |
|    n_updates             | 1330        |
|    policy_gradient_loss  | -0.00765    |
|    std                   | 1.12        |
|    value_loss            | 6.19        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.702        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.702        |
| reward                   | -0.85033405  |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -1.05e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 37           |
|    time_elapsed          | 1105         |
|    total_timesteps       | 276480       |
| train/                   |              |
|    approx_kl             | 0.0027253751 |
|    clip_fraction         | 0.0249       |
|    clip_range            | 0.2          |
|    cost_returns          | 1            |
|    cost_value_loss       | 0.87         |
|    cost_values           | 0.936        |
|    entropy               | -3.06        |
|    entropy_loss          | -3.06        |
|    explained_variance    | 0.167        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.8         |
|    n_updates             | 1340         |
|    policy_gradient_loss  | -0.00103     |
|    std                   | 1.12         |
|    value_loss            | 28.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.67        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.67        |
| reward                   | -0.8099492  |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -1.04e+03   |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 38          |
|    time_elapsed          | 1130        |
|    total_timesteps       | 278528      |
| train/                   |             |
|    approx_kl             | 0.004165626 |
|    clip_fraction         | 0.0331      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.85        |
|    cost_value_loss       | 0.144       |
|    cost_values           | 0.877       |
|    entropy               | -3.06       |
|    entropy_loss          | -3.06       |
|    explained_variance    | 0.627       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.65        |
|    n_updates             | 1350        |
|    policy_gradient_loss  | -0.00472    |
|    std                   | 1.12        |
|    value_loss            | 4.07        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.16        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.16        |
| reward                   | -1.6713834  |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -1.03e+03   |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 39          |
|    time_elapsed          | 1153        |
|    total_timesteps       | 280576      |
| train/                   |             |
|    approx_kl             | 0.003598948 |
|    clip_fraction         | 0.0139      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.83        |
|    cost_value_loss       | 0.296       |
|    cost_values           | 0.837       |
|    entropy               | -3.06       |
|    entropy_loss          | -3.06       |
|    explained_variance    | 0.17        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.28        |
|    n_updates             | 1360        |
|    policy_gradient_loss  | -0.00248    |
|    std                   | 1.12        |
|    value_loss            | 3.94        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.68         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.68         |
| reward                   | -1.0446986   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -1.02e+03    |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 40           |
|    time_elapsed          | 1176         |
|    total_timesteps       | 282624       |
| train/                   |              |
|    approx_kl             | 0.0033644019 |
|    clip_fraction         | 0.0126       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.689        |
|    cost_value_loss       | 0.0322       |
|    cost_values           | 0.798        |
|    entropy               | -3.06        |
|    entropy_loss          | -3.06        |
|    explained_variance    | 0.228        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 26.4         |
|    n_updates             | 1370         |
|    policy_gradient_loss  | -0.00115     |
|    std                   | 1.12         |
|    value_loss            | 61.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.21         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.21         |
| reward                   | -1.2010312   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 41           |
|    time_elapsed          | 1199         |
|    total_timesteps       | 284672       |
| train/                   |              |
|    approx_kl             | 0.0056183236 |
|    clip_fraction         | 0.0341       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.819        |
|    cost_value_loss       | 0.56         |
|    cost_values           | 0.785        |
|    entropy               | -3.06        |
|    entropy_loss          | -3.06        |
|    explained_variance    | 0.406        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.46         |
|    n_updates             | 1380         |
|    policy_gradient_loss  | -0.00452     |
|    std                   | 1.12         |
|    value_loss            | 13.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.34         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.34         |
| reward                   | -0.8951925   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -983         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 42           |
|    time_elapsed          | 1222         |
|    total_timesteps       | 286720       |
| train/                   |              |
|    approx_kl             | 0.0023824112 |
|    clip_fraction         | 0.0191       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.698        |
|    cost_value_loss       | 0.0467       |
|    cost_values           | 0.765        |
|    entropy               | -3.07        |
|    entropy_loss          | -3.07        |
|    explained_variance    | 0.0348       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.4         |
|    n_updates             | 1390         |
|    policy_gradient_loss  | -0.00266     |
|    std                   | 1.12         |
|    value_loss            | 21.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.94         |
| reward                   | -0.6521268   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -978         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 43           |
|    time_elapsed          | 1246         |
|    total_timesteps       | 288768       |
| train/                   |              |
|    approx_kl             | 0.0070767812 |
|    clip_fraction         | 0.0513       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.7          |
|    cost_value_loss       | 0.207        |
|    cost_values           | 0.71         |
|    entropy               | -3.07        |
|    entropy_loss          | -3.07        |
|    explained_variance    | 0.597        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.99         |
|    n_updates             | 1400         |
|    policy_gradient_loss  | -0.00702     |
|    std                   | 1.12         |
|    value_loss            | 11.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.55         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.55         |
| reward                   | -0.5481142   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -972         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 44           |
|    time_elapsed          | 1269         |
|    total_timesteps       | 290816       |
| train/                   |              |
|    approx_kl             | 0.0032593135 |
|    clip_fraction         | 0.0147       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.652        |
|    cost_value_loss       | 0.125        |
|    cost_values           | 0.664        |
|    entropy               | -3.07        |
|    entropy_loss          | -3.07        |
|    explained_variance    | 0.0473       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.46         |
|    n_updates             | 1410         |
|    policy_gradient_loss  | -0.0028      |
|    std                   | 1.12         |
|    value_loss            | 18.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.61         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.61         |
| reward                   | -0.644842    |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -969         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 45           |
|    time_elapsed          | 1292         |
|    total_timesteps       | 292864       |
| train/                   |              |
|    approx_kl             | 0.0044623325 |
|    clip_fraction         | 0.0464       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.788        |
|    cost_value_loss       | 0.591        |
|    cost_values           | 0.771        |
|    entropy               | -3.07        |
|    entropy_loss          | -3.07        |
|    explained_variance    | 0.0806       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5            |
|    n_updates             | 1420         |
|    policy_gradient_loss  | -0.00698     |
|    std                   | 1.13         |
|    value_loss            | 10.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -0.14413232  |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -952         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 46           |
|    time_elapsed          | 1315         |
|    total_timesteps       | 294912       |
| train/                   |              |
|    approx_kl             | 0.0058697336 |
|    clip_fraction         | 0.0229       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.914        |
|    cost_value_loss       | 1.06         |
|    cost_values           | 0.777        |
|    entropy               | -3.07        |
|    entropy_loss          | -3.07        |
|    explained_variance    | 0.57         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.8         |
|    n_updates             | 1430         |
|    policy_gradient_loss  | -0.00209     |
|    std                   | 1.13         |
|    value_loss            | 44.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.68        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.68        |
| reward                   | -0.5430343  |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -946        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 47          |
|    time_elapsed          | 1338        |
|    total_timesteps       | 296960      |
| train/                   |             |
|    approx_kl             | 0.007393484 |
|    clip_fraction         | 0.0633      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.813       |
|    cost_value_loss       | 0.319       |
|    cost_values           | 0.751       |
|    entropy               | -3.08       |
|    entropy_loss          | -3.08       |
|    explained_variance    | 0.495       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.7        |
|    n_updates             | 1440        |
|    policy_gradient_loss  | -0.00608    |
|    std                   | 1.13        |
|    value_loss            | 32.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.24         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.24         |
| reward                   | -0.94984406  |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -949         |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 48           |
|    time_elapsed          | 1361         |
|    total_timesteps       | 299008       |
| train/                   |              |
|    approx_kl             | 0.0016716295 |
|    clip_fraction         | 0.00171      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.683        |
|    cost_value_loss       | 0.105        |
|    cost_values           | 0.74         |
|    entropy               | -3.08        |
|    entropy_loss          | -3.08        |
|    explained_variance    | 0.559        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 93.9         |
|    n_updates             | 1450         |
|    policy_gradient_loss  | -0.00122     |
|    std                   | 1.13         |
|    value_loss            | 203          |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.27        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.27        |
| reward                   | -1.3650132  |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -953        |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 49          |
|    time_elapsed          | 1384        |
|    total_timesteps       | 301056      |
| train/                   |             |
|    approx_kl             | 0.004100208 |
|    clip_fraction         | 0.0393      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.878       |
|    cost_value_loss       | 0.546       |
|    cost_values           | 0.757       |
|    entropy               | -3.08       |
|    entropy_loss          | -3.08       |
|    explained_variance    | 0.659       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 27.5        |
|    n_updates             | 1460        |
|    policy_gradient_loss  | -0.0051     |
|    std                   | 1.13        |
|    value_loss            | 60.4        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ent-coefficient-ppol/1vjpjg9h
----------------------------------
| avg_speed          | 3.31      |
| cost               | 0         |
| is_success         | 0         |
| max_speed          | 3.31      |
| reward             | -1.336226 |
| rollout/           |           |
|    ep_len_mean     | 961       |
|    ep_rew_mean     | -950      |
| time/              |           |
|    fps             | 92        |
|    iterations      | 1         |
|    time_elapsed    | 22        |
|    total_timesteps | 303104    |
----------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -1.2656605   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -945         |
| time/                    |              |
|    fps                   | 90           |
|    iterations            | 2            |
|    time_elapsed          | 45           |
|    total_timesteps       | 305152       |
| train/                   |              |
|    approx_kl             | 0.0051598083 |
|    clip_fraction         | 0.0231       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.564        |
|    cost_value_loss       | 0.0377       |
|    cost_values           | 0.632        |
|    entropy               | -3.07        |
|    entropy_loss          | -3.07        |
|    explained_variance    | 0.704        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.46         |
|    n_updates             | 1480         |
|    policy_gradient_loss  | -0.004       |
|    std                   | 1.12         |
|    value_loss            | 21           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.45         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.45         |
| reward                   | -0.94785553  |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -938         |
| time/                    |              |
|    fps                   | 89           |
|    iterations            | 3            |
|    time_elapsed          | 68           |
|    total_timesteps       | 307200       |
| train/                   |              |
|    approx_kl             | 0.0039518913 |
|    clip_fraction         | 0.0336       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.647        |
|    cost_value_loss       | 0.377        |
|    cost_values           | 0.63         |
|    entropy               | -3.07        |
|    entropy_loss          | -3.07        |
|    explained_variance    | 0.821        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.39         |
|    n_updates             | 1490         |
|    policy_gradient_loss  | -0.00465     |
|    std                   | 1.13         |
|    value_loss            | 5.98         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -1.4114509  |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -932        |
| time/                    |             |
|    fps                   | 88          |
|    iterations            | 4           |
|    time_elapsed          | 92          |
|    total_timesteps       | 309248      |
| train/                   |             |
|    approx_kl             | 0.003974853 |
|    clip_fraction         | 0.00562     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.637       |
|    cost_value_loss       | 0.167       |
|    cost_values           | 0.671       |
|    entropy               | -3.07       |
|    entropy_loss          | -3.07       |
|    explained_variance    | 0.702       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15          |
|    n_updates             | 1500        |
|    policy_gradient_loss  | -0.000483   |
|    std                   | 1.12        |
|    value_loss            | 40.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -1.3018327  |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -926        |
| time/                    |             |
|    fps                   | 88          |
|    iterations            | 5           |
|    time_elapsed          | 116         |
|    total_timesteps       | 311296      |
| train/                   |             |
|    approx_kl             | 0.005916368 |
|    clip_fraction         | 0.0493      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.704       |
|    cost_value_loss       | 0.45        |
|    cost_values           | 0.676       |
|    entropy               | -3.07       |
|    entropy_loss          | -3.07       |
|    explained_variance    | 0.361       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.37        |
|    n_updates             | 1510        |
|    policy_gradient_loss  | -0.00612    |
|    std                   | 1.12        |
|    value_loss            | 18.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.24        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.24        |
| reward                   | -0.8741354  |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -933        |
| time/                    |             |
|    fps                   | 88          |
|    iterations            | 6           |
|    time_elapsed          | 139         |
|    total_timesteps       | 313344      |
| train/                   |             |
|    approx_kl             | 0.005186634 |
|    clip_fraction         | 0.0334      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.731       |
|    cost_value_loss       | 0.505       |
|    cost_values           | 0.689       |
|    entropy               | -3.07       |
|    entropy_loss          | -3.07       |
|    explained_variance    | 0.609       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 22.3        |
|    n_updates             | 1520        |
|    policy_gradient_loss  | -0.00406    |
|    std                   | 1.12        |
|    value_loss            | 47.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -1.1557846  |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -931        |
| time/                    |             |
|    fps                   | 87          |
|    iterations            | 7           |
|    time_elapsed          | 163         |
|    total_timesteps       | 315392      |
| train/                   |             |
|    approx_kl             | 0.005607605 |
|    clip_fraction         | 0.0529      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.849       |
|    cost_value_loss       | 1.09        |
|    cost_values           | 0.708       |
|    entropy               | -3.07       |
|    entropy_loss          | -3.07       |
|    explained_variance    | 0.597       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.26        |
|    n_updates             | 1530        |
|    policy_gradient_loss  | -0.00578    |
|    std                   | 1.12        |
|    value_loss            | 9.73        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.97         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.97         |
| reward                   | -2.346646    |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -933         |
| time/                    |              |
|    fps                   | 87           |
|    iterations            | 8            |
|    time_elapsed          | 187          |
|    total_timesteps       | 317440       |
| train/                   |              |
|    approx_kl             | 0.0051042167 |
|    clip_fraction         | 0.0404       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.872        |
|    cost_value_loss       | 0.611        |
|    cost_values           | 0.775        |
|    entropy               | -3.07        |
|    entropy_loss          | -3.07        |
|    explained_variance    | 0.444        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.45         |
|    n_updates             | 1540         |
|    policy_gradient_loss  | -0.00305     |
|    std                   | 1.12         |
|    value_loss            | 15.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.84        |
| reward                   | -2.006506   |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -952        |
| time/                    |             |
|    fps                   | 84          |
|    iterations            | 9           |
|    time_elapsed          | 217         |
|    total_timesteps       | 319488      |
| train/                   |             |
|    approx_kl             | 0.002471047 |
|    clip_fraction         | 0.00459     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.661       |
|    cost_value_loss       | 0.107       |
|    cost_values           | 0.752       |
|    entropy               | -3.07       |
|    entropy_loss          | -3.07       |
|    explained_variance    | 0.705       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.97        |
|    n_updates             | 1550        |
|    policy_gradient_loss  | -0.00169    |
|    std                   | 1.12        |
|    value_loss            | 34.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.93        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.93        |
| reward                   | -1.1852885  |
| rollout/                 |             |
|    ep_len_mean           | 986         |
|    ep_rew_mean           | -960        |
| time/                    |             |
|    fps                   | 81          |
|    iterations            | 10          |
|    time_elapsed          | 251         |
|    total_timesteps       | 321536      |
| train/                   |             |
|    approx_kl             | 0.000562763 |
|    clip_fraction         | 4.88e-05    |
|    clip_range            | 0.2         |
|    cost_returns          | 0.723       |
|    cost_value_loss       | 0.424       |
|    cost_values           | 0.687       |
|    entropy               | -3.07       |
|    entropy_loss          | -3.07       |
|    explained_variance    | 0.557       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 34          |
|    n_updates             | 1560        |
|    policy_gradient_loss  | -0.000633   |
|    std                   | 1.12        |
|    value_loss            | 108         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -2.0296812   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -968         |
| time/                    |              |
|    fps                   | 78           |
|    iterations            | 11           |
|    time_elapsed          | 286          |
|    total_timesteps       | 323584       |
| train/                   |              |
|    approx_kl             | 0.0050421683 |
|    clip_fraction         | 0.0164       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.732        |
|    cost_value_loss       | 0.14         |
|    cost_values           | 0.756        |
|    entropy               | -3.06        |
|    entropy_loss          | -3.07        |
|    explained_variance    | 0.703        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.4         |
|    n_updates             | 1570         |
|    policy_gradient_loss  | -0.0024      |
|    std                   | 1.12         |
|    value_loss            | 59.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.1413563  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -978        |
| time/                    |             |
|    fps                   | 76          |
|    iterations            | 12          |
|    time_elapsed          | 319         |
|    total_timesteps       | 325632      |
| train/                   |             |
|    approx_kl             | 0.006126402 |
|    clip_fraction         | 0.0159      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.763       |
|    cost_value_loss       | 0.191       |
|    cost_values           | 0.767       |
|    entropy               | -3.06       |
|    entropy_loss          | -3.06       |
|    explained_variance    | -1.83       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.49        |
|    n_updates             | 1580        |
|    policy_gradient_loss  | -0.00211    |
|    std                   | 1.12        |
|    value_loss            | 29.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.1153592  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -975        |
| time/                    |             |
|    fps                   | 76          |
|    iterations            | 13          |
|    time_elapsed          | 348         |
|    total_timesteps       | 327680      |
| train/                   |             |
|    approx_kl             | 0.005616213 |
|    clip_fraction         | 0.047       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.631       |
|    cost_value_loss       | 0.158       |
|    cost_values           | 0.654       |
|    entropy               | -3.06       |
|    entropy_loss          | -3.06       |
|    explained_variance    | 0.653       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 31.6        |
|    n_updates             | 1590        |
|    policy_gradient_loss  | -0.00503    |
|    std                   | 1.12        |
|    value_loss            | 69.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.61         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.61         |
| reward                   | -1.3622789   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -978         |
| time/                    |              |
|    fps                   | 75           |
|    iterations            | 14           |
|    time_elapsed          | 380          |
|    total_timesteps       | 329728       |
| train/                   |              |
|    approx_kl             | 0.0036584246 |
|    clip_fraction         | 0.0166       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.732        |
|    cost_value_loss       | 0.41         |
|    cost_values           | 0.718        |
|    entropy               | -3.05        |
|    entropy_loss          | -3.06        |
|    explained_variance    | 0.673        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.14         |
|    n_updates             | 1600         |
|    policy_gradient_loss  | -0.00324     |
|    std                   | 1.11         |
|    value_loss            | 9.98         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.09         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.09         |
| reward                   | -0.6345802   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -983         |
| time/                    |              |
|    fps                   | 74           |
|    iterations            | 15           |
|    time_elapsed          | 411          |
|    total_timesteps       | 331776       |
| train/                   |              |
|    approx_kl             | 0.0052369945 |
|    clip_fraction         | 0.0416       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.871        |
|    cost_value_loss       | 0.515        |
|    cost_values           | 0.757        |
|    entropy               | -3.04        |
|    entropy_loss          | -3.04        |
|    explained_variance    | 0.473        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.41         |
|    n_updates             | 1610         |
|    policy_gradient_loss  | -0.00526     |
|    std                   | 1.11         |
|    value_loss            | 20.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.59         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.59         |
| reward                   | -0.46587065  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -989         |
| time/                    |              |
|    fps                   | 73           |
|    iterations            | 16           |
|    time_elapsed          | 443          |
|    total_timesteps       | 333824       |
| train/                   |              |
|    approx_kl             | 0.0047489307 |
|    clip_fraction         | 0.0332       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.791        |
|    cost_value_loss       | 0.151        |
|    cost_values           | 0.796        |
|    entropy               | -3.04        |
|    entropy_loss          | -3.04        |
|    explained_variance    | 0.606        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.49         |
|    n_updates             | 1620         |
|    policy_gradient_loss  | -0.00343     |
|    std                   | 1.11         |
|    value_loss            | 9.46         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.4767561   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -998         |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 17           |
|    time_elapsed          | 481          |
|    total_timesteps       | 335872       |
| train/                   |              |
|    approx_kl             | 0.0035550222 |
|    clip_fraction         | 0.0227       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.665        |
|    cost_value_loss       | 0.0292       |
|    cost_values           | 0.73         |
|    entropy               | -3.04        |
|    entropy_loss          | -3.04        |
|    explained_variance    | 0.662        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.89         |
|    n_updates             | 1630         |
|    policy_gradient_loss  | -0.00269     |
|    std                   | 1.1          |
|    value_loss            | 13.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.39         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.39         |
| reward                   | -0.92405665  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 18           |
|    time_elapsed          | 520          |
|    total_timesteps       | 337920       |
| train/                   |              |
|    approx_kl             | 0.0066559445 |
|    clip_fraction         | 0.0304       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.655        |
|    cost_value_loss       | 0.31         |
|    cost_values           | 0.577        |
|    entropy               | -3.04        |
|    entropy_loss          | -3.04        |
|    explained_variance    | 0.682        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 28.7         |
|    n_updates             | 1640         |
|    policy_gradient_loss  | -0.00378     |
|    std                   | 1.1          |
|    value_loss            | 69.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.9550877   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.03e+03    |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 19           |
|    time_elapsed          | 557          |
|    total_timesteps       | 339968       |
| train/                   |              |
|    approx_kl             | 0.0047711213 |
|    clip_fraction         | 0.0179       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.607        |
|    cost_value_loss       | 0.449        |
|    cost_values           | 0.568        |
|    entropy               | -3.04        |
|    entropy_loss          | -3.04        |
|    explained_variance    | 0.478        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 73.2         |
|    n_updates             | 1650         |
|    policy_gradient_loss  | -0.00391     |
|    std                   | 1.11         |
|    value_loss            | 154          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -0.7291498   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.03e+03    |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 20           |
|    time_elapsed          | 588          |
|    total_timesteps       | 342016       |
| train/                   |              |
|    approx_kl             | 0.0046778666 |
|    clip_fraction         | 0.0259       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.598        |
|    cost_value_loss       | 0.222        |
|    cost_values           | 0.606        |
|    entropy               | -3.04        |
|    entropy_loss          | -3.04        |
|    explained_variance    | 0.61         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 57.5         |
|    n_updates             | 1660         |
|    policy_gradient_loss  | -0.00595     |
|    std                   | 1.11         |
|    value_loss            | 113          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.09         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.09         |
| reward                   | -0.52218187  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.04e+03    |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 21           |
|    time_elapsed          | 611          |
|    total_timesteps       | 344064       |
| train/                   |              |
|    approx_kl             | 0.0059064347 |
|    clip_fraction         | 0.0525       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.832        |
|    cost_value_loss       | 1.12         |
|    cost_values           | 0.678        |
|    entropy               | -3.04        |
|    entropy_loss          | -3.04        |
|    explained_variance    | 0.748        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.92         |
|    n_updates             | 1670         |
|    policy_gradient_loss  | -0.0061      |
|    std                   | 1.1          |
|    value_loss            | 16.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.86343527 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.05e+03   |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 22          |
|    time_elapsed          | 634         |
|    total_timesteps       | 346112      |
| train/                   |             |
|    approx_kl             | 0.009226639 |
|    clip_fraction         | 0.0364      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.06        |
|    cost_value_loss       | 0.499       |
|    cost_values           | 0.839       |
|    entropy               | -3.03       |
|    entropy_loss          | -3.03       |
|    explained_variance    | -0.394      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.61        |
|    n_updates             | 1680        |
|    policy_gradient_loss  | -0.0036     |
|    std                   | 1.1         |
|    value_loss            | 22.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.06         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.06         |
| reward                   | -1.2828155   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.04e+03    |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 23           |
|    time_elapsed          | 669          |
|    total_timesteps       | 348160       |
| train/                   |              |
|    approx_kl             | 0.0023494975 |
|    clip_fraction         | 0.00425      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.905        |
|    cost_value_loss       | 0.509        |
|    cost_values           | 0.897        |
|    entropy               | -3.03        |
|    entropy_loss          | -3.03        |
|    explained_variance    | -2.08        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.96         |
|    n_updates             | 1690         |
|    policy_gradient_loss  | -0.000959    |
|    std                   | 1.1          |
|    value_loss            | 30.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.96        |
| reward                   | -1.069978   |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.05e+03   |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 24          |
|    time_elapsed          | 709         |
|    total_timesteps       | 350208      |
| train/                   |             |
|    approx_kl             | 0.004096608 |
|    clip_fraction         | 0.0246      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.11        |
|    cost_value_loss       | 2.29        |
|    cost_values           | 0.896       |
|    entropy               | -3.03       |
|    entropy_loss          | -3.03       |
|    explained_variance    | 0.0853      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.63        |
|    n_updates             | 1700        |
|    policy_gradient_loss  | -0.00343    |
|    std                   | 1.1         |
|    value_loss            | 12.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.63         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.63         |
| reward                   | -1.2359813   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.05e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 25           |
|    time_elapsed          | 747          |
|    total_timesteps       | 352256       |
| train/                   |              |
|    approx_kl             | 0.0064749215 |
|    clip_fraction         | 0.033        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.917        |
|    cost_value_loss       | 0.483        |
|    cost_values           | 0.876        |
|    entropy               | -3.03        |
|    entropy_loss          | -3.03        |
|    explained_variance    | -0.478       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.5          |
|    n_updates             | 1710         |
|    policy_gradient_loss  | -0.00451     |
|    std                   | 1.1          |
|    value_loss            | 30.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.2875603  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.05e+03   |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 26          |
|    time_elapsed          | 784         |
|    total_timesteps       | 354304      |
| train/                   |             |
|    approx_kl             | 0.004820741 |
|    clip_fraction         | 0.0329      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.814       |
|    cost_value_loss       | 0.174       |
|    cost_values           | 0.838       |
|    entropy               | -3.03       |
|    entropy_loss          | -3.03       |
|    explained_variance    | 0.124       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.47        |
|    n_updates             | 1720        |
|    policy_gradient_loss  | -0.00463    |
|    std                   | 1.1         |
|    value_loss            | 16.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.753823    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.05e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 27           |
|    time_elapsed          | 824          |
|    total_timesteps       | 356352       |
| train/                   |              |
|    approx_kl             | 0.0064945016 |
|    clip_fraction         | 0.0447       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.672        |
|    cost_value_loss       | 0.0141       |
|    cost_values           | 0.758        |
|    entropy               | -3.03        |
|    entropy_loss          | -3.03        |
|    explained_variance    | 0.526        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.91         |
|    n_updates             | 1730         |
|    policy_gradient_loss  | -0.0048      |
|    std                   | 1.1          |
|    value_loss            | 13.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0723      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0723      |
| reward                   | -1.6443225  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.06e+03   |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 28          |
|    time_elapsed          | 862         |
|    total_timesteps       | 358400      |
| train/                   |             |
|    approx_kl             | 0.009300701 |
|    clip_fraction         | 0.0683      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.09        |
|    cost_value_loss       | 1.34        |
|    cost_values           | 0.851       |
|    entropy               | -3.03       |
|    entropy_loss          | -3.03       |
|    explained_variance    | 0.256       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.48        |
|    n_updates             | 1740        |
|    policy_gradient_loss  | -0.00729    |
|    std                   | 1.1         |
|    value_loss            | 12.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -0.7823801   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.07e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 29           |
|    time_elapsed          | 895          |
|    total_timesteps       | 360448       |
| train/                   |              |
|    approx_kl             | 0.0038559972 |
|    clip_fraction         | 0.00957      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.788        |
|    cost_value_loss       | 0.336        |
|    cost_values           | 0.767        |
|    entropy               | -3.03        |
|    entropy_loss          | -3.03        |
|    explained_variance    | 0.266        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.5         |
|    n_updates             | 1750         |
|    policy_gradient_loss  | -0.0016      |
|    std                   | 1.1          |
|    value_loss            | 56.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.77         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.77         |
| reward                   | -1.1103158   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.07e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 30           |
|    time_elapsed          | 924          |
|    total_timesteps       | 362496       |
| train/                   |              |
|    approx_kl             | 0.0035124645 |
|    clip_fraction         | 0.0353       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.894        |
|    cost_value_loss       | 0.674        |
|    cost_values           | 0.749        |
|    entropy               | -3.03        |
|    entropy_loss          | -3.03        |
|    explained_variance    | 0.668        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 49           |
|    n_updates             | 1760         |
|    policy_gradient_loss  | -0.00415     |
|    std                   | 1.1          |
|    value_loss            | 111          |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.29        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.29        |
| reward                   | -1.2397311  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.07e+03   |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 31          |
|    time_elapsed          | 947         |
|    total_timesteps       | 364544      |
| train/                   |             |
|    approx_kl             | 0.005403072 |
|    clip_fraction         | 0.0476      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.615       |
|    cost_value_loss       | 0.0167      |
|    cost_values           | 0.656       |
|    entropy               | -3.03       |
|    entropy_loss          | -3.03       |
|    explained_variance    | 0.827       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.69        |
|    n_updates             | 1770        |
|    policy_gradient_loss  | -0.00663    |
|    std                   | 1.1         |
|    value_loss            | 9.46        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.1658359  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.07e+03   |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 32          |
|    time_elapsed          | 982         |
|    total_timesteps       | 366592      |
| train/                   |             |
|    approx_kl             | 0.003753774 |
|    clip_fraction         | 0.0436      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.846       |
|    cost_value_loss       | 0.553       |
|    cost_values           | 0.766       |
|    entropy               | -3.02       |
|    entropy_loss          | -3.03       |
|    explained_variance    | 0.858       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.81        |
|    n_updates             | 1780        |
|    policy_gradient_loss  | -0.00426    |
|    std                   | 1.1         |
|    value_loss            | 10.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.7          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.7          |
| reward                   | -0.82977545  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.06e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 33           |
|    time_elapsed          | 1022         |
|    total_timesteps       | 368640       |
| train/                   |              |
|    approx_kl             | 0.0063611283 |
|    clip_fraction         | 0.0752       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.783        |
|    cost_value_loss       | 0.129        |
|    cost_values           | 0.784        |
|    entropy               | -3.01        |
|    entropy_loss          | -3.02        |
|    explained_variance    | 0.827        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.01         |
|    n_updates             | 1790         |
|    policy_gradient_loss  | -0.00844     |
|    std                   | 1.09         |
|    value_loss            | 8.82         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.91         |
| reward                   | -1.9013361   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.05e+03    |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 34           |
|    time_elapsed          | 1055         |
|    total_timesteps       | 370688       |
| train/                   |              |
|    approx_kl             | 0.0071093524 |
|    clip_fraction         | 0.0675       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.37         |
|    cost_value_loss       | 2.31         |
|    cost_values           | 0.883        |
|    entropy               | -3.01        |
|    entropy_loss          | -3.01        |
|    explained_variance    | 0.47         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.19         |
|    n_updates             | 1800         |
|    policy_gradient_loss  | -0.00632     |
|    std                   | 1.09         |
|    value_loss            | 13           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.91         |
| reward                   | -1.4125311   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.06e+03    |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 35           |
|    time_elapsed          | 1092         |
|    total_timesteps       | 372736       |
| train/                   |              |
|    approx_kl             | 0.0046774102 |
|    clip_fraction         | 0.0216       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.897        |
|    cost_value_loss       | 0.525        |
|    cost_values           | 0.79         |
|    entropy               | -3.01        |
|    entropy_loss          | -3.01        |
|    explained_variance    | 0.841        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.15         |
|    n_updates             | 1810         |
|    policy_gradient_loss  | -0.00327     |
|    std                   | 1.09         |
|    value_loss            | 16.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.1253313  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.06e+03   |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 36          |
|    time_elapsed          | 1131        |
|    total_timesteps       | 374784      |
| train/                   |             |
|    approx_kl             | 0.005098419 |
|    clip_fraction         | 0.0107      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.742       |
|    cost_value_loss       | 0.0159      |
|    cost_values           | 0.841       |
|    entropy               | -3.01       |
|    entropy_loss          | -3.01       |
|    explained_variance    | 0.755       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.52        |
|    n_updates             | 1820        |
|    policy_gradient_loss  | -0.00202    |
|    std                   | 1.09        |
|    value_loss            | 19.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.63        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.63        |
| reward                   | -0.84936786 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.07e+03   |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 37          |
|    time_elapsed          | 1170        |
|    total_timesteps       | 376832      |
| train/                   |             |
|    approx_kl             | 0.005895202 |
|    clip_fraction         | 0.0384      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.654       |
|    cost_value_loss       | 0.012       |
|    cost_values           | 0.72        |
|    entropy               | -3.01       |
|    entropy_loss          | -3.01       |
|    explained_variance    | 0.598       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.22        |
|    n_updates             | 1830        |
|    policy_gradient_loss  | -0.00353    |
|    std                   | 1.09        |
|    value_loss            | 7.33        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.63         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.63         |
| reward                   | -0.6900752   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.07e+03    |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 38           |
|    time_elapsed          | 1207         |
|    total_timesteps       | 378880       |
| train/                   |              |
|    approx_kl             | 0.0072077485 |
|    clip_fraction         | 0.0768       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.686        |
|    cost_value_loss       | 0.651        |
|    cost_values           | 0.582        |
|    entropy               | -3.01        |
|    entropy_loss          | -3.01        |
|    explained_variance    | 0.889        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.44         |
|    n_updates             | 1840         |
|    policy_gradient_loss  | -0.00739     |
|    std                   | 1.09         |
|    value_loss            | 12.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.5734869  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.06e+03   |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 39          |
|    time_elapsed          | 1245        |
|    total_timesteps       | 380928      |
| train/                   |             |
|    approx_kl             | 0.007319982 |
|    clip_fraction         | 0.07        |
|    clip_range            | 0.2         |
|    cost_returns          | 1.26        |
|    cost_value_loss       | 0.795       |
|    cost_values           | 0.913       |
|    entropy               | -3.01       |
|    entropy_loss          | -3.01       |
|    explained_variance    | 0.597       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.82        |
|    n_updates             | 1850        |
|    policy_gradient_loss  | -0.00694    |
|    std                   | 1.09        |
|    value_loss            | 9.94        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.27         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.27         |
| reward                   | -0.78076553  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.07e+03    |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 40           |
|    time_elapsed          | 1283         |
|    total_timesteps       | 382976       |
| train/                   |              |
|    approx_kl             | 0.0054092053 |
|    clip_fraction         | 0.0237       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.645        |
|    cost_value_loss       | 0.0662       |
|    cost_values           | 0.741        |
|    entropy               | -3.01        |
|    entropy_loss          | -3.01        |
|    explained_variance    | 0.833        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.01         |
|    n_updates             | 1860         |
|    policy_gradient_loss  | -0.00263     |
|    std                   | 1.09         |
|    value_loss            | 14.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -0.8981427   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.07e+03    |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 41           |
|    time_elapsed          | 1318         |
|    total_timesteps       | 385024       |
| train/                   |              |
|    approx_kl             | 0.0036790804 |
|    clip_fraction         | 0.0264       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.449        |
|    cost_value_loss       | 0.0263       |
|    cost_values           | 0.489        |
|    entropy               | -3.01        |
|    entropy_loss          | -3.01        |
|    explained_variance    | 0.82         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 32.4         |
|    n_updates             | 1870         |
|    policy_gradient_loss  | -0.00352     |
|    std                   | 1.09         |
|    value_loss            | 75.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.99        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.99        |
| reward                   | -0.9393115  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.07e+03   |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 42          |
|    time_elapsed          | 1349        |
|    total_timesteps       | 387072      |
| train/                   |             |
|    approx_kl             | 0.004003446 |
|    clip_fraction         | 0.035       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.508       |
|    cost_value_loss       | 0.152       |
|    cost_values           | 0.502       |
|    entropy               | -3          |
|    entropy_loss          | -3.01       |
|    explained_variance    | 0.867       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.8        |
|    n_updates             | 1880        |
|    policy_gradient_loss  | -0.00439    |
|    std                   | 1.09        |
|    value_loss            | 26.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.6          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.6          |
| reward                   | -0.74609935  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.07e+03    |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 43           |
|    time_elapsed          | 1372         |
|    total_timesteps       | 389120       |
| train/                   |              |
|    approx_kl             | 0.0044313506 |
|    clip_fraction         | 0.029        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.625        |
|    cost_value_loss       | 0.0447       |
|    cost_values           | 0.678        |
|    entropy               | -3.01        |
|    entropy_loss          | -3.01        |
|    explained_variance    | 0.92         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.79         |
|    n_updates             | 1890         |
|    policy_gradient_loss  | -0.00443     |
|    std                   | 1.09         |
|    value_loss            | 6.04         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -1.0192989  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.07e+03   |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 44          |
|    time_elapsed          | 1395        |
|    total_timesteps       | 391168      |
| train/                   |             |
|    approx_kl             | 0.006216205 |
|    clip_fraction         | 0.0447      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.638       |
|    cost_value_loss       | 0.216       |
|    cost_values           | 0.634       |
|    entropy               | -3.01       |
|    entropy_loss          | -3.01       |
|    explained_variance    | 0.727       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.14        |
|    n_updates             | 1900        |
|    policy_gradient_loss  | -0.00706    |
|    std                   | 1.09        |
|    value_loss            | 15.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.79         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.79         |
| reward                   | -0.66330975  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.06e+03    |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 45           |
|    time_elapsed          | 1418         |
|    total_timesteps       | 393216       |
| train/                   |              |
|    approx_kl             | 0.0055728485 |
|    clip_fraction         | 0.0572       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.801        |
|    cost_value_loss       | 0.407        |
|    cost_values           | 0.712        |
|    entropy               | -3.01        |
|    entropy_loss          | -3.01        |
|    explained_variance    | 0.882        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.75         |
|    n_updates             | 1910         |
|    policy_gradient_loss  | -0.00607     |
|    std                   | 1.09         |
|    value_loss            | 9.01         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.1          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.1          |
| reward                   | -0.24555561  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.06e+03    |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 46           |
|    time_elapsed          | 1452         |
|    total_timesteps       | 395264       |
| train/                   |              |
|    approx_kl             | 0.0043777237 |
|    clip_fraction         | 0.0215       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.17         |
|    cost_value_loss       | 1.59         |
|    cost_values           | 0.825        |
|    entropy               | -3           |
|    entropy_loss          | -3           |
|    explained_variance    | 0.646        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.3          |
|    n_updates             | 1920         |
|    policy_gradient_loss  | -0.00407     |
|    std                   | 1.09         |
|    value_loss            | 7.91         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.75         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.75         |
| reward                   | -0.97875774  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.04e+03    |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 47           |
|    time_elapsed          | 1490         |
|    total_timesteps       | 397312       |
| train/                   |              |
|    approx_kl             | 0.0058652624 |
|    clip_fraction         | 0.0813       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.11         |
|    cost_value_loss       | 0.762        |
|    cost_values           | 0.845        |
|    entropy               | -3           |
|    entropy_loss          | -3           |
|    explained_variance    | 0.811        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.88         |
|    n_updates             | 1930         |
|    policy_gradient_loss  | -0.00818     |
|    std                   | 1.08         |
|    value_loss            | 8.01         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.996281    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.04e+03    |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 48           |
|    time_elapsed          | 1524         |
|    total_timesteps       | 399360       |
| train/                   |              |
|    approx_kl             | 0.0068871905 |
|    clip_fraction         | 0.055        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.1          |
|    cost_value_loss       | 0.951        |
|    cost_values           | 0.749        |
|    entropy               | -3           |
|    entropy_loss          | -3           |
|    explained_variance    | 0.889        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.98         |
|    n_updates             | 1940         |
|    policy_gradient_loss  | -0.00582     |
|    std                   | 1.08         |
|    value_loss            | 9.22         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.2878156  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.03e+03   |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 49          |
|    time_elapsed          | 1548        |
|    total_timesteps       | 401408      |
| train/                   |             |
|    approx_kl             | 0.008050904 |
|    clip_fraction         | 0.0663      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.07        |
|    cost_value_loss       | 0.965       |
|    cost_values           | 0.855       |
|    entropy               | -3          |
|    entropy_loss          | -3          |
|    explained_variance    | 0.723       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.74        |
|    n_updates             | 1950        |
|    policy_gradient_loss  | -0.00651    |
|    std                   | 1.08        |
|    value_loss            | 9.83        |
------------------------------------------
------------------------------------
| avg_speed          | 8.03        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8.03        |
| reward             | -0.96744716 |
| rollout/           |             |
|    ep_len_mean     | 1e+03       |
|    ep_rew_mean     | -1.02e+03   |
| time/              |             |
|    fps             | 56          |
|    iterations      | 1           |
|    time_elapsed    | 35          |
|    total_timesteps | 403456      |
------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.8229591  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.02e+03   |
| time/                    |             |
|    fps                   | 54          |
|    iterations            | 2           |
|    time_elapsed          | 74          |
|    total_timesteps       | 405504      |
| train/                   |             |
|    approx_kl             | 0.003526222 |
|    clip_fraction         | 0.0231      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.09        |
|    cost_value_loss       | 1.25        |
|    cost_values           | 0.712       |
|    entropy               | -2.98       |
|    entropy_loss          | -2.98       |
|    explained_variance    | 0.911       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.33        |
|    n_updates             | 1970        |
|    policy_gradient_loss  | -0.00327    |
|    std                   | 1.07        |
|    value_loss            | 17.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.61         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.61         |
| reward                   | -0.47155294  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 56           |
|    iterations            | 3            |
|    time_elapsed          | 108          |
|    total_timesteps       | 407552       |
| train/                   |              |
|    approx_kl             | 0.0066220732 |
|    clip_fraction         | 0.0755       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.802        |
|    cost_value_loss       | 0.06         |
|    cost_values           | 0.824        |
|    entropy               | -2.98        |
|    entropy_loss          | -2.98        |
|    explained_variance    | 0.629        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.6          |
|    n_updates             | 1980         |
|    policy_gradient_loss  | -0.0083      |
|    std                   | 1.07         |
|    value_loss            | 9.37         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.83        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.83        |
| reward                   | -0.538949   |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.01e+03   |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 4           |
|    time_elapsed          | 131         |
|    total_timesteps       | 409600      |
| train/                   |             |
|    approx_kl             | 0.007751731 |
|    clip_fraction         | 0.0563      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.03        |
|    cost_value_loss       | 1.42        |
|    cost_values           | 0.818       |
|    entropy               | -2.98       |
|    entropy_loss          | -2.98       |
|    explained_variance    | 0.765       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.3         |
|    n_updates             | 1990        |
|    policy_gradient_loss  | -0.00519    |
|    std                   | 1.07        |
|    value_loss            | 10.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.7205663  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1e+03      |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 5           |
|    time_elapsed          | 154         |
|    total_timesteps       | 411648      |
| train/                   |             |
|    approx_kl             | 0.006606937 |
|    clip_fraction         | 0.0473      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.627       |
|    cost_value_loss       | 0.00945     |
|    cost_values           | 0.661       |
|    entropy               | -2.96       |
|    entropy_loss          | -2.97       |
|    explained_variance    | 0.954       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.57        |
|    n_updates             | 2000        |
|    policy_gradient_loss  | -0.00516    |
|    std                   | 1.07        |
|    value_loss            | 5.26        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.85        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.85        |
| reward                   | -1.0630809  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1e+03      |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 6           |
|    time_elapsed          | 178         |
|    total_timesteps       | 413696      |
| train/                   |             |
|    approx_kl             | 0.007236621 |
|    clip_fraction         | 0.0774      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.754       |
|    cost_value_loss       | 0.435       |
|    cost_values           | 0.689       |
|    entropy               | -2.96       |
|    entropy_loss          | -2.96       |
|    explained_variance    | 0.83        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.41        |
|    n_updates             | 2010        |
|    policy_gradient_loss  | -0.00919    |
|    std                   | 1.06        |
|    value_loss            | 6.41        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.42        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.42        |
| reward                   | -1.5684966  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -999        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 7           |
|    time_elapsed          | 213         |
|    total_timesteps       | 415744      |
| train/                   |             |
|    approx_kl             | 0.005677955 |
|    clip_fraction         | 0.0496      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.768       |
|    cost_value_loss       | 0.488       |
|    cost_values           | 0.727       |
|    entropy               | -2.95       |
|    entropy_loss          | -2.96       |
|    explained_variance    | 0.916       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.15        |
|    n_updates             | 2020        |
|    policy_gradient_loss  | -0.00571    |
|    std                   | 1.06        |
|    value_loss            | 6.65        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.76         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.76         |
| reward                   | -0.74276334  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -998         |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 8            |
|    time_elapsed          | 251          |
|    total_timesteps       | 417792       |
| train/                   |              |
|    approx_kl             | 0.0047058254 |
|    clip_fraction         | 0.0625       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.534        |
|    cost_value_loss       | 0.104        |
|    cost_values           | 0.553        |
|    entropy               | -2.94        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.93         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.93         |
|    n_updates             | 2030         |
|    policy_gradient_loss  | -0.00763     |
|    std                   | 1.06         |
|    value_loss            | 6.16         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.24         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.24         |
| reward                   | -0.78241897  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -978         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 9            |
|    time_elapsed          | 292          |
|    total_timesteps       | 419840       |
| train/                   |              |
|    approx_kl             | 0.0070672645 |
|    clip_fraction         | 0.058        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.844        |
|    cost_value_loss       | 0.34         |
|    cost_values           | 0.792        |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.779        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.81         |
|    n_updates             | 2040         |
|    policy_gradient_loss  | -0.00667     |
|    std                   | 1.05         |
|    value_loss            | 7.23         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.76         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.76         |
| reward                   | -0.78887564  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -973         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 10           |
|    time_elapsed          | 325          |
|    total_timesteps       | 421888       |
| train/                   |              |
|    approx_kl             | 0.0070048035 |
|    clip_fraction         | 0.0558       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.17         |
|    cost_value_loss       | 0.847        |
|    cost_values           | 0.898        |
|    entropy               | -2.93        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.782        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.89         |
|    n_updates             | 2050         |
|    policy_gradient_loss  | -0.00509     |
|    std                   | 1.05         |
|    value_loss            | 4.44         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.69083965 |
| rollout/                 |             |
|    ep_len_mean           | 998         |
|    ep_rew_mean           | -963        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 11          |
|    time_elapsed          | 358         |
|    total_timesteps       | 423936      |
| train/                   |             |
|    approx_kl             | 0.011189327 |
|    clip_fraction         | 0.123       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.759       |
|    cost_value_loss       | 0.297       |
|    cost_values           | 0.658       |
|    entropy               | -2.93       |
|    entropy_loss          | -2.93       |
|    explained_variance    | 0.907       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.25        |
|    n_updates             | 2060        |
|    policy_gradient_loss  | -0.0117     |
|    std                   | 1.05        |
|    value_loss            | 7.73        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.49867272 |
| rollout/                 |             |
|    ep_len_mean           | 998         |
|    ep_rew_mean           | -955        |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 12          |
|    time_elapsed          | 389         |
|    total_timesteps       | 425984      |
| train/                   |             |
|    approx_kl             | 0.006233869 |
|    clip_fraction         | 0.0833      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.58        |
|    cost_value_loss       | 2.54        |
|    cost_values           | 0.822       |
|    entropy               | -2.93       |
|    entropy_loss          | -2.93       |
|    explained_variance    | 0.564       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 27.5        |
|    n_updates             | 2070        |
|    policy_gradient_loss  | -0.0065     |
|    std                   | 1.05        |
|    value_loss            | 30.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.74        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.74        |
| reward                   | -0.87795645 |
| rollout/                 |             |
|    ep_len_mean           | 998         |
|    ep_rew_mean           | -951        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 13          |
|    time_elapsed          | 425         |
|    total_timesteps       | 428032      |
| train/                   |             |
|    approx_kl             | 0.004674187 |
|    clip_fraction         | 0.0604      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.08        |
|    cost_value_loss       | 1.13        |
|    cost_values           | 0.793       |
|    entropy               | -2.93       |
|    entropy_loss          | -2.93       |
|    explained_variance    | 0.911       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.45        |
|    n_updates             | 2080        |
|    policy_gradient_loss  | -0.00705    |
|    std                   | 1.05        |
|    value_loss            | 5.43        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.93        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.93        |
| reward                   | -0.999188   |
| rollout/                 |             |
|    ep_len_mean           | 998         |
|    ep_rew_mean           | -948        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 14          |
|    time_elapsed          | 459         |
|    total_timesteps       | 430080      |
| train/                   |             |
|    approx_kl             | 0.008888345 |
|    clip_fraction         | 0.131       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.04        |
|    cost_value_loss       | 0.89        |
|    cost_values           | 0.844       |
|    entropy               | -2.93       |
|    entropy_loss          | -2.93       |
|    explained_variance    | 0.821       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.73        |
|    n_updates             | 2090        |
|    policy_gradient_loss  | -0.0128     |
|    std                   | 1.05        |
|    value_loss            | 5.35        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.21         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.21         |
| reward                   | -0.8806737   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -937         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 15           |
|    time_elapsed          | 496          |
|    total_timesteps       | 432128       |
| train/                   |              |
|    approx_kl             | 0.0064238925 |
|    clip_fraction         | 0.0635       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.854        |
|    cost_value_loss       | 0.756        |
|    cost_values           | 0.714        |
|    entropy               | -2.92        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.777        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.36         |
|    n_updates             | 2100         |
|    policy_gradient_loss  | -0.00655     |
|    std                   | 1.04         |
|    value_loss            | 10.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -1.243569   |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -929        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 16          |
|    time_elapsed          | 535         |
|    total_timesteps       | 434176      |
| train/                   |             |
|    approx_kl             | 0.011489943 |
|    clip_fraction         | 0.101       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.2         |
|    cost_value_loss       | 1.33        |
|    cost_values           | 0.801       |
|    entropy               | -2.92       |
|    entropy_loss          | -2.92       |
|    explained_variance    | 0.571       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 18          |
|    n_updates             | 2110        |
|    policy_gradient_loss  | -0.00721    |
|    std                   | 1.04        |
|    value_loss            | 25.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.94470215 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -920        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 17          |
|    time_elapsed          | 571         |
|    total_timesteps       | 436224      |
| train/                   |             |
|    approx_kl             | 0.00808376  |
|    clip_fraction         | 0.0934      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.711       |
|    cost_value_loss       | 0.26        |
|    cost_values           | 0.725       |
|    entropy               | -2.92       |
|    entropy_loss          | -2.92       |
|    explained_variance    | 0.732       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.32        |
|    n_updates             | 2120        |
|    policy_gradient_loss  | -0.00962    |
|    std                   | 1.04        |
|    value_loss            | 5.97        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.925539   |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -906        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 18          |
|    time_elapsed          | 594         |
|    total_timesteps       | 438272      |
| train/                   |             |
|    approx_kl             | 0.004931427 |
|    clip_fraction         | 0.0558      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.15        |
|    cost_value_loss       | 1.23        |
|    cost_values           | 0.77        |
|    entropy               | -2.92       |
|    entropy_loss          | -2.92       |
|    explained_variance    | 0.673       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 22.9        |
|    n_updates             | 2130        |
|    policy_gradient_loss  | -0.0045     |
|    std                   | 1.04        |
|    value_loss            | 28.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.79797775  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -890         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 19           |
|    time_elapsed          | 616          |
|    total_timesteps       | 440320       |
| train/                   |              |
|    approx_kl             | 0.0049054725 |
|    clip_fraction         | 0.0531       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.22         |
|    cost_value_loss       | 1.96         |
|    cost_values           | 0.759        |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.883        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.95         |
|    n_updates             | 2140         |
|    policy_gradient_loss  | -0.00512     |
|    std                   | 1.04         |
|    value_loss            | 8.88         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.53893197 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -885        |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 20          |
|    time_elapsed          | 642         |
|    total_timesteps       | 442368      |
| train/                   |             |
|    approx_kl             | 0.003567801 |
|    clip_fraction         | 0.031       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.66        |
|    cost_value_loss       | 2.81        |
|    cost_values           | 0.782       |
|    entropy               | -2.91       |
|    entropy_loss          | -2.92       |
|    explained_variance    | 0.861       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.06        |
|    n_updates             | 2150        |
|    policy_gradient_loss  | -0.00317    |
|    std                   | 1.04        |
|    value_loss            | 19.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -0.7079557   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -880         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 21           |
|    time_elapsed          | 667          |
|    total_timesteps       | 444416       |
| train/                   |              |
|    approx_kl             | 0.0073052216 |
|    clip_fraction         | 0.108        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.967        |
|    cost_value_loss       | 0.631        |
|    cost_values           | 0.78         |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.855        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.06         |
|    n_updates             | 2160         |
|    policy_gradient_loss  | -0.0118      |
|    std                   | 1.04         |
|    value_loss            | 6.67         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.76        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.76        |
| reward                   | -0.82833755 |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -872        |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 22          |
|    time_elapsed          | 696         |
|    total_timesteps       | 446464      |
| train/                   |             |
|    approx_kl             | 0.010628503 |
|    clip_fraction         | 0.11        |
|    clip_range            | 0.2         |
|    cost_returns          | 1.31        |
|    cost_value_loss       | 1.99        |
|    cost_values           | 0.862       |
|    entropy               | -2.91       |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.891       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.75        |
|    n_updates             | 2170        |
|    policy_gradient_loss  | -0.011      |
|    std                   | 1.04        |
|    value_loss            | 6.39        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.82         |
| reward                   | -0.745922    |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -862         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 23           |
|    time_elapsed          | 726          |
|    total_timesteps       | 448512       |
| train/                   |              |
|    approx_kl             | 0.0047129737 |
|    clip_fraction         | 0.0224       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.88         |
|    cost_value_loss       | 4.25         |
|    cost_values           | 0.854        |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.784        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.4         |
|    n_updates             | 2180         |
|    policy_gradient_loss  | -0.00288     |
|    std                   | 1.04         |
|    value_loss            | 21.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.37        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.37        |
| reward                   | -0.8613868  |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -852        |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 24          |
|    time_elapsed          | 757         |
|    total_timesteps       | 450560      |
| train/                   |             |
|    approx_kl             | 0.003543657 |
|    clip_fraction         | 0.0462      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.3         |
|    cost_value_loss       | 2.05        |
|    cost_values           | 0.847       |
|    entropy               | -2.91       |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.855       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.77        |
|    n_updates             | 2190        |
|    policy_gradient_loss  | -0.00651    |
|    std                   | 1.04        |
|    value_loss            | 7.86        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.71        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.71        |
| reward                   | -0.32394016 |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -844        |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 25          |
|    time_elapsed          | 789         |
|    total_timesteps       | 452608      |
| train/                   |             |
|    approx_kl             | 0.010153141 |
|    clip_fraction         | 0.0634      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.837       |
|    cost_value_loss       | 0.433       |
|    cost_values           | 0.757       |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | 0.825       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.31        |
|    n_updates             | 2200        |
|    policy_gradient_loss  | -0.00667    |
|    std                   | 1.03        |
|    value_loss            | 4.83        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.0338911  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -837        |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 26          |
|    time_elapsed          | 820         |
|    total_timesteps       | 454656      |
| train/                   |             |
|    approx_kl             | 0.006522672 |
|    clip_fraction         | 0.13        |
|    clip_range            | 0.2         |
|    cost_returns          | 0.841       |
|    cost_value_loss       | 0.405       |
|    cost_values           | 0.764       |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | 0.832       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.55        |
|    n_updates             | 2210        |
|    policy_gradient_loss  | -0.0111     |
|    std                   | 1.03        |
|    value_loss            | 8.26        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -1.0087374   |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -825         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 27           |
|    time_elapsed          | 851          |
|    total_timesteps       | 456704       |
| train/                   |              |
|    approx_kl             | 0.0046570264 |
|    clip_fraction         | 0.0625       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.52         |
|    cost_value_loss       | 2.65         |
|    cost_values           | 0.833        |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.752        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.9         |
|    n_updates             | 2220         |
|    policy_gradient_loss  | -0.00366     |
|    std                   | 1.03         |
|    value_loss            | 37.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.83         |
| reward                   | -0.90257484  |
| rollout/                 |              |
|    ep_len_mean           | 972          |
|    ep_rew_mean           | -814         |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 28           |
|    time_elapsed          | 878          |
|    total_timesteps       | 458752       |
| train/                   |              |
|    approx_kl             | 0.0070479945 |
|    clip_fraction         | 0.0618       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.38         |
|    cost_value_loss       | 1.67         |
|    cost_values           | 0.884        |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.892        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.55         |
|    n_updates             | 2230         |
|    policy_gradient_loss  | -0.00726     |
|    std                   | 1.03         |
|    value_loss            | 10.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.49        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.49        |
| reward                   | -0.63025665 |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -807        |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 29          |
|    time_elapsed          | 901         |
|    total_timesteps       | 460800      |
| train/                   |             |
|    approx_kl             | 0.008361785 |
|    clip_fraction         | 0.0844      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.897       |
|    cost_value_loss       | 0.536       |
|    cost_values           | 0.782       |
|    entropy               | -2.89       |
|    entropy_loss          | -2.89       |
|    explained_variance    | 0.858       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.73        |
|    n_updates             | 2240        |
|    policy_gradient_loss  | -0.00958    |
|    std                   | 1.03        |
|    value_loss            | 6.15        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.2          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.2          |
| reward                   | -0.84149927  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -798         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 30           |
|    time_elapsed          | 923          |
|    total_timesteps       | 462848       |
| train/                   |              |
|    approx_kl             | 0.0030429168 |
|    clip_fraction         | 0.0188       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.29         |
|    cost_value_loss       | 5.07         |
|    cost_values           | 1.02         |
|    entropy               | -2.88        |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.628        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.59         |
|    n_updates             | 2250         |
|    policy_gradient_loss  | -0.0033      |
|    std                   | 1.02         |
|    value_loss            | 5.45         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.8354507  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -795        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 31          |
|    time_elapsed          | 956         |
|    total_timesteps       | 464896      |
| train/                   |             |
|    approx_kl             | 0.008343764 |
|    clip_fraction         | 0.0918      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.1         |
|    cost_value_loss       | 0.547       |
|    cost_values           | 0.905       |
|    entropy               | -2.87       |
|    entropy_loss          | -2.87       |
|    explained_variance    | 0.78        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.1        |
|    n_updates             | 2260        |
|    policy_gradient_loss  | -0.00596    |
|    std                   | 1.02        |
|    value_loss            | 23          |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -0.51378876  |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -795         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 32           |
|    time_elapsed          | 990          |
|    total_timesteps       | 466944       |
| train/                   |              |
|    approx_kl             | 0.0068756286 |
|    clip_fraction         | 0.0875       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.55         |
|    cost_value_loss       | 2.66         |
|    cost_values           | 0.868        |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.733        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.76         |
|    n_updates             | 2270         |
|    policy_gradient_loss  | -0.00806     |
|    std                   | 1.02         |
|    value_loss            | 4.99         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.67        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.67        |
| reward                   | -0.39168307 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -787        |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 33          |
|    time_elapsed          | 1029        |
|    total_timesteps       | 468992      |
| train/                   |             |
|    approx_kl             | 0.014567886 |
|    clip_fraction         | 0.175       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.34        |
|    cost_value_loss       | 1.41        |
|    cost_values           | 0.857       |
|    entropy               | -2.86       |
|    entropy_loss          | -2.87       |
|    explained_variance    | 0.916       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.6         |
|    n_updates             | 2280        |
|    policy_gradient_loss  | -0.0183     |
|    std                   | 1.01        |
|    value_loss            | 8.87        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.77625453 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -777        |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 34          |
|    time_elapsed          | 1062        |
|    total_timesteps       | 471040      |
| train/                   |             |
|    approx_kl             | 0.008374341 |
|    clip_fraction         | 0.112       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.07        |
|    cost_value_loss       | 0.96        |
|    cost_values           | 0.849       |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.818       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.98        |
|    n_updates             | 2290        |
|    policy_gradient_loss  | -0.0116     |
|    std                   | 1.01        |
|    value_loss            | 6.21        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.86121213 |
| rollout/                 |             |
|    ep_len_mean           | 967         |
|    ep_rew_mean           | -769        |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 35          |
|    time_elapsed          | 1100        |
|    total_timesteps       | 473088      |
| train/                   |             |
|    approx_kl             | 0.010529171 |
|    clip_fraction         | 0.127       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.55        |
|    cost_value_loss       | 2.14        |
|    cost_values           | 0.901       |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.565       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11          |
|    n_updates             | 2300        |
|    policy_gradient_loss  | -0.00917    |
|    std                   | 1.01        |
|    value_loss            | 18.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.5853089  |
| rollout/                 |             |
|    ep_len_mean           | 964         |
|    ep_rew_mean           | -762        |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 36          |
|    time_elapsed          | 1138        |
|    total_timesteps       | 475136      |
| train/                   |             |
|    approx_kl             | 0.008636219 |
|    clip_fraction         | 0.0868      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.11        |
|    cost_value_loss       | 0.797       |
|    cost_values           | 0.881       |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.402       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.54        |
|    n_updates             | 2310        |
|    policy_gradient_loss  | -0.00655    |
|    std                   | 1.01        |
|    value_loss            | 21.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.49040088  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -746         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 37           |
|    time_elapsed          | 1173         |
|    total_timesteps       | 477184       |
| train/                   |              |
|    approx_kl             | 0.0063087624 |
|    clip_fraction         | 0.0725       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.02         |
|    cost_value_loss       | 3.97         |
|    cost_values           | 0.926        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.725        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 18.2         |
|    n_updates             | 2320         |
|    policy_gradient_loss  | -0.00464     |
|    std                   | 1            |
|    value_loss            | 22.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.28        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.28        |
| reward                   | -0.860517   |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -724        |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 38          |
|    time_elapsed          | 1200        |
|    total_timesteps       | 479232      |
| train/                   |             |
|    approx_kl             | 0.009338893 |
|    clip_fraction         | 0.089       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.2         |
|    cost_value_loss       | 0.963       |
|    cost_values           | 0.924       |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.418       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 18.9        |
|    n_updates             | 2330        |
|    policy_gradient_loss  | -0.00815    |
|    std                   | 1           |
|    value_loss            | 27.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.91        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.91        |
| reward                   | -0.5865682  |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -720        |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 39          |
|    time_elapsed          | 1225        |
|    total_timesteps       | 481280      |
| train/                   |             |
|    approx_kl             | 0.007971548 |
|    clip_fraction         | 0.0797      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.52        |
|    cost_value_loss       | 1.95        |
|    cost_values           | 0.885       |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.733       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.9        |
|    n_updates             | 2340        |
|    policy_gradient_loss  | -0.00611    |
|    std                   | 1           |
|    value_loss            | 17.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5232816  |
| rollout/                 |             |
|    ep_len_mean           | 953         |
|    ep_rew_mean           | -713        |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 40          |
|    time_elapsed          | 1250        |
|    total_timesteps       | 483328      |
| train/                   |             |
|    approx_kl             | 0.007898582 |
|    clip_fraction         | 0.113       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.02        |
|    cost_value_loss       | 0.643       |
|    cost_values           | 0.847       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.889       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.16        |
|    n_updates             | 2350        |
|    policy_gradient_loss  | -0.0107     |
|    std                   | 0.998       |
|    value_loss            | 5.45        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.73         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.73         |
| reward                   | -0.89491063  |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -706         |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 41           |
|    time_elapsed          | 1277         |
|    total_timesteps       | 485376       |
| train/                   |              |
|    approx_kl             | 0.0055325623 |
|    clip_fraction         | 0.0458       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.45         |
|    cost_value_loss       | 2.36         |
|    cost_values           | 0.902        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.497        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.69         |
|    n_updates             | 2360         |
|    policy_gradient_loss  | -0.00423     |
|    std                   | 0.999        |
|    value_loss            | 20.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.27659327  |
| rollout/                 |              |
|    ep_len_mean           | 950          |
|    ep_rew_mean           | -700         |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 42           |
|    time_elapsed          | 1308         |
|    total_timesteps       | 487424       |
| train/                   |              |
|    approx_kl             | 0.0059040524 |
|    clip_fraction         | 0.0733       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.02         |
|    cost_value_loss       | 4.74         |
|    cost_values           | 0.928        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.798        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.89         |
|    n_updates             | 2370         |
|    policy_gradient_loss  | -0.00632     |
|    std                   | 1            |
|    value_loss            | 5.28         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.84065306  |
| rollout/                 |              |
|    ep_len_mean           | 950          |
|    ep_rew_mean           | -697         |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 43           |
|    time_elapsed          | 1340         |
|    total_timesteps       | 489472       |
| train/                   |              |
|    approx_kl             | 0.0068327687 |
|    clip_fraction         | 0.0593       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.84         |
|    cost_value_loss       | 3.17         |
|    cost_values           | 0.96         |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.371        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.1         |
|    n_updates             | 2380         |
|    policy_gradient_loss  | -0.00737     |
|    std                   | 0.999        |
|    value_loss            | 18.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.84        |
| reward                   | -0.5529179  |
| rollout/                 |             |
|    ep_len_mean           | 943         |
|    ep_rew_mean           | -686        |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 44          |
|    time_elapsed          | 1366        |
|    total_timesteps       | 491520      |
| train/                   |             |
|    approx_kl             | 0.007225507 |
|    clip_fraction         | 0.057       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.48        |
|    cost_value_loss       | 6.27        |
|    cost_values           | 0.961       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.757       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.72        |
|    n_updates             | 2390        |
|    policy_gradient_loss  | -0.00655    |
|    std                   | 0.998       |
|    value_loss            | 8.89        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.63449043 |
| rollout/                 |             |
|    ep_len_mean           | 938         |
|    ep_rew_mean           | -680        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 45          |
|    time_elapsed          | 1389        |
|    total_timesteps       | 493568      |
| train/                   |             |
|    approx_kl             | 0.009413182 |
|    clip_fraction         | 0.084       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.25        |
|    cost_value_loss       | 5.48        |
|    cost_values           | 0.975       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.584       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.92        |
|    n_updates             | 2400        |
|    policy_gradient_loss  | -0.0065     |
|    std                   | 0.997       |
|    value_loss            | 19.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.84        |
| reward                   | -0.74261385 |
| rollout/                 |             |
|    ep_len_mean           | 938         |
|    ep_rew_mean           | -672        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 46          |
|    time_elapsed          | 1412        |
|    total_timesteps       | 495616      |
| train/                   |             |
|    approx_kl             | 0.008991094 |
|    clip_fraction         | 0.112       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.88        |
|    cost_value_loss       | 4.54        |
|    cost_values           | 0.914       |
|    entropy               | -2.82       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.592       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.77        |
|    n_updates             | 2410        |
|    policy_gradient_loss  | -0.00653    |
|    std                   | 0.995       |
|    value_loss            | 15.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.66128296  |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -661         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 47           |
|    time_elapsed          | 1435         |
|    total_timesteps       | 497664       |
| train/                   |              |
|    approx_kl             | 0.0054911445 |
|    clip_fraction         | 0.0708       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.77         |
|    cost_value_loss       | 3.42         |
|    cost_values           | 0.92         |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.904        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.53         |
|    n_updates             | 2420         |
|    policy_gradient_loss  | -0.00766     |
|    std                   | 0.992        |
|    value_loss            | 3.68         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.47744778 |
| rollout/                 |             |
|    ep_len_mean           | 938         |
|    ep_rew_mean           | -654        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 48          |
|    time_elapsed          | 1459        |
|    total_timesteps       | 499712      |
| train/                   |             |
|    approx_kl             | 0.007870525 |
|    clip_fraction         | 0.0853      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.4         |
|    cost_value_loss       | 12.3        |
|    cost_values           | 1.05        |
|    entropy               | -2.81       |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0.739       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.98        |
|    n_updates             | 2430        |
|    policy_gradient_loss  | -0.0085     |
|    std                   | 0.989       |
|    value_loss            | 2.9         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.5929731  |
| rollout/                 |             |
|    ep_len_mean           | 938         |
|    ep_rew_mean           | -650        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 49          |
|    time_elapsed          | 1494        |
|    total_timesteps       | 501760      |
| train/                   |             |
|    approx_kl             | 0.005434932 |
|    clip_fraction         | 0.097       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.89        |
|    cost_value_loss       | 2.25        |
|    cost_values           | 1.23        |
|    entropy               | -2.81       |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0.694       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.1         |
|    n_updates             | 2440        |
|    policy_gradient_loss  | -0.00947    |
|    std                   | 0.989       |
|    value_loss            | 5.88        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ent-coefficient-ppol/1vjpjg9h
-----------------------------------
| avg_speed          | 7.82       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 7.82       |
| reward             | -0.4806658 |
| rollout/           |            |
|    ep_len_mean     | 938        |
|    ep_rew_mean     | -645       |
| time/              |            |
|    fps             | 60         |
|    iterations      | 1          |
|    time_elapsed    | 33         |
|    total_timesteps | 503808     |
-----------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.53498936  |
| rollout/                 |              |
|    ep_len_mean           | 933          |
|    ep_rew_mean           | -637         |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 2            |
|    time_elapsed          | 70           |
|    total_timesteps       | 505856       |
| train/                   |              |
|    approx_kl             | 0.0035761788 |
|    clip_fraction         | 0.0205       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.86         |
|    cost_value_loss       | 8.58         |
|    cost_values           | 1.12         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.879        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.1          |
|    n_updates             | 2460         |
|    policy_gradient_loss  | -0.00295     |
|    std                   | 0.989        |
|    value_loss            | 2.75         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.5157193  |
| rollout/                 |             |
|    ep_len_mean           | 924         |
|    ep_rew_mean           | -625        |
| time/                    |             |
|    fps                   | 56          |
|    iterations            | 3           |
|    time_elapsed          | 107         |
|    total_timesteps       | 507904      |
| train/                   |             |
|    approx_kl             | 0.010477275 |
|    clip_fraction         | 0.0857      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.89        |
|    cost_value_loss       | 6.08        |
|    cost_values           | 1.32        |
|    entropy               | -2.81       |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0.648       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.51        |
|    n_updates             | 2470        |
|    policy_gradient_loss  | -0.00447    |
|    std                   | 0.989       |
|    value_loss            | 12.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.63364494 |
| rollout/                 |             |
|    ep_len_mean           | 924         |
|    ep_rew_mean           | -618        |
| time/                    |             |
|    fps                   | 55          |
|    iterations            | 4           |
|    time_elapsed          | 146         |
|    total_timesteps       | 509952      |
| train/                   |             |
|    approx_kl             | 0.011316497 |
|    clip_fraction         | 0.133       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.48        |
|    cost_value_loss       | 4.66        |
|    cost_values           | 1.32        |
|    entropy               | -2.81       |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0.633       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11.6        |
|    n_updates             | 2480        |
|    policy_gradient_loss  | -0.00787    |
|    std                   | 0.988       |
|    value_loss            | 16.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.3001093  |
| rollout/                 |             |
|    ep_len_mean           | 915         |
|    ep_rew_mean           | -608        |
| time/                    |             |
|    fps                   | 55          |
|    iterations            | 5           |
|    time_elapsed          | 183         |
|    total_timesteps       | 512000      |
| train/                   |             |
|    approx_kl             | 0.010066767 |
|    clip_fraction         | 0.0845      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.65        |
|    cost_value_loss       | 11.2        |
|    cost_values           | 1.39        |
|    entropy               | -2.81       |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0.747       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.94        |
|    n_updates             | 2490        |
|    policy_gradient_loss  | -0.00662    |
|    std                   | 0.988       |
|    value_loss            | 2.48        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6715857  |
| rollout/                 |             |
|    ep_len_mean           | 915         |
|    ep_rew_mean           | -603        |
| time/                    |             |
|    fps                   | 54          |
|    iterations            | 6           |
|    time_elapsed          | 225         |
|    total_timesteps       | 514048      |
| train/                   |             |
|    approx_kl             | 0.010456858 |
|    clip_fraction         | 0.1         |
|    clip_range            | 0.2         |
|    cost_returns          | 3.13        |
|    cost_value_loss       | 6.74        |
|    cost_values           | 1.72        |
|    entropy               | -2.8        |
|    entropy_loss          | -2.8        |
|    explained_variance    | 0.697       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.26        |
|    n_updates             | 2500        |
|    policy_gradient_loss  | -0.00869    |
|    std                   | 0.985       |
|    value_loss            | 11.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -0.46558315 |
| rollout/                 |             |
|    ep_len_mean           | 918         |
|    ep_rew_mean           | -601        |
| time/                    |             |
|    fps                   | 54          |
|    iterations            | 7           |
|    time_elapsed          | 264         |
|    total_timesteps       | 516096      |
| train/                   |             |
|    approx_kl             | 0.011213925 |
|    clip_fraction         | 0.153       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.06        |
|    cost_value_loss       | 6.24        |
|    cost_values           | 1.74        |
|    entropy               | -2.79       |
|    entropy_loss          | -2.8        |
|    explained_variance    | 0.887       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.25        |
|    n_updates             | 2510        |
|    policy_gradient_loss  | -0.0148     |
|    std                   | 0.981       |
|    value_loss            | 2.13        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6499685   |
| rollout/                 |              |
|    ep_len_mean           | 918          |
|    ep_rew_mean           | -598         |
| time/                    |              |
|    fps                   | 55           |
|    iterations            | 8            |
|    time_elapsed          | 297          |
|    total_timesteps       | 518144       |
| train/                   |              |
|    approx_kl             | 0.0059923874 |
|    clip_fraction         | 0.0543       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.93         |
|    cost_value_loss       | 8.53         |
|    cost_values           | 2.02         |
|    entropy               | -2.79        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.726        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.9          |
|    n_updates             | 2520         |
|    policy_gradient_loss  | -0.00408     |
|    std                   | 0.978        |
|    value_loss            | 4.64         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.9          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.9          |
| reward                   | -0.66097915  |
| rollout/                 |              |
|    ep_len_mean           | 918          |
|    ep_rew_mean           | -594         |
| time/                    |              |
|    fps                   | 55           |
|    iterations            | 9            |
|    time_elapsed          | 329          |
|    total_timesteps       | 520192       |
| train/                   |              |
|    approx_kl             | 0.0073672268 |
|    clip_fraction         | 0.0695       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.22         |
|    cost_value_loss       | 1.52         |
|    cost_values           | 1.98         |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.796        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.02         |
|    n_updates             | 2530         |
|    policy_gradient_loss  | -0.00569     |
|    std                   | 0.976        |
|    value_loss            | 3.36         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -0.39388618 |
| rollout/                 |             |
|    ep_len_mean           | 911         |
|    ep_rew_mean           | -582        |
| time/                    |             |
|    fps                   | 57          |
|    iterations            | 10          |
|    time_elapsed          | 355         |
|    total_timesteps       | 522240      |
| train/                   |             |
|    approx_kl             | 0.009584289 |
|    clip_fraction         | 0.121       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.77        |
|    cost_value_loss       | 3.85        |
|    cost_values           | 1.86        |
|    entropy               | -2.77       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.762       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.79        |
|    n_updates             | 2540        |
|    policy_gradient_loss  | -0.011      |
|    std                   | 0.972       |
|    value_loss            | 4.84        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.37        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.37        |
| reward                   | -0.40812254 |
| rollout/                 |             |
|    ep_len_mean           | 898         |
|    ep_rew_mean           | -566        |
| time/                    |             |
|    fps                   | 58          |
|    iterations            | 11          |
|    time_elapsed          | 388         |
|    total_timesteps       | 524288      |
| train/                   |             |
|    approx_kl             | 0.006642544 |
|    clip_fraction         | 0.065       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.56        |
|    cost_value_loss       | 6.86        |
|    cost_values           | 1.92        |
|    entropy               | -2.77       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0.392       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16.6        |
|    n_updates             | 2550        |
|    policy_gradient_loss  | -0.00389    |
|    std                   | 0.97        |
|    value_loss            | 21          |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.34483883 |
| rollout/                 |             |
|    ep_len_mean           | 895         |
|    ep_rew_mean           | -558        |
| time/                    |             |
|    fps                   | 58          |
|    iterations            | 12          |
|    time_elapsed          | 420         |
|    total_timesteps       | 526336      |
| train/                   |             |
|    approx_kl             | 0.008237034 |
|    clip_fraction         | 0.088       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.66        |
|    cost_value_loss       | 6.75        |
|    cost_values           | 1.91        |
|    entropy               | -2.77       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0.613       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 16          |
|    n_updates             | 2560        |
|    policy_gradient_loss  | -0.00654    |
|    std                   | 0.968       |
|    value_loss            | 22          |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.5833036  |
| rollout/                 |             |
|    ep_len_mean           | 895         |
|    ep_rew_mean           | -554        |
| time/                    |             |
|    fps                   | 58          |
|    iterations            | 13          |
|    time_elapsed          | 452         |
|    total_timesteps       | 528384      |
| train/                   |             |
|    approx_kl             | 0.010342054 |
|    clip_fraction         | 0.0955      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.34        |
|    cost_value_loss       | 11.1        |
|    cost_values           | 1.88        |
|    entropy               | -2.76       |
|    entropy_loss          | -2.76       |
|    explained_variance    | 0.756       |
|    lagrangian_multiplier | 0.000249    |
|    learning_rate         | 0.0003      |
|    loss                  | 9.74        |
|    n_updates             | 2570        |
|    policy_gradient_loss  | -0.00642    |
|    std                   | 0.968       |
|    value_loss            | 9.88        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.84        |
| reward                   | -0.5758137  |
| rollout/                 |             |
|    ep_len_mean           | 896         |
|    ep_rew_mean           | -553        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 14          |
|    time_elapsed          | 483         |
|    total_timesteps       | 530432      |
| train/                   |             |
|    approx_kl             | 0.005290639 |
|    clip_fraction         | 0.0357      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.83        |
|    cost_value_loss       | 8.54        |
|    cost_values           | 1.97        |
|    entropy               | -2.76       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0.914       |
|    lagrangian_multiplier | 0.00155     |
|    learning_rate         | 0.0003      |
|    loss                  | 4           |
|    n_updates             | 2580        |
|    policy_gradient_loss  | -0.00391    |
|    std                   | 0.968       |
|    value_loss            | 2.85        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.36308122 |
| rollout/                 |             |
|    ep_len_mean           | 889         |
|    ep_rew_mean           | -542        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 15          |
|    time_elapsed          | 513         |
|    total_timesteps       | 532480      |
| train/                   |             |
|    approx_kl             | 0.008615435 |
|    clip_fraction         | 0.113       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.22        |
|    cost_value_loss       | 10.7        |
|    cost_values           | 2.16        |
|    entropy               | -2.76       |
|    entropy_loss          | -2.76       |
|    explained_variance    | 0.596       |
|    lagrangian_multiplier | 0.00147     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.11        |
|    n_updates             | 2590        |
|    policy_gradient_loss  | -0.00572    |
|    std                   | 0.967       |
|    value_loss            | 14.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.5892727   |
| rollout/                 |              |
|    ep_len_mean           | 887          |
|    ep_rew_mean           | -538         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 542          |
|    total_timesteps       | 534528       |
| train/                   |              |
|    approx_kl             | 0.0047549037 |
|    clip_fraction         | 0.0352       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.04         |
|    cost_value_loss       | 7.76         |
|    cost_values           | 2.22         |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.558        |
|    lagrangian_multiplier | 0.000188     |
|    learning_rate         | 0.0003       |
|    loss                  | 9.53         |
|    n_updates             | 2600         |
|    policy_gradient_loss  | -0.0023      |
|    std                   | 0.964        |
|    value_loss            | 15.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.7060294  |
| rollout/                 |             |
|    ep_len_mean           | 892         |
|    ep_rew_mean           | -538        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 17          |
|    time_elapsed          | 574         |
|    total_timesteps       | 536576      |
| train/                   |             |
|    approx_kl             | 0.007268764 |
|    clip_fraction         | 0.0941      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.75        |
|    cost_value_loss       | 13.3        |
|    cost_values           | 2.08        |
|    entropy               | -2.75       |
|    entropy_loss          | -2.76       |
|    explained_variance    | 0.717       |
|    lagrangian_multiplier | 0.0024      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.26        |
|    n_updates             | 2610        |
|    policy_gradient_loss  | -0.00703    |
|    std                   | 0.963       |
|    value_loss            | 13.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.9         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.9         |
| reward                   | -0.45506105 |
| rollout/                 |             |
|    ep_len_mean           | 889         |
|    ep_rew_mean           | -532        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 18          |
|    time_elapsed          | 608         |
|    total_timesteps       | 538624      |
| train/                   |             |
|    approx_kl             | 0.006185126 |
|    clip_fraction         | 0.117       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.19        |
|    cost_value_loss       | 11.8        |
|    cost_values           | 1.99        |
|    entropy               | -2.75       |
|    entropy_loss          | -2.75       |
|    explained_variance    | 0.89        |
|    lagrangian_multiplier | 0.00231     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.46        |
|    n_updates             | 2620        |
|    policy_gradient_loss  | -0.0113     |
|    std                   | 0.962       |
|    value_loss            | 2.37        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.6679698   |
| rollout/                 |              |
|    ep_len_mean           | 874          |
|    ep_rew_mean           | -518         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 648          |
|    total_timesteps       | 540672       |
| train/                   |              |
|    approx_kl             | 0.0059824763 |
|    clip_fraction         | 0.0656       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.45         |
|    cost_value_loss       | 6.23         |
|    cost_values           | 2.07         |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.677        |
|    lagrangian_multiplier | 0.00112      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.43         |
|    n_updates             | 2630         |
|    policy_gradient_loss  | -0.00563     |
|    std                   | 0.962        |
|    value_loss            | 13.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.42        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.42        |
| reward                   | -0.33528844 |
| rollout/                 |             |
|    ep_len_mean           | 866         |
|    ep_rew_mean           | -504        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 20          |
|    time_elapsed          | 684         |
|    total_timesteps       | 542720      |
| train/                   |             |
|    approx_kl             | 0.004795662 |
|    clip_fraction         | 0.0601      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.47        |
|    cost_value_loss       | 6.15        |
|    cost_values           | 1.9         |
|    entropy               | -2.74       |
|    entropy_loss          | -2.75       |
|    explained_variance    | 0.546       |
|    lagrangian_multiplier | 0.000611    |
|    learning_rate         | 0.0003      |
|    loss                  | 13.4        |
|    n_updates             | 2640        |
|    policy_gradient_loss  | -0.0034     |
|    std                   | 0.958       |
|    value_loss            | 28.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.88        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.88        |
| reward                   | -0.50165313 |
| rollout/                 |             |
|    ep_len_mean           | 866         |
|    ep_rew_mean           | -501        |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 21          |
|    time_elapsed          | 706         |
|    total_timesteps       | 544768      |
| train/                   |             |
|    approx_kl             | 0.009147648 |
|    clip_fraction         | 0.0613      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.87        |
|    cost_value_loss       | 8.1         |
|    cost_values           | 1.86        |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 0.624       |
|    lagrangian_multiplier | 0.00051     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.87        |
|    n_updates             | 2650        |
|    policy_gradient_loss  | -0.00377    |
|    std                   | 0.956       |
|    value_loss            | 16.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.38        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.38        |
| reward                   | -0.658155   |
| rollout/                 |             |
|    ep_len_mean           | 865         |
|    ep_rew_mean           | -498        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 22          |
|    time_elapsed          | 729         |
|    total_timesteps       | 546816      |
| train/                   |             |
|    approx_kl             | 0.006950844 |
|    clip_fraction         | 0.0941      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.03        |
|    cost_value_loss       | 10          |
|    cost_values           | 1.97        |
|    entropy               | -2.73       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 0.786       |
|    lagrangian_multiplier | 0.000813    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.43        |
|    n_updates             | 2660        |
|    policy_gradient_loss  | -0.00912    |
|    std                   | 0.952       |
|    value_loss            | 3.34        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.55247587 |
| rollout/                 |             |
|    ep_len_mean           | 858         |
|    ep_rew_mean           | -490        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 23          |
|    time_elapsed          | 752         |
|    total_timesteps       | 548864      |
| train/                   |             |
|    approx_kl             | 0.007057147 |
|    clip_fraction         | 0.0493      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.69        |
|    cost_value_loss       | 7.49        |
|    cost_values           | 1.92        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.73       |
|    explained_variance    | 0.672       |
|    lagrangian_multiplier | 0.000825    |
|    learning_rate         | 0.0003      |
|    loss                  | 7.95        |
|    n_updates             | 2670        |
|    policy_gradient_loss  | -0.00345    |
|    std                   | 0.948       |
|    value_loss            | 15.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.91        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.91        |
| reward                   | -0.5826643  |
| rollout/                 |             |
|    ep_len_mean           | 858         |
|    ep_rew_mean           | -485        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 24          |
|    time_elapsed          | 783         |
|    total_timesteps       | 550912      |
| train/                   |             |
|    approx_kl             | 0.007980768 |
|    clip_fraction         | 0.0773      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.92        |
|    cost_value_loss       | 7.14        |
|    cost_values           | 1.93        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.536       |
|    lagrangian_multiplier | 9.55e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 7.37        |
|    n_updates             | 2680        |
|    policy_gradient_loss  | -0.00503    |
|    std                   | 0.947       |
|    value_loss            | 10.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.5459067   |
| rollout/                 |              |
|    ep_len_mean           | 852          |
|    ep_rew_mean           | -476         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 25           |
|    time_elapsed          | 820          |
|    total_timesteps       | 552960       |
| train/                   |              |
|    approx_kl             | 0.0060297926 |
|    clip_fraction         | 0.0907       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.68         |
|    cost_value_loss       | 7.76         |
|    cost_values           | 2.23         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.766        |
|    lagrangian_multiplier | 0.000945     |
|    learning_rate         | 0.0003       |
|    loss                  | 3.85         |
|    n_updates             | 2690         |
|    policy_gradient_loss  | -0.00762     |
|    std                   | 0.941        |
|    value_loss            | 1.49         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.51768965 |
| rollout/                 |             |
|    ep_len_mean           | 848         |
|    ep_rew_mean           | -468        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 26          |
|    time_elapsed          | 858         |
|    total_timesteps       | 555008      |
| train/                   |             |
|    approx_kl             | 0.009495222 |
|    clip_fraction         | 0.134       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.15        |
|    cost_value_loss       | 9.62        |
|    cost_values           | 2.18        |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | 0.608       |
|    lagrangian_multiplier | 0.00207     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.95        |
|    n_updates             | 2700        |
|    policy_gradient_loss  | -0.00141    |
|    std                   | 0.94        |
|    value_loss            | 17.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.93        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.93        |
| reward                   | -0.59631866 |
| rollout/                 |             |
|    ep_len_mean           | 849         |
|    ep_rew_mean           | -465        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 27          |
|    time_elapsed          | 896         |
|    total_timesteps       | 557056      |
| train/                   |             |
|    approx_kl             | 0.007445398 |
|    clip_fraction         | 0.114       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.11        |
|    cost_value_loss       | 9.39        |
|    cost_values           | 2.05        |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | 0.668       |
|    lagrangian_multiplier | 0.00319     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.08        |
|    n_updates             | 2710        |
|    policy_gradient_loss  | -0.00793    |
|    std                   | 0.94        |
|    value_loss            | 10.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.47372705 |
| rollout/                 |             |
|    ep_len_mean           | 833         |
|    ep_rew_mean           | -454        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 28          |
|    time_elapsed          | 932         |
|    total_timesteps       | 559104      |
| train/                   |             |
|    approx_kl             | 0.015558699 |
|    clip_fraction         | 0.14        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.84        |
|    cost_value_loss       | 12.5        |
|    cost_values           | 2.07        |
|    entropy               | -2.7        |
|    entropy_loss          | -2.7        |
|    explained_variance    | 0.85        |
|    lagrangian_multiplier | 0.00283     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.46        |
|    n_updates             | 2720        |
|    policy_gradient_loss  | -0.0119     |
|    std                   | 0.937       |
|    value_loss            | 3.26        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.6612463  |
| rollout/                 |             |
|    ep_len_mean           | 840         |
|    ep_rew_mean           | -456        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 29          |
|    time_elapsed          | 968         |
|    total_timesteps       | 561152      |
| train/                   |             |
|    approx_kl             | 0.006515247 |
|    clip_fraction         | 0.0768      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.79        |
|    cost_value_loss       | 12.4        |
|    cost_values           | 2.17        |
|    entropy               | -2.69       |
|    entropy_loss          | -2.7        |
|    explained_variance    | 0.438       |
|    lagrangian_multiplier | 0.000927    |
|    learning_rate         | 0.0003      |
|    loss                  | 11.4        |
|    n_updates             | 2730        |
|    policy_gradient_loss  | -0.0039     |
|    std                   | 0.934       |
|    value_loss            | 24.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.4548216  |
| rollout/                 |             |
|    ep_len_mean           | 843         |
|    ep_rew_mean           | -457        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 30          |
|    time_elapsed          | 1002        |
|    total_timesteps       | 563200      |
| train/                   |             |
|    approx_kl             | 0.018359479 |
|    clip_fraction         | 0.102       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.79        |
|    cost_value_loss       | 7.17        |
|    cost_values           | 2.18        |
|    entropy               | -2.69       |
|    entropy_loss          | -2.69       |
|    explained_variance    | 0.519       |
|    lagrangian_multiplier | 0.00257     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.86        |
|    n_updates             | 2740        |
|    policy_gradient_loss  | -0.00746    |
|    std                   | 0.933       |
|    value_loss            | 6.81        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.32066575 |
| rollout/                 |             |
|    ep_len_mean           | 836         |
|    ep_rew_mean           | -447        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 31          |
|    time_elapsed          | 1036        |
|    total_timesteps       | 565248      |
| train/                   |             |
|    approx_kl             | 0.007789057 |
|    clip_fraction         | 0.0513      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.89        |
|    cost_value_loss       | 7.52        |
|    cost_values           | 2.12        |
|    entropy               | -2.68       |
|    entropy_loss          | -2.68       |
|    explained_variance    | 0.857       |
|    lagrangian_multiplier | 0.00124     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.9         |
|    n_updates             | 2750        |
|    policy_gradient_loss  | -0.00415    |
|    std                   | 0.927       |
|    value_loss            | 2.4         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.69         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.69         |
| reward                   | -0.40576252  |
| rollout/                 |              |
|    ep_len_mean           | 837          |
|    ep_rew_mean           | -445         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 32           |
|    time_elapsed          | 1070         |
|    total_timesteps       | 567296       |
| train/                   |              |
|    approx_kl             | 0.0066223564 |
|    clip_fraction         | 0.0578       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.4          |
|    cost_value_loss       | 9.22         |
|    cost_values           | 2.15         |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.327        |
|    lagrangian_multiplier | 0.000963     |
|    learning_rate         | 0.0003       |
|    loss                  | 7.89         |
|    n_updates             | 2760         |
|    policy_gradient_loss  | -0.0033      |
|    std                   | 0.925        |
|    value_loss            | 10.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.85         |
| reward                   | -0.580855    |
| rollout/                 |              |
|    ep_len_mean           | 821          |
|    ep_rew_mean           | -434         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 33           |
|    time_elapsed          | 1098         |
|    total_timesteps       | 569344       |
| train/                   |              |
|    approx_kl             | 0.0062785014 |
|    clip_fraction         | 0.108        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.06         |
|    cost_value_loss       | 10.4         |
|    cost_values           | 2.31         |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.595        |
|    lagrangian_multiplier | 0.00302      |
|    learning_rate         | 0.0003       |
|    loss                  | 4            |
|    n_updates             | 2770         |
|    policy_gradient_loss  | -0.00882     |
|    std                   | 0.926        |
|    value_loss            | 3.9          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.46883795 |
| rollout/                 |             |
|    ep_len_mean           | 821         |
|    ep_rew_mean           | -432        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 34          |
|    time_elapsed          | 1130        |
|    total_timesteps       | 571392      |
| train/                   |             |
|    approx_kl             | 0.009392968 |
|    clip_fraction         | 0.116       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.23        |
|    cost_value_loss       | 7.07        |
|    cost_values           | 2.29        |
|    entropy               | -2.68       |
|    entropy_loss          | -2.67       |
|    explained_variance    | 0.371       |
|    lagrangian_multiplier | 0.00252     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.87        |
|    n_updates             | 2780        |
|    policy_gradient_loss  | -0.00748    |
|    std                   | 0.927       |
|    value_loss            | 24.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.74600685 |
| rollout/                 |             |
|    ep_len_mean           | 818         |
|    ep_rew_mean           | -427        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 35          |
|    time_elapsed          | 1156        |
|    total_timesteps       | 573440      |
| train/                   |             |
|    approx_kl             | 0.008361054 |
|    clip_fraction         | 0.0571      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.61        |
|    cost_value_loss       | 9.36        |
|    cost_values           | 2.24        |
|    entropy               | -2.67       |
|    entropy_loss          | -2.67       |
|    explained_variance    | 0.773       |
|    lagrangian_multiplier | 0.00338     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.56        |
|    n_updates             | 2790        |
|    policy_gradient_loss  | -0.00359    |
|    std                   | 0.924       |
|    value_loss            | 2.33        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.4199992   |
| rollout/                 |              |
|    ep_len_mean           | 817          |
|    ep_rew_mean           | -423         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 36           |
|    time_elapsed          | 1182         |
|    total_timesteps       | 575488       |
| train/                   |              |
|    approx_kl             | 0.0056915227 |
|    clip_fraction         | 0.0794       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.88         |
|    cost_value_loss       | 13.5         |
|    cost_values           | 2.24         |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.503        |
|    lagrangian_multiplier | 0.00352      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.52         |
|    n_updates             | 2800         |
|    policy_gradient_loss  | -0.00331     |
|    std                   | 0.919        |
|    value_loss            | 15.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.30154318  |
| rollout/                 |              |
|    ep_len_mean           | 808          |
|    ep_rew_mean           | -417         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 37           |
|    time_elapsed          | 1219         |
|    total_timesteps       | 577536       |
| train/                   |              |
|    approx_kl             | 0.0076476843 |
|    clip_fraction         | 0.0907       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.77         |
|    cost_value_loss       | 11.9         |
|    cost_values           | 2.26         |
|    entropy               | -2.65        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.606        |
|    lagrangian_multiplier | 0.00357      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.55         |
|    n_updates             | 2810         |
|    policy_gradient_loss  | -0.00637     |
|    std                   | 0.917        |
|    value_loss            | 8.97         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.84        |
| reward                   | -0.42460012 |
| rollout/                 |             |
|    ep_len_mean           | 808         |
|    ep_rew_mean           | -415        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 38          |
|    time_elapsed          | 1255        |
|    total_timesteps       | 579584      |
| train/                   |             |
|    approx_kl             | 0.01295164  |
|    clip_fraction         | 0.144       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.73        |
|    cost_value_loss       | 11.2        |
|    cost_values           | 2.18        |
|    entropy               | -2.65       |
|    entropy_loss          | -2.65       |
|    explained_variance    | 0.52        |
|    lagrangian_multiplier | 0.00293     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.5         |
|    n_updates             | 2820        |
|    policy_gradient_loss  | -0.00769    |
|    std                   | 0.915       |
|    value_loss            | 15.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.3417213  |
| rollout/                 |             |
|    ep_len_mean           | 807         |
|    ep_rew_mean           | -414        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 39          |
|    time_elapsed          | 1291        |
|    total_timesteps       | 581632      |
| train/                   |             |
|    approx_kl             | 0.004960557 |
|    clip_fraction         | 0.0521      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.13        |
|    cost_value_loss       | 10.9        |
|    cost_values           | 2.15        |
|    entropy               | -2.63       |
|    entropy_loss          | -2.64       |
|    explained_variance    | 0.876       |
|    lagrangian_multiplier | 0.0038      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.52        |
|    n_updates             | 2830        |
|    policy_gradient_loss  | -0.0053     |
|    std                   | 0.908       |
|    value_loss            | 1.49        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.87        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.87        |
| reward                   | -0.4984646  |
| rollout/                 |             |
|    ep_len_mean           | 800         |
|    ep_rew_mean           | -407        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 40          |
|    time_elapsed          | 1323        |
|    total_timesteps       | 583680      |
| train/                   |             |
|    approx_kl             | 0.008806888 |
|    clip_fraction         | 0.129       |
|    clip_range            | 0.2         |
|    cost_returns          | 5           |
|    cost_value_loss       | 11.2        |
|    cost_values           | 2.39        |
|    entropy               | -2.63       |
|    entropy_loss          | -2.63       |
|    explained_variance    | 0.43        |
|    lagrangian_multiplier | 0.00472     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.53        |
|    n_updates             | 2840        |
|    policy_gradient_loss  | -0.0049     |
|    std                   | 0.907       |
|    value_loss            | 10.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.54589355  |
| rollout/                 |              |
|    ep_len_mean           | 803          |
|    ep_rew_mean           | -408         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 41           |
|    time_elapsed          | 1358         |
|    total_timesteps       | 585728       |
| train/                   |              |
|    approx_kl             | 0.0049419603 |
|    clip_fraction         | 0.0917       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.97         |
|    cost_value_loss       | 11.6         |
|    cost_values           | 2.49         |
|    entropy               | -2.63        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.271        |
|    lagrangian_multiplier | 0.00393      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.74         |
|    n_updates             | 2850         |
|    policy_gradient_loss  | -0.00203     |
|    std                   | 0.905        |
|    value_loss            | 17.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.93        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.93        |
| reward                   | -0.41554213 |
| rollout/                 |             |
|    ep_len_mean           | 803         |
|    ep_rew_mean           | -406        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 42          |
|    time_elapsed          | 1396        |
|    total_timesteps       | 587776      |
| train/                   |             |
|    approx_kl             | 0.008970933 |
|    clip_fraction         | 0.0682      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.06        |
|    cost_value_loss       | 12.1        |
|    cost_values           | 2.36        |
|    entropy               | -2.62       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0.543       |
|    lagrangian_multiplier | 0.00218     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.3         |
|    n_updates             | 2860        |
|    policy_gradient_loss  | -0.0059     |
|    std                   | 0.904       |
|    value_loss            | 9.91        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.7079827  |
| rollout/                 |             |
|    ep_len_mean           | 806         |
|    ep_rew_mean           | -405        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 43          |
|    time_elapsed          | 1431        |
|    total_timesteps       | 589824      |
| train/                   |             |
|    approx_kl             | 0.008666891 |
|    clip_fraction         | 0.071       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.9         |
|    cost_value_loss       | 11.5        |
|    cost_values           | 2.33        |
|    entropy               | -2.62       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0.712       |
|    lagrangian_multiplier | 0.00282     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.06        |
|    n_updates             | 2870        |
|    policy_gradient_loss  | -0.00592    |
|    std                   | 0.902       |
|    value_loss            | 2.38        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.4747544  |
| rollout/                 |             |
|    ep_len_mean           | 801         |
|    ep_rew_mean           | -401        |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 44          |
|    time_elapsed          | 1461        |
|    total_timesteps       | 591872      |
| train/                   |             |
|    approx_kl             | 0.008203786 |
|    clip_fraction         | 0.0661      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.13        |
|    cost_value_loss       | 13.1        |
|    cost_values           | 2.15        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0.703       |
|    lagrangian_multiplier | 0.00153     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.89        |
|    n_updates             | 2880        |
|    policy_gradient_loss  | -0.00353    |
|    std                   | 0.9         |
|    value_loss            | 8.35        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.72634065 |
| rollout/                 |             |
|    ep_len_mean           | 805         |
|    ep_rew_mean           | -400        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 45          |
|    time_elapsed          | 1485        |
|    total_timesteps       | 593920      |
| train/                   |             |
|    approx_kl             | 0.005109687 |
|    clip_fraction         | 0.0494      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.35        |
|    cost_value_loss       | 16          |
|    cost_values           | 2.17        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.301       |
|    lagrangian_multiplier | 0.00506     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.84        |
|    n_updates             | 2890        |
|    policy_gradient_loss  | -0.00375    |
|    std                   | 0.897       |
|    value_loss            | 9.31        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.88        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.88        |
| reward                   | -0.44258416 |
| rollout/                 |             |
|    ep_len_mean           | 783         |
|    ep_rew_mean           | -388        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 46          |
|    time_elapsed          | 1508        |
|    total_timesteps       | 595968      |
| train/                   |             |
|    approx_kl             | 0.006116974 |
|    clip_fraction         | 0.0398      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.7         |
|    cost_value_loss       | 12.4        |
|    cost_values           | 2.06        |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0.724       |
|    lagrangian_multiplier | 0.000823    |
|    learning_rate         | 0.0003      |
|    loss                  | 8.05        |
|    n_updates             | 2900        |
|    policy_gradient_loss  | -0.00241    |
|    std                   | 0.894       |
|    value_loss            | 9.69        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.06         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.06         |
| reward                   | -0.47139624  |
| rollout/                 |              |
|    ep_len_mean           | 783          |
|    ep_rew_mean           | -385         |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 47           |
|    time_elapsed          | 1531         |
|    total_timesteps       | 598016       |
| train/                   |              |
|    approx_kl             | 0.0043085837 |
|    clip_fraction         | 0.0338       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.14         |
|    cost_value_loss       | 9.17         |
|    cost_values           | 1.9          |
|    entropy               | -2.59        |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0.551        |
|    lagrangian_multiplier | 0.00294      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.33         |
|    n_updates             | 2910         |
|    policy_gradient_loss  | -0.00384     |
|    std                   | 0.892        |
|    value_loss            | 21.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -0.41958767  |
| rollout/                 |              |
|    ep_len_mean           | 786          |
|    ep_rew_mean           | -386         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 48           |
|    time_elapsed          | 1554         |
|    total_timesteps       | 600064       |
| train/                   |              |
|    approx_kl             | 0.0062537207 |
|    clip_fraction         | 0.0995       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.69         |
|    cost_value_loss       | 12.1         |
|    cost_values           | 2.11         |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.72         |
|    lagrangian_multiplier | 0.00559      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.57         |
|    n_updates             | 2920         |
|    policy_gradient_loss  | -0.0102      |
|    std                   | 0.891        |
|    value_loss            | 2.68         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.87        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.87        |
| reward                   | -0.49559835 |
| rollout/                 |             |
|    ep_len_mean           | 791         |
|    ep_rew_mean           | -387        |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 49          |
|    time_elapsed          | 1578        |
|    total_timesteps       | 602112      |
| train/                   |             |
|    approx_kl             | 0.004539959 |
|    clip_fraction         | 0.105       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.83        |
|    cost_value_loss       | 11.2        |
|    cost_values           | 2.36        |
|    entropy               | -2.58       |
|    entropy_loss          | -2.59       |
|    explained_variance    | 0.282       |
|    lagrangian_multiplier | 0.003       |
|    learning_rate         | 0.0003      |
|    loss                  | 5.49        |
|    n_updates             | 2930        |
|    policy_gradient_loss  | -0.00585    |
|    std                   | 0.888       |
|    value_loss            | 8.69        |
------------------------------------------
------------------------------------
| avg_speed          | 8           |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8           |
| reward             | -0.42787656 |
| rollout/           |             |
|    ep_len_mean     | 796         |
|    ep_rew_mean     | -389        |
| time/              |             |
|    fps             | 92          |
|    iterations      | 1           |
|    time_elapsed    | 22          |
|    total_timesteps | 604160      |
------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.33832645 |
| rollout/                 |             |
|    ep_len_mean           | 795         |
|    ep_rew_mean           | -385        |
| time/                    |             |
|    fps                   | 83          |
|    iterations            | 2           |
|    time_elapsed          | 48          |
|    total_timesteps       | 606208      |
| train/                   |             |
|    approx_kl             | 0.006690599 |
|    clip_fraction         | 0.0973      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.87        |
|    cost_value_loss       | 14.1        |
|    cost_values           | 2.12        |
|    entropy               | -2.58       |
|    entropy_loss          | -2.58       |
|    explained_variance    | 0.695       |
|    lagrangian_multiplier | 0.00794     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.68        |
|    n_updates             | 2950        |
|    policy_gradient_loss  | -0.00291    |
|    std                   | 0.887       |
|    value_loss            | 7.86        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.86        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.86        |
| reward                   | -0.2618215  |
| rollout/                 |             |
|    ep_len_mean           | 795         |
|    ep_rew_mean           | -383        |
| time/                    |             |
|    fps                   | 80          |
|    iterations            | 3           |
|    time_elapsed          | 76          |
|    total_timesteps       | 608256      |
| train/                   |             |
|    approx_kl             | 0.009045433 |
|    clip_fraction         | 0.103       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.35        |
|    cost_value_loss       | 10.9        |
|    cost_values           | 2.11        |
|    entropy               | -2.58       |
|    entropy_loss          | -2.58       |
|    explained_variance    | 0.731       |
|    lagrangian_multiplier | 0.00192     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.75        |
|    n_updates             | 2960        |
|    policy_gradient_loss  | -0.00325    |
|    std                   | 0.886       |
|    value_loss            | 9.16        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.77         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.77         |
| reward                   | -0.40898997  |
| rollout/                 |              |
|    ep_len_mean           | 785          |
|    ep_rew_mean           | -377         |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 4            |
|    time_elapsed          | 112          |
|    total_timesteps       | 610304       |
| train/                   |              |
|    approx_kl             | 0.0066236267 |
|    clip_fraction         | 0.0424       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.25         |
|    cost_value_loss       | 15.1         |
|    cost_values           | 2.26         |
|    entropy               | -2.56        |
|    entropy_loss          | -2.57        |
|    explained_variance    | 0.793        |
|    lagrangian_multiplier | 0.00668      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.67         |
|    n_updates             | 2970         |
|    policy_gradient_loss  | -0.00637     |
|    std                   | 0.881        |
|    value_loss            | 1.44         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.5636473   |
| rollout/                 |              |
|    ep_len_mean           | 789          |
|    ep_rew_mean           | -377         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 5            |
|    time_elapsed          | 147          |
|    total_timesteps       | 612352       |
| train/                   |              |
|    approx_kl             | 0.0058131414 |
|    clip_fraction         | 0.0754       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.4          |
|    cost_value_loss       | 3.3          |
|    cost_values           | 2.27         |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0.299        |
|    lagrangian_multiplier | 0.000803     |
|    learning_rate         | 0.0003       |
|    loss                  | 8.33         |
|    n_updates             | 2980         |
|    policy_gradient_loss  | -0.00422     |
|    std                   | 0.882        |
|    value_loss            | 20.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.44753605 |
| rollout/                 |             |
|    ep_len_mean           | 784         |
|    ep_rew_mean           | -371        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 6           |
|    time_elapsed          | 178         |
|    total_timesteps       | 614400      |
| train/                   |             |
|    approx_kl             | 0.011346345 |
|    clip_fraction         | 0.11        |
|    clip_range            | 0.2         |
|    cost_returns          | 5.16        |
|    cost_value_loss       | 13.6        |
|    cost_values           | 2.25        |
|    entropy               | -2.56       |
|    entropy_loss          | -2.56       |
|    explained_variance    | 0.616       |
|    lagrangian_multiplier | 0.0038      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.97        |
|    n_updates             | 2990        |
|    policy_gradient_loss  | -0.00561    |
|    std                   | 0.88        |
|    value_loss            | 7.66        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -0.33546814 |
| rollout/                 |             |
|    ep_len_mean           | 778         |
|    ep_rew_mean           | -367        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 7           |
|    time_elapsed          | 211         |
|    total_timesteps       | 616448      |
| train/                   |             |
|    approx_kl             | 0.005960144 |
|    clip_fraction         | 0.136       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.6         |
|    cost_value_loss       | 19          |
|    cost_values           | 2.13        |
|    entropy               | -2.55       |
|    entropy_loss          | -2.56       |
|    explained_variance    | 0.721       |
|    lagrangian_multiplier | 0.00627     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.68        |
|    n_updates             | 3000        |
|    policy_gradient_loss  | -0.00529    |
|    std                   | 0.879       |
|    value_loss            | 6.7         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.45958328  |
| rollout/                 |              |
|    ep_len_mean           | 785          |
|    ep_rew_mean           | -368         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 8            |
|    time_elapsed          | 244          |
|    total_timesteps       | 618496       |
| train/                   |              |
|    approx_kl             | 0.0074494863 |
|    clip_fraction         | 0.106        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.99         |
|    cost_value_loss       | 14.4         |
|    cost_values           | 2.16         |
|    entropy               | -2.55        |
|    entropy_loss          | -2.55        |
|    explained_variance    | 0.626        |
|    lagrangian_multiplier | 0.00364      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.46         |
|    n_updates             | 3010         |
|    policy_gradient_loss  | -0.00377     |
|    std                   | 0.877        |
|    value_loss            | 7.04         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.40235746 |
| rollout/                 |             |
|    ep_len_mean           | 779         |
|    ep_rew_mean           | -364        |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 9           |
|    time_elapsed          | 282         |
|    total_timesteps       | 620544      |
| train/                   |             |
|    approx_kl             | 0.011198852 |
|    clip_fraction         | 0.131       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.63        |
|    cost_value_loss       | 11.3        |
|    cost_values           | 2.09        |
|    entropy               | -2.55       |
|    entropy_loss          | -2.55       |
|    explained_variance    | 0.697       |
|    lagrangian_multiplier | 0.00135     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.99        |
|    n_updates             | 3020        |
|    policy_gradient_loss  | -0.00706    |
|    std                   | 0.877       |
|    value_loss            | 7.7         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.3895708  |
| rollout/                 |             |
|    ep_len_mean           | 772         |
|    ep_rew_mean           | -359        |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 10          |
|    time_elapsed          | 320         |
|    total_timesteps       | 622592      |
| train/                   |             |
|    approx_kl             | 0.009753273 |
|    clip_fraction         | 0.138       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.51        |
|    cost_value_loss       | 10.8        |
|    cost_values           | 1.93        |
|    entropy               | -2.55       |
|    entropy_loss          | -2.55       |
|    explained_variance    | 0.574       |
|    lagrangian_multiplier | 0.00207     |
|    learning_rate         | 0.0003      |
|    loss                  | 11.2        |
|    n_updates             | 3030        |
|    policy_gradient_loss  | -0.00485    |
|    std                   | 0.876       |
|    value_loss            | 19.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.65        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.65        |
| reward                   | -0.39223388 |
| rollout/                 |             |
|    ep_len_mean           | 770         |
|    ep_rew_mean           | -355        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 11          |
|    time_elapsed          | 357         |
|    total_timesteps       | 624640      |
| train/                   |             |
|    approx_kl             | 0.011561006 |
|    clip_fraction         | 0.136       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.4         |
|    cost_value_loss       | 10.5        |
|    cost_values           | 2.02        |
|    entropy               | -2.55       |
|    entropy_loss          | -2.55       |
|    explained_variance    | 0.276       |
|    lagrangian_multiplier | 0.00149     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.57        |
|    n_updates             | 3040        |
|    policy_gradient_loss  | -0.00761    |
|    std                   | 0.876       |
|    value_loss            | 17.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.25033253 |
| rollout/                 |             |
|    ep_len_mean           | 777         |
|    ep_rew_mean           | -356        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 12          |
|    time_elapsed          | 393         |
|    total_timesteps       | 626688      |
| train/                   |             |
|    approx_kl             | 0.008633451 |
|    clip_fraction         | 0.0875      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.4         |
|    cost_value_loss       | 15.3        |
|    cost_values           | 2.32        |
|    entropy               | -2.54       |
|    entropy_loss          | -2.54       |
|    explained_variance    | 0.366       |
|    lagrangian_multiplier | 0.0046      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.68        |
|    n_updates             | 3050        |
|    policy_gradient_loss  | -0.00433    |
|    std                   | 0.873       |
|    value_loss            | 7.57        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.83         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.83         |
| reward                   | -0.3693707   |
| rollout/                 |              |
|    ep_len_mean           | 774          |
|    ep_rew_mean           | -354         |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 13           |
|    time_elapsed          | 430          |
|    total_timesteps       | 628736       |
| train/                   |              |
|    approx_kl             | 0.0041988427 |
|    clip_fraction         | 0.0689       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.22         |
|    cost_value_loss       | 12.4         |
|    cost_values           | 2.27         |
|    entropy               | -2.53        |
|    entropy_loss          | -2.53        |
|    explained_variance    | 0.618        |
|    lagrangian_multiplier | 0.00276      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.19         |
|    n_updates             | 3060         |
|    policy_gradient_loss  | -0.00393     |
|    std                   | 0.869        |
|    value_loss            | 6.42         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.78        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.78        |
| reward                   | -0.5466344  |
| rollout/                 |             |
|    ep_len_mean           | 767         |
|    ep_rew_mean           | -349        |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 14          |
|    time_elapsed          | 462         |
|    total_timesteps       | 630784      |
| train/                   |             |
|    approx_kl             | 0.008683931 |
|    clip_fraction         | 0.108       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.45        |
|    cost_value_loss       | 14.4        |
|    cost_values           | 2.3         |
|    entropy               | -2.53       |
|    entropy_loss          | -2.53       |
|    explained_variance    | 0.318       |
|    lagrangian_multiplier | 0.00375     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.87        |
|    n_updates             | 3070        |
|    policy_gradient_loss  | -0.00329    |
|    std                   | 0.867       |
|    value_loss            | 11.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.28376487  |
| rollout/                 |              |
|    ep_len_mean           | 759          |
|    ep_rew_mean           | -344         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 15           |
|    time_elapsed          | 484          |
|    total_timesteps       | 632832       |
| train/                   |              |
|    approx_kl             | 0.0035114293 |
|    clip_fraction         | 0.073        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.55         |
|    cost_value_loss       | 10.8         |
|    cost_values           | 2.15         |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.531        |
|    lagrangian_multiplier | 0.0027       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.5          |
|    n_updates             | 3080         |
|    policy_gradient_loss  | -0.00232     |
|    std                   | 0.865        |
|    value_loss            | 12.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.6358527  |
| rollout/                 |             |
|    ep_len_mean           | 765         |
|    ep_rew_mean           | -346        |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 16          |
|    time_elapsed          | 507         |
|    total_timesteps       | 634880      |
| train/                   |             |
|    approx_kl             | 0.017209541 |
|    clip_fraction         | 0.107       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.27        |
|    cost_value_loss       | 10.5        |
|    cost_values           | 2.07        |
|    entropy               | -2.51       |
|    entropy_loss          | -2.52       |
|    explained_variance    | 0.73        |
|    lagrangian_multiplier | 0.00465     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.63        |
|    n_updates             | 3090        |
|    policy_gradient_loss  | -0.00372    |
|    std                   | 0.862       |
|    value_loss            | 7.3         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.84        |
| reward                   | -0.20800371 |
| rollout/                 |             |
|    ep_len_mean           | 763         |
|    ep_rew_mean           | -344        |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 17          |
|    time_elapsed          | 530         |
|    total_timesteps       | 636928      |
| train/                   |             |
|    approx_kl             | 0.009894259 |
|    clip_fraction         | 0.161       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.01        |
|    cost_value_loss       | 14.3        |
|    cost_values           | 2.23        |
|    entropy               | -2.51       |
|    entropy_loss          | -2.51       |
|    explained_variance    | 0.272       |
|    lagrangian_multiplier | 0.000652    |
|    learning_rate         | 0.0003      |
|    loss                  | 6.81        |
|    n_updates             | 3100        |
|    policy_gradient_loss  | -0.00371    |
|    std                   | 0.861       |
|    value_loss            | 8.16        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.41295648  |
| rollout/                 |              |
|    ep_len_mean           | 735          |
|    ep_rew_mean           | -328         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 18           |
|    time_elapsed          | 557          |
|    total_timesteps       | 638976       |
| train/                   |              |
|    approx_kl             | 0.0059139943 |
|    clip_fraction         | 0.0761       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.61         |
|    cost_value_loss       | 15.6         |
|    cost_values           | 2.41         |
|    entropy               | -2.51        |
|    entropy_loss          | -2.51        |
|    explained_variance    | 0.212        |
|    lagrangian_multiplier | 0.00443      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.48         |
|    n_updates             | 3110         |
|    policy_gradient_loss  | -0.00493     |
|    std                   | 0.86         |
|    value_loss            | 13.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5182139  |
| rollout/                 |             |
|    ep_len_mean           | 723         |
|    ep_rew_mean           | -322        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 19          |
|    time_elapsed          | 586         |
|    total_timesteps       | 641024      |
| train/                   |             |
|    approx_kl             | 0.007324166 |
|    clip_fraction         | 0.0867      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.19        |
|    cost_value_loss       | 13.4        |
|    cost_values           | 2.4         |
|    entropy               | -2.5        |
|    entropy_loss          | -2.5        |
|    explained_variance    | 0.21        |
|    lagrangian_multiplier | 0.00279     |
|    learning_rate         | 0.0003      |
|    loss                  | 10.7        |
|    n_updates             | 3120        |
|    policy_gradient_loss  | -0.00457    |
|    std                   | 0.856       |
|    value_loss            | 28.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.4735407  |
| rollout/                 |             |
|    ep_len_mean           | 731         |
|    ep_rew_mean           | -324        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 20          |
|    time_elapsed          | 616         |
|    total_timesteps       | 643072      |
| train/                   |             |
|    approx_kl             | 0.008438508 |
|    clip_fraction         | 0.0649      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.96        |
|    cost_value_loss       | 12          |
|    cost_values           | 2.32        |
|    entropy               | -2.5        |
|    entropy_loss          | -2.5        |
|    explained_variance    | 0.218       |
|    lagrangian_multiplier | 0.00416     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.98        |
|    n_updates             | 3130        |
|    policy_gradient_loss  | -0.00399    |
|    std                   | 0.858       |
|    value_loss            | 16.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.3479864   |
| rollout/                 |              |
|    ep_len_mean           | 719          |
|    ep_rew_mean           | -318         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 21           |
|    time_elapsed          | 650          |
|    total_timesteps       | 645120       |
| train/                   |              |
|    approx_kl             | 0.0043067243 |
|    clip_fraction         | 0.101        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.3          |
|    cost_value_loss       | 8.62         |
|    cost_values           | 2.18         |
|    entropy               | -2.49        |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0.458        |
|    lagrangian_multiplier | 0.00332      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.93         |
|    n_updates             | 3140         |
|    policy_gradient_loss  | -0.00334     |
|    std                   | 0.853        |
|    value_loss            | 11.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.41665697 |
| rollout/                 |             |
|    ep_len_mean           | 722         |
|    ep_rew_mean           | -318        |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 22          |
|    time_elapsed          | 688         |
|    total_timesteps       | 647168      |
| train/                   |             |
|    approx_kl             | 0.010708928 |
|    clip_fraction         | 0.117       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.74        |
|    cost_value_loss       | 11.2        |
|    cost_values           | 2.22        |
|    entropy               | -2.49       |
|    entropy_loss          | -2.49       |
|    explained_variance    | 0.338       |
|    lagrangian_multiplier | 0.00429     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.8         |
|    n_updates             | 3150        |
|    policy_gradient_loss  | -0.00626    |
|    std                   | 0.853       |
|    value_loss            | 11.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.29617476 |
| rollout/                 |             |
|    ep_len_mean           | 714         |
|    ep_rew_mean           | -314        |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 23          |
|    time_elapsed          | 718         |
|    total_timesteps       | 649216      |
| train/                   |             |
|    approx_kl             | 0.006359613 |
|    clip_fraction         | 0.0887      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.51        |
|    cost_value_loss       | 16          |
|    cost_values           | 2.17        |
|    entropy               | -2.48       |
|    entropy_loss          | -2.48       |
|    explained_variance    | 0.414       |
|    lagrangian_multiplier | 0.00386     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.25        |
|    n_updates             | 3160        |
|    policy_gradient_loss  | -0.00517    |
|    std                   | 0.849       |
|    value_loss            | 12.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.46651626  |
| rollout/                 |              |
|    ep_len_mean           | 708          |
|    ep_rew_mean           | -310         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 24           |
|    time_elapsed          | 741          |
|    total_timesteps       | 651264       |
| train/                   |              |
|    approx_kl             | 0.0059772544 |
|    clip_fraction         | 0.0734       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.97         |
|    cost_value_loss       | 14.1         |
|    cost_values           | 2.01         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.561        |
|    lagrangian_multiplier | 0.00296      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.63         |
|    n_updates             | 3170         |
|    policy_gradient_loss  | -0.00355     |
|    std                   | 0.846        |
|    value_loss            | 12.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.83         |
| reward                   | -0.392349    |
| rollout/                 |              |
|    ep_len_mean           | 693          |
|    ep_rew_mean           | -302         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 25           |
|    time_elapsed          | 764          |
|    total_timesteps       | 653312       |
| train/                   |              |
|    approx_kl             | 0.0040227184 |
|    clip_fraction         | 0.0418       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.28         |
|    cost_value_loss       | 14.7         |
|    cost_values           | 2.1          |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.393        |
|    lagrangian_multiplier | 0.00527      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.76         |
|    n_updates             | 3180         |
|    policy_gradient_loss  | -0.00291     |
|    std                   | 0.845        |
|    value_loss            | 21.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.87         |
| reward                   | -0.2949965   |
| rollout/                 |              |
|    ep_len_mean           | 668          |
|    ep_rew_mean           | -289         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 26           |
|    time_elapsed          | 789          |
|    total_timesteps       | 655360       |
| train/                   |              |
|    approx_kl             | 0.0103307795 |
|    clip_fraction         | 0.144        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.8          |
|    cost_value_loss       | 12.3         |
|    cost_values           | 1.97         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.476        |
|    lagrangian_multiplier | 0.00408      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.88         |
|    n_updates             | 3190         |
|    policy_gradient_loss  | -0.00703     |
|    std                   | 0.846        |
|    value_loss            | 20.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.8          |
| reward                   | -0.8696715   |
| rollout/                 |              |
|    ep_len_mean           | 671          |
|    ep_rew_mean           | -289         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 27           |
|    time_elapsed          | 822          |
|    total_timesteps       | 657408       |
| train/                   |              |
|    approx_kl             | 0.0075685736 |
|    clip_fraction         | 0.0732       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.77         |
|    cost_value_loss       | 12           |
|    cost_values           | 2.01         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.351        |
|    lagrangian_multiplier | 0.00339      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.96         |
|    n_updates             | 3200         |
|    policy_gradient_loss  | -0.00636     |
|    std                   | 0.845        |
|    value_loss            | 18.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.54279876 |
| rollout/                 |             |
|    ep_len_mean           | 653         |
|    ep_rew_mean           | -281        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 28          |
|    time_elapsed          | 858         |
|    total_timesteps       | 659456      |
| train/                   |             |
|    approx_kl             | 0.014570747 |
|    clip_fraction         | 0.133       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.68        |
|    cost_value_loss       | 9.9         |
|    cost_values           | 2.26        |
|    entropy               | -2.46       |
|    entropy_loss          | -2.47       |
|    explained_variance    | 0.28        |
|    lagrangian_multiplier | 0.00109     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.53        |
|    n_updates             | 3210        |
|    policy_gradient_loss  | -0.00615    |
|    std                   | 0.841       |
|    value_loss            | 10.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.3043234   |
| rollout/                 |              |
|    ep_len_mean           | 665          |
|    ep_rew_mean           | -287         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 29           |
|    time_elapsed          | 892          |
|    total_timesteps       | 661504       |
| train/                   |              |
|    approx_kl             | 0.0071439818 |
|    clip_fraction         | 0.121        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.86         |
|    cost_value_loss       | 22.1         |
|    cost_values           | 2.07         |
|    entropy               | -2.46        |
|    entropy_loss          | -2.46        |
|    explained_variance    | 0.545        |
|    lagrangian_multiplier | 0.00551      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.84         |
|    n_updates             | 3220         |
|    policy_gradient_loss  | -0.00684     |
|    std                   | 0.841        |
|    value_loss            | 16.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.20707725 |
| rollout/                 |             |
|    ep_len_mean           | 666         |
|    ep_rew_mean           | -286        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 30          |
|    time_elapsed          | 928         |
|    total_timesteps       | 663552      |
| train/                   |             |
|    approx_kl             | 0.010232763 |
|    clip_fraction         | 0.155       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.94        |
|    cost_value_loss       | 21.4        |
|    cost_values           | 2.12        |
|    entropy               | -2.46       |
|    entropy_loss          | -2.46       |
|    explained_variance    | 0.556       |
|    lagrangian_multiplier | 0.00686     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.11        |
|    n_updates             | 3230        |
|    policy_gradient_loss  | -0.0105     |
|    std                   | 0.841       |
|    value_loss            | 6.47        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.38571498 |
| rollout/                 |             |
|    ep_len_mean           | 663         |
|    ep_rew_mean           | -284        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 31          |
|    time_elapsed          | 961         |
|    total_timesteps       | 665600      |
| train/                   |             |
|    approx_kl             | 0.008606989 |
|    clip_fraction         | 0.0803      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.95        |
|    cost_value_loss       | 19          |
|    cost_values           | 2.25        |
|    entropy               | -2.46       |
|    entropy_loss          | -2.46       |
|    explained_variance    | 0.194       |
|    lagrangian_multiplier | 0.00198     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.1         |
|    n_updates             | 3240        |
|    policy_gradient_loss  | -0.00213    |
|    std                   | 0.841       |
|    value_loss            | 13.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.88        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.88        |
| reward                   | -0.39940706 |
| rollout/                 |             |
|    ep_len_mean           | 621         |
|    ep_rew_mean           | -265        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 32          |
|    time_elapsed          | 988         |
|    total_timesteps       | 667648      |
| train/                   |             |
|    approx_kl             | 0.008050266 |
|    clip_fraction         | 0.107       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.08        |
|    cost_value_loss       | 6.28        |
|    cost_values           | 2.36        |
|    entropy               | -2.45       |
|    entropy_loss          | -2.46       |
|    explained_variance    | 0.209       |
|    lagrangian_multiplier | 0.00252     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.04        |
|    n_updates             | 3250        |
|    policy_gradient_loss  | -0.00474    |
|    std                   | 0.838       |
|    value_loss            | 14.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.5596755  |
| rollout/                 |             |
|    ep_len_mean           | 629         |
|    ep_rew_mean           | -267        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 33          |
|    time_elapsed          | 1014        |
|    total_timesteps       | 669696      |
| train/                   |             |
|    approx_kl             | 0.008464068 |
|    clip_fraction         | 0.0888      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.45        |
|    cost_value_loss       | 9.01        |
|    cost_values           | 2.28        |
|    entropy               | -2.45       |
|    entropy_loss          | -2.45       |
|    explained_variance    | 0.314       |
|    lagrangian_multiplier | 0.00303     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.83        |
|    n_updates             | 3260        |
|    policy_gradient_loss  | -0.00585    |
|    std                   | 0.835       |
|    value_loss            | 30.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.4614493  |
| rollout/                 |             |
|    ep_len_mean           | 615         |
|    ep_rew_mean           | -261        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 34          |
|    time_elapsed          | 1050        |
|    total_timesteps       | 671744      |
| train/                   |             |
|    approx_kl             | 0.008213869 |
|    clip_fraction         | 0.0512      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.82        |
|    cost_value_loss       | 12.5        |
|    cost_values           | 2.1         |
|    entropy               | -2.43       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 0.84        |
|    lagrangian_multiplier | 0.00317     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.1         |
|    n_updates             | 3270        |
|    policy_gradient_loss  | -0.00298    |
|    std                   | 0.831       |
|    value_loss            | 2.01        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.91        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.91        |
| reward                   | -0.41879818 |
| rollout/                 |             |
|    ep_len_mean           | 610         |
|    ep_rew_mean           | -258        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 35          |
|    time_elapsed          | 1085        |
|    total_timesteps       | 673792      |
| train/                   |             |
|    approx_kl             | 0.011470179 |
|    clip_fraction         | 0.119       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.28        |
|    cost_value_loss       | 8.68        |
|    cost_values           | 2.25        |
|    entropy               | -2.43       |
|    entropy_loss          | -2.43       |
|    explained_variance    | 0.209       |
|    lagrangian_multiplier | 0.000479    |
|    learning_rate         | 0.0003      |
|    loss                  | 9.1         |
|    n_updates             | 3280        |
|    policy_gradient_loss  | -0.00305    |
|    std                   | 0.829       |
|    value_loss            | 13.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.17818241 |
| rollout/                 |             |
|    ep_len_mean           | 588         |
|    ep_rew_mean           | -248        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 36          |
|    time_elapsed          | 1115        |
|    total_timesteps       | 675840      |
| train/                   |             |
|    approx_kl             | 0.015137611 |
|    clip_fraction         | 0.167       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.02        |
|    cost_value_loss       | 12.9        |
|    cost_values           | 2.36        |
|    entropy               | -2.42       |
|    entropy_loss          | -2.42       |
|    explained_variance    | 0.392       |
|    lagrangian_multiplier | 0.00182     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.01        |
|    n_updates             | 3290        |
|    policy_gradient_loss  | -0.0081     |
|    std                   | 0.825       |
|    value_loss            | 8.75        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.37773612 |
| rollout/                 |             |
|    ep_len_mean           | 584         |
|    ep_rew_mean           | -245        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 37          |
|    time_elapsed          | 1147        |
|    total_timesteps       | 677888      |
| train/                   |             |
|    approx_kl             | 0.007517609 |
|    clip_fraction         | 0.0998      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.14        |
|    cost_value_loss       | 14          |
|    cost_values           | 2.21        |
|    entropy               | -2.41       |
|    entropy_loss          | -2.42       |
|    explained_variance    | 0.38        |
|    lagrangian_multiplier | 0.00498     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.06        |
|    n_updates             | 3300        |
|    policy_gradient_loss  | -0.00373    |
|    std                   | 0.823       |
|    value_loss            | 21.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.38786197 |
| rollout/                 |             |
|    ep_len_mean           | 587         |
|    ep_rew_mean           | -245        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 38          |
|    time_elapsed          | 1176        |
|    total_timesteps       | 679936      |
| train/                   |             |
|    approx_kl             | 0.017554915 |
|    clip_fraction         | 0.0824      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.37        |
|    cost_value_loss       | 16.6        |
|    cost_values           | 2.14        |
|    entropy               | -2.41       |
|    entropy_loss          | -2.41       |
|    explained_variance    | 0.411       |
|    lagrangian_multiplier | 0.00683     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.09        |
|    n_updates             | 3310        |
|    policy_gradient_loss  | -0.00381    |
|    std                   | 0.821       |
|    value_loss            | 17.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.4401353  |
| rollout/                 |             |
|    ep_len_mean           | 595         |
|    ep_rew_mean           | -248        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 39          |
|    time_elapsed          | 1206        |
|    total_timesteps       | 681984      |
| train/                   |             |
|    approx_kl             | 0.012633721 |
|    clip_fraction         | 0.0992      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.64        |
|    cost_value_loss       | 15.5        |
|    cost_values           | 2.32        |
|    entropy               | -2.41       |
|    entropy_loss          | -2.41       |
|    explained_variance    | 0.282       |
|    lagrangian_multiplier | 0.00309     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.86        |
|    n_updates             | 3320        |
|    policy_gradient_loss  | -0.00465    |
|    std                   | 0.82        |
|    value_loss            | 8.63        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.86        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.86        |
| reward                   | -0.38990432 |
| rollout/                 |             |
|    ep_len_mean           | 598         |
|    ep_rew_mean           | -249        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 40          |
|    time_elapsed          | 1231        |
|    total_timesteps       | 684032      |
| train/                   |             |
|    approx_kl             | 0.007598401 |
|    clip_fraction         | 0.113       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.57        |
|    cost_value_loss       | 14.2        |
|    cost_values           | 2.42        |
|    entropy               | -2.4        |
|    entropy_loss          | -2.4        |
|    explained_variance    | 0.449       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.3        |
|    n_updates             | 3330        |
|    policy_gradient_loss  | -0.00169    |
|    std                   | 0.818       |
|    value_loss            | 8.71        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.63315743 |
| rollout/                 |             |
|    ep_len_mean           | 589         |
|    ep_rew_mean           | -246        |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 41          |
|    time_elapsed          | 1254        |
|    total_timesteps       | 686080      |
| train/                   |             |
|    approx_kl             | 0.010573128 |
|    clip_fraction         | 0.151       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.67        |
|    cost_value_loss       | 26.3        |
|    cost_values           | 2.31        |
|    entropy               | -2.4        |
|    entropy_loss          | -2.4        |
|    explained_variance    | 0.88        |
|    lagrangian_multiplier | 0.0106      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.96        |
|    n_updates             | 3340        |
|    policy_gradient_loss  | -0.0115     |
|    std                   | 0.82        |
|    value_loss            | 1.71        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.91        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.91        |
| reward                   | -0.50065935 |
| rollout/                 |             |
|    ep_len_mean           | 564         |
|    ep_rew_mean           | -235        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 42          |
|    time_elapsed          | 1276        |
|    total_timesteps       | 688128      |
| train/                   |             |
|    approx_kl             | 0.006652359 |
|    clip_fraction         | 0.06        |
|    clip_range            | 0.2         |
|    cost_returns          | 5.57        |
|    cost_value_loss       | 14.3        |
|    cost_values           | 2.4         |
|    entropy               | -2.4        |
|    entropy_loss          | -2.4        |
|    explained_variance    | 0.303       |
|    lagrangian_multiplier | 0.00259     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.44        |
|    n_updates             | 3350        |
|    policy_gradient_loss  | -0.00433    |
|    std                   | 0.821       |
|    value_loss            | 11.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.41973013 |
| rollout/                 |             |
|    ep_len_mean           | 544         |
|    ep_rew_mean           | -225        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 43          |
|    time_elapsed          | 1306        |
|    total_timesteps       | 690176      |
| train/                   |             |
|    approx_kl             | 0.009168346 |
|    clip_fraction         | 0.066       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.43        |
|    cost_value_loss       | 12.8        |
|    cost_values           | 2.34        |
|    entropy               | -2.39       |
|    entropy_loss          | -2.4        |
|    explained_variance    | 0.223       |
|    lagrangian_multiplier | 0.00235     |
|    learning_rate         | 0.0003      |
|    loss                  | 11.3        |
|    n_updates             | 3360        |
|    policy_gradient_loss  | -0.00373    |
|    std                   | 0.816       |
|    value_loss            | 27          |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.22044341 |
| rollout/                 |             |
|    ep_len_mean           | 544         |
|    ep_rew_mean           | -224        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 44          |
|    time_elapsed          | 1339        |
|    total_timesteps       | 692224      |
| train/                   |             |
|    approx_kl             | 0.011677157 |
|    clip_fraction         | 0.117       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.86        |
|    cost_value_loss       | 10.5        |
|    cost_values           | 2.26        |
|    entropy               | -2.38       |
|    entropy_loss          | -2.39       |
|    explained_variance    | 0.284       |
|    lagrangian_multiplier | 0.0052      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.63        |
|    n_updates             | 3370        |
|    policy_gradient_loss  | -0.00636    |
|    std                   | 0.813       |
|    value_loss            | 20.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.75        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.75        |
| reward                   | -0.24432407 |
| rollout/                 |             |
|    ep_len_mean           | 557         |
|    ep_rew_mean           | -228        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 45          |
|    time_elapsed          | 1370        |
|    total_timesteps       | 694272      |
| train/                   |             |
|    approx_kl             | 0.012119209 |
|    clip_fraction         | 0.132       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.2         |
|    cost_value_loss       | 12.1        |
|    cost_values           | 2.29        |
|    entropy               | -2.38       |
|    entropy_loss          | -2.38       |
|    explained_variance    | 0.352       |
|    lagrangian_multiplier | 0.00577     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.27        |
|    n_updates             | 3380        |
|    policy_gradient_loss  | -0.00497    |
|    std                   | 0.811       |
|    value_loss            | 14.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.35804462 |
| rollout/                 |             |
|    ep_len_mean           | 559         |
|    ep_rew_mean           | -228        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 46          |
|    time_elapsed          | 1398        |
|    total_timesteps       | 696320      |
| train/                   |             |
|    approx_kl             | 0.008470095 |
|    clip_fraction         | 0.0878      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.83        |
|    cost_value_loss       | 12.6        |
|    cost_values           | 2.36        |
|    entropy               | -2.37       |
|    entropy_loss          | -2.37       |
|    explained_variance    | 0.448       |
|    lagrangian_multiplier | 0.00617     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.69        |
|    n_updates             | 3390        |
|    policy_gradient_loss  | -0.00221    |
|    std                   | 0.807       |
|    value_loss            | 11.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.2          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.2          |
| reward                   | -0.4711776   |
| rollout/                 |              |
|    ep_len_mean           | 554          |
|    ep_rew_mean           | -224         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 47           |
|    time_elapsed          | 1428         |
|    total_timesteps       | 698368       |
| train/                   |              |
|    approx_kl             | 0.0078460295 |
|    clip_fraction         | 0.0919       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.43         |
|    cost_value_loss       | 16           |
|    cost_values           | 2.32         |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.459        |
|    lagrangian_multiplier | 0.00301      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.81         |
|    n_updates             | 3400         |
|    policy_gradient_loss  | -0.00396     |
|    std                   | 0.807        |
|    value_loss            | 8.13         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.27149212  |
| rollout/                 |              |
|    ep_len_mean           | 539          |
|    ep_rew_mean           | -217         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 48           |
|    time_elapsed          | 1457         |
|    total_timesteps       | 700416       |
| train/                   |              |
|    approx_kl             | 0.0062100417 |
|    clip_fraction         | 0.07         |
|    clip_range            | 0.2          |
|    cost_returns          | 4.36         |
|    cost_value_loss       | 8.31         |
|    cost_values           | 2.26         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.371        |
|    lagrangian_multiplier | 0.00501      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.75         |
|    n_updates             | 3410         |
|    policy_gradient_loss  | -0.0051      |
|    std                   | 0.804        |
|    value_loss            | 14.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.4738138  |
| rollout/                 |             |
|    ep_len_mean           | 530         |
|    ep_rew_mean           | -213        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 49          |
|    time_elapsed          | 1484        |
|    total_timesteps       | 702464      |
| train/                   |             |
|    approx_kl             | 0.008386229 |
|    clip_fraction         | 0.0621      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.45        |
|    cost_value_loss       | 8.52        |
|    cost_values           | 2.26        |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.238       |
|    lagrangian_multiplier | 0.00324     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.27        |
|    n_updates             | 3420        |
|    policy_gradient_loss  | -0.00431    |
|    std                   | 0.802       |
|    value_loss            | 18.2        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ent-coefficient-ppol/1vjpjg9h
------------------------------------
| avg_speed          | 8.02        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8.02        |
| reward             | -0.24689087 |
| rollout/           |             |
|    ep_len_mean     | 516         |
|    ep_rew_mean     | -207        |
| time/              |             |
|    fps             | 93          |
|    iterations      | 1           |
|    time_elapsed    | 21          |
|    total_timesteps | 704512      |
------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.2710424  |
| rollout/                 |             |
|    ep_len_mean           | 526         |
|    ep_rew_mean           | -210        |
| time/                    |             |
|    fps                   | 91          |
|    iterations            | 2           |
|    time_elapsed          | 44          |
|    total_timesteps       | 706560      |
| train/                   |             |
|    approx_kl             | 0.008234398 |
|    clip_fraction         | 0.136       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.19        |
|    cost_value_loss       | 14.3        |
|    cost_values           | 2.2         |
|    entropy               | -2.35       |
|    entropy_loss          | -2.35       |
|    explained_variance    | 0.404       |
|    lagrangian_multiplier | 0.00353     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.3         |
|    n_updates             | 3440        |
|    policy_gradient_loss  | -0.00485    |
|    std                   | 0.799       |
|    value_loss            | 20.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.4959183  |
| rollout/                 |             |
|    ep_len_mean           | 527         |
|    ep_rew_mean           | -210        |
| time/                    |             |
|    fps                   | 79          |
|    iterations            | 3           |
|    time_elapsed          | 76          |
|    total_timesteps       | 708608      |
| train/                   |             |
|    approx_kl             | 0.009064782 |
|    clip_fraction         | 0.145       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.94        |
|    cost_value_loss       | 12.1        |
|    cost_values           | 2.19        |
|    entropy               | -2.34       |
|    entropy_loss          | -2.35       |
|    explained_variance    | 0.523       |
|    lagrangian_multiplier | 0.00536     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.04        |
|    n_updates             | 3450        |
|    policy_gradient_loss  | -0.00553    |
|    std                   | 0.799       |
|    value_loss            | 10.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.8          |
| reward                   | -0.79237485  |
| rollout/                 |              |
|    ep_len_mean           | 515          |
|    ep_rew_mean           | -203         |
| time/                    |              |
|    fps                   | 73           |
|    iterations            | 4            |
|    time_elapsed          | 112          |
|    total_timesteps       | 710656       |
| train/                   |              |
|    approx_kl             | 0.0067267134 |
|    clip_fraction         | 0.109        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.68         |
|    cost_value_loss       | 15.3         |
|    cost_values           | 2.36         |
|    entropy               | -2.33        |
|    entropy_loss          | -2.34        |
|    explained_variance    | 0.121        |
|    lagrangian_multiplier | 0.00306      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.87         |
|    n_updates             | 3460         |
|    policy_gradient_loss  | -0.00468     |
|    std                   | 0.794        |
|    value_loss            | 7.97         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.2867608  |
| rollout/                 |             |
|    ep_len_mean           | 485         |
|    ep_rew_mean           | -188        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 5           |
|    time_elapsed          | 143         |
|    total_timesteps       | 712704      |
| train/                   |             |
|    approx_kl             | 0.007385877 |
|    clip_fraction         | 0.115       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.62        |
|    cost_value_loss       | 14.9        |
|    cost_values           | 2.38        |
|    entropy               | -2.32       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 0.288       |
|    lagrangian_multiplier | 0.00248     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.9         |
|    n_updates             | 3470        |
|    policy_gradient_loss  | -0.00712    |
|    std                   | 0.79        |
|    value_loss            | 18.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.15929517 |
| rollout/                 |             |
|    ep_len_mean           | 484         |
|    ep_rew_mean           | -187        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 6           |
|    time_elapsed          | 172         |
|    total_timesteps       | 714752      |
| train/                   |             |
|    approx_kl             | 0.007080655 |
|    clip_fraction         | 0.0652      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.54        |
|    cost_value_loss       | 9.25        |
|    cost_values           | 2.26        |
|    entropy               | -2.31       |
|    entropy_loss          | -2.32       |
|    explained_variance    | 0.34        |
|    lagrangian_multiplier | 0.00427     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.6         |
|    n_updates             | 3480        |
|    policy_gradient_loss  | -0.00427    |
|    std                   | 0.786       |
|    value_loss            | 22.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.35939583 |
| rollout/                 |             |
|    ep_len_mean           | 470         |
|    ep_rew_mean           | -182        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 7           |
|    time_elapsed          | 205         |
|    total_timesteps       | 716800      |
| train/                   |             |
|    approx_kl             | 0.008262196 |
|    clip_fraction         | 0.127       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.49        |
|    cost_value_loss       | 13          |
|    cost_values           | 2.31        |
|    entropy               | -2.3        |
|    entropy_loss          | -2.31       |
|    explained_variance    | 0.435       |
|    lagrangian_multiplier | 0.00696     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.86        |
|    n_updates             | 3490        |
|    policy_gradient_loss  | -0.00574    |
|    std                   | 0.783       |
|    value_loss            | 9.07        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.41753295 |
| rollout/                 |             |
|    ep_len_mean           | 452         |
|    ep_rew_mean           | -175        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 8           |
|    time_elapsed          | 232         |
|    total_timesteps       | 718848      |
| train/                   |             |
|    approx_kl             | 0.011139187 |
|    clip_fraction         | 0.159       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.48        |
|    cost_value_loss       | 10.8        |
|    cost_values           | 2.21        |
|    entropy               | -2.29       |
|    entropy_loss          | -2.3        |
|    explained_variance    | 0.451       |
|    lagrangian_multiplier | 0.0018      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.97        |
|    n_updates             | 3500        |
|    policy_gradient_loss  | -0.00596    |
|    std                   | 0.78        |
|    value_loss            | 21.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.48897934 |
| rollout/                 |             |
|    ep_len_mean           | 457         |
|    ep_rew_mean           | -177        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 9           |
|    time_elapsed          | 257         |
|    total_timesteps       | 720896      |
| train/                   |             |
|    approx_kl             | 0.012285428 |
|    clip_fraction         | 0.104       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.65        |
|    cost_value_loss       | 10.8        |
|    cost_values           | 2.15        |
|    entropy               | -2.29       |
|    entropy_loss          | -2.29       |
|    explained_variance    | 0.507       |
|    lagrangian_multiplier | 0.00315     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.98        |
|    n_updates             | 3510        |
|    policy_gradient_loss  | -0.00577    |
|    std                   | 0.779       |
|    value_loss            | 17.6        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.4489789 |
| rollout/                 |            |
|    ep_len_mean           | 464        |
|    ep_rew_mean           | -179       |
| time/                    |            |
|    fps                   | 69         |
|    iterations            | 10         |
|    time_elapsed          | 292        |
|    total_timesteps       | 722944     |
| train/                   |            |
|    approx_kl             | 0.01096358 |
|    clip_fraction         | 0.131      |
|    clip_range            | 0.2        |
|    cost_returns          | 5.27       |
|    cost_value_loss       | 13.4       |
|    cost_values           | 2.29       |
|    entropy               | -2.29      |
|    entropy_loss          | -2.29      |
|    explained_variance    | 0.135      |
|    lagrangian_multiplier | 0.00134    |
|    learning_rate         | 0.0003     |
|    loss                  | 8.86       |
|    n_updates             | 3520       |
|    policy_gradient_loss  | -0.00479   |
|    std                   | 0.78       |
|    value_loss            | 10.6       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.30073157 |
| rollout/                 |             |
|    ep_len_mean           | 458         |
|    ep_rew_mean           | -177        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 11          |
|    time_elapsed          | 326         |
|    total_timesteps       | 724992      |
| train/                   |             |
|    approx_kl             | 0.009988822 |
|    clip_fraction         | 0.0602      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.52        |
|    cost_value_loss       | 16.9        |
|    cost_values           | 2.31        |
|    entropy               | -2.28       |
|    entropy_loss          | -2.29       |
|    explained_variance    | 0.528       |
|    lagrangian_multiplier | 0.00581     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.94        |
|    n_updates             | 3530        |
|    policy_gradient_loss  | -0.00458    |
|    std                   | 0.778       |
|    value_loss            | 15.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.34837034 |
| rollout/                 |             |
|    ep_len_mean           | 455         |
|    ep_rew_mean           | -176        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 12          |
|    time_elapsed          | 361         |
|    total_timesteps       | 727040      |
| train/                   |             |
|    approx_kl             | 0.007708898 |
|    clip_fraction         | 0.0765      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.26        |
|    cost_value_loss       | 14.2        |
|    cost_values           | 2.32        |
|    entropy               | -2.28       |
|    entropy_loss          | -2.28       |
|    explained_variance    | 0.457       |
|    lagrangian_multiplier | 0.00287     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.58        |
|    n_updates             | 3540        |
|    policy_gradient_loss  | -0.00211    |
|    std                   | 0.777       |
|    value_loss            | 10.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.47817215 |
| rollout/                 |             |
|    ep_len_mean           | 424         |
|    ep_rew_mean           | -163        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 13          |
|    time_elapsed          | 392         |
|    total_timesteps       | 729088      |
| train/                   |             |
|    approx_kl             | 0.008647096 |
|    clip_fraction         | 0.116       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.96        |
|    cost_value_loss       | 17.2        |
|    cost_values           | 2.49        |
|    entropy               | -2.28       |
|    entropy_loss          | -2.28       |
|    explained_variance    | 0.207       |
|    lagrangian_multiplier | 0.00539     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.38        |
|    n_updates             | 3550        |
|    policy_gradient_loss  | -0.00374    |
|    std                   | 0.777       |
|    value_loss            | 8.33        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.20384046 |
| rollout/                 |             |
|    ep_len_mean           | 431         |
|    ep_rew_mean           | -166        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 14          |
|    time_elapsed          | 425         |
|    total_timesteps       | 731136      |
| train/                   |             |
|    approx_kl             | 0.01051391  |
|    clip_fraction         | 0.0764      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.72        |
|    cost_value_loss       | 18.1        |
|    cost_values           | 2.38        |
|    entropy               | -2.27       |
|    entropy_loss          | -2.28       |
|    explained_variance    | 0.483       |
|    lagrangian_multiplier | 0.00538     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.59        |
|    n_updates             | 3560        |
|    policy_gradient_loss  | -0.00305    |
|    std                   | 0.774       |
|    value_loss            | 19.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.4775192   |
| rollout/                 |              |
|    ep_len_mean           | 430          |
|    ep_rew_mean           | -165         |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 15           |
|    time_elapsed          | 457          |
|    total_timesteps       | 733184       |
| train/                   |              |
|    approx_kl             | 0.0073567606 |
|    clip_fraction         | 0.107        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.29         |
|    cost_value_loss       | 8.77         |
|    cost_values           | 2.22         |
|    entropy               | -2.26        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0.535        |
|    lagrangian_multiplier | 0.00235      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.41         |
|    n_updates             | 3570         |
|    policy_gradient_loss  | -0.00603     |
|    std                   | 0.77         |
|    value_loss            | 17.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.24932586 |
| rollout/                 |             |
|    ep_len_mean           | 425         |
|    ep_rew_mean           | -163        |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 16          |
|    time_elapsed          | 486         |
|    total_timesteps       | 735232      |
| train/                   |             |
|    approx_kl             | 0.008988593 |
|    clip_fraction         | 0.104       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.24        |
|    cost_value_loss       | 13.2        |
|    cost_values           | 2.31        |
|    entropy               | -2.25       |
|    entropy_loss          | -2.26       |
|    explained_variance    | 0.384       |
|    lagrangian_multiplier | 0.00692     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.36        |
|    n_updates             | 3580        |
|    policy_gradient_loss  | -0.00447    |
|    std                   | 0.768       |
|    value_loss            | 11.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.43606064 |
| rollout/                 |             |
|    ep_len_mean           | 428         |
|    ep_rew_mean           | -163        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 17          |
|    time_elapsed          | 511         |
|    total_timesteps       | 737280      |
| train/                   |             |
|    approx_kl             | 0.014083048 |
|    clip_fraction         | 0.152       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.17        |
|    cost_value_loss       | 13.5        |
|    cost_values           | 2.35        |
|    entropy               | -2.25       |
|    entropy_loss          | -2.25       |
|    explained_variance    | 0.549       |
|    lagrangian_multiplier | 0.00362     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.32        |
|    n_updates             | 3590        |
|    policy_gradient_loss  | -0.00403    |
|    std                   | 0.766       |
|    value_loss            | 13.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.2658867  |
| rollout/                 |             |
|    ep_len_mean           | 423         |
|    ep_rew_mean           | -160        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 18          |
|    time_elapsed          | 534         |
|    total_timesteps       | 739328      |
| train/                   |             |
|    approx_kl             | 0.008332027 |
|    clip_fraction         | 0.103       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.31        |
|    cost_value_loss       | 12.5        |
|    cost_values           | 2.47        |
|    entropy               | -2.24       |
|    entropy_loss          | -2.25       |
|    explained_variance    | 0.252       |
|    lagrangian_multiplier | 0.00283     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.57        |
|    n_updates             | 3600        |
|    policy_gradient_loss  | -0.00308    |
|    std                   | 0.765       |
|    value_loss            | 9.4         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.34566605 |
| rollout/                 |             |
|    ep_len_mean           | 422         |
|    ep_rew_mean           | -160        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 19          |
|    time_elapsed          | 560         |
|    total_timesteps       | 741376      |
| train/                   |             |
|    approx_kl             | 0.008739544 |
|    clip_fraction         | 0.0854      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.75        |
|    cost_value_loss       | 14.3        |
|    cost_values           | 2.53        |
|    entropy               | -2.24       |
|    entropy_loss          | -2.24       |
|    explained_variance    | 0.419       |
|    lagrangian_multiplier | 0.00401     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.1         |
|    n_updates             | 3610        |
|    policy_gradient_loss  | -0.00287    |
|    std                   | 0.764       |
|    value_loss            | 13.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -0.38917816 |
| rollout/                 |             |
|    ep_len_mean           | 409         |
|    ep_rew_mean           | -154        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 20          |
|    time_elapsed          | 593         |
|    total_timesteps       | 743424      |
| train/                   |             |
|    approx_kl             | 0.01906152  |
|    clip_fraction         | 0.162       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.18        |
|    cost_value_loss       | 10.6        |
|    cost_values           | 2.55        |
|    entropy               | -2.23       |
|    entropy_loss          | -2.24       |
|    explained_variance    | 0.392       |
|    lagrangian_multiplier | 0.00272     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.25        |
|    n_updates             | 3620        |
|    policy_gradient_loss  | -0.00468    |
|    std                   | 0.761       |
|    value_loss            | 7.56        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.5660669  |
| rollout/                 |             |
|    ep_len_mean           | 418         |
|    ep_rew_mean           | -157        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 21          |
|    time_elapsed          | 628         |
|    total_timesteps       | 745472      |
| train/                   |             |
|    approx_kl             | 0.007788982 |
|    clip_fraction         | 0.113       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.84        |
|    cost_value_loss       | 18.2        |
|    cost_values           | 2.45        |
|    entropy               | -2.23       |
|    entropy_loss          | -2.23       |
|    explained_variance    | 0.386       |
|    lagrangian_multiplier | 0.00563     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.48        |
|    n_updates             | 3630        |
|    policy_gradient_loss  | -0.00265    |
|    std                   | 0.759       |
|    value_loss            | 23.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.39240158 |
| rollout/                 |             |
|    ep_len_mean           | 421         |
|    ep_rew_mean           | -158        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 22          |
|    time_elapsed          | 660         |
|    total_timesteps       | 747520      |
| train/                   |             |
|    approx_kl             | 0.017634157 |
|    clip_fraction         | 0.11        |
|    clip_range            | 0.2         |
|    cost_returns          | 6.03        |
|    cost_value_loss       | 17.3        |
|    cost_values           | 2.51        |
|    entropy               | -2.23       |
|    entropy_loss          | -2.23       |
|    explained_variance    | 0.386       |
|    lagrangian_multiplier | 0.0043      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.39        |
|    n_updates             | 3640        |
|    policy_gradient_loss  | -0.00684    |
|    std                   | 0.762       |
|    value_loss            | 11.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.27310777 |
| rollout/                 |             |
|    ep_len_mean           | 405         |
|    ep_rew_mean           | -153        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 23          |
|    time_elapsed          | 687         |
|    total_timesteps       | 749568      |
| train/                   |             |
|    approx_kl             | 0.029307885 |
|    clip_fraction         | 0.161       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.69        |
|    cost_value_loss       | 8.58        |
|    cost_values           | 2.59        |
|    entropy               | -2.23       |
|    entropy_loss          | -2.23       |
|    explained_variance    | 0.318       |
|    lagrangian_multiplier | 0.00325     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.11        |
|    n_updates             | 3650        |
|    policy_gradient_loss  | -0.00374    |
|    std                   | 0.761       |
|    value_loss            | 11.9        |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.6        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.6        |
| reward                   | -0.6588447 |
| rollout/                 |            |
|    ep_len_mean           | 398        |
|    ep_rew_mean           | -150       |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 24         |
|    time_elapsed          | 721        |
|    total_timesteps       | 751616     |
| train/                   |            |
|    approx_kl             | 0.01096342 |
|    clip_fraction         | 0.0906     |
|    clip_range            | 0.2        |
|    cost_returns          | 5.45       |
|    cost_value_loss       | 12.6       |
|    cost_values           | 2.6        |
|    entropy               | -2.22      |
|    entropy_loss          | -2.23      |
|    explained_variance    | 0.345      |
|    lagrangian_multiplier | 0.0086     |
|    learning_rate         | 0.0003     |
|    loss                  | 4.19       |
|    n_updates             | 3660       |
|    policy_gradient_loss  | -0.0026    |
|    std                   | 0.756      |
|    value_loss            | 14         |
-----------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.29128954 |
| rollout/                 |             |
|    ep_len_mean           | 403         |
|    ep_rew_mean           | -151        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 25          |
|    time_elapsed          | 748         |
|    total_timesteps       | 753664      |
| train/                   |             |
|    approx_kl             | 0.006131938 |
|    clip_fraction         | 0.0919      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.49        |
|    cost_value_loss       | 13.9        |
|    cost_values           | 2.53        |
|    entropy               | -2.21       |
|    entropy_loss          | -2.22       |
|    explained_variance    | 0.458       |
|    lagrangian_multiplier | 0.00357     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.24        |
|    n_updates             | 3670        |
|    policy_gradient_loss  | -0.00537    |
|    std                   | 0.752       |
|    value_loss            | 17.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.7048454  |
| rollout/                 |             |
|    ep_len_mean           | 398         |
|    ep_rew_mean           | -149        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 26          |
|    time_elapsed          | 771         |
|    total_timesteps       | 755712      |
| train/                   |             |
|    approx_kl             | 0.009390016 |
|    clip_fraction         | 0.105       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.05        |
|    cost_value_loss       | 12.2        |
|    cost_values           | 2.52        |
|    entropy               | -2.2        |
|    entropy_loss          | -2.21       |
|    explained_variance    | 0.444       |
|    lagrangian_multiplier | 0.00383     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.26        |
|    n_updates             | 3680        |
|    policy_gradient_loss  | -0.00584    |
|    std                   | 0.749       |
|    value_loss            | 14.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.3070051   |
| rollout/                 |              |
|    ep_len_mean           | 400          |
|    ep_rew_mean           | -149         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 27           |
|    time_elapsed          | 795          |
|    total_timesteps       | 757760       |
| train/                   |              |
|    approx_kl             | 0.0079162475 |
|    clip_fraction         | 0.108        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.21         |
|    cost_value_loss       | 11.9         |
|    cost_values           | 2.49         |
|    entropy               | -2.2         |
|    entropy_loss          | -2.2         |
|    explained_variance    | 0.438        |
|    lagrangian_multiplier | 0.00439      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.52         |
|    n_updates             | 3690         |
|    policy_gradient_loss  | -0.00133     |
|    std                   | 0.748        |
|    value_loss            | 18.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.39        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.39        |
| reward                   | -0.66424686 |
| rollout/                 |             |
|    ep_len_mean           | 414         |
|    ep_rew_mean           | -153        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 28          |
|    time_elapsed          | 827         |
|    total_timesteps       | 759808      |
| train/                   |             |
|    approx_kl             | 0.018078486 |
|    clip_fraction         | 0.102       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.37        |
|    cost_value_loss       | 13.1        |
|    cost_values           | 2.58        |
|    entropy               | -2.2        |
|    entropy_loss          | -2.2        |
|    explained_variance    | 0.449       |
|    lagrangian_multiplier | 0.00732     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.19        |
|    n_updates             | 3700        |
|    policy_gradient_loss  | -0.0035     |
|    std                   | 0.749       |
|    value_loss            | 7.9         |
------------------------------------------
------------------------------------------
| avg_speed                | 4.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.8         |
| reward                   | -0.49969202 |
| rollout/                 |             |
|    ep_len_mean           | 400         |
|    ep_rew_mean           | -148        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 29          |
|    time_elapsed          | 866         |
|    total_timesteps       | 761856      |
| train/                   |             |
|    approx_kl             | 0.007529209 |
|    clip_fraction         | 0.0821      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.71        |
|    cost_value_loss       | 23.5        |
|    cost_values           | 2.53        |
|    entropy               | -2.19       |
|    entropy_loss          | -2.19       |
|    explained_variance    | 0.508       |
|    lagrangian_multiplier | 0.00277     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.04        |
|    n_updates             | 3710        |
|    policy_gradient_loss  | -0.000197   |
|    std                   | 0.747       |
|    value_loss            | 14.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.18508701 |
| rollout/                 |             |
|    ep_len_mean           | 397         |
|    ep_rew_mean           | -146        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 30          |
|    time_elapsed          | 900         |
|    total_timesteps       | 763904      |
| train/                   |             |
|    approx_kl             | 0.011927424 |
|    clip_fraction         | 0.161       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.34        |
|    cost_value_loss       | 12.7        |
|    cost_values           | 2.5         |
|    entropy               | -2.19       |
|    entropy_loss          | -2.19       |
|    explained_variance    | 0.522       |
|    lagrangian_multiplier | 0.00261     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.73        |
|    n_updates             | 3720        |
|    policy_gradient_loss  | -0.00635    |
|    std                   | 0.747       |
|    value_loss            | 13.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.44052634 |
| rollout/                 |             |
|    ep_len_mean           | 379         |
|    ep_rew_mean           | -139        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 31          |
|    time_elapsed          | 929         |
|    total_timesteps       | 765952      |
| train/                   |             |
|    approx_kl             | 0.008706104 |
|    clip_fraction         | 0.109       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.56        |
|    cost_value_loss       | 8.64        |
|    cost_values           | 2.53        |
|    entropy               | -2.19       |
|    entropy_loss          | -2.19       |
|    explained_variance    | 0.487       |
|    lagrangian_multiplier | 0.000859    |
|    learning_rate         | 0.0003      |
|    loss                  | 9.98        |
|    n_updates             | 3730        |
|    policy_gradient_loss  | -0.00449    |
|    std                   | 0.745       |
|    value_loss            | 13.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2220115  |
| rollout/                 |             |
|    ep_len_mean           | 379         |
|    ep_rew_mean           | -138        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 32          |
|    time_elapsed          | 956         |
|    total_timesteps       | 768000      |
| train/                   |             |
|    approx_kl             | 0.009932753 |
|    clip_fraction         | 0.101       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.01        |
|    cost_value_loss       | 16.5        |
|    cost_values           | 2.57        |
|    entropy               | -2.18       |
|    entropy_loss          | -2.18       |
|    explained_variance    | 0.499       |
|    lagrangian_multiplier | 0.00537     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.28        |
|    n_updates             | 3740        |
|    policy_gradient_loss  | -0.00461    |
|    std                   | 0.742       |
|    value_loss            | 15.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.47302097  |
| rollout/                 |              |
|    ep_len_mean           | 375          |
|    ep_rew_mean           | -136         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 33           |
|    time_elapsed          | 987          |
|    total_timesteps       | 770048       |
| train/                   |              |
|    approx_kl             | 0.0130393505 |
|    clip_fraction         | 0.112        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.28         |
|    cost_value_loss       | 11.9         |
|    cost_values           | 2.68         |
|    entropy               | -2.17        |
|    entropy_loss          | -2.18        |
|    explained_variance    | 0.234        |
|    lagrangian_multiplier | 0.00527      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.41         |
|    n_updates             | 3750         |
|    policy_gradient_loss  | -0.00687     |
|    std                   | 0.74         |
|    value_loss            | 14.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.88        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.88        |
| reward                   | -0.48147017 |
| rollout/                 |             |
|    ep_len_mean           | 369         |
|    ep_rew_mean           | -134        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 34          |
|    time_elapsed          | 1017        |
|    total_timesteps       | 772096      |
| train/                   |             |
|    approx_kl             | 0.009537801 |
|    clip_fraction         | 0.0928      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.65        |
|    cost_value_loss       | 13          |
|    cost_values           | 2.63        |
|    entropy               | -2.17       |
|    entropy_loss          | -2.17       |
|    explained_variance    | 0.421       |
|    lagrangian_multiplier | 0.0058      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.23        |
|    n_updates             | 3760        |
|    policy_gradient_loss  | -0.00345    |
|    std                   | 0.739       |
|    value_loss            | 15.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.27962235 |
| rollout/                 |             |
|    ep_len_mean           | 355         |
|    ep_rew_mean           | -130        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 35          |
|    time_elapsed          | 1047        |
|    total_timesteps       | 774144      |
| train/                   |             |
|    approx_kl             | 0.00841137  |
|    clip_fraction         | 0.0588      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.17        |
|    cost_value_loss       | 19.4        |
|    cost_values           | 2.64        |
|    entropy               | -2.15       |
|    entropy_loss          | -2.16       |
|    explained_variance    | 0.469       |
|    lagrangian_multiplier | 0.00576     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.9         |
|    n_updates             | 3770        |
|    policy_gradient_loss  | -0.00438    |
|    std                   | 0.735       |
|    value_loss            | 12.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.2946789   |
| rollout/                 |              |
|    ep_len_mean           | 365          |
|    ep_rew_mean           | -133         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 36           |
|    time_elapsed          | 1078         |
|    total_timesteps       | 776192       |
| train/                   |              |
|    approx_kl             | 0.0056052646 |
|    clip_fraction         | 0.056        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.71         |
|    cost_value_loss       | 16.1         |
|    cost_values           | 2.65         |
|    entropy               | -2.14        |
|    entropy_loss          | -2.15        |
|    explained_variance    | 0.419        |
|    lagrangian_multiplier | 0.00455      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.62         |
|    n_updates             | 3780         |
|    policy_gradient_loss  | -0.00478     |
|    std                   | 0.73         |
|    value_loss            | 12.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.37749463 |
| rollout/                 |             |
|    ep_len_mean           | 357         |
|    ep_rew_mean           | -130        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 37          |
|    time_elapsed          | 1107        |
|    total_timesteps       | 778240      |
| train/                   |             |
|    approx_kl             | 0.012114303 |
|    clip_fraction         | 0.13        |
|    clip_range            | 0.2         |
|    cost_returns          | 5.6         |
|    cost_value_loss       | 14.2        |
|    cost_values           | 2.61        |
|    entropy               | -2.14       |
|    entropy_loss          | -2.14       |
|    explained_variance    | 0.594       |
|    lagrangian_multiplier | 0.00391     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.51        |
|    n_updates             | 3790        |
|    policy_gradient_loss  | -0.00641    |
|    std                   | 0.729       |
|    value_loss            | 12.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.93         |
| reward                   | -0.7934485   |
| rollout/                 |              |
|    ep_len_mean           | 365          |
|    ep_rew_mean           | -132         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 38           |
|    time_elapsed          | 1138         |
|    total_timesteps       | 780288       |
| train/                   |              |
|    approx_kl             | 0.0049892347 |
|    clip_fraction         | 0.0754       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.59         |
|    cost_value_loss       | 14.1         |
|    cost_values           | 2.57         |
|    entropy               | -2.13        |
|    entropy_loss          | -2.13        |
|    explained_variance    | 0.367        |
|    lagrangian_multiplier | 0.00385      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.69         |
|    n_updates             | 3800         |
|    policy_gradient_loss  | -0.00375     |
|    std                   | 0.727        |
|    value_loss            | 16           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.23969941 |
| rollout/                 |             |
|    ep_len_mean           | 356         |
|    ep_rew_mean           | -129        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 39          |
|    time_elapsed          | 1168        |
|    total_timesteps       | 782336      |
| train/                   |             |
|    approx_kl             | 0.009797964 |
|    clip_fraction         | 0.13        |
|    clip_range            | 0.2         |
|    cost_returns          | 5.59        |
|    cost_value_loss       | 12.9        |
|    cost_values           | 2.61        |
|    entropy               | -2.12       |
|    entropy_loss          | -2.12       |
|    explained_variance    | 0.303       |
|    lagrangian_multiplier | 0.00383     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.1         |
|    n_updates             | 3810        |
|    policy_gradient_loss  | -0.00819    |
|    std                   | 0.722       |
|    value_loss            | 10.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.77        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.77        |
| reward                   | -0.24301876 |
| rollout/                 |             |
|    ep_len_mean           | 349         |
|    ep_rew_mean           | -126        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 40          |
|    time_elapsed          | 1202        |
|    total_timesteps       | 784384      |
| train/                   |             |
|    approx_kl             | 0.010319204 |
|    clip_fraction         | 0.0893      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.01        |
|    cost_value_loss       | 16.2        |
|    cost_values           | 2.62        |
|    entropy               | -2.1        |
|    entropy_loss          | -2.11       |
|    explained_variance    | 0.431       |
|    lagrangian_multiplier | 0.00166     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.69        |
|    n_updates             | 3820        |
|    policy_gradient_loss  | -0.00534    |
|    std                   | 0.716       |
|    value_loss            | 17.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.13353322 |
| rollout/                 |             |
|    ep_len_mean           | 356         |
|    ep_rew_mean           | -129        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 41          |
|    time_elapsed          | 1233        |
|    total_timesteps       | 786432      |
| train/                   |             |
|    approx_kl             | 0.011651311 |
|    clip_fraction         | 0.124       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.69        |
|    cost_value_loss       | 14.6        |
|    cost_values           | 2.62        |
|    entropy               | -2.1        |
|    entropy_loss          | -2.1        |
|    explained_variance    | 0.549       |
|    lagrangian_multiplier | 0.00348     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.48        |
|    n_updates             | 3830        |
|    policy_gradient_loss  | -0.00576    |
|    std                   | 0.717       |
|    value_loss            | 12.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.21313538 |
| rollout/                 |             |
|    ep_len_mean           | 343         |
|    ep_rew_mean           | -124        |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 42          |
|    time_elapsed          | 1263        |
|    total_timesteps       | 788480      |
| train/                   |             |
|    approx_kl             | 0.013221279 |
|    clip_fraction         | 0.0955      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.33        |
|    cost_value_loss       | 17.9        |
|    cost_values           | 2.67        |
|    entropy               | -2.1        |
|    entropy_loss          | -2.1        |
|    explained_variance    | 0.537       |
|    lagrangian_multiplier | 0.00585     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.89        |
|    n_updates             | 3840        |
|    policy_gradient_loss  | -0.00434    |
|    std                   | 0.713       |
|    value_loss            | 12.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.47080952  |
| rollout/                 |              |
|    ep_len_mean           | 329          |
|    ep_rew_mean           | -119         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 43           |
|    time_elapsed          | 1291         |
|    total_timesteps       | 790528       |
| train/                   |              |
|    approx_kl             | 0.0049945572 |
|    clip_fraction         | 0.0583       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.36         |
|    cost_value_loss       | 11           |
|    cost_values           | 2.6          |
|    entropy               | -2.08        |
|    entropy_loss          | -2.09        |
|    explained_variance    | 0.56         |
|    lagrangian_multiplier | 0.00575      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.66         |
|    n_updates             | 3850         |
|    policy_gradient_loss  | -0.00561     |
|    std                   | 0.71         |
|    value_loss            | 20.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.4          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.4          |
| reward                   | -0.71321315  |
| rollout/                 |              |
|    ep_len_mean           | 321          |
|    ep_rew_mean           | -116         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 44           |
|    time_elapsed          | 1314         |
|    total_timesteps       | 792576       |
| train/                   |              |
|    approx_kl             | 0.0106311655 |
|    clip_fraction         | 0.104        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.73         |
|    cost_value_loss       | 14.9         |
|    cost_values           | 2.68         |
|    entropy               | -2.08        |
|    entropy_loss          | -2.08        |
|    explained_variance    | 0.356        |
|    lagrangian_multiplier | 0.00345      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.56         |
|    n_updates             | 3860         |
|    policy_gradient_loss  | -0.00503     |
|    std                   | 0.708        |
|    value_loss            | 16.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.28465968  |
| rollout/                 |              |
|    ep_len_mean           | 309          |
|    ep_rew_mean           | -112         |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 45           |
|    time_elapsed          | 1337         |
|    total_timesteps       | 794624       |
| train/                   |              |
|    approx_kl             | 0.0057565183 |
|    clip_fraction         | 0.0671       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.89         |
|    cost_value_loss       | 15.1         |
|    cost_values           | 2.71         |
|    entropy               | -2.07        |
|    entropy_loss          | -2.08        |
|    explained_variance    | 0.418        |
|    lagrangian_multiplier | 0.00429      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.2          |
|    n_updates             | 3870         |
|    policy_gradient_loss  | -0.0029      |
|    std                   | 0.705        |
|    value_loss            | 18.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.24199481 |
| rollout/                 |             |
|    ep_len_mean           | 300         |
|    ep_rew_mean           | -109        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 46          |
|    time_elapsed          | 1361        |
|    total_timesteps       | 796672      |
| train/                   |             |
|    approx_kl             | 0.008651246 |
|    clip_fraction         | 0.0924      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.8         |
|    cost_value_loss       | 13          |
|    cost_values           | 2.78        |
|    entropy               | -2.07       |
|    entropy_loss          | -2.07       |
|    explained_variance    | 0.412       |
|    lagrangian_multiplier | 0.0042      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.7         |
|    n_updates             | 3880        |
|    policy_gradient_loss  | -0.00367    |
|    std                   | 0.704       |
|    value_loss            | 15          |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.43520343 |
| rollout/                 |             |
|    ep_len_mean           | 297         |
|    ep_rew_mean           | -109        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 47          |
|    time_elapsed          | 1385        |
|    total_timesteps       | 798720      |
| train/                   |             |
|    approx_kl             | 0.00606957  |
|    clip_fraction         | 0.0756      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.6         |
|    cost_value_loss       | 13.8        |
|    cost_values           | 2.76        |
|    entropy               | -2.06       |
|    entropy_loss          | -2.07       |
|    explained_variance    | 0.405       |
|    lagrangian_multiplier | 0.00494     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.47        |
|    n_updates             | 3890        |
|    policy_gradient_loss  | -0.00342    |
|    std                   | 0.703       |
|    value_loss            | 19.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.39601403 |
| rollout/                 |             |
|    ep_len_mean           | 310         |
|    ep_rew_mean           | -113        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 48          |
|    time_elapsed          | 1410        |
|    total_timesteps       | 800768      |
| train/                   |             |
|    approx_kl             | 0.0083191   |
|    clip_fraction         | 0.0872      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.69        |
|    cost_value_loss       | 19.9        |
|    cost_values           | 2.81        |
|    entropy               | -2.06       |
|    entropy_loss          | -2.06       |
|    explained_variance    | 0.455       |
|    lagrangian_multiplier | 0.00622     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.22        |
|    n_updates             | 3900        |
|    policy_gradient_loss  | -0.00414    |
|    std                   | 0.703       |
|    value_loss            | 10.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.40468633 |
| rollout/                 |             |
|    ep_len_mean           | 319         |
|    ep_rew_mean           | -117        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 49          |
|    time_elapsed          | 1434        |
|    total_timesteps       | 802816      |
| train/                   |             |
|    approx_kl             | 0.009946512 |
|    clip_fraction         | 0.119       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.01        |
|    cost_value_loss       | 13.3        |
|    cost_values           | 2.84        |
|    entropy               | -2.06       |
|    entropy_loss          | -2.06       |
|    explained_variance    | 0.432       |
|    lagrangian_multiplier | 0.00419     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.95        |
|    n_updates             | 3910        |
|    policy_gradient_loss  | -0.00321    |
|    std                   | 0.699       |
|    value_loss            | 8.09        |
------------------------------------------
------------------------------------
| avg_speed          | 8           |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8           |
| reward             | -0.25823188 |
| rollout/           |             |
|    ep_len_mean     | 305         |
|    ep_rew_mean     | -111        |
| time/              |             |
|    fps             | 88          |
|    iterations      | 1           |
|    time_elapsed    | 23          |
|    total_timesteps | 804864      |
------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.26768178 |
| rollout/                 |             |
|    ep_len_mean           | 303         |
|    ep_rew_mean           | -110        |
| time/                    |             |
|    fps                   | 85          |
|    iterations            | 2           |
|    time_elapsed          | 47          |
|    total_timesteps       | 806912      |
| train/                   |             |
|    approx_kl             | 0.011716471 |
|    clip_fraction         | 0.0833      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.05        |
|    cost_value_loss       | 13.8        |
|    cost_values           | 2.84        |
|    entropy               | -2.04       |
|    entropy_loss          | -2.05       |
|    explained_variance    | 0.326       |
|    lagrangian_multiplier | 0.00415     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.86        |
|    n_updates             | 3930        |
|    policy_gradient_loss  | -0.00404    |
|    std                   | 0.696       |
|    value_loss            | 16          |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.31289446 |
| rollout/                 |             |
|    ep_len_mean           | 286         |
|    ep_rew_mean           | -104        |
| time/                    |             |
|    fps                   | 84          |
|    iterations            | 3           |
|    time_elapsed          | 72          |
|    total_timesteps       | 808960      |
| train/                   |             |
|    approx_kl             | 0.011426429 |
|    clip_fraction         | 0.13        |
|    clip_range            | 0.2         |
|    cost_returns          | 6.55        |
|    cost_value_loss       | 19.6        |
|    cost_values           | 2.82        |
|    entropy               | -2.03       |
|    entropy_loss          | -2.04       |
|    explained_variance    | 0.457       |
|    lagrangian_multiplier | 0.00564     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.37        |
|    n_updates             | 3940        |
|    policy_gradient_loss  | -0.00145    |
|    std                   | 0.692       |
|    value_loss            | 16.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.3283279  |
| rollout/                 |             |
|    ep_len_mean           | 293         |
|    ep_rew_mean           | -106        |
| time/                    |             |
|    fps                   | 84          |
|    iterations            | 4           |
|    time_elapsed          | 96          |
|    total_timesteps       | 811008      |
| train/                   |             |
|    approx_kl             | 0.008554711 |
|    clip_fraction         | 0.0801      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.07        |
|    cost_value_loss       | 14.6        |
|    cost_values           | 2.83        |
|    entropy               | -2.03       |
|    entropy_loss          | -2.03       |
|    explained_variance    | 0.424       |
|    lagrangian_multiplier | 0.00741     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.58        |
|    n_updates             | 3950        |
|    policy_gradient_loss  | -0.00478    |
|    std                   | 0.691       |
|    value_loss            | 20.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -0.39130133  |
| rollout/                 |              |
|    ep_len_mean           | 298          |
|    ep_rew_mean           | -107         |
| time/                    |              |
|    fps                   | 84           |
|    iterations            | 5            |
|    time_elapsed          | 120          |
|    total_timesteps       | 813056       |
| train/                   |              |
|    approx_kl             | 0.0065605175 |
|    clip_fraction         | 0.051        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.04         |
|    cost_value_loss       | 13.6         |
|    cost_values           | 2.88         |
|    entropy               | -2.02        |
|    entropy_loss          | -2.03        |
|    explained_variance    | 0.248        |
|    lagrangian_multiplier | 0.00375      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.27         |
|    n_updates             | 3960         |
|    policy_gradient_loss  | -0.00219     |
|    std                   | 0.686        |
|    value_loss            | 7.17         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.33469206 |
| rollout/                 |             |
|    ep_len_mean           | 280         |
|    ep_rew_mean           | -101        |
| time/                    |             |
|    fps                   | 84          |
|    iterations            | 6           |
|    time_elapsed          | 145         |
|    total_timesteps       | 815104      |
| train/                   |             |
|    approx_kl             | 0.009447674 |
|    clip_fraction         | 0.128       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.4         |
|    cost_value_loss       | 15.1        |
|    cost_values           | 2.91        |
|    entropy               | -2.02       |
|    entropy_loss          | -2.01       |
|    explained_variance    | 0.444       |
|    lagrangian_multiplier | 0.00306     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.58        |
|    n_updates             | 3970        |
|    policy_gradient_loss  | -0.00466    |
|    std                   | 0.687       |
|    value_loss            | 9.05        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.36450166 |
| rollout/                 |             |
|    ep_len_mean           | 279         |
|    ep_rew_mean           | -101        |
| time/                    |             |
|    fps                   | 84          |
|    iterations            | 7           |
|    time_elapsed          | 170         |
|    total_timesteps       | 817152      |
| train/                   |             |
|    approx_kl             | 0.011707959 |
|    clip_fraction         | 0.114       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.78        |
|    cost_value_loss       | 12.9        |
|    cost_values           | 2.86        |
|    entropy               | -2.01       |
|    entropy_loss          | -2.02       |
|    explained_variance    | 0.386       |
|    lagrangian_multiplier | 0.00263     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.73        |
|    n_updates             | 3980        |
|    policy_gradient_loss  | -0.00315    |
|    std                   | 0.687       |
|    value_loss            | 18.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.33864263  |
| rollout/                 |              |
|    ep_len_mean           | 289          |
|    ep_rew_mean           | -104         |
| time/                    |              |
|    fps                   | 84           |
|    iterations            | 8            |
|    time_elapsed          | 194          |
|    total_timesteps       | 819200       |
| train/                   |              |
|    approx_kl             | 0.0075655608 |
|    clip_fraction         | 0.0715       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.74         |
|    cost_value_loss       | 12.4         |
|    cost_values           | 2.86         |
|    entropy               | -2.01        |
|    entropy_loss          | -2.01        |
|    explained_variance    | 0.442        |
|    lagrangian_multiplier | 0.0028       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.66         |
|    n_updates             | 3990         |
|    policy_gradient_loss  | -0.00197     |
|    std                   | 0.686        |
|    value_loss            | 20.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.35642466 |
| rollout/                 |             |
|    ep_len_mean           | 286         |
|    ep_rew_mean           | -103        |
| time/                    |             |
|    fps                   | 82          |
|    iterations            | 9           |
|    time_elapsed          | 223         |
|    total_timesteps       | 821248      |
| train/                   |             |
|    approx_kl             | 0.004332795 |
|    clip_fraction         | 0.0505      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.56        |
|    cost_value_loss       | 11.8        |
|    cost_values           | 2.85        |
|    entropy               | -2.01       |
|    entropy_loss          | -2.01       |
|    explained_variance    | 0.367       |
|    lagrangian_multiplier | 0.00419     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.49        |
|    n_updates             | 4000        |
|    policy_gradient_loss  | -0.00236    |
|    std                   | 0.685       |
|    value_loss            | 12.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.06        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.06        |
| reward                   | -0.24908216 |
| rollout/                 |             |
|    ep_len_mean           | 285         |
|    ep_rew_mean           | -103        |
| time/                    |             |
|    fps                   | 82          |
|    iterations            | 10          |
|    time_elapsed          | 248         |
|    total_timesteps       | 823296      |
| train/                   |             |
|    approx_kl             | 0.007081068 |
|    clip_fraction         | 0.072       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.6         |
|    cost_value_loss       | 12.8        |
|    cost_values           | 2.86        |
|    entropy               | -2.01       |
|    entropy_loss          | -2.01       |
|    explained_variance    | 0.499       |
|    lagrangian_multiplier | 0.00615     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.58        |
|    n_updates             | 4010        |
|    policy_gradient_loss  | -0.00259    |
|    std                   | 0.685       |
|    value_loss            | 15.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.33065033 |
| rollout/                 |             |
|    ep_len_mean           | 284         |
|    ep_rew_mean           | -102        |
| time/                    |             |
|    fps                   | 82          |
|    iterations            | 11          |
|    time_elapsed          | 271         |
|    total_timesteps       | 825344      |
| train/                   |             |
|    approx_kl             | 0.009879317 |
|    clip_fraction         | 0.0925      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.32        |
|    cost_value_loss       | 11          |
|    cost_values           | 2.86        |
|    entropy               | -2          |
|    entropy_loss          | -2.01       |
|    explained_variance    | 0.435       |
|    lagrangian_multiplier | 0.00182     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.88        |
|    n_updates             | 4020        |
|    policy_gradient_loss  | -0.00446    |
|    std                   | 0.684       |
|    value_loss            | 18.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.22205587  |
| rollout/                 |              |
|    ep_len_mean           | 266          |
|    ep_rew_mean           | -95.7        |
| time/                    |              |
|    fps                   | 82           |
|    iterations            | 12           |
|    time_elapsed          | 296          |
|    total_timesteps       | 827392       |
| train/                   |              |
|    approx_kl             | 0.0070733395 |
|    clip_fraction         | 0.0804       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.91         |
|    cost_value_loss       | 13.9         |
|    cost_values           | 2.89         |
|    entropy               | -1.99        |
|    entropy_loss          | -2           |
|    explained_variance    | 0.446        |
|    lagrangian_multiplier | 0.00492      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.24         |
|    n_updates             | 4030         |
|    policy_gradient_loss  | -0.00448     |
|    std                   | 0.679        |
|    value_loss            | 17.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.33350623  |
| rollout/                 |              |
|    ep_len_mean           | 245          |
|    ep_rew_mean           | -88.5        |
| time/                    |              |
|    fps                   | 80           |
|    iterations            | 13           |
|    time_elapsed          | 329          |
|    total_timesteps       | 829440       |
| train/                   |              |
|    approx_kl             | 0.0115778465 |
|    clip_fraction         | 0.0957       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.88         |
|    cost_value_loss       | 13.3         |
|    cost_values           | 2.91         |
|    entropy               | -1.98        |
|    entropy_loss          | -1.99        |
|    explained_variance    | 0.411        |
|    lagrangian_multiplier | 0.00342      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.11         |
|    n_updates             | 4040         |
|    policy_gradient_loss  | -0.00327     |
|    std                   | 0.675        |
|    value_loss            | 14.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.29        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.29        |
| reward                   | -0.7146606  |
| rollout/                 |             |
|    ep_len_mean           | 243         |
|    ep_rew_mean           | -87.8       |
| time/                    |             |
|    fps                   | 79          |
|    iterations            | 14          |
|    time_elapsed          | 362         |
|    total_timesteps       | 831488      |
| train/                   |             |
|    approx_kl             | 0.007979933 |
|    clip_fraction         | 0.102       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.49        |
|    cost_value_loss       | 11.8        |
|    cost_values           | 2.86        |
|    entropy               | -1.97       |
|    entropy_loss          | -1.97       |
|    explained_variance    | 0.516       |
|    lagrangian_multiplier | 0.00282     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.88        |
|    n_updates             | 4050        |
|    policy_gradient_loss  | -0.00547    |
|    std                   | 0.67        |
|    value_loss            | 21          |
------------------------------------------
-------------------------------------------
| avg_speed                | 4            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4            |
| reward                   | -0.745467    |
| rollout/                 |              |
|    ep_len_mean           | 251          |
|    ep_rew_mean           | -90.1        |
| time/                    |              |
|    fps                   | 76           |
|    iterations            | 15           |
|    time_elapsed          | 401          |
|    total_timesteps       | 833536       |
| train/                   |              |
|    approx_kl             | 0.0064462433 |
|    clip_fraction         | 0.0736       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.47         |
|    cost_value_loss       | 13           |
|    cost_values           | 2.87         |
|    entropy               | -1.95        |
|    entropy_loss          | -1.96        |
|    explained_variance    | 0.451        |
|    lagrangian_multiplier | 0.00423      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.3          |
|    n_updates             | 4060         |
|    policy_gradient_loss  | -0.00407     |
|    std                   | 0.667        |
|    value_loss            | 11.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.28399363  |
| rollout/                 |              |
|    ep_len_mean           | 236          |
|    ep_rew_mean           | -85.9        |
| time/                    |              |
|    fps                   | 75           |
|    iterations            | 16           |
|    time_elapsed          | 435          |
|    total_timesteps       | 835584       |
| train/                   |              |
|    approx_kl             | 0.0064245826 |
|    clip_fraction         | 0.0874       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.74         |
|    cost_value_loss       | 13.4         |
|    cost_values           | 2.78         |
|    entropy               | -1.96        |
|    entropy_loss          | -1.95        |
|    explained_variance    | 0.54         |
|    lagrangian_multiplier | 0.00497      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.95         |
|    n_updates             | 4070         |
|    policy_gradient_loss  | -0.00462     |
|    std                   | 0.668        |
|    value_loss            | 13.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.293775   |
| rollout/                 |             |
|    ep_len_mean           | 232         |
|    ep_rew_mean           | -84.6       |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 17          |
|    time_elapsed          | 471         |
|    total_timesteps       | 837632      |
| train/                   |             |
|    approx_kl             | 0.008535003 |
|    clip_fraction         | 0.0747      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.9         |
|    cost_value_loss       | 13          |
|    cost_values           | 2.84        |
|    entropy               | -1.96       |
|    entropy_loss          | -1.96       |
|    explained_variance    | 0.501       |
|    lagrangian_multiplier | 0.00479     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.18        |
|    n_updates             | 4080        |
|    policy_gradient_loss  | -0.00254    |
|    std                   | 0.668       |
|    value_loss            | 11.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 6           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6           |
| reward                   | -0.46017545 |
| rollout/                 |             |
|    ep_len_mean           | 239         |
|    ep_rew_mean           | -86.4       |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 18          |
|    time_elapsed          | 510         |
|    total_timesteps       | 839680      |
| train/                   |             |
|    approx_kl             | 0.00808464  |
|    clip_fraction         | 0.0851      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.89        |
|    cost_value_loss       | 13.9        |
|    cost_values           | 2.88        |
|    entropy               | -1.95       |
|    entropy_loss          | -1.95       |
|    explained_variance    | 0.522       |
|    lagrangian_multiplier | 0.00614     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.6         |
|    n_updates             | 4090        |
|    policy_gradient_loss  | -0.00416    |
|    std                   | 0.666       |
|    value_loss            | 14.8        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8.01       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.01       |
| reward                   | -0.1856276 |
| rollout/                 |            |
|    ep_len_mean           | 241        |
|    ep_rew_mean           | -87        |
| time/                    |            |
|    fps                   | 71         |
|    iterations            | 19         |
|    time_elapsed          | 547        |
|    total_timesteps       | 841728     |
| train/                   |            |
|    approx_kl             | 0.00891479 |
|    clip_fraction         | 0.155      |
|    clip_range            | 0.2        |
|    cost_returns          | 5.17       |
|    cost_value_loss       | 8.95       |
|    cost_values           | 2.82       |
|    entropy               | -1.94      |
|    entropy_loss          | -1.95      |
|    explained_variance    | 0.434      |
|    lagrangian_multiplier | 0.00282    |
|    learning_rate         | 0.0003     |
|    loss                  | 5.13       |
|    n_updates             | 4100       |
|    policy_gradient_loss  | -0.00524   |
|    std                   | 0.665      |
|    value_loss            | 9.99       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.20085423 |
| rollout/                 |             |
|    ep_len_mean           | 238         |
|    ep_rew_mean           | -85.6       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 20          |
|    time_elapsed          | 584         |
|    total_timesteps       | 843776      |
| train/                   |             |
|    approx_kl             | 0.006337949 |
|    clip_fraction         | 0.0785      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.81        |
|    cost_value_loss       | 9.71        |
|    cost_values           | 2.81        |
|    entropy               | -1.94       |
|    entropy_loss          | -1.94       |
|    explained_variance    | 0.544       |
|    lagrangian_multiplier | 0.00359     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.7         |
|    n_updates             | 4110        |
|    policy_gradient_loss  | -0.0041     |
|    std                   | 0.664       |
|    value_loss            | 14.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.42433637 |
| rollout/                 |             |
|    ep_len_mean           | 237         |
|    ep_rew_mean           | -84.8       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 21          |
|    time_elapsed          | 618         |
|    total_timesteps       | 845824      |
| train/                   |             |
|    approx_kl             | 0.008760292 |
|    clip_fraction         | 0.0666      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.02        |
|    cost_value_loss       | 14.5        |
|    cost_values           | 2.86        |
|    entropy               | -1.94       |
|    entropy_loss          | -1.94       |
|    explained_variance    | 0.402       |
|    lagrangian_multiplier | 0.00643     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.18        |
|    n_updates             | 4120        |
|    policy_gradient_loss  | -0.00265    |
|    std                   | 0.662       |
|    value_loss            | 12.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.15902278  |
| rollout/                 |              |
|    ep_len_mean           | 233          |
|    ep_rew_mean           | -83.9        |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 22           |
|    time_elapsed          | 643          |
|    total_timesteps       | 847872       |
| train/                   |              |
|    approx_kl             | 0.0061741485 |
|    clip_fraction         | 0.0789       |
|    clip_range            | 0.2          |
|    cost_returns          | 6            |
|    cost_value_loss       | 16           |
|    cost_values           | 2.77         |
|    entropy               | -1.93        |
|    entropy_loss          | -1.93        |
|    explained_variance    | 0.479        |
|    lagrangian_multiplier | 0.00497      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.62         |
|    n_updates             | 4130         |
|    policy_gradient_loss  | -0.00322     |
|    std                   | 0.66         |
|    value_loss            | 16.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.29242    |
| rollout/                 |             |
|    ep_len_mean           | 239         |
|    ep_rew_mean           | -85.8       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 23          |
|    time_elapsed          | 666         |
|    total_timesteps       | 849920      |
| train/                   |             |
|    approx_kl             | 0.009511862 |
|    clip_fraction         | 0.0804      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.74        |
|    cost_value_loss       | 12.9        |
|    cost_values           | 2.81        |
|    entropy               | -1.92       |
|    entropy_loss          | -1.93       |
|    explained_variance    | 0.572       |
|    lagrangian_multiplier | 0.00444     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.61        |
|    n_updates             | 4140        |
|    policy_gradient_loss  | -0.00387    |
|    std                   | 0.658       |
|    value_loss            | 16.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.35147846 |
| rollout/                 |             |
|    ep_len_mean           | 233         |
|    ep_rew_mean           | -83.8       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 24          |
|    time_elapsed          | 692         |
|    total_timesteps       | 851968      |
| train/                   |             |
|    approx_kl             | 0.00602751  |
|    clip_fraction         | 0.0687      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.33        |
|    cost_value_loss       | 9.97        |
|    cost_values           | 2.81        |
|    entropy               | -1.91       |
|    entropy_loss          | -1.92       |
|    explained_variance    | 0.427       |
|    lagrangian_multiplier | 0.00526     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.07        |
|    n_updates             | 4150        |
|    policy_gradient_loss  | -0.00198    |
|    std                   | 0.655       |
|    value_loss            | 15.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2192165  |
| rollout/                 |             |
|    ep_len_mean           | 232         |
|    ep_rew_mean           | -82.8       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 25          |
|    time_elapsed          | 718         |
|    total_timesteps       | 854016      |
| train/                   |             |
|    approx_kl             | 0.005602898 |
|    clip_fraction         | 0.064       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.95        |
|    cost_value_loss       | 13.1        |
|    cost_values           | 2.9         |
|    entropy               | -1.9        |
|    entropy_loss          | -1.91       |
|    explained_variance    | 0.402       |
|    lagrangian_multiplier | 0.00588     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.7         |
|    n_updates             | 4160        |
|    policy_gradient_loss  | -0.00425    |
|    std                   | 0.652       |
|    value_loss            | 17          |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.39932606 |
| rollout/                 |             |
|    ep_len_mean           | 240         |
|    ep_rew_mean           | -85.4       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 26          |
|    time_elapsed          | 742         |
|    total_timesteps       | 856064      |
| train/                   |             |
|    approx_kl             | 0.014109109 |
|    clip_fraction         | 0.138       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.94        |
|    cost_value_loss       | 13          |
|    cost_values           | 2.92        |
|    entropy               | -1.9        |
|    entropy_loss          | -1.9        |
|    explained_variance    | 0.51        |
|    lagrangian_multiplier | 0.0054      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.39        |
|    n_updates             | 4170        |
|    policy_gradient_loss  | -0.00711    |
|    std                   | 0.651       |
|    value_loss            | 12.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.5163367  |
| rollout/                 |             |
|    ep_len_mean           | 245         |
|    ep_rew_mean           | -87         |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 27          |
|    time_elapsed          | 765         |
|    total_timesteps       | 858112      |
| train/                   |             |
|    approx_kl             | 0.014214404 |
|    clip_fraction         | 0.121       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.22        |
|    cost_value_loss       | 10.5        |
|    cost_values           | 2.87        |
|    entropy               | -1.88       |
|    entropy_loss          | -1.89       |
|    explained_variance    | 0.51        |
|    lagrangian_multiplier | 0.00355     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.77        |
|    n_updates             | 4180        |
|    policy_gradient_loss  | -0.00448    |
|    std                   | 0.646       |
|    value_loss            | 10.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.44726622 |
| rollout/                 |             |
|    ep_len_mean           | 242         |
|    ep_rew_mean           | -85.4       |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 28          |
|    time_elapsed          | 788         |
|    total_timesteps       | 860160      |
| train/                   |             |
|    approx_kl             | 0.012793129 |
|    clip_fraction         | 0.116       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.95        |
|    cost_value_loss       | 8.85        |
|    cost_values           | 2.86        |
|    entropy               | -1.88       |
|    entropy_loss          | -1.88       |
|    explained_variance    | 0.408       |
|    lagrangian_multiplier | 0.0026      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.59        |
|    n_updates             | 4190        |
|    policy_gradient_loss  | -0.00472    |
|    std                   | 0.643       |
|    value_loss            | 10.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.82        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.82        |
| reward                   | -0.22808439 |
| rollout/                 |             |
|    ep_len_mean           | 242         |
|    ep_rew_mean           | -86.1       |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 29          |
|    time_elapsed          | 812         |
|    total_timesteps       | 862208      |
| train/                   |             |
|    approx_kl             | 0.013809003 |
|    clip_fraction         | 0.162       |
|    clip_range            | 0.2         |
|    cost_returns          | 5           |
|    cost_value_loss       | 7.61        |
|    cost_values           | 2.86        |
|    entropy               | -1.88       |
|    entropy_loss          | -1.88       |
|    explained_variance    | 0.454       |
|    lagrangian_multiplier | 0.00303     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.36        |
|    n_updates             | 4200        |
|    policy_gradient_loss  | -0.00741    |
|    std                   | 0.642       |
|    value_loss            | 13.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.40358204  |
| rollout/                 |              |
|    ep_len_mean           | 239          |
|    ep_rew_mean           | -84.7        |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 30           |
|    time_elapsed          | 847          |
|    total_timesteps       | 864256       |
| train/                   |              |
|    approx_kl             | 0.0071563814 |
|    clip_fraction         | 0.0841       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.94         |
|    cost_value_loss       | 13.4         |
|    cost_values           | 2.9          |
|    entropy               | -1.87        |
|    entropy_loss          | -1.87        |
|    explained_variance    | 0.482        |
|    lagrangian_multiplier | 0.00349      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.07         |
|    n_updates             | 4210         |
|    policy_gradient_loss  | -0.00316     |
|    std                   | 0.64         |
|    value_loss            | 14.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.96         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 6.96         |
| reward                   | -0.28486654  |
| rollout/                 |              |
|    ep_len_mean           | 229          |
|    ep_rew_mean           | -81.7        |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 31           |
|    time_elapsed          | 884          |
|    total_timesteps       | 866304       |
| train/                   |              |
|    approx_kl             | 0.0038381387 |
|    clip_fraction         | 0.0935       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.65         |
|    cost_value_loss       | 11.1         |
|    cost_values           | 2.9          |
|    entropy               | -1.86        |
|    entropy_loss          | -1.87        |
|    explained_variance    | 0.265        |
|    lagrangian_multiplier | 0.00522      |
|    learning_rate         | 0.0003       |
|    loss                  | 5            |
|    n_updates             | 4220         |
|    policy_gradient_loss  | -0.0034      |
|    std                   | 0.638        |
|    value_loss            | 10.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.22378975 |
| rollout/                 |             |
|    ep_len_mean           | 226         |
|    ep_rew_mean           | -80.3       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 32          |
|    time_elapsed          | 924         |
|    total_timesteps       | 868352      |
| train/                   |             |
|    approx_kl             | 0.00636138  |
|    clip_fraction         | 0.0957      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.06        |
|    cost_value_loss       | 14.7        |
|    cost_values           | 2.87        |
|    entropy               | -1.85       |
|    entropy_loss          | -1.86       |
|    explained_variance    | 0.585       |
|    lagrangian_multiplier | 0.00346     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.09        |
|    n_updates             | 4230        |
|    policy_gradient_loss  | -0.00447    |
|    std                   | 0.636       |
|    value_loss            | 17.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.18865757 |
| rollout/                 |             |
|    ep_len_mean           | 232         |
|    ep_rew_mean           | -82         |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 33          |
|    time_elapsed          | 960         |
|    total_timesteps       | 870400      |
| train/                   |             |
|    approx_kl             | 0.011973972 |
|    clip_fraction         | 0.156       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.21        |
|    cost_value_loss       | 10.2        |
|    cost_values           | 2.83        |
|    entropy               | -1.85       |
|    entropy_loss          | -1.85       |
|    explained_variance    | 0.464       |
|    lagrangian_multiplier | 0.00467     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.49        |
|    n_updates             | 4240        |
|    policy_gradient_loss  | -0.006      |
|    std                   | 0.633       |
|    value_loss            | 12.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.33711308  |
| rollout/                 |              |
|    ep_len_mean           | 236          |
|    ep_rew_mean           | -82.9        |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 34           |
|    time_elapsed          | 996          |
|    total_timesteps       | 872448       |
| train/                   |              |
|    approx_kl             | 0.0065704137 |
|    clip_fraction         | 0.095        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.26         |
|    cost_value_loss       | 9.65         |
|    cost_values           | 2.84         |
|    entropy               | -1.84        |
|    entropy_loss          | -1.84        |
|    explained_variance    | 0.524        |
|    lagrangian_multiplier | 0.00409      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.42         |
|    n_updates             | 4250         |
|    policy_gradient_loss  | -0.00221     |
|    std                   | 0.629        |
|    value_loss            | 7.63         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.8177243  |
| rollout/                 |             |
|    ep_len_mean           | 236         |
|    ep_rew_mean           | -82.7       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 35          |
|    time_elapsed          | 1034        |
|    total_timesteps       | 874496      |
| train/                   |             |
|    approx_kl             | 0.013645846 |
|    clip_fraction         | 0.11        |
|    clip_range            | 0.2         |
|    cost_returns          | 5.85        |
|    cost_value_loss       | 13.1        |
|    cost_values           | 2.87        |
|    entropy               | -1.83       |
|    entropy_loss          | -1.83       |
|    explained_variance    | 0.547       |
|    lagrangian_multiplier | 0.00438     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.01        |
|    n_updates             | 4260        |
|    policy_gradient_loss  | -0.00403    |
|    std                   | 0.626       |
|    value_loss            | 12.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.2066381   |
| rollout/                 |              |
|    ep_len_mean           | 235          |
|    ep_rew_mean           | -82.5        |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 36           |
|    time_elapsed          | 1069         |
|    total_timesteps       | 876544       |
| train/                   |              |
|    approx_kl             | 0.0069798655 |
|    clip_fraction         | 0.0699       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.38         |
|    cost_value_loss       | 10.1         |
|    cost_values           | 2.93         |
|    entropy               | -1.81        |
|    entropy_loss          | -1.82        |
|    explained_variance    | 0.358        |
|    lagrangian_multiplier | 0.00431      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.2          |
|    n_updates             | 4270         |
|    policy_gradient_loss  | -0.00562     |
|    std                   | 0.622        |
|    value_loss            | 17.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.3417016  |
| rollout/                 |             |
|    ep_len_mean           | 228         |
|    ep_rew_mean           | -80.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 37          |
|    time_elapsed          | 1102        |
|    total_timesteps       | 878592      |
| train/                   |             |
|    approx_kl             | 0.013863079 |
|    clip_fraction         | 0.106       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.73        |
|    cost_value_loss       | 10.8        |
|    cost_values           | 2.89        |
|    entropy               | -1.8        |
|    entropy_loss          | -1.81       |
|    explained_variance    | 0.589       |
|    lagrangian_multiplier | 0.00532     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.66        |
|    n_updates             | 4280        |
|    policy_gradient_loss  | -0.00438    |
|    std                   | 0.618       |
|    value_loss            | 9.76        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.18180962 |
| rollout/                 |             |
|    ep_len_mean           | 217         |
|    ep_rew_mean           | -77.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 38          |
|    time_elapsed          | 1134        |
|    total_timesteps       | 880640      |
| train/                   |             |
|    approx_kl             | 0.00869401  |
|    clip_fraction         | 0.0792      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.93        |
|    cost_value_loss       | 14.5        |
|    cost_values           | 2.84        |
|    entropy               | -1.79       |
|    entropy_loss          | -1.8        |
|    explained_variance    | 0.6         |
|    lagrangian_multiplier | 0.0038      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.07        |
|    n_updates             | 4290        |
|    policy_gradient_loss  | -0.00409    |
|    std                   | 0.615       |
|    value_loss            | 18.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -0.18869776  |
| rollout/                 |              |
|    ep_len_mean           | 216          |
|    ep_rew_mean           | -77.4        |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 39           |
|    time_elapsed          | 1163         |
|    total_timesteps       | 882688       |
| train/                   |              |
|    approx_kl             | 0.0077953124 |
|    clip_fraction         | 0.111        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.97         |
|    cost_value_loss       | 8.86         |
|    cost_values           | 2.8          |
|    entropy               | -1.78        |
|    entropy_loss          | -1.78        |
|    explained_variance    | 0.538        |
|    lagrangian_multiplier | 0.00152      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.96         |
|    n_updates             | 4300         |
|    policy_gradient_loss  | -0.00508     |
|    std                   | 0.611        |
|    value_loss            | 13.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.33505043  |
| rollout/                 |              |
|    ep_len_mean           | 204          |
|    ep_rew_mean           | -74.7        |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 40           |
|    time_elapsed          | 1189         |
|    total_timesteps       | 884736       |
| train/                   |              |
|    approx_kl             | 0.0071087503 |
|    clip_fraction         | 0.0702       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.14         |
|    cost_value_loss       | 9.53         |
|    cost_values           | 2.79         |
|    entropy               | -1.77        |
|    entropy_loss          | -1.77        |
|    explained_variance    | 0.608        |
|    lagrangian_multiplier | 0.00343      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.69         |
|    n_updates             | 4310         |
|    policy_gradient_loss  | -0.00465     |
|    std                   | 0.609        |
|    value_loss            | 18.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.49875832 |
| rollout/                 |             |
|    ep_len_mean           | 208         |
|    ep_rew_mean           | -76.1       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 41          |
|    time_elapsed          | 1216        |
|    total_timesteps       | 886784      |
| train/                   |             |
|    approx_kl             | 0.010316993 |
|    clip_fraction         | 0.115       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.17        |
|    cost_value_loss       | 10.8        |
|    cost_values           | 2.71        |
|    entropy               | -1.76       |
|    entropy_loss          | -1.77       |
|    explained_variance    | 0.413       |
|    lagrangian_multiplier | 0.00263     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.22        |
|    n_updates             | 4320        |
|    policy_gradient_loss  | -0.00709    |
|    std                   | 0.608       |
|    value_loss            | 13.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4081976   |
| rollout/                 |              |
|    ep_len_mean           | 191          |
|    ep_rew_mean           | -72.2        |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 42           |
|    time_elapsed          | 1245         |
|    total_timesteps       | 888832       |
| train/                   |              |
|    approx_kl             | 0.0066412813 |
|    clip_fraction         | 0.0736       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.86         |
|    cost_value_loss       | 13.4         |
|    cost_values           | 2.81         |
|    entropy               | -1.76        |
|    entropy_loss          | -1.76        |
|    explained_variance    | 0.539        |
|    lagrangian_multiplier | 0.00404      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.05         |
|    n_updates             | 4330         |
|    policy_gradient_loss  | -0.00451     |
|    std                   | 0.607        |
|    value_loss            | 16.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.447101   |
| rollout/                 |             |
|    ep_len_mean           | 181         |
|    ep_rew_mean           | -68.8       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 43          |
|    time_elapsed          | 1275        |
|    total_timesteps       | 890880      |
| train/                   |             |
|    approx_kl             | 0.004788314 |
|    clip_fraction         | 0.0659      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.93        |
|    cost_value_loss       | 14.4        |
|    cost_values           | 2.87        |
|    entropy               | -1.76       |
|    entropy_loss          | -1.76       |
|    explained_variance    | 0.452       |
|    lagrangian_multiplier | 0.00404     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.74        |
|    n_updates             | 4340        |
|    policy_gradient_loss  | -0.00529    |
|    std                   | 0.608       |
|    value_loss            | 20.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.1867565  |
| rollout/                 |             |
|    ep_len_mean           | 189         |
|    ep_rew_mean           | -71.6       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 44          |
|    time_elapsed          | 1305        |
|    total_timesteps       | 892928      |
| train/                   |             |
|    approx_kl             | 0.008225412 |
|    clip_fraction         | 0.0747      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.7         |
|    cost_value_loss       | 11.9        |
|    cost_values           | 2.87        |
|    entropy               | -1.75       |
|    entropy_loss          | -1.76       |
|    explained_variance    | 0.547       |
|    lagrangian_multiplier | 0.00401     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.09        |
|    n_updates             | 4350        |
|    policy_gradient_loss  | -0.00277    |
|    std                   | 0.606       |
|    value_loss            | 15.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.38599768 |
| rollout/                 |             |
|    ep_len_mean           | 171         |
|    ep_rew_mean           | -66.4       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 45          |
|    time_elapsed          | 1335        |
|    total_timesteps       | 894976      |
| train/                   |             |
|    approx_kl             | 0.007533878 |
|    clip_fraction         | 0.11        |
|    clip_range            | 0.2         |
|    cost_returns          | 5.31        |
|    cost_value_loss       | 9.79        |
|    cost_values           | 2.9         |
|    entropy               | -1.75       |
|    entropy_loss          | -1.75       |
|    explained_variance    | 0.493       |
|    lagrangian_multiplier | 0.0041      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.58        |
|    n_updates             | 4360        |
|    policy_gradient_loss  | -0.00347    |
|    std                   | 0.606       |
|    value_loss            | 12.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.22192101  |
| rollout/                 |              |
|    ep_len_mean           | 173          |
|    ep_rew_mean           | -66.7        |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 46           |
|    time_elapsed          | 1366         |
|    total_timesteps       | 897024       |
| train/                   |              |
|    approx_kl             | 0.0075177345 |
|    clip_fraction         | 0.0938       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.19         |
|    cost_value_loss       | 9.05         |
|    cost_values           | 2.85         |
|    entropy               | -1.74        |
|    entropy_loss          | -1.74        |
|    explained_variance    | 0.514        |
|    lagrangian_multiplier | 0.00484      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.62         |
|    n_updates             | 4370         |
|    policy_gradient_loss  | -0.00749     |
|    std                   | 0.602        |
|    value_loss            | 17.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.33275205 |
| rollout/                 |             |
|    ep_len_mean           | 175         |
|    ep_rew_mean           | -66.7       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 47          |
|    time_elapsed          | 1393        |
|    total_timesteps       | 899072      |
| train/                   |             |
|    approx_kl             | 0.017728887 |
|    clip_fraction         | 0.0938      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.26        |
|    cost_value_loss       | 8.89        |
|    cost_values           | 2.87        |
|    entropy               | -1.73       |
|    entropy_loss          | -1.73       |
|    explained_variance    | 0.64        |
|    lagrangian_multiplier | 0.00463     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.93        |
|    n_updates             | 4380        |
|    policy_gradient_loss  | -0.00577    |
|    std                   | 0.599       |
|    value_loss            | 11.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.29306075 |
| rollout/                 |             |
|    ep_len_mean           | 183         |
|    ep_rew_mean           | -69.1       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 48          |
|    time_elapsed          | 1417        |
|    total_timesteps       | 901120      |
| train/                   |             |
|    approx_kl             | 0.010686375 |
|    clip_fraction         | 0.0892      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.18        |
|    cost_value_loss       | 10.6        |
|    cost_values           | 2.91        |
|    entropy               | -1.72       |
|    entropy_loss          | -1.72       |
|    explained_variance    | 0.618       |
|    lagrangian_multiplier | 0.00195     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.37        |
|    n_updates             | 4390        |
|    policy_gradient_loss  | -0.00399    |
|    std                   | 0.596       |
|    value_loss            | 13.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.40222436  |
| rollout/                 |              |
|    ep_len_mean           | 186          |
|    ep_rew_mean           | -69.8        |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 49           |
|    time_elapsed          | 1440         |
|    total_timesteps       | 903168       |
| train/                   |              |
|    approx_kl             | 0.0068587735 |
|    clip_fraction         | 0.114        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.12         |
|    cost_value_loss       | 13.9         |
|    cost_values           | 2.94         |
|    entropy               | -1.71        |
|    entropy_loss          | -1.71        |
|    explained_variance    | 0.446        |
|    lagrangian_multiplier | 0.00447      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.86         |
|    n_updates             | 4400         |
|    policy_gradient_loss  | -0.00506     |
|    std                   | 0.593        |
|    value_loss            | 11.2         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ent-coefficient-ppol/1vjpjg9h
-----------------------------------
| avg_speed          | 8.01       |
| cost               | 1          |
| is_success         | 0          |
| max_speed          | 8.01       |
| reward             | -0.2827908 |
| rollout/           |            |
|    ep_len_mean     | 187        |
|    ep_rew_mean     | -68.8      |
| time/              |            |
|    fps             | 70         |
|    iterations      | 1          |
|    time_elapsed    | 29         |
|    total_timesteps | 905216     |
-----------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.15583122  |
| rollout/                 |              |
|    ep_len_mean           | 186          |
|    ep_rew_mean           | -67.8        |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 2            |
|    time_elapsed          | 60           |
|    total_timesteps       | 907264       |
| train/                   |              |
|    approx_kl             | 0.0067809597 |
|    clip_fraction         | 0.0705       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.01         |
|    cost_value_loss       | 14           |
|    cost_values           | 2.95         |
|    entropy               | -1.7         |
|    entropy_loss          | -1.7         |
|    explained_variance    | 0.356        |
|    lagrangian_multiplier | 0.00547      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.63         |
|    n_updates             | 4420         |
|    policy_gradient_loss  | -0.00225     |
|    std                   | 0.591        |
|    value_loss            | 13.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.86        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.86        |
| reward                   | -0.32425988 |
| rollout/                 |             |
|    ep_len_mean           | 190         |
|    ep_rew_mean           | -68.8       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 3           |
|    time_elapsed          | 93          |
|    total_timesteps       | 909312      |
| train/                   |             |
|    approx_kl             | 0.007910735 |
|    clip_fraction         | 0.0999      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.72        |
|    cost_value_loss       | 13          |
|    cost_values           | 2.94        |
|    entropy               | -1.69       |
|    entropy_loss          | -1.7        |
|    explained_variance    | 0.471       |
|    lagrangian_multiplier | 0.00297     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.27        |
|    n_updates             | 4430        |
|    policy_gradient_loss  | -0.00288    |
|    std                   | 0.589       |
|    value_loss            | 17.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.11        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.11        |
| reward                   | -0.4227004  |
| rollout/                 |             |
|    ep_len_mean           | 184         |
|    ep_rew_mean           | -66.7       |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 4           |
|    time_elapsed          | 130         |
|    total_timesteps       | 911360      |
| train/                   |             |
|    approx_kl             | 0.010050686 |
|    clip_fraction         | 0.0639      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.67        |
|    cost_value_loss       | 12.2        |
|    cost_values           | 2.92        |
|    entropy               | -1.69       |
|    entropy_loss          | -1.69       |
|    explained_variance    | 0.486       |
|    lagrangian_multiplier | 0.00474     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.62        |
|    n_updates             | 4440        |
|    policy_gradient_loss  | -0.0021     |
|    std                   | 0.59        |
|    value_loss            | 12.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.29990616 |
| rollout/                 |             |
|    ep_len_mean           | 197         |
|    ep_rew_mean           | -70.6       |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 5           |
|    time_elapsed          | 168         |
|    total_timesteps       | 913408      |
| train/                   |             |
|    approx_kl             | 0.009530126 |
|    clip_fraction         | 0.0826      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.66        |
|    cost_value_loss       | 12.5        |
|    cost_values           | 2.92        |
|    entropy               | -1.69       |
|    entropy_loss          | -1.69       |
|    explained_variance    | 0.597       |
|    lagrangian_multiplier | 0.00514     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.24        |
|    n_updates             | 4450        |
|    policy_gradient_loss  | -0.0021     |
|    std                   | 0.588       |
|    value_loss            | 15.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.34059072 |
| rollout/                 |             |
|    ep_len_mean           | 208         |
|    ep_rew_mean           | -74         |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 6           |
|    time_elapsed          | 206         |
|    total_timesteps       | 915456      |
| train/                   |             |
|    approx_kl             | 0.023109091 |
|    clip_fraction         | 0.111       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.64        |
|    cost_value_loss       | 13.4        |
|    cost_values           | 2.88        |
|    entropy               | -1.69       |
|    entropy_loss          | -1.69       |
|    explained_variance    | 0.525       |
|    lagrangian_multiplier | 0.00292     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.83        |
|    n_updates             | 4460        |
|    policy_gradient_loss  | -0.00177    |
|    std                   | 0.588       |
|    value_loss            | 8.37        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.22605278 |
| rollout/                 |             |
|    ep_len_mean           | 196         |
|    ep_rew_mean           | -70.2       |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 7           |
|    time_elapsed          | 240         |
|    total_timesteps       | 917504      |
| train/                   |             |
|    approx_kl             | 0.008421817 |
|    clip_fraction         | 0.151       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.93        |
|    cost_value_loss       | 14.8        |
|    cost_values           | 2.86        |
|    entropy               | -1.69       |
|    entropy_loss          | -1.69       |
|    explained_variance    | 0.544       |
|    lagrangian_multiplier | 0.00591     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.14        |
|    n_updates             | 4470        |
|    policy_gradient_loss  | -0.000435   |
|    std                   | 0.587       |
|    value_loss            | 10          |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.19852762 |
| rollout/                 |             |
|    ep_len_mean           | 193         |
|    ep_rew_mean           | -69         |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 8           |
|    time_elapsed          | 276         |
|    total_timesteps       | 919552      |
| train/                   |             |
|    approx_kl             | 0.012042467 |
|    clip_fraction         | 0.0935      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.39        |
|    cost_value_loss       | 11.8        |
|    cost_values           | 2.88        |
|    entropy               | -1.67       |
|    entropy_loss          | -1.68       |
|    explained_variance    | 0.584       |
|    lagrangian_multiplier | 0.00387     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.43        |
|    n_updates             | 4480        |
|    policy_gradient_loss  | -0.0034     |
|    std                   | 0.584       |
|    value_loss            | 17.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.24246304 |
| rollout/                 |             |
|    ep_len_mean           | 198         |
|    ep_rew_mean           | -71.1       |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 9           |
|    time_elapsed          | 307         |
|    total_timesteps       | 921600      |
| train/                   |             |
|    approx_kl             | 0.010229057 |
|    clip_fraction         | 0.0943      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.94        |
|    cost_value_loss       | 15.1        |
|    cost_values           | 2.92        |
|    entropy               | -1.67       |
|    entropy_loss          | -1.67       |
|    explained_variance    | 0.567       |
|    lagrangian_multiplier | 0.00234     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.81        |
|    n_updates             | 4490        |
|    policy_gradient_loss  | -0.00322    |
|    std                   | 0.582       |
|    value_loss            | 14          |
------------------------------------------
------------------------------------------
| avg_speed                | 1.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.8         |
| reward                   | -0.6026471  |
| rollout/                 |             |
|    ep_len_mean           | 199         |
|    ep_rew_mean           | -70.8       |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 10          |
|    time_elapsed          | 340         |
|    total_timesteps       | 923648      |
| train/                   |             |
|    approx_kl             | 0.017377278 |
|    clip_fraction         | 0.123       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.77        |
|    cost_value_loss       | 8.53        |
|    cost_values           | 2.88        |
|    entropy               | -1.66       |
|    entropy_loss          | -1.66       |
|    explained_variance    | 0.365       |
|    lagrangian_multiplier | 0.0036      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.75        |
|    n_updates             | 4500        |
|    policy_gradient_loss  | -0.00835    |
|    std                   | 0.579       |
|    value_loss            | 8.73        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.18809809  |
| rollout/                 |              |
|    ep_len_mean           | 199          |
|    ep_rew_mean           | -71.3        |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 11           |
|    time_elapsed          | 369          |
|    total_timesteps       | 925696       |
| train/                   |              |
|    approx_kl             | 0.0043945145 |
|    clip_fraction         | 0.0749       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.88         |
|    cost_value_loss       | 8.11         |
|    cost_values           | 2.9          |
|    entropy               | -1.66        |
|    entropy_loss          | -1.66        |
|    explained_variance    | 0.375        |
|    lagrangian_multiplier | 0.00242      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.52         |
|    n_updates             | 4510         |
|    policy_gradient_loss  | -0.00292     |
|    std                   | 0.58         |
|    value_loss            | 14.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.44        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.44        |
| reward                   | -0.38791832 |
| rollout/                 |             |
|    ep_len_mean           | 204         |
|    ep_rew_mean           | -72.9       |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 12          |
|    time_elapsed          | 398         |
|    total_timesteps       | 927744      |
| train/                   |             |
|    approx_kl             | 0.008053196 |
|    clip_fraction         | 0.091       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.35        |
|    cost_value_loss       | 9.77        |
|    cost_values           | 2.88        |
|    entropy               | -1.65       |
|    entropy_loss          | -1.66       |
|    explained_variance    | 0.579       |
|    lagrangian_multiplier | 0.00309     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.43        |
|    n_updates             | 4520        |
|    policy_gradient_loss  | -0.00277    |
|    std                   | 0.578       |
|    value_loss            | 13.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.9         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.9         |
| reward                   | -0.2264909  |
| rollout/                 |             |
|    ep_len_mean           | 196         |
|    ep_rew_mean           | -70.4       |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 13          |
|    time_elapsed          | 429         |
|    total_timesteps       | 929792      |
| train/                   |             |
|    approx_kl             | 0.008208778 |
|    clip_fraction         | 0.0786      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.73        |
|    cost_value_loss       | 14.5        |
|    cost_values           | 2.9         |
|    entropy               | -1.64       |
|    entropy_loss          | -1.65       |
|    explained_variance    | 0.589       |
|    lagrangian_multiplier | 0.00475     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.82        |
|    n_updates             | 4530        |
|    policy_gradient_loss  | -0.0028     |
|    std                   | 0.575       |
|    value_loss            | 10.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.2803159   |
| rollout/                 |              |
|    ep_len_mean           | 202          |
|    ep_rew_mean           | -72.3        |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 14           |
|    time_elapsed          | 465          |
|    total_timesteps       | 931840       |
| train/                   |              |
|    approx_kl             | 0.0072754067 |
|    clip_fraction         | 0.0775       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.43         |
|    cost_value_loss       | 12.4         |
|    cost_values           | 2.89         |
|    entropy               | -1.64        |
|    entropy_loss          | -1.64        |
|    explained_variance    | 0.587        |
|    lagrangian_multiplier | 0.00189      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.19         |
|    n_updates             | 4540         |
|    policy_gradient_loss  | -0.0023      |
|    std                   | 0.574        |
|    value_loss            | 15.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.18868251 |
| rollout/                 |             |
|    ep_len_mean           | 199         |
|    ep_rew_mean           | -71.5       |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 15          |
|    time_elapsed          | 500         |
|    total_timesteps       | 933888      |
| train/                   |             |
|    approx_kl             | 0.009550078 |
|    clip_fraction         | 0.08        |
|    clip_range            | 0.2         |
|    cost_returns          | 5.21        |
|    cost_value_loss       | 12.7        |
|    cost_values           | 2.82        |
|    entropy               | -1.63       |
|    entropy_loss          | -1.64       |
|    explained_variance    | 0.653       |
|    lagrangian_multiplier | 0.00523     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.47        |
|    n_updates             | 4550        |
|    policy_gradient_loss  | -0.00426    |
|    std                   | 0.572       |
|    value_loss            | 10.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.3226535  |
| rollout/                 |             |
|    ep_len_mean           | 196         |
|    ep_rew_mean           | -70.3       |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 16          |
|    time_elapsed          | 531         |
|    total_timesteps       | 935936      |
| train/                   |             |
|    approx_kl             | 0.005259108 |
|    clip_fraction         | 0.053       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.68        |
|    cost_value_loss       | 14.3        |
|    cost_values           | 2.87        |
|    entropy               | -1.64       |
|    entropy_loss          | -1.64       |
|    explained_variance    | 0.548       |
|    lagrangian_multiplier | 0.00436     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.67        |
|    n_updates             | 4560        |
|    policy_gradient_loss  | -0.000627   |
|    std                   | 0.574       |
|    value_loss            | 9.48        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.175314    |
| rollout/                 |              |
|    ep_len_mean           | 203          |
|    ep_rew_mean           | -72.3        |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 17           |
|    time_elapsed          | 565          |
|    total_timesteps       | 937984       |
| train/                   |              |
|    approx_kl             | 0.0036400016 |
|    clip_fraction         | 0.0764       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.2          |
|    cost_value_loss       | 14.5         |
|    cost_values           | 2.91         |
|    entropy               | -1.63        |
|    entropy_loss          | -1.64        |
|    explained_variance    | 0.542        |
|    lagrangian_multiplier | 0.00653      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.02         |
|    n_updates             | 4570         |
|    policy_gradient_loss  | -0.00324     |
|    std                   | 0.572        |
|    value_loss            | 11.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.12036354 |
| rollout/                 |             |
|    ep_len_mean           | 208         |
|    ep_rew_mean           | -74         |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 18          |
|    time_elapsed          | 595         |
|    total_timesteps       | 940032      |
| train/                   |             |
|    approx_kl             | 0.006784002 |
|    clip_fraction         | 0.0884      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.02        |
|    cost_value_loss       | 13.5        |
|    cost_values           | 2.93        |
|    entropy               | -1.63       |
|    entropy_loss          | -1.63       |
|    explained_variance    | 0.568       |
|    lagrangian_multiplier | 0.00494     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.84        |
|    n_updates             | 4580        |
|    policy_gradient_loss  | -0.00384    |
|    std                   | 0.571       |
|    value_loss            | 13.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.6350008  |
| rollout/                 |             |
|    ep_len_mean           | 200         |
|    ep_rew_mean           | -71.3       |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 19          |
|    time_elapsed          | 624         |
|    total_timesteps       | 942080      |
| train/                   |             |
|    approx_kl             | 0.014342781 |
|    clip_fraction         | 0.134       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.39        |
|    cost_value_loss       | 16.6        |
|    cost_values           | 2.95        |
|    entropy               | -1.64       |
|    entropy_loss          | -1.63       |
|    explained_variance    | 0.431       |
|    lagrangian_multiplier | 0.00917     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.87        |
|    n_updates             | 4590        |
|    policy_gradient_loss  | -0.00587    |
|    std                   | 0.573       |
|    value_loss            | 12.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.67        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.67        |
| reward                   | -0.25847372 |
| rollout/                 |             |
|    ep_len_mean           | 201         |
|    ep_rew_mean           | -71.9       |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 20          |
|    time_elapsed          | 654         |
|    total_timesteps       | 944128      |
| train/                   |             |
|    approx_kl             | 0.007524852 |
|    clip_fraction         | 0.0988      |
|    clip_range            | 0.2         |
|    cost_returns          | 6           |
|    cost_value_loss       | 13.6        |
|    cost_values           | 2.94        |
|    entropy               | -1.63       |
|    entropy_loss          | -1.63       |
|    explained_variance    | 0.509       |
|    lagrangian_multiplier | 0.00525     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.7         |
|    n_updates             | 4600        |
|    policy_gradient_loss  | -0.00434    |
|    std                   | 0.57        |
|    value_loss            | 12.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.36229247 |
| rollout/                 |             |
|    ep_len_mean           | 199         |
|    ep_rew_mean           | -71.2       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 21          |
|    time_elapsed          | 678         |
|    total_timesteps       | 946176      |
| train/                   |             |
|    approx_kl             | 0.00920286  |
|    clip_fraction         | 0.099       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.02        |
|    cost_value_loss       | 13.8        |
|    cost_values           | 2.95        |
|    entropy               | -1.62       |
|    entropy_loss          | -1.62       |
|    explained_variance    | 0.519       |
|    lagrangian_multiplier | 0.0034      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.58        |
|    n_updates             | 4610        |
|    policy_gradient_loss  | -0.00348    |
|    std                   | 0.568       |
|    value_loss            | 14.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.54        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.54        |
| reward                   | -0.3085096  |
| rollout/                 |             |
|    ep_len_mean           | 200         |
|    ep_rew_mean           | -71.3       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 22          |
|    time_elapsed          | 701         |
|    total_timesteps       | 948224      |
| train/                   |             |
|    approx_kl             | 0.007117225 |
|    clip_fraction         | 0.11        |
|    clip_range            | 0.2         |
|    cost_returns          | 5.39        |
|    cost_value_loss       | 11.4        |
|    cost_values           | 2.93        |
|    entropy               | -1.62       |
|    entropy_loss          | -1.62       |
|    explained_variance    | 0.543       |
|    lagrangian_multiplier | 0.0049      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.37        |
|    n_updates             | 4620        |
|    policy_gradient_loss  | -0.00487    |
|    std                   | 0.57        |
|    value_loss            | 11.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2550747  |
| rollout/                 |             |
|    ep_len_mean           | 204         |
|    ep_rew_mean           | -72.5       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 23          |
|    time_elapsed          | 727         |
|    total_timesteps       | 950272      |
| train/                   |             |
|    approx_kl             | 0.016810426 |
|    clip_fraction         | 0.106       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.14        |
|    cost_value_loss       | 14.3        |
|    cost_values           | 2.94        |
|    entropy               | -1.62       |
|    entropy_loss          | -1.62       |
|    explained_variance    | 0.503       |
|    lagrangian_multiplier | 0.00491     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.42        |
|    n_updates             | 4630        |
|    policy_gradient_loss  | -0.00256    |
|    std                   | 0.57        |
|    value_loss            | 14.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.34825742 |
| rollout/                 |             |
|    ep_len_mean           | 207         |
|    ep_rew_mean           | -73.5       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 24          |
|    time_elapsed          | 751         |
|    total_timesteps       | 952320      |
| train/                   |             |
|    approx_kl             | 0.005687343 |
|    clip_fraction         | 0.109       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.33        |
|    cost_value_loss       | 12          |
|    cost_values           | 2.88        |
|    entropy               | -1.62       |
|    entropy_loss          | -1.62       |
|    explained_variance    | 0.506       |
|    lagrangian_multiplier | 0.00312     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.39        |
|    n_updates             | 4640        |
|    policy_gradient_loss  | -0.00447    |
|    std                   | 0.569       |
|    value_loss            | 12.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.3106482  |
| rollout/                 |             |
|    ep_len_mean           | 201         |
|    ep_rew_mean           | -72         |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 25          |
|    time_elapsed          | 774         |
|    total_timesteps       | 954368      |
| train/                   |             |
|    approx_kl             | 0.005224145 |
|    clip_fraction         | 0.0813      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.83        |
|    cost_value_loss       | 12.7        |
|    cost_values           | 2.92        |
|    entropy               | -1.61       |
|    entropy_loss          | -1.61       |
|    explained_variance    | 0.549       |
|    lagrangian_multiplier | 0.00523     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.41        |
|    n_updates             | 4650        |
|    policy_gradient_loss  | -0.00131    |
|    std                   | 0.568       |
|    value_loss            | 11.5        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.3572351 |
| rollout/                 |            |
|    ep_len_mean           | 197        |
|    ep_rew_mean           | -71        |
| time/                    |            |
|    fps                   | 66         |
|    iterations            | 26         |
|    time_elapsed          | 797        |
|    total_timesteps       | 956416     |
| train/                   |            |
|    approx_kl             | 0.01732399 |
|    clip_fraction         | 0.0957     |
|    clip_range            | 0.2        |
|    cost_returns          | 5.52       |
|    cost_value_loss       | 12.6       |
|    cost_values           | 2.86       |
|    entropy               | -1.6       |
|    entropy_loss          | -1.61      |
|    explained_variance    | 0.49       |
|    lagrangian_multiplier | 0.00514    |
|    learning_rate         | 0.0003     |
|    loss                  | 5.32       |
|    n_updates             | 4660       |
|    policy_gradient_loss  | -0.00329   |
|    std                   | 0.565      |
|    value_loss            | 11.9       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.45165145  |
| rollout/                 |              |
|    ep_len_mean           | 203          |
|    ep_rew_mean           | -73.4        |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 27           |
|    time_elapsed          | 820          |
|    total_timesteps       | 958464       |
| train/                   |              |
|    approx_kl             | 0.0078010336 |
|    clip_fraction         | 0.127        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.94         |
|    cost_value_loss       | 15           |
|    cost_values           | 2.86         |
|    entropy               | -1.6         |
|    entropy_loss          | -1.6         |
|    explained_variance    | 0.562        |
|    lagrangian_multiplier | 0.00458      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.06         |
|    n_updates             | 4670         |
|    policy_gradient_loss  | -0.00692     |
|    std                   | 0.565        |
|    value_loss            | 12.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.36635602 |
| rollout/                 |             |
|    ep_len_mean           | 210         |
|    ep_rew_mean           | -75.5       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 28          |
|    time_elapsed          | 848         |
|    total_timesteps       | 960512      |
| train/                   |             |
|    approx_kl             | 0.014938244 |
|    clip_fraction         | 0.126       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.56        |
|    cost_value_loss       | 20.2        |
|    cost_values           | 2.89        |
|    entropy               | -1.59       |
|    entropy_loss          | -1.6        |
|    explained_variance    | 0.397       |
|    lagrangian_multiplier | 0.00442     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.62        |
|    n_updates             | 4680        |
|    policy_gradient_loss  | -0.00528    |
|    std                   | 0.563       |
|    value_loss            | 12          |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.42589173 |
| rollout/                 |             |
|    ep_len_mean           | 208         |
|    ep_rew_mean           | -74.9       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 29          |
|    time_elapsed          | 880         |
|    total_timesteps       | 962560      |
| train/                   |             |
|    approx_kl             | 0.009842046 |
|    clip_fraction         | 0.116       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.73        |
|    cost_value_loss       | 13          |
|    cost_values           | 2.94        |
|    entropy               | -1.58       |
|    entropy_loss          | -1.59       |
|    explained_variance    | 0.498       |
|    lagrangian_multiplier | 0.00492     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.32        |
|    n_updates             | 4690        |
|    policy_gradient_loss  | -0.00364    |
|    std                   | 0.562       |
|    value_loss            | 9.22        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.25450128  |
| rollout/                 |              |
|    ep_len_mean           | 215          |
|    ep_rew_mean           | -76.8        |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 30           |
|    time_elapsed          | 910          |
|    total_timesteps       | 964608       |
| train/                   |              |
|    approx_kl             | 0.0063481694 |
|    clip_fraction         | 0.0921       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.16         |
|    cost_value_loss       | 14.3         |
|    cost_values           | 2.97         |
|    entropy               | -1.58        |
|    entropy_loss          | -1.58        |
|    explained_variance    | 0.399        |
|    lagrangian_multiplier | 0.00514      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.06         |
|    n_updates             | 4700         |
|    policy_gradient_loss  | -0.00584     |
|    std                   | 0.56         |
|    value_loss            | 16.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.99        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.99        |
| reward                   | -0.2998978  |
| rollout/                 |             |
|    ep_len_mean           | 220         |
|    ep_rew_mean           | -78.2       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 31          |
|    time_elapsed          | 943         |
|    total_timesteps       | 966656      |
| train/                   |             |
|    approx_kl             | 0.007846259 |
|    clip_fraction         | 0.0912      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.55        |
|    cost_value_loss       | 18          |
|    cost_values           | 2.98        |
|    entropy               | -1.57       |
|    entropy_loss          | -1.57       |
|    explained_variance    | 0.462       |
|    lagrangian_multiplier | 0.00634     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.86        |
|    n_updates             | 4710        |
|    policy_gradient_loss  | -0.00295    |
|    std                   | 0.559       |
|    value_loss            | 12          |
------------------------------------------
-----------------------------------------
| avg_speed                | 7.95       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.95       |
| reward                   | -0.2982765 |
| rollout/                 |            |
|    ep_len_mean           | 212        |
|    ep_rew_mean           | -76.2      |
| time/                    |            |
|    fps                   | 67         |
|    iterations            | 32         |
|    time_elapsed          | 977        |
|    total_timesteps       | 968704     |
| train/                   |            |
|    approx_kl             | 0.01587456 |
|    clip_fraction         | 0.102      |
|    clip_range            | 0.2        |
|    cost_returns          | 6.61       |
|    cost_value_loss       | 17.1       |
|    cost_values           | 2.98       |
|    entropy               | -1.57      |
|    entropy_loss          | -1.57      |
|    explained_variance    | 0.349      |
|    lagrangian_multiplier | 0.00542    |
|    learning_rate         | 0.0003     |
|    loss                  | 5.74       |
|    n_updates             | 4720       |
|    policy_gradient_loss  | -0.00507   |
|    std                   | 0.558      |
|    value_loss            | 13.9       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.3694667  |
| rollout/                 |             |
|    ep_len_mean           | 218         |
|    ep_rew_mean           | -77.5       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 33          |
|    time_elapsed          | 1014        |
|    total_timesteps       | 970752      |
| train/                   |             |
|    approx_kl             | 0.008636898 |
|    clip_fraction         | 0.0854      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.23        |
|    cost_value_loss       | 15.8        |
|    cost_values           | 2.97        |
|    entropy               | -1.56       |
|    entropy_loss          | -1.57       |
|    explained_variance    | 0.491       |
|    lagrangian_multiplier | 0.00504     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.48        |
|    n_updates             | 4730        |
|    policy_gradient_loss  | -0.00289    |
|    std                   | 0.557       |
|    value_loss            | 17.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.7441222  |
| rollout/                 |             |
|    ep_len_mean           | 207         |
|    ep_rew_mean           | -74.2       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 34          |
|    time_elapsed          | 1052        |
|    total_timesteps       | 972800      |
| train/                   |             |
|    approx_kl             | 0.010155074 |
|    clip_fraction         | 0.133       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.09        |
|    cost_value_loss       | 13.3        |
|    cost_values           | 2.98        |
|    entropy               | -1.55       |
|    entropy_loss          | -1.56       |
|    explained_variance    | 0.405       |
|    lagrangian_multiplier | 0.0046      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.41        |
|    n_updates             | 4740        |
|    policy_gradient_loss  | -0.00476    |
|    std                   | 0.556       |
|    value_loss            | 14.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.18946724 |
| rollout/                 |             |
|    ep_len_mean           | 205         |
|    ep_rew_mean           | -73.4       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 35          |
|    time_elapsed          | 1088        |
|    total_timesteps       | 974848      |
| train/                   |             |
|    approx_kl             | 0.008965189 |
|    clip_fraction         | 0.133       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.08        |
|    cost_value_loss       | 15.9        |
|    cost_values           | 2.96        |
|    entropy               | -1.54       |
|    entropy_loss          | -1.55       |
|    explained_variance    | 0.566       |
|    lagrangian_multiplier | 0.0061      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.79        |
|    n_updates             | 4750        |
|    policy_gradient_loss  | -0.0069     |
|    std                   | 0.552       |
|    value_loss            | 14.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.33606187 |
| rollout/                 |             |
|    ep_len_mean           | 200         |
|    ep_rew_mean           | -71.1       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 36          |
|    time_elapsed          | 1127        |
|    total_timesteps       | 976896      |
| train/                   |             |
|    approx_kl             | 0.010514269 |
|    clip_fraction         | 0.0955      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.15        |
|    cost_value_loss       | 14.7        |
|    cost_values           | 2.98        |
|    entropy               | -1.53       |
|    entropy_loss          | -1.53       |
|    explained_variance    | 0.503       |
|    lagrangian_multiplier | 0.00342     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.88        |
|    n_updates             | 4760        |
|    policy_gradient_loss  | -0.00414    |
|    std                   | 0.548       |
|    value_loss            | 12.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.22235118 |
| rollout/                 |             |
|    ep_len_mean           | 192         |
|    ep_rew_mean           | -68         |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 37          |
|    time_elapsed          | 1162        |
|    total_timesteps       | 978944      |
| train/                   |             |
|    approx_kl             | 0.008385818 |
|    clip_fraction         | 0.113       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.03        |
|    cost_value_loss       | 13.4        |
|    cost_values           | 2.97        |
|    entropy               | -1.52       |
|    entropy_loss          | -1.52       |
|    explained_variance    | 0.508       |
|    lagrangian_multiplier | 0.0068      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.05        |
|    n_updates             | 4770        |
|    policy_gradient_loss  | -0.00378    |
|    std                   | 0.546       |
|    value_loss            | 12.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.7977021  |
| rollout/                 |             |
|    ep_len_mean           | 191         |
|    ep_rew_mean           | -67         |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 38          |
|    time_elapsed          | 1196        |
|    total_timesteps       | 980992      |
| train/                   |             |
|    approx_kl             | 0.008132118 |
|    clip_fraction         | 0.0982      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.3         |
|    cost_value_loss       | 14.9        |
|    cost_values           | 2.99        |
|    entropy               | -1.51       |
|    entropy_loss          | -1.52       |
|    explained_variance    | 0.404       |
|    lagrangian_multiplier | 0.00697     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.31        |
|    n_updates             | 4780        |
|    policy_gradient_loss  | -0.00419    |
|    std                   | 0.545       |
|    value_loss            | 12.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.310481   |
| rollout/                 |             |
|    ep_len_mean           | 196         |
|    ep_rew_mean           | -68         |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 39          |
|    time_elapsed          | 1232        |
|    total_timesteps       | 983040      |
| train/                   |             |
|    approx_kl             | 0.007631802 |
|    clip_fraction         | 0.121       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.76        |
|    cost_value_loss       | 12.3        |
|    cost_values           | 2.98        |
|    entropy               | -1.5        |
|    entropy_loss          | -1.51       |
|    explained_variance    | 0.436       |
|    lagrangian_multiplier | 0.00384     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.79        |
|    n_updates             | 4790        |
|    policy_gradient_loss  | -0.00385    |
|    std                   | 0.542       |
|    value_loss            | 15.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.13731971 |
| rollout/                 |             |
|    ep_len_mean           | 181         |
|    ep_rew_mean           | -63.8       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 40          |
|    time_elapsed          | 1268        |
|    total_timesteps       | 985088      |
| train/                   |             |
|    approx_kl             | 0.009119069 |
|    clip_fraction         | 0.121       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.09        |
|    cost_value_loss       | 13.4        |
|    cost_values           | 2.99        |
|    entropy               | -1.49       |
|    entropy_loss          | -1.5        |
|    explained_variance    | 0.579       |
|    lagrangian_multiplier | 0.00489     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.04        |
|    n_updates             | 4800        |
|    policy_gradient_loss  | -0.00569    |
|    std                   | 0.539       |
|    value_loss            | 7.8         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.40458068 |
| rollout/                 |             |
|    ep_len_mean           | 187         |
|    ep_rew_mean           | -65         |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 41          |
|    time_elapsed          | 1304        |
|    total_timesteps       | 987136      |
| train/                   |             |
|    approx_kl             | 0.007013322 |
|    clip_fraction         | 0.107       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.89        |
|    cost_value_loss       | 13.3        |
|    cost_values           | 2.95        |
|    entropy               | -1.49       |
|    entropy_loss          | -1.49       |
|    explained_variance    | 0.557       |
|    lagrangian_multiplier | 0.00319     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.94        |
|    n_updates             | 4810        |
|    policy_gradient_loss  | -0.00539    |
|    std                   | 0.538       |
|    value_loss            | 16.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2            |
| reward                   | -0.86145884  |
| rollout/                 |              |
|    ep_len_mean           | 185          |
|    ep_rew_mean           | -64.8        |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 42           |
|    time_elapsed          | 1332         |
|    total_timesteps       | 989184       |
| train/                   |              |
|    approx_kl             | 0.0077605387 |
|    clip_fraction         | 0.117        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.98         |
|    cost_value_loss       | 12.5         |
|    cost_values           | 2.96         |
|    entropy               | -1.48        |
|    entropy_loss          | -1.48        |
|    explained_variance    | 0.587        |
|    lagrangian_multiplier | 0.0057       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.02         |
|    n_updates             | 4820         |
|    policy_gradient_loss  | -0.00502     |
|    std                   | 0.537        |
|    value_loss            | 9.3          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.2914394  |
| rollout/                 |             |
|    ep_len_mean           | 183         |
|    ep_rew_mean           | -63.8       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 43          |
|    time_elapsed          | 1357        |
|    total_timesteps       | 991232      |
| train/                   |             |
|    approx_kl             | 0.014750776 |
|    clip_fraction         | 0.177       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.99        |
|    cost_value_loss       | 13.2        |
|    cost_values           | 2.96        |
|    entropy               | -1.48       |
|    entropy_loss          | -1.48       |
|    explained_variance    | 0.612       |
|    lagrangian_multiplier | 0.00634     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.9         |
|    n_updates             | 4830        |
|    policy_gradient_loss  | 0.00133     |
|    std                   | 0.537       |
|    value_loss            | 12.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.35130066 |
| rollout/                 |             |
|    ep_len_mean           | 187         |
|    ep_rew_mean           | -65         |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 44          |
|    time_elapsed          | 1383        |
|    total_timesteps       | 993280      |
| train/                   |             |
|    approx_kl             | 0.009779952 |
|    clip_fraction         | 0.0885      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.72        |
|    cost_value_loss       | 11.9        |
|    cost_values           | 2.94        |
|    entropy               | -1.47       |
|    entropy_loss          | -1.47       |
|    explained_variance    | 0.618       |
|    lagrangian_multiplier | 0.00556     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.38        |
|    n_updates             | 4840        |
|    policy_gradient_loss  | -0.0047     |
|    std                   | 0.536       |
|    value_loss            | 12.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.15        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.15        |
| reward                   | -0.63809115 |
| rollout/                 |             |
|    ep_len_mean           | 180         |
|    ep_rew_mean           | -62.9       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 45          |
|    time_elapsed          | 1411        |
|    total_timesteps       | 995328      |
| train/                   |             |
|    approx_kl             | 0.007031749 |
|    clip_fraction         | 0.0854      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.92        |
|    cost_value_loss       | 12.8        |
|    cost_values           | 2.96        |
|    entropy               | -1.46       |
|    entropy_loss          | -1.46       |
|    explained_variance    | 0.61        |
|    lagrangian_multiplier | 0.00337     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.84        |
|    n_updates             | 4850        |
|    policy_gradient_loss  | -0.00248    |
|    std                   | 0.534       |
|    value_loss            | 9.66        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.5904854  |
| rollout/                 |             |
|    ep_len_mean           | 180         |
|    ep_rew_mean           | -63.7       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 46          |
|    time_elapsed          | 1434        |
|    total_timesteps       | 997376      |
| train/                   |             |
|    approx_kl             | 0.004615777 |
|    clip_fraction         | 0.058       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.65        |
|    cost_value_loss       | 11.4        |
|    cost_values           | 2.95        |
|    entropy               | -1.46       |
|    entropy_loss          | -1.46       |
|    explained_variance    | 0.595       |
|    lagrangian_multiplier | 0.00472     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.96        |
|    n_updates             | 4860        |
|    policy_gradient_loss  | -0.0035     |
|    std                   | 0.533       |
|    value_loss            | 14.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.20189008  |
| rollout/                 |              |
|    ep_len_mean           | 166          |
|    ep_rew_mean           | -59.7        |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 47           |
|    time_elapsed          | 1458         |
|    total_timesteps       | 999424       |
| train/                   |              |
|    approx_kl             | 0.0072020814 |
|    clip_fraction         | 0.0838       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.68         |
|    cost_value_loss       | 11.8         |
|    cost_values           | 2.9          |
|    entropy               | -1.45        |
|    entropy_loss          | -1.45        |
|    explained_variance    | 0.589        |
|    lagrangian_multiplier | 0.00518      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.2          |
|    n_updates             | 4870         |
|    policy_gradient_loss  | -0.00314     |
|    std                   | 0.532        |
|    value_loss            | 11.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.15617579 |
| rollout/                 |             |
|    ep_len_mean           | 169         |
|    ep_rew_mean           | -60.4       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 48          |
|    time_elapsed          | 1487        |
|    total_timesteps       | 1001472     |
| train/                   |             |
|    approx_kl             | 0.009900656 |
|    clip_fraction         | 0.0983      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.56        |
|    cost_value_loss       | 11.2        |
|    cost_values           | 2.94        |
|    entropy               | -1.44       |
|    entropy_loss          | -1.45       |
|    explained_variance    | 0.544       |
|    lagrangian_multiplier | 0.00255     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.76        |
|    n_updates             | 4880        |
|    policy_gradient_loss  | -0.00281    |
|    std                   | 0.531       |
|    value_loss            | 12.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.3         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.3         |
| reward                   | -0.5168216  |
| rollout/                 |             |
|    ep_len_mean           | 165         |
|    ep_rew_mean           | -59         |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 49          |
|    time_elapsed          | 1520        |
|    total_timesteps       | 1003520     |
| train/                   |             |
|    approx_kl             | 0.008970374 |
|    clip_fraction         | 0.123       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.87        |
|    cost_value_loss       | 11.9        |
|    cost_values           | 2.94        |
|    entropy               | -1.44       |
|    entropy_loss          | -1.44       |
|    explained_variance    | 0.528       |
|    lagrangian_multiplier | 0.00486     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.89        |
|    n_updates             | 4890        |
|    policy_gradient_loss  | -0.00333    |
|    std                   | 0.53        |
|    value_loss            | 13.5        |
------------------------------------------
------------------------------------
| avg_speed          | 8.03        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8.03        |
| reward             | -0.19465101 |
| rollout/           |             |
|    ep_len_mean     | 161         |
|    ep_rew_mean     | -58         |
| time/              |             |
|    fps             | 92          |
|    iterations      | 1           |
|    time_elapsed    | 22          |
|    total_timesteps | 1005568     |
------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.28477734 |
| rollout/                 |             |
|    ep_len_mean           | 160         |
|    ep_rew_mean           | -57.7       |
| time/                    |             |
|    fps                   | 90          |
|    iterations            | 2           |
|    time_elapsed          | 45          |
|    total_timesteps       | 1007616     |
| train/                   |             |
|    approx_kl             | 0.007367287 |
|    clip_fraction         | 0.108       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.07        |
|    cost_value_loss       | 9.08        |
|    cost_values           | 2.87        |
|    entropy               | -1.41       |
|    entropy_loss          | -1.42       |
|    explained_variance    | 0.558       |
|    lagrangian_multiplier | 0.00312     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.6         |
|    n_updates             | 4910        |
|    policy_gradient_loss  | -0.00125    |
|    std                   | 0.523       |
|    value_loss            | 13.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.40707317 |
| rollout/                 |             |
|    ep_len_mean           | 151         |
|    ep_rew_mean           | -55.1       |
| time/                    |             |
|    fps                   | 83          |
|    iterations            | 3           |
|    time_elapsed          | 73          |
|    total_timesteps       | 1009664     |
| train/                   |             |
|    approx_kl             | 0.012064506 |
|    clip_fraction         | 0.0731      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.92        |
|    cost_value_loss       | 8.52        |
|    cost_values           | 2.87        |
|    entropy               | -1.41       |
|    entropy_loss          | -1.41       |
|    explained_variance    | 0.594       |
|    lagrangian_multiplier | 0.00241     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.87        |
|    n_updates             | 4920        |
|    policy_gradient_loss  | -0.00312    |
|    std                   | 0.522       |
|    value_loss            | 15          |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2405946  |
| rollout/                 |             |
|    ep_len_mean           | 144         |
|    ep_rew_mean           | -52.9       |
| time/                    |             |
|    fps                   | 78          |
|    iterations            | 4           |
|    time_elapsed          | 103         |
|    total_timesteps       | 1011712     |
| train/                   |             |
|    approx_kl             | 0.008061097 |
|    clip_fraction         | 0.101       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.53        |
|    cost_value_loss       | 11.1        |
|    cost_values           | 2.89        |
|    entropy               | -1.41       |
|    entropy_loss          | -1.41       |
|    explained_variance    | 0.653       |
|    lagrangian_multiplier | 0.00283     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.75        |
|    n_updates             | 4930        |
|    policy_gradient_loss  | -0.00231    |
|    std                   | 0.521       |
|    value_loss            | 13.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.2337452  |
| rollout/                 |             |
|    ep_len_mean           | 142         |
|    ep_rew_mean           | -52.4       |
| time/                    |             |
|    fps                   | 75          |
|    iterations            | 5           |
|    time_elapsed          | 136         |
|    total_timesteps       | 1013760     |
| train/                   |             |
|    approx_kl             | 0.008124006 |
|    clip_fraction         | 0.0905      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.2         |
|    cost_value_loss       | 10.4        |
|    cost_values           | 2.89        |
|    entropy               | -1.4        |
|    entropy_loss          | -1.4        |
|    explained_variance    | 0.498       |
|    lagrangian_multiplier | 0.00376     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.78        |
|    n_updates             | 4940        |
|    policy_gradient_loss  | -0.00504    |
|    std                   | 0.519       |
|    value_loss            | 13.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.39439133 |
| rollout/                 |             |
|    ep_len_mean           | 137         |
|    ep_rew_mean           | -51.3       |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 6           |
|    time_elapsed          | 168         |
|    total_timesteps       | 1015808     |
| train/                   |             |
|    approx_kl             | 0.006885505 |
|    clip_fraction         | 0.0716      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.55        |
|    cost_value_loss       | 11.5        |
|    cost_values           | 2.92        |
|    entropy               | -1.39       |
|    entropy_loss          | -1.4        |
|    explained_variance    | 0.591       |
|    lagrangian_multiplier | 0.00537     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.72        |
|    n_updates             | 4950        |
|    policy_gradient_loss  | -0.00143    |
|    std                   | 0.518       |
|    value_loss            | 12.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -0.28913188  |
| rollout/                 |              |
|    ep_len_mean           | 135          |
|    ep_rew_mean           | -50.9        |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 7            |
|    time_elapsed          | 198          |
|    total_timesteps       | 1017856      |
| train/                   |              |
|    approx_kl             | 0.0055841096 |
|    clip_fraction         | 0.071        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.47         |
|    cost_value_loss       | 11           |
|    cost_values           | 2.92         |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 0.598        |
|    lagrangian_multiplier | 0.00232      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.21         |
|    n_updates             | 4960         |
|    policy_gradient_loss  | -0.00287     |
|    std                   | 0.518        |
|    value_loss            | 13.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7            |
| reward                   | -0.5216697   |
| rollout/                 |              |
|    ep_len_mean           | 139          |
|    ep_rew_mean           | -51.9        |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 8            |
|    time_elapsed          | 228          |
|    total_timesteps       | 1019904      |
| train/                   |              |
|    approx_kl             | 0.0095072165 |
|    clip_fraction         | 0.0747       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.97         |
|    cost_value_loss       | 13.4         |
|    cost_values           | 2.95         |
|    entropy               | -1.39        |
|    entropy_loss          | -1.39        |
|    explained_variance    | 0.53         |
|    lagrangian_multiplier | 0.00703      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.02         |
|    n_updates             | 4970         |
|    policy_gradient_loss  | -0.00166     |
|    std                   | 0.517        |
|    value_loss            | 10.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.2862523   |
| rollout/                 |              |
|    ep_len_mean           | 139          |
|    ep_rew_mean           | -52          |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 9            |
|    time_elapsed          | 258          |
|    total_timesteps       | 1021952      |
| train/                   |              |
|    approx_kl             | 0.0046333075 |
|    clip_fraction         | 0.0963       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.55         |
|    cost_value_loss       | 10.8         |
|    cost_values           | 2.93         |
|    entropy               | -1.38        |
|    entropy_loss          | -1.38        |
|    explained_variance    | 0.58         |
|    lagrangian_multiplier | 0.00359      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.4          |
|    n_updates             | 4980         |
|    policy_gradient_loss  | -0.00166     |
|    std                   | 0.514        |
|    value_loss            | 9.5          |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8.02       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.02       |
| reward                   | -0.3744687 |
| rollout/                 |            |
|    ep_len_mean           | 141        |
|    ep_rew_mean           | -52.3      |
| time/                    |            |
|    fps                   | 71         |
|    iterations            | 10         |
|    time_elapsed          | 286        |
|    total_timesteps       | 1024000    |
| train/                   |            |
|    approx_kl             | 0.01056867 |
|    clip_fraction         | 0.111      |
|    clip_range            | 0.2        |
|    cost_returns          | 5.56       |
|    cost_value_loss       | 11.1       |
|    cost_values           | 2.9        |
|    entropy               | -1.37      |
|    entropy_loss          | -1.37      |
|    explained_variance    | 0.589      |
|    lagrangian_multiplier | 0.00366    |
|    learning_rate         | 0.0003     |
|    loss                  | 6.5        |
|    n_updates             | 4990       |
|    policy_gradient_loss  | -0.00515   |
|    std                   | 0.511      |
|    value_loss            | 13.6       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.2288157   |
| rollout/                 |              |
|    ep_len_mean           | 151          |
|    ep_rew_mean           | -54.8        |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 11           |
|    time_elapsed          | 312          |
|    total_timesteps       | 1026048      |
| train/                   |              |
|    approx_kl             | 0.0071101002 |
|    clip_fraction         | 0.0948       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.89         |
|    cost_value_loss       | 13.1         |
|    cost_values           | 2.94         |
|    entropy               | -1.36        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 0.515        |
|    lagrangian_multiplier | 0.00429      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.74         |
|    n_updates             | 5000         |
|    policy_gradient_loss  | -0.00262     |
|    std                   | 0.509        |
|    value_loss            | 12.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.33480012  |
| rollout/                 |              |
|    ep_len_mean           | 150          |
|    ep_rew_mean           | -54.4        |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 12           |
|    time_elapsed          | 338          |
|    total_timesteps       | 1028096      |
| train/                   |              |
|    approx_kl             | 0.0101135215 |
|    clip_fraction         | 0.102        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.53         |
|    cost_value_loss       | 16.1         |
|    cost_values           | 2.98         |
|    entropy               | -1.35        |
|    entropy_loss          | -1.36        |
|    explained_variance    | 0.433        |
|    lagrangian_multiplier | 0.00554      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.49         |
|    n_updates             | 5010         |
|    policy_gradient_loss  | -0.00204     |
|    std                   | 0.508        |
|    value_loss            | 9.22         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3604633  |
| rollout/                 |             |
|    ep_len_mean           | 156         |
|    ep_rew_mean           | -56.4       |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 13          |
|    time_elapsed          | 367         |
|    total_timesteps       | 1030144     |
| train/                   |             |
|    approx_kl             | 0.008087227 |
|    clip_fraction         | 0.119       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.84        |
|    cost_value_loss       | 12.3        |
|    cost_values           | 2.97        |
|    entropy               | -1.34       |
|    entropy_loss          | -1.35       |
|    explained_variance    | 0.464       |
|    lagrangian_multiplier | 0.00513     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.68        |
|    n_updates             | 5020        |
|    policy_gradient_loss  | -0.000871   |
|    std                   | 0.507       |
|    value_loss            | 13.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.27651995 |
| rollout/                 |             |
|    ep_len_mean           | 165         |
|    ep_rew_mean           | -59.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 14          |
|    time_elapsed          | 403         |
|    total_timesteps       | 1032192     |
| train/                   |             |
|    approx_kl             | 0.020888077 |
|    clip_fraction         | 0.116       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.73        |
|    cost_value_loss       | 12.8        |
|    cost_values           | 2.93        |
|    entropy               | -1.34       |
|    entropy_loss          | -1.34       |
|    explained_variance    | 0.564       |
|    lagrangian_multiplier | 0.00387     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.27        |
|    n_updates             | 5030        |
|    policy_gradient_loss  | -0.00168    |
|    std                   | 0.506       |
|    value_loss            | 14.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.2959064  |
| rollout/                 |             |
|    ep_len_mean           | 167         |
|    ep_rew_mean           | -60         |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 15          |
|    time_elapsed          | 441         |
|    total_timesteps       | 1034240     |
| train/                   |             |
|    approx_kl             | 0.007909401 |
|    clip_fraction         | 0.142       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.94        |
|    cost_value_loss       | 13.4        |
|    cost_values           | 2.97        |
|    entropy               | -1.33       |
|    entropy_loss          | -1.34       |
|    explained_variance    | 0.465       |
|    lagrangian_multiplier | 0.00419     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.61        |
|    n_updates             | 5040        |
|    policy_gradient_loss  | -0.000939   |
|    std                   | 0.503       |
|    value_loss            | 11.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.29142755 |
| rollout/                 |             |
|    ep_len_mean           | 161         |
|    ep_rew_mean           | -57.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 16          |
|    time_elapsed          | 475         |
|    total_timesteps       | 1036288     |
| train/                   |             |
|    approx_kl             | 0.015031761 |
|    clip_fraction         | 0.118       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.9         |
|    cost_value_loss       | 11.9        |
|    cost_values           | 2.97        |
|    entropy               | -1.32       |
|    entropy_loss          | -1.32       |
|    explained_variance    | 0.517       |
|    lagrangian_multiplier | 0.00376     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.93        |
|    n_updates             | 5050        |
|    policy_gradient_loss  | -0.00298    |
|    std                   | 0.501       |
|    value_loss            | 12.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.49        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.49        |
| reward                   | -0.268415   |
| rollout/                 |             |
|    ep_len_mean           | 163         |
|    ep_rew_mean           | -58.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 17          |
|    time_elapsed          | 507         |
|    total_timesteps       | 1038336     |
| train/                   |             |
|    approx_kl             | 0.007684919 |
|    clip_fraction         | 0.103       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.53        |
|    cost_value_loss       | 9.76        |
|    cost_values           | 2.95        |
|    entropy               | -1.32       |
|    entropy_loss          | -1.32       |
|    explained_variance    | 0.483       |
|    lagrangian_multiplier | 0.00684     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.89        |
|    n_updates             | 5060        |
|    policy_gradient_loss  | -0.0026     |
|    std                   | 0.5         |
|    value_loss            | 12.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.25628287  |
| rollout/                 |              |
|    ep_len_mean           | 167          |
|    ep_rew_mean           | -59.3        |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 18           |
|    time_elapsed          | 541          |
|    total_timesteps       | 1040384      |
| train/                   |              |
|    approx_kl             | 0.0069686268 |
|    clip_fraction         | 0.097        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.54         |
|    cost_value_loss       | 11.3         |
|    cost_values           | 2.91         |
|    entropy               | -1.31        |
|    entropy_loss          | -1.31        |
|    explained_variance    | 0.528        |
|    lagrangian_multiplier | 0.0048       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.68         |
|    n_updates             | 5070         |
|    policy_gradient_loss  | -0.00174     |
|    std                   | 0.499        |
|    value_loss            | 13.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.36972463 |
| rollout/                 |             |
|    ep_len_mean           | 160         |
|    ep_rew_mean           | -57.2       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 19          |
|    time_elapsed          | 581         |
|    total_timesteps       | 1042432     |
| train/                   |             |
|    approx_kl             | 0.008206508 |
|    clip_fraction         | 0.0753      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.16        |
|    cost_value_loss       | 13.9        |
|    cost_values           | 2.94        |
|    entropy               | -1.3        |
|    entropy_loss          | -1.31       |
|    explained_variance    | 0.58        |
|    lagrangian_multiplier | 0.00597     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.39        |
|    n_updates             | 5080        |
|    policy_gradient_loss  | -0.00261    |
|    std                   | 0.497       |
|    value_loss            | 11.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.34        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.34        |
| reward                   | -0.47606534 |
| rollout/                 |             |
|    ep_len_mean           | 156         |
|    ep_rew_mean           | -55.7       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 20          |
|    time_elapsed          | 613         |
|    total_timesteps       | 1044480     |
| train/                   |             |
|    approx_kl             | 0.007927766 |
|    clip_fraction         | 0.084       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.8         |
|    cost_value_loss       | 12.2        |
|    cost_values           | 2.93        |
|    entropy               | -1.28       |
|    entropy_loss          | -1.29       |
|    explained_variance    | 0.578       |
|    lagrangian_multiplier | 0.00893     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.55        |
|    n_updates             | 5090        |
|    policy_gradient_loss  | -0.00496    |
|    std                   | 0.492       |
|    value_loss            | 12          |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.39098012 |
| rollout/                 |             |
|    ep_len_mean           | 160         |
|    ep_rew_mean           | -56.4       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 21          |
|    time_elapsed          | 643         |
|    total_timesteps       | 1046528     |
| train/                   |             |
|    approx_kl             | 0.008299714 |
|    clip_fraction         | 0.0806      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.85        |
|    cost_value_loss       | 12.5        |
|    cost_values           | 2.93        |
|    entropy               | -1.28       |
|    entropy_loss          | -1.28       |
|    explained_variance    | 0.601       |
|    lagrangian_multiplier | 0.00416     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.04        |
|    n_updates             | 5100        |
|    policy_gradient_loss  | -0.00332    |
|    std                   | 0.491       |
|    value_loss            | 12.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.5571982  |
| rollout/                 |             |
|    ep_len_mean           | 160         |
|    ep_rew_mean           | -56.2       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 22          |
|    time_elapsed          | 667         |
|    total_timesteps       | 1048576     |
| train/                   |             |
|    approx_kl             | 0.013408054 |
|    clip_fraction         | 0.107       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.01        |
|    cost_value_loss       | 13.4        |
|    cost_values           | 2.95        |
|    entropy               | -1.27       |
|    entropy_loss          | -1.28       |
|    explained_variance    | 0.609       |
|    lagrangian_multiplier | 0.00363     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.18        |
|    n_updates             | 5110        |
|    policy_gradient_loss  | -0.00105    |
|    std                   | 0.489       |
|    value_loss            | 10.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.2         |
| reward                   | -0.2271581  |
| rollout/                 |             |
|    ep_len_mean           | 164         |
|    ep_rew_mean           | -57         |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 23          |
|    time_elapsed          | 690         |
|    total_timesteps       | 1050624     |
| train/                   |             |
|    approx_kl             | 0.012242233 |
|    clip_fraction         | 0.102       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.22        |
|    cost_value_loss       | 14.7        |
|    cost_values           | 2.97        |
|    entropy               | -1.26       |
|    entropy_loss          | -1.27       |
|    explained_variance    | 0.552       |
|    lagrangian_multiplier | 0.00562     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.14        |
|    n_updates             | 5120        |
|    policy_gradient_loss  | -0.00113    |
|    std                   | 0.488       |
|    value_loss            | 9.41        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.7504839  |
| rollout/                 |             |
|    ep_len_mean           | 160         |
|    ep_rew_mean           | -55.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 24          |
|    time_elapsed          | 713         |
|    total_timesteps       | 1052672     |
| train/                   |             |
|    approx_kl             | 0.007555572 |
|    clip_fraction         | 0.0787      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.73        |
|    cost_value_loss       | 10.8        |
|    cost_values           | 2.98        |
|    entropy               | -1.26       |
|    entropy_loss          | -1.26       |
|    explained_variance    | 0.44        |
|    lagrangian_multiplier | 0.00592     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.68        |
|    n_updates             | 5130        |
|    policy_gradient_loss  | -0.00394    |
|    std                   | 0.487       |
|    value_loss            | 10.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.76        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.76        |
| reward                   | -0.287536   |
| rollout/                 |             |
|    ep_len_mean           | 157         |
|    ep_rew_mean           | -54.9       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 25          |
|    time_elapsed          | 736         |
|    total_timesteps       | 1054720     |
| train/                   |             |
|    approx_kl             | 0.007820772 |
|    clip_fraction         | 0.0952      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.07        |
|    cost_value_loss       | 14.2        |
|    cost_values           | 2.95        |
|    entropy               | -1.25       |
|    entropy_loss          | -1.25       |
|    explained_variance    | 0.57        |
|    lagrangian_multiplier | 0.00362     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.52        |
|    n_updates             | 5140        |
|    policy_gradient_loss  | -0.0052     |
|    std                   | 0.485       |
|    value_loss            | 13          |
------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.79782593 |
| rollout/                 |             |
|    ep_len_mean           | 157         |
|    ep_rew_mean           | -55.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 26          |
|    time_elapsed          | 759         |
|    total_timesteps       | 1056768     |
| train/                   |             |
|    approx_kl             | 0.009997445 |
|    clip_fraction         | 0.126       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.34        |
|    cost_value_loss       | 9.57        |
|    cost_values           | 2.94        |
|    entropy               | -1.25       |
|    entropy_loss          | -1.25       |
|    explained_variance    | 0.535       |
|    lagrangian_multiplier | 0.0027      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.13        |
|    n_updates             | 5150        |
|    policy_gradient_loss  | -0.00281    |
|    std                   | 0.486       |
|    value_loss            | 13.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.33921573 |
| rollout/                 |             |
|    ep_len_mean           | 156         |
|    ep_rew_mean           | -54.9       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 27          |
|    time_elapsed          | 782         |
|    total_timesteps       | 1058816     |
| train/                   |             |
|    approx_kl             | 0.008423212 |
|    clip_fraction         | 0.107       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.31        |
|    cost_value_loss       | 11.1        |
|    cost_values           | 2.92        |
|    entropy               | -1.24       |
|    entropy_loss          | -1.25       |
|    explained_variance    | 0.577       |
|    lagrangian_multiplier | 0.00308     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.87        |
|    n_updates             | 5160        |
|    policy_gradient_loss  | -0.00408    |
|    std                   | 0.485       |
|    value_loss            | 11.4        |
------------------------------------------
-----------------------------------------
| avg_speed                | 4          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 4          |
| reward                   | -0.4560559 |
| rollout/                 |            |
|    ep_len_mean           | 154        |
|    ep_rew_mean           | -54        |
| time/                    |            |
|    fps                   | 70         |
|    iterations            | 28         |
|    time_elapsed          | 808        |
|    total_timesteps       | 1060864    |
| train/                   |            |
|    approx_kl             | 0.01097599 |
|    clip_fraction         | 0.105      |
|    clip_range            | 0.2        |
|    cost_returns          | 5.55       |
|    cost_value_loss       | 11.1       |
|    cost_values           | 2.94       |
|    entropy               | -1.24      |
|    entropy_loss          | -1.24      |
|    explained_variance    | 0.577      |
|    lagrangian_multiplier | 0.00555    |
|    learning_rate         | 0.0003     |
|    loss                  | 5.15       |
|    n_updates             | 5170       |
|    policy_gradient_loss  | -0.0044    |
|    std                   | 0.486      |
|    value_loss            | 11.1       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.23697479 |
| rollout/                 |             |
|    ep_len_mean           | 153         |
|    ep_rew_mean           | -53.6       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 29          |
|    time_elapsed          | 834         |
|    total_timesteps       | 1062912     |
| train/                   |             |
|    approx_kl             | 0.011141462 |
|    clip_fraction         | 0.0801      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.55        |
|    cost_value_loss       | 10.9        |
|    cost_values           | 2.92        |
|    entropy               | -1.24       |
|    entropy_loss          | -1.24       |
|    explained_variance    | 0.587       |
|    lagrangian_multiplier | 0.00279     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.26        |
|    n_updates             | 5180        |
|    policy_gradient_loss  | -0.00262    |
|    std                   | 0.485       |
|    value_loss            | 12.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.25361514 |
| rollout/                 |             |
|    ep_len_mean           | 156         |
|    ep_rew_mean           | -54.7       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 30          |
|    time_elapsed          | 865         |
|    total_timesteps       | 1064960     |
| train/                   |             |
|    approx_kl             | 0.005814491 |
|    clip_fraction         | 0.0828      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.18        |
|    cost_value_loss       | 14.6        |
|    cost_values           | 2.95        |
|    entropy               | -1.23       |
|    entropy_loss          | -1.23       |
|    explained_variance    | 0.573       |
|    lagrangian_multiplier | 0.00487     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.59        |
|    n_updates             | 5190        |
|    policy_gradient_loss  | -0.00229    |
|    std                   | 0.482       |
|    value_loss            | 10.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3075504  |
| rollout/                 |             |
|    ep_len_mean           | 155         |
|    ep_rew_mean           | -54.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 31          |
|    time_elapsed          | 899         |
|    total_timesteps       | 1067008     |
| train/                   |             |
|    approx_kl             | 0.010776125 |
|    clip_fraction         | 0.115       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.25        |
|    cost_value_loss       | 14.5        |
|    cost_values           | 2.96        |
|    entropy               | -1.22       |
|    entropy_loss          | -1.22       |
|    explained_variance    | 0.568       |
|    lagrangian_multiplier | 0.00797     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.57        |
|    n_updates             | 5200        |
|    policy_gradient_loss  | -0.000189   |
|    std                   | 0.48        |
|    value_loss            | 7.74        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.93        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.93        |
| reward                   | -0.8186065  |
| rollout/                 |             |
|    ep_len_mean           | 157         |
|    ep_rew_mean           | -54.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 32          |
|    time_elapsed          | 927         |
|    total_timesteps       | 1069056     |
| train/                   |             |
|    approx_kl             | 0.008637529 |
|    clip_fraction         | 0.0927      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.46        |
|    cost_value_loss       | 10.1        |
|    cost_values           | 2.95        |
|    entropy               | -1.21       |
|    entropy_loss          | -1.22       |
|    explained_variance    | 0.519       |
|    lagrangian_multiplier | 0.00318     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.55        |
|    n_updates             | 5210        |
|    policy_gradient_loss  | -0.00355    |
|    std                   | 0.479       |
|    value_loss            | 12          |
------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.8682859  |
| rollout/                 |             |
|    ep_len_mean           | 149         |
|    ep_rew_mean           | -52.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 33          |
|    time_elapsed          | 959         |
|    total_timesteps       | 1071104     |
| train/                   |             |
|    approx_kl             | 0.008202455 |
|    clip_fraction         | 0.0996      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.53        |
|    cost_value_loss       | 10.5        |
|    cost_values           | 2.91        |
|    entropy               | -1.21       |
|    entropy_loss          | -1.21       |
|    explained_variance    | 0.612       |
|    lagrangian_multiplier | 0.00268     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.43        |
|    n_updates             | 5220        |
|    policy_gradient_loss  | -0.00597    |
|    std                   | 0.478       |
|    value_loss            | 11.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -0.28213745 |
| rollout/                 |             |
|    ep_len_mean           | 145         |
|    ep_rew_mean           | -51.7       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 34          |
|    time_elapsed          | 993         |
|    total_timesteps       | 1073152     |
| train/                   |             |
|    approx_kl             | 0.017342146 |
|    clip_fraction         | 0.0881      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.68        |
|    cost_value_loss       | 6.88        |
|    cost_values           | 2.82        |
|    entropy               | -1.2        |
|    entropy_loss          | -1.21       |
|    explained_variance    | 0.709       |
|    lagrangian_multiplier | 0.000957    |
|    learning_rate         | 0.0003      |
|    loss                  | 7.81        |
|    n_updates             | 5230        |
|    policy_gradient_loss  | -0.00183    |
|    std                   | 0.477       |
|    value_loss            | 13.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.79        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.79        |
| reward                   | -0.15434502 |
| rollout/                 |             |
|    ep_len_mean           | 155         |
|    ep_rew_mean           | -54.3       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 35          |
|    time_elapsed          | 1025        |
|    total_timesteps       | 1075200     |
| train/                   |             |
|    approx_kl             | 0.007816858 |
|    clip_fraction         | 0.117       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.13        |
|    cost_value_loss       | 13.9        |
|    cost_values           | 2.91        |
|    entropy               | -1.2        |
|    entropy_loss          | -1.2        |
|    explained_variance    | 0.559       |
|    lagrangian_multiplier | 0.00548     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.01        |
|    n_updates             | 5240        |
|    policy_gradient_loss  | -0.000431   |
|    std                   | 0.475       |
|    value_loss            | 8.95        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.22148147 |
| rollout/                 |             |
|    ep_len_mean           | 147         |
|    ep_rew_mean           | -52.5       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 36          |
|    time_elapsed          | 1053        |
|    total_timesteps       | 1077248     |
| train/                   |             |
|    approx_kl             | 0.007313603 |
|    clip_fraction         | 0.0913      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.88        |
|    cost_value_loss       | 12.7        |
|    cost_values           | 2.95        |
|    entropy               | -1.19       |
|    entropy_loss          | -1.2        |
|    explained_variance    | 0.516       |
|    lagrangian_multiplier | 0.0039      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.17        |
|    n_updates             | 5250        |
|    policy_gradient_loss  | -0.00444    |
|    std                   | 0.475       |
|    value_loss            | 12          |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.7160119  |
| rollout/                 |             |
|    ep_len_mean           | 139         |
|    ep_rew_mean           | -50.2       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 37          |
|    time_elapsed          | 1087        |
|    total_timesteps       | 1079296     |
| train/                   |             |
|    approx_kl             | 0.010093439 |
|    clip_fraction         | 0.0735      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.73        |
|    cost_value_loss       | 12.5        |
|    cost_values           | 2.94        |
|    entropy               | -1.2        |
|    entropy_loss          | -1.19       |
|    explained_variance    | 0.509       |
|    lagrangian_multiplier | 0.00382     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.14        |
|    n_updates             | 5260        |
|    policy_gradient_loss  | -0.00206    |
|    std                   | 0.476       |
|    value_loss            | 13.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.8         |
| reward                   | -0.51883346 |
| rollout/                 |             |
|    ep_len_mean           | 134         |
|    ep_rew_mean           | -49.3       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 38          |
|    time_elapsed          | 1120        |
|    total_timesteps       | 1081344     |
| train/                   |             |
|    approx_kl             | 0.007829702 |
|    clip_fraction         | 0.0876      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.78        |
|    cost_value_loss       | 12.6        |
|    cost_values           | 2.87        |
|    entropy               | -1.2        |
|    entropy_loss          | -1.2        |
|    explained_variance    | 0.626       |
|    lagrangian_multiplier | 0.00678     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.7         |
|    n_updates             | 5270        |
|    policy_gradient_loss  | -0.00173    |
|    std                   | 0.476       |
|    value_loss            | 11.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.8         |
| reward                   | -0.6705366  |
| rollout/                 |             |
|    ep_len_mean           | 137         |
|    ep_rew_mean           | -49.5       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 39          |
|    time_elapsed          | 1153        |
|    total_timesteps       | 1083392     |
| train/                   |             |
|    approx_kl             | 0.009100189 |
|    clip_fraction         | 0.113       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.28        |
|    cost_value_loss       | 9.8         |
|    cost_values           | 2.91        |
|    entropy               | -1.2        |
|    entropy_loss          | -1.2        |
|    explained_variance    | 0.621       |
|    lagrangian_multiplier | 0.00483     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.21        |
|    n_updates             | 5280        |
|    policy_gradient_loss  | -0.00208    |
|    std                   | 0.477       |
|    value_loss            | 11          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.22218114  |
| rollout/                 |              |
|    ep_len_mean           | 137          |
|    ep_rew_mean           | -49.2        |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 40           |
|    time_elapsed          | 1189         |
|    total_timesteps       | 1085440      |
| train/                   |              |
|    approx_kl             | 0.0062617557 |
|    clip_fraction         | 0.0776       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.57         |
|    cost_value_loss       | 11.7         |
|    cost_values           | 2.89         |
|    entropy               | -1.18        |
|    entropy_loss          | -1.19        |
|    explained_variance    | 0.632        |
|    lagrangian_multiplier | 0.00403      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.42         |
|    n_updates             | 5290         |
|    policy_gradient_loss  | -0.00178     |
|    std                   | 0.473        |
|    value_loss            | 10.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7           |
| reward                   | -0.36809796 |
| rollout/                 |             |
|    ep_len_mean           | 131         |
|    ep_rew_mean           | -47.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 41          |
|    time_elapsed          | 1224        |
|    total_timesteps       | 1087488     |
| train/                   |             |
|    approx_kl             | 0.012832889 |
|    clip_fraction         | 0.102       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.68        |
|    cost_value_loss       | 12          |
|    cost_values           | 2.9         |
|    entropy               | -1.17       |
|    entropy_loss          | -1.17       |
|    explained_variance    | 0.661       |
|    lagrangian_multiplier | 0.00386     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.55        |
|    n_updates             | 5300        |
|    policy_gradient_loss  | -0.00165    |
|    std                   | 0.471       |
|    value_loss            | 9.61        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.24949664 |
| rollout/                 |             |
|    ep_len_mean           | 134         |
|    ep_rew_mean           | -48.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 42          |
|    time_elapsed          | 1260        |
|    total_timesteps       | 1089536     |
| train/                   |             |
|    approx_kl             | 0.00795764  |
|    clip_fraction         | 0.138       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.11        |
|    cost_value_loss       | 9.31        |
|    cost_values           | 2.85        |
|    entropy               | -1.15       |
|    entropy_loss          | -1.16       |
|    explained_variance    | 0.634       |
|    lagrangian_multiplier | 0.00436     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.04        |
|    n_updates             | 5310        |
|    policy_gradient_loss  | -0.000338   |
|    std                   | 0.467       |
|    value_loss            | 11          |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.23202483 |
| rollout/                 |             |
|    ep_len_mean           | 128         |
|    ep_rew_mean           | -46.7       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 43          |
|    time_elapsed          | 1296        |
|    total_timesteps       | 1091584     |
| train/                   |             |
|    approx_kl             | 0.009917596 |
|    clip_fraction         | 0.0947      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.8         |
|    cost_value_loss       | 12.4        |
|    cost_values           | 2.83        |
|    entropy               | -1.14       |
|    entropy_loss          | -1.15       |
|    explained_variance    | 0.623       |
|    lagrangian_multiplier | 0.0055      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.93        |
|    n_updates             | 5320        |
|    policy_gradient_loss  | -0.00487    |
|    std                   | 0.464       |
|    value_loss            | 10.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.32187992  |
| rollout/                 |              |
|    ep_len_mean           | 129          |
|    ep_rew_mean           | -46.9        |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 44           |
|    time_elapsed          | 1333         |
|    total_timesteps       | 1093632      |
| train/                   |              |
|    approx_kl             | 0.0061192093 |
|    clip_fraction         | 0.073        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.49         |
|    cost_value_loss       | 11.4         |
|    cost_values           | 2.86         |
|    entropy               | -1.12        |
|    entropy_loss          | -1.13        |
|    explained_variance    | 0.61         |
|    lagrangian_multiplier | 0.0052       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.11         |
|    n_updates             | 5330         |
|    policy_gradient_loss  | -0.00339     |
|    std                   | 0.461        |
|    value_loss            | 11.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.85        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.85        |
| reward                   | -0.26183558 |
| rollout/                 |             |
|    ep_len_mean           | 127         |
|    ep_rew_mean           | -46.6       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 45          |
|    time_elapsed          | 1365        |
|    total_timesteps       | 1095680     |
| train/                   |             |
|    approx_kl             | 0.008641768 |
|    clip_fraction         | 0.0971      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.63        |
|    cost_value_loss       | 11.9        |
|    cost_values           | 2.91        |
|    entropy               | -1.12       |
|    entropy_loss          | -1.12       |
|    explained_variance    | 0.625       |
|    lagrangian_multiplier | 0.00298     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.92        |
|    n_updates             | 5340        |
|    policy_gradient_loss  | -0.00544    |
|    std                   | 0.461       |
|    value_loss            | 10.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.99        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.99        |
| reward                   | -0.27301988 |
| rollout/                 |             |
|    ep_len_mean           | 123         |
|    ep_rew_mean           | -46.1       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 46          |
|    time_elapsed          | 1397        |
|    total_timesteps       | 1097728     |
| train/                   |             |
|    approx_kl             | 0.009308396 |
|    clip_fraction         | 0.126       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.55        |
|    cost_value_loss       | 10.9        |
|    cost_values           | 2.87        |
|    entropy               | -1.12       |
|    entropy_loss          | -1.12       |
|    explained_variance    | 0.627       |
|    lagrangian_multiplier | 0.00474     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.14        |
|    n_updates             | 5350        |
|    policy_gradient_loss  | -0.000397   |
|    std                   | 0.461       |
|    value_loss            | 11.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.80555815 |
| rollout/                 |             |
|    ep_len_mean           | 122         |
|    ep_rew_mean           | -45.7       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 47          |
|    time_elapsed          | 1433        |
|    total_timesteps       | 1099776     |
| train/                   |             |
|    approx_kl             | 0.010923684 |
|    clip_fraction         | 0.117       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.6         |
|    cost_value_loss       | 12.1        |
|    cost_values           | 2.86        |
|    entropy               | -1.11       |
|    entropy_loss          | -1.12       |
|    explained_variance    | 0.676       |
|    lagrangian_multiplier | 0.00207     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.83        |
|    n_updates             | 5360        |
|    policy_gradient_loss  | -0.000992   |
|    std                   | 0.46        |
|    value_loss            | 10.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.28         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.28         |
| reward                   | -0.7758785   |
| rollout/                 |              |
|    ep_len_mean           | 121          |
|    ep_rew_mean           | -45.3        |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 48           |
|    time_elapsed          | 1468         |
|    total_timesteps       | 1101824      |
| train/                   |              |
|    approx_kl             | 0.0068030483 |
|    clip_fraction         | 0.108        |
|    clip_range            | 0.2          |
|    cost_returns          | 5            |
|    cost_value_loss       | 9.07         |
|    cost_values           | 2.85         |
|    entropy               | -1.11        |
|    entropy_loss          | -1.11        |
|    explained_variance    | 0.64         |
|    lagrangian_multiplier | 0.00266      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.26         |
|    n_updates             | 5370         |
|    policy_gradient_loss  | -0.00409     |
|    std                   | 0.46         |
|    value_loss            | 10.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.22049671  |
| rollout/                 |              |
|    ep_len_mean           | 120          |
|    ep_rew_mean           | -45          |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 49           |
|    time_elapsed          | 1493         |
|    total_timesteps       | 1103872      |
| train/                   |              |
|    approx_kl             | 0.0071437466 |
|    clip_fraction         | 0.105        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.34         |
|    cost_value_loss       | 10.5         |
|    cost_values           | 2.87         |
|    entropy               | -1.11        |
|    entropy_loss          | -1.11        |
|    explained_variance    | 0.634        |
|    lagrangian_multiplier | 0.00297      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.66         |
|    n_updates             | 5380         |
|    policy_gradient_loss  | -0.00347     |
|    std                   | 0.459        |
|    value_loss            | 10.1         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ent-coefficient-ppol/1vjpjg9h
------------------------------------
| avg_speed          | 8.03        |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 8.03        |
| reward             | -0.31344435 |
| rollout/           |             |
|    ep_len_mean     | 120         |
|    ep_rew_mean     | -45.1       |
| time/              |             |
|    fps             | 91          |
|    iterations      | 1           |
|    time_elapsed    | 22          |
|    total_timesteps | 1105920     |
------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.31362152 |
| rollout/                 |             |
|    ep_len_mean           | 116         |
|    ep_rew_mean           | -43.5       |
| time/                    |             |
|    fps                   | 89          |
|    iterations            | 2           |
|    time_elapsed          | 45          |
|    total_timesteps       | 1107968     |
| train/                   |             |
|    approx_kl             | 0.009327972 |
|    clip_fraction         | 0.0761      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.61        |
|    cost_value_loss       | 11.3        |
|    cost_values           | 2.9         |
|    entropy               | -1.1        |
|    entropy_loss          | -1.1        |
|    explained_variance    | 0.651       |
|    lagrangian_multiplier | 0.00294     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.76        |
|    n_updates             | 5400        |
|    policy_gradient_loss  | -0.00194    |
|    std                   | 0.458       |
|    value_loss            | 9.71        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.28125176 |
| rollout/                 |             |
|    ep_len_mean           | 115         |
|    ep_rew_mean           | -42.9       |
| time/                    |             |
|    fps                   | 89          |
|    iterations            | 3           |
|    time_elapsed          | 68          |
|    total_timesteps       | 1110016     |
| train/                   |             |
|    approx_kl             | 0.00709619  |
|    clip_fraction         | 0.0951      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.28        |
|    cost_value_loss       | 9.91        |
|    cost_values           | 2.9         |
|    entropy               | -1.09       |
|    entropy_loss          | -1.09       |
|    explained_variance    | 0.639       |
|    lagrangian_multiplier | 0.0025      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.32        |
|    n_updates             | 5410        |
|    policy_gradient_loss  | -0.00239    |
|    std                   | 0.457       |
|    value_loss            | 10.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.86        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.86        |
| reward                   | -0.3057517  |
| rollout/                 |             |
|    ep_len_mean           | 117         |
|    ep_rew_mean           | -43.2       |
| time/                    |             |
|    fps                   | 88          |
|    iterations            | 4           |
|    time_elapsed          | 92          |
|    total_timesteps       | 1112064     |
| train/                   |             |
|    approx_kl             | 0.008175548 |
|    clip_fraction         | 0.0885      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.57        |
|    cost_value_loss       | 10.9        |
|    cost_values           | 2.93        |
|    entropy               | -1.08       |
|    entropy_loss          | -1.08       |
|    explained_variance    | 0.6         |
|    lagrangian_multiplier | 0.00361     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.14        |
|    n_updates             | 5420        |
|    policy_gradient_loss  | -0.00115    |
|    std                   | 0.455       |
|    value_loss            | 8.73        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.21405052 |
| rollout/                 |             |
|    ep_len_mean           | 121         |
|    ep_rew_mean           | -44.8       |
| time/                    |             |
|    fps                   | 88          |
|    iterations            | 5           |
|    time_elapsed          | 115         |
|    total_timesteps       | 1114112     |
| train/                   |             |
|    approx_kl             | 0.011832433 |
|    clip_fraction         | 0.111       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.34        |
|    cost_value_loss       | 10.9        |
|    cost_values           | 2.84        |
|    entropy               | -1.07       |
|    entropy_loss          | -1.07       |
|    explained_variance    | 0.71        |
|    lagrangian_multiplier | 0.00294     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.65        |
|    n_updates             | 5430        |
|    policy_gradient_loss  | -0.00402    |
|    std                   | 0.453       |
|    value_loss            | 9.03        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.22179605 |
| rollout/                 |             |
|    ep_len_mean           | 120         |
|    ep_rew_mean           | -44.2       |
| time/                    |             |
|    fps                   | 85          |
|    iterations            | 6           |
|    time_elapsed          | 143         |
|    total_timesteps       | 1116160     |
| train/                   |             |
|    approx_kl             | 0.012580327 |
|    clip_fraction         | 0.111       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.6         |
|    cost_value_loss       | 11.5        |
|    cost_values           | 2.87        |
|    entropy               | -1.07       |
|    entropy_loss          | -1.07       |
|    explained_variance    | 0.659       |
|    lagrangian_multiplier | 0.00239     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.91        |
|    n_updates             | 5440        |
|    policy_gradient_loss  | -0.00663    |
|    std                   | 0.453       |
|    value_loss            | 8.02        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.24175522 |
| rollout/                 |             |
|    ep_len_mean           | 110         |
|    ep_rew_mean           | -42.2       |
| time/                    |             |
|    fps                   | 80          |
|    iterations            | 7           |
|    time_elapsed          | 177         |
|    total_timesteps       | 1118208     |
| train/                   |             |
|    approx_kl             | 0.01354535  |
|    clip_fraction         | 0.104       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.37        |
|    cost_value_loss       | 11.1        |
|    cost_values           | 2.82        |
|    entropy               | -1.07       |
|    entropy_loss          | -1.07       |
|    explained_variance    | 0.634       |
|    lagrangian_multiplier | 0.00405     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.48        |
|    n_updates             | 5450        |
|    policy_gradient_loss  | -0.0049     |
|    std                   | 0.453       |
|    value_loss            | 11.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.27        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.27        |
| reward                   | -0.46898505 |
| rollout/                 |             |
|    ep_len_mean           | 108         |
|    ep_rew_mean           | -41.6       |
| time/                    |             |
|    fps                   | 77          |
|    iterations            | 8           |
|    time_elapsed          | 210         |
|    total_timesteps       | 1120256     |
| train/                   |             |
|    approx_kl             | 0.011457414 |
|    clip_fraction         | 0.118       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.08        |
|    cost_value_loss       | 10.8        |
|    cost_values           | 2.78        |
|    entropy               | -1.07       |
|    entropy_loss          | -1.07       |
|    explained_variance    | 0.69        |
|    lagrangian_multiplier | 0.00166     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.63        |
|    n_updates             | 5460        |
|    policy_gradient_loss  | -0.00264    |
|    std                   | 0.454       |
|    value_loss            | 13.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.4          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.4          |
| reward                   | -0.61956424  |
| rollout/                 |              |
|    ep_len_mean           | 106          |
|    ep_rew_mean           | -41.4        |
| time/                    |              |
|    fps                   | 75           |
|    iterations            | 9            |
|    time_elapsed          | 244          |
|    total_timesteps       | 1122304      |
| train/                   |              |
|    approx_kl             | 0.0061942777 |
|    clip_fraction         | 0.0875       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.19         |
|    cost_value_loss       | 9.66         |
|    cost_values           | 2.82         |
|    entropy               | -1.07        |
|    entropy_loss          | -1.07        |
|    explained_variance    | 0.682        |
|    lagrangian_multiplier | 0.00253      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.69         |
|    n_updates             | 5470         |
|    policy_gradient_loss  | -0.00253     |
|    std                   | 0.454        |
|    value_loss            | 9.68         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.4          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.4          |
| reward                   | -0.785546    |
| rollout/                 |              |
|    ep_len_mean           | 114          |
|    ep_rew_mean           | -43.2        |
| time/                    |              |
|    fps                   | 73           |
|    iterations            | 10           |
|    time_elapsed          | 277          |
|    total_timesteps       | 1124352      |
| train/                   |              |
|    approx_kl             | 0.0042969566 |
|    clip_fraction         | 0.0796       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.29         |
|    cost_value_loss       | 10.4         |
|    cost_values           | 2.86         |
|    entropy               | -1.06        |
|    entropy_loss          | -1.07        |
|    explained_variance    | 0.689        |
|    lagrangian_multiplier | 0.00477      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.82         |
|    n_updates             | 5480         |
|    policy_gradient_loss  | -0.0022      |
|    std                   | 0.454        |
|    value_loss            | 9.13         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.84        |
| reward                   | -0.41638434 |
| rollout/                 |             |
|    ep_len_mean           | 113         |
|    ep_rew_mean           | -43         |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 11          |
|    time_elapsed          | 310         |
|    total_timesteps       | 1126400     |
| train/                   |             |
|    approx_kl             | 0.009688157 |
|    clip_fraction         | 0.0991      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.52        |
|    cost_value_loss       | 10.5        |
|    cost_values           | 2.89        |
|    entropy               | -1.06       |
|    entropy_loss          | -1.06       |
|    explained_variance    | 0.632       |
|    lagrangian_multiplier | 0.00348     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.28        |
|    n_updates             | 5490        |
|    policy_gradient_loss  | -0.0033     |
|    std                   | 0.453       |
|    value_loss            | 8.18        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.24395435 |
| rollout/                 |             |
|    ep_len_mean           | 113         |
|    ep_rew_mean           | -42.9       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 12          |
|    time_elapsed          | 341         |
|    total_timesteps       | 1128448     |
| train/                   |             |
|    approx_kl             | 0.00945742  |
|    clip_fraction         | 0.0745      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.13        |
|    cost_value_loss       | 9.5         |
|    cost_values           | 2.85        |
|    entropy               | -1.05       |
|    entropy_loss          | -1.06       |
|    explained_variance    | 0.677       |
|    lagrangian_multiplier | 0.00404     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.89        |
|    n_updates             | 5500        |
|    policy_gradient_loss  | -0.00392    |
|    std                   | 0.45        |
|    value_loss            | 9.48        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.33851972 |
| rollout/                 |             |
|    ep_len_mean           | 124         |
|    ep_rew_mean           | -45.8       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 13          |
|    time_elapsed          | 371         |
|    total_timesteps       | 1130496     |
| train/                   |             |
|    approx_kl             | 0.017983867 |
|    clip_fraction         | 0.11        |
|    clip_range            | 0.2         |
|    cost_returns          | 5.85        |
|    cost_value_loss       | 12.3        |
|    cost_values           | 2.9         |
|    entropy               | -1.04       |
|    entropy_loss          | -1.04       |
|    explained_variance    | 0.699       |
|    lagrangian_multiplier | 0.00309     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.25        |
|    n_updates             | 5510        |
|    policy_gradient_loss  | -0.00227    |
|    std                   | 0.449       |
|    value_loss            | 6.83        |
------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.6297033  |
| rollout/                 |             |
|    ep_len_mean           | 123         |
|    ep_rew_mean           | -46.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 14          |
|    time_elapsed          | 407         |
|    total_timesteps       | 1132544     |
| train/                   |             |
|    approx_kl             | 0.012366005 |
|    clip_fraction         | 0.084       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.49        |
|    cost_value_loss       | 7.12        |
|    cost_values           | 2.81        |
|    entropy               | -1.05       |
|    entropy_loss          | -1.05       |
|    explained_variance    | 0.583       |
|    lagrangian_multiplier | 0.00203     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.28        |
|    n_updates             | 5520        |
|    policy_gradient_loss  | -0.00253    |
|    std                   | 0.45        |
|    value_loss            | 13.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.20354198  |
| rollout/                 |              |
|    ep_len_mean           | 110          |
|    ep_rew_mean           | -42.3        |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 15           |
|    time_elapsed          | 447          |
|    total_timesteps       | 1134592      |
| train/                   |              |
|    approx_kl             | 0.0052414676 |
|    clip_fraction         | 0.0865       |
|    clip_range            | 0.2          |
|    cost_returns          | 5            |
|    cost_value_loss       | 8.54         |
|    cost_values           | 2.82         |
|    entropy               | -1.04        |
|    entropy_loss          | -1.05        |
|    explained_variance    | 0.689        |
|    lagrangian_multiplier | 0.00362      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.88         |
|    n_updates             | 5530         |
|    policy_gradient_loss  | -0.00107     |
|    std                   | 0.45         |
|    value_loss            | 10.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 5            |
| reward                   | -0.6796996   |
| rollout/                 |              |
|    ep_len_mean           | 114          |
|    ep_rew_mean           | -43.5        |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 16           |
|    time_elapsed          | 482          |
|    total_timesteps       | 1136640      |
| train/                   |              |
|    approx_kl             | 0.0074706757 |
|    clip_fraction         | 0.0802       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.09         |
|    cost_value_loss       | 8.65         |
|    cost_values           | 2.9          |
|    entropy               | -1.04        |
|    entropy_loss          | -1.04        |
|    explained_variance    | 0.637        |
|    lagrangian_multiplier | 0.00344      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.48         |
|    n_updates             | 5540         |
|    policy_gradient_loss  | -0.003       |
|    std                   | 0.449        |
|    value_loss            | 11           |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.2         |
| reward                   | -0.4188584  |
| rollout/                 |             |
|    ep_len_mean           | 96.6        |
|    ep_rew_mean           | -38.9       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 17          |
|    time_elapsed          | 513         |
|    total_timesteps       | 1138688     |
| train/                   |             |
|    approx_kl             | 0.012411298 |
|    clip_fraction         | 0.131       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.66        |
|    cost_value_loss       | 11.3        |
|    cost_values           | 2.92        |
|    entropy               | -1.04       |
|    entropy_loss          | -1.04       |
|    explained_variance    | 0.622       |
|    lagrangian_multiplier | 0.00511     |
|    learning_rate         | 0.0003      |
|    loss                  | 5           |
|    n_updates             | 5550        |
|    policy_gradient_loss  | -0.00142    |
|    std                   | 0.451       |
|    value_loss            | 9.72        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.2702459  |
| rollout/                 |             |
|    ep_len_mean           | 98          |
|    ep_rew_mean           | -39.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 18          |
|    time_elapsed          | 540         |
|    total_timesteps       | 1140736     |
| train/                   |             |
|    approx_kl             | 0.010445324 |
|    clip_fraction         | 0.103       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.09        |
|    cost_value_loss       | 9.2         |
|    cost_values           | 2.85        |
|    entropy               | -1.05       |
|    entropy_loss          | -1.04       |
|    explained_variance    | 0.695       |
|    lagrangian_multiplier | 0.00314     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.58        |
|    n_updates             | 5560        |
|    policy_gradient_loss  | -0.00145    |
|    std                   | 0.454       |
|    value_loss            | 11.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.21348566 |
| rollout/                 |             |
|    ep_len_mean           | 106         |
|    ep_rew_mean           | -41.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 19          |
|    time_elapsed          | 569         |
|    total_timesteps       | 1142784     |
| train/                   |             |
|    approx_kl             | 0.011577891 |
|    clip_fraction         | 0.135       |
|    clip_range            | 0.2         |
|    cost_returns          | 5           |
|    cost_value_loss       | 8.61        |
|    cost_values           | 2.86        |
|    entropy               | -1.05       |
|    entropy_loss          | -1.05       |
|    explained_variance    | 0.709       |
|    lagrangian_multiplier | 0.00236     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.57        |
|    n_updates             | 5570        |
|    policy_gradient_loss  | -0.00106    |
|    std                   | 0.454       |
|    value_loss            | 10.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.26681802 |
| rollout/                 |             |
|    ep_len_mean           | 106         |
|    ep_rew_mean           | -41.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 20          |
|    time_elapsed          | 593         |
|    total_timesteps       | 1144832     |
| train/                   |             |
|    approx_kl             | 0.016723843 |
|    clip_fraction         | 0.0973      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.29        |
|    cost_value_loss       | 8.99        |
|    cost_values           | 2.9         |
|    entropy               | -1.05       |
|    entropy_loss          | -1.05       |
|    explained_variance    | 0.655       |
|    lagrangian_multiplier | 0.00396     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.21        |
|    n_updates             | 5580        |
|    policy_gradient_loss  | -0.000987   |
|    std                   | 0.455       |
|    value_loss            | 6.61        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.18702386 |
| rollout/                 |             |
|    ep_len_mean           | 105         |
|    ep_rew_mean           | -41         |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 21          |
|    time_elapsed          | 617         |
|    total_timesteps       | 1146880     |
| train/                   |             |
|    approx_kl             | 0.015910566 |
|    clip_fraction         | 0.168       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.43        |
|    cost_value_loss       | 9.95        |
|    cost_values           | 2.9         |
|    entropy               | -1.05       |
|    entropy_loss          | -1.05       |
|    explained_variance    | 0.671       |
|    lagrangian_multiplier | 0.00341     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.53        |
|    n_updates             | 5590        |
|    policy_gradient_loss  | 0.0031      |
|    std                   | 0.456       |
|    value_loss            | 10.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.78874034 |
| rollout/                 |             |
|    ep_len_mean           | 113         |
|    ep_rew_mean           | -43         |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 22          |
|    time_elapsed          | 643         |
|    total_timesteps       | 1148928     |
| train/                   |             |
|    approx_kl             | 0.007564532 |
|    clip_fraction         | 0.11        |
|    clip_range            | 0.2         |
|    cost_returns          | 5           |
|    cost_value_loss       | 8.11        |
|    cost_values           | 2.9         |
|    entropy               | -1.05       |
|    entropy_loss          | -1.05       |
|    explained_variance    | 0.633       |
|    lagrangian_multiplier | 0.00328     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.96        |
|    n_updates             | 5600        |
|    policy_gradient_loss  | -0.00328    |
|    std                   | 0.455       |
|    value_loss            | 10.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.1854386   |
| rollout/                 |              |
|    ep_len_mean           | 118          |
|    ep_rew_mean           | -44.2        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 23           |
|    time_elapsed          | 672          |
|    total_timesteps       | 1150976      |
| train/                   |              |
|    approx_kl             | 0.0080742575 |
|    clip_fraction         | 0.103        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.14         |
|    cost_value_loss       | 8.03         |
|    cost_values           | 2.9          |
|    entropy               | -1.03        |
|    entropy_loss          | -1.04        |
|    explained_variance    | 0.616        |
|    lagrangian_multiplier | 0.00532      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.39         |
|    n_updates             | 5610         |
|    policy_gradient_loss  | -0.0035      |
|    std                   | 0.452        |
|    value_loss            | 8.61         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6            |
| reward                   | -0.22327669  |
| rollout/                 |              |
|    ep_len_mean           | 122          |
|    ep_rew_mean           | -45.2        |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 24           |
|    time_elapsed          | 705          |
|    total_timesteps       | 1153024      |
| train/                   |              |
|    approx_kl             | 0.0062180497 |
|    clip_fraction         | 0.108        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.58         |
|    cost_value_loss       | 10.6         |
|    cost_values           | 2.91         |
|    entropy               | -1.03        |
|    entropy_loss          | -1.03        |
|    explained_variance    | 0.562        |
|    lagrangian_multiplier | 0.004        |
|    learning_rate         | 0.0003       |
|    loss                  | 5.12         |
|    n_updates             | 5620         |
|    policy_gradient_loss  | -0.000772    |
|    std                   | 0.452        |
|    value_loss            | 10.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.6         |
| reward                   | -0.29075956 |
| rollout/                 |             |
|    ep_len_mean           | 114         |
|    ep_rew_mean           | -43.6       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 25          |
|    time_elapsed          | 740         |
|    total_timesteps       | 1155072     |
| train/                   |             |
|    approx_kl             | 0.010007744 |
|    clip_fraction         | 0.111       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.23        |
|    cost_value_loss       | 9.01        |
|    cost_values           | 2.91        |
|    entropy               | -1.03       |
|    entropy_loss          | -1.03       |
|    explained_variance    | 0.599       |
|    lagrangian_multiplier | 0.00264     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.18        |
|    n_updates             | 5630        |
|    policy_gradient_loss  | -0.00064    |
|    std                   | 0.451       |
|    value_loss            | 12.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.85        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.85        |
| reward                   | -0.25977245 |
| rollout/                 |             |
|    ep_len_mean           | 117         |
|    ep_rew_mean           | -44.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 26          |
|    time_elapsed          | 777         |
|    total_timesteps       | 1157120     |
| train/                   |             |
|    approx_kl             | 0.009340763 |
|    clip_fraction         | 0.111       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.21        |
|    cost_value_loss       | 9.34        |
|    cost_values           | 2.86        |
|    entropy               | -1.02       |
|    entropy_loss          | -1.02       |
|    explained_variance    | 0.685       |
|    lagrangian_multiplier | 0.00392     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.04        |
|    n_updates             | 5640        |
|    policy_gradient_loss  | 0.000858    |
|    std                   | 0.45        |
|    value_loss            | 11.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.93        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.93        |
| reward                   | -0.2400226  |
| rollout/                 |             |
|    ep_len_mean           | 111         |
|    ep_rew_mean           | -43.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 27          |
|    time_elapsed          | 813         |
|    total_timesteps       | 1159168     |
| train/                   |             |
|    approx_kl             | 0.006917078 |
|    clip_fraction         | 0.0885      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.43        |
|    cost_value_loss       | 10.3        |
|    cost_values           | 2.91        |
|    entropy               | -1.02       |
|    entropy_loss          | -1.02       |
|    explained_variance    | 0.551       |
|    lagrangian_multiplier | 0.00344     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.6         |
|    n_updates             | 5650        |
|    policy_gradient_loss  | -0.00304    |
|    std                   | 0.45        |
|    value_loss            | 10.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.19        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.19        |
| reward                   | -0.6262271  |
| rollout/                 |             |
|    ep_len_mean           | 104         |
|    ep_rew_mean           | -40.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 28          |
|    time_elapsed          | 836         |
|    total_timesteps       | 1161216     |
| train/                   |             |
|    approx_kl             | 0.008408702 |
|    clip_fraction         | 0.0811      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.99        |
|    cost_value_loss       | 8.47        |
|    cost_values           | 2.86        |
|    entropy               | -1.02       |
|    entropy_loss          | -1.02       |
|    explained_variance    | 0.653       |
|    lagrangian_multiplier | 0.00373     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.26        |
|    n_updates             | 5660        |
|    policy_gradient_loss  | -0.00102    |
|    std                   | 0.45        |
|    value_loss            | 12.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.03        |
| reward                   | -0.70764637 |
| rollout/                 |             |
|    ep_len_mean           | 106         |
|    ep_rew_mean           | -41.6       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 29          |
|    time_elapsed          | 859         |
|    total_timesteps       | 1163264     |
| train/                   |             |
|    approx_kl             | 0.013534961 |
|    clip_fraction         | 0.139       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.05        |
|    cost_value_loss       | 8.43        |
|    cost_values           | 2.89        |
|    entropy               | -1.01       |
|    entropy_loss          | -1.02       |
|    explained_variance    | 0.72        |
|    lagrangian_multiplier | 0.00228     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.55        |
|    n_updates             | 5670        |
|    policy_gradient_loss  | 0.00104     |
|    std                   | 0.448       |
|    value_loss            | 9.63        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.22112375 |
| rollout/                 |             |
|    ep_len_mean           | 105         |
|    ep_rew_mean           | -40.8       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 30          |
|    time_elapsed          | 890         |
|    total_timesteps       | 1165312     |
| train/                   |             |
|    approx_kl             | 0.006151862 |
|    clip_fraction         | 0.0849      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.22        |
|    cost_value_loss       | 9.48        |
|    cost_values           | 2.91        |
|    entropy               | -1.01       |
|    entropy_loss          | -1.01       |
|    explained_variance    | 0.689       |
|    lagrangian_multiplier | 0.0052      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.69        |
|    n_updates             | 5680        |
|    policy_gradient_loss  | -0.00262    |
|    std                   | 0.447       |
|    value_loss            | 9.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.33496484 |
| rollout/                 |             |
|    ep_len_mean           | 106         |
|    ep_rew_mean           | -41.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 31          |
|    time_elapsed          | 928         |
|    total_timesteps       | 1167360     |
| train/                   |             |
|    approx_kl             | 0.007158165 |
|    clip_fraction         | 0.0912      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.15        |
|    cost_value_loss       | 8.98        |
|    cost_values           | 2.87        |
|    entropy               | -1          |
|    entropy_loss          | -1.01       |
|    explained_variance    | 0.655       |
|    lagrangian_multiplier | 0.00461     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.09        |
|    n_updates             | 5690        |
|    policy_gradient_loss  | -0.00225    |
|    std                   | 0.446       |
|    value_loss            | 11.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.30337977  |
| rollout/                 |              |
|    ep_len_mean           | 113          |
|    ep_rew_mean           | -43.1        |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 32           |
|    time_elapsed          | 961          |
|    total_timesteps       | 1169408      |
| train/                   |              |
|    approx_kl             | 0.0042631677 |
|    clip_fraction         | 0.0795       |
|    clip_range            | 0.2          |
|    cost_returns          | 5            |
|    cost_value_loss       | 8.53         |
|    cost_values           | 2.87         |
|    entropy               | -1           |
|    entropy_loss          | -1           |
|    explained_variance    | 0.624        |
|    lagrangian_multiplier | 0.00395      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.68         |
|    n_updates             | 5700         |
|    policy_gradient_loss  | -0.00368     |
|    std                   | 0.446        |
|    value_loss            | 9.42         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5           |
| reward                   | -0.62683755 |
| rollout/                 |             |
|    ep_len_mean           | 114         |
|    ep_rew_mean           | -42.9       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 33          |
|    time_elapsed          | 996         |
|    total_timesteps       | 1171456     |
| train/                   |             |
|    approx_kl             | 0.010844418 |
|    clip_fraction         | 0.118       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.41        |
|    cost_value_loss       | 9.97        |
|    cost_values           | 2.91        |
|    entropy               | -0.999      |
|    entropy_loss          | -1          |
|    explained_variance    | 0.556       |
|    lagrangian_multiplier | 0.00386     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.34        |
|    n_updates             | 5710        |
|    policy_gradient_loss  | -0.00408    |
|    std                   | 0.446       |
|    value_loss            | 9.77        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.8          |
| reward                   | -0.6577206   |
| rollout/                 |              |
|    ep_len_mean           | 110          |
|    ep_rew_mean           | -42.2        |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 34           |
|    time_elapsed          | 1033         |
|    total_timesteps       | 1173504      |
| train/                   |              |
|    approx_kl             | 0.0137791615 |
|    clip_fraction         | 0.116        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.28         |
|    cost_value_loss       | 10.1         |
|    cost_values           | 2.91         |
|    entropy               | -0.996       |
|    entropy_loss          | -0.998       |
|    explained_variance    | 0.659        |
|    lagrangian_multiplier | 0.00255      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.13         |
|    n_updates             | 5720         |
|    policy_gradient_loss  | -0.00216     |
|    std                   | 0.445        |
|    value_loss            | 10.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.2615389  |
| rollout/                 |             |
|    ep_len_mean           | 116         |
|    ep_rew_mean           | -43.9       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 35          |
|    time_elapsed          | 1067        |
|    total_timesteps       | 1175552     |
| train/                   |             |
|    approx_kl             | 0.012888578 |
|    clip_fraction         | 0.103       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.32        |
|    cost_value_loss       | 9.34        |
|    cost_values           | 2.9         |
|    entropy               | -0.987      |
|    entropy_loss          | -0.992      |
|    explained_variance    | 0.667       |
|    lagrangian_multiplier | 0.004       |
|    learning_rate         | 0.0003      |
|    loss                  | 5.24        |
|    n_updates             | 5730        |
|    policy_gradient_loss  | -0.00291    |
|    std                   | 0.443       |
|    value_loss            | 9.89        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.6         |
| reward                   | -0.5505732  |
| rollout/                 |             |
|    ep_len_mean           | 113         |
|    ep_rew_mean           | -43.4       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 36          |
|    time_elapsed          | 1095        |
|    total_timesteps       | 1177600     |
| train/                   |             |
|    approx_kl             | 0.005992331 |
|    clip_fraction         | 0.0996      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.4         |
|    cost_value_loss       | 10.5        |
|    cost_values           | 2.91        |
|    entropy               | -0.976      |
|    entropy_loss          | -0.982      |
|    explained_variance    | 0.594       |
|    lagrangian_multiplier | 0.00461     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.47        |
|    n_updates             | 5740        |
|    policy_gradient_loss  | -0.00364    |
|    std                   | 0.441       |
|    value_loss            | 11.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.35937852 |
| rollout/                 |             |
|    ep_len_mean           | 103         |
|    ep_rew_mean           | -40.5       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 37          |
|    time_elapsed          | 1124        |
|    total_timesteps       | 1179648     |
| train/                   |             |
|    approx_kl             | 0.009980749 |
|    clip_fraction         | 0.0882      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.41        |
|    cost_value_loss       | 10.5        |
|    cost_values           | 2.9         |
|    entropy               | -0.966      |
|    entropy_loss          | -0.97       |
|    explained_variance    | 0.694       |
|    lagrangian_multiplier | 0.00495     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.22        |
|    n_updates             | 5750        |
|    policy_gradient_loss  | -0.00206    |
|    std                   | 0.439       |
|    value_loss            | 11.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.26350966 |
| rollout/                 |             |
|    ep_len_mean           | 102         |
|    ep_rew_mean           | -40.7       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 38          |
|    time_elapsed          | 1154        |
|    total_timesteps       | 1181696     |
| train/                   |             |
|    approx_kl             | 0.004278441 |
|    clip_fraction         | 0.0533      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.27        |
|    cost_value_loss       | 9.7         |
|    cost_values           | 2.88        |
|    entropy               | -0.959      |
|    entropy_loss          | -0.962      |
|    explained_variance    | 0.667       |
|    lagrangian_multiplier | 0.00395     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.38        |
|    n_updates             | 5760        |
|    policy_gradient_loss  | -0.00281    |
|    std                   | 0.437       |
|    value_loss            | 10.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.21252863 |
| rollout/                 |             |
|    ep_len_mean           | 103         |
|    ep_rew_mean           | -40.5       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 39          |
|    time_elapsed          | 1186        |
|    total_timesteps       | 1183744     |
| train/                   |             |
|    approx_kl             | 0.012317699 |
|    clip_fraction         | 0.137       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.47        |
|    cost_value_loss       | 10.6        |
|    cost_values           | 2.9         |
|    entropy               | -0.959      |
|    entropy_loss          | -0.959      |
|    explained_variance    | 0.678       |
|    lagrangian_multiplier | 0.0045      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.19        |
|    n_updates             | 5770        |
|    policy_gradient_loss  | -0.00571    |
|    std                   | 0.437       |
|    value_loss            | 10.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.93        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.93        |
| reward                   | -0.23820414 |
| rollout/                 |             |
|    ep_len_mean           | 104         |
|    ep_rew_mean           | -40.2       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 40          |
|    time_elapsed          | 1218        |
|    total_timesteps       | 1185792     |
| train/                   |             |
|    approx_kl             | 0.008147465 |
|    clip_fraction         | 0.116       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.55        |
|    cost_value_loss       | 10.6        |
|    cost_values           | 2.93        |
|    entropy               | -0.96       |
|    entropy_loss          | -0.96       |
|    explained_variance    | 0.666       |
|    lagrangian_multiplier | 0.00458     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.94        |
|    n_updates             | 5780        |
|    policy_gradient_loss  | -0.0019     |
|    std                   | 0.437       |
|    value_loss            | 8.81        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.6         |
| reward                   | -0.56265795 |
| rollout/                 |             |
|    ep_len_mean           | 103         |
|    ep_rew_mean           | -39.5       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 41          |
|    time_elapsed          | 1254        |
|    total_timesteps       | 1187840     |
| train/                   |             |
|    approx_kl             | 0.008888524 |
|    clip_fraction         | 0.0981      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.56        |
|    cost_value_loss       | 11.8        |
|    cost_values           | 2.91        |
|    entropy               | -0.952      |
|    entropy_loss          | -0.957      |
|    explained_variance    | 0.648       |
|    lagrangian_multiplier | 0.00727     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.41        |
|    n_updates             | 5790        |
|    policy_gradient_loss  | -0.00176    |
|    std                   | 0.435       |
|    value_loss            | 8.91        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.59         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 5.59         |
| reward                   | -0.6676723   |
| rollout/                 |              |
|    ep_len_mean           | 107          |
|    ep_rew_mean           | -40.6        |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 42           |
|    time_elapsed          | 1287         |
|    total_timesteps       | 1189888      |
| train/                   |              |
|    approx_kl             | 0.0037801103 |
|    clip_fraction         | 0.0888       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.28         |
|    cost_value_loss       | 10.4         |
|    cost_values           | 2.9          |
|    entropy               | -0.941       |
|    entropy_loss          | -0.946       |
|    explained_variance    | 0.7          |
|    lagrangian_multiplier | 0.00234      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.37         |
|    n_updates             | 5800         |
|    policy_gradient_loss  | -0.0019      |
|    std                   | 0.434        |
|    value_loss            | 9.87         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.61406744 |
| rollout/                 |             |
|    ep_len_mean           | 105         |
|    ep_rew_mean           | -39.7       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 43          |
|    time_elapsed          | 1314        |
|    total_timesteps       | 1191936     |
| train/                   |             |
|    approx_kl             | 0.014698524 |
|    clip_fraction         | 0.111       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.39        |
|    cost_value_loss       | 10.4        |
|    cost_values           | 2.94        |
|    entropy               | -0.936      |
|    entropy_loss          | -0.938      |
|    explained_variance    | 0.72        |
|    lagrangian_multiplier | 0.00597     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.36        |
|    n_updates             | 5810        |
|    policy_gradient_loss  | -0.00189    |
|    std                   | 0.433       |
|    value_loss            | 7.5         |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.7629622  |
| rollout/                 |             |
|    ep_len_mean           | 101         |
|    ep_rew_mean           | -38.6       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 44          |
|    time_elapsed          | 1341        |
|    total_timesteps       | 1193984     |
| train/                   |             |
|    approx_kl             | 0.012207085 |
|    clip_fraction         | 0.0976      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.27        |
|    cost_value_loss       | 9.78        |
|    cost_values           | 2.93        |
|    entropy               | -0.934      |
|    entropy_loss          | -0.935      |
|    explained_variance    | 0.711       |
|    lagrangian_multiplier | 0.00329     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.27        |
|    n_updates             | 5820        |
|    policy_gradient_loss  | -0.00137    |
|    std                   | 0.434       |
|    value_loss            | 9.47        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.4         |
| reward                   | -0.29503417 |
| rollout/                 |             |
|    ep_len_mean           | 96.7        |
|    ep_rew_mean           | -37.5       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 45          |
|    time_elapsed          | 1364        |
|    total_timesteps       | 1196032     |
| train/                   |             |
|    approx_kl             | 0.01387831  |
|    clip_fraction         | 0.118       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.93        |
|    cost_value_loss       | 7.98        |
|    cost_values           | 2.92        |
|    entropy               | -0.926      |
|    entropy_loss          | -0.93       |
|    explained_variance    | 0.757       |
|    lagrangian_multiplier | 0.00254     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.9         |
|    n_updates             | 5830        |
|    policy_gradient_loss  | -0.00229    |
|    std                   | 0.433       |
|    value_loss            | 8.29        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.7         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.7         |
| reward                   | -0.25799027 |
| rollout/                 |             |
|    ep_len_mean           | 98.1        |
|    ep_rew_mean           | -38         |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 46          |
|    time_elapsed          | 1388        |
|    total_timesteps       | 1198080     |
| train/                   |             |
|    approx_kl             | 0.011369272 |
|    clip_fraction         | 0.11        |
|    clip_range            | 0.2         |
|    cost_returns          | 5.19        |
|    cost_value_loss       | 9.24        |
|    cost_values           | 2.92        |
|    entropy               | -0.918      |
|    entropy_loss          | -0.923      |
|    explained_variance    | 0.76        |
|    lagrangian_multiplier | 0.00277     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.39        |
|    n_updates             | 5840        |
|    policy_gradient_loss  | -0.00562    |
|    std                   | 0.432       |
|    value_loss            | 7.73        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.2650741  |
| rollout/                 |             |
|    ep_len_mean           | 94.5        |
|    ep_rew_mean           | -36.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 47          |
|    time_elapsed          | 1412        |
|    total_timesteps       | 1200128     |
| train/                   |             |
|    approx_kl             | 0.006680342 |
|    clip_fraction         | 0.12        |
|    clip_range            | 0.2         |
|    cost_returns          | 5.27        |
|    cost_value_loss       | 9.06        |
|    cost_values           | 2.93        |
|    entropy               | -0.908      |
|    entropy_loss          | -0.913      |
|    explained_variance    | 0.75        |
|    lagrangian_multiplier | 0.00315     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.01        |
|    n_updates             | 5850        |
|    policy_gradient_loss  | -0.00285    |
|    std                   | 0.43        |
|    value_loss            | 7.53        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.16864541 |
| rollout/                 |             |
|    ep_len_mean           | 97.1        |
|    ep_rew_mean           | -38.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 48          |
|    time_elapsed          | 1444        |
|    total_timesteps       | 1202176     |
| train/                   |             |
|    approx_kl             | 0.021282986 |
|    clip_fraction         | 0.111       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.11        |
|    cost_value_loss       | 8.32        |
|    cost_values           | 2.92        |
|    entropy               | -0.897      |
|    entropy_loss          | -0.903      |
|    explained_variance    | 0.757       |
|    lagrangian_multiplier | 0.00312     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.85        |
|    n_updates             | 5860        |
|    policy_gradient_loss  | 0.000743    |
|    std                   | 0.427       |
|    value_loss            | 7.52        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.71        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.71        |
| reward                   | -0.30990607 |
| rollout/                 |             |
|    ep_len_mean           | 100         |
|    ep_rew_mean           | -38.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 49          |
|    time_elapsed          | 1474        |
|    total_timesteps       | 1204224     |
| train/                   |             |
|    approx_kl             | 0.018359672 |
|    clip_fraction         | 0.15        |
|    clip_range            | 0.2         |
|    cost_returns          | 5.08        |
|    cost_value_loss       | 8.63        |
|    cost_values           | 2.94        |
|    entropy               | -0.883      |
|    entropy_loss          | -0.89       |
|    explained_variance    | 0.74        |
|    lagrangian_multiplier | 0.00469     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.44        |
|    n_updates             | 5870        |
|    policy_gradient_loss  | 0.00173     |
|    std                   | 0.425       |
|    value_loss            | 8           |
------------------------------------------
------------------------------------
| avg_speed          | 2.6         |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 2.6         |
| reward             | -0.68484956 |
| rollout/           |             |
|    ep_len_mean     | 97          |
|    ep_rew_mean     | -38         |
| time/              |             |
|    fps             | 57          |
|    iterations      | 1           |
|    time_elapsed    | 35          |
|    total_timesteps | 1206272     |
------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.31422737 |
| rollout/                 |             |
|    ep_len_mean           | 95          |
|    ep_rew_mean           | -37.7       |
| time/                    |             |
|    fps                   | 57          |
|    iterations            | 2           |
|    time_elapsed          | 71          |
|    total_timesteps       | 1208320     |
| train/                   |             |
|    approx_kl             | 0.008375957 |
|    clip_fraction         | 0.111       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.97        |
|    cost_value_loss       | 8.31        |
|    cost_values           | 2.9         |
|    entropy               | -0.871      |
|    entropy_loss          | -0.87       |
|    explained_variance    | 0.726       |
|    lagrangian_multiplier | 0.00181     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.7         |
|    n_updates             | 5890        |
|    policy_gradient_loss  | 0.000902    |
|    std                   | 0.422       |
|    value_loss            | 9.09        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.26700503 |
| rollout/                 |             |
|    ep_len_mean           | 91.5        |
|    ep_rew_mean           | -36.8       |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 3           |
|    time_elapsed          | 99          |
|    total_timesteps       | 1210368     |
| train/                   |             |
|    approx_kl             | 0.011863979 |
|    clip_fraction         | 0.0849      |
|    clip_range            | 0.2         |
|    cost_returns          | 5           |
|    cost_value_loss       | 8.82        |
|    cost_values           | 2.89        |
|    entropy               | -0.864      |
|    entropy_loss          | -0.868      |
|    explained_variance    | 0.759       |
|    lagrangian_multiplier | 0.00429     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.74        |
|    n_updates             | 5900        |
|    policy_gradient_loss  | -0.00299    |
|    std                   | 0.42        |
|    value_loss            | 9.14        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.2          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 6.2          |
| reward                   | -0.2755201   |
| rollout/                 |              |
|    ep_len_mean           | 93.4         |
|    ep_rew_mean           | -37.8        |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 4            |
|    time_elapsed          | 129          |
|    total_timesteps       | 1212416      |
| train/                   |              |
|    approx_kl             | 0.0076136063 |
|    clip_fraction         | 0.0911       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.79         |
|    cost_value_loss       | 7.72         |
|    cost_values           | 2.89         |
|    entropy               | -0.854       |
|    entropy_loss          | -0.859       |
|    explained_variance    | 0.785        |
|    lagrangian_multiplier | 0.00299      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.86         |
|    n_updates             | 5910         |
|    policy_gradient_loss  | -0.0048      |
|    std                   | 0.418        |
|    value_loss            | 7.76         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.8846586  |
| rollout/                 |             |
|    ep_len_mean           | 92.7        |
|    ep_rew_mean           | -37.4       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 5           |
|    time_elapsed          | 159         |
|    total_timesteps       | 1214464     |
| train/                   |             |
|    approx_kl             | 0.008206837 |
|    clip_fraction         | 0.0993      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.89        |
|    cost_value_loss       | 8.17        |
|    cost_values           | 2.87        |
|    entropy               | -0.849      |
|    entropy_loss          | -0.851      |
|    explained_variance    | 0.592       |
|    lagrangian_multiplier | 0.00392     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.78        |
|    n_updates             | 5920        |
|    policy_gradient_loss  | -0.00587    |
|    std                   | 0.416       |
|    value_loss            | 9.9         |
------------------------------------------
------------------------------------------
| avg_speed                | 3.79        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.79        |
| reward                   | -0.6361882  |
| rollout/                 |             |
|    ep_len_mean           | 92.8        |
|    ep_rew_mean           | -37.8       |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 6           |
|    time_elapsed          | 196         |
|    total_timesteps       | 1216512     |
| train/                   |             |
|    approx_kl             | 0.012788212 |
|    clip_fraction         | 0.109       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.01        |
|    cost_value_loss       | 7.82        |
|    cost_values           | 2.86        |
|    entropy               | -0.841      |
|    entropy_loss          | -0.845      |
|    explained_variance    | 0.674       |
|    lagrangian_multiplier | 0.00384     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.76        |
|    n_updates             | 5930        |
|    policy_gradient_loss  | -0.0014     |
|    std                   | 0.415       |
|    value_loss            | 9.88        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.8         |
| reward                   | -0.50621855 |
| rollout/                 |             |
|    ep_len_mean           | 93.5        |
|    ep_rew_mean           | -37.7       |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 7           |
|    time_elapsed          | 231         |
|    total_timesteps       | 1218560     |
| train/                   |             |
|    approx_kl             | 0.008672015 |
|    clip_fraction         | 0.105       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.93        |
|    cost_value_loss       | 7.9         |
|    cost_values           | 2.9         |
|    entropy               | -0.844      |
|    entropy_loss          | -0.841      |
|    explained_variance    | 0.703       |
|    lagrangian_multiplier | 0.00252     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.1         |
|    n_updates             | 5940        |
|    policy_gradient_loss  | -0.000393   |
|    std                   | 0.416       |
|    value_loss            | 10.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.8         |
| reward                   | -0.6951141  |
| rollout/                 |             |
|    ep_len_mean           | 93.3        |
|    ep_rew_mean           | -37.4       |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 8           |
|    time_elapsed          | 266         |
|    total_timesteps       | 1220608     |
| train/                   |             |
|    approx_kl             | 0.006997296 |
|    clip_fraction         | 0.0886      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.12        |
|    cost_value_loss       | 8.69        |
|    cost_values           | 2.9         |
|    entropy               | -0.831      |
|    entropy_loss          | -0.838      |
|    explained_variance    | 0.784       |
|    lagrangian_multiplier | 0.00168     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.56        |
|    n_updates             | 5950        |
|    policy_gradient_loss  | -0.000264   |
|    std                   | 0.414       |
|    value_loss            | 7.64        |
------------------------------------------
------------------------------------------
| avg_speed                | 6           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6           |
| reward                   | -0.31889355 |
| rollout/                 |             |
|    ep_len_mean           | 94.1        |
|    ep_rew_mean           | -37.4       |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 9           |
|    time_elapsed          | 305         |
|    total_timesteps       | 1222656     |
| train/                   |             |
|    approx_kl             | 0.009329214 |
|    clip_fraction         | 0.105       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.87        |
|    cost_value_loss       | 7.23        |
|    cost_values           | 2.92        |
|    entropy               | -0.816      |
|    entropy_loss          | -0.823      |
|    explained_variance    | 0.73        |
|    lagrangian_multiplier | 0.00222     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.47        |
|    n_updates             | 5960        |
|    policy_gradient_loss  | -0.00121    |
|    std                   | 0.411       |
|    value_loss            | 8.37        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.2         |
| reward                   | -0.5823927  |
| rollout/                 |             |
|    ep_len_mean           | 96.4        |
|    ep_rew_mean           | -37.8       |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 10          |
|    time_elapsed          | 340         |
|    total_timesteps       | 1224704     |
| train/                   |             |
|    approx_kl             | 0.013447041 |
|    clip_fraction         | 0.115       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.24        |
|    cost_value_loss       | 9.05        |
|    cost_values           | 2.92        |
|    entropy               | -0.807      |
|    entropy_loss          | -0.811      |
|    explained_variance    | 0.733       |
|    lagrangian_multiplier | 0.00333     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.12        |
|    n_updates             | 5970        |
|    policy_gradient_loss  | -0.00443    |
|    std                   | 0.41        |
|    value_loss            | 8.05        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.31016788 |
| rollout/                 |             |
|    ep_len_mean           | 98.4        |
|    ep_rew_mean           | -38.3       |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 11          |
|    time_elapsed          | 374         |
|    total_timesteps       | 1226752     |
| train/                   |             |
|    approx_kl             | 0.007390229 |
|    clip_fraction         | 0.105       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.71        |
|    cost_value_loss       | 11.6        |
|    cost_values           | 2.95        |
|    entropy               | -0.793      |
|    entropy_loss          | -0.8        |
|    explained_variance    | 0.683       |
|    lagrangian_multiplier | 0.00423     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.97        |
|    n_updates             | 5980        |
|    policy_gradient_loss  | -0.00123    |
|    std                   | 0.408       |
|    value_loss            | 7.99        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.5         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.5         |
| reward                   | -0.60782325 |
| rollout/                 |             |
|    ep_len_mean           | 95.2        |
|    ep_rew_mean           | -37.3       |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 12          |
|    time_elapsed          | 410         |
|    total_timesteps       | 1228800     |
| train/                   |             |
|    approx_kl             | 0.008827771 |
|    clip_fraction         | 0.139       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.07        |
|    cost_value_loss       | 8.01        |
|    cost_values           | 2.93        |
|    entropy               | -0.787      |
|    entropy_loss          | -0.789      |
|    explained_variance    | 0.738       |
|    lagrangian_multiplier | 0.00276     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.98        |
|    n_updates             | 5990        |
|    policy_gradient_loss  | 0.000271    |
|    std                   | 0.407       |
|    value_loss            | 8.53        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.28108147 |
| rollout/                 |             |
|    ep_len_mean           | 92.5        |
|    ep_rew_mean           | -36.7       |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 13          |
|    time_elapsed          | 446         |
|    total_timesteps       | 1230848     |
| train/                   |             |
|    approx_kl             | 0.010194425 |
|    clip_fraction         | 0.139       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.87        |
|    cost_value_loss       | 7.65        |
|    cost_values           | 2.92        |
|    entropy               | -0.781      |
|    entropy_loss          | -0.784      |
|    explained_variance    | 0.736       |
|    lagrangian_multiplier | 0.00148     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.23        |
|    n_updates             | 6000        |
|    policy_gradient_loss  | -0.00129    |
|    std                   | 0.406       |
|    value_loss            | 9.48        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.71        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.71        |
| reward                   | -0.21714397 |
| rollout/                 |             |
|    ep_len_mean           | 86          |
|    ep_rew_mean           | -35.1       |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 14          |
|    time_elapsed          | 480         |
|    total_timesteps       | 1232896     |
| train/                   |             |
|    approx_kl             | 0.007364639 |
|    clip_fraction         | 0.0857      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.73        |
|    cost_value_loss       | 7.41        |
|    cost_values           | 2.91        |
|    entropy               | -0.783      |
|    entropy_loss          | -0.782      |
|    explained_variance    | 0.736       |
|    lagrangian_multiplier | 0.00318     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.55        |
|    n_updates             | 6010        |
|    policy_gradient_loss  | -0.00269    |
|    std                   | 0.407       |
|    value_loss            | 8.61        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.91922766 |
| rollout/                 |             |
|    ep_len_mean           | 83.5        |
|    ep_rew_mean           | -34.2       |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 15          |
|    time_elapsed          | 517         |
|    total_timesteps       | 1234944     |
| train/                   |             |
|    approx_kl             | 0.010603152 |
|    clip_fraction         | 0.12        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.76        |
|    cost_value_loss       | 6.93        |
|    cost_values           | 2.9         |
|    entropy               | -0.778      |
|    entropy_loss          | -0.781      |
|    explained_variance    | 0.796       |
|    lagrangian_multiplier | 0.00274     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.77        |
|    n_updates             | 6020        |
|    policy_gradient_loss  | -0.00407    |
|    std                   | 0.407       |
|    value_loss            | 7.74        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.23197576  |
| rollout/                 |              |
|    ep_len_mean           | 83.7         |
|    ep_rew_mean           | -34.3        |
| time/                    |              |
|    fps                   | 58           |
|    iterations            | 16           |
|    time_elapsed          | 556          |
|    total_timesteps       | 1236992      |
| train/                   |              |
|    approx_kl             | 0.0127039235 |
|    clip_fraction         | 0.105        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.16         |
|    cost_value_loss       | 9.05         |
|    cost_values           | 2.91         |
|    entropy               | -0.772       |
|    entropy_loss          | -0.775       |
|    explained_variance    | 0.775        |
|    lagrangian_multiplier | 0.00433      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.6          |
|    n_updates             | 6030         |
|    policy_gradient_loss  | -0.00175     |
|    std                   | 0.406        |
|    value_loss            | 7.26         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.8403043  |
| rollout/                 |             |
|    ep_len_mean           | 85          |
|    ep_rew_mean           | -34.7       |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 17          |
|    time_elapsed          | 588         |
|    total_timesteps       | 1239040     |
| train/                   |             |
|    approx_kl             | 0.012040031 |
|    clip_fraction         | 0.0897      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.23        |
|    cost_value_loss       | 9.53        |
|    cost_values           | 2.93        |
|    entropy               | -0.777      |
|    entropy_loss          | -0.774      |
|    explained_variance    | 0.758       |
|    lagrangian_multiplier | 0.00324     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.99        |
|    n_updates             | 6040        |
|    policy_gradient_loss  | -0.00244    |
|    std                   | 0.408       |
|    value_loss            | 7.65        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.52337486 |
| rollout/                 |             |
|    ep_len_mean           | 87.4        |
|    ep_rew_mean           | -35.2       |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 18          |
|    time_elapsed          | 616         |
|    total_timesteps       | 1241088     |
| train/                   |             |
|    approx_kl             | 0.011051992 |
|    clip_fraction         | 0.114       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.04        |
|    cost_value_loss       | 8.31        |
|    cost_values           | 2.91        |
|    entropy               | -0.773      |
|    entropy_loss          | -0.776      |
|    explained_variance    | 0.763       |
|    lagrangian_multiplier | 0.00317     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.87        |
|    n_updates             | 6050        |
|    policy_gradient_loss  | -0.00313    |
|    std                   | 0.408       |
|    value_loss            | 7.95        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.26086265  |
| rollout/                 |              |
|    ep_len_mean           | 88.7         |
|    ep_rew_mean           | -35.6        |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 19           |
|    time_elapsed          | 642          |
|    total_timesteps       | 1243136      |
| train/                   |              |
|    approx_kl             | 0.0066794353 |
|    clip_fraction         | 0.0889       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.04         |
|    cost_value_loss       | 8.29         |
|    cost_values           | 2.9          |
|    entropy               | -0.764       |
|    entropy_loss          | -0.768       |
|    explained_variance    | 0.771        |
|    lagrangian_multiplier | 0.00184      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.22         |
|    n_updates             | 6060         |
|    policy_gradient_loss  | -0.00101     |
|    std                   | 0.407        |
|    value_loss            | 7.34         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.40017375 |
| rollout/                 |             |
|    ep_len_mean           | 85.3        |
|    ep_rew_mean           | -35         |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 20          |
|    time_elapsed          | 666         |
|    total_timesteps       | 1245184     |
| train/                   |             |
|    approx_kl             | 0.013966802 |
|    clip_fraction         | 0.11        |
|    clip_range            | 0.2         |
|    cost_returns          | 5.23        |
|    cost_value_loss       | 9.91        |
|    cost_values           | 2.92        |
|    entropy               | -0.756      |
|    entropy_loss          | -0.76       |
|    explained_variance    | 0.728       |
|    lagrangian_multiplier | 0.00414     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.68        |
|    n_updates             | 6070        |
|    policy_gradient_loss  | -0.00323    |
|    std                   | 0.406       |
|    value_loss            | 7.44        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.3031557  |
| rollout/                 |             |
|    ep_len_mean           | 88          |
|    ep_rew_mean           | -36.2       |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 21          |
|    time_elapsed          | 689         |
|    total_timesteps       | 1247232     |
| train/                   |             |
|    approx_kl             | 0.009010358 |
|    clip_fraction         | 0.112       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.19        |
|    cost_value_loss       | 9.08        |
|    cost_values           | 2.92        |
|    entropy               | -0.748      |
|    entropy_loss          | -0.752      |
|    explained_variance    | 0.787       |
|    lagrangian_multiplier | 0.00296     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.02        |
|    n_updates             | 6080        |
|    policy_gradient_loss  | -0.00236    |
|    std                   | 0.405       |
|    value_loss            | 8.04        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.88        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.88        |
| reward                   | -0.2082206  |
| rollout/                 |             |
|    ep_len_mean           | 90.5        |
|    ep_rew_mean           | -37.1       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 22          |
|    time_elapsed          | 712         |
|    total_timesteps       | 1249280     |
| train/                   |             |
|    approx_kl             | 0.005800993 |
|    clip_fraction         | 0.121       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.67        |
|    cost_value_loss       | 7.9         |
|    cost_values           | 2.89        |
|    entropy               | -0.746      |
|    entropy_loss          | -0.747      |
|    explained_variance    | 0.705       |
|    lagrangian_multiplier | 0.00289     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.93        |
|    n_updates             | 6090        |
|    policy_gradient_loss  | -0.00266    |
|    std                   | 0.404       |
|    value_loss            | 8.42        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.272137   |
| rollout/                 |             |
|    ep_len_mean           | 84.7        |
|    ep_rew_mean           | -35.6       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 23          |
|    time_elapsed          | 737         |
|    total_timesteps       | 1251328     |
| train/                   |             |
|    approx_kl             | 0.011026465 |
|    clip_fraction         | 0.0963      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.04        |
|    cost_value_loss       | 8.14        |
|    cost_values           | 2.89        |
|    entropy               | -0.741      |
|    entropy_loss          | -0.744      |
|    explained_variance    | 0.679       |
|    lagrangian_multiplier | 0.00353     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.18        |
|    n_updates             | 6100        |
|    policy_gradient_loss  | -0.00225    |
|    std                   | 0.404       |
|    value_loss            | 9.76        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.7185601  |
| rollout/                 |             |
|    ep_len_mean           | 84.9        |
|    ep_rew_mean           | -35.6       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 24          |
|    time_elapsed          | 766         |
|    total_timesteps       | 1253376     |
| train/                   |             |
|    approx_kl             | 0.008310561 |
|    clip_fraction         | 0.11        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.75        |
|    cost_value_loss       | 7.6         |
|    cost_values           | 2.91        |
|    entropy               | -0.746      |
|    entropy_loss          | -0.743      |
|    explained_variance    | 0.733       |
|    lagrangian_multiplier | 0.00238     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.56        |
|    n_updates             | 6110        |
|    policy_gradient_loss  | -0.000791   |
|    std                   | 0.407       |
|    value_loss            | 9.39        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.8         |
| reward                   | -0.17669845 |
| rollout/                 |             |
|    ep_len_mean           | 84.7        |
|    ep_rew_mean           | -35.3       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 25          |
|    time_elapsed          | 795         |
|    total_timesteps       | 1255424     |
| train/                   |             |
|    approx_kl             | 0.00842404  |
|    clip_fraction         | 0.0846      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.84        |
|    cost_value_loss       | 7.57        |
|    cost_values           | 2.9         |
|    entropy               | -0.739      |
|    entropy_loss          | -0.744      |
|    explained_variance    | 0.779       |
|    lagrangian_multiplier | 0.00372     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.49        |
|    n_updates             | 6120        |
|    policy_gradient_loss  | -0.000944   |
|    std                   | 0.406       |
|    value_loss            | 8.18        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.21905386 |
| rollout/                 |             |
|    ep_len_mean           | 80.8        |
|    ep_rew_mean           | -33.9       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 26          |
|    time_elapsed          | 825         |
|    total_timesteps       | 1257472     |
| train/                   |             |
|    approx_kl             | 0.011251973 |
|    clip_fraction         | 0.108       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.78        |
|    cost_value_loss       | 7.73        |
|    cost_values           | 2.9         |
|    entropy               | -0.74       |
|    entropy_loss          | -0.738      |
|    explained_variance    | 0.776       |
|    lagrangian_multiplier | 0.00327     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.42        |
|    n_updates             | 6130        |
|    policy_gradient_loss  | -0.00384    |
|    std                   | 0.407       |
|    value_loss            | 6.47        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.2906271 |
| rollout/                 |            |
|    ep_len_mean           | 82.1       |
|    ep_rew_mean           | -34.2      |
| time/                    |            |
|    fps                   | 64         |
|    iterations            | 27         |
|    time_elapsed          | 854        |
|    total_timesteps       | 1259520    |
| train/                   |            |
|    approx_kl             | 0.00869537 |
|    clip_fraction         | 0.122      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.99       |
|    cost_value_loss       | 8.46       |
|    cost_values           | 2.87       |
|    entropy               | -0.741     |
|    entropy_loss          | -0.741     |
|    explained_variance    | 0.813      |
|    lagrangian_multiplier | 0.00292    |
|    learning_rate         | 0.0003     |
|    loss                  | 4.6        |
|    n_updates             | 6140       |
|    policy_gradient_loss  | -0.00196   |
|    std                   | 0.406      |
|    value_loss            | 6.69       |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.48        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.48        |
| reward                   | -0.32441998 |
| rollout/                 |             |
|    ep_len_mean           | 84.8        |
|    ep_rew_mean           | -35         |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 28          |
|    time_elapsed          | 885         |
|    total_timesteps       | 1261568     |
| train/                   |             |
|    approx_kl             | 0.010869314 |
|    clip_fraction         | 0.116       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.25        |
|    cost_value_loss       | 9.34        |
|    cost_values           | 2.9         |
|    entropy               | -0.733      |
|    entropy_loss          | -0.737      |
|    explained_variance    | 0.796       |
|    lagrangian_multiplier | 0.00287     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.93        |
|    n_updates             | 6150        |
|    policy_gradient_loss  | -0.00227    |
|    std                   | 0.404       |
|    value_loss            | 6.47        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.2         |
| reward                   | -0.80146    |
| rollout/                 |             |
|    ep_len_mean           | 82.2        |
|    ep_rew_mean           | -34.3       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 29          |
|    time_elapsed          | 920         |
|    total_timesteps       | 1263616     |
| train/                   |             |
|    approx_kl             | 0.010146753 |
|    clip_fraction         | 0.103       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.86        |
|    cost_value_loss       | 8.15        |
|    cost_values           | 2.88        |
|    entropy               | -0.733      |
|    entropy_loss          | -0.732      |
|    explained_variance    | 0.79        |
|    lagrangian_multiplier | 0.00475     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.18        |
|    n_updates             | 6160        |
|    policy_gradient_loss  | -0.00124    |
|    std                   | 0.404       |
|    value_loss            | 6.85        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.20204781  |
| rollout/                 |              |
|    ep_len_mean           | 83.9         |
|    ep_rew_mean           | -34.7        |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 30           |
|    time_elapsed          | 957          |
|    total_timesteps       | 1265664      |
| train/                   |              |
|    approx_kl             | 0.0060008005 |
|    clip_fraction         | 0.0968       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.59         |
|    cost_value_loss       | 6.9          |
|    cost_values           | 2.85         |
|    entropy               | -0.727       |
|    entropy_loss          | -0.731       |
|    explained_variance    | 0.829        |
|    lagrangian_multiplier | 0.0023       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.77         |
|    n_updates             | 6170         |
|    policy_gradient_loss  | -0.000664    |
|    std                   | 0.403        |
|    value_loss            | 6.82         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.5216522  |
| rollout/                 |             |
|    ep_len_mean           | 87          |
|    ep_rew_mean           | -35.9       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 31          |
|    time_elapsed          | 993         |
|    total_timesteps       | 1267712     |
| train/                   |             |
|    approx_kl             | 0.012632329 |
|    clip_fraction         | 0.0987      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.8         |
|    cost_value_loss       | 7.25        |
|    cost_values           | 2.91        |
|    entropy               | -0.719      |
|    entropy_loss          | -0.723      |
|    explained_variance    | 0.769       |
|    lagrangian_multiplier | 0.00316     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.51        |
|    n_updates             | 6180        |
|    policy_gradient_loss  | -0.00154    |
|    std                   | 0.402       |
|    value_loss            | 7.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.6         |
| reward                   | -0.7668569  |
| rollout/                 |             |
|    ep_len_mean           | 84.6        |
|    ep_rew_mean           | -35.2       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 32          |
|    time_elapsed          | 1027        |
|    total_timesteps       | 1269760     |
| train/                   |             |
|    approx_kl             | 0.010910282 |
|    clip_fraction         | 0.117       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.26        |
|    cost_value_loss       | 9.36        |
|    cost_values           | 2.9         |
|    entropy               | -0.713      |
|    entropy_loss          | -0.715      |
|    explained_variance    | 0.788       |
|    lagrangian_multiplier | 0.00219     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.46        |
|    n_updates             | 6190        |
|    policy_gradient_loss  | -0.00151    |
|    std                   | 0.402       |
|    value_loss            | 7.23        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.2         |
| reward                   | -0.68045574 |
| rollout/                 |             |
|    ep_len_mean           | 87.1        |
|    ep_rew_mean           | -35.5       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 33          |
|    time_elapsed          | 1062        |
|    total_timesteps       | 1271808     |
| train/                   |             |
|    approx_kl             | 0.007667052 |
|    clip_fraction         | 0.0963      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.22        |
|    cost_value_loss       | 9.68        |
|    cost_values           | 2.92        |
|    entropy               | -0.713      |
|    entropy_loss          | -0.714      |
|    explained_variance    | 0.748       |
|    lagrangian_multiplier | 0.00375     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.09        |
|    n_updates             | 6200        |
|    policy_gradient_loss  | -0.00304    |
|    std                   | 0.402       |
|    value_loss            | 7.99        |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.7362821  |
| rollout/                 |             |
|    ep_len_mean           | 89.8        |
|    ep_rew_mean           | -36.1       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 34          |
|    time_elapsed          | 1098        |
|    total_timesteps       | 1273856     |
| train/                   |             |
|    approx_kl             | 0.008097847 |
|    clip_fraction         | 0.0946      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.17        |
|    cost_value_loss       | 8.74        |
|    cost_values           | 2.95        |
|    entropy               | -0.707      |
|    entropy_loss          | -0.711      |
|    explained_variance    | 0.674       |
|    lagrangian_multiplier | 0.00287     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.13        |
|    n_updates             | 6210        |
|    policy_gradient_loss  | -0.00081    |
|    std                   | 0.401       |
|    value_loss            | 7.96        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.7887077  |
| rollout/                 |             |
|    ep_len_mean           | 88.2        |
|    ep_rew_mean           | -35.5       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 35          |
|    time_elapsed          | 1136        |
|    total_timesteps       | 1275904     |
| train/                   |             |
|    approx_kl             | 0.006544959 |
|    clip_fraction         | 0.0836      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.97        |
|    cost_value_loss       | 8.02        |
|    cost_values           | 2.92        |
|    entropy               | -0.698      |
|    entropy_loss          | -0.703      |
|    explained_variance    | 0.724       |
|    lagrangian_multiplier | 0.00218     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.96        |
|    n_updates             | 6220        |
|    policy_gradient_loss  | -0.000612   |
|    std                   | 0.4         |
|    value_loss            | 8.25        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.20928237 |
| rollout/                 |             |
|    ep_len_mean           | 86.7        |
|    ep_rew_mean           | -35.1       |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 36          |
|    time_elapsed          | 1173        |
|    total_timesteps       | 1277952     |
| train/                   |             |
|    approx_kl             | 0.010265129 |
|    clip_fraction         | 0.117       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.24        |
|    cost_value_loss       | 9.19        |
|    cost_values           | 2.94        |
|    entropy               | -0.689      |
|    entropy_loss          | -0.693      |
|    explained_variance    | 0.719       |
|    lagrangian_multiplier | 0.0038      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.15        |
|    n_updates             | 6230        |
|    policy_gradient_loss  | -0.00154    |
|    std                   | 0.398       |
|    value_loss            | 8.81        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.54        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.54        |
| reward                   | -0.1660441  |
| rollout/                 |             |
|    ep_len_mean           | 82.5        |
|    ep_rew_mean           | -34.2       |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 37          |
|    time_elapsed          | 1210        |
|    total_timesteps       | 1280000     |
| train/                   |             |
|    approx_kl             | 0.015769977 |
|    clip_fraction         | 0.0747      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.94        |
|    cost_value_loss       | 8.34        |
|    cost_values           | 2.9         |
|    entropy               | -0.675      |
|    entropy_loss          | -0.682      |
|    explained_variance    | 0.75        |
|    lagrangian_multiplier | 0.00317     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.13        |
|    n_updates             | 6240        |
|    policy_gradient_loss  | -0.00159    |
|    std                   | 0.395       |
|    value_loss            | 8.12        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.17916673 |
| rollout/                 |             |
|    ep_len_mean           | 79.4        |
|    ep_rew_mean           | -33.9       |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 38          |
|    time_elapsed          | 1245        |
|    total_timesteps       | 1282048     |
| train/                   |             |
|    approx_kl             | 0.009072028 |
|    clip_fraction         | 0.161       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.95        |
|    cost_value_loss       | 7.81        |
|    cost_values           | 2.91        |
|    entropy               | -0.665      |
|    entropy_loss          | -0.67       |
|    explained_variance    | 0.742       |
|    lagrangian_multiplier | 0.00338     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.81        |
|    n_updates             | 6250        |
|    policy_gradient_loss  | 0.00171     |
|    std                   | 0.393       |
|    value_loss            | 8.52        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.2         |
| reward                   | -0.8283006  |
| rollout/                 |             |
|    ep_len_mean           | 81.1        |
|    ep_rew_mean           | -34.6       |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 39          |
|    time_elapsed          | 1275        |
|    total_timesteps       | 1284096     |
| train/                   |             |
|    approx_kl             | 0.014747195 |
|    clip_fraction         | 0.126       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.44        |
|    cost_value_loss       | 5.94        |
|    cost_values           | 2.89        |
|    entropy               | -0.659      |
|    entropy_loss          | -0.662      |
|    explained_variance    | 0.787       |
|    lagrangian_multiplier | 0.00157     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.52        |
|    n_updates             | 6260        |
|    policy_gradient_loss  | -0.0032     |
|    std                   | 0.392       |
|    value_loss            | 8.53        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.32573515 |
| rollout/                 |             |
|    ep_len_mean           | 75.3        |
|    ep_rew_mean           | -32.5       |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 40          |
|    time_elapsed          | 1304        |
|    total_timesteps       | 1286144     |
| train/                   |             |
|    approx_kl             | 0.010086702 |
|    clip_fraction         | 0.128       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.82        |
|    cost_value_loss       | 6.67        |
|    cost_values           | 2.89        |
|    entropy               | -0.661      |
|    entropy_loss          | -0.66       |
|    explained_variance    | 0.719       |
|    lagrangian_multiplier | 0.00278     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.98        |
|    n_updates             | 6270        |
|    policy_gradient_loss  | -0.00367    |
|    std                   | 0.393       |
|    value_loss            | 8.83        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.29        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.29        |
| reward                   | -0.21942942 |
| rollout/                 |             |
|    ep_len_mean           | 75.8        |
|    ep_rew_mean           | -32.7       |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 41          |
|    time_elapsed          | 1334        |
|    total_timesteps       | 1288192     |
| train/                   |             |
|    approx_kl             | 0.017779704 |
|    clip_fraction         | 0.1         |
|    clip_range            | 0.2         |
|    cost_returns          | 4.67        |
|    cost_value_loss       | 6.71        |
|    cost_values           | 2.91        |
|    entropy               | -0.655      |
|    entropy_loss          | -0.659      |
|    explained_variance    | 0.779       |
|    lagrangian_multiplier | 0.00268     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.74        |
|    n_updates             | 6280        |
|    policy_gradient_loss  | -0.0027     |
|    std                   | 0.392       |
|    value_loss            | 7.53        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -0.23223564  |
| rollout/                 |              |
|    ep_len_mean           | 78           |
|    ep_rew_mean           | -33          |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 42           |
|    time_elapsed          | 1362         |
|    total_timesteps       | 1290240      |
| train/                   |              |
|    approx_kl             | 0.0066841925 |
|    clip_fraction         | 0.136        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.76         |
|    cost_value_loss       | 7.59         |
|    cost_values           | 2.9          |
|    entropy               | -0.645       |
|    entropy_loss          | -0.649       |
|    explained_variance    | 0.834        |
|    lagrangian_multiplier | 0.00229      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.7          |
|    n_updates             | 6290         |
|    policy_gradient_loss  | 0.0014       |
|    std                   | 0.39         |
|    value_loss            | 6.17         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.2          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.2          |
| reward                   | -0.77780426  |
| rollout/                 |              |
|    ep_len_mean           | 76           |
|    ep_rew_mean           | -32.4        |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 43           |
|    time_elapsed          | 1389         |
|    total_timesteps       | 1292288      |
| train/                   |              |
|    approx_kl             | 0.0068424535 |
|    clip_fraction         | 0.157        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.16         |
|    cost_value_loss       | 8.8          |
|    cost_values           | 2.92         |
|    entropy               | -0.641       |
|    entropy_loss          | -0.642       |
|    explained_variance    | 0.825        |
|    lagrangian_multiplier | 0.00281      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.43         |
|    n_updates             | 6300         |
|    policy_gradient_loss  | 0.00137      |
|    std                   | 0.389        |
|    value_loss            | 5.2          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.18609491 |
| rollout/                 |             |
|    ep_len_mean           | 77          |
|    ep_rew_mean           | -32.6       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 44          |
|    time_elapsed          | 1418        |
|    total_timesteps       | 1294336     |
| train/                   |             |
|    approx_kl             | 0.021033088 |
|    clip_fraction         | 0.127       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.66        |
|    cost_value_loss       | 7.22        |
|    cost_values           | 2.88        |
|    entropy               | -0.626      |
|    entropy_loss          | -0.635      |
|    explained_variance    | 0.837       |
|    lagrangian_multiplier | 0.00135     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.24        |
|    n_updates             | 6310        |
|    policy_gradient_loss  | 0.000138    |
|    std                   | 0.387       |
|    value_loss            | 6.24        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.5         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.5         |
| reward                   | -0.18730879 |
| rollout/                 |             |
|    ep_len_mean           | 74.8        |
|    ep_rew_mean           | -31.8       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 45          |
|    time_elapsed          | 1441        |
|    total_timesteps       | 1296384     |
| train/                   |             |
|    approx_kl             | 0.009975874 |
|    clip_fraction         | 0.129       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.95        |
|    cost_value_loss       | 8.17        |
|    cost_values           | 2.9         |
|    entropy               | -0.609      |
|    entropy_loss          | -0.617      |
|    explained_variance    | 0.841       |
|    lagrangian_multiplier | 0.00265     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.53        |
|    n_updates             | 6320        |
|    policy_gradient_loss  | -0.000703   |
|    std                   | 0.384       |
|    value_loss            | 5.63        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.22734372 |
| rollout/                 |             |
|    ep_len_mean           | 71          |
|    ep_rew_mean           | -29.9       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 46          |
|    time_elapsed          | 1464        |
|    total_timesteps       | 1298432     |
| train/                   |             |
|    approx_kl             | 0.01201416  |
|    clip_fraction         | 0.107       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.87        |
|    cost_value_loss       | 7.28        |
|    cost_values           | 2.92        |
|    entropy               | -0.606      |
|    entropy_loss          | -0.607      |
|    explained_variance    | 0.872       |
|    lagrangian_multiplier | 0.00265     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.25        |
|    n_updates             | 6330        |
|    policy_gradient_loss  | -0.00255    |
|    std                   | 0.383       |
|    value_loss            | 4.64        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.2         |
| reward                   | -0.36036074 |
| rollout/                 |             |
|    ep_len_mean           | 68.5        |
|    ep_rew_mean           | -29         |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 47          |
|    time_elapsed          | 1487        |
|    total_timesteps       | 1300480     |
| train/                   |             |
|    approx_kl             | 0.009016727 |
|    clip_fraction         | 0.113       |
|    clip_range            | 0.2         |
|    cost_returns          | 5           |
|    cost_value_loss       | 8.01        |
|    cost_values           | 2.95        |
|    entropy               | -0.596      |
|    entropy_loss          | -0.602      |
|    explained_variance    | 0.851       |
|    lagrangian_multiplier | 0.00423     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.02        |
|    n_updates             | 6340        |
|    policy_gradient_loss  | 0.000679    |
|    std                   | 0.381       |
|    value_loss            | 4.49        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.17807822 |
| rollout/                 |             |
|    ep_len_mean           | 72          |
|    ep_rew_mean           | -29.7       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 48          |
|    time_elapsed          | 1520        |
|    total_timesteps       | 1302528     |
| train/                   |             |
|    approx_kl             | 0.014291313 |
|    clip_fraction         | 0.142       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.68        |
|    cost_value_loss       | 6.77        |
|    cost_values           | 2.92        |
|    entropy               | -0.588      |
|    entropy_loss          | -0.592      |
|    explained_variance    | 0.87        |
|    lagrangian_multiplier | 0.00259     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.01        |
|    n_updates             | 6350        |
|    policy_gradient_loss  | -0.000723   |
|    std                   | 0.38        |
|    value_loss            | 4.38        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.25871533 |
| rollout/                 |             |
|    ep_len_mean           | 72.7        |
|    ep_rew_mean           | -30.2       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 49          |
|    time_elapsed          | 1556        |
|    total_timesteps       | 1304576     |
| train/                   |             |
|    approx_kl             | 0.009650186 |
|    clip_fraction         | 0.134       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.05        |
|    cost_value_loss       | 8.28        |
|    cost_values           | 2.95        |
|    entropy               | -0.595      |
|    entropy_loss          | -0.59       |
|    explained_variance    | 0.832       |
|    lagrangian_multiplier | 0.00387     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.21        |
|    n_updates             | 6360        |
|    policy_gradient_loss  | -0.00177    |
|    std                   | 0.382       |
|    value_loss            | 4.87        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ent-coefficient-ppol/1vjpjg9h
------------------------------------
| avg_speed          | 8           |
| cost               | 0           |
| is_success         | 1           |
| max_speed          | 8           |
| reward             | -0.11422652 |
| rollout/           |             |
|    ep_len_mean     | 75          |
|    ep_rew_mean     | -31.5       |
| time/              |             |
|    fps             | 63          |
|    iterations      | 1           |
|    time_elapsed    | 32          |
|    total_timesteps | 1306624     |
------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.68841875 |
| rollout/                 |             |
|    ep_len_mean           | 80.1        |
|    ep_rew_mean           | -33.1       |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 2           |
|    time_elapsed          | 67          |
|    total_timesteps       | 1308672     |
| train/                   |             |
|    approx_kl             | 0.018612575 |
|    clip_fraction         | 0.119       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.95        |
|    cost_value_loss       | 7.59        |
|    cost_values           | 2.92        |
|    entropy               | -0.593      |
|    entropy_loss          | -0.594      |
|    explained_variance    | 0.83        |
|    lagrangian_multiplier | 0.0037      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.11        |
|    n_updates             | 6380        |
|    policy_gradient_loss  | -0.0019     |
|    std                   | 0.383       |
|    value_loss            | 5.58        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.41677317  |
| rollout/                 |              |
|    ep_len_mean           | 80.2         |
|    ep_rew_mean           | -33.2        |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 3            |
|    time_elapsed          | 100          |
|    total_timesteps       | 1310720      |
| train/                   |              |
|    approx_kl             | 0.0094528105 |
|    clip_fraction         | 0.118        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.09         |
|    cost_value_loss       | 8.05         |
|    cost_values           | 2.93         |
|    entropy               | -0.589       |
|    entropy_loss          | -0.59        |
|    explained_variance    | 0.827        |
|    lagrangian_multiplier | 0.00412      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.01         |
|    n_updates             | 6390         |
|    policy_gradient_loss  | 0.000856     |
|    std                   | 0.383        |
|    value_loss            | 5.28         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.8         |
| reward                   | -0.7151621  |
| rollout/                 |             |
|    ep_len_mean           | 83.8        |
|    ep_rew_mean           | -34.6       |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 4           |
|    time_elapsed          | 133         |
|    total_timesteps       | 1312768     |
| train/                   |             |
|    approx_kl             | 0.009554599 |
|    clip_fraction         | 0.131       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.16        |
|    cost_value_loss       | 8.61        |
|    cost_values           | 2.94        |
|    entropy               | -0.59       |
|    entropy_loss          | -0.589      |
|    explained_variance    | 0.81        |
|    lagrangian_multiplier | 0.00312     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.6         |
|    n_updates             | 6400        |
|    policy_gradient_loss  | 0.00167     |
|    std                   | 0.384       |
|    value_loss            | 5.87        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.15711832 |
| rollout/                 |             |
|    ep_len_mean           | 81.4        |
|    ep_rew_mean           | -34.2       |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 5           |
|    time_elapsed          | 168         |
|    total_timesteps       | 1314816     |
| train/                   |             |
|    approx_kl             | 0.008240251 |
|    clip_fraction         | 0.118       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.9         |
|    cost_value_loss       | 8.07        |
|    cost_values           | 2.91        |
|    entropy               | -0.586      |
|    entropy_loss          | -0.589      |
|    explained_variance    | 0.78        |
|    lagrangian_multiplier | 0.00285     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.05        |
|    n_updates             | 6410        |
|    policy_gradient_loss  | -0.00273    |
|    std                   | 0.384       |
|    value_loss            | 7.67        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.42098844 |
| rollout/                 |             |
|    ep_len_mean           | 78.8        |
|    ep_rew_mean           | -33.6       |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 6           |
|    time_elapsed          | 205         |
|    total_timesteps       | 1316864     |
| train/                   |             |
|    approx_kl             | 0.03508259  |
|    clip_fraction         | 0.135       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.71        |
|    cost_value_loss       | 7.03        |
|    cost_values           | 2.89        |
|    entropy               | -0.589      |
|    entropy_loss          | -0.587      |
|    explained_variance    | 0.823       |
|    lagrangian_multiplier | 0.00233     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.61        |
|    n_updates             | 6420        |
|    policy_gradient_loss  | 0.00149     |
|    std                   | 0.385       |
|    value_loss            | 7.2         |
------------------------------------------
------------------------------------------
| avg_speed                | 3           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3           |
| reward                   | -0.81409127 |
| rollout/                 |             |
|    ep_len_mean           | 80.4        |
|    ep_rew_mean           | -34.2       |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 7           |
|    time_elapsed          | 238         |
|    total_timesteps       | 1318912     |
| train/                   |             |
|    approx_kl             | 0.014401891 |
|    clip_fraction         | 0.114       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.71        |
|    cost_value_loss       | 7.26        |
|    cost_values           | 2.91        |
|    entropy               | -0.583      |
|    entropy_loss          | -0.587      |
|    explained_variance    | 0.745       |
|    lagrangian_multiplier | 0.00267     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.62        |
|    n_updates             | 6430        |
|    policy_gradient_loss  | -0.00188    |
|    std                   | 0.384       |
|    value_loss            | 7.5         |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.8410095  |
| rollout/                 |             |
|    ep_len_mean           | 81.2        |
|    ep_rew_mean           | -34.3       |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 8           |
|    time_elapsed          | 268         |
|    total_timesteps       | 1320960     |
| train/                   |             |
|    approx_kl             | 0.009019228 |
|    clip_fraction         | 0.0995      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.98        |
|    cost_value_loss       | 8.04        |
|    cost_values           | 2.91        |
|    entropy               | -0.587      |
|    entropy_loss          | -0.584      |
|    explained_variance    | 0.763       |
|    lagrangian_multiplier | 0.00307     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.66        |
|    n_updates             | 6440        |
|    policy_gradient_loss  | -0.000963   |
|    std                   | 0.385       |
|    value_loss            | 7.43        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.28194243  |
| rollout/                 |              |
|    ep_len_mean           | 82           |
|    ep_rew_mean           | -34.5        |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 9            |
|    time_elapsed          | 296          |
|    total_timesteps       | 1323008      |
| train/                   |              |
|    approx_kl             | 0.0067850943 |
|    clip_fraction         | 0.106        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.07         |
|    cost_value_loss       | 9.2          |
|    cost_values           | 2.92         |
|    entropy               | -0.582       |
|    entropy_loss          | -0.585       |
|    explained_variance    | 0.739        |
|    lagrangian_multiplier | 0.0035       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.89         |
|    n_updates             | 6450         |
|    policy_gradient_loss  | -0.00289     |
|    std                   | 0.384        |
|    value_loss            | 8.07         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.20840326 |
| rollout/                 |             |
|    ep_len_mean           | 80.9        |
|    ep_rew_mean           | -34         |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 10          |
|    time_elapsed          | 328         |
|    total_timesteps       | 1325056     |
| train/                   |             |
|    approx_kl             | 0.016933853 |
|    clip_fraction         | 0.114       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.15        |
|    cost_value_loss       | 9.76        |
|    cost_values           | 2.92        |
|    entropy               | -0.567      |
|    entropy_loss          | -0.574      |
|    explained_variance    | 0.751       |
|    lagrangian_multiplier | 0.00428     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.64        |
|    n_updates             | 6460        |
|    policy_gradient_loss  | -0.00483    |
|    std                   | 0.381       |
|    value_loss            | 8.2         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.74        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.74        |
| reward                   | -0.20543368 |
| rollout/                 |             |
|    ep_len_mean           | 77.4        |
|    ep_rew_mean           | -33.1       |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 11          |
|    time_elapsed          | 367         |
|    total_timesteps       | 1327104     |
| train/                   |             |
|    approx_kl             | 0.015500799 |
|    clip_fraction         | 0.117       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.98        |
|    cost_value_loss       | 7.77        |
|    cost_values           | 2.93        |
|    entropy               | -0.558      |
|    entropy_loss          | -0.562      |
|    explained_variance    | 0.794       |
|    lagrangian_multiplier | 0.00227     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.87        |
|    n_updates             | 6470        |
|    policy_gradient_loss  | -0.00035    |
|    std                   | 0.38        |
|    value_loss            | 6.84        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.17215376  |
| rollout/                 |              |
|    ep_len_mean           | 77           |
|    ep_rew_mean           | -33          |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 12           |
|    time_elapsed          | 400          |
|    total_timesteps       | 1329152      |
| train/                   |              |
|    approx_kl             | 0.0064349817 |
|    clip_fraction         | 0.0848       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.01         |
|    cost_value_loss       | 8.55         |
|    cost_values           | 2.92         |
|    entropy               | -0.553       |
|    entropy_loss          | -0.555       |
|    explained_variance    | 0.805        |
|    lagrangian_multiplier | 0.00299      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.66         |
|    n_updates             | 6480         |
|    policy_gradient_loss  | -0.00305     |
|    std                   | 0.38         |
|    value_loss            | 6.97         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.2665544   |
| rollout/                 |              |
|    ep_len_mean           | 75.8         |
|    ep_rew_mean           | -32.5        |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 13           |
|    time_elapsed          | 435          |
|    total_timesteps       | 1331200      |
| train/                   |              |
|    approx_kl             | 0.0100066755 |
|    clip_fraction         | 0.0813       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.1          |
|    cost_value_loss       | 8.22         |
|    cost_values           | 2.93         |
|    entropy               | -0.541       |
|    entropy_loss          | -0.548       |
|    explained_variance    | 0.757        |
|    lagrangian_multiplier | 0.00229      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.29         |
|    n_updates             | 6490         |
|    policy_gradient_loss  | 0.0013       |
|    std                   | 0.378        |
|    value_loss            | 7.48         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.32647613 |
| rollout/                 |             |
|    ep_len_mean           | 71.7        |
|    ep_rew_mean           | -31.3       |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 14          |
|    time_elapsed          | 471         |
|    total_timesteps       | 1333248     |
| train/                   |             |
|    approx_kl             | 0.010029797 |
|    clip_fraction         | 0.103       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.66        |
|    cost_value_loss       | 7.53        |
|    cost_values           | 2.89        |
|    entropy               | -0.532      |
|    entropy_loss          | -0.537      |
|    explained_variance    | 0.801       |
|    lagrangian_multiplier | 0.00211     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.92        |
|    n_updates             | 6500        |
|    policy_gradient_loss  | -0.00378    |
|    std                   | 0.377       |
|    value_loss            | 7.22        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.23714098 |
| rollout/                 |             |
|    ep_len_mean           | 71.6        |
|    ep_rew_mean           | -31.1       |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 15          |
|    time_elapsed          | 504         |
|    total_timesteps       | 1335296     |
| train/                   |             |
|    approx_kl             | 0.018319422 |
|    clip_fraction         | 0.133       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.45        |
|    cost_value_loss       | 6.08        |
|    cost_values           | 2.9         |
|    entropy               | -0.529      |
|    entropy_loss          | -0.53       |
|    explained_variance    | 0.854       |
|    lagrangian_multiplier | 0.00228     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.28        |
|    n_updates             | 6510        |
|    policy_gradient_loss  | -0.000175   |
|    std                   | 0.376       |
|    value_loss            | 5.48        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.4          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.4          |
| reward                   | -0.6134725   |
| rollout/                 |              |
|    ep_len_mean           | 69.9         |
|    ep_rew_mean           | -30.7        |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 16           |
|    time_elapsed          | 542          |
|    total_timesteps       | 1337344      |
| train/                   |              |
|    approx_kl             | 0.0066847606 |
|    clip_fraction         | 0.104        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.79         |
|    cost_value_loss       | 7.58         |
|    cost_values           | 2.9          |
|    entropy               | -0.527       |
|    entropy_loss          | -0.528       |
|    explained_variance    | 0.85         |
|    lagrangian_multiplier | 0.00272      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.47         |
|    n_updates             | 6520         |
|    policy_gradient_loss  | -0.000506    |
|    std                   | 0.376        |
|    value_loss            | 5.59         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3326737  |
| rollout/                 |             |
|    ep_len_mean           | 68.4        |
|    ep_rew_mean           | -30.4       |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 17          |
|    time_elapsed          | 576         |
|    total_timesteps       | 1339392     |
| train/                   |             |
|    approx_kl             | 0.011307117 |
|    clip_fraction         | 0.136       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.84        |
|    cost_value_loss       | 7.86        |
|    cost_values           | 2.91        |
|    entropy               | -0.527      |
|    entropy_loss          | -0.527      |
|    explained_variance    | 0.859       |
|    lagrangian_multiplier | 0.00303     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.43        |
|    n_updates             | 6530        |
|    policy_gradient_loss  | 0.00127     |
|    std                   | 0.377       |
|    value_loss            | 5.18        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.24547286 |
| rollout/                 |             |
|    ep_len_mean           | 70.4        |
|    ep_rew_mean           | -30.9       |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 18          |
|    time_elapsed          | 609         |
|    total_timesteps       | 1341440     |
| train/                   |             |
|    approx_kl             | 0.018696323 |
|    clip_fraction         | 0.126       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.61        |
|    cost_value_loss       | 6.9         |
|    cost_values           | 2.9         |
|    entropy               | -0.529      |
|    entropy_loss          | -0.529      |
|    explained_variance    | 0.858       |
|    lagrangian_multiplier | 0.0022      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.44        |
|    n_updates             | 6540        |
|    policy_gradient_loss  | 6.18e-05    |
|    std                   | 0.377       |
|    value_loss            | 5.51        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.59357274 |
| rollout/                 |             |
|    ep_len_mean           | 73.8        |
|    ep_rew_mean           | -31.5       |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 19          |
|    time_elapsed          | 632         |
|    total_timesteps       | 1343488     |
| train/                   |             |
|    approx_kl             | 0.014026144 |
|    clip_fraction         | 0.168       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.81        |
|    cost_value_loss       | 7.61        |
|    cost_values           | 2.91        |
|    entropy               | -0.531      |
|    entropy_loss          | -0.53       |
|    explained_variance    | 0.831       |
|    lagrangian_multiplier | 0.00223     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.51        |
|    n_updates             | 6550        |
|    policy_gradient_loss  | 8.65e-05    |
|    std                   | 0.377       |
|    value_loss            | 5.38        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.16135336  |
| rollout/                 |              |
|    ep_len_mean           | 74.2         |
|    ep_rew_mean           | -31.5        |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 20           |
|    time_elapsed          | 655          |
|    total_timesteps       | 1345536      |
| train/                   |              |
|    approx_kl             | 0.0121547375 |
|    clip_fraction         | 0.108        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.84         |
|    cost_value_loss       | 6.83         |
|    cost_values           | 2.9          |
|    entropy               | -0.528       |
|    entropy_loss          | -0.53        |
|    explained_variance    | 0.79         |
|    lagrangian_multiplier | 0.00302      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.26         |
|    n_updates             | 6560         |
|    policy_gradient_loss  | -0.00183     |
|    std                   | 0.378        |
|    value_loss            | 6.13         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.35171482 |
| rollout/                 |             |
|    ep_len_mean           | 76.5        |
|    ep_rew_mean           | -32.2       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 21          |
|    time_elapsed          | 679         |
|    total_timesteps       | 1347584     |
| train/                   |             |
|    approx_kl             | 0.009028557 |
|    clip_fraction         | 0.107       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.59        |
|    cost_value_loss       | 6.06        |
|    cost_values           | 2.88        |
|    entropy               | -0.523      |
|    entropy_loss          | -0.526      |
|    explained_variance    | 0.824       |
|    lagrangian_multiplier | 0.00141     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.62        |
|    n_updates             | 6570        |
|    policy_gradient_loss  | 0.000652    |
|    std                   | 0.377       |
|    value_loss            | 5.98        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.8723414  |
| rollout/                 |             |
|    ep_len_mean           | 74.1        |
|    ep_rew_mean           | -31.6       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 22          |
|    time_elapsed          | 704         |
|    total_timesteps       | 1349632     |
| train/                   |             |
|    approx_kl             | 0.018782044 |
|    clip_fraction         | 0.133       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.56        |
|    cost_value_loss       | 6.32        |
|    cost_values           | 2.91        |
|    entropy               | -0.519      |
|    entropy_loss          | -0.521      |
|    explained_variance    | 0.843       |
|    lagrangian_multiplier | 0.00307     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.81        |
|    n_updates             | 6580        |
|    policy_gradient_loss  | -0.00213    |
|    std                   | 0.376       |
|    value_loss            | 5.35        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.12248018 |
| rollout/                 |             |
|    ep_len_mean           | 73.1        |
|    ep_rew_mean           | -31.3       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 23          |
|    time_elapsed          | 732         |
|    total_timesteps       | 1351680     |
| train/                   |             |
|    approx_kl             | 0.007872206 |
|    clip_fraction         | 0.114       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.52        |
|    cost_value_loss       | 6.15        |
|    cost_values           | 2.88        |
|    entropy               | -0.511      |
|    entropy_loss          | -0.515      |
|    explained_variance    | 0.875       |
|    lagrangian_multiplier | 0.00116     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.27        |
|    n_updates             | 6590        |
|    policy_gradient_loss  | -0.000425   |
|    std                   | 0.375       |
|    value_loss            | 5.01        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.06        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.06        |
| reward                   | -0.25212938 |
| rollout/                 |             |
|    ep_len_mean           | 69.2        |
|    ep_rew_mean           | -30.4       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 24          |
|    time_elapsed          | 762         |
|    total_timesteps       | 1353728     |
| train/                   |             |
|    approx_kl             | 0.006737179 |
|    clip_fraction         | 0.114       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.02        |
|    cost_value_loss       | 8.07        |
|    cost_values           | 2.92        |
|    entropy               | -0.505      |
|    entropy_loss          | -0.508      |
|    explained_variance    | 0.735       |
|    lagrangian_multiplier | 0.00341     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.39        |
|    n_updates             | 6600        |
|    policy_gradient_loss  | -0.00454    |
|    std                   | 0.374       |
|    value_loss            | 6.45        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.29797196 |
| rollout/                 |             |
|    ep_len_mean           | 72          |
|    ep_rew_mean           | -31.3       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 25          |
|    time_elapsed          | 793         |
|    total_timesteps       | 1355776     |
| train/                   |             |
|    approx_kl             | 0.013239492 |
|    clip_fraction         | 0.138       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.56        |
|    cost_value_loss       | 6.08        |
|    cost_values           | 2.9         |
|    entropy               | -0.499      |
|    entropy_loss          | -0.502      |
|    explained_variance    | 0.85        |
|    lagrangian_multiplier | 0.00153     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.1         |
|    n_updates             | 6610        |
|    policy_gradient_loss  | -0.0017     |
|    std                   | 0.373       |
|    value_loss            | 5.64        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.08        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.08        |
| reward                   | -0.70830566 |
| rollout/                 |             |
|    ep_len_mean           | 70.4        |
|    ep_rew_mean           | -31.3       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 26          |
|    time_elapsed          | 827         |
|    total_timesteps       | 1357824     |
| train/                   |             |
|    approx_kl             | 0.016672146 |
|    clip_fraction         | 0.144       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.09        |
|    cost_value_loss       | 8.42        |
|    cost_values           | 2.91        |
|    entropy               | -0.499      |
|    entropy_loss          | -0.499      |
|    explained_variance    | 0.837       |
|    lagrangian_multiplier | 0.00272     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.62        |
|    n_updates             | 6620        |
|    policy_gradient_loss  | -0.00167    |
|    std                   | 0.374       |
|    value_loss            | 5.54        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.88        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.88        |
| reward                   | -0.2771758  |
| rollout/                 |             |
|    ep_len_mean           | 75          |
|    ep_rew_mean           | -32.9       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 27          |
|    time_elapsed          | 862         |
|    total_timesteps       | 1359872     |
| train/                   |             |
|    approx_kl             | 0.010210881 |
|    clip_fraction         | 0.107       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.58        |
|    cost_value_loss       | 6.82        |
|    cost_values           | 2.87        |
|    entropy               | -0.49       |
|    entropy_loss          | -0.496      |
|    explained_variance    | 0.821       |
|    lagrangian_multiplier | 0.0032      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.39        |
|    n_updates             | 6630        |
|    policy_gradient_loss  | -0.00314    |
|    std                   | 0.372       |
|    value_loss            | 7.05        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.30550995 |
| rollout/                 |             |
|    ep_len_mean           | 82.5        |
|    ep_rew_mean           | -34.8       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 28          |
|    time_elapsed          | 898         |
|    total_timesteps       | 1361920     |
| train/                   |             |
|    approx_kl             | 0.011107379 |
|    clip_fraction         | 0.0809      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.92        |
|    cost_value_loss       | 7.65        |
|    cost_values           | 2.9         |
|    entropy               | -0.482      |
|    entropy_loss          | -0.486      |
|    explained_variance    | 0.774       |
|    lagrangian_multiplier | 0.00329     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.43        |
|    n_updates             | 6640        |
|    policy_gradient_loss  | -0.00301    |
|    std                   | 0.371       |
|    value_loss            | 6.61        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.14854914 |
| rollout/                 |             |
|    ep_len_mean           | 81.7        |
|    ep_rew_mean           | -34.5       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 29          |
|    time_elapsed          | 933         |
|    total_timesteps       | 1363968     |
| train/                   |             |
|    approx_kl             | 0.014125597 |
|    clip_fraction         | 0.0873      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.26        |
|    cost_value_loss       | 9.05        |
|    cost_values           | 2.94        |
|    entropy               | -0.476      |
|    entropy_loss          | -0.479      |
|    explained_variance    | 0.756       |
|    lagrangian_multiplier | 0.00364     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.54        |
|    n_updates             | 6650        |
|    policy_gradient_loss  | -0.0029     |
|    std                   | 0.37        |
|    value_loss            | 6.42        |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.6        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.6        |
| reward                   | -0.8209277 |
| rollout/                 |            |
|    ep_len_mean           | 83.2       |
|    ep_rew_mean           | -34.5      |
| time/                    |            |
|    fps                   | 63         |
|    iterations            | 30         |
|    time_elapsed          | 965        |
|    total_timesteps       | 1366016    |
| train/                   |            |
|    approx_kl             | 0.00880496 |
|    clip_fraction         | 0.114      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.92       |
|    cost_value_loss       | 7.97       |
|    cost_values           | 2.91       |
|    entropy               | -0.482     |
|    entropy_loss          | -0.478     |
|    explained_variance    | 0.834      |
|    lagrangian_multiplier | 0.0033     |
|    learning_rate         | 0.0003     |
|    loss                  | 4.59       |
|    n_updates             | 6660       |
|    policy_gradient_loss  | -0.000687  |
|    std                   | 0.371      |
|    value_loss            | 6.67       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3156188  |
| rollout/                 |             |
|    ep_len_mean           | 75.4        |
|    ep_rew_mean           | -32         |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 31          |
|    time_elapsed          | 995         |
|    total_timesteps       | 1368064     |
| train/                   |             |
|    approx_kl             | 0.015024604 |
|    clip_fraction         | 0.134       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.92        |
|    cost_value_loss       | 7.71        |
|    cost_values           | 2.91        |
|    entropy               | -0.474      |
|    entropy_loss          | -0.48       |
|    explained_variance    | 0.876       |
|    lagrangian_multiplier | 0.00333     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.09        |
|    n_updates             | 6670        |
|    policy_gradient_loss  | -0.00131    |
|    std                   | 0.37        |
|    value_loss            | 4.95        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.33463746 |
| rollout/                 |             |
|    ep_len_mean           | 73.2        |
|    ep_rew_mean           | -31.5       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 32          |
|    time_elapsed          | 1030        |
|    total_timesteps       | 1370112     |
| train/                   |             |
|    approx_kl             | 0.01148929  |
|    clip_fraction         | 0.114       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.56        |
|    cost_value_loss       | 6.35        |
|    cost_values           | 2.9         |
|    entropy               | -0.468      |
|    entropy_loss          | -0.471      |
|    explained_variance    | 0.847       |
|    lagrangian_multiplier | 0.00245     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.28        |
|    n_updates             | 6680        |
|    policy_gradient_loss  | -0.00215    |
|    std                   | 0.37        |
|    value_loss            | 5.77        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2777151  |
| rollout/                 |             |
|    ep_len_mean           | 74.8        |
|    ep_rew_mean           | -31.9       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 33          |
|    time_elapsed          | 1066        |
|    total_timesteps       | 1372160     |
| train/                   |             |
|    approx_kl             | 0.012867078 |
|    clip_fraction         | 0.145       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.63        |
|    cost_value_loss       | 6.53        |
|    cost_values           | 2.91        |
|    entropy               | -0.464      |
|    entropy_loss          | -0.465      |
|    explained_variance    | 0.817       |
|    lagrangian_multiplier | 0.00318     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.06        |
|    n_updates             | 6690        |
|    policy_gradient_loss  | -0.00095    |
|    std                   | 0.37        |
|    value_loss            | 5.85        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3379303  |
| rollout/                 |             |
|    ep_len_mean           | 73.6        |
|    ep_rew_mean           | -31.8       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 34          |
|    time_elapsed          | 1103        |
|    total_timesteps       | 1374208     |
| train/                   |             |
|    approx_kl             | 0.014651023 |
|    clip_fraction         | 0.112       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.81        |
|    cost_value_loss       | 7.3         |
|    cost_values           | 2.9         |
|    entropy               | -0.464      |
|    entropy_loss          | -0.463      |
|    explained_variance    | 0.845       |
|    lagrangian_multiplier | 0.00292     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.31        |
|    n_updates             | 6700        |
|    policy_gradient_loss  | -0.00119    |
|    std                   | 0.371       |
|    value_loss            | 5.72        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.32843384 |
| rollout/                 |             |
|    ep_len_mean           | 74.7        |
|    ep_rew_mean           | -32         |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 35          |
|    time_elapsed          | 1140        |
|    total_timesteps       | 1376256     |
| train/                   |             |
|    approx_kl             | 0.014738708 |
|    clip_fraction         | 0.133       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.57        |
|    cost_value_loss       | 6.3         |
|    cost_values           | 2.89        |
|    entropy               | -0.457      |
|    entropy_loss          | -0.461      |
|    explained_variance    | 0.876       |
|    lagrangian_multiplier | 0.00131     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.67        |
|    n_updates             | 6710        |
|    policy_gradient_loss  | 0.00218     |
|    std                   | 0.37        |
|    value_loss            | 5.05        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.6         |
| reward                   | -0.29061398 |
| rollout/                 |             |
|    ep_len_mean           | 75.6        |
|    ep_rew_mean           | -32.3       |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 36          |
|    time_elapsed          | 1174        |
|    total_timesteps       | 1378304     |
| train/                   |             |
|    approx_kl             | 0.012389553 |
|    clip_fraction         | 0.125       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.58        |
|    cost_value_loss       | 6.12        |
|    cost_values           | 2.89        |
|    entropy               | -0.453      |
|    entropy_loss          | -0.454      |
|    explained_variance    | 0.774       |
|    lagrangian_multiplier | 0.00174     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.48        |
|    n_updates             | 6720        |
|    policy_gradient_loss  | 0.00128     |
|    std                   | 0.37        |
|    value_loss            | 6.13        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3003796  |
| rollout/                 |             |
|    ep_len_mean           | 71.5        |
|    ep_rew_mean           | -31.1       |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 37          |
|    time_elapsed          | 1207        |
|    total_timesteps       | 1380352     |
| train/                   |             |
|    approx_kl             | 0.006941355 |
|    clip_fraction         | 0.0784      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.95        |
|    cost_value_loss       | 7.37        |
|    cost_values           | 2.91        |
|    entropy               | -0.446      |
|    entropy_loss          | -0.45       |
|    explained_variance    | 0.793       |
|    lagrangian_multiplier | 0.00171     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.87        |
|    n_updates             | 6730        |
|    policy_gradient_loss  | -0.00383    |
|    std                   | 0.369       |
|    value_loss            | 6.56        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.34915787 |
| rollout/                 |             |
|    ep_len_mean           | 67.8        |
|    ep_rew_mean           | -30         |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 38          |
|    time_elapsed          | 1235        |
|    total_timesteps       | 1382400     |
| train/                   |             |
|    approx_kl             | 0.008570861 |
|    clip_fraction         | 0.113       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.44        |
|    cost_value_loss       | 5.83        |
|    cost_values           | 2.86        |
|    entropy               | -0.444      |
|    entropy_loss          | -0.445      |
|    explained_variance    | 0.845       |
|    lagrangian_multiplier | 0.00162     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.73        |
|    n_updates             | 6740        |
|    policy_gradient_loss  | -0.00123    |
|    std                   | 0.368       |
|    value_loss            | 6.47        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.2          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.2          |
| reward                   | -0.5933979   |
| rollout/                 |              |
|    ep_len_mean           | 67.2         |
|    ep_rew_mean           | -29.9        |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 39           |
|    time_elapsed          | 1264         |
|    total_timesteps       | 1384448      |
| train/                   |              |
|    approx_kl             | 0.0075859623 |
|    clip_fraction         | 0.105        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.57         |
|    cost_value_loss       | 6.05         |
|    cost_values           | 2.88         |
|    entropy               | -0.44        |
|    entropy_loss          | -0.442       |
|    explained_variance    | 0.866        |
|    lagrangian_multiplier | 0.0034       |
|    learning_rate         | 0.0003       |
|    loss                  | 3.83         |
|    n_updates             | 6750         |
|    policy_gradient_loss  | -0.000784    |
|    std                   | 0.367        |
|    value_loss            | 5.01         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.22840127 |
| rollout/                 |             |
|    ep_len_mean           | 69.9        |
|    ep_rew_mean           | -31.1       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 40          |
|    time_elapsed          | 1295        |
|    total_timesteps       | 1386496     |
| train/                   |             |
|    approx_kl             | 0.014741807 |
|    clip_fraction         | 0.106       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.76        |
|    cost_value_loss       | 7.01        |
|    cost_values           | 2.91        |
|    entropy               | -0.441      |
|    entropy_loss          | -0.44       |
|    explained_variance    | 0.833       |
|    lagrangian_multiplier | 0.00277     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.12        |
|    n_updates             | 6760        |
|    policy_gradient_loss  | -0.00124    |
|    std                   | 0.367       |
|    value_loss            | 5.33        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.76837146 |
| rollout/                 |             |
|    ep_len_mean           | 70.9        |
|    ep_rew_mean           | -31.4       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 41          |
|    time_elapsed          | 1331        |
|    total_timesteps       | 1388544     |
| train/                   |             |
|    approx_kl             | 0.018490857 |
|    clip_fraction         | 0.15        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.47        |
|    cost_value_loss       | 5.79        |
|    cost_values           | 2.87        |
|    entropy               | -0.438      |
|    entropy_loss          | -0.44       |
|    explained_variance    | 0.874       |
|    lagrangian_multiplier | 0.00142     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.35        |
|    n_updates             | 6770        |
|    policy_gradient_loss  | 0.00321     |
|    std                   | 0.367       |
|    value_loss            | 4.94        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.7504839  |
| rollout/                 |             |
|    ep_len_mean           | 74.7        |
|    ep_rew_mean           | -32.3       |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 42          |
|    time_elapsed          | 1368        |
|    total_timesteps       | 1390592     |
| train/                   |             |
|    approx_kl             | 0.016193163 |
|    clip_fraction         | 0.145       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.48        |
|    cost_value_loss       | 6.04        |
|    cost_values           | 2.89        |
|    entropy               | -0.429      |
|    entropy_loss          | -0.433      |
|    explained_variance    | 0.881       |
|    lagrangian_multiplier | 0.00136     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.38        |
|    n_updates             | 6780        |
|    policy_gradient_loss  | 0.00571     |
|    std                   | 0.365       |
|    value_loss            | 4.5         |
------------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.64525074 |
| rollout/                 |             |
|    ep_len_mean           | 75.4        |
|    ep_rew_mean           | -32.1       |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 43          |
|    time_elapsed          | 1402        |
|    total_timesteps       | 1392640     |
| train/                   |             |
|    approx_kl             | 0.030073833 |
|    clip_fraction         | 0.14        |
|    clip_range            | 0.2         |
|    cost_returns          | 5.02        |
|    cost_value_loss       | 8.17        |
|    cost_values           | 2.91        |
|    entropy               | -0.42       |
|    entropy_loss          | -0.424      |
|    explained_variance    | 0.851       |
|    lagrangian_multiplier | 0.00467     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.94        |
|    n_updates             | 6790        |
|    policy_gradient_loss  | 0.00044     |
|    std                   | 0.364       |
|    value_loss            | 4.81        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2528253  |
| rollout/                 |             |
|    ep_len_mean           | 76.8        |
|    ep_rew_mean           | -31.9       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 44          |
|    time_elapsed          | 1428        |
|    total_timesteps       | 1394688     |
| train/                   |             |
|    approx_kl             | 0.016205402 |
|    clip_fraction         | 0.144       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.97        |
|    cost_value_loss       | 7.5         |
|    cost_values           | 2.93        |
|    entropy               | -0.415      |
|    entropy_loss          | -0.418      |
|    explained_variance    | 0.835       |
|    lagrangian_multiplier | 0.00276     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.37        |
|    n_updates             | 6800        |
|    policy_gradient_loss  | 0.00123     |
|    std                   | 0.364       |
|    value_loss            | 4.96        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.7328305  |
| rollout/                 |             |
|    ep_len_mean           | 75          |
|    ep_rew_mean           | -30.9       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 45          |
|    time_elapsed          | 1453        |
|    total_timesteps       | 1396736     |
| train/                   |             |
|    approx_kl             | 0.011007923 |
|    clip_fraction         | 0.156       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.01        |
|    cost_value_loss       | 8.41        |
|    cost_values           | 2.93        |
|    entropy               | -0.412      |
|    entropy_loss          | -0.414      |
|    explained_variance    | 0.845       |
|    lagrangian_multiplier | 0.00316     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.44        |
|    n_updates             | 6810        |
|    policy_gradient_loss  | 0.000825    |
|    std                   | 0.364       |
|    value_loss            | 4.96        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.30840102 |
| rollout/                 |             |
|    ep_len_mean           | 70.7        |
|    ep_rew_mean           | -30.3       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 46          |
|    time_elapsed          | 1477        |
|    total_timesteps       | 1398784     |
| train/                   |             |
|    approx_kl             | 0.034376692 |
|    clip_fraction         | 0.107       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.65        |
|    cost_value_loss       | 6.46        |
|    cost_values           | 2.9         |
|    entropy               | -0.401      |
|    entropy_loss          | -0.407      |
|    explained_variance    | 0.888       |
|    lagrangian_multiplier | 0.00104     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.55        |
|    n_updates             | 6820        |
|    policy_gradient_loss  | 0.0021      |
|    std                   | 0.362       |
|    value_loss            | 4.45        |
------------------------------------------
-----------------------------------------
| avg_speed                | 2.4        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 2.4        |
| reward                   | -0.9057309 |
| rollout/                 |            |
|    ep_len_mean           | 68.5       |
|    ep_rew_mean           | -30        |
| time/                    |            |
|    fps                   | 64         |
|    iterations            | 47         |
|    time_elapsed          | 1500       |
|    total_timesteps       | 1400832    |
| train/                   |            |
|    approx_kl             | 0.01173237 |
|    clip_fraction         | 0.159      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.32       |
|    cost_value_loss       | 5.39       |
|    cost_values           | 2.87       |
|    entropy               | -0.4       |
|    entropy_loss          | -0.401     |
|    explained_variance    | 0.882      |
|    lagrangian_multiplier | 0.00265    |
|    learning_rate         | 0.0003     |
|    loss                  | 3.68       |
|    n_updates             | 6830       |
|    policy_gradient_loss  | 0.000498   |
|    std                   | 0.363      |
|    value_loss            | 4.47       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3688666  |
| rollout/                 |             |
|    ep_len_mean           | 68.1        |
|    ep_rew_mean           | -30.2       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 48          |
|    time_elapsed          | 1524        |
|    total_timesteps       | 1402880     |
| train/                   |             |
|    approx_kl             | 0.014163985 |
|    clip_fraction         | 0.12        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.69        |
|    cost_value_loss       | 7.17        |
|    cost_values           | 2.88        |
|    entropy               | -0.39       |
|    entropy_loss          | -0.396      |
|    explained_variance    | 0.885       |
|    lagrangian_multiplier | 0.00332     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.97        |
|    n_updates             | 6840        |
|    policy_gradient_loss  | 0.000876    |
|    std                   | 0.361       |
|    value_loss            | 4.38        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.7245547  |
| rollout/                 |             |
|    ep_len_mean           | 68          |
|    ep_rew_mean           | -30.2       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 49          |
|    time_elapsed          | 1548        |
|    total_timesteps       | 1404928     |
| train/                   |             |
|    approx_kl             | 0.012368128 |
|    clip_fraction         | 0.152       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.8         |
|    cost_value_loss       | 7.16        |
|    cost_values           | 2.89        |
|    entropy               | -0.381      |
|    entropy_loss          | -0.384      |
|    explained_variance    | 0.871       |
|    lagrangian_multiplier | 0.00357     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.95        |
|    n_updates             | 6850        |
|    policy_gradient_loss  | 0.00405     |
|    std                   | 0.36        |
|    value_loss            | 4.67        |
------------------------------------------
-----------------------------------
| avg_speed          | 3.2        |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 3.2        |
| reward             | -0.8287182 |
| rollout/           |            |
|    ep_len_mean     | 65.2       |
|    ep_rew_mean     | -29.2      |
| time/              |            |
|    fps             | 87         |
|    iterations      | 1          |
|    time_elapsed    | 23         |
|    total_timesteps | 1406976    |
-----------------------------------
------------------------------------------
| avg_speed                | 5.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.6         |
| reward                   | -0.2118414  |
| rollout/                 |             |
|    ep_len_mean           | 68.5        |
|    ep_rew_mean           | -30.6       |
| time/                    |             |
|    fps                   | 85          |
|    iterations            | 2           |
|    time_elapsed          | 47          |
|    total_timesteps       | 1409024     |
| train/                   |             |
|    approx_kl             | 0.013967926 |
|    clip_fraction         | 0.113       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.66        |
|    cost_value_loss       | 6.81        |
|    cost_values           | 2.88        |
|    entropy               | -0.368      |
|    entropy_loss          | -0.37       |
|    explained_variance    | 0.908       |
|    lagrangian_multiplier | 0.00196     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.11        |
|    n_updates             | 6870        |
|    policy_gradient_loss  | 0.00382     |
|    std                   | 0.358       |
|    value_loss            | 3.51        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.07        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.07        |
| reward                   | -0.2155137  |
| rollout/                 |             |
|    ep_len_mean           | 71.8        |
|    ep_rew_mean           | -31.5       |
| time/                    |             |
|    fps                   | 84          |
|    iterations            | 3           |
|    time_elapsed          | 72          |
|    total_timesteps       | 1411072     |
| train/                   |             |
|    approx_kl             | 0.017887749 |
|    clip_fraction         | 0.159       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.27        |
|    cost_value_loss       | 5.79        |
|    cost_values           | 2.85        |
|    entropy               | -0.37       |
|    entropy_loss          | -0.369      |
|    explained_variance    | 0.858       |
|    lagrangian_multiplier | 0.00193     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.12        |
|    n_updates             | 6880        |
|    policy_gradient_loss  | 0.000126    |
|    std                   | 0.36        |
|    value_loss            | 4.95        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.93        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.93        |
| reward                   | -0.27299988 |
| rollout/                 |             |
|    ep_len_mean           | 73.3        |
|    ep_rew_mean           | -31.9       |
| time/                    |             |
|    fps                   | 83          |
|    iterations            | 4           |
|    time_elapsed          | 97          |
|    total_timesteps       | 1413120     |
| train/                   |             |
|    approx_kl             | 0.011686188 |
|    clip_fraction         | 0.164       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.07        |
|    cost_value_loss       | 8.62        |
|    cost_values           | 2.88        |
|    entropy               | -0.37       |
|    entropy_loss          | -0.37       |
|    explained_variance    | 0.814       |
|    lagrangian_multiplier | 0.00315     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.52        |
|    n_updates             | 6890        |
|    policy_gradient_loss  | 0.00225     |
|    std                   | 0.36        |
|    value_loss            | 5.61        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.74        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.74        |
| reward                   | -0.32267144 |
| rollout/                 |             |
|    ep_len_mean           | 72.3        |
|    ep_rew_mean           | -31.5       |
| time/                    |             |
|    fps                   | 80          |
|    iterations            | 5           |
|    time_elapsed          | 126         |
|    total_timesteps       | 1415168     |
| train/                   |             |
|    approx_kl             | 0.006827999 |
|    clip_fraction         | 0.134       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.8         |
|    cost_value_loss       | 7.31        |
|    cost_values           | 2.89        |
|    entropy               | -0.373      |
|    entropy_loss          | -0.371      |
|    explained_variance    | 0.849       |
|    lagrangian_multiplier | 0.00227     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.36        |
|    n_updates             | 6900        |
|    policy_gradient_loss  | -0.000238   |
|    std                   | 0.361       |
|    value_loss            | 5.1         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2938126  |
| rollout/                 |             |
|    ep_len_mean           | 71.1        |
|    ep_rew_mean           | -30.8       |
| time/                    |             |
|    fps                   | 80          |
|    iterations            | 6           |
|    time_elapsed          | 153         |
|    total_timesteps       | 1417216     |
| train/                   |             |
|    approx_kl             | 0.014143241 |
|    clip_fraction         | 0.118       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.72        |
|    cost_value_loss       | 7.23        |
|    cost_values           | 2.9         |
|    entropy               | -0.371      |
|    entropy_loss          | -0.372      |
|    explained_variance    | 0.852       |
|    lagrangian_multiplier | 0.00297     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.3         |
|    n_updates             | 6910        |
|    policy_gradient_loss  | -0.00425    |
|    std                   | 0.361       |
|    value_loss            | 5.33        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.8         |
| reward                   | -0.71500146 |
| rollout/                 |             |
|    ep_len_mean           | 72.2        |
|    ep_rew_mean           | -31.2       |
| time/                    |             |
|    fps                   | 79          |
|    iterations            | 7           |
|    time_elapsed          | 181         |
|    total_timesteps       | 1419264     |
| train/                   |             |
|    approx_kl             | 0.012109396 |
|    clip_fraction         | 0.122       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.47        |
|    cost_value_loss       | 5.9         |
|    cost_values           | 2.89        |
|    entropy               | -0.372      |
|    entropy_loss          | -0.371      |
|    explained_variance    | 0.865       |
|    lagrangian_multiplier | 0.0029      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.99        |
|    n_updates             | 6920        |
|    policy_gradient_loss  | -0.000453   |
|    std                   | 0.362       |
|    value_loss            | 5.14        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.37960646 |
| rollout/                 |             |
|    ep_len_mean           | 70.5        |
|    ep_rew_mean           | -30.6       |
| time/                    |             |
|    fps                   | 78          |
|    iterations            | 8           |
|    time_elapsed          | 208         |
|    total_timesteps       | 1421312     |
| train/                   |             |
|    approx_kl             | 0.013842514 |
|    clip_fraction         | 0.148       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.58        |
|    cost_value_loss       | 6.35        |
|    cost_values           | 2.86        |
|    entropy               | -0.367      |
|    entropy_loss          | -0.37       |
|    explained_variance    | 0.816       |
|    lagrangian_multiplier | 0.00316     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.94        |
|    n_updates             | 6930        |
|    policy_gradient_loss  | 0.00145     |
|    std                   | 0.362       |
|    value_loss            | 5.54        |
------------------------------------------
------------------------------------------
| avg_speed                | 7           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7           |
| reward                   | -0.33668643 |
| rollout/                 |             |
|    ep_len_mean           | 71.9        |
|    ep_rew_mean           | -31.3       |
| time/                    |             |
|    fps                   | 75          |
|    iterations            | 9           |
|    time_elapsed          | 242         |
|    total_timesteps       | 1423360     |
| train/                   |             |
|    approx_kl             | 0.011079392 |
|    clip_fraction         | 0.142       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.66        |
|    cost_value_loss       | 6.97        |
|    cost_values           | 2.83        |
|    entropy               | -0.358      |
|    entropy_loss          | -0.362      |
|    explained_variance    | 0.882       |
|    lagrangian_multiplier | 0.00156     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.41        |
|    n_updates             | 6940        |
|    policy_gradient_loss  | 0.00218     |
|    std                   | 0.36        |
|    value_loss            | 4.51        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.24222891 |
| rollout/                 |             |
|    ep_len_mean           | 67.5        |
|    ep_rew_mean           | -30.4       |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 10          |
|    time_elapsed          | 279         |
|    total_timesteps       | 1425408     |
| train/                   |             |
|    approx_kl             | 0.025140021 |
|    clip_fraction         | 0.127       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.58        |
|    cost_value_loss       | 6.92        |
|    cost_values           | 2.88        |
|    entropy               | -0.358      |
|    entropy_loss          | -0.358      |
|    explained_variance    | 0.838       |
|    lagrangian_multiplier | 0.00293     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.13        |
|    n_updates             | 6950        |
|    policy_gradient_loss  | -0.000126   |
|    std                   | 0.36        |
|    value_loss            | 5.71        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.53        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.53        |
| reward                   | -0.22426464 |
| rollout/                 |             |
|    ep_len_mean           | 66.1        |
|    ep_rew_mean           | -29.9       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 11          |
|    time_elapsed          | 317         |
|    total_timesteps       | 1427456     |
| train/                   |             |
|    approx_kl             | 0.011518932 |
|    clip_fraction         | 0.121       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.53        |
|    cost_value_loss       | 6.25        |
|    cost_values           | 2.86        |
|    entropy               | -0.35       |
|    entropy_loss          | -0.355      |
|    explained_variance    | 0.88        |
|    lagrangian_multiplier | 0.00185     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.31        |
|    n_updates             | 6960        |
|    policy_gradient_loss  | -0.000883   |
|    std                   | 0.359       |
|    value_loss            | 4.96        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.83        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.83        |
| reward                   | -0.26776898 |
| rollout/                 |             |
|    ep_len_mean           | 63.8        |
|    ep_rew_mean           | -29         |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 12          |
|    time_elapsed          | 350         |
|    total_timesteps       | 1429504     |
| train/                   |             |
|    approx_kl             | 0.012174662 |
|    clip_fraction         | 0.156       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.44        |
|    cost_value_loss       | 5.83        |
|    cost_values           | 2.84        |
|    entropy               | -0.336      |
|    entropy_loss          | -0.344      |
|    explained_variance    | 0.892       |
|    lagrangian_multiplier | 0.0029      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.6         |
|    n_updates             | 6970        |
|    policy_gradient_loss  | -0.0017     |
|    std                   | 0.357       |
|    value_loss            | 4.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -0.2099198  |
| rollout/                 |             |
|    ep_len_mean           | 64.5        |
|    ep_rew_mean           | -28.7       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 13          |
|    time_elapsed          | 384         |
|    total_timesteps       | 1431552     |
| train/                   |             |
|    approx_kl             | 0.014053185 |
|    clip_fraction         | 0.131       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.66        |
|    cost_value_loss       | 7           |
|    cost_values           | 2.84        |
|    entropy               | -0.332      |
|    entropy_loss          | -0.333      |
|    explained_variance    | 0.872       |
|    lagrangian_multiplier | 0.00291     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.02        |
|    n_updates             | 6980        |
|    policy_gradient_loss  | 0.000683    |
|    std                   | 0.357       |
|    value_loss            | 4.54        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.8         |
| reward                   | -0.87156785 |
| rollout/                 |             |
|    ep_len_mean           | 65.1        |
|    ep_rew_mean           | -28.8       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 14          |
|    time_elapsed          | 407         |
|    total_timesteps       | 1433600     |
| train/                   |             |
|    approx_kl             | 0.009019859 |
|    clip_fraction         | 0.114       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.63        |
|    cost_value_loss       | 6.92        |
|    cost_values           | 2.86        |
|    entropy               | -0.331      |
|    entropy_loss          | -0.331      |
|    explained_variance    | 0.9         |
|    lagrangian_multiplier | 0.0023      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.87        |
|    n_updates             | 6990        |
|    policy_gradient_loss  | -0.00119    |
|    std                   | 0.357       |
|    value_loss            | 3.66        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.32473266 |
| rollout/                 |             |
|    ep_len_mean           | 65.7        |
|    ep_rew_mean           | -29.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 15          |
|    time_elapsed          | 438         |
|    total_timesteps       | 1435648     |
| train/                   |             |
|    approx_kl             | 0.020646118 |
|    clip_fraction         | 0.129       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.62        |
|    cost_value_loss       | 6.74        |
|    cost_values           | 2.87        |
|    entropy               | -0.33       |
|    entropy_loss          | -0.329      |
|    explained_variance    | 0.86        |
|    lagrangian_multiplier | 0.00243     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.16        |
|    n_updates             | 7000        |
|    policy_gradient_loss  | 0.00228     |
|    std                   | 0.357       |
|    value_loss            | 4.7         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.32312799 |
| rollout/                 |             |
|    ep_len_mean           | 63.3        |
|    ep_rew_mean           | -28.6       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 16          |
|    time_elapsed          | 467         |
|    total_timesteps       | 1437696     |
| train/                   |             |
|    approx_kl             | 0.010486304 |
|    clip_fraction         | 0.13        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.66        |
|    cost_value_loss       | 6.95        |
|    cost_values           | 2.87        |
|    entropy               | -0.33       |
|    entropy_loss          | -0.331      |
|    explained_variance    | 0.862       |
|    lagrangian_multiplier | 0.00273     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.12        |
|    n_updates             | 7010        |
|    policy_gradient_loss  | 0.00263     |
|    std                   | 0.358       |
|    value_loss            | 4.85        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.32330105 |
| rollout/                 |             |
|    ep_len_mean           | 63.1        |
|    ep_rew_mean           | -28.9       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 17          |
|    time_elapsed          | 499         |
|    total_timesteps       | 1439744     |
| train/                   |             |
|    approx_kl             | 0.009073068 |
|    clip_fraction         | 0.0971      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.76        |
|    cost_value_loss       | 7.04        |
|    cost_values           | 2.9         |
|    entropy               | -0.324      |
|    entropy_loss          | -0.327      |
|    explained_variance    | 0.894       |
|    lagrangian_multiplier | 0.00224     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.05        |
|    n_updates             | 7020        |
|    policy_gradient_loss  | -0.000668   |
|    std                   | 0.357       |
|    value_loss            | 3.94        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.32258645 |
| rollout/                 |             |
|    ep_len_mean           | 61.6        |
|    ep_rew_mean           | -28.6       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 18          |
|    time_elapsed          | 530         |
|    total_timesteps       | 1441792     |
| train/                   |             |
|    approx_kl             | 0.017374726 |
|    clip_fraction         | 0.148       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.74        |
|    cost_value_loss       | 7.26        |
|    cost_values           | 2.9         |
|    entropy               | -0.315      |
|    entropy_loss          | -0.32       |
|    explained_variance    | 0.91        |
|    lagrangian_multiplier | 0.00244     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.87        |
|    n_updates             | 7030        |
|    policy_gradient_loss  | -0.000556   |
|    std                   | 0.356       |
|    value_loss            | 3.37        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3960033  |
| rollout/                 |             |
|    ep_len_mean           | 66          |
|    ep_rew_mean           | -29.8       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 19          |
|    time_elapsed          | 557         |
|    total_timesteps       | 1443840     |
| train/                   |             |
|    approx_kl             | 0.019758536 |
|    clip_fraction         | 0.164       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.52        |
|    cost_value_loss       | 5.9         |
|    cost_values           | 2.88        |
|    entropy               | -0.308      |
|    entropy_loss          | -0.312      |
|    explained_variance    | 0.91        |
|    lagrangian_multiplier | 0.00238     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.73        |
|    n_updates             | 7040        |
|    policy_gradient_loss  | 0.00162     |
|    std                   | 0.354       |
|    value_loss            | 3.67        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.1248493  |
| rollout/                 |             |
|    ep_len_mean           | 65.8        |
|    ep_rew_mean           | -29.9       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 20          |
|    time_elapsed          | 585         |
|    total_timesteps       | 1445888     |
| train/                   |             |
|    approx_kl             | 0.019927729 |
|    clip_fraction         | 0.155       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.72        |
|    cost_value_loss       | 6.76        |
|    cost_values           | 2.89        |
|    entropy               | -0.308      |
|    entropy_loss          | -0.307      |
|    explained_variance    | 0.865       |
|    lagrangian_multiplier | 0.00231     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.96        |
|    n_updates             | 7050        |
|    policy_gradient_loss  | 0.00475     |
|    std                   | 0.355       |
|    value_loss            | 3.95        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.7875792  |
| rollout/                 |             |
|    ep_len_mean           | 64.2        |
|    ep_rew_mean           | -29.6       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 21          |
|    time_elapsed          | 613         |
|    total_timesteps       | 1447936     |
| train/                   |             |
|    approx_kl             | 0.013724839 |
|    clip_fraction         | 0.125       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.17        |
|    cost_value_loss       | 4.9         |
|    cost_values           | 2.85        |
|    entropy               | -0.302      |
|    entropy_loss          | -0.306      |
|    explained_variance    | 0.912       |
|    lagrangian_multiplier | 0.00134     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.43        |
|    n_updates             | 7060        |
|    policy_gradient_loss  | 0.00192     |
|    std                   | 0.355       |
|    value_loss            | 3.43        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.63        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.63        |
| reward                   | -0.39338395 |
| rollout/                 |             |
|    ep_len_mean           | 59.5        |
|    ep_rew_mean           | -28.4       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 22          |
|    time_elapsed          | 641         |
|    total_timesteps       | 1449984     |
| train/                   |             |
|    approx_kl             | 0.01939034  |
|    clip_fraction         | 0.156       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.25        |
|    cost_value_loss       | 5.35        |
|    cost_values           | 2.84        |
|    entropy               | -0.293      |
|    entropy_loss          | -0.298      |
|    explained_variance    | 0.931       |
|    lagrangian_multiplier | 0.000826    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.82        |
|    n_updates             | 7070        |
|    policy_gradient_loss  | -0.000612   |
|    std                   | 0.353       |
|    value_loss            | 3.12        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.8         |
| reward                   | -0.6381094  |
| rollout/                 |             |
|    ep_len_mean           | 58.1        |
|    ep_rew_mean           | -27.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 23          |
|    time_elapsed          | 668         |
|    total_timesteps       | 1452032     |
| train/                   |             |
|    approx_kl             | 0.015409255 |
|    clip_fraction         | 0.14        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.32        |
|    cost_value_loss       | 5.55        |
|    cost_values           | 2.83        |
|    entropy               | -0.295      |
|    entropy_loss          | -0.293      |
|    explained_variance    | 0.922       |
|    lagrangian_multiplier | 0.00141     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.73        |
|    n_updates             | 7080        |
|    policy_gradient_loss  | 0.000528    |
|    std                   | 0.355       |
|    value_loss            | 2.9         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.52166134 |
| rollout/                 |             |
|    ep_len_mean           | 58.4        |
|    ep_rew_mean           | -27.6       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 24          |
|    time_elapsed          | 696         |
|    total_timesteps       | 1454080     |
| train/                   |             |
|    approx_kl             | 0.014559235 |
|    clip_fraction         | 0.148       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.45        |
|    cost_value_loss       | 6.43        |
|    cost_values           | 2.84        |
|    entropy               | -0.289      |
|    entropy_loss          | -0.293      |
|    explained_variance    | 0.925       |
|    lagrangian_multiplier | 0.00201     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.66        |
|    n_updates             | 7090        |
|    policy_gradient_loss  | 0.00205     |
|    std                   | 0.353       |
|    value_loss            | 2.83        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.84387624 |
| rollout/                 |             |
|    ep_len_mean           | 57.5        |
|    ep_rew_mean           | -27.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 25          |
|    time_elapsed          | 730         |
|    total_timesteps       | 1456128     |
| train/                   |             |
|    approx_kl             | 0.013822953 |
|    clip_fraction         | 0.131       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.35        |
|    cost_value_loss       | 5.59        |
|    cost_values           | 2.83        |
|    entropy               | -0.29       |
|    entropy_loss          | -0.289      |
|    explained_variance    | 0.911       |
|    lagrangian_multiplier | 0.00263     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.55        |
|    n_updates             | 7100        |
|    policy_gradient_loss  | 0.00145     |
|    std                   | 0.353       |
|    value_loss            | 3.45        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3195123  |
| rollout/                 |             |
|    ep_len_mean           | 60.9        |
|    ep_rew_mean           | -28.8       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 26          |
|    time_elapsed          | 753         |
|    total_timesteps       | 1458176     |
| train/                   |             |
|    approx_kl             | 0.014118556 |
|    clip_fraction         | 0.123       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.3         |
|    cost_value_loss       | 5.48        |
|    cost_values           | 2.81        |
|    entropy               | -0.28       |
|    entropy_loss          | -0.285      |
|    explained_variance    | 0.914       |
|    lagrangian_multiplier | 0.0024      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.58        |
|    n_updates             | 7110        |
|    policy_gradient_loss  | -0.00385    |
|    std                   | 0.351       |
|    value_loss            | 3.26        |
------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.56260663 |
| rollout/                 |             |
|    ep_len_mean           | 63.3        |
|    ep_rew_mean           | -29         |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 27          |
|    time_elapsed          | 777         |
|    total_timesteps       | 1460224     |
| train/                   |             |
|    approx_kl             | 0.027014088 |
|    clip_fraction         | 0.166       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.39        |
|    cost_value_loss       | 6.17        |
|    cost_values           | 2.82        |
|    entropy               | -0.278      |
|    entropy_loss          | -0.279      |
|    explained_variance    | 0.888       |
|    lagrangian_multiplier | 0.000808    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.39        |
|    n_updates             | 7120        |
|    policy_gradient_loss  | 0.0047      |
|    std                   | 0.352       |
|    value_loss            | 3.9         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.42576694 |
| rollout/                 |             |
|    ep_len_mean           | 68.2        |
|    ep_rew_mean           | -30.7       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 28          |
|    time_elapsed          | 807         |
|    total_timesteps       | 1462272     |
| train/                   |             |
|    approx_kl             | 0.02756021  |
|    clip_fraction         | 0.128       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.75        |
|    cost_value_loss       | 7.63        |
|    cost_values           | 2.82        |
|    entropy               | -0.28       |
|    entropy_loss          | -0.279      |
|    explained_variance    | 0.853       |
|    lagrangian_multiplier | 0.002       |
|    learning_rate         | 0.0003      |
|    loss                  | 4.45        |
|    n_updates             | 7130        |
|    policy_gradient_loss  | 0.000176    |
|    std                   | 0.353       |
|    value_loss            | 4.58        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.19370545 |
| rollout/                 |             |
|    ep_len_mean           | 68.2        |
|    ep_rew_mean           | -30.6       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 29          |
|    time_elapsed          | 845         |
|    total_timesteps       | 1464320     |
| train/                   |             |
|    approx_kl             | 0.014414063 |
|    clip_fraction         | 0.141       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.76        |
|    cost_value_loss       | 7.59        |
|    cost_values           | 2.84        |
|    entropy               | -0.273      |
|    entropy_loss          | -0.277      |
|    explained_variance    | 0.863       |
|    lagrangian_multiplier | 0.00196     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.55        |
|    n_updates             | 7140        |
|    policy_gradient_loss  | 0.00098     |
|    std                   | 0.352       |
|    value_loss            | 4.77        |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.2        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.2        |
| reward                   | -0.5586829 |
| rollout/                 |            |
|    ep_len_mean           | 66.3       |
|    ep_rew_mean           | -30.2      |
| time/                    |            |
|    fps                   | 69         |
|    iterations            | 30         |
|    time_elapsed          | 883        |
|    total_timesteps       | 1466368    |
| train/                   |            |
|    approx_kl             | 0.00949987 |
|    clip_fraction         | 0.115      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.93       |
|    cost_value_loss       | 8.37       |
|    cost_values           | 2.85       |
|    entropy               | -0.264     |
|    entropy_loss          | -0.268     |
|    explained_variance    | 0.867      |
|    lagrangian_multiplier | 0.00265    |
|    learning_rate         | 0.0003     |
|    loss                  | 4.37       |
|    n_updates             | 7150       |
|    policy_gradient_loss  | 0.000369   |
|    std                   | 0.35       |
|    value_loss            | 4.94       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.34857494  |
| rollout/                 |              |
|    ep_len_mean           | 63.1         |
|    ep_rew_mean           | -29.1        |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 31           |
|    time_elapsed          | 919          |
|    total_timesteps       | 1468416      |
| train/                   |              |
|    approx_kl             | 0.0119557865 |
|    clip_fraction         | 0.134        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.73         |
|    cost_value_loss       | 7.41         |
|    cost_values           | 2.84         |
|    entropy               | -0.263       |
|    entropy_loss          | -0.263       |
|    explained_variance    | 0.888        |
|    lagrangian_multiplier | 0.00406      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.74         |
|    n_updates             | 7160         |
|    policy_gradient_loss  | 0.00269      |
|    std                   | 0.349        |
|    value_loss            | 4.28         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1            |
| reward                   | -0.8487898   |
| rollout/                 |              |
|    ep_len_mean           | 60.2         |
|    ep_rew_mean           | -28          |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 32           |
|    time_elapsed          | 956          |
|    total_timesteps       | 1470464      |
| train/                   |              |
|    approx_kl             | 0.0067791184 |
|    clip_fraction         | 0.117        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.55         |
|    cost_value_loss       | 6.82         |
|    cost_values           | 2.84         |
|    entropy               | -0.256       |
|    entropy_loss          | -0.26        |
|    explained_variance    | 0.909        |
|    lagrangian_multiplier | 0.00181      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.1          |
|    n_updates             | 7170         |
|    policy_gradient_loss  | 0.0038       |
|    std                   | 0.347        |
|    value_loss            | 3.69         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.5939857  |
| rollout/                 |             |
|    ep_len_mean           | 61.2        |
|    ep_rew_mean           | -28.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 33          |
|    time_elapsed          | 990         |
|    total_timesteps       | 1472512     |
| train/                   |             |
|    approx_kl             | 0.009261296 |
|    clip_fraction         | 0.105       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.58        |
|    cost_value_loss       | 6.77        |
|    cost_values           | 2.82        |
|    entropy               | -0.251      |
|    entropy_loss          | -0.252      |
|    explained_variance    | 0.907       |
|    lagrangian_multiplier | 0.00275     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.82        |
|    n_updates             | 7180        |
|    policy_gradient_loss  | -0.0038     |
|    std                   | 0.347       |
|    value_loss            | 3.64        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.53218985 |
| rollout/                 |             |
|    ep_len_mean           | 61.9        |
|    ep_rew_mean           | -29         |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 34          |
|    time_elapsed          | 1025        |
|    total_timesteps       | 1474560     |
| train/                   |             |
|    approx_kl             | 0.009537462 |
|    clip_fraction         | 0.132       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.34        |
|    cost_value_loss       | 5.7         |
|    cost_values           | 2.83        |
|    entropy               | -0.244      |
|    entropy_loss          | -0.248      |
|    explained_variance    | 0.918       |
|    lagrangian_multiplier | 0.00354     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.33        |
|    n_updates             | 7190        |
|    policy_gradient_loss  | 0.000824    |
|    std                   | 0.347       |
|    value_loss            | 3.16        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.33468285 |
| rollout/                 |             |
|    ep_len_mean           | 63.1        |
|    ep_rew_mean           | -29.6       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 35          |
|    time_elapsed          | 1056        |
|    total_timesteps       | 1476608     |
| train/                   |             |
|    approx_kl             | 0.015942665 |
|    clip_fraction         | 0.166       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.26        |
|    cost_value_loss       | 5.49        |
|    cost_values           | 2.81        |
|    entropy               | -0.236      |
|    entropy_loss          | -0.239      |
|    explained_variance    | 0.891       |
|    lagrangian_multiplier | 0.00195     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.81        |
|    n_updates             | 7200        |
|    policy_gradient_loss  | 0.00391     |
|    std                   | 0.347       |
|    value_loss            | 4.2         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.38684812 |
| rollout/                 |             |
|    ep_len_mean           | 62.2        |
|    ep_rew_mean           | -29         |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 36          |
|    time_elapsed          | 1092        |
|    total_timesteps       | 1478656     |
| train/                   |             |
|    approx_kl             | 0.007071262 |
|    clip_fraction         | 0.14        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.39        |
|    cost_value_loss       | 5.67        |
|    cost_values           | 2.82        |
|    entropy               | -0.227      |
|    entropy_loss          | -0.232      |
|    explained_variance    | 0.895       |
|    lagrangian_multiplier | 0.00176     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.85        |
|    n_updates             | 7210        |
|    policy_gradient_loss  | 0.00123     |
|    std                   | 0.345       |
|    value_loss            | 3.71        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.4138191  |
| rollout/                 |             |
|    ep_len_mean           | 61          |
|    ep_rew_mean           | -28.3       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 37          |
|    time_elapsed          | 1119        |
|    total_timesteps       | 1480704     |
| train/                   |             |
|    approx_kl             | 0.014503755 |
|    clip_fraction         | 0.0975      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.38        |
|    cost_value_loss       | 6.45        |
|    cost_values           | 2.7         |
|    entropy               | -0.223      |
|    entropy_loss          | -0.224      |
|    explained_variance    | 0.898       |
|    lagrangian_multiplier | 0.00198     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.9         |
|    n_updates             | 7220        |
|    policy_gradient_loss  | 0.000971    |
|    std                   | 0.346       |
|    value_loss            | 3.74        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.8         |
| reward                   | -0.82872796 |
| rollout/                 |             |
|    ep_len_mean           | 63          |
|    ep_rew_mean           | -28.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 38          |
|    time_elapsed          | 1142        |
|    total_timesteps       | 1482752     |
| train/                   |             |
|    approx_kl             | 0.014188366 |
|    clip_fraction         | 0.161       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.28        |
|    cost_value_loss       | 6.3         |
|    cost_values           | 2.62        |
|    entropy               | -0.225      |
|    entropy_loss          | -0.224      |
|    explained_variance    | 0.915       |
|    lagrangian_multiplier | 0.00109     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.97        |
|    n_updates             | 7230        |
|    policy_gradient_loss  | 0.00598     |
|    std                   | 0.347       |
|    value_loss            | 3.4         |
------------------------------------------
------------------------------------------
| avg_speed                | 6.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.4         |
| reward                   | -0.23641537 |
| rollout/                 |             |
|    ep_len_mean           | 63.3        |
|    ep_rew_mean           | -28.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 39          |
|    time_elapsed          | 1167        |
|    total_timesteps       | 1484800     |
| train/                   |             |
|    approx_kl             | 0.008318373 |
|    clip_fraction         | 0.137       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.41        |
|    cost_value_loss       | 7.22        |
|    cost_values           | 2.68        |
|    entropy               | -0.225      |
|    entropy_loss          | -0.226      |
|    explained_variance    | 0.905       |
|    lagrangian_multiplier | 0.00124     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.3         |
|    n_updates             | 7240        |
|    policy_gradient_loss  | 0.00167     |
|    std                   | 0.347       |
|    value_loss            | 3.58        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.35830912 |
| rollout/                 |             |
|    ep_len_mean           | 64.5        |
|    ep_rew_mean           | -29.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 40          |
|    time_elapsed          | 1202        |
|    total_timesteps       | 1486848     |
| train/                   |             |
|    approx_kl             | 0.00984847  |
|    clip_fraction         | 0.138       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.55        |
|    cost_value_loss       | 6.7         |
|    cost_values           | 2.77        |
|    entropy               | -0.225      |
|    entropy_loss          | -0.225      |
|    explained_variance    | 0.894       |
|    lagrangian_multiplier | 0.000954    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.24        |
|    n_updates             | 7250        |
|    policy_gradient_loss  | 0.00155     |
|    std                   | 0.347       |
|    value_loss            | 3.68        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.24095231 |
| rollout/                 |             |
|    ep_len_mean           | 63.3        |
|    ep_rew_mean           | -28.8       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 41          |
|    time_elapsed          | 1236        |
|    total_timesteps       | 1488896     |
| train/                   |             |
|    approx_kl             | 0.027071122 |
|    clip_fraction         | 0.15        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.67        |
|    cost_value_loss       | 7.37        |
|    cost_values           | 2.81        |
|    entropy               | -0.213      |
|    entropy_loss          | -0.22       |
|    explained_variance    | 0.879       |
|    lagrangian_multiplier | 0.00265     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.09        |
|    n_updates             | 7260        |
|    policy_gradient_loss  | -0.000823   |
|    std                   | 0.345       |
|    value_loss            | 4.47        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.85620236 |
| rollout/                 |             |
|    ep_len_mean           | 62.2        |
|    ep_rew_mean           | -28.6       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 42          |
|    time_elapsed          | 1271        |
|    total_timesteps       | 1490944     |
| train/                   |             |
|    approx_kl             | 0.016395606 |
|    clip_fraction         | 0.142       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.74        |
|    cost_value_loss       | 7.37        |
|    cost_values           | 2.82        |
|    entropy               | -0.205      |
|    entropy_loss          | -0.209      |
|    explained_variance    | 0.873       |
|    lagrangian_multiplier | 0.0022      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.13        |
|    n_updates             | 7270        |
|    policy_gradient_loss  | -0.000709   |
|    std                   | 0.344       |
|    value_loss            | 4.27        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 1           |
| max_speed                | 8           |
| reward                   | -0.11449359 |
| rollout/                 |             |
|    ep_len_mean           | 57.6        |
|    ep_rew_mean           | -27.2       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 43          |
|    time_elapsed          | 1308        |
|    total_timesteps       | 1492992     |
| train/                   |             |
|    approx_kl             | 0.008597503 |
|    clip_fraction         | 0.129       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.18        |
|    cost_value_loss       | 5.37        |
|    cost_values           | 2.77        |
|    entropy               | -0.195      |
|    entropy_loss          | -0.2        |
|    explained_variance    | 0.899       |
|    lagrangian_multiplier | 0.000815    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.31        |
|    n_updates             | 7280        |
|    policy_gradient_loss  | 0.000793    |
|    std                   | 0.342       |
|    value_loss            | 4.14        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.6         |
| reward                   | -0.8149046  |
| rollout/                 |             |
|    ep_len_mean           | 56.4        |
|    ep_rew_mean           | -27.3       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 44          |
|    time_elapsed          | 1346        |
|    total_timesteps       | 1495040     |
| train/                   |             |
|    approx_kl             | 0.037855484 |
|    clip_fraction         | 0.115       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.94        |
|    cost_value_loss       | 4.19        |
|    cost_values           | 2.77        |
|    entropy               | -0.189      |
|    entropy_loss          | -0.19       |
|    explained_variance    | 0.925       |
|    lagrangian_multiplier | 0.000757    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.51        |
|    n_updates             | 7290        |
|    policy_gradient_loss  | 0.00113     |
|    std                   | 0.342       |
|    value_loss            | 3.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 1           |
| max_speed                | 8.01        |
| reward                   | -0.09731092 |
| rollout/                 |             |
|    ep_len_mean           | 57          |
|    ep_rew_mean           | -27.3       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 45          |
|    time_elapsed          | 1383        |
|    total_timesteps       | 1497088     |
| train/                   |             |
|    approx_kl             | 0.013958218 |
|    clip_fraction         | 0.148       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.5         |
|    cost_value_loss       | 6.66        |
|    cost_values           | 2.79        |
|    entropy               | -0.184      |
|    entropy_loss          | -0.186      |
|    explained_variance    | 0.922       |
|    lagrangian_multiplier | 0.00217     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.83        |
|    n_updates             | 7300        |
|    policy_gradient_loss  | 0.00304     |
|    std                   | 0.342       |
|    value_loss            | 3.01        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.37514618  |
| rollout/                 |              |
|    ep_len_mean           | 57.7         |
|    ep_rew_mean           | -27.2        |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 46           |
|    time_elapsed          | 1420         |
|    total_timesteps       | 1499136      |
| train/                   |              |
|    approx_kl             | 0.0107366145 |
|    clip_fraction         | 0.146        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.37         |
|    cost_value_loss       | 5.82         |
|    cost_values           | 2.78         |
|    entropy               | -0.181       |
|    entropy_loss          | -0.183       |
|    explained_variance    | 0.932        |
|    lagrangian_multiplier | 0.00245      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.38         |
|    n_updates             | 7310         |
|    policy_gradient_loss  | -0.00127     |
|    std                   | 0.342        |
|    value_loss            | 2.73         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.7925409  |
| rollout/                 |             |
|    ep_len_mean           | 57          |
|    ep_rew_mean           | -27.7       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 47          |
|    time_elapsed          | 1457        |
|    total_timesteps       | 1501184     |
| train/                   |             |
|    approx_kl             | 0.020643339 |
|    clip_fraction         | 0.158       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.43        |
|    cost_value_loss       | 6.01        |
|    cost_values           | 2.78        |
|    entropy               | -0.181      |
|    entropy_loss          | -0.18       |
|    explained_variance    | 0.903       |
|    lagrangian_multiplier | 0.0023      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.55        |
|    n_updates             | 7320        |
|    policy_gradient_loss  | 0.00289     |
|    std                   | 0.342       |
|    value_loss            | 3.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.18188937 |
| rollout/                 |             |
|    ep_len_mean           | 60.4        |
|    ep_rew_mean           | -29         |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 48          |
|    time_elapsed          | 1491        |
|    total_timesteps       | 1503232     |
| train/                   |             |
|    approx_kl             | 0.016596746 |
|    clip_fraction         | 0.132       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.69        |
|    cost_value_loss       | 3.35        |
|    cost_values           | 2.72        |
|    entropy               | -0.174      |
|    entropy_loss          | -0.178      |
|    explained_variance    | 0.931       |
|    lagrangian_multiplier | 0.000377    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.14        |
|    n_updates             | 7330        |
|    policy_gradient_loss  | 3.66e-05    |
|    std                   | 0.341       |
|    value_loss            | 2.99        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.39375648 |
| rollout/                 |             |
|    ep_len_mean           | 61.9        |
|    ep_rew_mean           | -30.2       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 49          |
|    time_elapsed          | 1525        |
|    total_timesteps       | 1505280     |
| train/                   |             |
|    approx_kl             | 0.009870261 |
|    clip_fraction         | 0.134       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.11        |
|    cost_value_loss       | 5.2         |
|    cost_values           | 2.68        |
|    entropy               | -0.167      |
|    entropy_loss          | -0.171      |
|    explained_variance    | 0.87        |
|    lagrangian_multiplier | 0.00212     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.59        |
|    n_updates             | 7340        |
|    policy_gradient_loss  | 0.00312     |
|    std                   | 0.341       |
|    value_loss            | 4.31        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ent-coefficient-ppol/1vjpjg9h
------------------------------------
| avg_speed          | 8           |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8           |
| reward             | -0.34541315 |
| rollout/           |             |
|    ep_len_mean     | 65.6        |
|    ep_rew_mean     | -31.3       |
| time/              |             |
|    fps             | 64          |
|    iterations      | 1           |
|    time_elapsed    | 31          |
|    total_timesteps | 1507328     |
------------------------------------
------------------------------------------
| avg_speed                | 7.73        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.73        |
| reward                   | -0.38400638 |
| rollout/                 |             |
|    ep_len_mean           | 64.4        |
|    ep_rew_mean           | -30.8       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 2           |
|    time_elapsed          | 63          |
|    total_timesteps       | 1509376     |
| train/                   |             |
|    approx_kl             | 0.012028994 |
|    clip_fraction         | 0.115       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.02        |
|    cost_value_loss       | 4.61        |
|    cost_values           | 2.72        |
|    entropy               | -0.155      |
|    entropy_loss          | -0.159      |
|    explained_variance    | 0.869       |
|    lagrangian_multiplier | 0.00248     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.69        |
|    n_updates             | 7360        |
|    policy_gradient_loss  | 0.00418     |
|    std                   | 0.34        |
|    value_loss            | 5.37        |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.587868   |
| rollout/                 |             |
|    ep_len_mean           | 63.4        |
|    ep_rew_mean           | -30.1       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 3           |
|    time_elapsed          | 93          |
|    total_timesteps       | 1511424     |
| train/                   |             |
|    approx_kl             | 0.018698992 |
|    clip_fraction         | 0.138       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.12        |
|    cost_value_loss       | 5.43        |
|    cost_values           | 2.74        |
|    entropy               | -0.145      |
|    entropy_loss          | -0.149      |
|    explained_variance    | 0.905       |
|    lagrangian_multiplier | 0.000583    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.25        |
|    n_updates             | 7370        |
|    policy_gradient_loss  | 0.00265     |
|    std                   | 0.338       |
|    value_loss            | 3.99        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.36179042 |
| rollout/                 |             |
|    ep_len_mean           | 62.2        |
|    ep_rew_mean           | -29.3       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 4           |
|    time_elapsed          | 125         |
|    total_timesteps       | 1513472     |
| train/                   |             |
|    approx_kl             | 0.015647914 |
|    clip_fraction         | 0.198       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.83        |
|    cost_value_loss       | 4.08        |
|    cost_values           | 2.72        |
|    entropy               | -0.146      |
|    entropy_loss          | -0.145      |
|    explained_variance    | 0.884       |
|    lagrangian_multiplier | 0.00107     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.74        |
|    n_updates             | 7380        |
|    policy_gradient_loss  | 0.00343     |
|    std                   | 0.338       |
|    value_loss            | 4.66        |
------------------------------------------
------------------------------------------
| avg_speed                | 5           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5           |
| reward                   | -0.7077577  |
| rollout/                 |             |
|    ep_len_mean           | 61.6        |
|    ep_rew_mean           | -29.1       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 5           |
|    time_elapsed          | 155         |
|    total_timesteps       | 1515520     |
| train/                   |             |
|    approx_kl             | 0.024709886 |
|    clip_fraction         | 0.157       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.78        |
|    cost_value_loss       | 3.53        |
|    cost_values           | 2.7         |
|    entropy               | -0.144      |
|    entropy_loss          | -0.145      |
|    explained_variance    | 0.894       |
|    lagrangian_multiplier | 0.000807    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.45        |
|    n_updates             | 7390        |
|    policy_gradient_loss  | 0.00328     |
|    std                   | 0.338       |
|    value_loss            | 4.08        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.8          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 5.8          |
| reward                   | -0.3171237   |
| rollout/                 |              |
|    ep_len_mean           | 61.2         |
|    ep_rew_mean           | -29.1        |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 6            |
|    time_elapsed          | 186          |
|    total_timesteps       | 1517568      |
| train/                   |              |
|    approx_kl             | 0.0069089634 |
|    clip_fraction         | 0.117        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.96         |
|    cost_value_loss       | 4.41         |
|    cost_values           | 2.69         |
|    entropy               | -0.149       |
|    entropy_loss          | -0.146       |
|    explained_variance    | 0.886        |
|    lagrangian_multiplier | 0.00164      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.75         |
|    n_updates             | 7400         |
|    policy_gradient_loss  | 0.000597     |
|    std                   | 0.339        |
|    value_loss            | 4.72         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.7115234  |
| rollout/                 |             |
|    ep_len_mean           | 59          |
|    ep_rew_mean           | -28.4       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 7           |
|    time_elapsed          | 220         |
|    total_timesteps       | 1519616     |
| train/                   |             |
|    approx_kl             | 0.011671678 |
|    clip_fraction         | 0.139       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.16        |
|    cost_value_loss       | 5.51        |
|    cost_values           | 2.66        |
|    entropy               | -0.146      |
|    entropy_loss          | -0.148      |
|    explained_variance    | 0.892       |
|    lagrangian_multiplier | 0.00171     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.87        |
|    n_updates             | 7410        |
|    policy_gradient_loss  | -0.00139    |
|    std                   | 0.339       |
|    value_loss            | 4.15        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.79        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.79        |
| reward                   | -0.28868175 |
| rollout/                 |             |
|    ep_len_mean           | 55.9        |
|    ep_rew_mean           | -27.1       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 8           |
|    time_elapsed          | 245         |
|    total_timesteps       | 1521664     |
| train/                   |             |
|    approx_kl             | 0.011569798 |
|    clip_fraction         | 0.105       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.82        |
|    cost_value_loss       | 4.1         |
|    cost_values           | 2.63        |
|    entropy               | -0.14       |
|    entropy_loss          | -0.143      |
|    explained_variance    | 0.927       |
|    lagrangian_multiplier | 0.000528    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.24        |
|    n_updates             | 7420        |
|    policy_gradient_loss  | 0.00278     |
|    std                   | 0.339       |
|    value_loss            | 3.13        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.5555835  |
| rollout/                 |             |
|    ep_len_mean           | 56.8        |
|    ep_rew_mean           | -27.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 9           |
|    time_elapsed          | 269         |
|    total_timesteps       | 1523712     |
| train/                   |             |
|    approx_kl             | 0.017572157 |
|    clip_fraction         | 0.143       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.9         |
|    cost_value_loss       | 4.04        |
|    cost_values           | 2.65        |
|    entropy               | -0.136      |
|    entropy_loss          | -0.138      |
|    explained_variance    | 0.915       |
|    lagrangian_multiplier | 0.00102     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.18        |
|    n_updates             | 7430        |
|    policy_gradient_loss  | 0.00113     |
|    std                   | 0.338       |
|    value_loss            | 3.27        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.37        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.37        |
| reward                   | -0.36943632 |
| rollout/                 |             |
|    ep_len_mean           | 58.7        |
|    ep_rew_mean           | -28.1       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 10          |
|    time_elapsed          | 294         |
|    total_timesteps       | 1525760     |
| train/                   |             |
|    approx_kl             | 0.013493698 |
|    clip_fraction         | 0.137       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.96        |
|    cost_value_loss       | 4.48        |
|    cost_values           | 2.66        |
|    entropy               | -0.133      |
|    entropy_loss          | -0.135      |
|    explained_variance    | 0.915       |
|    lagrangian_multiplier | 0.000261    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.37        |
|    n_updates             | 7440        |
|    policy_gradient_loss  | 0.00267     |
|    std                   | 0.338       |
|    value_loss            | 3.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.86357707 |
| rollout/                 |             |
|    ep_len_mean           | 60.8        |
|    ep_rew_mean           | -28.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 11          |
|    time_elapsed          | 327         |
|    total_timesteps       | 1527808     |
| train/                   |             |
|    approx_kl             | 0.006570669 |
|    clip_fraction         | 0.124       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.76        |
|    cost_value_loss       | 4.13        |
|    cost_values           | 2.67        |
|    entropy               | -0.121      |
|    entropy_loss          | -0.127      |
|    explained_variance    | 0.913       |
|    lagrangian_multiplier | 0.000803    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.35        |
|    n_updates             | 7450        |
|    policy_gradient_loss  | 0.00259     |
|    std                   | 0.336       |
|    value_loss            | 3.59        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.6276308  |
| rollout/                 |             |
|    ep_len_mean           | 59.1        |
|    ep_rew_mean           | -28.1       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 12          |
|    time_elapsed          | 362         |
|    total_timesteps       | 1529856     |
| train/                   |             |
|    approx_kl             | 0.010200993 |
|    clip_fraction         | 0.135       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.86        |
|    cost_value_loss       | 4.67        |
|    cost_values           | 2.61        |
|    entropy               | -0.112      |
|    entropy_loss          | -0.115      |
|    explained_variance    | 0.922       |
|    lagrangian_multiplier | 0.000479    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.81        |
|    n_updates             | 7460        |
|    policy_gradient_loss  | 0.0013      |
|    std                   | 0.334       |
|    value_loss            | 3.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.62664807 |
| rollout/                 |             |
|    ep_len_mean           | 57.3        |
|    ep_rew_mean           | -27.8       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 13          |
|    time_elapsed          | 394         |
|    total_timesteps       | 1531904     |
| train/                   |             |
|    approx_kl             | 0.012809641 |
|    clip_fraction         | 0.145       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.83        |
|    cost_value_loss       | 4.42        |
|    cost_values           | 2.57        |
|    entropy               | -0.112      |
|    entropy_loss          | -0.111      |
|    explained_variance    | 0.939       |
|    lagrangian_multiplier | 0.000787    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.03        |
|    n_updates             | 7470        |
|    policy_gradient_loss  | 0.00425     |
|    std                   | 0.334       |
|    value_loss            | 2.31        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.9192046  |
| rollout/                 |             |
|    ep_len_mean           | 57.4        |
|    ep_rew_mean           | -27.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 14          |
|    time_elapsed          | 418         |
|    total_timesteps       | 1533952     |
| train/                   |             |
|    approx_kl             | 0.016714694 |
|    clip_fraction         | 0.137       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.37        |
|    cost_value_loss       | 3.16        |
|    cost_values           | 2.52        |
|    entropy               | -0.11       |
|    entropy_loss          | -0.111      |
|    explained_variance    | 0.935       |
|    lagrangian_multiplier | 0.00119     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.83        |
|    n_updates             | 7480        |
|    policy_gradient_loss  | 0.00152     |
|    std                   | 0.334       |
|    value_loss            | 2.75        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.4         |
| reward                   | -0.37779912 |
| rollout/                 |             |
|    ep_len_mean           | 57.9        |
|    ep_rew_mean           | -28.2       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 15          |
|    time_elapsed          | 442         |
|    total_timesteps       | 1536000     |
| train/                   |             |
|    approx_kl             | 0.009387694 |
|    clip_fraction         | 0.123       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.82        |
|    cost_value_loss       | 4.5         |
|    cost_values           | 2.41        |
|    entropy               | -0.106      |
|    entropy_loss          | -0.108      |
|    explained_variance    | 0.926       |
|    lagrangian_multiplier | 0.0015      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.18        |
|    n_updates             | 7490        |
|    policy_gradient_loss  | 0.00389     |
|    std                   | 0.333       |
|    value_loss            | 2.91        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.92821544 |
| rollout/                 |             |
|    ep_len_mean           | 58          |
|    ep_rew_mean           | -28         |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 16          |
|    time_elapsed          | 465         |
|    total_timesteps       | 1538048     |
| train/                   |             |
|    approx_kl             | 0.012630596 |
|    clip_fraction         | 0.114       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.85        |
|    cost_value_loss       | 4.39        |
|    cost_values           | 2.5         |
|    entropy               | -0.0926     |
|    entropy_loss          | -0.0997     |
|    explained_variance    | 0.921       |
|    lagrangian_multiplier | 0.000358    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.59        |
|    n_updates             | 7500        |
|    policy_gradient_loss  | 0.000411    |
|    std                   | 0.332       |
|    value_loss            | 3.2         |
------------------------------------------
------------------------------------------
| avg_speed                | 1.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.8         |
| reward                   | -0.7233143  |
| rollout/                 |             |
|    ep_len_mean           | 58.8        |
|    ep_rew_mean           | -28.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 17          |
|    time_elapsed          | 495         |
|    total_timesteps       | 1540096     |
| train/                   |             |
|    approx_kl             | 0.013269178 |
|    clip_fraction         | 0.121       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.81        |
|    cost_value_loss       | 4.29        |
|    cost_values           | 2.55        |
|    entropy               | -0.0826     |
|    entropy_loss          | -0.0871     |
|    explained_variance    | 0.931       |
|    lagrangian_multiplier | 0.000715    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.3         |
|    n_updates             | 7510        |
|    policy_gradient_loss  | 0.00326     |
|    std                   | 0.33        |
|    value_loss            | 2.75        |
------------------------------------------
-----------------------------------------
| avg_speed                | 4          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 4          |
| reward                   | -0.7122963 |
| rollout/                 |            |
|    ep_len_mean           | 61.5       |
|    ep_rew_mean           | -28.9      |
| time/                    |            |
|    fps                   | 69         |
|    iterations            | 18         |
|    time_elapsed          | 530        |
|    total_timesteps       | 1542144    |
| train/                   |            |
|    approx_kl             | 0.0107426  |
|    clip_fraction         | 0.118      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.01       |
|    cost_value_loss       | 4.89       |
|    cost_values           | 2.56       |
|    entropy               | -0.0761    |
|    entropy_loss          | -0.0794    |
|    explained_variance    | 0.897      |
|    lagrangian_multiplier | 0.00117    |
|    learning_rate         | 0.0003     |
|    loss                  | 3.5        |
|    n_updates             | 7520       |
|    policy_gradient_loss  | -0.00115   |
|    std                   | 0.329      |
|    value_loss            | 3.69       |
-----------------------------------------
------------------------------------------
| avg_speed                | 2.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.6         |
| reward                   | -0.66004145 |
| rollout/                 |             |
|    ep_len_mean           | 61.8        |
|    ep_rew_mean           | -29         |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 19          |
|    time_elapsed          | 559         |
|    total_timesteps       | 1544192     |
| train/                   |             |
|    approx_kl             | 0.015985928 |
|    clip_fraction         | 0.131       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.71        |
|    cost_value_loss       | 3.76        |
|    cost_values           | 2.58        |
|    entropy               | -0.0571     |
|    entropy_loss          | -0.0668     |
|    explained_variance    | 0.912       |
|    lagrangian_multiplier | 0.00156     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.32        |
|    n_updates             | 7530        |
|    policy_gradient_loss  | -0.00166    |
|    std                   | 0.326       |
|    value_loss            | 3.64        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.8         |
| reward                   | -0.68808097 |
| rollout/                 |             |
|    ep_len_mean           | 61.4        |
|    ep_rew_mean           | -29         |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 20          |
|    time_elapsed          | 582         |
|    total_timesteps       | 1546240     |
| train/                   |             |
|    approx_kl             | 0.016482038 |
|    clip_fraction         | 0.15        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.93        |
|    cost_value_loss       | 4.58        |
|    cost_values           | 2.57        |
|    entropy               | -0.0463     |
|    entropy_loss          | -0.0508     |
|    explained_variance    | 0.904       |
|    lagrangian_multiplier | 0.00106     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.46        |
|    n_updates             | 7540        |
|    policy_gradient_loss  | 0.00285     |
|    std                   | 0.324       |
|    value_loss            | 3.57        |
------------------------------------------
-----------------------------------------
| avg_speed                | 6.4        |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 6.4        |
| reward                   | -0.3470197 |
| rollout/                 |            |
|    ep_len_mean           | 60.9       |
|    ep_rew_mean           | -28.6      |
| time/                    |            |
|    fps                   | 70         |
|    iterations            | 21         |
|    time_elapsed          | 609        |
|    total_timesteps       | 1548288    |
| train/                   |            |
|    approx_kl             | 0.00984016 |
|    clip_fraction         | 0.155      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.77       |
|    cost_value_loss       | 4.01       |
|    cost_values           | 2.57       |
|    entropy               | -0.0406    |
|    entropy_loss          | -0.0429    |
|    explained_variance    | 0.913      |
|    lagrangian_multiplier | 0.0021     |
|    learning_rate         | 0.0003     |
|    loss                  | 3.09       |
|    n_updates             | 7550       |
|    policy_gradient_loss  | 0.00444    |
|    std                   | 0.323      |
|    value_loss            | 3.6        |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.18965676 |
| rollout/                 |             |
|    ep_len_mean           | 60.3        |
|    ep_rew_mean           | -28.4       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 22          |
|    time_elapsed          | 642         |
|    total_timesteps       | 1550336     |
| train/                   |             |
|    approx_kl             | 0.015011617 |
|    clip_fraction         | 0.157       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.77        |
|    cost_value_loss       | 4.08        |
|    cost_values           | 2.54        |
|    entropy               | -0.0366     |
|    entropy_loss          | -0.0382     |
|    explained_variance    | 0.903       |
|    lagrangian_multiplier | 0.000901    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.49        |
|    n_updates             | 7560        |
|    policy_gradient_loss  | 0.00448     |
|    std                   | 0.323       |
|    value_loss            | 3.67        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.15225983 |
| rollout/                 |             |
|    ep_len_mean           | 56.6        |
|    ep_rew_mean           | -26.8       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 23          |
|    time_elapsed          | 678         |
|    total_timesteps       | 1552384     |
| train/                   |             |
|    approx_kl             | 0.009762183 |
|    clip_fraction         | 0.116       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.83        |
|    cost_value_loss       | 4.45        |
|    cost_values           | 2.54        |
|    entropy               | -0.0287     |
|    entropy_loss          | -0.0333     |
|    explained_variance    | 0.901       |
|    lagrangian_multiplier | 0.000731    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.92        |
|    n_updates             | 7570        |
|    policy_gradient_loss  | 0.00152     |
|    std                   | 0.322       |
|    value_loss            | 3.9         |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.75310504 |
| rollout/                 |             |
|    ep_len_mean           | 54.8        |
|    ep_rew_mean           | -26.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 24          |
|    time_elapsed          | 713         |
|    total_timesteps       | 1554432     |
| train/                   |             |
|    approx_kl             | 0.013594456 |
|    clip_fraction         | 0.142       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.03        |
|    cost_value_loss       | 4.94        |
|    cost_values           | 2.59        |
|    entropy               | -0.0223     |
|    entropy_loss          | -0.0252     |
|    explained_variance    | 0.887       |
|    lagrangian_multiplier | 0.0025      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.52        |
|    n_updates             | 7580        |
|    policy_gradient_loss  | 0.0016      |
|    std                   | 0.321       |
|    value_loss            | 3.9         |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.7017332  |
| rollout/                 |             |
|    ep_len_mean           | 55.6        |
|    ep_rew_mean           | -26.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 25          |
|    time_elapsed          | 749         |
|    total_timesteps       | 1556480     |
| train/                   |             |
|    approx_kl             | 0.013449473 |
|    clip_fraction         | 0.131       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.94        |
|    cost_value_loss       | 4.76        |
|    cost_values           | 2.56        |
|    entropy               | -0.0187     |
|    entropy_loss          | -0.0206     |
|    explained_variance    | 0.93        |
|    lagrangian_multiplier | 0.000747    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.37        |
|    n_updates             | 7590        |
|    policy_gradient_loss  | -0.00105    |
|    std                   | 0.321       |
|    value_loss            | 2.83        |
------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.84883815 |
| rollout/                 |             |
|    ep_len_mean           | 57.2        |
|    ep_rew_mean           | -27.4       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 26          |
|    time_elapsed          | 786         |
|    total_timesteps       | 1558528     |
| train/                   |             |
|    approx_kl             | 0.013036769 |
|    clip_fraction         | 0.156       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.85        |
|    cost_value_loss       | 4.07        |
|    cost_values           | 2.55        |
|    entropy               | -0.0177     |
|    entropy_loss          | -0.0183     |
|    explained_variance    | 0.91        |
|    lagrangian_multiplier | 0.00199     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.08        |
|    n_updates             | 7600        |
|    policy_gradient_loss  | 0.00204     |
|    std                   | 0.321       |
|    value_loss            | 3.37        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.37340766 |
| rollout/                 |             |
|    ep_len_mean           | 56.4        |
|    ep_rew_mean           | -27.1       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 27          |
|    time_elapsed          | 819         |
|    total_timesteps       | 1560576     |
| train/                   |             |
|    approx_kl             | 0.017579766 |
|    clip_fraction         | 0.161       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.81        |
|    cost_value_loss       | 4.12        |
|    cost_values           | 2.55        |
|    entropy               | -0.0145     |
|    entropy_loss          | -0.0167     |
|    explained_variance    | 0.913       |
|    lagrangian_multiplier | 0.000321    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.37        |
|    n_updates             | 7610        |
|    policy_gradient_loss  | 0.00611     |
|    std                   | 0.321       |
|    value_loss            | 3.23        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.22209954 |
| rollout/                 |             |
|    ep_len_mean           | 54.2        |
|    ep_rew_mean           | -26.2       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 28          |
|    time_elapsed          | 846         |
|    total_timesteps       | 1562624     |
| train/                   |             |
|    approx_kl             | 0.011033733 |
|    clip_fraction         | 0.159       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.84        |
|    cost_value_loss       | 4.54        |
|    cost_values           | 2.53        |
|    entropy               | -0.00943    |
|    entropy_loss          | -0.0117     |
|    explained_variance    | 0.939       |
|    lagrangian_multiplier | 0.00159     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.1         |
|    n_updates             | 7620        |
|    policy_gradient_loss  | 0.00373     |
|    std                   | 0.321       |
|    value_loss            | 2.49        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3            |
| reward                   | -0.7902385   |
| rollout/                 |              |
|    ep_len_mean           | 53.6         |
|    ep_rew_mean           | -26.1        |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 29           |
|    time_elapsed          | 880          |
|    total_timesteps       | 1564672      |
| train/                   |              |
|    approx_kl             | 0.0116949435 |
|    clip_fraction         | 0.135        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.92         |
|    cost_value_loss       | 4.58         |
|    cost_values           | 2.49         |
|    entropy               | 0.000699     |
|    entropy_loss          | -0.0037      |
|    explained_variance    | 0.944        |
|    lagrangian_multiplier | 0.00225      |
|    learning_rate         | 0.0003       |
|    loss                  | 2.88         |
|    n_updates             | 7630         |
|    policy_gradient_loss  | 0.0061       |
|    std                   | 0.32         |
|    value_loss            | 2.08         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3           |
| reward                   | -0.62323517 |
| rollout/                 |             |
|    ep_len_mean           | 54.1        |
|    ep_rew_mean           | -26.4       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 30          |
|    time_elapsed          | 916         |
|    total_timesteps       | 1566720     |
| train/                   |             |
|    approx_kl             | 0.012153688 |
|    clip_fraction         | 0.173       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.84        |
|    cost_value_loss       | 4.88        |
|    cost_values           | 2.46        |
|    entropy               | 0.00681     |
|    entropy_loss          | 0.00438     |
|    explained_variance    | 0.931       |
|    lagrangian_multiplier | 0.00206     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.1         |
|    n_updates             | 7640        |
|    policy_gradient_loss  | -0.00164    |
|    std                   | 0.32        |
|    value_loss            | 2.51        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.88349336 |
| rollout/                 |             |
|    ep_len_mean           | 57.8        |
|    ep_rew_mean           | -27.1       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 31          |
|    time_elapsed          | 950         |
|    total_timesteps       | 1568768     |
| train/                   |             |
|    approx_kl             | 0.02612966  |
|    clip_fraction         | 0.183       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.67        |
|    cost_value_loss       | 4.16        |
|    cost_values           | 2.45        |
|    entropy               | 0.0122      |
|    entropy_loss          | 0.00903     |
|    explained_variance    | 0.955       |
|    lagrangian_multiplier | 0.00053     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.11        |
|    n_updates             | 7650        |
|    policy_gradient_loss  | 0.00598     |
|    std                   | 0.32        |
|    value_loss            | 1.8         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.24190524 |
| rollout/                 |             |
|    ep_len_mean           | 57.1        |
|    ep_rew_mean           | -26.9       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 32          |
|    time_elapsed          | 984         |
|    total_timesteps       | 1570816     |
| train/                   |             |
|    approx_kl             | 0.015779082 |
|    clip_fraction         | 0.154       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.15        |
|    cost_value_loss       | 6.02        |
|    cost_values           | 2.43        |
|    entropy               | 0.0109      |
|    entropy_loss          | 0.0124      |
|    explained_variance    | 0.888       |
|    lagrangian_multiplier | 8.09e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.33        |
|    n_updates             | 7660        |
|    policy_gradient_loss  | 0.00846     |
|    std                   | 0.32        |
|    value_loss            | 3.4         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.13426335 |
| rollout/                 |             |
|    ep_len_mean           | 63.8        |
|    ep_rew_mean           | -28.5       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 33          |
|    time_elapsed          | 1015        |
|    total_timesteps       | 1572864     |
| train/                   |             |
|    approx_kl             | 0.016088944 |
|    clip_fraction         | 0.15        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.77        |
|    cost_value_loss       | 4.28        |
|    cost_values           | 2.53        |
|    entropy               | 0.0111      |
|    entropy_loss          | 0.0108      |
|    explained_variance    | 0.903       |
|    lagrangian_multiplier | 0.00133     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.4         |
|    n_updates             | 7670        |
|    policy_gradient_loss  | 0.00344     |
|    std                   | 0.321       |
|    value_loss            | 3.47        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.33336276 |
| rollout/                 |             |
|    ep_len_mean           | 63          |
|    ep_rew_mean           | -28.5       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 34          |
|    time_elapsed          | 1045        |
|    total_timesteps       | 1574912     |
| train/                   |             |
|    approx_kl             | 0.009469362 |
|    clip_fraction         | 0.125       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.38        |
|    cost_value_loss       | 6.15        |
|    cost_values           | 2.5         |
|    entropy               | 0.00995     |
|    entropy_loss          | 0.0108      |
|    explained_variance    | 0.816       |
|    lagrangian_multiplier | 0.000953    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.02        |
|    n_updates             | 7680        |
|    policy_gradient_loss  | 0.000838    |
|    std                   | 0.322       |
|    value_loss            | 4.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.6         |
| reward                   | -0.88774776 |
| rollout/                 |             |
|    ep_len_mean           | 64.5        |
|    ep_rew_mean           | -29.1       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 35          |
|    time_elapsed          | 1075        |
|    total_timesteps       | 1576960     |
| train/                   |             |
|    approx_kl             | 0.013748105 |
|    clip_fraction         | 0.137       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.98        |
|    cost_value_loss       | 4.43        |
|    cost_values           | 2.56        |
|    entropy               | 0.0121      |
|    entropy_loss          | 0.0105      |
|    explained_variance    | 0.871       |
|    lagrangian_multiplier | 0.000739    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.8         |
|    n_updates             | 7690        |
|    policy_gradient_loss  | 0.00244     |
|    std                   | 0.321       |
|    value_loss            | 4.47        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.24027264 |
| rollout/                 |             |
|    ep_len_mean           | 57.5        |
|    ep_rew_mean           | -27.6       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 36          |
|    time_elapsed          | 1107        |
|    total_timesteps       | 1579008     |
| train/                   |             |
|    approx_kl             | 0.012156265 |
|    clip_fraction         | 0.134       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.98        |
|    cost_value_loss       | 5.06        |
|    cost_values           | 2.54        |
|    entropy               | 0.00957     |
|    entropy_loss          | 0.0115      |
|    explained_variance    | 0.892       |
|    lagrangian_multiplier | 0.00122     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.59        |
|    n_updates             | 7700        |
|    policy_gradient_loss  | -0.000487   |
|    std                   | 0.321       |
|    value_loss            | 4.02        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.6494845  |
| rollout/                 |             |
|    ep_len_mean           | 55.7        |
|    ep_rew_mean           | -27         |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 37          |
|    time_elapsed          | 1139        |
|    total_timesteps       | 1581056     |
| train/                   |             |
|    approx_kl             | 0.012711529 |
|    clip_fraction         | 0.159       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.68        |
|    cost_value_loss       | 4.02        |
|    cost_values           | 2.48        |
|    entropy               | 0.0101      |
|    entropy_loss          | 0.00962     |
|    explained_variance    | 0.919       |
|    lagrangian_multiplier | 0.000733    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.54        |
|    n_updates             | 7710        |
|    policy_gradient_loss  | 0.00544     |
|    std                   | 0.322       |
|    value_loss            | 3.47        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.8276349  |
| rollout/                 |             |
|    ep_len_mean           | 55.3        |
|    ep_rew_mean           | -26.7       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 38          |
|    time_elapsed          | 1166        |
|    total_timesteps       | 1583104     |
| train/                   |             |
|    approx_kl             | 0.025758605 |
|    clip_fraction         | 0.17        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.76        |
|    cost_value_loss       | 4.79        |
|    cost_values           | 2.35        |
|    entropy               | 0.0119      |
|    entropy_loss          | 0.0112      |
|    explained_variance    | 0.936       |
|    lagrangian_multiplier | 0.000272    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.54        |
|    n_updates             | 7720        |
|    policy_gradient_loss  | 0.00602     |
|    std                   | 0.322       |
|    value_loss            | 2.51        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.4         |
| reward                   | -0.42171866 |
| rollout/                 |             |
|    ep_len_mean           | 54.7        |
|    ep_rew_mean           | -25.9       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 39          |
|    time_elapsed          | 1191        |
|    total_timesteps       | 1585152     |
| train/                   |             |
|    approx_kl             | 0.009256138 |
|    clip_fraction         | 0.115       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.8         |
|    cost_value_loss       | 5.02        |
|    cost_values           | 2.38        |
|    entropy               | 0.0124      |
|    entropy_loss          | 0.0119      |
|    explained_variance    | 0.91        |
|    lagrangian_multiplier | 0.00103     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.27        |
|    n_updates             | 7730        |
|    policy_gradient_loss  | 0.00209     |
|    std                   | 0.322       |
|    value_loss            | 2.96        |
------------------------------------------
-----------------------------------------
| avg_speed                | 1.8        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 1.8        |
| reward                   | -0.6381094 |
| rollout/                 |            |
|    ep_len_mean           | 56.2       |
|    ep_rew_mean           | -26.7      |
| time/                    |            |
|    fps                   | 67         |
|    iterations            | 40         |
|    time_elapsed          | 1214       |
|    total_timesteps       | 1587200    |
| train/                   |            |
|    approx_kl             | 0.02318454 |
|    clip_fraction         | 0.128      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.9        |
|    cost_value_loss       | 4.82       |
|    cost_values           | 2.42       |
|    entropy               | 0.0195     |
|    entropy_loss          | 0.0161     |
|    explained_variance    | 0.934      |
|    lagrangian_multiplier | 0.00029    |
|    learning_rate         | 0.0003     |
|    loss                  | 3.5        |
|    n_updates             | 7740       |
|    policy_gradient_loss  | 0.00506    |
|    std                   | 0.321      |
|    value_loss            | 2.34       |
-----------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.83630735 |
| rollout/                 |             |
|    ep_len_mean           | 54.3        |
|    ep_rew_mean           | -26         |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 41          |
|    time_elapsed          | 1238        |
|    total_timesteps       | 1589248     |
| train/                   |             |
|    approx_kl             | 0.036563657 |
|    clip_fraction         | 0.19        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.79        |
|    cost_value_loss       | 4.44        |
|    cost_values           | 2.45        |
|    entropy               | 0.0194      |
|    entropy_loss          | 0.0199      |
|    explained_variance    | 0.944       |
|    lagrangian_multiplier | 0.00147     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.11        |
|    n_updates             | 7750        |
|    policy_gradient_loss  | 0.0117      |
|    std                   | 0.322       |
|    value_loss            | 2.28        |
------------------------------------------
-----------------------------------------
| avg_speed                | 5.4        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 5.4        |
| reward                   | -0.5777999 |
| rollout/                 |            |
|    ep_len_mean           | 52.4       |
|    ep_rew_mean           | -25.5      |
| time/                    |            |
|    fps                   | 67         |
|    iterations            | 42         |
|    time_elapsed          | 1266       |
|    total_timesteps       | 1591296    |
| train/                   |            |
|    approx_kl             | 0.01723262 |
|    clip_fraction         | 0.159      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.92       |
|    cost_value_loss       | 5.23       |
|    cost_values           | 2.44       |
|    entropy               | 0.0283     |
|    entropy_loss          | 0.0229     |
|    explained_variance    | 0.928      |
|    lagrangian_multiplier | 0.000917   |
|    learning_rate         | 0.0003     |
|    loss                  | 3.41       |
|    n_updates             | 7760       |
|    policy_gradient_loss  | 0.00617    |
|    std                   | 0.322      |
|    value_loss            | 2.55       |
-----------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.8231775  |
| rollout/                 |             |
|    ep_len_mean           | 52.8        |
|    ep_rew_mean           | -25.6       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 43          |
|    time_elapsed          | 1295        |
|    total_timesteps       | 1593344     |
| train/                   |             |
|    approx_kl             | 0.011337344 |
|    clip_fraction         | 0.126       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.88        |
|    cost_value_loss       | 5.16        |
|    cost_values           | 2.39        |
|    entropy               | 0.0403      |
|    entropy_loss          | 0.0345      |
|    explained_variance    | 0.953       |
|    lagrangian_multiplier | 0.0011      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.05        |
|    n_updates             | 7770        |
|    policy_gradient_loss  | 0.0047      |
|    std                   | 0.32        |
|    value_loss            | 1.8         |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.4          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.4          |
| reward                   | -0.8833734   |
| rollout/                 |              |
|    ep_len_mean           | 55.4         |
|    ep_rew_mean           | -26.7        |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 44           |
|    time_elapsed          | 1319         |
|    total_timesteps       | 1595392      |
| train/                   |              |
|    approx_kl             | 0.0124189295 |
|    clip_fraction         | 0.152        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.98         |
|    cost_value_loss       | 5.37         |
|    cost_values           | 2.41         |
|    entropy               | 0.0494       |
|    entropy_loss          | 0.045        |
|    explained_variance    | 0.945        |
|    lagrangian_multiplier | 0.00215      |
|    learning_rate         | 0.0003       |
|    loss                  | 2.99         |
|    n_updates             | 7780         |
|    policy_gradient_loss  | 0.00447      |
|    std                   | 0.319        |
|    value_loss            | 2.05         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.36472932 |
| rollout/                 |             |
|    ep_len_mean           | 56.3        |
|    ep_rew_mean           | -26.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 45          |
|    time_elapsed          | 1342        |
|    total_timesteps       | 1597440     |
| train/                   |             |
|    approx_kl             | 0.010569345 |
|    clip_fraction         | 0.132       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.83        |
|    cost_value_loss       | 4.96        |
|    cost_values           | 2.41        |
|    entropy               | 0.0604      |
|    entropy_loss          | 0.0553      |
|    explained_variance    | 0.922       |
|    lagrangian_multiplier | 0.00201     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.13        |
|    n_updates             | 7790        |
|    policy_gradient_loss  | 0.00128     |
|    std                   | 0.317       |
|    value_loss            | 2.79        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.66406286 |
| rollout/                 |             |
|    ep_len_mean           | 56          |
|    ep_rew_mean           | -26.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 46          |
|    time_elapsed          | 1368        |
|    total_timesteps       | 1599488     |
| train/                   |             |
|    approx_kl             | 0.008339067 |
|    clip_fraction         | 0.135       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.03        |
|    cost_value_loss       | 5.5         |
|    cost_values           | 2.45        |
|    entropy               | 0.0626      |
|    entropy_loss          | 0.0621      |
|    explained_variance    | 0.914       |
|    lagrangian_multiplier | 0.00291     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.18        |
|    n_updates             | 7800        |
|    policy_gradient_loss  | 0.00313     |
|    std                   | 0.317       |
|    value_loss            | 2.89        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.30648717 |
| rollout/                 |             |
|    ep_len_mean           | 54.7        |
|    ep_rew_mean           | -26         |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 47          |
|    time_elapsed          | 1405        |
|    total_timesteps       | 1601536     |
| train/                   |             |
|    approx_kl             | 0.015279876 |
|    clip_fraction         | 0.158       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.89        |
|    cost_value_loss       | 5.06        |
|    cost_values           | 2.39        |
|    entropy               | 0.0715      |
|    entropy_loss          | 0.0667      |
|    explained_variance    | 0.929       |
|    lagrangian_multiplier | 0.000972    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.06        |
|    n_updates             | 7810        |
|    policy_gradient_loss  | 0.00238     |
|    std                   | 0.316       |
|    value_loss            | 2.55        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.8585351  |
| rollout/                 |             |
|    ep_len_mean           | 54.7        |
|    ep_rew_mean           | -26.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 48          |
|    time_elapsed          | 1431        |
|    total_timesteps       | 1603584     |
| train/                   |             |
|    approx_kl             | 0.019615725 |
|    clip_fraction         | 0.143       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.14        |
|    cost_value_loss       | 6.26        |
|    cost_values           | 2.35        |
|    entropy               | 0.079       |
|    entropy_loss          | 0.0761      |
|    explained_variance    | 0.937       |
|    lagrangian_multiplier | 0.00162     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.39        |
|    n_updates             | 7820        |
|    policy_gradient_loss  | 0.00735     |
|    std                   | 0.315       |
|    value_loss            | 2.3         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.26257142 |
| rollout/                 |             |
|    ep_len_mean           | 54.1        |
|    ep_rew_mean           | -26.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 49          |
|    time_elapsed          | 1460        |
|    total_timesteps       | 1605632     |
| train/                   |             |
|    approx_kl             | 0.024088038 |
|    clip_fraction         | 0.169       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.75        |
|    cost_value_loss       | 5.18        |
|    cost_values           | 2.34        |
|    entropy               | 0.0798      |
|    entropy_loss          | 0.0797      |
|    explained_variance    | 0.941       |
|    lagrangian_multiplier | 0.00155     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.14        |
|    n_updates             | 7830        |
|    policy_gradient_loss  | 0.00575     |
|    std                   | 0.315       |
|    value_loss            | 2.43        |
------------------------------------------
-----------------------------------
| avg_speed          | 5          |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 5          |
| reward             | -0.5326505 |
| rollout/           |            |
|    ep_len_mean     | 54.1       |
|    ep_rew_mean     | -26.1      |
| time/              |            |
|    fps             | 69         |
|    iterations      | 1          |
|    time_elapsed    | 29         |
|    total_timesteps | 1607680    |
-----------------------------------
-------------------------------------------
| avg_speed                | 2            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2            |
| reward                   | -0.65277207  |
| rollout/                 |              |
|    ep_len_mean           | 55           |
|    ep_rew_mean           | -26.3        |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 2            |
|    time_elapsed          | 61           |
|    total_timesteps       | 1609728      |
| train/                   |              |
|    approx_kl             | 0.0086287595 |
|    clip_fraction         | 0.159        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.73         |
|    cost_value_loss       | 4.71         |
|    cost_values           | 2.3          |
|    entropy               | 0.0855       |
|    entropy_loss          | 0.082        |
|    explained_variance    | 0.937        |
|    lagrangian_multiplier | 0.000603     |
|    learning_rate         | 0.0003       |
|    loss                  | 3.11         |
|    n_updates             | 7850         |
|    policy_gradient_loss  | 0.00535      |
|    std                   | 0.315        |
|    value_loss            | 2.3          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.8199565  |
| rollout/                 |             |
|    ep_len_mean           | 52.5        |
|    ep_rew_mean           | -25.4       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 3           |
|    time_elapsed          | 92          |
|    total_timesteps       | 1611776     |
| train/                   |             |
|    approx_kl             | 0.017882394 |
|    clip_fraction         | 0.168       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.72        |
|    cost_value_loss       | 5.17        |
|    cost_values           | 2.28        |
|    entropy               | 0.092       |
|    entropy_loss          | 0.0888      |
|    explained_variance    | 0.945       |
|    lagrangian_multiplier | 0.00145     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.23        |
|    n_updates             | 7860        |
|    policy_gradient_loss  | 0.00208     |
|    std                   | 0.314       |
|    value_loss            | 2.13        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.33480257 |
| rollout/                 |             |
|    ep_len_mean           | 54.1        |
|    ep_rew_mean           | -25.5       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 4           |
|    time_elapsed          | 126         |
|    total_timesteps       | 1613824     |
| train/                   |             |
|    approx_kl             | 0.017569102 |
|    clip_fraction         | 0.179       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.77        |
|    cost_value_loss       | 5.01        |
|    cost_values           | 2.25        |
|    entropy               | 0.0955      |
|    entropy_loss          | 0.0937      |
|    explained_variance    | 0.947       |
|    lagrangian_multiplier | 0.0012      |
|    learning_rate         | 0.0003      |
|    loss                  | 2.88        |
|    n_updates             | 7870        |
|    policy_gradient_loss  | 0.00216     |
|    std                   | 0.314       |
|    value_loss            | 1.89        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.84387267 |
| rollout/                 |             |
|    ep_len_mean           | 55.1        |
|    ep_rew_mean           | -25.8       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 5           |
|    time_elapsed          | 160         |
|    total_timesteps       | 1615872     |
| train/                   |             |
|    approx_kl             | 0.015259158 |
|    clip_fraction         | 0.178       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.11        |
|    cost_value_loss       | 6.05        |
|    cost_values           | 2.29        |
|    entropy               | 0.104       |
|    entropy_loss          | 0.0997      |
|    explained_variance    | 0.947       |
|    lagrangian_multiplier | 0.00308     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.01        |
|    n_updates             | 7880        |
|    policy_gradient_loss  | 0.00384     |
|    std                   | 0.313       |
|    value_loss            | 1.85        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.29740134 |
| rollout/                 |             |
|    ep_len_mean           | 54.5        |
|    ep_rew_mean           | -25.7       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 6           |
|    time_elapsed          | 191         |
|    total_timesteps       | 1617920     |
| train/                   |             |
|    approx_kl             | 0.010037966 |
|    clip_fraction         | 0.166       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.65        |
|    cost_value_loss       | 4.66        |
|    cost_values           | 2.3         |
|    entropy               | 0.107       |
|    entropy_loss          | 0.106       |
|    explained_variance    | 0.943       |
|    lagrangian_multiplier | 0.00189     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.89        |
|    n_updates             | 7890        |
|    policy_gradient_loss  | 0.00856     |
|    std                   | 0.313       |
|    value_loss            | 2.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.7954075  |
| rollout/                 |             |
|    ep_len_mean           | 53.8        |
|    ep_rew_mean           | -25.4       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 7           |
|    time_elapsed          | 225         |
|    total_timesteps       | 1619968     |
| train/                   |             |
|    approx_kl             | 0.018629441 |
|    clip_fraction         | 0.157       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.95        |
|    cost_value_loss       | 5.83        |
|    cost_values           | 2.28        |
|    entropy               | 0.105       |
|    entropy_loss          | 0.106       |
|    explained_variance    | 0.945       |
|    lagrangian_multiplier | 0.0018      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.19        |
|    n_updates             | 7900        |
|    policy_gradient_loss  | 0.00262     |
|    std                   | 0.314       |
|    value_loss            | 1.9         |
------------------------------------------
------------------------------------------
| avg_speed                | 4.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.4         |
| reward                   | -0.54718745 |
| rollout/                 |             |
|    ep_len_mean           | 54.1        |
|    ep_rew_mean           | -25.7       |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 8           |
|    time_elapsed          | 261         |
|    total_timesteps       | 1622016     |
| train/                   |             |
|    approx_kl             | 0.0162195   |
|    clip_fraction         | 0.154       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.05        |
|    cost_value_loss       | 6.13        |
|    cost_values           | 2.32        |
|    entropy               | 0.108       |
|    entropy_loss          | 0.106       |
|    explained_variance    | 0.948       |
|    lagrangian_multiplier | 0.00196     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.05        |
|    n_updates             | 7910        |
|    policy_gradient_loss  | 0.00397     |
|    std                   | 0.314       |
|    value_loss            | 1.83        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.172228   |
| rollout/                 |             |
|    ep_len_mean           | 54.2        |
|    ep_rew_mean           | -26.2       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 9           |
|    time_elapsed          | 289         |
|    total_timesteps       | 1624064     |
| train/                   |             |
|    approx_kl             | 0.019131035 |
|    clip_fraction         | 0.15        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.88        |
|    cost_value_loss       | 5.52        |
|    cost_values           | 2.32        |
|    entropy               | 0.12        |
|    entropy_loss          | 0.114       |
|    explained_variance    | 0.934       |
|    lagrangian_multiplier | 0.000691    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.52        |
|    n_updates             | 7920        |
|    policy_gradient_loss  | 0.00159     |
|    std                   | 0.312       |
|    value_loss            | 2.43        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.62737954 |
| rollout/                 |             |
|    ep_len_mean           | 52.6        |
|    ep_rew_mean           | -25.7       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 10          |
|    time_elapsed          | 315         |
|    total_timesteps       | 1626112     |
| train/                   |             |
|    approx_kl             | 0.015685413 |
|    clip_fraction         | 0.145       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.82        |
|    cost_value_loss       | 4.72        |
|    cost_values           | 2.39        |
|    entropy               | 0.128       |
|    entropy_loss          | 0.124       |
|    explained_variance    | 0.94        |
|    lagrangian_multiplier | 0.00239     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.83        |
|    n_updates             | 7930        |
|    policy_gradient_loss  | 0.00451     |
|    std                   | 0.311       |
|    value_loss            | 2.37        |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.58831227 |
| rollout/                 |             |
|    ep_len_mean           | 53.2        |
|    ep_rew_mean           | -25.6       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 11          |
|    time_elapsed          | 341         |
|    total_timesteps       | 1628160     |
| train/                   |             |
|    approx_kl             | 0.01972298  |
|    clip_fraction         | 0.139       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.81        |
|    cost_value_loss       | 4.82        |
|    cost_values           | 2.34        |
|    entropy               | 0.134       |
|    entropy_loss          | 0.131       |
|    explained_variance    | 0.956       |
|    lagrangian_multiplier | 0.00297     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.69        |
|    n_updates             | 7940        |
|    policy_gradient_loss  | 0.00249     |
|    std                   | 0.31        |
|    value_loss            | 1.63        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.6134725  |
| rollout/                 |             |
|    ep_len_mean           | 51.6        |
|    ep_rew_mean           | -25.3       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 12          |
|    time_elapsed          | 367         |
|    total_timesteps       | 1630208     |
| train/                   |             |
|    approx_kl             | 0.015821181 |
|    clip_fraction         | 0.188       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.02        |
|    cost_value_loss       | 5.73        |
|    cost_values           | 2.3         |
|    entropy               | 0.142       |
|    entropy_loss          | 0.138       |
|    explained_variance    | 0.92        |
|    lagrangian_multiplier | 0.00143     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.26        |
|    n_updates             | 7950        |
|    policy_gradient_loss  | 0.00884     |
|    std                   | 0.308       |
|    value_loss            | 2.66        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.30268702 |
| rollout/                 |             |
|    ep_len_mean           | 53          |
|    ep_rew_mean           | -26.1       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 13          |
|    time_elapsed          | 402         |
|    total_timesteps       | 1632256     |
| train/                   |             |
|    approx_kl             | 0.019022714 |
|    clip_fraction         | 0.212       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.51        |
|    cost_value_loss       | 4           |
|    cost_values           | 2.28        |
|    entropy               | 0.157       |
|    entropy_loss          | 0.15        |
|    explained_variance    | 0.963       |
|    lagrangian_multiplier | 0.00082     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.86        |
|    n_updates             | 7960        |
|    policy_gradient_loss  | 0.0109      |
|    std                   | 0.306       |
|    value_loss            | 1.59        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.46310925 |
| rollout/                 |             |
|    ep_len_mean           | 53.1        |
|    ep_rew_mean           | -26.2       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 14          |
|    time_elapsed          | 437         |
|    total_timesteps       | 1634304     |
| train/                   |             |
|    approx_kl             | 0.015476049 |
|    clip_fraction         | 0.169       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.85        |
|    cost_value_loss       | 5.33        |
|    cost_values           | 2.25        |
|    entropy               | 0.156       |
|    entropy_loss          | 0.158       |
|    explained_variance    | 0.918       |
|    lagrangian_multiplier | 0.00213     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.04        |
|    n_updates             | 7970        |
|    policy_gradient_loss  | 0.000557    |
|    std                   | 0.306       |
|    value_loss            | 2.73        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.5359347  |
| rollout/                 |             |
|    ep_len_mean           | 56.6        |
|    ep_rew_mean           | -27.8       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 15          |
|    time_elapsed          | 466         |
|    total_timesteps       | 1636352     |
| train/                   |             |
|    approx_kl             | 0.011440968 |
|    clip_fraction         | 0.158       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.62        |
|    cost_value_loss       | 4.18        |
|    cost_values           | 2.27        |
|    entropy               | 0.164       |
|    entropy_loss          | 0.158       |
|    explained_variance    | 0.93        |
|    lagrangian_multiplier | 0.000697    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.05        |
|    n_updates             | 7980        |
|    policy_gradient_loss  | -0.000295   |
|    std                   | 0.305       |
|    value_loss            | 2.7         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.31346443 |
| rollout/                 |             |
|    ep_len_mean           | 52.8        |
|    ep_rew_mean           | -26         |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 16          |
|    time_elapsed          | 489         |
|    total_timesteps       | 1638400     |
| train/                   |             |
|    approx_kl             | 0.02188298  |
|    clip_fraction         | 0.142       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.61        |
|    cost_value_loss       | 4.31        |
|    cost_values           | 2.25        |
|    entropy               | 0.168       |
|    entropy_loss          | 0.166       |
|    explained_variance    | 0.93        |
|    lagrangian_multiplier | 0.00142     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.99        |
|    n_updates             | 7990        |
|    policy_gradient_loss  | 0.00717     |
|    std                   | 0.305       |
|    value_loss            | 2.9         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.13293327 |
| rollout/                 |             |
|    ep_len_mean           | 50.8        |
|    ep_rew_mean           | -25.8       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 17          |
|    time_elapsed          | 519         |
|    total_timesteps       | 1640448     |
| train/                   |             |
|    approx_kl             | 0.020409552 |
|    clip_fraction         | 0.162       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.55        |
|    cost_value_loss       | 4.18        |
|    cost_values           | 2.24        |
|    entropy               | 0.17        |
|    entropy_loss          | 0.169       |
|    explained_variance    | 0.933       |
|    lagrangian_multiplier | 0.00111     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.96        |
|    n_updates             | 8000        |
|    policy_gradient_loss  | 0.00683     |
|    std                   | 0.306       |
|    value_loss            | 2.39        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.36288506 |
| rollout/                 |             |
|    ep_len_mean           | 50.4        |
|    ep_rew_mean           | -25.5       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 18          |
|    time_elapsed          | 554         |
|    total_timesteps       | 1642496     |
| train/                   |             |
|    approx_kl             | 0.023372868 |
|    clip_fraction         | 0.13        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.41        |
|    cost_value_loss       | 3.68        |
|    cost_values           | 2.17        |
|    entropy               | 0.173       |
|    entropy_loss          | 0.171       |
|    explained_variance    | 0.956       |
|    lagrangian_multiplier | 0.00116     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.4         |
|    n_updates             | 8010        |
|    policy_gradient_loss  | 0.00294     |
|    std                   | 0.306       |
|    value_loss            | 1.85        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2663024  |
| rollout/                 |             |
|    ep_len_mean           | 50.4        |
|    ep_rew_mean           | -24.9       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 19          |
|    time_elapsed          | 585         |
|    total_timesteps       | 1644544     |
| train/                   |             |
|    approx_kl             | 0.015455939 |
|    clip_fraction         | 0.149       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.65        |
|    cost_value_loss       | 4.68        |
|    cost_values           | 2.21        |
|    entropy               | 0.178       |
|    entropy_loss          | 0.176       |
|    explained_variance    | 0.944       |
|    lagrangian_multiplier | 0.00132     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.84        |
|    n_updates             | 8020        |
|    policy_gradient_loss  | 0.00299     |
|    std                   | 0.306       |
|    value_loss            | 2.14        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.48200476 |
| rollout/                 |             |
|    ep_len_mean           | 49.4        |
|    ep_rew_mean           | -24.7       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 20          |
|    time_elapsed          | 617         |
|    total_timesteps       | 1646592     |
| train/                   |             |
|    approx_kl             | 0.029110089 |
|    clip_fraction         | 0.184       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.78        |
|    cost_value_loss       | 5.05        |
|    cost_values           | 2.21        |
|    entropy               | 0.176       |
|    entropy_loss          | 0.178       |
|    explained_variance    | 0.939       |
|    lagrangian_multiplier | 0.00227     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.9         |
|    n_updates             | 8030        |
|    policy_gradient_loss  | 0.00656     |
|    std                   | 0.307       |
|    value_loss            | 2.05        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.22260596 |
| rollout/                 |             |
|    ep_len_mean           | 49.9        |
|    ep_rew_mean           | -25.1       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 21          |
|    time_elapsed          | 643         |
|    total_timesteps       | 1648640     |
| train/                   |             |
|    approx_kl             | 0.013299124 |
|    clip_fraction         | 0.186       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.56        |
|    cost_value_loss       | 4.3         |
|    cost_values           | 2.18        |
|    entropy               | 0.179       |
|    entropy_loss          | 0.177       |
|    explained_variance    | 0.955       |
|    lagrangian_multiplier | 0.00124     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.59        |
|    n_updates             | 8040        |
|    policy_gradient_loss  | 0.00222     |
|    std                   | 0.306       |
|    value_loss            | 1.78        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.25384942 |
| rollout/                 |             |
|    ep_len_mean           | 52.5        |
|    ep_rew_mean           | -25.8       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 22          |
|    time_elapsed          | 666         |
|    total_timesteps       | 1650688     |
| train/                   |             |
|    approx_kl             | 0.014768696 |
|    clip_fraction         | 0.146       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.78        |
|    cost_value_loss       | 5.47        |
|    cost_values           | 2.21        |
|    entropy               | 0.181       |
|    entropy_loss          | 0.181       |
|    explained_variance    | 0.964       |
|    lagrangian_multiplier | 0.00195     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.94        |
|    n_updates             | 8050        |
|    policy_gradient_loss  | 0.00377     |
|    std                   | 0.306       |
|    value_loss            | 1.44        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.387142   |
| rollout/                 |             |
|    ep_len_mean           | 53.7        |
|    ep_rew_mean           | -26.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 23          |
|    time_elapsed          | 690         |
|    total_timesteps       | 1652736     |
| train/                   |             |
|    approx_kl             | 0.010692091 |
|    clip_fraction         | 0.139       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.7         |
|    cost_value_loss       | 4.77        |
|    cost_values           | 2.25        |
|    entropy               | 0.185       |
|    entropy_loss          | 0.183       |
|    explained_variance    | 0.892       |
|    lagrangian_multiplier | 0.00214     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.96        |
|    n_updates             | 8060        |
|    policy_gradient_loss  | -0.000695   |
|    std                   | 0.306       |
|    value_loss            | 3.03        |
------------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.619835   |
| rollout/                 |             |
|    ep_len_mean           | 54.1        |
|    ep_rew_mean           | -26.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 24          |
|    time_elapsed          | 722         |
|    total_timesteps       | 1654784     |
| train/                   |             |
|    approx_kl             | 0.018313516 |
|    clip_fraction         | 0.165       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.7         |
|    cost_value_loss       | 4.6         |
|    cost_values           | 2.21        |
|    entropy               | 0.181       |
|    entropy_loss          | 0.184       |
|    explained_variance    | 0.951       |
|    lagrangian_multiplier | 0.000604    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.9         |
|    n_updates             | 8070        |
|    policy_gradient_loss  | 0.00198     |
|    std                   | 0.308       |
|    value_loss            | 1.8         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.8675673  |
| rollout/                 |             |
|    ep_len_mean           | 50.6        |
|    ep_rew_mean           | -25.6       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 25          |
|    time_elapsed          | 755         |
|    total_timesteps       | 1656832     |
| train/                   |             |
|    approx_kl             | 0.051788695 |
|    clip_fraction         | 0.164       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.47        |
|    cost_value_loss       | 3.95        |
|    cost_values           | 2.21        |
|    entropy               | 0.183       |
|    entropy_loss          | 0.181       |
|    explained_variance    | 0.955       |
|    lagrangian_multiplier | 0.000605    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.79        |
|    n_updates             | 8080        |
|    policy_gradient_loss  | 0.00267     |
|    std                   | 0.307       |
|    value_loss            | 1.89        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.44023094 |
| rollout/                 |             |
|    ep_len_mean           | 52.2        |
|    ep_rew_mean           | -26.2       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 26          |
|    time_elapsed          | 783         |
|    total_timesteps       | 1658880     |
| train/                   |             |
|    approx_kl             | 0.01939657  |
|    clip_fraction         | 0.183       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.52        |
|    cost_value_loss       | 4.54        |
|    cost_values           | 2.17        |
|    entropy               | 0.188       |
|    entropy_loss          | 0.185       |
|    explained_variance    | 0.943       |
|    lagrangian_multiplier | 0.00243     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.68        |
|    n_updates             | 8090        |
|    policy_gradient_loss  | 0.00858     |
|    std                   | 0.306       |
|    value_loss            | 2.23        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.8972065  |
| rollout/                 |             |
|    ep_len_mean           | 52.6        |
|    ep_rew_mean           | -25.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 27          |
|    time_elapsed          | 812         |
|    total_timesteps       | 1660928     |
| train/                   |             |
|    approx_kl             | 0.014555033 |
|    clip_fraction         | 0.176       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.8         |
|    cost_value_loss       | 5.29        |
|    cost_values           | 2.15        |
|    entropy               | 0.189       |
|    entropy_loss          | 0.189       |
|    explained_variance    | 0.952       |
|    lagrangian_multiplier | 0.00146     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.95        |
|    n_updates             | 8100        |
|    policy_gradient_loss  | 0.00444     |
|    std                   | 0.306       |
|    value_loss            | 1.83        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.6         |
| reward                   | -0.28656104 |
| rollout/                 |             |
|    ep_len_mean           | 55.5        |
|    ep_rew_mean           | -26.8       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 28          |
|    time_elapsed          | 844         |
|    total_timesteps       | 1662976     |
| train/                   |             |
|    approx_kl             | 0.015517008 |
|    clip_fraction         | 0.174       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.85        |
|    cost_value_loss       | 5.49        |
|    cost_values           | 2.2         |
|    entropy               | 0.195       |
|    entropy_loss          | 0.192       |
|    explained_variance    | 0.943       |
|    lagrangian_multiplier | 0.00124     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.15        |
|    n_updates             | 8110        |
|    policy_gradient_loss  | 0.00474     |
|    std                   | 0.305       |
|    value_loss            | 2.19        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.5535972  |
| rollout/                 |             |
|    ep_len_mean           | 54.6        |
|    ep_rew_mean           | -26.4       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 29          |
|    time_elapsed          | 880         |
|    total_timesteps       | 1665024     |
| train/                   |             |
|    approx_kl             | 0.012599881 |
|    clip_fraction         | 0.143       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.09        |
|    cost_value_loss       | 6.18        |
|    cost_values           | 2.24        |
|    entropy               | 0.204       |
|    entropy_loss          | 0.199       |
|    explained_variance    | 0.867       |
|    lagrangian_multiplier | 0.00144     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.57        |
|    n_updates             | 8120        |
|    policy_gradient_loss  | 0.00301     |
|    std                   | 0.304       |
|    value_loss            | 3.66        |
------------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.8666941  |
| rollout/                 |             |
|    ep_len_mean           | 55.5        |
|    ep_rew_mean           | -26.6       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 30          |
|    time_elapsed          | 911         |
|    total_timesteps       | 1667072     |
| train/                   |             |
|    approx_kl             | 0.018713277 |
|    clip_fraction         | 0.14        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.72        |
|    cost_value_loss       | 5.05        |
|    cost_values           | 2.27        |
|    entropy               | 0.206       |
|    entropy_loss          | 0.206       |
|    explained_variance    | 0.92        |
|    lagrangian_multiplier | 0.00179     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.15        |
|    n_updates             | 8130        |
|    policy_gradient_loss  | 0.00473     |
|    std                   | 0.304       |
|    value_loss            | 2.82        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.4         |
| reward                   | -0.33551916 |
| rollout/                 |             |
|    ep_len_mean           | 54.7        |
|    ep_rew_mean           | -26.6       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 31          |
|    time_elapsed          | 942         |
|    total_timesteps       | 1669120     |
| train/                   |             |
|    approx_kl             | 0.014800871 |
|    clip_fraction         | 0.148       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.83        |
|    cost_value_loss       | 5.61        |
|    cost_values           | 2.21        |
|    entropy               | 0.208       |
|    entropy_loss          | 0.207       |
|    explained_variance    | 0.877       |
|    lagrangian_multiplier | 0.00129     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.74        |
|    n_updates             | 8140        |
|    policy_gradient_loss  | 0.00267     |
|    std                   | 0.303       |
|    value_loss            | 3.88        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.71166694 |
| rollout/                 |             |
|    ep_len_mean           | 55.5        |
|    ep_rew_mean           | -27.2       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 32          |
|    time_elapsed          | 973         |
|    total_timesteps       | 1671168     |
| train/                   |             |
|    approx_kl             | 0.009344159 |
|    clip_fraction         | 0.156       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.53        |
|    cost_value_loss       | 4.4         |
|    cost_values           | 2.21        |
|    entropy               | 0.209       |
|    entropy_loss          | 0.209       |
|    explained_variance    | 0.91        |
|    lagrangian_multiplier | 0.00111     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.1         |
|    n_updates             | 8150        |
|    policy_gradient_loss  | 0.000907    |
|    std                   | 0.303       |
|    value_loss            | 3.39        |
------------------------------------------
------------------------------------------
| avg_speed                | 6           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6           |
| reward                   | -0.26959684 |
| rollout/                 |             |
|    ep_len_mean           | 51.8        |
|    ep_rew_mean           | -25.6       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 33          |
|    time_elapsed          | 1004        |
|    total_timesteps       | 1673216     |
| train/                   |             |
|    approx_kl             | 0.008654104 |
|    clip_fraction         | 0.12        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.62        |
|    cost_value_loss       | 4.77        |
|    cost_values           | 2.16        |
|    entropy               | 0.212       |
|    entropy_loss          | 0.21        |
|    explained_variance    | 0.947       |
|    lagrangian_multiplier | 0.000537    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.35        |
|    n_updates             | 8160        |
|    policy_gradient_loss  | 0.00307     |
|    std                   | 0.302       |
|    value_loss            | 2.14        |
------------------------------------------
------------------------------------------
| avg_speed                | 6           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6           |
| reward                   | -0.19345209 |
| rollout/                 |             |
|    ep_len_mean           | 51          |
|    ep_rew_mean           | -25.4       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 34          |
|    time_elapsed          | 1035        |
|    total_timesteps       | 1675264     |
| train/                   |             |
|    approx_kl             | 0.031345464 |
|    clip_fraction         | 0.192       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.77        |
|    cost_value_loss       | 5.08        |
|    cost_values           | 2.17        |
|    entropy               | 0.216       |
|    entropy_loss          | 0.215       |
|    explained_variance    | 0.958       |
|    lagrangian_multiplier | 0.000911    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.88        |
|    n_updates             | 8170        |
|    policy_gradient_loss  | 0.0137      |
|    std                   | 0.302       |
|    value_loss            | 1.7         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.30706492 |
| rollout/                 |             |
|    ep_len_mean           | 52.1        |
|    ep_rew_mean           | -26         |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 35          |
|    time_elapsed          | 1066        |
|    total_timesteps       | 1677312     |
| train/                   |             |
|    approx_kl             | 0.011272107 |
|    clip_fraction         | 0.168       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.65        |
|    cost_value_loss       | 4.73        |
|    cost_values           | 2.17        |
|    entropy               | 0.221       |
|    entropy_loss          | 0.219       |
|    explained_variance    | 0.958       |
|    lagrangian_multiplier | 0.00153     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.84        |
|    n_updates             | 8180        |
|    policy_gradient_loss  | 0.00477     |
|    std                   | 0.301       |
|    value_loss            | 1.67        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3329125  |
| rollout/                 |             |
|    ep_len_mean           | 50.9        |
|    ep_rew_mean           | -25.2       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 36          |
|    time_elapsed          | 1097        |
|    total_timesteps       | 1679360     |
| train/                   |             |
|    approx_kl             | 0.024824373 |
|    clip_fraction         | 0.176       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.72        |
|    cost_value_loss       | 4.98        |
|    cost_values           | 2.18        |
|    entropy               | 0.221       |
|    entropy_loss          | 0.221       |
|    explained_variance    | 0.946       |
|    lagrangian_multiplier | 0.00114     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.96        |
|    n_updates             | 8190        |
|    policy_gradient_loss  | 0.00693     |
|    std                   | 0.301       |
|    value_loss            | 2.15        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3644486  |
| rollout/                 |             |
|    ep_len_mean           | 50.4        |
|    ep_rew_mean           | -25         |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 37          |
|    time_elapsed          | 1128        |
|    total_timesteps       | 1681408     |
| train/                   |             |
|    approx_kl             | 0.018190369 |
|    clip_fraction         | 0.177       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.75        |
|    cost_value_loss       | 4.99        |
|    cost_values           | 2.22        |
|    entropy               | 0.227       |
|    entropy_loss          | 0.224       |
|    explained_variance    | 0.948       |
|    lagrangian_multiplier | 0.00209     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.96        |
|    n_updates             | 8200        |
|    policy_gradient_loss  | 0.00322     |
|    std                   | 0.301       |
|    value_loss            | 1.97        |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.81615645 |
| rollout/                 |             |
|    ep_len_mean           | 51.4        |
|    ep_rew_mean           | -25.4       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 38          |
|    time_elapsed          | 1162        |
|    total_timesteps       | 1683456     |
| train/                   |             |
|    approx_kl             | 0.017647762 |
|    clip_fraction         | 0.175       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.73        |
|    cost_value_loss       | 4.92        |
|    cost_values           | 2.14        |
|    entropy               | 0.236       |
|    entropy_loss          | 0.232       |
|    explained_variance    | 0.955       |
|    lagrangian_multiplier | 0.00283     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.67        |
|    n_updates             | 8210        |
|    policy_gradient_loss  | 0.00431     |
|    std                   | 0.3         |
|    value_loss            | 1.64        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.4         |
| reward                   | -0.44546613 |
| rollout/                 |             |
|    ep_len_mean           | 51          |
|    ep_rew_mean           | -25.6       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 39          |
|    time_elapsed          | 1198        |
|    total_timesteps       | 1685504     |
| train/                   |             |
|    approx_kl             | 0.021362204 |
|    clip_fraction         | 0.147       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.61        |
|    cost_value_loss       | 4.89        |
|    cost_values           | 2.12        |
|    entropy               | 0.244       |
|    entropy_loss          | 0.241       |
|    explained_variance    | 0.951       |
|    lagrangian_multiplier | 0.00107     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.86        |
|    n_updates             | 8220        |
|    policy_gradient_loss  | -0.000204   |
|    std                   | 0.298       |
|    value_loss            | 1.97        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.2         |
| reward                   | -0.28169197 |
| rollout/                 |             |
|    ep_len_mean           | 52          |
|    ep_rew_mean           | -26.5       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 40          |
|    time_elapsed          | 1228        |
|    total_timesteps       | 1687552     |
| train/                   |             |
|    approx_kl             | 0.024274498 |
|    clip_fraction         | 0.171       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.43        |
|    cost_value_loss       | 4.06        |
|    cost_values           | 2.17        |
|    entropy               | 0.248       |
|    entropy_loss          | 0.246       |
|    explained_variance    | 0.934       |
|    lagrangian_multiplier | 0.00128     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.84        |
|    n_updates             | 8230        |
|    policy_gradient_loss  | 0.00516     |
|    std                   | 0.298       |
|    value_loss            | 2.48        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.7442583  |
| rollout/                 |             |
|    ep_len_mean           | 52.7        |
|    ep_rew_mean           | -26.9       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 41          |
|    time_elapsed          | 1255        |
|    total_timesteps       | 1689600     |
| train/                   |             |
|    approx_kl             | 0.016945317 |
|    clip_fraction         | 0.181       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.58        |
|    cost_value_loss       | 4.54        |
|    cost_values           | 2.17        |
|    entropy               | 0.254       |
|    entropy_loss          | 0.251       |
|    explained_variance    | 0.946       |
|    lagrangian_multiplier | 0.000648    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.26        |
|    n_updates             | 8240        |
|    policy_gradient_loss  | 0.00675     |
|    std                   | 0.297       |
|    value_loss            | 2.06        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.2         |
| reward                   | -0.3333741  |
| rollout/                 |             |
|    ep_len_mean           | 51.8        |
|    ep_rew_mean           | -26         |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 42          |
|    time_elapsed          | 1281        |
|    total_timesteps       | 1691648     |
| train/                   |             |
|    approx_kl             | 0.030960934 |
|    clip_fraction         | 0.171       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.44        |
|    cost_value_loss       | 3.85        |
|    cost_values           | 2.18        |
|    entropy               | 0.25        |
|    entropy_loss          | 0.252       |
|    explained_variance    | 0.931       |
|    lagrangian_multiplier | 0.00135     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.74        |
|    n_updates             | 8250        |
|    policy_gradient_loss  | 0.00197     |
|    std                   | 0.297       |
|    value_loss            | 2.7         |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.7655791  |
| rollout/                 |             |
|    ep_len_mean           | 49.5        |
|    ep_rew_mean           | -25.1       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 43          |
|    time_elapsed          | 1311        |
|    total_timesteps       | 1693696     |
| train/                   |             |
|    approx_kl             | 0.027614247 |
|    clip_fraction         | 0.188       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.78        |
|    cost_value_loss       | 5.26        |
|    cost_values           | 2.16        |
|    entropy               | 0.252       |
|    entropy_loss          | 0.251       |
|    explained_variance    | 0.919       |
|    lagrangian_multiplier | 0.00158     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.29        |
|    n_updates             | 8260        |
|    policy_gradient_loss  | 0.0057      |
|    std                   | 0.297       |
|    value_loss            | 2.73        |
------------------------------------------
------------------------------------------
| avg_speed                | 6           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6           |
| reward                   | -0.39632934 |
| rollout/                 |             |
|    ep_len_mean           | 49.2        |
|    ep_rew_mean           | -25         |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 44          |
|    time_elapsed          | 1345        |
|    total_timesteps       | 1695744     |
| train/                   |             |
|    approx_kl             | 0.012726607 |
|    clip_fraction         | 0.174       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.53        |
|    cost_value_loss       | 4.07        |
|    cost_values           | 2.13        |
|    entropy               | 0.253       |
|    entropy_loss          | 0.253       |
|    explained_variance    | 0.952       |
|    lagrangian_multiplier | 0.000763    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.7         |
|    n_updates             | 8270        |
|    policy_gradient_loss  | 0.00729     |
|    std                   | 0.297       |
|    value_loss            | 1.85        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.9268822  |
| rollout/                 |             |
|    ep_len_mean           | 50.8        |
|    ep_rew_mean           | -25.4       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 45          |
|    time_elapsed          | 1380        |
|    total_timesteps       | 1697792     |
| train/                   |             |
|    approx_kl             | 0.023775844 |
|    clip_fraction         | 0.188       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.71        |
|    cost_value_loss       | 4.82        |
|    cost_values           | 2.13        |
|    entropy               | 0.259       |
|    entropy_loss          | 0.256       |
|    explained_variance    | 0.94        |
|    lagrangian_multiplier | 0.00113     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.95        |
|    n_updates             | 8280        |
|    policy_gradient_loss  | 0.00372     |
|    std                   | 0.296       |
|    value_loss            | 2.18        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.38        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.38        |
| reward                   | -0.25789207 |
| rollout/                 |             |
|    ep_len_mean           | 51.8        |
|    ep_rew_mean           | -25.1       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 46          |
|    time_elapsed          | 1417        |
|    total_timesteps       | 1699840     |
| train/                   |             |
|    approx_kl             | 0.020644488 |
|    clip_fraction         | 0.171       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.71        |
|    cost_value_loss       | 5.15        |
|    cost_values           | 2.14        |
|    entropy               | 0.268       |
|    entropy_loss          | 0.264       |
|    explained_variance    | 0.95        |
|    lagrangian_multiplier | 0.000587    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.16        |
|    n_updates             | 8290        |
|    policy_gradient_loss  | 0.00667     |
|    std                   | 0.295       |
|    value_loss            | 1.88        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.2         |
| reward                   | -0.4996765  |
| rollout/                 |             |
|    ep_len_mean           | 51.1        |
|    ep_rew_mean           | -25         |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 47          |
|    time_elapsed          | 1451        |
|    total_timesteps       | 1701888     |
| train/                   |             |
|    approx_kl             | 0.011171376 |
|    clip_fraction         | 0.161       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.6         |
|    cost_value_loss       | 5           |
|    cost_values           | 2.09        |
|    entropy               | 0.277       |
|    entropy_loss          | 0.272       |
|    explained_variance    | 0.954       |
|    lagrangian_multiplier | 0.00078     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.97        |
|    n_updates             | 8300        |
|    policy_gradient_loss  | 0.00686     |
|    std                   | 0.294       |
|    value_loss            | 1.66        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.18652949 |
| rollout/                 |             |
|    ep_len_mean           | 50.2        |
|    ep_rew_mean           | -25.1       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 48          |
|    time_elapsed          | 1476        |
|    total_timesteps       | 1703936     |
| train/                   |             |
|    approx_kl             | 0.015990347 |
|    clip_fraction         | 0.194       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.42        |
|    cost_value_loss       | 4.17        |
|    cost_values           | 2.06        |
|    entropy               | 0.285       |
|    entropy_loss          | 0.282       |
|    explained_variance    | 0.95        |
|    lagrangian_multiplier | 0.000663    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.03        |
|    n_updates             | 8310        |
|    policy_gradient_loss  | 0.00629     |
|    std                   | 0.292       |
|    value_loss            | 1.92        |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.8        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.8        |
| reward                   | -0.657517  |
| rollout/                 |            |
|    ep_len_mean           | 49.9       |
|    ep_rew_mean           | -25.2      |
| time/                    |            |
|    fps                   | 66         |
|    iterations            | 49         |
|    time_elapsed          | 1500       |
|    total_timesteps       | 1705984    |
| train/                   |            |
|    approx_kl             | 0.03120912 |
|    clip_fraction         | 0.144      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.38       |
|    cost_value_loss       | 4.04       |
|    cost_values           | 2.02       |
|    entropy               | 0.29       |
|    entropy_loss          | 0.288      |
|    explained_variance    | 0.95       |
|    lagrangian_multiplier | 0.00213    |
|    learning_rate         | 0.0003     |
|    loss                  | 2.43       |
|    n_updates             | 8320       |
|    policy_gradient_loss  | 0.00373    |
|    std                   | 0.291      |
|    value_loss            | 1.9        |
-----------------------------------------
Directory already exists: tests/PPOL_New/models/ent-coefficient-ppol/1vjpjg9h
-----------------------------------
| avg_speed          | 7.91       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 7.91       |
| reward             | -0.1949646 |
| rollout/           |            |
|    ep_len_mean     | 50.5       |
|    ep_rew_mean     | -25.2      |
| time/              |            |
|    fps             | 90         |
|    iterations      | 1          |
|    time_elapsed    | 22         |
|    total_timesteps | 1708032    |
-----------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.65700036 |
| rollout/                 |             |
|    ep_len_mean           | 50.3        |
|    ep_rew_mean           | -25.6       |
| time/                    |             |
|    fps                   | 78          |
|    iterations            | 2           |
|    time_elapsed          | 51          |
|    total_timesteps       | 1710080     |
| train/                   |             |
|    approx_kl             | 0.031652015 |
|    clip_fraction         | 0.163       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.35        |
|    cost_value_loss       | 4.11        |
|    cost_values           | 2.01        |
|    entropy               | 0.299       |
|    entropy_loss          | 0.294       |
|    explained_variance    | 0.954       |
|    lagrangian_multiplier | 0.00187     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.62        |
|    n_updates             | 8340        |
|    policy_gradient_loss  | 0.00588     |
|    std                   | 0.29        |
|    value_loss            | 1.82        |
------------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.6804766  |
| rollout/                 |             |
|    ep_len_mean           | 51.1        |
|    ep_rew_mean           | -26.1       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 3           |
|    time_elapsed          | 91          |
|    total_timesteps       | 1712128     |
| train/                   |             |
|    approx_kl             | 0.027846605 |
|    clip_fraction         | 0.19        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.43        |
|    cost_value_loss       | 4.26        |
|    cost_values           | 2.01        |
|    entropy               | 0.298       |
|    entropy_loss          | 0.299       |
|    explained_variance    | 0.959       |
|    lagrangian_multiplier | 0.00185     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.52        |
|    n_updates             | 8350        |
|    policy_gradient_loss  | 0.00766     |
|    std                   | 0.291       |
|    value_loss            | 1.73        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 1           |
| max_speed                | 8           |
| reward                   | -0.10263183 |
| rollout/                 |             |
|    ep_len_mean           | 49.9        |
|    ep_rew_mean           | -25.5       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 4           |
|    time_elapsed          | 126         |
|    total_timesteps       | 1714176     |
| train/                   |             |
|    approx_kl             | 0.014592059 |
|    clip_fraction         | 0.15        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.39        |
|    cost_value_loss       | 4.15        |
|    cost_values           | 2.01        |
|    entropy               | 0.298       |
|    entropy_loss          | 0.298       |
|    explained_variance    | 0.953       |
|    lagrangian_multiplier | 0.000848    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.91        |
|    n_updates             | 8360        |
|    policy_gradient_loss  | 0.00661     |
|    std                   | 0.292       |
|    value_loss            | 1.94        |
------------------------------------------
-----------------------------------------
| avg_speed                | 1.8        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 1.8        |
| reward                   | -0.850402  |
| rollout/                 |            |
|    ep_len_mean           | 50.1       |
|    ep_rew_mean           | -25.7      |
| time/                    |            |
|    fps                   | 63         |
|    iterations            | 5          |
|    time_elapsed          | 162        |
|    total_timesteps       | 1716224    |
| train/                   |            |
|    approx_kl             | 0.00675409 |
|    clip_fraction         | 0.133      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.56       |
|    cost_value_loss       | 4.85       |
|    cost_values           | 2.02       |
|    entropy               | 0.301      |
|    entropy_loss          | 0.299      |
|    explained_variance    | 0.95       |
|    lagrangian_multiplier | 0.00115    |
|    learning_rate         | 0.0003     |
|    loss                  | 2.92       |
|    n_updates             | 8370       |
|    policy_gradient_loss  | 0.00159    |
|    std                   | 0.292      |
|    value_loss            | 1.96       |
-----------------------------------------
------------------------------------------
| avg_speed                | 5.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.6         |
| reward                   | -0.34266263 |
| rollout/                 |             |
|    ep_len_mean           | 48.8        |
|    ep_rew_mean           | -25.2       |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 6           |
|    time_elapsed          | 199         |
|    total_timesteps       | 1718272     |
| train/                   |             |
|    approx_kl             | 0.019920684 |
|    clip_fraction         | 0.157       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.51        |
|    cost_value_loss       | 4.68        |
|    cost_values           | 2.02        |
|    entropy               | 0.304       |
|    entropy_loss          | 0.303       |
|    explained_variance    | 0.958       |
|    lagrangian_multiplier | 0.00125     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.67        |
|    n_updates             | 8380        |
|    policy_gradient_loss  | 0.00301     |
|    std                   | 0.293       |
|    value_loss            | 1.62        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.8         |
| reward                   | -0.2066063  |
| rollout/                 |             |
|    ep_len_mean           | 47          |
|    ep_rew_mean           | -25         |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 7           |
|    time_elapsed          | 234         |
|    total_timesteps       | 1720320     |
| train/                   |             |
|    approx_kl             | 0.013356596 |
|    clip_fraction         | 0.151       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.25        |
|    cost_value_loss       | 3.62        |
|    cost_values           | 2.01        |
|    entropy               | 0.314       |
|    entropy_loss          | 0.309       |
|    explained_variance    | 0.967       |
|    lagrangian_multiplier | 0.000817    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.42        |
|    n_updates             | 8390        |
|    policy_gradient_loss  | 0.00257     |
|    std                   | 0.292       |
|    value_loss            | 1.38        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.6         |
| reward                   | -0.5865744  |
| rollout/                 |             |
|    ep_len_mean           | 47.8        |
|    ep_rew_mean           | -25.1       |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 8           |
|    time_elapsed          | 262         |
|    total_timesteps       | 1722368     |
| train/                   |             |
|    approx_kl             | 0.013021638 |
|    clip_fraction         | 0.215       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.4         |
|    cost_value_loss       | 4.06        |
|    cost_values           | 2           |
|    entropy               | 0.313       |
|    entropy_loss          | 0.314       |
|    explained_variance    | 0.969       |
|    lagrangian_multiplier | 0.000976    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.41        |
|    n_updates             | 8400        |
|    policy_gradient_loss  | 0.0027      |
|    std                   | 0.293       |
|    value_loss            | 1.25        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.8         |
| reward                   | -0.31715685 |
| rollout/                 |             |
|    ep_len_mean           | 50.5        |
|    ep_rew_mean           | -25.7       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 9           |
|    time_elapsed          | 287         |
|    total_timesteps       | 1724416     |
| train/                   |             |
|    approx_kl             | 0.016497433 |
|    clip_fraction         | 0.175       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.38        |
|    cost_value_loss       | 4.1         |
|    cost_values           | 2           |
|    entropy               | 0.312       |
|    entropy_loss          | 0.312       |
|    explained_variance    | 0.958       |
|    lagrangian_multiplier | 0.00218     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.43        |
|    n_updates             | 8410        |
|    policy_gradient_loss  | 0.00456     |
|    std                   | 0.293       |
|    value_loss            | 1.64        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.05        |
| reward                   | -0.16563655 |
| rollout/                 |             |
|    ep_len_mean           | 54.1        |
|    ep_rew_mean           | -26.2       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 10          |
|    time_elapsed          | 311         |
|    total_timesteps       | 1726464     |
| train/                   |             |
|    approx_kl             | 0.016200239 |
|    clip_fraction         | 0.19        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.67        |
|    cost_value_loss       | 5.15        |
|    cost_values           | 2.03        |
|    entropy               | 0.308       |
|    entropy_loss          | 0.31        |
|    explained_variance    | 0.913       |
|    lagrangian_multiplier | 0.000979    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.18        |
|    n_updates             | 8420        |
|    policy_gradient_loss  | 0.0103      |
|    std                   | 0.294       |
|    value_loss            | 2.88        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.26294473 |
| rollout/                 |             |
|    ep_len_mean           | 53          |
|    ep_rew_mean           | -25.9       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 11          |
|    time_elapsed          | 337         |
|    total_timesteps       | 1728512     |
| train/                   |             |
|    approx_kl             | 0.013555555 |
|    clip_fraction         | 0.162       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.33        |
|    cost_value_loss       | 4.11        |
|    cost_values           | 2.07        |
|    entropy               | 0.303       |
|    entropy_loss          | 0.306       |
|    explained_variance    | 0.89        |
|    lagrangian_multiplier | 0.00154     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.91        |
|    n_updates             | 8430        |
|    policy_gradient_loss  | 0.00278     |
|    std                   | 0.295       |
|    value_loss            | 3.23        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.8         |
| reward                   | -0.6016546  |
| rollout/                 |             |
|    ep_len_mean           | 49.2        |
|    ep_rew_mean           | -24.7       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 12          |
|    time_elapsed          | 373         |
|    total_timesteps       | 1730560     |
| train/                   |             |
|    approx_kl             | 0.021541154 |
|    clip_fraction         | 0.167       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.35        |
|    cost_value_loss       | 3.97        |
|    cost_values           | 2           |
|    entropy               | 0.316       |
|    entropy_loss          | 0.308       |
|    explained_variance    | 0.94        |
|    lagrangian_multiplier | 0.000906    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.83        |
|    n_updates             | 8440        |
|    policy_gradient_loss  | 0.00942     |
|    std                   | 0.293       |
|    value_loss            | 2.26        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.2         |
| reward                   | -0.5523191  |
| rollout/                 |             |
|    ep_len_mean           | 48.2        |
|    ep_rew_mean           | -25.1       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 13          |
|    time_elapsed          | 406         |
|    total_timesteps       | 1732608     |
| train/                   |             |
|    approx_kl             | 0.014812135 |
|    clip_fraction         | 0.182       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.19        |
|    cost_value_loss       | 3.59        |
|    cost_values           | 1.93        |
|    entropy               | 0.319       |
|    entropy_loss          | 0.318       |
|    explained_variance    | 0.958       |
|    lagrangian_multiplier | 0.000299    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.54        |
|    n_updates             | 8450        |
|    policy_gradient_loss  | 0.0083      |
|    std                   | 0.293       |
|    value_loss            | 1.6         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.34290558 |
| rollout/                 |             |
|    ep_len_mean           | 49.2        |
|    ep_rew_mean           | -25.9       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 14          |
|    time_elapsed          | 440         |
|    total_timesteps       | 1734656     |
| train/                   |             |
|    approx_kl             | 0.015189167 |
|    clip_fraction         | 0.169       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.27        |
|    cost_value_loss       | 3.88        |
|    cost_values           | 1.89        |
|    entropy               | 0.314       |
|    entropy_loss          | 0.317       |
|    explained_variance    | 0.956       |
|    lagrangian_multiplier | 0.00141     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.51        |
|    n_updates             | 8460        |
|    policy_gradient_loss  | 0.00258     |
|    std                   | 0.294       |
|    value_loss            | 1.79        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.7977021  |
| rollout/                 |             |
|    ep_len_mean           | 48.5        |
|    ep_rew_mean           | -25.4       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 15          |
|    time_elapsed          | 477         |
|    total_timesteps       | 1736704     |
| train/                   |             |
|    approx_kl             | 0.026886415 |
|    clip_fraction         | 0.168       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.17        |
|    cost_value_loss       | 3.71        |
|    cost_values           | 1.96        |
|    entropy               | 0.308       |
|    entropy_loss          | 0.311       |
|    explained_variance    | 0.961       |
|    lagrangian_multiplier | 0.00135     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.4         |
|    n_updates             | 8470        |
|    policy_gradient_loss  | 0.000546    |
|    std                   | 0.296       |
|    value_loss            | 1.64        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.7168824  |
| rollout/                 |             |
|    ep_len_mean           | 49.8        |
|    ep_rew_mean           | -25.6       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 16          |
|    time_elapsed          | 513         |
|    total_timesteps       | 1738752     |
| train/                   |             |
|    approx_kl             | 0.025615081 |
|    clip_fraction         | 0.187       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.25        |
|    cost_value_loss       | 4           |
|    cost_values           | 1.94        |
|    entropy               | 0.303       |
|    entropy_loss          | 0.305       |
|    explained_variance    | 0.959       |
|    lagrangian_multiplier | 0.00072     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.69        |
|    n_updates             | 8480        |
|    policy_gradient_loss  | 0.0116      |
|    std                   | 0.297       |
|    value_loss            | 1.61        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.28909326 |
| rollout/                 |             |
|    ep_len_mean           | 48.9        |
|    ep_rew_mean           | -25.6       |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 17          |
|    time_elapsed          | 554         |
|    total_timesteps       | 1740800     |
| train/                   |             |
|    approx_kl             | 0.01065829  |
|    clip_fraction         | 0.138       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.44        |
|    cost_value_loss       | 4.38        |
|    cost_values           | 1.98        |
|    entropy               | 0.313       |
|    entropy_loss          | 0.307       |
|    explained_variance    | 0.952       |
|    lagrangian_multiplier | 0.000981    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.5         |
|    n_updates             | 8490        |
|    policy_gradient_loss  | 0.00312     |
|    std                   | 0.296       |
|    value_loss            | 1.74        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.8         |
| reward                   | -0.32294977 |
| rollout/                 |             |
|    ep_len_mean           | 50.8        |
|    ep_rew_mean           | -26.1       |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 18          |
|    time_elapsed          | 590         |
|    total_timesteps       | 1742848     |
| train/                   |             |
|    approx_kl             | 0.010918947 |
|    clip_fraction         | 0.15        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.42        |
|    cost_value_loss       | 4.34        |
|    cost_values           | 2           |
|    entropy               | 0.315       |
|    entropy_loss          | 0.315       |
|    explained_variance    | 0.956       |
|    lagrangian_multiplier | 0.000663    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.89        |
|    n_updates             | 8500        |
|    policy_gradient_loss  | 0.00483     |
|    std                   | 0.295       |
|    value_loss            | 1.72        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.3344926  |
| rollout/                 |             |
|    ep_len_mean           | 51.5        |
|    ep_rew_mean           | -25.8       |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 19          |
|    time_elapsed          | 627         |
|    total_timesteps       | 1744896     |
| train/                   |             |
|    approx_kl             | 0.020880505 |
|    clip_fraction         | 0.171       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.67        |
|    cost_value_loss       | 4.92        |
|    cost_values           | 2.03        |
|    entropy               | 0.321       |
|    entropy_loss          | 0.318       |
|    explained_variance    | 0.956       |
|    lagrangian_multiplier | 0.00363     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.52        |
|    n_updates             | 8510        |
|    policy_gradient_loss  | 0.0033      |
|    std                   | 0.295       |
|    value_loss            | 1.72        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.2         |
| reward                   | -0.62494606 |
| rollout/                 |             |
|    ep_len_mean           | 50          |
|    ep_rew_mean           | -25         |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 20          |
|    time_elapsed          | 658         |
|    total_timesteps       | 1746944     |
| train/                   |             |
|    approx_kl             | 0.020520594 |
|    clip_fraction         | 0.19        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.83        |
|    cost_value_loss       | 5.67        |
|    cost_values           | 2.04        |
|    entropy               | 0.324       |
|    entropy_loss          | 0.323       |
|    explained_variance    | 0.947       |
|    lagrangian_multiplier | 0.00158     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.07        |
|    n_updates             | 8520        |
|    policy_gradient_loss  | 0.00438     |
|    std                   | 0.295       |
|    value_loss            | 1.89        |
------------------------------------------
------------------------------------------
| avg_speed                | 3           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3           |
| reward                   | -0.8671699  |
| rollout/                 |             |
|    ep_len_mean           | 48.5        |
|    ep_rew_mean           | -24.7       |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 21          |
|    time_elapsed          | 694         |
|    total_timesteps       | 1748992     |
| train/                   |             |
|    approx_kl             | 0.027824976 |
|    clip_fraction         | 0.242       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.31        |
|    cost_value_loss       | 4.14        |
|    cost_values           | 1.99        |
|    entropy               | 0.319       |
|    entropy_loss          | 0.323       |
|    explained_variance    | 0.961       |
|    lagrangian_multiplier | 0.000165    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.75        |
|    n_updates             | 8530        |
|    policy_gradient_loss  | 0.0132      |
|    std                   | 0.296       |
|    value_loss            | 1.54        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.7458744  |
| rollout/                 |             |
|    ep_len_mean           | 48.9        |
|    ep_rew_mean           | -25         |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 22          |
|    time_elapsed          | 724         |
|    total_timesteps       | 1751040     |
| train/                   |             |
|    approx_kl             | 0.019836769 |
|    clip_fraction         | 0.157       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.57        |
|    cost_value_loss       | 4.88        |
|    cost_values           | 1.98        |
|    entropy               | 0.325       |
|    entropy_loss          | 0.321       |
|    explained_variance    | 0.965       |
|    lagrangian_multiplier | 0.00134     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.63        |
|    n_updates             | 8540        |
|    policy_gradient_loss  | 0.00546     |
|    std                   | 0.295       |
|    value_loss            | 1.33        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.34372872 |
| rollout/                 |             |
|    ep_len_mean           | 50.1        |
|    ep_rew_mean           | -25.6       |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 23          |
|    time_elapsed          | 748         |
|    total_timesteps       | 1753088     |
| train/                   |             |
|    approx_kl             | 0.023979332 |
|    clip_fraction         | 0.189       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.62        |
|    cost_value_loss       | 5.06        |
|    cost_values           | 1.96        |
|    entropy               | 0.329       |
|    entropy_loss          | 0.327       |
|    explained_variance    | 0.969       |
|    lagrangian_multiplier | 0.0023      |
|    learning_rate         | 0.0003      |
|    loss                  | 2.55        |
|    n_updates             | 8550        |
|    policy_gradient_loss  | 0.00311     |
|    std                   | 0.295       |
|    value_loss            | 1.28        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.8         |
| reward                   | -0.69074506 |
| rollout/                 |             |
|    ep_len_mean           | 51.7        |
|    ep_rew_mean           | -26.1       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 24          |
|    time_elapsed          | 771         |
|    total_timesteps       | 1755136     |
| train/                   |             |
|    approx_kl             | 0.013529046 |
|    clip_fraction         | 0.193       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.63        |
|    cost_value_loss       | 5.15        |
|    cost_values           | 1.97        |
|    entropy               | 0.334       |
|    entropy_loss          | 0.331       |
|    explained_variance    | 0.964       |
|    lagrangian_multiplier | 0.00213     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.6         |
|    n_updates             | 8560        |
|    policy_gradient_loss  | 0.00683     |
|    std                   | 0.296       |
|    value_loss            | 1.39        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.8         |
| reward                   | -0.28909466 |
| rollout/                 |             |
|    ep_len_mean           | 50.1        |
|    ep_rew_mean           | -25.4       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 25          |
|    time_elapsed          | 795         |
|    total_timesteps       | 1757184     |
| train/                   |             |
|    approx_kl             | 0.029072182 |
|    clip_fraction         | 0.153       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.62        |
|    cost_value_loss       | 5.1         |
|    cost_values           | 2           |
|    entropy               | 0.334       |
|    entropy_loss          | 0.335       |
|    explained_variance    | 0.946       |
|    lagrangian_multiplier | 0.000483    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.5         |
|    n_updates             | 8570        |
|    policy_gradient_loss  | 0.003       |
|    std                   | 0.296       |
|    value_loss            | 2.15        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.37716988 |
| rollout/                 |             |
|    ep_len_mean           | 49.9        |
|    ep_rew_mean           | -25.7       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 26          |
|    time_elapsed          | 823         |
|    total_timesteps       | 1759232     |
| train/                   |             |
|    approx_kl             | 0.009547895 |
|    clip_fraction         | 0.165       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.53        |
|    cost_value_loss       | 4.55        |
|    cost_values           | 2.03        |
|    entropy               | 0.332       |
|    entropy_loss          | 0.333       |
|    explained_variance    | 0.959       |
|    lagrangian_multiplier | 0.000217    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.06        |
|    n_updates             | 8580        |
|    policy_gradient_loss  | 0.007       |
|    std                   | 0.297       |
|    value_loss            | 1.67        |
------------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.78972846 |
| rollout/                 |             |
|    ep_len_mean           | 48.9        |
|    ep_rew_mean           | -25.2       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 27          |
|    time_elapsed          | 854         |
|    total_timesteps       | 1761280     |
| train/                   |             |
|    approx_kl             | 0.026104819 |
|    clip_fraction         | 0.219       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.54        |
|    cost_value_loss       | 4.88        |
|    cost_values           | 1.97        |
|    entropy               | 0.333       |
|    entropy_loss          | 0.332       |
|    explained_variance    | 0.958       |
|    lagrangian_multiplier | 0.00153     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.73        |
|    n_updates             | 8590        |
|    policy_gradient_loss  | 0.0105      |
|    std                   | 0.297       |
|    value_loss            | 1.67        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.4         |
| reward                   | -0.5842617  |
| rollout/                 |             |
|    ep_len_mean           | 48.9        |
|    ep_rew_mean           | -24.9       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 28          |
|    time_elapsed          | 883         |
|    total_timesteps       | 1763328     |
| train/                   |             |
|    approx_kl             | 0.030793073 |
|    clip_fraction         | 0.162       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.57        |
|    cost_value_loss       | 5.1         |
|    cost_values           | 1.94        |
|    entropy               | 0.345       |
|    entropy_loss          | 0.339       |
|    explained_variance    | 0.956       |
|    lagrangian_multiplier | 0.00252     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.68        |
|    n_updates             | 8600        |
|    policy_gradient_loss  | 0.00356     |
|    std                   | 0.295       |
|    value_loss            | 1.58        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.61        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.61        |
| reward                   | -0.40095887 |
| rollout/                 |             |
|    ep_len_mean           | 47.7        |
|    ep_rew_mean           | -25.3       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 29          |
|    time_elapsed          | 915         |
|    total_timesteps       | 1765376     |
| train/                   |             |
|    approx_kl             | 0.029615603 |
|    clip_fraction         | 0.244       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.4         |
|    cost_value_loss       | 4.6         |
|    cost_values           | 1.86        |
|    entropy               | 0.354       |
|    entropy_loss          | 0.349       |
|    explained_variance    | 0.973       |
|    lagrangian_multiplier | 0.000306    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.58        |
|    n_updates             | 8610        |
|    policy_gradient_loss  | 0.00942     |
|    std                   | 0.293       |
|    value_loss            | 1.05        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.94886696 |
| rollout/                 |             |
|    ep_len_mean           | 46.7        |
|    ep_rew_mean           | -25.1       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 30          |
|    time_elapsed          | 946         |
|    total_timesteps       | 1767424     |
| train/                   |             |
|    approx_kl             | 0.033316925 |
|    clip_fraction         | 0.181       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.08        |
|    cost_value_loss       | 3.35        |
|    cost_values           | 1.86        |
|    entropy               | 0.361       |
|    entropy_loss          | 0.358       |
|    explained_variance    | 0.968       |
|    lagrangian_multiplier | 0.000921    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.23        |
|    n_updates             | 8620        |
|    policy_gradient_loss  | 0.0093      |
|    std                   | 0.292       |
|    value_loss            | 1.4         |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.7629622  |
| rollout/                 |             |
|    ep_len_mean           | 48.5        |
|    ep_rew_mean           | -25.1       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 31          |
|    time_elapsed          | 979         |
|    total_timesteps       | 1769472     |
| train/                   |             |
|    approx_kl             | 0.022488803 |
|    clip_fraction         | 0.199       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.08        |
|    cost_value_loss       | 3.67        |
|    cost_values           | 1.81        |
|    entropy               | 0.369       |
|    entropy_loss          | 0.365       |
|    explained_variance    | 0.955       |
|    lagrangian_multiplier | 0.0012      |
|    learning_rate         | 0.0003      |
|    loss                  | 2.26        |
|    n_updates             | 8630        |
|    policy_gradient_loss  | 0.00782     |
|    std                   | 0.291       |
|    value_loss            | 1.64        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.6140705  |
| rollout/                 |             |
|    ep_len_mean           | 49.8        |
|    ep_rew_mean           | -25.7       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 32          |
|    time_elapsed          | 1009        |
|    total_timesteps       | 1771520     |
| train/                   |             |
|    approx_kl             | 0.023060525 |
|    clip_fraction         | 0.156       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.5         |
|    cost_value_loss       | 5.06        |
|    cost_values           | 1.84        |
|    entropy               | 0.37        |
|    entropy_loss          | 0.371       |
|    explained_variance    | 0.949       |
|    lagrangian_multiplier | 0.00222     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.52        |
|    n_updates             | 8640        |
|    policy_gradient_loss  | 0.00592     |
|    std                   | 0.291       |
|    value_loss            | 1.84        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.9053323  |
| rollout/                 |             |
|    ep_len_mean           | 50.4        |
|    ep_rew_mean           | -25.6       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 33          |
|    time_elapsed          | 1038        |
|    total_timesteps       | 1773568     |
| train/                   |             |
|    approx_kl             | 0.015491027 |
|    clip_fraction         | 0.185       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.07        |
|    cost_value_loss       | 3.3         |
|    cost_values           | 1.86        |
|    entropy               | 0.375       |
|    entropy_loss          | 0.372       |
|    explained_variance    | 0.945       |
|    lagrangian_multiplier | 0.00106     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.29        |
|    n_updates             | 8650        |
|    policy_gradient_loss  | 0.00786     |
|    std                   | 0.291       |
|    value_loss            | 2.1         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.35536394 |
| rollout/                 |             |
|    ep_len_mean           | 49.7        |
|    ep_rew_mean           | -25.6       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 34          |
|    time_elapsed          | 1062        |
|    total_timesteps       | 1775616     |
| train/                   |             |
|    approx_kl             | 0.0214037   |
|    clip_fraction         | 0.158       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.49        |
|    cost_value_loss       | 4.75        |
|    cost_values           | 1.87        |
|    entropy               | 0.379       |
|    entropy_loss          | 0.378       |
|    explained_variance    | 0.947       |
|    lagrangian_multiplier | 0.00175     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.6         |
|    n_updates             | 8660        |
|    policy_gradient_loss  | 0.00488     |
|    std                   | 0.29        |
|    value_loss            | 1.96        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.52218103 |
| rollout/                 |             |
|    ep_len_mean           | 46.5        |
|    ep_rew_mean           | -24.5       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 35          |
|    time_elapsed          | 1089        |
|    total_timesteps       | 1777664     |
| train/                   |             |
|    approx_kl             | 0.020680701 |
|    clip_fraction         | 0.193       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.27        |
|    cost_value_loss       | 4.2         |
|    cost_values           | 1.86        |
|    entropy               | 0.378       |
|    entropy_loss          | 0.378       |
|    explained_variance    | 0.964       |
|    lagrangian_multiplier | 0.000711    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.7         |
|    n_updates             | 8670        |
|    policy_gradient_loss  | 0.00843     |
|    std                   | 0.291       |
|    value_loss            | 1.41        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.3300209  |
| rollout/                 |             |
|    ep_len_mean           | 47.4        |
|    ep_rew_mean           | -24.6       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 36          |
|    time_elapsed          | 1122        |
|    total_timesteps       | 1779712     |
| train/                   |             |
|    approx_kl             | 0.027158864 |
|    clip_fraction         | 0.178       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.26        |
|    cost_value_loss       | 4.08        |
|    cost_values           | 1.79        |
|    entropy               | 0.375       |
|    entropy_loss          | 0.377       |
|    explained_variance    | 0.968       |
|    lagrangian_multiplier | 0.00206     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.26        |
|    n_updates             | 8680        |
|    policy_gradient_loss  | 0.00685     |
|    std                   | 0.292       |
|    value_loss            | 1.26        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.14400816 |
| rollout/                 |             |
|    ep_len_mean           | 49.3        |
|    ep_rew_mean           | -25.4       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 37          |
|    time_elapsed          | 1156        |
|    total_timesteps       | 1781760     |
| train/                   |             |
|    approx_kl             | 0.018371418 |
|    clip_fraction         | 0.154       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.35        |
|    cost_value_loss       | 4.68        |
|    cost_values           | 1.77        |
|    entropy               | 0.383       |
|    entropy_loss          | 0.378       |
|    explained_variance    | 0.952       |
|    lagrangian_multiplier | 0.0012      |
|    learning_rate         | 0.0003      |
|    loss                  | 2.81        |
|    n_updates             | 8690        |
|    policy_gradient_loss  | 0.00535     |
|    std                   | 0.292       |
|    value_loss            | 1.74        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.6789227  |
| rollout/                 |             |
|    ep_len_mean           | 48.6        |
|    ep_rew_mean           | -25         |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 38          |
|    time_elapsed          | 1191        |
|    total_timesteps       | 1783808     |
| train/                   |             |
|    approx_kl             | 0.013125787 |
|    clip_fraction         | 0.134       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.35        |
|    cost_value_loss       | 4.71        |
|    cost_values           | 1.84        |
|    entropy               | 0.394       |
|    entropy_loss          | 0.389       |
|    explained_variance    | 0.953       |
|    lagrangian_multiplier | 0.000402    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.81        |
|    n_updates             | 8700        |
|    policy_gradient_loss  | 0.00556     |
|    std                   | 0.291       |
|    value_loss            | 1.69        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.5881758  |
| rollout/                 |             |
|    ep_len_mean           | 47.5        |
|    ep_rew_mean           | -24.9       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 39          |
|    time_elapsed          | 1226        |
|    total_timesteps       | 1785856     |
| train/                   |             |
|    approx_kl             | 0.015420067 |
|    clip_fraction         | 0.179       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.16        |
|    cost_value_loss       | 4           |
|    cost_values           | 1.8         |
|    entropy               | 0.399       |
|    entropy_loss          | 0.397       |
|    explained_variance    | 0.954       |
|    lagrangian_multiplier | 1.55e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.8         |
|    n_updates             | 8710        |
|    policy_gradient_loss  | 0.00451     |
|    std                   | 0.291       |
|    value_loss            | 1.58        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.6         |
| reward                   | -0.4205687  |
| rollout/                 |             |
|    ep_len_mean           | 47          |
|    ep_rew_mean           | -24.6       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 40          |
|    time_elapsed          | 1261        |
|    total_timesteps       | 1787904     |
| train/                   |             |
|    approx_kl             | 0.010810747 |
|    clip_fraction         | 0.125       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.15        |
|    cost_value_loss       | 4.07        |
|    cost_values           | 1.77        |
|    entropy               | 0.403       |
|    entropy_loss          | 0.401       |
|    explained_variance    | 0.95        |
|    lagrangian_multiplier | 0.000293    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.59        |
|    n_updates             | 8720        |
|    policy_gradient_loss  | 0.00427     |
|    std                   | 0.291       |
|    value_loss            | 1.85        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 1           |
| max_speed                | 8.01        |
| reward                   | -0.09473856 |
| rollout/                 |             |
|    ep_len_mean           | 45.9        |
|    ep_rew_mean           | -24.3       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 41          |
|    time_elapsed          | 1299        |
|    total_timesteps       | 1789952     |
| train/                   |             |
|    approx_kl             | 0.024138406 |
|    clip_fraction         | 0.221       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.23        |
|    cost_value_loss       | 4.18        |
|    cost_values           | 1.85        |
|    entropy               | 0.403       |
|    entropy_loss          | 0.403       |
|    explained_variance    | 0.957       |
|    lagrangian_multiplier | 0.00162     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.52        |
|    n_updates             | 8730        |
|    policy_gradient_loss  | 0.00873     |
|    std                   | 0.292       |
|    value_loss            | 1.65        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.8         |
| reward                   | -0.9356585  |
| rollout/                 |             |
|    ep_len_mean           | 46.7        |
|    ep_rew_mean           | -24.4       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 42          |
|    time_elapsed          | 1337        |
|    total_timesteps       | 1792000     |
| train/                   |             |
|    approx_kl             | 0.019230561 |
|    clip_fraction         | 0.2         |
|    clip_range            | 0.2         |
|    cost_returns          | 2.87        |
|    cost_value_loss       | 2.69        |
|    cost_values           | 1.8         |
|    entropy               | 0.403       |
|    entropy_loss          | 0.404       |
|    explained_variance    | 0.964       |
|    lagrangian_multiplier | 0.000771    |
|    learning_rate         | 0.0003      |
|    loss                  | 1.86        |
|    n_updates             | 8740        |
|    policy_gradient_loss  | 0.00423     |
|    std                   | 0.292       |
|    value_loss            | 1.36        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 1            |
| max_speed                | 8.04         |
| reward                   | -0.114033304 |
| rollout/                 |              |
|    ep_len_mean           | 46.8         |
|    ep_rew_mean           | -24.6        |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 43           |
|    time_elapsed          | 1373         |
|    total_timesteps       | 1794048      |
| train/                   |              |
|    approx_kl             | 0.02075893   |
|    clip_fraction         | 0.18         |
|    clip_range            | 0.2          |
|    cost_returns          | 3.23         |
|    cost_value_loss       | 4.2          |
|    cost_values           | 1.76         |
|    entropy               | 0.408        |
|    entropy_loss          | 0.405        |
|    explained_variance    | 0.963        |
|    lagrangian_multiplier | 0.000566     |
|    learning_rate         | 0.0003       |
|    loss                  | 2.45         |
|    n_updates             | 8750         |
|    policy_gradient_loss  | 0.00189      |
|    std                   | 0.292        |
|    value_loss            | 1.39         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 5          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 5          |
| reward                   | -0.54463   |
| rollout/                 |            |
|    ep_len_mean           | 45.2       |
|    ep_rew_mean           | -23.9      |
| time/                    |            |
|    fps                   | 63         |
|    iterations            | 44         |
|    time_elapsed          | 1408       |
|    total_timesteps       | 1796096    |
| train/                   |            |
|    approx_kl             | 0.03046593 |
|    clip_fraction         | 0.214      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.09       |
|    cost_value_loss       | 3.52       |
|    cost_values           | 1.77       |
|    entropy               | 0.406      |
|    entropy_loss          | 0.408      |
|    explained_variance    | 0.952      |
|    lagrangian_multiplier | 0.00137    |
|    learning_rate         | 0.0003     |
|    loss                  | 2.25       |
|    n_updates             | 8760       |
|    policy_gradient_loss  | 0.0126     |
|    std                   | 0.292      |
|    value_loss            | 1.7        |
-----------------------------------------
------------------------------------------
| avg_speed                | 2.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.8         |
| reward                   | -0.8194247  |
| rollout/                 |             |
|    ep_len_mean           | 45.8        |
|    ep_rew_mean           | -23.5       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 45          |
|    time_elapsed          | 1442        |
|    total_timesteps       | 1798144     |
| train/                   |             |
|    approx_kl             | 0.019788224 |
|    clip_fraction         | 0.171       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.16        |
|    cost_value_loss       | 3.82        |
|    cost_values           | 1.74        |
|    entropy               | 0.411       |
|    entropy_loss          | 0.408       |
|    explained_variance    | 0.972       |
|    lagrangian_multiplier | 1.01e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.31        |
|    n_updates             | 8770        |
|    policy_gradient_loss  | 0.00759     |
|    std                   | 0.291       |
|    value_loss            | 1.01        |
------------------------------------------
------------------------------------------
| avg_speed                | 6           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6           |
| reward                   | -0.49496102 |
| rollout/                 |             |
|    ep_len_mean           | 45.7        |
|    ep_rew_mean           | -23.9       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 46          |
|    time_elapsed          | 1472        |
|    total_timesteps       | 1800192     |
| train/                   |             |
|    approx_kl             | 0.035448335 |
|    clip_fraction         | 0.194       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.92        |
|    cost_value_loss       | 3.16        |
|    cost_values           | 1.76        |
|    entropy               | 0.415       |
|    entropy_loss          | 0.413       |
|    explained_variance    | 0.931       |
|    lagrangian_multiplier | 0.000507    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.52        |
|    n_updates             | 8780        |
|    policy_gradient_loss  | 0.0119      |
|    std                   | 0.29        |
|    value_loss            | 2.29        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.37414426 |
| rollout/                 |             |
|    ep_len_mean           | 44.4        |
|    ep_rew_mean           | -23.4       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 47          |
|    time_elapsed          | 1501        |
|    total_timesteps       | 1802240     |
| train/                   |             |
|    approx_kl             | 0.014249034 |
|    clip_fraction         | 0.187       |
|    clip_range            | 0.2         |
|    cost_returns          | 3           |
|    cost_value_loss       | 2.96        |
|    cost_values           | 1.75        |
|    entropy               | 0.42        |
|    entropy_loss          | 0.418       |
|    explained_variance    | 0.968       |
|    lagrangian_multiplier | 0.000922    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.03        |
|    n_updates             | 8790        |
|    policy_gradient_loss  | 0.0118      |
|    std                   | 0.29        |
|    value_loss            | 1.12        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.34796843 |
| rollout/                 |             |
|    ep_len_mean           | 47.3        |
|    ep_rew_mean           | -24.9       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 48          |
|    time_elapsed          | 1532        |
|    total_timesteps       | 1804288     |
| train/                   |             |
|    approx_kl             | 0.01767904  |
|    clip_fraction         | 0.196       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.88        |
|    cost_value_loss       | 2.96        |
|    cost_values           | 1.67        |
|    entropy               | 0.421       |
|    entropy_loss          | 0.421       |
|    explained_variance    | 0.973       |
|    lagrangian_multiplier | 0.000147    |
|    learning_rate         | 0.0003      |
|    loss                  | 1.87        |
|    n_updates             | 8800        |
|    policy_gradient_loss  | 0.0118      |
|    std                   | 0.29        |
|    value_loss            | 1           |
------------------------------------------
------------------------------------------
| avg_speed                | 6.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.6         |
| reward                   | -0.31433865 |
| rollout/                 |             |
|    ep_len_mean           | 48.7        |
|    ep_rew_mean           | -25.4       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 49          |
|    time_elapsed          | 1562        |
|    total_timesteps       | 1806336     |
| train/                   |             |
|    approx_kl             | 0.019139115 |
|    clip_fraction         | 0.178       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.94        |
|    cost_value_loss       | 3.19        |
|    cost_values           | 1.71        |
|    entropy               | 0.415       |
|    entropy_loss          | 0.419       |
|    explained_variance    | 0.96        |
|    lagrangian_multiplier | 0.000139    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.27        |
|    n_updates             | 8810        |
|    policy_gradient_loss  | 0.000775    |
|    std                   | 0.291       |
|    value_loss            | 1.58        |
------------------------------------------
-----------------------------------
| avg_speed          | 0.6        |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 0.6        |
| reward             | -0.7680628 |
| rollout/           |            |
|    ep_len_mean     | 47.1       |
|    ep_rew_mean     | -24.9      |
| time/              |            |
|    fps             | 67         |
|    iterations      | 1          |
|    time_elapsed    | 30         |
|    total_timesteps | 1808384    |
-----------------------------------
-----------------------------------------
| avg_speed                | 3.2        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 3.2        |
| reward                   | -0.8534313 |
| rollout/                 |            |
|    ep_len_mean           | 45.9       |
|    ep_rew_mean           | -24.3      |
| time/                    |            |
|    fps                   | 64         |
|    iterations            | 2          |
|    time_elapsed          | 63         |
|    total_timesteps       | 1810432    |
| train/                   |            |
|    approx_kl             | 0.03090368 |
|    clip_fraction         | 0.232      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.14       |
|    cost_value_loss       | 3.59       |
|    cost_values           | 1.78       |
|    entropy               | 0.434      |
|    entropy_loss          | 0.43       |
|    explained_variance    | 0.98       |
|    lagrangian_multiplier | 0.00123    |
|    learning_rate         | 0.0003     |
|    loss                  | 2.03       |
|    n_updates             | 8830       |
|    policy_gradient_loss  | 0.00873    |
|    std                   | 0.288      |
|    value_loss            | 0.793      |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.21073109  |
| rollout/                 |              |
|    ep_len_mean           | 44.6         |
|    ep_rew_mean           | -23.6        |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 3            |
|    time_elapsed          | 96           |
|    total_timesteps       | 1812480      |
| train/                   |              |
|    approx_kl             | 0.0092886565 |
|    clip_fraction         | 0.159        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.07         |
|    cost_value_loss       | 3.23         |
|    cost_values           | 1.76         |
|    entropy               | 0.435        |
|    entropy_loss          | 0.436        |
|    explained_variance    | 0.976        |
|    lagrangian_multiplier | 0.000941     |
|    learning_rate         | 0.0003       |
|    loss                  | 1.98         |
|    n_updates             | 8840         |
|    policy_gradient_loss  | 0.00693      |
|    std                   | 0.289        |
|    value_loss            | 0.945        |
-------------------------------------------
-----------------------------------------
| avg_speed                | 3.2        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 3.2        |
| reward                   | -0.8996407 |
| rollout/                 |            |
|    ep_len_mean           | 46         |
|    ep_rew_mean           | -23.6      |
| time/                    |            |
|    fps                   | 63         |
|    iterations            | 4          |
|    time_elapsed          | 129        |
|    total_timesteps       | 1814528    |
| train/                   |            |
|    approx_kl             | 0.06334363 |
|    clip_fraction         | 0.176      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.03       |
|    cost_value_loss       | 3.27       |
|    cost_values           | 1.78       |
|    entropy               | 0.436      |
|    entropy_loss          | 0.435      |
|    explained_variance    | 0.98       |
|    lagrangian_multiplier | 0.0013     |
|    learning_rate         | 0.0003     |
|    loss                  | 2.01       |
|    n_updates             | 8850       |
|    policy_gradient_loss  | 0.00517    |
|    std                   | 0.288      |
|    value_loss            | 0.738      |
-----------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.64929354 |
| rollout/                 |             |
|    ep_len_mean           | 46.3        |
|    ep_rew_mean           | -23.7       |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 5           |
|    time_elapsed          | 165         |
|    total_timesteps       | 1816576     |
| train/                   |             |
|    approx_kl             | 0.016189393 |
|    clip_fraction         | 0.199       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.19        |
|    cost_value_loss       | 3.99        |
|    cost_values           | 1.74        |
|    entropy               | 0.434       |
|    entropy_loss          | 0.436       |
|    explained_variance    | 0.967       |
|    lagrangian_multiplier | 0.0016      |
|    learning_rate         | 0.0003      |
|    loss                  | 2.18        |
|    n_updates             | 8860        |
|    policy_gradient_loss  | 0.00801     |
|    std                   | 0.289       |
|    value_loss            | 1.13        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.5872394  |
| rollout/                 |             |
|    ep_len_mean           | 46          |
|    ep_rew_mean           | -23.7       |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 6           |
|    time_elapsed          | 198         |
|    total_timesteps       | 1818624     |
| train/                   |             |
|    approx_kl             | 0.016124545 |
|    clip_fraction         | 0.16        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.07        |
|    cost_value_loss       | 3.6         |
|    cost_values           | 1.77        |
|    entropy               | 0.428       |
|    entropy_loss          | 0.431       |
|    explained_variance    | 0.959       |
|    lagrangian_multiplier | 0.00107     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.25        |
|    n_updates             | 8870        |
|    policy_gradient_loss  | 0.00352     |
|    std                   | 0.29        |
|    value_loss            | 1.53        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.79        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.79        |
| reward                   | -0.3528821  |
| rollout/                 |             |
|    ep_len_mean           | 45.9        |
|    ep_rew_mean           | -23.8       |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 7           |
|    time_elapsed          | 230         |
|    total_timesteps       | 1820672     |
| train/                   |             |
|    approx_kl             | 0.007905181 |
|    clip_fraction         | 0.185       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.91        |
|    cost_value_loss       | 3.09        |
|    cost_values           | 1.79        |
|    entropy               | 0.425       |
|    entropy_loss          | 0.426       |
|    explained_variance    | 0.922       |
|    lagrangian_multiplier | 0.000347    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.58        |
|    n_updates             | 8880        |
|    policy_gradient_loss  | 0.00721     |
|    std                   | 0.291       |
|    value_loss            | 2.31        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.7415662  |
| rollout/                 |             |
|    ep_len_mean           | 45.5        |
|    ep_rew_mean           | -24.2       |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 8           |
|    time_elapsed          | 264         |
|    total_timesteps       | 1822720     |
| train/                   |             |
|    approx_kl             | 0.017906452 |
|    clip_fraction         | 0.17        |
|    clip_range            | 0.2         |
|    cost_returns          | 2.96        |
|    cost_value_loss       | 3.22        |
|    cost_values           | 1.81        |
|    entropy               | 0.43        |
|    entropy_loss          | 0.427       |
|    explained_variance    | 0.954       |
|    lagrangian_multiplier | 0.00106     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.19        |
|    n_updates             | 8890        |
|    policy_gradient_loss  | 0.00381     |
|    std                   | 0.291       |
|    value_loss            | 1.59        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.6         |
| reward                   | -0.8877328  |
| rollout/                 |             |
|    ep_len_mean           | 45.1        |
|    ep_rew_mean           | -24.7       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 9           |
|    time_elapsed          | 289         |
|    total_timesteps       | 1824768     |
| train/                   |             |
|    approx_kl             | 0.025845025 |
|    clip_fraction         | 0.162       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.02        |
|    cost_value_loss       | 3.48        |
|    cost_values           | 1.75        |
|    entropy               | 0.438       |
|    entropy_loss          | 0.434       |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0.00122     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.21        |
|    n_updates             | 8900        |
|    policy_gradient_loss  | 0.00616     |
|    std                   | 0.291       |
|    value_loss            | 1.12        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.32874337 |
| rollout/                 |             |
|    ep_len_mean           | 46.4        |
|    ep_rew_mean           | -24.5       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 10          |
|    time_elapsed          | 312         |
|    total_timesteps       | 1826816     |
| train/                   |             |
|    approx_kl             | 0.036065545 |
|    clip_fraction         | 0.196       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.93        |
|    cost_value_loss       | 3.12        |
|    cost_values           | 1.73        |
|    entropy               | 0.449       |
|    entropy_loss          | 0.443       |
|    explained_variance    | 0.969       |
|    lagrangian_multiplier | 0.000481    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.11        |
|    n_updates             | 8910        |
|    policy_gradient_loss  | 0.00288     |
|    std                   | 0.289       |
|    value_loss            | 1.23        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.6          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.6          |
| reward                   | -0.28460968  |
| rollout/                 |              |
|    ep_len_mean           | 46.5         |
|    ep_rew_mean           | -23.9        |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 11           |
|    time_elapsed          | 336          |
|    total_timesteps       | 1828864      |
| train/                   |              |
|    approx_kl             | 0.0118455775 |
|    clip_fraction         | 0.197        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.21         |
|    cost_value_loss       | 3.97         |
|    cost_values           | 1.78         |
|    entropy               | 0.449        |
|    entropy_loss          | 0.449        |
|    explained_variance    | 0.947        |
|    lagrangian_multiplier | 0.0028       |
|    learning_rate         | 0.0003       |
|    loss                  | 2.15         |
|    n_updates             | 8920         |
|    policy_gradient_loss  | 0.00897      |
|    std                   | 0.289        |
|    value_loss            | 1.62         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.5676764  |
| rollout/                 |             |
|    ep_len_mean           | 49          |
|    ep_rew_mean           | -25.1       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 12          |
|    time_elapsed          | 366         |
|    total_timesteps       | 1830912     |
| train/                   |             |
|    approx_kl             | 0.014003046 |
|    clip_fraction         | 0.21        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.19        |
|    cost_value_loss       | 3.88        |
|    cost_values           | 1.78        |
|    entropy               | 0.448       |
|    entropy_loss          | 0.448       |
|    explained_variance    | 0.966       |
|    lagrangian_multiplier | 0.000693    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.56        |
|    n_updates             | 8930        |
|    policy_gradient_loss  | 0.0107      |
|    std                   | 0.289       |
|    value_loss            | 1.31        |
------------------------------------------
-----------------------------------------
| avg_speed                | 6.4        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 6.4        |
| reward                   | -0.4624703 |
| rollout/                 |            |
|    ep_len_mean           | 46.5       |
|    ep_rew_mean           | -24.5      |
| time/                    |            |
|    fps                   | 66         |
|    iterations            | 13         |
|    time_elapsed          | 400        |
|    total_timesteps       | 1832960    |
| train/                   |            |
|    approx_kl             | 0.02668687 |
|    clip_fraction         | 0.176      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.18       |
|    cost_value_loss       | 3.9        |
|    cost_values           | 1.78       |
|    entropy               | 0.448      |
|    entropy_loss          | 0.448      |
|    explained_variance    | 0.942      |
|    lagrangian_multiplier | 0.00153    |
|    learning_rate         | 0.0003     |
|    loss                  | 2.46       |
|    n_updates             | 8940       |
|    policy_gradient_loss  | 0.00512    |
|    std                   | 0.29       |
|    value_loss            | 1.98       |
-----------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.74728644 |
| rollout/                 |             |
|    ep_len_mean           | 44.2        |
|    ep_rew_mean           | -23.7       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 14          |
|    time_elapsed          | 429         |
|    total_timesteps       | 1835008     |
| train/                   |             |
|    approx_kl             | 0.02426126  |
|    clip_fraction         | 0.176       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.18        |
|    cost_value_loss       | 3.7         |
|    cost_values           | 1.8         |
|    entropy               | 0.448       |
|    entropy_loss          | 0.448       |
|    explained_variance    | 0.973       |
|    lagrangian_multiplier | 0.00191     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.08        |
|    n_updates             | 8950        |
|    policy_gradient_loss  | 0.00242     |
|    std                   | 0.291       |
|    value_loss            | 0.971       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.6         |
| reward                   | -0.37924927 |
| rollout/                 |             |
|    ep_len_mean           | 44.3        |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 15          |
|    time_elapsed          | 461         |
|    total_timesteps       | 1837056     |
| train/                   |             |
|    approx_kl             | 0.01594013  |
|    clip_fraction         | 0.202       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.05        |
|    cost_value_loss       | 3.47        |
|    cost_values           | 1.74        |
|    entropy               | 0.451       |
|    entropy_loss          | 0.449       |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0.000427    |
|    learning_rate         | 0.0003      |
|    loss                  | 1.95        |
|    n_updates             | 8960        |
|    policy_gradient_loss  | 0.00701     |
|    std                   | 0.29        |
|    value_loss            | 0.739       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.8608079  |
| rollout/                 |             |
|    ep_len_mean           | 47.8        |
|    ep_rew_mean           | -24.5       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 16          |
|    time_elapsed          | 493         |
|    total_timesteps       | 1839104     |
| train/                   |             |
|    approx_kl             | 0.024830565 |
|    clip_fraction         | 0.219       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.1         |
|    cost_value_loss       | 3.7         |
|    cost_values           | 1.71        |
|    entropy               | 0.454       |
|    entropy_loss          | 0.452       |
|    explained_variance    | 0.967       |
|    lagrangian_multiplier | 0.00148     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.92        |
|    n_updates             | 8970        |
|    policy_gradient_loss  | 0.00957     |
|    std                   | 0.288       |
|    value_loss            | 0.959       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.88110644 |
| rollout/                 |             |
|    ep_len_mean           | 47.7        |
|    ep_rew_mean           | -24.6       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 17          |
|    time_elapsed          | 523         |
|    total_timesteps       | 1841152     |
| train/                   |             |
|    approx_kl             | 0.02108396  |
|    clip_fraction         | 0.202       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.9         |
|    cost_value_loss       | 3.39        |
|    cost_values           | 1.68        |
|    entropy               | 0.459       |
|    entropy_loss          | 0.457       |
|    explained_variance    | 0.964       |
|    lagrangian_multiplier | 1.36e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.38        |
|    n_updates             | 8980        |
|    policy_gradient_loss  | 0.0072      |
|    std                   | 0.289       |
|    value_loss            | 1.46        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.18        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.18        |
| reward                   | -0.480585   |
| rollout/                 |             |
|    ep_len_mean           | 45.1        |
|    ep_rew_mean           | -24.2       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 18          |
|    time_elapsed          | 547         |
|    total_timesteps       | 1843200     |
| train/                   |             |
|    approx_kl             | 0.020217028 |
|    clip_fraction         | 0.167       |
|    clip_range            | 0.2         |
|    cost_returns          | 3           |
|    cost_value_loss       | 3.15        |
|    cost_values           | 1.73        |
|    entropy               | 0.461       |
|    entropy_loss          | 0.46        |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0.000797    |
|    learning_rate         | 0.0003      |
|    loss                  | 1.96        |
|    n_updates             | 8990        |
|    policy_gradient_loss  | 0.00603     |
|    std                   | 0.288       |
|    value_loss            | 0.95        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.4         |
| reward                   | -0.34630242 |
| rollout/                 |             |
|    ep_len_mean           | 44.7        |
|    ep_rew_mean           | -23.4       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 19          |
|    time_elapsed          | 573         |
|    total_timesteps       | 1845248     |
| train/                   |             |
|    approx_kl             | 0.022949986 |
|    clip_fraction         | 0.184       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.88        |
|    cost_value_loss       | 2.88        |
|    cost_values           | 1.71        |
|    entropy               | 0.469       |
|    entropy_loss          | 0.465       |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 0.00118     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.96        |
|    n_updates             | 9000        |
|    policy_gradient_loss  | 0.00498     |
|    std                   | 0.287       |
|    value_loss            | 0.873       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.62663627 |
| rollout/                 |             |
|    ep_len_mean           | 45.4        |
|    ep_rew_mean           | -23.8       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 20          |
|    time_elapsed          | 602         |
|    total_timesteps       | 1847296     |
| train/                   |             |
|    approx_kl             | 0.015058073 |
|    clip_fraction         | 0.183       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.96        |
|    cost_value_loss       | 3.18        |
|    cost_values           | 1.64        |
|    entropy               | 0.472       |
|    entropy_loss          | 0.471       |
|    explained_variance    | 0.973       |
|    lagrangian_multiplier | 0.000854    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.06        |
|    n_updates             | 9010        |
|    policy_gradient_loss  | 0.0141      |
|    std                   | 0.286       |
|    value_loss            | 0.915       |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.8          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4.8          |
| reward                   | -0.63572395  |
| rollout/                 |              |
|    ep_len_mean           | 45.3         |
|    ep_rew_mean           | -24.1        |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 21           |
|    time_elapsed          | 631          |
|    total_timesteps       | 1849344      |
| train/                   |              |
|    approx_kl             | 0.0140374955 |
|    clip_fraction         | 0.164        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.86         |
|    cost_value_loss       | 3.01         |
|    cost_values           | 1.63         |
|    entropy               | 0.473        |
|    entropy_loss          | 0.472        |
|    explained_variance    | 0.973        |
|    lagrangian_multiplier | 0.000335     |
|    learning_rate         | 0.0003       |
|    loss                  | 2.09         |
|    n_updates             | 9020         |
|    policy_gradient_loss  | 0.00716      |
|    std                   | 0.286        |
|    value_loss            | 1.17         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 2.6        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 2.6        |
| reward                   | -0.6812265 |
| rollout/                 |            |
|    ep_len_mean           | 44.9       |
|    ep_rew_mean           | -23.4      |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 22         |
|    time_elapsed          | 660        |
|    total_timesteps       | 1851392    |
| train/                   |            |
|    approx_kl             | 0.01756889 |
|    clip_fraction         | 0.165      |
|    clip_range            | 0.2        |
|    cost_returns          | 2.97       |
|    cost_value_loss       | 3.07       |
|    cost_values           | 1.7        |
|    entropy               | 0.477      |
|    entropy_loss          | 0.476      |
|    explained_variance    | 0.976      |
|    lagrangian_multiplier | 4.11e-05   |
|    learning_rate         | 0.0003     |
|    loss                  | 2.06       |
|    n_updates             | 9030       |
|    policy_gradient_loss  | 0.00783    |
|    std                   | 0.286      |
|    value_loss            | 0.889      |
-----------------------------------------
------------------------------------------
| avg_speed                | 6.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.2         |
| reward                   | -0.51262575 |
| rollout/                 |             |
|    ep_len_mean           | 44.7        |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 23          |
|    time_elapsed          | 690         |
|    total_timesteps       | 1853440     |
| train/                   |             |
|    approx_kl             | 0.013261948 |
|    clip_fraction         | 0.187       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.98        |
|    cost_value_loss       | 3.3         |
|    cost_values           | 1.69        |
|    entropy               | 0.471       |
|    entropy_loss          | 0.474       |
|    explained_variance    | 0.97        |
|    lagrangian_multiplier | 0.0014      |
|    learning_rate         | 0.0003      |
|    loss                  | 1.99        |
|    n_updates             | 9040        |
|    policy_gradient_loss  | 0.00841     |
|    std                   | 0.287       |
|    value_loss            | 1.04        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.8         |
| reward                   | -0.45541087 |
| rollout/                 |             |
|    ep_len_mean           | 45.6        |
|    ep_rew_mean           | -24.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 24          |
|    time_elapsed          | 719         |
|    total_timesteps       | 1855488     |
| train/                   |             |
|    approx_kl             | 0.014752344 |
|    clip_fraction         | 0.175       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.08        |
|    cost_value_loss       | 3.65        |
|    cost_values           | 1.69        |
|    entropy               | 0.474       |
|    entropy_loss          | 0.471       |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0.00131     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.97        |
|    n_updates             | 9050        |
|    policy_gradient_loss  | 0.00818     |
|    std                   | 0.286       |
|    value_loss            | 0.771       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.32161704 |
| rollout/                 |             |
|    ep_len_mean           | 45.8        |
|    ep_rew_mean           | -24         |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 25          |
|    time_elapsed          | 749         |
|    total_timesteps       | 1857536     |
| train/                   |             |
|    approx_kl             | 0.021380272 |
|    clip_fraction         | 0.199       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.58        |
|    cost_value_loss       | 2.33        |
|    cost_values           | 1.67        |
|    entropy               | 0.476       |
|    entropy_loss          | 0.476       |
|    explained_variance    | 0.938       |
|    lagrangian_multiplier | 0.000836    |
|    learning_rate         | 0.0003      |
|    loss                  | 1.83        |
|    n_updates             | 9060        |
|    policy_gradient_loss  | 0.00959     |
|    std                   | 0.286       |
|    value_loss            | 1.72        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.12978892 |
| rollout/                 |             |
|    ep_len_mean           | 45.5        |
|    ep_rew_mean           | -24         |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 26          |
|    time_elapsed          | 780         |
|    total_timesteps       | 1859584     |
| train/                   |             |
|    approx_kl             | 0.021050576 |
|    clip_fraction         | 0.175       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.9         |
|    cost_value_loss       | 3.21        |
|    cost_values           | 1.61        |
|    entropy               | 0.48        |
|    entropy_loss          | 0.477       |
|    explained_variance    | 0.972       |
|    lagrangian_multiplier | 0.000183    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.06        |
|    n_updates             | 9070        |
|    policy_gradient_loss  | 0.0048      |
|    std                   | 0.287       |
|    value_loss            | 0.997       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3707472  |
| rollout/                 |             |
|    ep_len_mean           | 45          |
|    ep_rew_mean           | -23.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 27          |
|    time_elapsed          | 809         |
|    total_timesteps       | 1861632     |
| train/                   |             |
|    approx_kl             | 0.024717737 |
|    clip_fraction         | 0.199       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.94        |
|    cost_value_loss       | 3.41        |
|    cost_values           | 1.62        |
|    entropy               | 0.486       |
|    entropy_loss          | 0.483       |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0.000587    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.06        |
|    n_updates             | 9080        |
|    policy_gradient_loss  | 0.0122      |
|    std                   | 0.287       |
|    value_loss            | 0.995       |
------------------------------------------
-----------------------------------------
| avg_speed                | 1.6        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 1.6        |
| reward                   | -0.5886169 |
| rollout/                 |            |
|    ep_len_mean           | 47         |
|    ep_rew_mean           | -24.4      |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 28         |
|    time_elapsed          | 842        |
|    total_timesteps       | 1863680    |
| train/                   |            |
|    approx_kl             | 0.02068537 |
|    clip_fraction         | 0.188      |
|    clip_range            | 0.2        |
|    cost_returns          | 2.89       |
|    cost_value_loss       | 3          |
|    cost_values           | 1.64       |
|    entropy               | 0.495      |
|    entropy_loss          | 0.491      |
|    explained_variance    | 0.973      |
|    lagrangian_multiplier | 0.00102    |
|    learning_rate         | 0.0003     |
|    loss                  | 1.92       |
|    n_updates             | 9090       |
|    policy_gradient_loss  | 0.0107     |
|    std                   | 0.286      |
|    value_loss            | 1.05       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.1333632  |
| rollout/                 |             |
|    ep_len_mean           | 47.4        |
|    ep_rew_mean           | -24.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 29          |
|    time_elapsed          | 867         |
|    total_timesteps       | 1865728     |
| train/                   |             |
|    approx_kl             | 0.024138872 |
|    clip_fraction         | 0.158       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.11        |
|    cost_value_loss       | 3.84        |
|    cost_values           | 1.64        |
|    entropy               | 0.495       |
|    entropy_loss          | 0.496       |
|    explained_variance    | 0.952       |
|    lagrangian_multiplier | 0.000664    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.38        |
|    n_updates             | 9100        |
|    policy_gradient_loss  | 0.0114      |
|    std                   | 0.286       |
|    value_loss            | 1.59        |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.78874034 |
| rollout/                 |             |
|    ep_len_mean           | 45.5        |
|    ep_rew_mean           | -23.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 30          |
|    time_elapsed          | 892         |
|    total_timesteps       | 1867776     |
| train/                   |             |
|    approx_kl             | 0.030383449 |
|    clip_fraction         | 0.185       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.02        |
|    cost_value_loss       | 3.41        |
|    cost_values           | 1.69        |
|    entropy               | 0.498       |
|    entropy_loss          | 0.496       |
|    explained_variance    | 0.972       |
|    lagrangian_multiplier | 0.00105     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.19        |
|    n_updates             | 9110        |
|    policy_gradient_loss  | 0.00789     |
|    std                   | 0.286       |
|    value_loss            | 1.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.68419373 |
| rollout/                 |             |
|    ep_len_mean           | 46.6        |
|    ep_rew_mean           | -24.8       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 31          |
|    time_elapsed          | 917         |
|    total_timesteps       | 1869824     |
| train/                   |             |
|    approx_kl             | 0.01710618  |
|    clip_fraction         | 0.2         |
|    clip_range            | 0.2         |
|    cost_returns          | 2.82        |
|    cost_value_loss       | 3.04        |
|    cost_values           | 1.65        |
|    entropy               | 0.496       |
|    entropy_loss          | 0.497       |
|    explained_variance    | 0.973       |
|    lagrangian_multiplier | 0.000823    |
|    learning_rate         | 0.0003      |
|    loss                  | 1.93        |
|    n_updates             | 9120        |
|    policy_gradient_loss  | 0.007       |
|    std                   | 0.287       |
|    value_loss            | 1.03        |
------------------------------------------
-----------------------------------------
| avg_speed                | 3.6        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 3.6        |
| reward                   | -0.7098836 |
| rollout/                 |            |
|    ep_len_mean           | 47.2       |
|    ep_rew_mean           | -24.6      |
| time/                    |            |
|    fps                   | 69         |
|    iterations            | 32         |
|    time_elapsed          | 941        |
|    total_timesteps       | 1871872    |
| train/                   |            |
|    approx_kl             | 0.00850098 |
|    clip_fraction         | 0.16       |
|    clip_range            | 0.2        |
|    cost_returns          | 2.87       |
|    cost_value_loss       | 3.44       |
|    cost_values           | 1.63       |
|    entropy               | 0.497      |
|    entropy_loss          | 0.495      |
|    explained_variance    | 0.95       |
|    lagrangian_multiplier | 7.59e-05   |
|    learning_rate         | 0.0003     |
|    loss                  | 2.44       |
|    n_updates             | 9130       |
|    policy_gradient_loss  | 0.00917    |
|    std                   | 0.287      |
|    value_loss            | 1.85       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 7            |
| cost                     | 0            |
| is_success               | 1            |
| max_speed                | 7            |
| reward                   | -0.115986586 |
| rollout/                 |              |
|    ep_len_mean           | 47.2         |
|    ep_rew_mean           | -24.2        |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 33           |
|    time_elapsed          | 965          |
|    total_timesteps       | 1873920      |
| train/                   |              |
|    approx_kl             | 0.03610939   |
|    clip_fraction         | 0.167        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.99         |
|    cost_value_loss       | 3.27         |
|    cost_values           | 1.71         |
|    entropy               | 0.489        |
|    entropy_loss          | 0.494        |
|    explained_variance    | 0.944        |
|    lagrangian_multiplier | 0.00139      |
|    learning_rate         | 0.0003       |
|    loss                  | 2.2          |
|    n_updates             | 9140         |
|    policy_gradient_loss  | 0.00467      |
|    std                   | 0.287        |
|    value_loss            | 1.87         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.5296473  |
| rollout/                 |             |
|    ep_len_mean           | 45.7        |
|    ep_rew_mean           | -24.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 34          |
|    time_elapsed          | 989         |
|    total_timesteps       | 1875968     |
| train/                   |             |
|    approx_kl             | 0.030041117 |
|    clip_fraction         | 0.143       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.03        |
|    cost_value_loss       | 3.23        |
|    cost_values           | 1.77        |
|    entropy               | 0.501       |
|    entropy_loss          | 0.494       |
|    explained_variance    | 0.944       |
|    lagrangian_multiplier | 5.3e-05     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.72        |
|    n_updates             | 9150        |
|    policy_gradient_loss  | 0.00674     |
|    std                   | 0.286       |
|    value_loss            | 2.06        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.8         |
| reward                   | -0.29860976 |
| rollout/                 |             |
|    ep_len_mean           | 44.5        |
|    ep_rew_mean           | -23.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 35          |
|    time_elapsed          | 1013        |
|    total_timesteps       | 1878016     |
| train/                   |             |
|    approx_kl             | 0.014581899 |
|    clip_fraction         | 0.197       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.91        |
|    cost_value_loss       | 2.81        |
|    cost_values           | 1.74        |
|    entropy               | 0.51        |
|    entropy_loss          | 0.506       |
|    explained_variance    | 0.968       |
|    lagrangian_multiplier | 0.000268    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.23        |
|    n_updates             | 9160        |
|    policy_gradient_loss  | 0.00728     |
|    std                   | 0.284       |
|    value_loss            | 1.26        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.2         |
| reward                   | -0.7010704  |
| rollout/                 |             |
|    ep_len_mean           | 45.7        |
|    ep_rew_mean           | -24         |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 36          |
|    time_elapsed          | 1038        |
|    total_timesteps       | 1880064     |
| train/                   |             |
|    approx_kl             | 0.012316897 |
|    clip_fraction         | 0.17        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.08        |
|    cost_value_loss       | 3.4         |
|    cost_values           | 1.7         |
|    entropy               | 0.519       |
|    entropy_loss          | 0.515       |
|    explained_variance    | 0.973       |
|    lagrangian_multiplier | 0.000505    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.02        |
|    n_updates             | 9170        |
|    policy_gradient_loss  | 0.00979     |
|    std                   | 0.283       |
|    value_loss            | 0.991       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.34650782 |
| rollout/                 |             |
|    ep_len_mean           | 46.4        |
|    ep_rew_mean           | -24.3       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 37          |
|    time_elapsed          | 1061        |
|    total_timesteps       | 1882112     |
| train/                   |             |
|    approx_kl             | 0.018769797 |
|    clip_fraction         | 0.217       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.07        |
|    cost_value_loss       | 3.46        |
|    cost_values           | 1.71        |
|    entropy               | 0.523       |
|    entropy_loss          | 0.522       |
|    explained_variance    | 0.968       |
|    lagrangian_multiplier | 0.00206     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.04        |
|    n_updates             | 9180        |
|    policy_gradient_loss  | 0.00824     |
|    std                   | 0.282       |
|    value_loss            | 1.28        |
------------------------------------------
-----------------------------------------
| avg_speed                | 5.2        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 5.2        |
| reward                   | -0.5517226 |
| rollout/                 |            |
|    ep_len_mean           | 45.2       |
|    ep_rew_mean           | -24.3      |
| time/                    |            |
|    fps                   | 71         |
|    iterations            | 38         |
|    time_elapsed          | 1085       |
|    total_timesteps       | 1884160    |
| train/                   |            |
|    approx_kl             | 0.05650765 |
|    clip_fraction         | 0.174      |
|    clip_range            | 0.2        |
|    cost_returns          | 2.98       |
|    cost_value_loss       | 3.29       |
|    cost_values           | 1.71       |
|    entropy               | 0.526      |
|    entropy_loss          | 0.524      |
|    explained_variance    | 0.979      |
|    lagrangian_multiplier | 0.000663   |
|    learning_rate         | 0.0003     |
|    loss                  | 2.03       |
|    n_updates             | 9190       |
|    policy_gradient_loss  | 0.00797    |
|    std                   | 0.281      |
|    value_loss            | 0.824      |
-----------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.9275497  |
| rollout/                 |             |
|    ep_len_mean           | 46.4        |
|    ep_rew_mean           | -24.6       |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 39          |
|    time_elapsed          | 1109        |
|    total_timesteps       | 1886208     |
| train/                   |             |
|    approx_kl             | 0.014021473 |
|    clip_fraction         | 0.187       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.94        |
|    cost_value_loss       | 3.24        |
|    cost_values           | 1.66        |
|    entropy               | 0.521       |
|    entropy_loss          | 0.524       |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 0.00165     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.92        |
|    n_updates             | 9200        |
|    policy_gradient_loss  | 0.0129      |
|    std                   | 0.284       |
|    value_loss            | 0.872       |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.31845772 |
| rollout/                 |             |
|    ep_len_mean           | 47.7        |
|    ep_rew_mean           | -25.1       |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 40          |
|    time_elapsed          | 1133        |
|    total_timesteps       | 1888256     |
| train/                   |             |
|    approx_kl             | 0.029299034 |
|    clip_fraction         | 0.194       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.14        |
|    cost_value_loss       | 3.99        |
|    cost_values           | 1.67        |
|    entropy               | 0.522       |
|    entropy_loss          | 0.52        |
|    explained_variance    | 0.969       |
|    lagrangian_multiplier | 0.00123     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.29        |
|    n_updates             | 9210        |
|    policy_gradient_loss  | 0.00546     |
|    std                   | 0.283       |
|    value_loss            | 1.2         |
------------------------------------------
-----------------------------------------
| avg_speed                | 3.4        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 3.4        |
| reward                   | -0.70541   |
| rollout/                 |            |
|    ep_len_mean           | 46.4       |
|    ep_rew_mean           | -24.5      |
| time/                    |            |
|    fps                   | 72         |
|    iterations            | 41         |
|    time_elapsed          | 1157       |
|    total_timesteps       | 1890304    |
| train/                   |            |
|    approx_kl             | 0.02016642 |
|    clip_fraction         | 0.193      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.25       |
|    cost_value_loss       | 4.09       |
|    cost_values           | 1.73       |
|    entropy               | 0.527      |
|    entropy_loss          | 0.525      |
|    explained_variance    | 0.964      |
|    lagrangian_multiplier | 0.00152    |
|    learning_rate         | 0.0003     |
|    loss                  | 2.4        |
|    n_updates             | 9220       |
|    policy_gradient_loss  | 0.00996    |
|    std                   | 0.283      |
|    value_loss            | 1.38       |
-----------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.81637603 |
| rollout/                 |             |
|    ep_len_mean           | 46.3        |
|    ep_rew_mean           | -24         |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 42          |
|    time_elapsed          | 1181        |
|    total_timesteps       | 1892352     |
| train/                   |             |
|    approx_kl             | 0.024918959 |
|    clip_fraction         | 0.215       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.03        |
|    cost_value_loss       | 3.31        |
|    cost_values           | 1.75        |
|    entropy               | 0.529       |
|    entropy_loss          | 0.528       |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0.000837    |
|    learning_rate         | 0.0003      |
|    loss                  | 1.99        |
|    n_updates             | 9230        |
|    policy_gradient_loss  | 0.0132      |
|    std                   | 0.283       |
|    value_loss            | 0.67        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.90666413 |
| rollout/                 |             |
|    ep_len_mean           | 45.4        |
|    ep_rew_mean           | -23.8       |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 43          |
|    time_elapsed          | 1206        |
|    total_timesteps       | 1894400     |
| train/                   |             |
|    approx_kl             | 0.019379146 |
|    clip_fraction         | 0.214       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.13        |
|    cost_value_loss       | 3.96        |
|    cost_values           | 1.7         |
|    entropy               | 0.534       |
|    entropy_loss          | 0.531       |
|    explained_variance    | 0.961       |
|    lagrangian_multiplier | 0.000124    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.66        |
|    n_updates             | 9240        |
|    policy_gradient_loss  | 0.0114      |
|    std                   | 0.282       |
|    value_loss            | 1.39        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.2         |
| reward                   | -0.6783039  |
| rollout/                 |             |
|    ep_len_mean           | 44.3        |
|    ep_rew_mean           | -23.4       |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 44          |
|    time_elapsed          | 1230        |
|    total_timesteps       | 1896448     |
| train/                   |             |
|    approx_kl             | 0.038561955 |
|    clip_fraction         | 0.168       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.1         |
|    cost_value_loss       | 3.53        |
|    cost_values           | 1.74        |
|    entropy               | 0.535       |
|    entropy_loss          | 0.535       |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0.000206    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.45        |
|    n_updates             | 9250        |
|    policy_gradient_loss  | 0.0101      |
|    std                   | 0.283       |
|    value_loss            | 1.04        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.4         |
| reward                   | -0.21306781 |
| rollout/                 |             |
|    ep_len_mean           | 44.7        |
|    ep_rew_mean           | -23.5       |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 45          |
|    time_elapsed          | 1254        |
|    total_timesteps       | 1898496     |
| train/                   |             |
|    approx_kl             | 0.011712024 |
|    clip_fraction         | 0.215       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.03        |
|    cost_value_loss       | 3.5         |
|    cost_values           | 1.73        |
|    entropy               | 0.528       |
|    entropy_loss          | 0.532       |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0.000499    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.07        |
|    n_updates             | 9260        |
|    policy_gradient_loss  | 0.0137      |
|    std                   | 0.284       |
|    value_loss            | 0.928       |
------------------------------------------
-----------------------------------------
| avg_speed                | 4.2        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 4.2        |
| reward                   | -0.632607  |
| rollout/                 |            |
|    ep_len_mean           | 45.2       |
|    ep_rew_mean           | -23.7      |
| time/                    |            |
|    fps                   | 73         |
|    iterations            | 46         |
|    time_elapsed          | 1277       |
|    total_timesteps       | 1900544    |
| train/                   |            |
|    approx_kl             | 0.03823089 |
|    clip_fraction         | 0.215      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.09       |
|    cost_value_loss       | 3.76       |
|    cost_values           | 1.7        |
|    entropy               | 0.53       |
|    entropy_loss          | 0.529      |
|    explained_variance    | 0.98       |
|    lagrangian_multiplier | 0.00153    |
|    learning_rate         | 0.0003     |
|    loss                  | 2.11       |
|    n_updates             | 9270       |
|    policy_gradient_loss  | 0.00739    |
|    std                   | 0.284      |
|    value_loss            | 0.784      |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 1            |
| max_speed                | 8            |
| reward                   | -0.089860804 |
| rollout/                 |              |
|    ep_len_mean           | 45.9         |
|    ep_rew_mean           | -24.2        |
| time/                    |              |
|    fps                   | 73           |
|    iterations            | 47           |
|    time_elapsed          | 1301         |
|    total_timesteps       | 1902592      |
| train/                   |              |
|    approx_kl             | 0.022912476  |
|    clip_fraction         | 0.215        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.99         |
|    cost_value_loss       | 3.56         |
|    cost_values           | 1.66         |
|    entropy               | 0.528        |
|    entropy_loss          | 0.53         |
|    explained_variance    | 0.959        |
|    lagrangian_multiplier | 0.000833     |
|    learning_rate         | 0.0003       |
|    loss                  | 2.38         |
|    n_updates             | 9280         |
|    policy_gradient_loss  | 0.00814      |
|    std                   | 0.285        |
|    value_loss            | 1.49         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.84333557 |
| rollout/                 |             |
|    ep_len_mean           | 46.5        |
|    ep_rew_mean           | -24.7       |
| time/                    |             |
|    fps                   | 74          |
|    iterations            | 48          |
|    time_elapsed          | 1324        |
|    total_timesteps       | 1904640     |
| train/                   |             |
|    approx_kl             | 0.01589017  |
|    clip_fraction         | 0.173       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.99        |
|    cost_value_loss       | 3.37        |
|    cost_values           | 1.66        |
|    entropy               | 0.53        |
|    entropy_loss          | 0.529       |
|    explained_variance    | 0.969       |
|    lagrangian_multiplier | 0.000674    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.12        |
|    n_updates             | 9290        |
|    policy_gradient_loss  | 0.00802     |
|    std                   | 0.285       |
|    value_loss            | 1.22        |
------------------------------------------
------------------------------------------
| avg_speed                | 5           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5           |
| reward                   | -0.68278116 |
| rollout/                 |             |
|    ep_len_mean           | 45.6        |
|    ep_rew_mean           | -24.3       |
| time/                    |             |
|    fps                   | 74          |
|    iterations            | 49          |
|    time_elapsed          | 1348        |
|    total_timesteps       | 1906688     |
| train/                   |             |
|    approx_kl             | 0.018030785 |
|    clip_fraction         | 0.173       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.98        |
|    cost_value_loss       | 3.41        |
|    cost_values           | 1.66        |
|    entropy               | 0.531       |
|    entropy_loss          | 0.532       |
|    explained_variance    | 0.953       |
|    lagrangian_multiplier | 0.00038     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.37        |
|    n_updates             | 9300        |
|    policy_gradient_loss  | 0.00756     |
|    std                   | 0.284       |
|    value_loss            | 1.76        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ent-coefficient-ppol/1vjpjg9h
-----------------------------------
| avg_speed          | 4.8        |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 4.8        |
| reward             | -0.5401445 |
| rollout/           |            |
|    ep_len_mean     | 44.5       |
|    ep_rew_mean     | -23.4      |
| time/              |            |
|    fps             | 75         |
|    iterations      | 1          |
|    time_elapsed    | 27         |
|    total_timesteps | 1908736    |
-----------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.6822458  |
| rollout/                 |             |
|    ep_len_mean           | 44.6        |
|    ep_rew_mean           | -23.9       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 2           |
|    time_elapsed          | 58          |
|    total_timesteps       | 1910784     |
| train/                   |             |
|    approx_kl             | 0.015695097 |
|    clip_fraction         | 0.183       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.88        |
|    cost_value_loss       | 3.18        |
|    cost_values           | 1.63        |
|    entropy               | 0.531       |
|    entropy_loss          | 0.531       |
|    explained_variance    | 0.963       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.2         |
|    n_updates             | 9320        |
|    policy_gradient_loss  | 0.00514     |
|    std                   | 0.286       |
|    value_loss            | 1.32        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.48200476 |
| rollout/                 |             |
|    ep_len_mean           | 45.7        |
|    ep_rew_mean           | -24         |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 3           |
|    time_elapsed          | 87          |
|    total_timesteps       | 1912832     |
| train/                   |             |
|    approx_kl             | 0.013621075 |
|    clip_fraction         | 0.152       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.88        |
|    cost_value_loss       | 3.12        |
|    cost_values           | 1.7         |
|    entropy               | 0.525       |
|    entropy_loss          | 0.528       |
|    explained_variance    | 0.966       |
|    lagrangian_multiplier | 0.00115     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.03        |
|    n_updates             | 9330        |
|    policy_gradient_loss  | 0.00458     |
|    std                   | 0.287       |
|    value_loss            | 1.33        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.8         |
| reward                   | -0.9204258  |
| rollout/                 |             |
|    ep_len_mean           | 47.1        |
|    ep_rew_mean           | -24.5       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 4           |
|    time_elapsed          | 122         |
|    total_timesteps       | 1914880     |
| train/                   |             |
|    approx_kl             | 0.060728863 |
|    clip_fraction         | 0.234       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.04        |
|    cost_value_loss       | 3.36        |
|    cost_values           | 1.7         |
|    entropy               | 0.527       |
|    entropy_loss          | 0.526       |
|    explained_variance    | 0.951       |
|    lagrangian_multiplier | 0.000983    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.2         |
|    n_updates             | 9340        |
|    policy_gradient_loss  | 0.0119      |
|    std                   | 0.286       |
|    value_loss            | 1.62        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.4         |
| reward                   | -0.17396788 |
| rollout/                 |             |
|    ep_len_mean           | 45.3        |
|    ep_rew_mean           | -24.2       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 5           |
|    time_elapsed          | 152         |
|    total_timesteps       | 1916928     |
| train/                   |             |
|    approx_kl             | 0.032986987 |
|    clip_fraction         | 0.238       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.01        |
|    cost_value_loss       | 3.64        |
|    cost_values           | 1.71        |
|    entropy               | 0.522       |
|    entropy_loss          | 0.525       |
|    explained_variance    | 0.963       |
|    lagrangian_multiplier | 0.000589    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.4         |
|    n_updates             | 9350        |
|    policy_gradient_loss  | 0.0121      |
|    std                   | 0.286       |
|    value_loss            | 1.48        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.20975631 |
| rollout/                 |             |
|    ep_len_mean           | 44.3        |
|    ep_rew_mean           | -23.8       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 6           |
|    time_elapsed          | 182         |
|    total_timesteps       | 1918976     |
| train/                   |             |
|    approx_kl             | 0.03956782  |
|    clip_fraction         | 0.195       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.2         |
|    cost_value_loss       | 3.86        |
|    cost_values           | 1.72        |
|    entropy               | 0.522       |
|    entropy_loss          | 0.522       |
|    explained_variance    | 0.965       |
|    lagrangian_multiplier | 0.000705    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.37        |
|    n_updates             | 9360        |
|    policy_gradient_loss  | 0.00925     |
|    std                   | 0.287       |
|    value_loss            | 1.37        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.81738675 |
| rollout/                 |             |
|    ep_len_mean           | 42.8        |
|    ep_rew_mean           | -22.7       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 7           |
|    time_elapsed          | 211         |
|    total_timesteps       | 1921024     |
| train/                   |             |
|    approx_kl             | 0.023205819 |
|    clip_fraction         | 0.195       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.01        |
|    cost_value_loss       | 3.26        |
|    cost_values           | 1.73        |
|    entropy               | 0.52        |
|    entropy_loss          | 0.521       |
|    explained_variance    | 0.971       |
|    lagrangian_multiplier | 0.00143     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.03        |
|    n_updates             | 9370        |
|    policy_gradient_loss  | 0.00661     |
|    std                   | 0.287       |
|    value_loss            | 1.09        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.7387308  |
| rollout/                 |             |
|    ep_len_mean           | 44.4        |
|    ep_rew_mean           | -23.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 8           |
|    time_elapsed          | 240         |
|    total_timesteps       | 1923072     |
| train/                   |             |
|    approx_kl             | 0.015056811 |
|    clip_fraction         | 0.209       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.05        |
|    cost_value_loss       | 3.76        |
|    cost_values           | 1.69        |
|    entropy               | 0.529       |
|    entropy_loss          | 0.524       |
|    explained_variance    | 0.973       |
|    lagrangian_multiplier | 0.00187     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.17        |
|    n_updates             | 9380        |
|    policy_gradient_loss  | 0.00541     |
|    std                   | 0.286       |
|    value_loss            | 0.943       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.86        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.86        |
| reward                   | -0.25496903 |
| rollout/                 |             |
|    ep_len_mean           | 44.3        |
|    ep_rew_mean           | -23.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 9           |
|    time_elapsed          | 270         |
|    total_timesteps       | 1925120     |
| train/                   |             |
|    approx_kl             | 0.03012751  |
|    clip_fraction         | 0.227       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.16        |
|    cost_value_loss       | 4.12        |
|    cost_values           | 1.62        |
|    entropy               | 0.526       |
|    entropy_loss          | 0.529       |
|    explained_variance    | 0.948       |
|    lagrangian_multiplier | 0.000917    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.36        |
|    n_updates             | 9390        |
|    policy_gradient_loss  | 0.00768     |
|    std                   | 0.287       |
|    value_loss            | 1.48        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.8675673  |
| rollout/                 |             |
|    ep_len_mean           | 43.9        |
|    ep_rew_mean           | -23.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 10          |
|    time_elapsed          | 300         |
|    total_timesteps       | 1927168     |
| train/                   |             |
|    approx_kl             | 0.017394163 |
|    clip_fraction         | 0.151       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.09        |
|    cost_value_loss       | 3.96        |
|    cost_values           | 1.66        |
|    entropy               | 0.531       |
|    entropy_loss          | 0.528       |
|    explained_variance    | 0.97        |
|    lagrangian_multiplier | 0.000979    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.3         |
|    n_updates             | 9400        |
|    policy_gradient_loss  | 0.0101      |
|    std                   | 0.286       |
|    value_loss            | 1.09        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.6          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.6          |
| reward                   | -0.624436    |
| rollout/                 |              |
|    ep_len_mean           | 43.9         |
|    ep_rew_mean           | -23.8        |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 11           |
|    time_elapsed          | 330          |
|    total_timesteps       | 1929216      |
| train/                   |              |
|    approx_kl             | 0.0148222605 |
|    clip_fraction         | 0.176        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.92         |
|    cost_value_loss       | 3.27         |
|    cost_values           | 1.67         |
|    entropy               | 0.53         |
|    entropy_loss          | 0.531        |
|    explained_variance    | 0.977        |
|    lagrangian_multiplier | 0.00175      |
|    learning_rate         | 0.0003       |
|    loss                  | 1.98         |
|    n_updates             | 9410         |
|    policy_gradient_loss  | 0.00489      |
|    std                   | 0.286        |
|    value_loss            | 0.896        |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.6         |
| reward                   | -0.50690466 |
| rollout/                 |             |
|    ep_len_mean           | 45.9        |
|    ep_rew_mean           | -24.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 12          |
|    time_elapsed          | 360         |
|    total_timesteps       | 1931264     |
| train/                   |             |
|    approx_kl             | 0.011991401 |
|    clip_fraction         | 0.16        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.11        |
|    cost_value_loss       | 4.11        |
|    cost_values           | 1.67        |
|    entropy               | 0.538       |
|    entropy_loss          | 0.533       |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0.0037      |
|    learning_rate         | 0.0003      |
|    loss                  | 2.1         |
|    n_updates             | 9420        |
|    policy_gradient_loss  | 0.00525     |
|    std                   | 0.284       |
|    value_loss            | 1.04        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.4         |
| reward                   | -0.6151741  |
| rollout/                 |             |
|    ep_len_mean           | 45.6        |
|    ep_rew_mean           | -24         |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 13          |
|    time_elapsed          | 393         |
|    total_timesteps       | 1933312     |
| train/                   |             |
|    approx_kl             | 0.015407928 |
|    clip_fraction         | 0.18        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.33        |
|    cost_value_loss       | 5           |
|    cost_values           | 1.69        |
|    entropy               | 0.541       |
|    entropy_loss          | 0.54        |
|    explained_variance    | 0.959       |
|    lagrangian_multiplier | 0.00106     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.57        |
|    n_updates             | 9430        |
|    policy_gradient_loss  | 0.0045      |
|    std                   | 0.283       |
|    value_loss            | 1.46        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.22156435 |
| rollout/                 |             |
|    ep_len_mean           | 45.8        |
|    ep_rew_mean           | -24.5       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 14          |
|    time_elapsed          | 422         |
|    total_timesteps       | 1935360     |
| train/                   |             |
|    approx_kl             | 0.072058365 |
|    clip_fraction         | 0.226       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.15        |
|    cost_value_loss       | 3.89        |
|    cost_values           | 1.74        |
|    entropy               | 0.537       |
|    entropy_loss          | 0.54        |
|    explained_variance    | 0.973       |
|    lagrangian_multiplier | 0.00149     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.28        |
|    n_updates             | 9440        |
|    policy_gradient_loss  | 0.0125      |
|    std                   | 0.284       |
|    value_loss            | 0.941       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.46835026 |
| rollout/                 |             |
|    ep_len_mean           | 46.1        |
|    ep_rew_mean           | -24.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 15          |
|    time_elapsed          | 451         |
|    total_timesteps       | 1937408     |
| train/                   |             |
|    approx_kl             | 0.016170267 |
|    clip_fraction         | 0.153       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.14        |
|    cost_value_loss       | 4.21        |
|    cost_values           | 1.67        |
|    entropy               | 0.539       |
|    entropy_loss          | 0.537       |
|    explained_variance    | 0.966       |
|    lagrangian_multiplier | 0.00108     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.32        |
|    n_updates             | 9450        |
|    policy_gradient_loss  | 0.00528     |
|    std                   | 0.285       |
|    value_loss            | 1.37        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.38635397 |
| rollout/                 |             |
|    ep_len_mean           | 44.1        |
|    ep_rew_mean           | -24.1       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 16          |
|    time_elapsed          | 474         |
|    total_timesteps       | 1939456     |
| train/                   |             |
|    approx_kl             | 0.038613375 |
|    clip_fraction         | 0.222       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.07        |
|    cost_value_loss       | 3.7         |
|    cost_values           | 1.69        |
|    entropy               | 0.543       |
|    entropy_loss          | 0.541       |
|    explained_variance    | 0.973       |
|    lagrangian_multiplier | 0.000483    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.42        |
|    n_updates             | 9460        |
|    policy_gradient_loss  | 0.0166      |
|    std                   | 0.285       |
|    value_loss            | 1.04        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.6         |
| reward                   | -0.34159854 |
| rollout/                 |             |
|    ep_len_mean           | 42.8        |
|    ep_rew_mean           | -23.5       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 17          |
|    time_elapsed          | 498         |
|    total_timesteps       | 1941504     |
| train/                   |             |
|    approx_kl             | 0.009591776 |
|    clip_fraction         | 0.159       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.95        |
|    cost_value_loss       | 3.58        |
|    cost_values           | 1.62        |
|    entropy               | 0.549       |
|    entropy_loss          | 0.545       |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0.0012      |
|    learning_rate         | 0.0003      |
|    loss                  | 2.02        |
|    n_updates             | 9470        |
|    policy_gradient_loss  | 0.00457     |
|    std                   | 0.285       |
|    value_loss            | 0.977       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.17610514 |
| rollout/                 |             |
|    ep_len_mean           | 45          |
|    ep_rew_mean           | -23.6       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 18          |
|    time_elapsed          | 526         |
|    total_timesteps       | 1943552     |
| train/                   |             |
|    approx_kl             | 0.026815709 |
|    clip_fraction         | 0.183       |
|    clip_range            | 0.2         |
|    cost_returns          | 3           |
|    cost_value_loss       | 3.44        |
|    cost_values           | 1.63        |
|    entropy               | 0.556       |
|    entropy_loss          | 0.553       |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0.000223    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.05        |
|    n_updates             | 9480        |
|    policy_gradient_loss  | 0.00769     |
|    std                   | 0.284       |
|    value_loss            | 0.918       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.6605517  |
| rollout/                 |             |
|    ep_len_mean           | 45.8        |
|    ep_rew_mean           | -23.9       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 19          |
|    time_elapsed          | 556         |
|    total_timesteps       | 1945600     |
| train/                   |             |
|    approx_kl             | 0.024035815 |
|    clip_fraction         | 0.177       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.08        |
|    cost_value_loss       | 4.06        |
|    cost_values           | 1.62        |
|    entropy               | 0.565       |
|    entropy_loss          | 0.561       |
|    explained_variance    | 0.952       |
|    lagrangian_multiplier | 0.000485    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.58        |
|    n_updates             | 9490        |
|    policy_gradient_loss  | 0.00742     |
|    std                   | 0.282       |
|    value_loss            | 1.61        |
------------------------------------------
-----------------------------------------
| avg_speed                | 1.8        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 1.8        |
| reward                   | -0.5719996 |
| rollout/                 |            |
|    ep_len_mean           | 43.6       |
|    ep_rew_mean           | -23.3      |
| time/                    |            |
|    fps                   | 69         |
|    iterations            | 20         |
|    time_elapsed          | 585        |
|    total_timesteps       | 1947648    |
| train/                   |            |
|    approx_kl             | 0.04160152 |
|    clip_fraction         | 0.212      |
|    clip_range            | 0.2        |
|    cost_returns          | 2.99       |
|    cost_value_loss       | 3.68       |
|    cost_values           | 1.67       |
|    entropy               | 0.568      |
|    entropy_loss          | 0.567      |
|    explained_variance    | 0.976      |
|    lagrangian_multiplier | 0.000488   |
|    learning_rate         | 0.0003     |
|    loss                  | 2.06       |
|    n_updates             | 9500       |
|    policy_gradient_loss  | 0.00825    |
|    std                   | 0.281      |
|    value_loss            | 0.898      |
-----------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.5296473  |
| rollout/                 |             |
|    ep_len_mean           | 45.3        |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 21          |
|    time_elapsed          | 618         |
|    total_timesteps       | 1949696     |
| train/                   |             |
|    approx_kl             | 0.028824057 |
|    clip_fraction         | 0.183       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.16        |
|    cost_value_loss       | 4.26        |
|    cost_values           | 1.65        |
|    entropy               | 0.566       |
|    entropy_loss          | 0.567       |
|    explained_variance    | 0.964       |
|    lagrangian_multiplier | 0.00152     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.35        |
|    n_updates             | 9510        |
|    policy_gradient_loss  | 0.00446     |
|    std                   | 0.281       |
|    value_loss            | 1.33        |
------------------------------------------
------------------------------------------
| avg_speed                | 5           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5           |
| reward                   | -0.49032104 |
| rollout/                 |             |
|    ep_len_mean           | 50          |
|    ep_rew_mean           | -24.4       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 22          |
|    time_elapsed          | 648         |
|    total_timesteps       | 1951744     |
| train/                   |             |
|    approx_kl             | 0.014440596 |
|    clip_fraction         | 0.193       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.28        |
|    cost_value_loss       | 4.57        |
|    cost_values           | 1.68        |
|    entropy               | 0.564       |
|    entropy_loss          | 0.565       |
|    explained_variance    | 0.933       |
|    lagrangian_multiplier | 0.000427    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.9         |
|    n_updates             | 9520        |
|    policy_gradient_loss  | 0.00981     |
|    std                   | 0.282       |
|    value_loss            | 2.05        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.735084   |
| rollout/                 |             |
|    ep_len_mean           | 49.1        |
|    ep_rew_mean           | -24.8       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 23          |
|    time_elapsed          | 677         |
|    total_timesteps       | 1953792     |
| train/                   |             |
|    approx_kl             | 0.021272205 |
|    clip_fraction         | 0.186       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.44        |
|    cost_value_loss       | 5.54        |
|    cost_values           | 1.71        |
|    entropy               | 0.56        |
|    entropy_loss          | 0.562       |
|    explained_variance    | 0.926       |
|    lagrangian_multiplier | 0.0011      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.16        |
|    n_updates             | 9530        |
|    policy_gradient_loss  | 0.00743     |
|    std                   | 0.282       |
|    value_loss            | 2.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.79        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.79        |
| reward                   | -0.21624146 |
| rollout/                 |             |
|    ep_len_mean           | 48.4        |
|    ep_rew_mean           | -24.7       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 24          |
|    time_elapsed          | 705         |
|    total_timesteps       | 1955840     |
| train/                   |             |
|    approx_kl             | 0.039743915 |
|    clip_fraction         | 0.214       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.34        |
|    cost_value_loss       | 4.82        |
|    cost_values           | 1.74        |
|    entropy               | 0.563       |
|    entropy_loss          | 0.561       |
|    explained_variance    | 0.964       |
|    lagrangian_multiplier | 0.000679    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.69        |
|    n_updates             | 9540        |
|    policy_gradient_loss  | 0.00776     |
|    std                   | 0.281       |
|    value_loss            | 1.33        |
------------------------------------------
-----------------------------------------
| avg_speed                | 4          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 4          |
| reward                   | -0.7291777 |
| rollout/                 |            |
|    ep_len_mean           | 46.4       |
|    ep_rew_mean           | -24        |
| time/                    |            |
|    fps                   | 70         |
|    iterations            | 25         |
|    time_elapsed          | 729        |
|    total_timesteps       | 1957888    |
| train/                   |            |
|    approx_kl             | 0.03367244 |
|    clip_fraction         | 0.194      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.1        |
|    cost_value_loss       | 3.92       |
|    cost_values           | 1.71       |
|    entropy               | 0.559      |
|    entropy_loss          | 0.561      |
|    explained_variance    | 0.959      |
|    lagrangian_multiplier | 0.00119    |
|    learning_rate         | 0.0003     |
|    loss                  | 2.34       |
|    n_updates             | 9550       |
|    policy_gradient_loss  | 0.00863    |
|    std                   | 0.282      |
|    value_loss            | 1.56       |
-----------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.7617359  |
| rollout/                 |             |
|    ep_len_mean           | 45.1        |
|    ep_rew_mean           | -23.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 26          |
|    time_elapsed          | 753         |
|    total_timesteps       | 1959936     |
| train/                   |             |
|    approx_kl             | 0.012414025 |
|    clip_fraction         | 0.192       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.33        |
|    cost_value_loss       | 5.02        |
|    cost_values           | 1.67        |
|    entropy               | 0.554       |
|    entropy_loss          | 0.556       |
|    explained_variance    | 0.97        |
|    lagrangian_multiplier | 0.00253     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.33        |
|    n_updates             | 9560        |
|    policy_gradient_loss  | 0.00937     |
|    std                   | 0.282       |
|    value_loss            | 1.16        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.8         |
| reward                   | -0.77664894 |
| rollout/                 |             |
|    ep_len_mean           | 45.9        |
|    ep_rew_mean           | -23.8       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 27          |
|    time_elapsed          | 777         |
|    total_timesteps       | 1961984     |
| train/                   |             |
|    approx_kl             | 0.02244366  |
|    clip_fraction         | 0.201       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.18        |
|    cost_value_loss       | 4.33        |
|    cost_values           | 1.68        |
|    entropy               | 0.559       |
|    entropy_loss          | 0.556       |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0.000301    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.58        |
|    n_updates             | 9570        |
|    policy_gradient_loss  | 0.00725     |
|    std                   | 0.282       |
|    value_loss            | 0.757       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.7370482  |
| rollout/                 |             |
|    ep_len_mean           | 49.2        |
|    ep_rew_mean           | -24.9       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 28          |
|    time_elapsed          | 801         |
|    total_timesteps       | 1964032     |
| train/                   |             |
|    approx_kl             | 0.054808475 |
|    clip_fraction         | 0.187       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.08        |
|    cost_value_loss       | 3.96        |
|    cost_values           | 1.66        |
|    entropy               | 0.567       |
|    entropy_loss          | 0.563       |
|    explained_variance    | 0.912       |
|    lagrangian_multiplier | 0.00119     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.31        |
|    n_updates             | 9580        |
|    policy_gradient_loss  | 0.00973     |
|    std                   | 0.281       |
|    value_loss            | 2.39        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.8675673  |
| rollout/                 |             |
|    ep_len_mean           | 49.2        |
|    ep_rew_mean           | -24.4       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 29          |
|    time_elapsed          | 825         |
|    total_timesteps       | 1966080     |
| train/                   |             |
|    approx_kl             | 0.027678909 |
|    clip_fraction         | 0.231       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.22        |
|    cost_value_loss       | 4.79        |
|    cost_values           | 1.63        |
|    entropy               | 0.575       |
|    entropy_loss          | 0.572       |
|    explained_variance    | 0.9         |
|    lagrangian_multiplier | 9.86e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.69        |
|    n_updates             | 9590        |
|    policy_gradient_loss  | 0.0125      |
|    std                   | 0.279       |
|    value_loss            | 3.05        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.2         |
| reward                   | -0.63621175 |
| rollout/                 |             |
|    ep_len_mean           | 44.6        |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 30          |
|    time_elapsed          | 850         |
|    total_timesteps       | 1968128     |
| train/                   |             |
|    approx_kl             | 0.02645863  |
|    clip_fraction         | 0.18        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.17        |
|    cost_value_loss       | 4.34        |
|    cost_values           | 1.69        |
|    entropy               | 0.578       |
|    entropy_loss          | 0.576       |
|    explained_variance    | 0.93        |
|    lagrangian_multiplier | 8.29e-06    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.02        |
|    n_updates             | 9600        |
|    policy_gradient_loss  | 0.00679     |
|    std                   | 0.278       |
|    value_loss            | 2.35        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.8         |
| reward                   | -0.845066   |
| rollout/                 |             |
|    ep_len_mean           | 45.6        |
|    ep_rew_mean           | -23.6       |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 31          |
|    time_elapsed          | 875         |
|    total_timesteps       | 1970176     |
| train/                   |             |
|    approx_kl             | 0.025312074 |
|    clip_fraction         | 0.178       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.07        |
|    cost_value_loss       | 3.76        |
|    cost_values           | 1.7         |
|    entropy               | 0.582       |
|    entropy_loss          | 0.581       |
|    explained_variance    | 0.947       |
|    lagrangian_multiplier | 0.00174     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.35        |
|    n_updates             | 9610        |
|    policy_gradient_loss  | 0.0128      |
|    std                   | 0.278       |
|    value_loss            | 1.9         |
------------------------------------------
------------------------------------------
| avg_speed                | 5.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.2         |
| reward                   | -0.52814823 |
| rollout/                 |             |
|    ep_len_mean           | 46.8        |
|    ep_rew_mean           | -23.8       |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 32          |
|    time_elapsed          | 900         |
|    total_timesteps       | 1972224     |
| train/                   |             |
|    approx_kl             | 0.014491874 |
|    clip_fraction         | 0.119       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.3         |
|    cost_value_loss       | 4.76        |
|    cost_values           | 1.65        |
|    entropy               | 0.586       |
|    entropy_loss          | 0.584       |
|    explained_variance    | 0.94        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.2         |
|    n_updates             | 9620        |
|    policy_gradient_loss  | 0.00582     |
|    std                   | 0.278       |
|    value_loss            | 1.92        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.6         |
| reward                   | -0.2756983  |
| rollout/                 |             |
|    ep_len_mean           | 49.1        |
|    ep_rew_mean           | -24.9       |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 33          |
|    time_elapsed          | 925         |
|    total_timesteps       | 1974272     |
| train/                   |             |
|    approx_kl             | 0.016132131 |
|    clip_fraction         | 0.159       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.2         |
|    cost_value_loss       | 4.23        |
|    cost_values           | 1.75        |
|    entropy               | 0.588       |
|    entropy_loss          | 0.587       |
|    explained_variance    | 0.946       |
|    lagrangian_multiplier | 0.000809    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.59        |
|    n_updates             | 9630        |
|    policy_gradient_loss  | 0.0149      |
|    std                   | 0.278       |
|    value_loss            | 1.91        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.4         |
| reward                   | -0.33084342 |
| rollout/                 |             |
|    ep_len_mean           | 47.3        |
|    ep_rew_mean           | -24.2       |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 34          |
|    time_elapsed          | 950         |
|    total_timesteps       | 1976320     |
| train/                   |             |
|    approx_kl             | 0.03199525  |
|    clip_fraction         | 0.172       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.48        |
|    cost_value_loss       | 5.18        |
|    cost_values           | 1.8         |
|    entropy               | 0.589       |
|    entropy_loss          | 0.588       |
|    explained_variance    | 0.941       |
|    lagrangian_multiplier | 0.00191     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.77        |
|    n_updates             | 9640        |
|    policy_gradient_loss  | 0.00761     |
|    std                   | 0.278       |
|    value_loss            | 2.05        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.6248759  |
| rollout/                 |             |
|    ep_len_mean           | 45.9        |
|    ep_rew_mean           | -23.5       |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 35          |
|    time_elapsed          | 976         |
|    total_timesteps       | 1978368     |
| train/                   |             |
|    approx_kl             | 0.010941069 |
|    clip_fraction         | 0.175       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.46        |
|    cost_value_loss       | 4.89        |
|    cost_values           | 1.85        |
|    entropy               | 0.593       |
|    entropy_loss          | 0.591       |
|    explained_variance    | 0.955       |
|    lagrangian_multiplier | 0.00113     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.8         |
|    n_updates             | 9650        |
|    policy_gradient_loss  | 0.00129     |
|    std                   | 0.278       |
|    value_loss            | 1.66        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.4         |
| reward                   | -0.13425995 |
| rollout/                 |             |
|    ep_len_mean           | 45.6        |
|    ep_rew_mean           | -23.6       |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 36          |
|    time_elapsed          | 1000        |
|    total_timesteps       | 1980416     |
| train/                   |             |
|    approx_kl             | 0.027005143 |
|    clip_fraction         | 0.185       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.42        |
|    cost_value_loss       | 4.65        |
|    cost_values           | 1.84        |
|    entropy               | 0.593       |
|    entropy_loss          | 0.593       |
|    explained_variance    | 0.951       |
|    lagrangian_multiplier | 0.000926    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.65        |
|    n_updates             | 9660        |
|    policy_gradient_loss  | 0.00955     |
|    std                   | 0.279       |
|    value_loss            | 1.73        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.81060624 |
| rollout/                 |             |
|    ep_len_mean           | 45.6        |
|    ep_rew_mean           | -23.9       |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 37          |
|    time_elapsed          | 1025        |
|    total_timesteps       | 1982464     |
| train/                   |             |
|    approx_kl             | 0.032549743 |
|    clip_fraction         | 0.193       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.41        |
|    cost_value_loss       | 4.82        |
|    cost_values           | 1.8         |
|    entropy               | 0.599       |
|    entropy_loss          | 0.596       |
|    explained_variance    | 0.955       |
|    lagrangian_multiplier | 0.000669    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.71        |
|    n_updates             | 9670        |
|    policy_gradient_loss  | 0.0053      |
|    std                   | 0.278       |
|    value_loss            | 1.56        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.27659804 |
| rollout/                 |             |
|    ep_len_mean           | 44.9        |
|    ep_rew_mean           | -24.2       |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 38          |
|    time_elapsed          | 1052        |
|    total_timesteps       | 1984512     |
| train/                   |             |
|    approx_kl             | 0.036772355 |
|    clip_fraction         | 0.213       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.23        |
|    cost_value_loss       | 4.25        |
|    cost_values           | 1.79        |
|    entropy               | 0.6         |
|    entropy_loss          | 0.6         |
|    explained_variance    | 0.972       |
|    lagrangian_multiplier | 0.0013      |
|    learning_rate         | 0.0003      |
|    loss                  | 2.34        |
|    n_updates             | 9680        |
|    policy_gradient_loss  | 0.0164      |
|    std                   | 0.278       |
|    value_loss            | 1.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.8         |
| reward                   | -0.6272341  |
| rollout/                 |             |
|    ep_len_mean           | 45.5        |
|    ep_rew_mean           | -23.4       |
| time/                    |             |
|    fps                   | 74          |
|    iterations            | 39          |
|    time_elapsed          | 1078        |
|    total_timesteps       | 1986560     |
| train/                   |             |
|    approx_kl             | 0.033107772 |
|    clip_fraction         | 0.191       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.22        |
|    cost_value_loss       | 4.43        |
|    cost_values           | 1.74        |
|    entropy               | 0.61        |
|    entropy_loss          | 0.604       |
|    explained_variance    | 0.972       |
|    lagrangian_multiplier | 0.00196     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.25        |
|    n_updates             | 9690        |
|    policy_gradient_loss  | 0.0136      |
|    std                   | 0.277       |
|    value_loss            | 1.07        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.99        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.99        |
| reward                   | -0.3660897  |
| rollout/                 |             |
|    ep_len_mean           | 45.6        |
|    ep_rew_mean           | -22.9       |
| time/                    |             |
|    fps                   | 74          |
|    iterations            | 40          |
|    time_elapsed          | 1104        |
|    total_timesteps       | 1988608     |
| train/                   |             |
|    approx_kl             | 0.013722806 |
|    clip_fraction         | 0.152       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.41        |
|    cost_value_loss       | 5.18        |
|    cost_values           | 1.74        |
|    entropy               | 0.621       |
|    entropy_loss          | 0.615       |
|    explained_variance    | 0.957       |
|    lagrangian_multiplier | 0.000374    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.02        |
|    n_updates             | 9700        |
|    policy_gradient_loss  | 0.00898     |
|    std                   | 0.274       |
|    value_loss            | 1.42        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.61875564 |
| rollout/                 |             |
|    ep_len_mean           | 45.6        |
|    ep_rew_mean           | -23.4       |
| time/                    |             |
|    fps                   | 74          |
|    iterations            | 41          |
|    time_elapsed          | 1129        |
|    total_timesteps       | 1990656     |
| train/                   |             |
|    approx_kl             | 0.06235019  |
|    clip_fraction         | 0.25        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.31        |
|    cost_value_loss       | 4.69        |
|    cost_values           | 1.73        |
|    entropy               | 0.621       |
|    entropy_loss          | 0.623       |
|    explained_variance    | 0.972       |
|    lagrangian_multiplier | 0.000789    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.71        |
|    n_updates             | 9710        |
|    policy_gradient_loss  | 0.0146      |
|    std                   | 0.275       |
|    value_loss            | 1.04        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.38920814 |
| rollout/                 |             |
|    ep_len_mean           | 47.9        |
|    ep_rew_mean           | -24.4       |
| time/                    |             |
|    fps                   | 74          |
|    iterations            | 42          |
|    time_elapsed          | 1155        |
|    total_timesteps       | 1992704     |
| train/                   |             |
|    approx_kl             | 0.02893992  |
|    clip_fraction         | 0.209       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.57        |
|    cost_value_loss       | 6.19        |
|    cost_values           | 1.69        |
|    entropy               | 0.627       |
|    entropy_loss          | 0.623       |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0.000934    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.1         |
|    n_updates             | 9720        |
|    policy_gradient_loss  | 0.00855     |
|    std                   | 0.274       |
|    value_loss            | 1.03        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3320009  |
| rollout/                 |             |
|    ep_len_mean           | 47.9        |
|    ep_rew_mean           | -24.4       |
| time/                    |             |
|    fps                   | 74          |
|    iterations            | 43          |
|    time_elapsed          | 1180        |
|    total_timesteps       | 1994752     |
| train/                   |             |
|    approx_kl             | 0.012009098 |
|    clip_fraction         | 0.173       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.42        |
|    cost_value_loss       | 5.49        |
|    cost_values           | 1.72        |
|    entropy               | 0.628       |
|    entropy_loss          | 0.629       |
|    explained_variance    | 0.963       |
|    lagrangian_multiplier | 0.000743    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.79        |
|    n_updates             | 9730        |
|    policy_gradient_loss  | 0.00715     |
|    std                   | 0.273       |
|    value_loss            | 1.47        |
------------------------------------------
------------------------------------------
| avg_speed                | 5           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5           |
| reward                   | -0.536711   |
| rollout/                 |             |
|    ep_len_mean           | 46.2        |
|    ep_rew_mean           | -23.8       |
| time/                    |             |
|    fps                   | 74          |
|    iterations            | 44          |
|    time_elapsed          | 1205        |
|    total_timesteps       | 1996800     |
| train/                   |             |
|    approx_kl             | 0.016118594 |
|    clip_fraction         | 0.189       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.35        |
|    cost_value_loss       | 4.58        |
|    cost_values           | 1.76        |
|    entropy               | 0.638       |
|    entropy_loss          | 0.631       |
|    explained_variance    | 0.969       |
|    lagrangian_multiplier | 0.000598    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.58        |
|    n_updates             | 9740        |
|    policy_gradient_loss  | 0.00637     |
|    std                   | 0.272       |
|    value_loss            | 1.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.7641342  |
| rollout/                 |             |
|    ep_len_mean           | 44.6        |
|    ep_rew_mean           | -23.4       |
| time/                    |             |
|    fps                   | 74          |
|    iterations            | 45          |
|    time_elapsed          | 1230        |
|    total_timesteps       | 1998848     |
| train/                   |             |
|    approx_kl             | 0.018911485 |
|    clip_fraction         | 0.167       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.34        |
|    cost_value_loss       | 4.75        |
|    cost_values           | 1.74        |
|    entropy               | 0.649       |
|    entropy_loss          | 0.644       |
|    explained_variance    | 0.967       |
|    lagrangian_multiplier | 0.00174     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.41        |
|    n_updates             | 9750        |
|    policy_gradient_loss  | 0.00476     |
|    std                   | 0.27        |
|    value_loss            | 1.21        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.43392125 |
| rollout/                 |             |
|    ep_len_mean           | 43.6        |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 74          |
|    iterations            | 46          |
|    time_elapsed          | 1257        |
|    total_timesteps       | 2000896     |
| train/                   |             |
|    approx_kl             | 0.019915976 |
|    clip_fraction         | 0.217       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.38        |
|    cost_value_loss       | 4.97        |
|    cost_values           | 1.7         |
|    entropy               | 0.658       |
|    entropy_loss          | 0.653       |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0.00177     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.33        |
|    n_updates             | 9760        |
|    policy_gradient_loss  | 0.0119      |
|    std                   | 0.268       |
|    value_loss            | 0.736       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.2         |
| reward                   | -0.2316899  |
| rollout/                 |             |
|    ep_len_mean           | 45          |
|    ep_rew_mean           | -23.5       |
| time/                    |             |
|    fps                   | 74          |
|    iterations            | 47          |
|    time_elapsed          | 1285        |
|    total_timesteps       | 2002944     |
| train/                   |             |
|    approx_kl             | 0.033794682 |
|    clip_fraction         | 0.226       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.28        |
|    cost_value_loss       | 4.55        |
|    cost_values           | 1.7         |
|    entropy               | 0.66        |
|    entropy_loss          | 0.659       |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0.00229     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.19        |
|    n_updates             | 9770        |
|    policy_gradient_loss  | 0.00909     |
|    std                   | 0.267       |
|    value_loss            | 0.692       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.84149927 |
| rollout/                 |             |
|    ep_len_mean           | 46.9        |
|    ep_rew_mean           | -23.9       |
| time/                    |             |
|    fps                   | 74          |
|    iterations            | 48          |
|    time_elapsed          | 1313        |
|    total_timesteps       | 2004992     |
| train/                   |             |
|    approx_kl             | 0.021020917 |
|    clip_fraction         | 0.223       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.15        |
|    cost_value_loss       | 4.68        |
|    cost_values           | 1.63        |
|    entropy               | 0.652       |
|    entropy_loss          | 0.657       |
|    explained_variance    | 0.966       |
|    lagrangian_multiplier | 0.00122     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.48        |
|    n_updates             | 9780        |
|    policy_gradient_loss  | 0.0124      |
|    std                   | 0.268       |
|    value_loss            | 1.24        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.32084823 |
| rollout/                 |             |
|    ep_len_mean           | 47.9        |
|    ep_rew_mean           | -23.8       |
| time/                    |             |
|    fps                   | 74          |
|    iterations            | 49          |
|    time_elapsed          | 1346        |
|    total_timesteps       | 2007040     |
| train/                   |             |
|    approx_kl             | 0.012457227 |
|    clip_fraction         | 0.159       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.17        |
|    cost_value_loss       | 4.67        |
|    cost_values           | 1.65        |
|    entropy               | 0.649       |
|    entropy_loss          | 0.65        |
|    explained_variance    | 0.957       |
|    lagrangian_multiplier | 0.00149     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.59        |
|    n_updates             | 9790        |
|    policy_gradient_loss  | 0.00947     |
|    std                   | 0.269       |
|    value_loss            | 1.52        |
------------------------------------------
------------------------------------
| avg_speed          | 0.4         |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.4         |
| reward             | -0.82016647 |
| rollout/           |             |
|    ep_len_mean     | 46.6        |
|    ep_rew_mean     | -23.6       |
| time/              |             |
|    fps             | 55          |
|    iterations      | 1           |
|    time_elapsed    | 37          |
|    total_timesteps | 2009088     |
------------------------------------
-----------------------------------------
| avg_speed                | 3.4        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 3.4        |
| reward                   | -0.6456249 |
| rollout/                 |            |
|    ep_len_mean           | 45.7       |
|    ep_rew_mean           | -24        |
| time/                    |            |
|    fps                   | 52         |
|    iterations            | 2          |
|    time_elapsed          | 77         |
|    total_timesteps       | 2011136    |
| train/                   |            |
|    approx_kl             | 0.04488325 |
|    clip_fraction         | 0.235      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.21       |
|    cost_value_loss       | 4.46       |
|    cost_values           | 1.66       |
|    entropy               | 0.657      |
|    entropy_loss          | 0.656      |
|    explained_variance    | 0.962      |
|    lagrangian_multiplier | 0.000164   |
|    learning_rate         | 0.0003     |
|    loss                  | 2.98       |
|    n_updates             | 9810       |
|    policy_gradient_loss  | 0.0183     |
|    std                   | 0.268      |
|    value_loss            | 1.46       |
-----------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.47431508 |
| rollout/                 |             |
|    ep_len_mean           | 44.6        |
|    ep_rew_mean           | -23.7       |
| time/                    |             |
|    fps                   | 56          |
|    iterations            | 3           |
|    time_elapsed          | 109         |
|    total_timesteps       | 2013184     |
| train/                   |             |
|    approx_kl             | 0.0197973   |
|    clip_fraction         | 0.21        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.25        |
|    cost_value_loss       | 4.85        |
|    cost_values           | 1.63        |
|    entropy               | 0.655       |
|    entropy_loss          | 0.656       |
|    explained_variance    | 0.965       |
|    lagrangian_multiplier | 0.000375    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.83        |
|    n_updates             | 9820        |
|    policy_gradient_loss  | 0.0117      |
|    std                   | 0.268       |
|    value_loss            | 1.35        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.4205385  |
| rollout/                 |             |
|    ep_len_mean           | 45          |
|    ep_rew_mean           | -23.4       |
| time/                    |             |
|    fps                   | 55          |
|    iterations            | 4           |
|    time_elapsed          | 146         |
|    total_timesteps       | 2015232     |
| train/                   |             |
|    approx_kl             | 0.015659194 |
|    clip_fraction         | 0.183       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.06        |
|    cost_value_loss       | 4.22        |
|    cost_values           | 1.61        |
|    entropy               | 0.653       |
|    entropy_loss          | 0.654       |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0.000906    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.21        |
|    n_updates             | 9830        |
|    policy_gradient_loss  | 0.00728     |
|    std                   | 0.269       |
|    value_loss            | 0.971       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.639715   |
| rollout/                 |             |
|    ep_len_mean           | 46.3        |
|    ep_rew_mean           | -24.2       |
| time/                    |             |
|    fps                   | 56          |
|    iterations            | 5           |
|    time_elapsed          | 182         |
|    total_timesteps       | 2017280     |
| train/                   |             |
|    approx_kl             | 0.021526985 |
|    clip_fraction         | 0.171       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.1         |
|    cost_value_loss       | 4.46        |
|    cost_values           | 1.6         |
|    entropy               | 0.655       |
|    entropy_loss          | 0.654       |
|    explained_variance    | 0.971       |
|    lagrangian_multiplier | 0.00337     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.16        |
|    n_updates             | 9840        |
|    policy_gradient_loss  | 0.00327     |
|    std                   | 0.269       |
|    value_loss            | 1.06        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.8         |
| reward                   | -0.5719996  |
| rollout/                 |             |
|    ep_len_mean           | 45.5        |
|    ep_rew_mean           | -24.3       |
| time/                    |             |
|    fps                   | 58          |
|    iterations            | 6           |
|    time_elapsed          | 209         |
|    total_timesteps       | 2019328     |
| train/                   |             |
|    approx_kl             | 0.023460934 |
|    clip_fraction         | 0.21        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.33        |
|    cost_value_loss       | 5.52        |
|    cost_values           | 1.57        |
|    entropy               | 0.656       |
|    entropy_loss          | 0.655       |
|    explained_variance    | 0.968       |
|    lagrangian_multiplier | 0.000465    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.03        |
|    n_updates             | 9850        |
|    policy_gradient_loss  | 0.011       |
|    std                   | 0.269       |
|    value_loss            | 1.28        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3058722  |
| rollout/                 |             |
|    ep_len_mean           | 44.1        |
|    ep_rew_mean           | -23.2       |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 7           |
|    time_elapsed          | 238         |
|    total_timesteps       | 2021376     |
| train/                   |             |
|    approx_kl             | 0.030323409 |
|    clip_fraction         | 0.254       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.18        |
|    cost_value_loss       | 4.54        |
|    cost_values           | 1.63        |
|    entropy               | 0.658       |
|    entropy_loss          | 0.658       |
|    explained_variance    | 0.956       |
|    lagrangian_multiplier | 0.000679    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.67        |
|    n_updates             | 9860        |
|    policy_gradient_loss  | 0.00957     |
|    std                   | 0.269       |
|    value_loss            | 1.67        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.3920657  |
| rollout/                 |             |
|    ep_len_mean           | 43.6        |
|    ep_rew_mean           | -23.1       |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 8           |
|    time_elapsed          | 269         |
|    total_timesteps       | 2023424     |
| train/                   |             |
|    approx_kl             | 0.019004509 |
|    clip_fraction         | 0.183       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.23        |
|    cost_value_loss       | 4.48        |
|    cost_values           | 1.63        |
|    entropy               | 0.661       |
|    entropy_loss          | 0.659       |
|    explained_variance    | 0.951       |
|    lagrangian_multiplier | 0.000944    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.6         |
|    n_updates             | 9870        |
|    policy_gradient_loss  | 0.0103      |
|    std                   | 0.269       |
|    value_loss            | 1.65        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.24516545 |
| rollout/                 |             |
|    ep_len_mean           | 45.4        |
|    ep_rew_mean           | -23.8       |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 9           |
|    time_elapsed          | 297         |
|    total_timesteps       | 2025472     |
| train/                   |             |
|    approx_kl             | 0.015773447 |
|    clip_fraction         | 0.178       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.22        |
|    cost_value_loss       | 4.63        |
|    cost_values           | 1.62        |
|    entropy               | 0.671       |
|    entropy_loss          | 0.666       |
|    explained_variance    | 0.973       |
|    lagrangian_multiplier | 0.000743    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.54        |
|    n_updates             | 9880        |
|    policy_gradient_loss  | 0.0106      |
|    std                   | 0.267       |
|    value_loss            | 1.04        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.7829959  |
| rollout/                 |             |
|    ep_len_mean           | 45.5        |
|    ep_rew_mean           | -23.6       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 10          |
|    time_elapsed          | 320         |
|    total_timesteps       | 2027520     |
| train/                   |             |
|    approx_kl             | 0.023070306 |
|    clip_fraction         | 0.232       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.26        |
|    cost_value_loss       | 4.68        |
|    cost_values           | 1.62        |
|    entropy               | 0.672       |
|    entropy_loss          | 0.673       |
|    explained_variance    | 0.947       |
|    lagrangian_multiplier | 9.05e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.79        |
|    n_updates             | 9890        |
|    policy_gradient_loss  | 0.0091      |
|    std                   | 0.268       |
|    value_loss            | 1.62        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.75965947 |
| rollout/                 |             |
|    ep_len_mean           | 47          |
|    ep_rew_mean           | -24.3       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 11          |
|    time_elapsed          | 344         |
|    total_timesteps       | 2029568     |
| train/                   |             |
|    approx_kl             | 0.03057066  |
|    clip_fraction         | 0.179       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.22        |
|    cost_value_loss       | 4.57        |
|    cost_values           | 1.7         |
|    entropy               | 0.676       |
|    entropy_loss          | 0.673       |
|    explained_variance    | 0.972       |
|    lagrangian_multiplier | 0.00207     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.2         |
|    n_updates             | 9900        |
|    policy_gradient_loss  | 0.0121      |
|    std                   | 0.267       |
|    value_loss            | 1.02        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.43675205 |
| rollout/                 |             |
|    ep_len_mean           | 46.2        |
|    ep_rew_mean           | -24.5       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 12          |
|    time_elapsed          | 373         |
|    total_timesteps       | 2031616     |
| train/                   |             |
|    approx_kl             | 0.027397312 |
|    clip_fraction         | 0.243       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.23        |
|    cost_value_loss       | 4.54        |
|    cost_values           | 1.66        |
|    entropy               | 0.677       |
|    entropy_loss          | 0.677       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0.000303    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.58        |
|    n_updates             | 9910        |
|    policy_gradient_loss  | 0.00784     |
|    std                   | 0.267       |
|    value_loss            | 0.928       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 1           |
| max_speed                | 8           |
| reward                   | -0.10026409 |
| rollout/                 |             |
|    ep_len_mean           | 46.2        |
|    ep_rew_mean           | -24.1       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 13          |
|    time_elapsed          | 401         |
|    total_timesteps       | 2033664     |
| train/                   |             |
|    approx_kl             | 0.02664561  |
|    clip_fraction         | 0.202       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.31        |
|    cost_value_loss       | 5.12        |
|    cost_values           | 1.65        |
|    entropy               | 0.678       |
|    entropy_loss          | 0.678       |
|    explained_variance    | 0.972       |
|    lagrangian_multiplier | 0.00221     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.44        |
|    n_updates             | 9920        |
|    policy_gradient_loss  | 0.0157      |
|    std                   | 0.268       |
|    value_loss            | 1.16        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.7681538  |
| rollout/                 |             |
|    ep_len_mean           | 45.5        |
|    ep_rew_mean           | -24         |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 14          |
|    time_elapsed          | 425         |
|    total_timesteps       | 2035712     |
| train/                   |             |
|    approx_kl             | 0.039057653 |
|    clip_fraction         | 0.162       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.3         |
|    cost_value_loss       | 5.24        |
|    cost_values           | 1.61        |
|    entropy               | 0.678       |
|    entropy_loss          | 0.678       |
|    explained_variance    | 0.95        |
|    lagrangian_multiplier | 0.00224     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.61        |
|    n_updates             | 9930        |
|    policy_gradient_loss  | 0.00364     |
|    std                   | 0.269       |
|    value_loss            | 1.71        |
------------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.65121126 |
| rollout/                 |             |
|    ep_len_mean           | 44.5        |
|    ep_rew_mean           | -23.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 15          |
|    time_elapsed          | 448         |
|    total_timesteps       | 2037760     |
| train/                   |             |
|    approx_kl             | 0.019145193 |
|    clip_fraction         | 0.188       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.05        |
|    cost_value_loss       | 4.3         |
|    cost_values           | 1.6         |
|    entropy               | 0.682       |
|    entropy_loss          | 0.68        |
|    explained_variance    | 0.967       |
|    lagrangian_multiplier | 0.00105     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.51        |
|    n_updates             | 9940        |
|    policy_gradient_loss  | 0.0154      |
|    std                   | 0.268       |
|    value_loss            | 1.28        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.8          |
| reward                   | -0.82896537  |
| rollout/                 |              |
|    ep_len_mean           | 44.3         |
|    ep_rew_mean           | -23.4        |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 16           |
|    time_elapsed          | 472          |
|    total_timesteps       | 2039808      |
| train/                   |              |
|    approx_kl             | 0.0117866695 |
|    clip_fraction         | 0.166        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.25         |
|    cost_value_loss       | 4.8          |
|    cost_values           | 1.59         |
|    entropy               | 0.69         |
|    entropy_loss          | 0.685        |
|    explained_variance    | 0.97         |
|    lagrangian_multiplier | 0.00049      |
|    learning_rate         | 0.0003       |
|    loss                  | 2.67         |
|    n_updates             | 9950         |
|    policy_gradient_loss  | 0.00702      |
|    std                   | 0.268        |
|    value_loss            | 1.14         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.58874846 |
| rollout/                 |             |
|    ep_len_mean           | 45.8        |
|    ep_rew_mean           | -23.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 17          |
|    time_elapsed          | 506         |
|    total_timesteps       | 2041856     |
| train/                   |             |
|    approx_kl             | 0.02647946  |
|    clip_fraction         | 0.215       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.3         |
|    cost_value_loss       | 4.96        |
|    cost_values           | 1.62        |
|    entropy               | 0.684       |
|    entropy_loss          | 0.688       |
|    explained_variance    | 0.962       |
|    lagrangian_multiplier | 0.0021      |
|    learning_rate         | 0.0003      |
|    loss                  | 2.4         |
|    n_updates             | 9960        |
|    policy_gradient_loss  | 0.00831     |
|    std                   | 0.269       |
|    value_loss            | 1.3         |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.85987407 |
| rollout/                 |             |
|    ep_len_mean           | 44.5        |
|    ep_rew_mean           | -23.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 18          |
|    time_elapsed          | 539         |
|    total_timesteps       | 2043904     |
| train/                   |             |
|    approx_kl             | 0.036979035 |
|    clip_fraction         | 0.187       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.4         |
|    cost_value_loss       | 5.38        |
|    cost_values           | 1.64        |
|    entropy               | 0.684       |
|    entropy_loss          | 0.683       |
|    explained_variance    | 0.957       |
|    lagrangian_multiplier | 0.00124     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.82        |
|    n_updates             | 9970        |
|    policy_gradient_loss  | 0.00713     |
|    std                   | 0.268       |
|    value_loss            | 1.53        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.33092505 |
| rollout/                 |             |
|    ep_len_mean           | 43.5        |
|    ep_rew_mean           | -23         |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 19          |
|    time_elapsed          | 576         |
|    total_timesteps       | 2045952     |
| train/                   |             |
|    approx_kl             | 0.055423215 |
|    clip_fraction         | 0.216       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.27        |
|    cost_value_loss       | 4.73        |
|    cost_values           | 1.65        |
|    entropy               | 0.683       |
|    entropy_loss          | 0.685       |
|    explained_variance    | 0.971       |
|    lagrangian_multiplier | 0.000775    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.57        |
|    n_updates             | 9980        |
|    policy_gradient_loss  | 0.0115      |
|    std                   | 0.268       |
|    value_loss            | 1.12        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.84399563 |
| rollout/                 |             |
|    ep_len_mean           | 43.5        |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 20          |
|    time_elapsed          | 612         |
|    total_timesteps       | 2048000     |
| train/                   |             |
|    approx_kl             | 0.016417556 |
|    clip_fraction         | 0.194       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.21        |
|    cost_value_loss       | 4.77        |
|    cost_values           | 1.59        |
|    entropy               | 0.672       |
|    entropy_loss          | 0.678       |
|    explained_variance    | 0.964       |
|    lagrangian_multiplier | 0.00142     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.41        |
|    n_updates             | 9990        |
|    policy_gradient_loss  | 0.00812     |
|    std                   | 0.27        |
|    value_loss            | 1.29        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.2         |
| reward                   | -0.13246678 |
| rollout/                 |             |
|    ep_len_mean           | 44.4        |
|    ep_rew_mean           | -23.7       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 21          |
|    time_elapsed          | 650         |
|    total_timesteps       | 2050048     |
| train/                   |             |
|    approx_kl             | 0.038201533 |
|    clip_fraction         | 0.242       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.24        |
|    cost_value_loss       | 4.68        |
|    cost_values           | 1.61        |
|    entropy               | 0.671       |
|    entropy_loss          | 0.671       |
|    explained_variance    | 0.97        |
|    lagrangian_multiplier | 0.000556    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.7         |
|    n_updates             | 10000       |
|    policy_gradient_loss  | 0.00831     |
|    std                   | 0.27        |
|    value_loss            | 1.14        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.6         |
| reward                   | -0.5865744  |
| rollout/                 |             |
|    ep_len_mean           | 45.5        |
|    ep_rew_mean           | -23.9       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 22          |
|    time_elapsed          | 685         |
|    total_timesteps       | 2052096     |
| train/                   |             |
|    approx_kl             | 0.036286704 |
|    clip_fraction         | 0.19        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.21        |
|    cost_value_loss       | 4.81        |
|    cost_values           | 1.58        |
|    entropy               | 0.674       |
|    entropy_loss          | 0.673       |
|    explained_variance    | 0.967       |
|    lagrangian_multiplier | 0.00223     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.24        |
|    n_updates             | 10010       |
|    policy_gradient_loss  | 0.0131      |
|    std                   | 0.27        |
|    value_loss            | 1.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.6193789  |
| rollout/                 |             |
|    ep_len_mean           | 44.7        |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 23          |
|    time_elapsed          | 720         |
|    total_timesteps       | 2054144     |
| train/                   |             |
|    approx_kl             | 0.025580546 |
|    clip_fraction         | 0.2         |
|    clip_range            | 0.2         |
|    cost_returns          | 3.17        |
|    cost_value_loss       | 4.79        |
|    cost_values           | 1.56        |
|    entropy               | 0.679       |
|    entropy_loss          | 0.677       |
|    explained_variance    | 0.953       |
|    lagrangian_multiplier | 0.00263     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.24        |
|    n_updates             | 10020       |
|    policy_gradient_loss  | 0.01        |
|    std                   | 0.268       |
|    value_loss            | 1.62        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.62663627 |
| rollout/                 |             |
|    ep_len_mean           | 44.2        |
|    ep_rew_mean           | -23         |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 24          |
|    time_elapsed          | 753         |
|    total_timesteps       | 2056192     |
| train/                   |             |
|    approx_kl             | 0.046159554 |
|    clip_fraction         | 0.214       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.17        |
|    cost_value_loss       | 4.84        |
|    cost_values           | 1.58        |
|    entropy               | 0.678       |
|    entropy_loss          | 0.68        |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0.000624    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.61        |
|    n_updates             | 10030       |
|    policy_gradient_loss  | 0.0124      |
|    std                   | 0.268       |
|    value_loss            | 0.899       |
------------------------------------------
------------------------------------------
| avg_speed                | 8.06        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.06        |
| reward                   | -0.21571614 |
| rollout/                 |             |
|    ep_len_mean           | 45.7        |
|    ep_rew_mean           | -23.4       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 25          |
|    time_elapsed          | 787         |
|    total_timesteps       | 2058240     |
| train/                   |             |
|    approx_kl             | 0.022678617 |
|    clip_fraction         | 0.178       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.27        |
|    cost_value_loss       | 4.91        |
|    cost_values           | 1.58        |
|    entropy               | 0.677       |
|    entropy_loss          | 0.677       |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0.000818    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.63        |
|    n_updates             | 10040       |
|    policy_gradient_loss  | 0.00788     |
|    std                   | 0.269       |
|    value_loss            | 0.933       |
------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.33762747 |
| rollout/                 |             |
|    ep_len_mean           | 45.1        |
|    ep_rew_mean           | -23.5       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 26          |
|    time_elapsed          | 822         |
|    total_timesteps       | 2060288     |
| train/                   |             |
|    approx_kl             | 0.024438959 |
|    clip_fraction         | 0.223       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.26        |
|    cost_value_loss       | 5.13        |
|    cost_values           | 1.59        |
|    entropy               | 0.682       |
|    entropy_loss          | 0.68        |
|    explained_variance    | 0.97        |
|    lagrangian_multiplier | 0.00127     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.53        |
|    n_updates             | 10050       |
|    policy_gradient_loss  | 0.00997     |
|    std                   | 0.268       |
|    value_loss            | 1.06        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.4         |
| reward                   | -0.27731064 |
| rollout/                 |             |
|    ep_len_mean           | 45.5        |
|    ep_rew_mean           | -23.5       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 27          |
|    time_elapsed          | 855         |
|    total_timesteps       | 2062336     |
| train/                   |             |
|    approx_kl             | 0.030946553 |
|    clip_fraction         | 0.21        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.07        |
|    cost_value_loss       | 4.09        |
|    cost_values           | 1.58        |
|    entropy               | 0.688       |
|    entropy_loss          | 0.685       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0.000665    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.26        |
|    n_updates             | 10060       |
|    policy_gradient_loss  | 0.0127      |
|    std                   | 0.267       |
|    value_loss            | 0.9         |
------------------------------------------
-----------------------------------------
| avg_speed                | 2          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 2          |
| reward                   | -0.7629622 |
| rollout/                 |            |
|    ep_len_mean           | 46.4       |
|    ep_rew_mean           | -23.6      |
| time/                    |            |
|    fps                   | 64         |
|    iterations            | 28         |
|    time_elapsed          | 886        |
|    total_timesteps       | 2064384    |
| train/                   |            |
|    approx_kl             | 0.05194394 |
|    clip_fraction         | 0.201      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.16       |
|    cost_value_loss       | 4.5        |
|    cost_values           | 1.58       |
|    entropy               | 0.694      |
|    entropy_loss          | 0.692      |
|    explained_variance    | 0.967      |
|    lagrangian_multiplier | 0.000553   |
|    learning_rate         | 0.0003     |
|    loss                  | 2.62       |
|    n_updates             | 10070      |
|    policy_gradient_loss  | 0.00929    |
|    std                   | 0.266      |
|    value_loss            | 1.14       |
-----------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.32409373 |
| rollout/                 |             |
|    ep_len_mean           | 46.2        |
|    ep_rew_mean           | -23.6       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 29          |
|    time_elapsed          | 916         |
|    total_timesteps       | 2066432     |
| train/                   |             |
|    approx_kl             | 0.018663907 |
|    clip_fraction         | 0.178       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.29        |
|    cost_value_loss       | 5.08        |
|    cost_values           | 1.6         |
|    entropy               | 0.7         |
|    entropy_loss          | 0.696       |
|    explained_variance    | 0.97        |
|    lagrangian_multiplier | 0.0019      |
|    learning_rate         | 0.0003      |
|    loss                  | 2.39        |
|    n_updates             | 10080       |
|    policy_gradient_loss  | 0.00857     |
|    std                   | 0.266       |
|    value_loss            | 1.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.8146281  |
| rollout/                 |             |
|    ep_len_mean           | 45.7        |
|    ep_rew_mean           | -23.8       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 30          |
|    time_elapsed          | 947         |
|    total_timesteps       | 2068480     |
| train/                   |             |
|    approx_kl             | 0.022983707 |
|    clip_fraction         | 0.235       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.16        |
|    cost_value_loss       | 4.38        |
|    cost_values           | 1.59        |
|    entropy               | 0.71        |
|    entropy_loss          | 0.705       |
|    explained_variance    | 0.96        |
|    lagrangian_multiplier | 0.000235    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.87        |
|    n_updates             | 10090       |
|    policy_gradient_loss  | 0.0191      |
|    std                   | 0.265       |
|    value_loss            | 1.44        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.2         |
| reward                   | -0.335265   |
| rollout/                 |             |
|    ep_len_mean           | 45.2        |
|    ep_rew_mean           | -24.1       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 31          |
|    time_elapsed          | 981         |
|    total_timesteps       | 2070528     |
| train/                   |             |
|    approx_kl             | 0.023321927 |
|    clip_fraction         | 0.202       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.15        |
|    cost_value_loss       | 4.79        |
|    cost_values           | 1.55        |
|    entropy               | 0.716       |
|    entropy_loss          | 0.714       |
|    explained_variance    | 0.973       |
|    lagrangian_multiplier | 0.00213     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.31        |
|    n_updates             | 10100       |
|    policy_gradient_loss  | 0.0125      |
|    std                   | 0.264       |
|    value_loss            | 1.03        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 1           |
| max_speed                | 8           |
| reward                   | -0.11485345 |
| rollout/                 |             |
|    ep_len_mean           | 45          |
|    ep_rew_mean           | -23.6       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 32          |
|    time_elapsed          | 1017        |
|    total_timesteps       | 2072576     |
| train/                   |             |
|    approx_kl             | 0.022607159 |
|    clip_fraction         | 0.211       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.15        |
|    cost_value_loss       | 4.72        |
|    cost_values           | 1.53        |
|    entropy               | 0.714       |
|    entropy_loss          | 0.716       |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0.00114     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.42        |
|    n_updates             | 10110       |
|    policy_gradient_loss  | 0.0107      |
|    std                   | 0.265       |
|    value_loss            | 0.913       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.6         |
| reward                   | -0.8390885  |
| rollout/                 |             |
|    ep_len_mean           | 45.7        |
|    ep_rew_mean           | -23.6       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 33          |
|    time_elapsed          | 1049        |
|    total_timesteps       | 2074624     |
| train/                   |             |
|    approx_kl             | 0.030771868 |
|    clip_fraction         | 0.203       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.17        |
|    cost_value_loss       | 4.66        |
|    cost_values           | 1.54        |
|    entropy               | 0.717       |
|    entropy_loss          | 0.715       |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0.00158     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.38        |
|    n_updates             | 10120       |
|    policy_gradient_loss  | 0.0133      |
|    std                   | 0.265       |
|    value_loss            | 0.938       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.140873   |
| rollout/                 |             |
|    ep_len_mean           | 46.6        |
|    ep_rew_mean           | -24.1       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 34          |
|    time_elapsed          | 1073        |
|    total_timesteps       | 2076672     |
| train/                   |             |
|    approx_kl             | 0.018579733 |
|    clip_fraction         | 0.207       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.23        |
|    cost_value_loss       | 5.03        |
|    cost_values           | 1.54        |
|    entropy               | 0.711       |
|    entropy_loss          | 0.715       |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0.000814    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.65        |
|    n_updates             | 10130       |
|    policy_gradient_loss  | 0.00875     |
|    std                   | 0.266       |
|    value_loss            | 0.96        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.20940647 |
| rollout/                 |             |
|    ep_len_mean           | 46.4        |
|    ep_rew_mean           | -24.1       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 35          |
|    time_elapsed          | 1096        |
|    total_timesteps       | 2078720     |
| train/                   |             |
|    approx_kl             | 0.038397957 |
|    clip_fraction         | 0.23        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.18        |
|    cost_value_loss       | 4.89        |
|    cost_values           | 1.57        |
|    entropy               | 0.711       |
|    entropy_loss          | 0.71        |
|    explained_variance    | 0.956       |
|    lagrangian_multiplier | 0.00209     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.32        |
|    n_updates             | 10140       |
|    policy_gradient_loss  | 0.0109      |
|    std                   | 0.265       |
|    value_loss            | 1.42        |
------------------------------------------
-----------------------------------------
| avg_speed                | 1.4        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 1.4        |
| reward                   | -0.642715  |
| rollout/                 |            |
|    ep_len_mean           | 47.9       |
|    ep_rew_mean           | -24.7      |
| time/                    |            |
|    fps                   | 65         |
|    iterations            | 36         |
|    time_elapsed          | 1120       |
|    total_timesteps       | 2080768    |
| train/                   |            |
|    approx_kl             | 0.03861318 |
|    clip_fraction         | 0.208      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.02       |
|    cost_value_loss       | 4.5        |
|    cost_values           | 1.5        |
|    entropy               | 0.708      |
|    entropy_loss          | 0.71       |
|    explained_variance    | 0.952      |
|    lagrangian_multiplier | 0.00052    |
|    learning_rate         | 0.0003     |
|    loss                  | 2.83       |
|    n_updates             | 10150      |
|    policy_gradient_loss  | 0.0111     |
|    std                   | 0.265      |
|    value_loss            | 1.87       |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.59357274 |
| rollout/                 |             |
|    ep_len_mean           | 46.6        |
|    ep_rew_mean           | -24.1       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 37          |
|    time_elapsed          | 1148        |
|    total_timesteps       | 2082816     |
| train/                   |             |
|    approx_kl             | 0.020273551 |
|    clip_fraction         | 0.229       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.13        |
|    cost_value_loss       | 4.8         |
|    cost_values           | 1.48        |
|    entropy               | 0.704       |
|    entropy_loss          | 0.706       |
|    explained_variance    | 0.915       |
|    lagrangian_multiplier | 0.000637    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.25        |
|    n_updates             | 10160       |
|    policy_gradient_loss  | 0.00873     |
|    std                   | 0.266       |
|    value_loss            | 2.82        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.8         |
| reward                   | -0.7240165  |
| rollout/                 |             |
|    ep_len_mean           | 43.8        |
|    ep_rew_mean           | -23.2       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 38          |
|    time_elapsed          | 1176        |
|    total_timesteps       | 2084864     |
| train/                   |             |
|    approx_kl             | 0.009936196 |
|    clip_fraction         | 0.184       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.19        |
|    cost_value_loss       | 4.7         |
|    cost_values           | 1.58        |
|    entropy               | 0.703       |
|    entropy_loss          | 0.703       |
|    explained_variance    | 0.929       |
|    lagrangian_multiplier | 0.000677    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.12        |
|    n_updates             | 10170       |
|    policy_gradient_loss  | 0.00761     |
|    std                   | 0.267       |
|    value_loss            | 2.48        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.6         |
| reward                   | -0.34381992 |
| rollout/                 |             |
|    ep_len_mean           | 43.9        |
|    ep_rew_mean           | -23.2       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 39          |
|    time_elapsed          | 1200        |
|    total_timesteps       | 2086912     |
| train/                   |             |
|    approx_kl             | 0.023377566 |
|    clip_fraction         | 0.212       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.94        |
|    cost_value_loss       | 3.63        |
|    cost_values           | 1.63        |
|    entropy               | 0.708       |
|    entropy_loss          | 0.707       |
|    explained_variance    | 0.963       |
|    lagrangian_multiplier | 0.00193     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.11        |
|    n_updates             | 10180       |
|    policy_gradient_loss  | 0.0134      |
|    std                   | 0.266       |
|    value_loss            | 1.36        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.7488243  |
| rollout/                 |             |
|    ep_len_mean           | 45.8        |
|    ep_rew_mean           | -23.8       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 40          |
|    time_elapsed          | 1227        |
|    total_timesteps       | 2088960     |
| train/                   |             |
|    approx_kl             | 0.017424833 |
|    clip_fraction         | 0.189       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.35        |
|    cost_value_loss       | 5.45        |
|    cost_values           | 1.56        |
|    entropy               | 0.713       |
|    entropy_loss          | 0.71        |
|    explained_variance    | 0.952       |
|    lagrangian_multiplier | 0.000249    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.4         |
|    n_updates             | 10190       |
|    policy_gradient_loss  | 0.0103      |
|    std                   | 0.265       |
|    value_loss            | 1.72        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.6         |
| reward                   | -0.51982754 |
| rollout/                 |             |
|    ep_len_mean           | 45.4        |
|    ep_rew_mean           | -23.9       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 41          |
|    time_elapsed          | 1262        |
|    total_timesteps       | 2091008     |
| train/                   |             |
|    approx_kl             | 0.042907994 |
|    clip_fraction         | 0.185       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.31        |
|    cost_value_loss       | 5.55        |
|    cost_values           | 1.57        |
|    entropy               | 0.715       |
|    entropy_loss          | 0.715       |
|    explained_variance    | 0.95        |
|    lagrangian_multiplier | 2.52e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.53        |
|    n_updates             | 10200       |
|    policy_gradient_loss  | 0.0133      |
|    std                   | 0.266       |
|    value_loss            | 1.8         |
------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.6328714  |
| rollout/                 |             |
|    ep_len_mean           | 44.4        |
|    ep_rew_mean           | -23.7       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 42          |
|    time_elapsed          | 1301        |
|    total_timesteps       | 2093056     |
| train/                   |             |
|    approx_kl             | 0.030942094 |
|    clip_fraction         | 0.247       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.16        |
|    cost_value_loss       | 4.77        |
|    cost_values           | 1.6         |
|    entropy               | 0.715       |
|    entropy_loss          | 0.714       |
|    explained_variance    | 0.965       |
|    lagrangian_multiplier | 0.000685    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.58        |
|    n_updates             | 10210       |
|    policy_gradient_loss  | 0.0196      |
|    std                   | 0.266       |
|    value_loss            | 1.27        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.76006764 |
| rollout/                 |             |
|    ep_len_mean           | 43.4        |
|    ep_rew_mean           | -23.2       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 43          |
|    time_elapsed          | 1335        |
|    total_timesteps       | 2095104     |
| train/                   |             |
|    approx_kl             | 0.022458    |
|    clip_fraction         | 0.243       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.09        |
|    cost_value_loss       | 4.38        |
|    cost_values           | 1.6         |
|    entropy               | 0.71        |
|    entropy_loss          | 0.713       |
|    explained_variance    | 0.966       |
|    lagrangian_multiplier | 0.00272     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.27        |
|    n_updates             | 10220       |
|    policy_gradient_loss  | 0.00992     |
|    std                   | 0.267       |
|    value_loss            | 1.33        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.2         |
| reward                   | -0.35523233 |
| rollout/                 |             |
|    ep_len_mean           | 44.3        |
|    ep_rew_mean           | -23.5       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 44          |
|    time_elapsed          | 1364        |
|    total_timesteps       | 2097152     |
| train/                   |             |
|    approx_kl             | 0.022295957 |
|    clip_fraction         | 0.181       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.11        |
|    cost_value_loss       | 4.34        |
|    cost_values           | 1.59        |
|    entropy               | 0.711       |
|    entropy_loss          | 0.711       |
|    explained_variance    | 0.961       |
|    lagrangian_multiplier | 0.000177    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.81        |
|    n_updates             | 10230       |
|    policy_gradient_loss  | 0.00992     |
|    std                   | 0.266       |
|    value_loss            | 1.34        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.7223119  |
| rollout/                 |             |
|    ep_len_mean           | 44.8        |
|    ep_rew_mean           | -23.8       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 45          |
|    time_elapsed          | 1393        |
|    total_timesteps       | 2099200     |
| train/                   |             |
|    approx_kl             | 0.036662217 |
|    clip_fraction         | 0.229       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.05        |
|    cost_value_loss       | 3.96        |
|    cost_values           | 1.61        |
|    entropy               | 0.713       |
|    entropy_loss          | 0.712       |
|    explained_variance    | 0.938       |
|    lagrangian_multiplier | 0.000224    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.81        |
|    n_updates             | 10240       |
|    policy_gradient_loss  | 0.0159      |
|    std                   | 0.266       |
|    value_loss            | 1.96        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.55508655 |
| rollout/                 |             |
|    ep_len_mean           | 43.6        |
|    ep_rew_mean           | -23.4       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 46          |
|    time_elapsed          | 1422        |
|    total_timesteps       | 2101248     |
| train/                   |             |
|    approx_kl             | 0.037798785 |
|    clip_fraction         | 0.191       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.21        |
|    cost_value_loss       | 4.59        |
|    cost_values           | 1.65        |
|    entropy               | 0.726       |
|    entropy_loss          | 0.719       |
|    explained_variance    | 0.953       |
|    lagrangian_multiplier | 0.000795    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.54        |
|    n_updates             | 10250       |
|    policy_gradient_loss  | 0.00682     |
|    std                   | 0.265       |
|    value_loss            | 1.62        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.33162677 |
| rollout/                 |             |
|    ep_len_mean           | 42.7        |
|    ep_rew_mean           | -23         |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 47          |
|    time_elapsed          | 1457        |
|    total_timesteps       | 2103296     |
| train/                   |             |
|    approx_kl             | 0.048664343 |
|    clip_fraction         | 0.167       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.22        |
|    cost_value_loss       | 4.6         |
|    cost_values           | 1.65        |
|    entropy               | 0.73        |
|    entropy_loss          | 0.729       |
|    explained_variance    | 0.97        |
|    lagrangian_multiplier | 0.000604    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.57        |
|    n_updates             | 10260       |
|    policy_gradient_loss  | 0.00485     |
|    std                   | 0.264       |
|    value_loss            | 1.14        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.83866847 |
| rollout/                 |             |
|    ep_len_mean           | 44.1        |
|    ep_rew_mean           | -23.1       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 48          |
|    time_elapsed          | 1489        |
|    total_timesteps       | 2105344     |
| train/                   |             |
|    approx_kl             | 0.024158385 |
|    clip_fraction         | 0.223       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.12        |
|    cost_value_loss       | 4.18        |
|    cost_values           | 1.67        |
|    entropy               | 0.73        |
|    entropy_loss          | 0.729       |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0.00126     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.49        |
|    n_updates             | 10270       |
|    policy_gradient_loss  | 0.0127      |
|    std                   | 0.264       |
|    value_loss            | 0.814       |
------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.5970982  |
| rollout/                 |             |
|    ep_len_mean           | 45.5        |
|    ep_rew_mean           | -23.7       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 49          |
|    time_elapsed          | 1525        |
|    total_timesteps       | 2107392     |
| train/                   |             |
|    approx_kl             | 0.027075063 |
|    clip_fraction         | 0.248       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.18        |
|    cost_value_loss       | 4.67        |
|    cost_values           | 1.61        |
|    entropy               | 0.732       |
|    entropy_loss          | 0.732       |
|    explained_variance    | 0.957       |
|    lagrangian_multiplier | 0.000805    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.67        |
|    n_updates             | 10280       |
|    policy_gradient_loss  | 0.0117      |
|    std                   | 0.265       |
|    value_loss            | 1.41        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ent-coefficient-ppol/1vjpjg9h
------------------------------------
| avg_speed          | 8.02        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8.02        |
| reward             | -0.22025907 |
| rollout/           |             |
|    ep_len_mean     | 47.3        |
|    ep_rew_mean     | -24.5       |
| time/              |             |
|    fps             | 64          |
|    iterations      | 1           |
|    time_elapsed    | 31          |
|    total_timesteps | 2109440     |
------------------------------------
------------------------------------------
| avg_speed                | 5.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.6         |
| reward                   | -0.45559475 |
| rollout/                 |             |
|    ep_len_mean           | 47.5        |
|    ep_rew_mean           | -24.4       |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 2           |
|    time_elapsed          | 65          |
|    total_timesteps       | 2111488     |
| train/                   |             |
|    approx_kl             | 0.06103473  |
|    clip_fraction         | 0.213       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.34        |
|    cost_value_loss       | 5.27        |
|    cost_values           | 1.66        |
|    entropy               | 0.743       |
|    entropy_loss          | 0.739       |
|    explained_variance    | 0.965       |
|    lagrangian_multiplier | 0.00122     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.64        |
|    n_updates             | 10300       |
|    policy_gradient_loss  | 0.00387     |
|    std                   | 0.263       |
|    value_loss            | 1.2         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.79        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.79        |
| reward                   | -0.1803453  |
| rollout/                 |             |
|    ep_len_mean           | 47.2        |
|    ep_rew_mean           | -24.2       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 3           |
|    time_elapsed          | 96          |
|    total_timesteps       | 2113536     |
| train/                   |             |
|    approx_kl             | 0.040670052 |
|    clip_fraction         | 0.192       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.45        |
|    cost_value_loss       | 5.49        |
|    cost_values           | 1.7         |
|    entropy               | 0.744       |
|    entropy_loss          | 0.744       |
|    explained_variance    | 0.969       |
|    lagrangian_multiplier | 0.00211     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.52        |
|    n_updates             | 10310       |
|    policy_gradient_loss  | 0.0112      |
|    std                   | 0.262       |
|    value_loss            | 1.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 7           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7           |
| reward                   | -0.12542541 |
| rollout/                 |             |
|    ep_len_mean           | 47.1        |
|    ep_rew_mean           | -24.3       |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 4           |
|    time_elapsed          | 132         |
|    total_timesteps       | 2115584     |
| train/                   |             |
|    approx_kl             | 0.03074895  |
|    clip_fraction         | 0.202       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.19        |
|    cost_value_loss       | 4.49        |
|    cost_values           | 1.67        |
|    entropy               | 0.745       |
|    entropy_loss          | 0.745       |
|    explained_variance    | 0.968       |
|    lagrangian_multiplier | 0.00104     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.49        |
|    n_updates             | 10320       |
|    policy_gradient_loss  | 0.0125      |
|    std                   | 0.261       |
|    value_loss            | 1.25        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.4         |
| reward                   | -0.8118199  |
| rollout/                 |             |
|    ep_len_mean           | 45.7        |
|    ep_rew_mean           | -23.9       |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 5           |
|    time_elapsed          | 171         |
|    total_timesteps       | 2117632     |
| train/                   |             |
|    approx_kl             | 0.025328869 |
|    clip_fraction         | 0.212       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.09        |
|    cost_value_loss       | 4.32        |
|    cost_values           | 1.65        |
|    entropy               | 0.744       |
|    entropy_loss          | 0.745       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0.000845    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.41        |
|    n_updates             | 10330       |
|    policy_gradient_loss  | 0.0119      |
|    std                   | 0.261       |
|    value_loss            | 0.956       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.86724913 |
| rollout/                 |             |
|    ep_len_mean           | 44.4        |
|    ep_rew_mean           | -23.2       |
| time/                    |             |
|    fps                   | 60          |
|    iterations            | 6           |
|    time_elapsed          | 203         |
|    total_timesteps       | 2119680     |
| train/                   |             |
|    approx_kl             | 0.02888612  |
|    clip_fraction         | 0.218       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.2         |
|    cost_value_loss       | 4.58        |
|    cost_values           | 1.63        |
|    entropy               | 0.746       |
|    entropy_loss          | 0.744       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0.00102     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.47        |
|    n_updates             | 10340       |
|    policy_gradient_loss  | 0.0172      |
|    std                   | 0.261       |
|    value_loss            | 0.978       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.21        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.21        |
| reward                   | -0.24772663 |
| rollout/                 |             |
|    ep_len_mean           | 45.3        |
|    ep_rew_mean           | -23.6       |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 7           |
|    time_elapsed          | 234         |
|    total_timesteps       | 2121728     |
| train/                   |             |
|    approx_kl             | 0.01753991  |
|    clip_fraction         | 0.15        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.24        |
|    cost_value_loss       | 4.87        |
|    cost_values           | 1.63        |
|    entropy               | 0.746       |
|    entropy_loss          | 0.746       |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0.00108     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.45        |
|    n_updates             | 10350       |
|    policy_gradient_loss  | 0.00213     |
|    std                   | 0.261       |
|    value_loss            | 0.794       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.69016564 |
| rollout/                 |             |
|    ep_len_mean           | 45.5        |
|    ep_rew_mean           | -24         |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 8           |
|    time_elapsed          | 264         |
|    total_timesteps       | 2123776     |
| train/                   |             |
|    approx_kl             | 0.023492718 |
|    clip_fraction         | 0.209       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.46        |
|    cost_value_loss       | 5.75        |
|    cost_values           | 1.59        |
|    entropy               | 0.748       |
|    entropy_loss          | 0.747       |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0.000846    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.85        |
|    n_updates             | 10360       |
|    policy_gradient_loss  | 0.0147      |
|    std                   | 0.261       |
|    value_loss            | 0.982       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.8         |
| reward                   | -0.7035265  |
| rollout/                 |             |
|    ep_len_mean           | 44.6        |
|    ep_rew_mean           | -23.5       |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 9           |
|    time_elapsed          | 296         |
|    total_timesteps       | 2125824     |
| train/                   |             |
|    approx_kl             | 0.031797726 |
|    clip_fraction         | 0.26        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.14        |
|    cost_value_loss       | 4.48        |
|    cost_values           | 1.59        |
|    entropy               | 0.743       |
|    entropy_loss          | 0.746       |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0.000662    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.48        |
|    n_updates             | 10370       |
|    policy_gradient_loss  | 0.0245      |
|    std                   | 0.261       |
|    value_loss            | 0.779       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.88110644 |
| rollout/                 |             |
|    ep_len_mean           | 46          |
|    ep_rew_mean           | -23.9       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 10          |
|    time_elapsed          | 320         |
|    total_timesteps       | 2127872     |
| train/                   |             |
|    approx_kl             | 0.02884468  |
|    clip_fraction         | 0.201       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.24        |
|    cost_value_loss       | 4.81        |
|    cost_values           | 1.6         |
|    entropy               | 0.751       |
|    entropy_loss          | 0.746       |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0.000858    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.36        |
|    n_updates             | 10380       |
|    policy_gradient_loss  | 0.00827     |
|    std                   | 0.26        |
|    value_loss            | 0.749       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.2         |
| reward                   | -0.516604   |
| rollout/                 |             |
|    ep_len_mean           | 46.4        |
|    ep_rew_mean           | -24.1       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 11          |
|    time_elapsed          | 346         |
|    total_timesteps       | 2129920     |
| train/                   |             |
|    approx_kl             | 0.027518183 |
|    clip_fraction         | 0.234       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.19        |
|    cost_value_loss       | 4.87        |
|    cost_values           | 1.58        |
|    entropy               | 0.755       |
|    entropy_loss          | 0.753       |
|    explained_variance    | 0.972       |
|    lagrangian_multiplier | 0.00015     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.98        |
|    n_updates             | 10390       |
|    policy_gradient_loss  | 0.0177      |
|    std                   | 0.26        |
|    value_loss            | 1.06        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.3347016 |
| rollout/                 |            |
|    ep_len_mean           | 45.4       |
|    ep_rew_mean           | -23.7      |
| time/                    |            |
|    fps                   | 64         |
|    iterations            | 12         |
|    time_elapsed          | 379        |
|    total_timesteps       | 2131968    |
| train/                   |            |
|    approx_kl             | 0.03491169 |
|    clip_fraction         | 0.215      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.32       |
|    cost_value_loss       | 5.41       |
|    cost_values           | 1.56       |
|    entropy               | 0.76       |
|    entropy_loss          | 0.758      |
|    explained_variance    | 0.976      |
|    lagrangian_multiplier | 0.00197    |
|    learning_rate         | 0.0003     |
|    loss                  | 2.6        |
|    n_updates             | 10400      |
|    policy_gradient_loss  | 0.0161     |
|    std                   | 0.259      |
|    value_loss            | 0.938      |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 1            |
| max_speed                | 8            |
| reward                   | -0.095323354 |
| rollout/                 |              |
|    ep_len_mean           | 45.4         |
|    ep_rew_mean           | -23.6        |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 13           |
|    time_elapsed          | 417          |
|    total_timesteps       | 2134016      |
| train/                   |              |
|    approx_kl             | 0.017856564  |
|    clip_fraction         | 0.197        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.07         |
|    cost_value_loss       | 4.12         |
|    cost_values           | 1.56         |
|    entropy               | 0.76         |
|    entropy_loss          | 0.761        |
|    explained_variance    | 0.973        |
|    lagrangian_multiplier | 0.000678     |
|    learning_rate         | 0.0003       |
|    loss                  | 2.31         |
|    n_updates             | 10410        |
|    policy_gradient_loss  | 0.0115       |
|    std                   | 0.259        |
|    value_loss            | 0.994        |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.83        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.83        |
| reward                   | -0.37417653 |
| rollout/                 |             |
|    ep_len_mean           | 46.2        |
|    ep_rew_mean           | -24.1       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 14          |
|    time_elapsed          | 444         |
|    total_timesteps       | 2136064     |
| train/                   |             |
|    approx_kl             | 0.03434787  |
|    clip_fraction         | 0.196       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.14        |
|    cost_value_loss       | 4.37        |
|    cost_values           | 1.6         |
|    entropy               | 0.756       |
|    entropy_loss          | 0.759       |
|    explained_variance    | 0.969       |
|    lagrangian_multiplier | 0.00208     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.29        |
|    n_updates             | 10420       |
|    policy_gradient_loss  | 0.00524     |
|    std                   | 0.259       |
|    value_loss            | 1.16        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.6         |
| reward                   | -0.32791686 |
| rollout/                 |             |
|    ep_len_mean           | 46.5        |
|    ep_rew_mean           | -24.2       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 15          |
|    time_elapsed          | 467         |
|    total_timesteps       | 2138112     |
| train/                   |             |
|    approx_kl             | 0.047972284 |
|    clip_fraction         | 0.197       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.41        |
|    cost_value_loss       | 5.31        |
|    cost_values           | 1.63        |
|    entropy               | 0.753       |
|    entropy_loss          | 0.754       |
|    explained_variance    | 0.969       |
|    lagrangian_multiplier | 0.00225     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.32        |
|    n_updates             | 10430       |
|    policy_gradient_loss  | 0.00859     |
|    std                   | 0.259       |
|    value_loss            | 1.16        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.2         |
| reward                   | -0.3336417  |
| rollout/                 |             |
|    ep_len_mean           | 47.2        |
|    ep_rew_mean           | -24.2       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 16          |
|    time_elapsed          | 491         |
|    total_timesteps       | 2140160     |
| train/                   |             |
|    approx_kl             | 0.010873219 |
|    clip_fraction         | 0.2         |
|    clip_range            | 0.2         |
|    cost_returns          | 3.61        |
|    cost_value_loss       | 6.18        |
|    cost_values           | 1.7         |
|    entropy               | 0.757       |
|    entropy_loss          | 0.754       |
|    explained_variance    | 0.96        |
|    lagrangian_multiplier | 0.00178     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.92        |
|    n_updates             | 10440       |
|    policy_gradient_loss  | 0.0112      |
|    std                   | 0.258       |
|    value_loss            | 1.41        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.5505406  |
| rollout/                 |             |
|    ep_len_mean           | 47.4        |
|    ep_rew_mean           | -24.4       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 17          |
|    time_elapsed          | 519         |
|    total_timesteps       | 2142208     |
| train/                   |             |
|    approx_kl             | 0.055413596 |
|    clip_fraction         | 0.178       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.41        |
|    cost_value_loss       | 5.3         |
|    cost_values           | 1.75        |
|    entropy               | 0.77        |
|    entropy_loss          | 0.764       |
|    explained_variance    | 0.963       |
|    lagrangian_multiplier | 0.0014      |
|    learning_rate         | 0.0003      |
|    loss                  | 2.78        |
|    n_updates             | 10450       |
|    policy_gradient_loss  | 0.00744     |
|    std                   | 0.257       |
|    value_loss            | 1.44        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3076246  |
| rollout/                 |             |
|    ep_len_mean           | 45.1        |
|    ep_rew_mean           | -23.5       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 18          |
|    time_elapsed          | 549         |
|    total_timesteps       | 2144256     |
| train/                   |             |
|    approx_kl             | 0.028570369 |
|    clip_fraction         | 0.199       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.15        |
|    cost_value_loss       | 4.17        |
|    cost_values           | 1.71        |
|    entropy               | 0.771       |
|    entropy_loss          | 0.772       |
|    explained_variance    | 0.966       |
|    lagrangian_multiplier | 0.000214    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.63        |
|    n_updates             | 10460       |
|    policy_gradient_loss  | 0.0112      |
|    std                   | 0.257       |
|    value_loss            | 1.29        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.2         |
| reward                   | -0.60566103 |
| rollout/                 |             |
|    ep_len_mean           | 45.3        |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 19          |
|    time_elapsed          | 577         |
|    total_timesteps       | 2146304     |
| train/                   |             |
|    approx_kl             | 0.07310137  |
|    clip_fraction         | 0.296       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.25        |
|    cost_value_loss       | 4.47        |
|    cost_values           | 1.7         |
|    entropy               | 0.768       |
|    entropy_loss          | 0.77        |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0.00203     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.29        |
|    n_updates             | 10470       |
|    policy_gradient_loss  | 0.0174      |
|    std                   | 0.257       |
|    value_loss            | 0.923       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.4         |
| reward                   | -0.12555566 |
| rollout/                 |             |
|    ep_len_mean           | 45.4        |
|    ep_rew_mean           | -23.5       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 20          |
|    time_elapsed          | 607         |
|    total_timesteps       | 2148352     |
| train/                   |             |
|    approx_kl             | 0.059884183 |
|    clip_fraction         | 0.245       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.26        |
|    cost_value_loss       | 4.95        |
|    cost_values           | 1.62        |
|    entropy               | 0.771       |
|    entropy_loss          | 0.77        |
|    explained_variance    | 0.961       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.22        |
|    n_updates             | 10480       |
|    policy_gradient_loss  | 0.0151      |
|    std                   | 0.256       |
|    value_loss            | 1.28        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.6         |
| reward                   | -0.61492574 |
| rollout/                 |             |
|    ep_len_mean           | 45.6        |
|    ep_rew_mean           | -24         |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 21          |
|    time_elapsed          | 643         |
|    total_timesteps       | 2150400     |
| train/                   |             |
|    approx_kl             | 0.031620912 |
|    clip_fraction         | 0.2         |
|    clip_range            | 0.2         |
|    cost_returns          | 3.21        |
|    cost_value_loss       | 4.39        |
|    cost_values           | 1.66        |
|    entropy               | 0.773       |
|    entropy_loss          | 0.772       |
|    explained_variance    | 0.973       |
|    lagrangian_multiplier | 0.00115     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.26        |
|    n_updates             | 10490       |
|    policy_gradient_loss  | 0.00694     |
|    std                   | 0.255       |
|    value_loss            | 0.967       |
------------------------------------------
-----------------------------------------
| avg_speed                | 3.8        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 3.8        |
| reward                   | -0.6825003 |
| rollout/                 |            |
|    ep_len_mean           | 47         |
|    ep_rew_mean           | -24.7      |
| time/                    |            |
|    fps                   | 66         |
|    iterations            | 22         |
|    time_elapsed          | 677        |
|    total_timesteps       | 2152448    |
| train/                   |            |
|    approx_kl             | 0.03351531 |
|    clip_fraction         | 0.188      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.18       |
|    cost_value_loss       | 4.64       |
|    cost_values           | 1.63       |
|    entropy               | 0.77       |
|    entropy_loss          | 0.771      |
|    explained_variance    | 0.976      |
|    lagrangian_multiplier | 0.00158    |
|    learning_rate         | 0.0003     |
|    loss                  | 2.36       |
|    n_updates             | 10500      |
|    policy_gradient_loss  | 0.00628    |
|    std                   | 0.256      |
|    value_loss            | 0.98       |
-----------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.78507864 |
| rollout/                 |             |
|    ep_len_mean           | 47.1        |
|    ep_rew_mean           | -24.3       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 23          |
|    time_elapsed          | 713         |
|    total_timesteps       | 2154496     |
| train/                   |             |
|    approx_kl             | 0.01860037  |
|    clip_fraction         | 0.187       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.34        |
|    cost_value_loss       | 5           |
|    cost_values           | 1.67        |
|    entropy               | 0.772       |
|    entropy_loss          | 0.771       |
|    explained_variance    | 0.968       |
|    lagrangian_multiplier | 0.000601    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.59        |
|    n_updates             | 10510       |
|    policy_gradient_loss  | 0.0102      |
|    std                   | 0.255       |
|    value_loss            | 1.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.8         |
| reward                   | -0.8896386  |
| rollout/                 |             |
|    ep_len_mean           | 48.1        |
|    ep_rew_mean           | -24.3       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 24          |
|    time_elapsed          | 750         |
|    total_timesteps       | 2156544     |
| train/                   |             |
|    approx_kl             | 0.032867435 |
|    clip_fraction         | 0.206       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.35        |
|    cost_value_loss       | 5           |
|    cost_values           | 1.69        |
|    entropy               | 0.784       |
|    entropy_loss          | 0.778       |
|    explained_variance    | 0.958       |
|    lagrangian_multiplier | 0.000499    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.98        |
|    n_updates             | 10520       |
|    policy_gradient_loss  | 0.00888     |
|    std                   | 0.254       |
|    value_loss            | 1.47        |
------------------------------------------
-----------------------------------------
| avg_speed                | 2.8        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 2.8        |
| reward                   | -0.7690623 |
| rollout/                 |            |
|    ep_len_mean           | 48         |
|    ep_rew_mean           | -24.6      |
| time/                    |            |
|    fps                   | 65         |
|    iterations            | 25         |
|    time_elapsed          | 781        |
|    total_timesteps       | 2158592    |
| train/                   |            |
|    approx_kl             | 0.01950894 |
|    clip_fraction         | 0.219      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.35       |
|    cost_value_loss       | 5.23       |
|    cost_values           | 1.65       |
|    entropy               | 0.783      |
|    entropy_loss          | 0.785      |
|    explained_variance    | 0.957      |
|    lagrangian_multiplier | 0.00171    |
|    learning_rate         | 0.0003     |
|    loss                  | 2.55       |
|    n_updates             | 10530      |
|    policy_gradient_loss  | 0.00882    |
|    std                   | 0.254      |
|    value_loss            | 1.48       |
-----------------------------------------
------------------------------------------
| avg_speed                | 2.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.6         |
| reward                   | -0.8625946  |
| rollout/                 |             |
|    ep_len_mean           | 45.8        |
|    ep_rew_mean           | -23.6       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 26          |
|    time_elapsed          | 814         |
|    total_timesteps       | 2160640     |
| train/                   |             |
|    approx_kl             | 0.011649565 |
|    clip_fraction         | 0.18        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.41        |
|    cost_value_loss       | 5.35        |
|    cost_values           | 1.69        |
|    entropy               | 0.779       |
|    entropy_loss          | 0.781       |
|    explained_variance    | 0.962       |
|    lagrangian_multiplier | 0.00178     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.68        |
|    n_updates             | 10540       |
|    policy_gradient_loss  | 0.00559     |
|    std                   | 0.255       |
|    value_loss            | 1.47        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.22503538 |
| rollout/                 |             |
|    ep_len_mean           | 44          |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 27          |
|    time_elapsed          | 845         |
|    total_timesteps       | 2162688     |
| train/                   |             |
|    approx_kl             | 0.025072437 |
|    clip_fraction         | 0.154       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.19        |
|    cost_value_loss       | 4.49        |
|    cost_values           | 1.7         |
|    entropy               | 0.775       |
|    entropy_loss          | 0.778       |
|    explained_variance    | 0.959       |
|    lagrangian_multiplier | 0.000708    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.71        |
|    n_updates             | 10550       |
|    policy_gradient_loss  | 0.00498     |
|    std                   | 0.256       |
|    value_loss            | 1.34        |
------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.8464787  |
| rollout/                 |             |
|    ep_len_mean           | 43.2        |
|    ep_rew_mean           | -23.1       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 28          |
|    time_elapsed          | 875         |
|    total_timesteps       | 2164736     |
| train/                   |             |
|    approx_kl             | 0.020295756 |
|    clip_fraction         | 0.252       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.15        |
|    cost_value_loss       | 4.1         |
|    cost_values           | 1.67        |
|    entropy               | 0.772       |
|    entropy_loss          | 0.773       |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0.00188     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.11        |
|    n_updates             | 10560       |
|    policy_gradient_loss  | 0.0115      |
|    std                   | 0.257       |
|    value_loss            | 0.824       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.75702214 |
| rollout/                 |             |
|    ep_len_mean           | 44.8        |
|    ep_rew_mean           | -23.6       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 29          |
|    time_elapsed          | 903         |
|    total_timesteps       | 2166784     |
| train/                   |             |
|    approx_kl             | 0.02751122  |
|    clip_fraction         | 0.221       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.94        |
|    cost_value_loss       | 3.65        |
|    cost_values           | 1.64        |
|    entropy               | 0.778       |
|    entropy_loss          | 0.775       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0.000616    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.16        |
|    n_updates             | 10570       |
|    policy_gradient_loss  | 0.0145      |
|    std                   | 0.256       |
|    value_loss            | 0.914       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.79619116 |
| rollout/                 |             |
|    ep_len_mean           | 46.1        |
|    ep_rew_mean           | -24.1       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 30          |
|    time_elapsed          | 926         |
|    total_timesteps       | 2168832     |
| train/                   |             |
|    approx_kl             | 0.016852286 |
|    clip_fraction         | 0.186       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.04        |
|    cost_value_loss       | 4.15        |
|    cost_values           | 1.55        |
|    entropy               | 0.781       |
|    entropy_loss          | 0.78        |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0.000877    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.24        |
|    n_updates             | 10580       |
|    policy_gradient_loss  | 0.00215     |
|    std                   | 0.255       |
|    value_loss            | 0.828       |
------------------------------------------
-----------------------------------------
| avg_speed                | 6.57       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 6.57       |
| reward                   | -0.2248468 |
| rollout/                 |            |
|    ep_len_mean           | 44.7       |
|    ep_rew_mean           | -24        |
| time/                    |            |
|    fps                   | 66         |
|    iterations            | 31         |
|    time_elapsed          | 950        |
|    total_timesteps       | 2170880    |
| train/                   |            |
|    approx_kl             | 0.01745107 |
|    clip_fraction         | 0.179      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.21       |
|    cost_value_loss       | 4.45       |
|    cost_values           | 1.63       |
|    entropy               | 0.792      |
|    entropy_loss          | 0.786      |
|    explained_variance    | 0.969      |
|    lagrangian_multiplier | 0.000204   |
|    learning_rate         | 0.0003     |
|    loss                  | 2.6        |
|    n_updates             | 10590      |
|    policy_gradient_loss  | 0.00682    |
|    std                   | 0.253      |
|    value_loss            | 1.15       |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.2         |
| reward                   | -0.27882516 |
| rollout/                 |             |
|    ep_len_mean           | 44.7        |
|    ep_rew_mean           | -23.9       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 32          |
|    time_elapsed          | 981         |
|    total_timesteps       | 2172928     |
| train/                   |             |
|    approx_kl             | 0.019681588 |
|    clip_fraction         | 0.171       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.07        |
|    cost_value_loss       | 3.97        |
|    cost_values           | 1.64        |
|    entropy               | 0.801       |
|    entropy_loss          | 0.798       |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0.000967    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.29        |
|    n_updates             | 10600       |
|    policy_gradient_loss  | 0.00661     |
|    std                   | 0.252       |
|    value_loss            | 0.89        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.5030113  |
| rollout/                 |             |
|    ep_len_mean           | 44.7        |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 33          |
|    time_elapsed          | 1015        |
|    total_timesteps       | 2174976     |
| train/                   |             |
|    approx_kl             | 0.035002556 |
|    clip_fraction         | 0.242       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.12        |
|    cost_value_loss       | 4.32        |
|    cost_values           | 1.6         |
|    entropy               | 0.801       |
|    entropy_loss          | 0.801       |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 0.00046     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.38        |
|    n_updates             | 10610       |
|    policy_gradient_loss  | 0.00911     |
|    std                   | 0.252       |
|    value_loss            | 0.755       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.6         |
| reward                   | -0.8390885  |
| rollout/                 |             |
|    ep_len_mean           | 44.1        |
|    ep_rew_mean           | -23         |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 34          |
|    time_elapsed          | 1046        |
|    total_timesteps       | 2177024     |
| train/                   |             |
|    approx_kl             | 0.019823248 |
|    clip_fraction         | 0.169       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.15        |
|    cost_value_loss       | 4.63        |
|    cost_values           | 1.55        |
|    entropy               | 0.804       |
|    entropy_loss          | 0.802       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0.000988    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.36        |
|    n_updates             | 10620       |
|    policy_gradient_loss  | 0.0104      |
|    std                   | 0.252       |
|    value_loss            | 0.893       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.4931795  |
| rollout/                 |             |
|    ep_len_mean           | 44.8        |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 35          |
|    time_elapsed          | 1073        |
|    total_timesteps       | 2179072     |
| train/                   |             |
|    approx_kl             | 0.023252381 |
|    clip_fraction         | 0.215       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.16        |
|    cost_value_loss       | 4.47        |
|    cost_values           | 1.61        |
|    entropy               | 0.804       |
|    entropy_loss          | 0.804       |
|    explained_variance    | 0.967       |
|    lagrangian_multiplier | 0.00214     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.25        |
|    n_updates             | 10630       |
|    policy_gradient_loss  | 0.0079      |
|    std                   | 0.251       |
|    value_loss            | 1.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.19147944 |
| rollout/                 |             |
|    ep_len_mean           | 44.3        |
|    ep_rew_mean           | -22.7       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 36          |
|    time_elapsed          | 1099        |
|    total_timesteps       | 2181120     |
| train/                   |             |
|    approx_kl             | 0.01680881  |
|    clip_fraction         | 0.22        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.1         |
|    cost_value_loss       | 4.32        |
|    cost_values           | 1.58        |
|    entropy               | 0.795       |
|    entropy_loss          | 0.799       |
|    explained_variance    | 0.966       |
|    lagrangian_multiplier | 0.000748    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.47        |
|    n_updates             | 10640       |
|    policy_gradient_loss  | 0.00375     |
|    std                   | 0.252       |
|    value_loss            | 1.23        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.23213011 |
| rollout/                 |             |
|    ep_len_mean           | 44.7        |
|    ep_rew_mean           | -22.6       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 37          |
|    time_elapsed          | 1128        |
|    total_timesteps       | 2183168     |
| train/                   |             |
|    approx_kl             | 0.021493845 |
|    clip_fraction         | 0.189       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.08        |
|    cost_value_loss       | 4.13        |
|    cost_values           | 1.58        |
|    entropy               | 0.796       |
|    entropy_loss          | 0.794       |
|    explained_variance    | 0.966       |
|    lagrangian_multiplier | 0.000788    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.55        |
|    n_updates             | 10650       |
|    policy_gradient_loss  | 0.015       |
|    std                   | 0.253       |
|    value_loss            | 1.11        |
------------------------------------------
-----------------------------------------
| avg_speed                | 1.4        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 1.4        |
| reward                   | -0.5030731 |
| rollout/                 |            |
|    ep_len_mean           | 45         |
|    ep_rew_mean           | -23.2      |
| time/                    |            |
|    fps                   | 67         |
|    iterations            | 38         |
|    time_elapsed          | 1158       |
|    total_timesteps       | 2185216    |
| train/                   |            |
|    approx_kl             | 0.03828226 |
|    clip_fraction         | 0.201      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.25       |
|    cost_value_loss       | 4.98       |
|    cost_values           | 1.6        |
|    entropy               | 0.786      |
|    entropy_loss          | 0.792      |
|    explained_variance    | 0.97       |
|    lagrangian_multiplier | 0.00151    |
|    learning_rate         | 0.0003     |
|    loss                  | 2.47       |
|    n_updates             | 10660      |
|    policy_gradient_loss  | 0.00952    |
|    std                   | 0.255      |
|    value_loss            | 1.08       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.34369674 |
| rollout/                 |             |
|    ep_len_mean           | 46.1        |
|    ep_rew_mean           | -23.7       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 39          |
|    time_elapsed          | 1191        |
|    total_timesteps       | 2187264     |
| train/                   |             |
|    approx_kl             | 0.041905493 |
|    clip_fraction         | 0.262       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.23        |
|    cost_value_loss       | 4.64        |
|    cost_values           | 1.61        |
|    entropy               | 0.781       |
|    entropy_loss          | 0.783       |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0.00119     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.37        |
|    n_updates             | 10670       |
|    policy_gradient_loss  | 0.0164      |
|    std                   | 0.255       |
|    value_loss            | 0.82        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.4         |
| cost                     | 0           |
| is_success               | 1           |
| max_speed                | 7.4         |
| reward                   | -0.10786988 |
| rollout/                 |             |
|    ep_len_mean           | 45.6        |
|    ep_rew_mean           | -23.4       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 40          |
|    time_elapsed          | 1216        |
|    total_timesteps       | 2189312     |
| train/                   |             |
|    approx_kl             | 0.018679254 |
|    clip_fraction         | 0.171       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.39        |
|    cost_value_loss       | 5.39        |
|    cost_values           | 1.56        |
|    entropy               | 0.784       |
|    entropy_loss          | 0.781       |
|    explained_variance    | 0.966       |
|    lagrangian_multiplier | 0.000114    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.15        |
|    n_updates             | 10680       |
|    policy_gradient_loss  | 0.0077      |
|    std                   | 0.255       |
|    value_loss            | 1.21        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.37141046 |
| rollout/                 |             |
|    ep_len_mean           | 45.2        |
|    ep_rew_mean           | -23.8       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 41          |
|    time_elapsed          | 1240        |
|    total_timesteps       | 2191360     |
| train/                   |             |
|    approx_kl             | 0.02005993  |
|    clip_fraction         | 0.195       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.02        |
|    cost_value_loss       | 3.8         |
|    cost_values           | 1.57        |
|    entropy               | 0.79        |
|    entropy_loss          | 0.788       |
|    explained_variance    | 0.97        |
|    lagrangian_multiplier | 0.00065     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.34        |
|    n_updates             | 10690       |
|    policy_gradient_loss  | 0.011       |
|    std                   | 0.254       |
|    value_loss            | 1.07        |
------------------------------------------
-----------------------------------------
| avg_speed                | 3.8        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 3.8        |
| reward                   | -0.6450538 |
| rollout/                 |            |
|    ep_len_mean           | 45         |
|    ep_rew_mean           | -23.7      |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 42         |
|    time_elapsed          | 1263       |
|    total_timesteps       | 2193408    |
| train/                   |            |
|    approx_kl             | 0.02822112 |
|    clip_fraction         | 0.183      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.15       |
|    cost_value_loss       | 4.51       |
|    cost_values           | 1.55       |
|    entropy               | 0.79       |
|    entropy_loss          | 0.79       |
|    explained_variance    | 0.972      |
|    lagrangian_multiplier | 0.00174    |
|    learning_rate         | 0.0003     |
|    loss                  | 2.38       |
|    n_updates             | 10700      |
|    policy_gradient_loss  | 0.0104     |
|    std                   | 0.254      |
|    value_loss            | 1.1        |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.560286   |
| rollout/                 |             |
|    ep_len_mean           | 44.8        |
|    ep_rew_mean           | -23.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 43          |
|    time_elapsed          | 1290        |
|    total_timesteps       | 2195456     |
| train/                   |             |
|    approx_kl             | 0.023619717 |
|    clip_fraction         | 0.203       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.92        |
|    cost_value_loss       | 3.76        |
|    cost_values           | 1.54        |
|    entropy               | 0.795       |
|    entropy_loss          | 0.792       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0.000453    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.22        |
|    n_updates             | 10710       |
|    policy_gradient_loss  | 0.00899     |
|    std                   | 0.253       |
|    value_loss            | 0.909       |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.4        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.4        |
| reward                   | -0.5183368 |
| rollout/                 |            |
|    ep_len_mean           | 45.2       |
|    ep_rew_mean           | -23.9      |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 44         |
|    time_elapsed          | 1324       |
|    total_timesteps       | 2197504    |
| train/                   |            |
|    approx_kl             | 0.04847795 |
|    clip_fraction         | 0.246      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.15       |
|    cost_value_loss       | 4.66       |
|    cost_values           | 1.53       |
|    entropy               | 0.799      |
|    entropy_loss          | 0.797      |
|    explained_variance    | 0.966      |
|    lagrangian_multiplier | 0.00118    |
|    learning_rate         | 0.0003     |
|    loss                  | 2.37       |
|    n_updates             | 10720      |
|    policy_gradient_loss  | 0.0119     |
|    std                   | 0.252      |
|    value_loss            | 1.14       |
-----------------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.8151657  |
| rollout/                 |             |
|    ep_len_mean           | 45.4        |
|    ep_rew_mean           | -24.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 45          |
|    time_elapsed          | 1354        |
|    total_timesteps       | 2199552     |
| train/                   |             |
|    approx_kl             | 0.021460652 |
|    clip_fraction         | 0.17        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.26        |
|    cost_value_loss       | 4.77        |
|    cost_values           | 1.56        |
|    entropy               | 0.801       |
|    entropy_loss          | 0.8         |
|    explained_variance    | 0.97        |
|    lagrangian_multiplier | 0.000365    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.67        |
|    n_updates             | 10730       |
|    policy_gradient_loss  | 0.00591     |
|    std                   | 0.252       |
|    value_loss            | 1.23        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.23004036 |
| rollout/                 |             |
|    ep_len_mean           | 44.5        |
|    ep_rew_mean           | -23.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 46          |
|    time_elapsed          | 1384        |
|    total_timesteps       | 2201600     |
| train/                   |             |
|    approx_kl             | 0.046379164 |
|    clip_fraction         | 0.205       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.14        |
|    cost_value_loss       | 4.31        |
|    cost_values           | 1.61        |
|    entropy               | 0.806       |
|    entropy_loss          | 0.804       |
|    explained_variance    | 0.972       |
|    lagrangian_multiplier | 0.000988    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.57        |
|    n_updates             | 10740       |
|    policy_gradient_loss  | 0.0118      |
|    std                   | 0.252       |
|    value_loss            | 1.07        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.20450374 |
| rollout/                 |             |
|    ep_len_mean           | 43.5        |
|    ep_rew_mean           | -22.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 47          |
|    time_elapsed          | 1415        |
|    total_timesteps       | 2203648     |
| train/                   |             |
|    approx_kl             | 0.020591162 |
|    clip_fraction         | 0.22        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.07        |
|    cost_value_loss       | 4.15        |
|    cost_values           | 1.55        |
|    entropy               | 0.803       |
|    entropy_loss          | 0.805       |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0.00159     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.08        |
|    n_updates             | 10750       |
|    policy_gradient_loss  | 0.00893     |
|    std                   | 0.252       |
|    value_loss            | 0.669       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.46347275 |
| rollout/                 |             |
|    ep_len_mean           | 44.4        |
|    ep_rew_mean           | -22.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 48          |
|    time_elapsed          | 1445        |
|    total_timesteps       | 2205696     |
| train/                   |             |
|    approx_kl             | 0.037725847 |
|    clip_fraction         | 0.232       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.08        |
|    cost_value_loss       | 4.21        |
|    cost_values           | 1.55        |
|    entropy               | 0.794       |
|    entropy_loss          | 0.799       |
|    explained_variance    | 0.971       |
|    lagrangian_multiplier | 0.00182     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.1         |
|    n_updates             | 10760       |
|    policy_gradient_loss  | 0.00727     |
|    std                   | 0.253       |
|    value_loss            | 0.981       |
------------------------------------------
-----------------------------------------
| avg_speed                | 4.6        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 4.6        |
| reward                   | -0.6079423 |
| rollout/                 |            |
|    ep_len_mean           | 44.5       |
|    ep_rew_mean           | -23        |
| time/                    |            |
|    fps                   | 67         |
|    iterations            | 49         |
|    time_elapsed          | 1478       |
|    total_timesteps       | 2207744    |
| train/                   |            |
|    approx_kl             | 0.03229378 |
|    clip_fraction         | 0.243      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.16       |
|    cost_value_loss       | 4.46       |
|    cost_values           | 1.55       |
|    entropy               | 0.794      |
|    entropy_loss          | 0.793      |
|    explained_variance    | 0.97       |
|    lagrangian_multiplier | 0.000909   |
|    learning_rate         | 0.0003     |
|    loss                  | 2.35       |
|    n_updates             | 10770      |
|    policy_gradient_loss  | 0.0119     |
|    std                   | 0.254      |
|    value_loss            | 1.04       |
-----------------------------------------
-----------------------------------
| avg_speed          | 1.2        |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 1.2        |
| reward             | -0.8759144 |
| rollout/           |            |
|    ep_len_mean     | 44         |
|    ep_rew_mean     | -22.8      |
| time/              |            |
|    fps             | 67         |
|    iterations      | 1          |
|    time_elapsed    | 30         |
|    total_timesteps | 2209792    |
-----------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.18581438 |
| rollout/                 |             |
|    ep_len_mean           | 44.1        |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 2           |
|    time_elapsed          | 60          |
|    total_timesteps       | 2211840     |
| train/                   |             |
|    approx_kl             | 0.017913425 |
|    clip_fraction         | 0.197       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.13        |
|    cost_value_loss       | 4.39        |
|    cost_values           | 1.59        |
|    entropy               | 0.804       |
|    entropy_loss          | 0.801       |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0.00029     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.42        |
|    n_updates             | 10790       |
|    policy_gradient_loss  | 0.0122      |
|    std                   | 0.253       |
|    value_loss            | 0.91        |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.7655791  |
| rollout/                 |             |
|    ep_len_mean           | 45.3        |
|    ep_rew_mean           | -24.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 3           |
|    time_elapsed          | 89          |
|    total_timesteps       | 2213888     |
| train/                   |             |
|    approx_kl             | 0.038218297 |
|    clip_fraction         | 0.201       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.13        |
|    cost_value_loss       | 4.58        |
|    cost_values           | 1.54        |
|    entropy               | 0.813       |
|    entropy_loss          | 0.808       |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0.000657    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.45        |
|    n_updates             | 10800       |
|    policy_gradient_loss  | 0.0107      |
|    std                   | 0.252       |
|    value_loss            | 0.747       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.740352   |
| rollout/                 |             |
|    ep_len_mean           | 47.2        |
|    ep_rew_mean           | -24.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 4           |
|    time_elapsed          | 119         |
|    total_timesteps       | 2215936     |
| train/                   |             |
|    approx_kl             | 0.014507865 |
|    clip_fraction         | 0.225       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.32        |
|    cost_value_loss       | 5.37        |
|    cost_values           | 1.56        |
|    entropy               | 0.817       |
|    entropy_loss          | 0.816       |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0.000425    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.72        |
|    n_updates             | 10810       |
|    policy_gradient_loss  | 0.0123      |
|    std                   | 0.252       |
|    value_loss            | 1.02        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.38883212 |
| rollout/                 |             |
|    ep_len_mean           | 46          |
|    ep_rew_mean           | -24.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 5           |
|    time_elapsed          | 148         |
|    total_timesteps       | 2217984     |
| train/                   |             |
|    approx_kl             | 0.050473943 |
|    clip_fraction         | 0.191       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.21        |
|    cost_value_loss       | 4.84        |
|    cost_values           | 1.62        |
|    entropy               | 0.826       |
|    entropy_loss          | 0.821       |
|    explained_variance    | 0.963       |
|    lagrangian_multiplier | 0.00104     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.44        |
|    n_updates             | 10820       |
|    policy_gradient_loss  | 0.00724     |
|    std                   | 0.25        |
|    value_loss            | 1.38        |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.83792084 |
| rollout/                 |             |
|    ep_len_mean           | 43          |
|    ep_rew_mean           | -23.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 6           |
|    time_elapsed          | 174         |
|    total_timesteps       | 2220032     |
| train/                   |             |
|    approx_kl             | 0.03175914  |
|    clip_fraction         | 0.229       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.13        |
|    cost_value_loss       | 4.37        |
|    cost_values           | 1.63        |
|    entropy               | 0.833       |
|    entropy_loss          | 0.83        |
|    explained_variance    | 0.972       |
|    lagrangian_multiplier | 0.000259    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.66        |
|    n_updates             | 10830       |
|    policy_gradient_loss  | 0.0108      |
|    std                   | 0.248       |
|    value_loss            | 1.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.63638    |
| rollout/                 |             |
|    ep_len_mean           | 43.1        |
|    ep_rew_mean           | -23.4       |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 7           |
|    time_elapsed          | 198         |
|    total_timesteps       | 2222080     |
| train/                   |             |
|    approx_kl             | 0.035605825 |
|    clip_fraction         | 0.246       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.94        |
|    cost_value_loss       | 3.66        |
|    cost_values           | 1.54        |
|    entropy               | 0.832       |
|    entropy_loss          | 0.832       |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0.000678    |
|    learning_rate         | 0.0003      |
|    loss                  | 1.95        |
|    n_updates             | 10840       |
|    policy_gradient_loss  | 0.0113      |
|    std                   | 0.248       |
|    value_loss            | 0.545       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.4         |
| reward                   | -0.18326302 |
| rollout/                 |             |
|    ep_len_mean           | 43.8        |
|    ep_rew_mean           | -23.7       |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 8           |
|    time_elapsed          | 222         |
|    total_timesteps       | 2224128     |
| train/                   |             |
|    approx_kl             | 0.021891646 |
|    clip_fraction         | 0.25        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.03        |
|    cost_value_loss       | 4.26        |
|    cost_values           | 1.52        |
|    entropy               | 0.834       |
|    entropy_loss          | 0.833       |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0.00221     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.06        |
|    n_updates             | 10850       |
|    policy_gradient_loss  | 0.00928     |
|    std                   | 0.248       |
|    value_loss            | 0.579       |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.4        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.4        |
| reward                   | -0.8441996 |
| rollout/                 |            |
|    ep_len_mean           | 43.9       |
|    ep_rew_mean           | -23.8      |
| time/                    |            |
|    fps                   | 75         |
|    iterations            | 9          |
|    time_elapsed          | 245        |
|    total_timesteps       | 2226176    |
| train/                   |            |
|    approx_kl             | 0.03638275 |
|    clip_fraction         | 0.231      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.03       |
|    cost_value_loss       | 4.03       |
|    cost_values           | 1.55       |
|    entropy               | 0.832      |
|    entropy_loss          | 0.833      |
|    explained_variance    | 0.981      |
|    lagrangian_multiplier | 0.00113    |
|    learning_rate         | 0.0003     |
|    loss                  | 2.13       |
|    n_updates             | 10860      |
|    policy_gradient_loss  | 0.0123     |
|    std                   | 0.247      |
|    value_loss            | 0.762      |
-----------------------------------------
------------------------------------------
| avg_speed                | 7           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7           |
| reward                   | -0.31877065 |
| rollout/                 |             |
|    ep_len_mean           | 45          |
|    ep_rew_mean           | -24         |
| time/                    |             |
|    fps                   | 75          |
|    iterations            | 10          |
|    time_elapsed          | 269         |
|    total_timesteps       | 2228224     |
| train/                   |             |
|    approx_kl             | 0.05156535  |
|    clip_fraction         | 0.207       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.03        |
|    cost_value_loss       | 4.41        |
|    cost_values           | 1.53        |
|    entropy               | 0.833       |
|    entropy_loss          | 0.832       |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0.00102     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.37        |
|    n_updates             | 10870       |
|    policy_gradient_loss  | 0.0147      |
|    std                   | 0.247       |
|    value_loss            | 0.781       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.17573415 |
| rollout/                 |             |
|    ep_len_mean           | 45.3        |
|    ep_rew_mean           | -23.5       |
| time/                    |             |
|    fps                   | 74          |
|    iterations            | 11          |
|    time_elapsed          | 302         |
|    total_timesteps       | 2230272     |
| train/                   |             |
|    approx_kl             | 0.040609997 |
|    clip_fraction         | 0.207       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.18        |
|    cost_value_loss       | 4.74        |
|    cost_values           | 1.52        |
|    entropy               | 0.83        |
|    entropy_loss          | 0.832       |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0.00227     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.33        |
|    n_updates             | 10880       |
|    policy_gradient_loss  | 0.0131      |
|    std                   | 0.248       |
|    value_loss            | 0.974       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.6         |
| reward                   | -0.36701012 |
| rollout/                 |             |
|    ep_len_mean           | 46.4        |
|    ep_rew_mean           | -24.1       |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 12          |
|    time_elapsed          | 336         |
|    total_timesteps       | 2232320     |
| train/                   |             |
|    approx_kl             | 0.028050438 |
|    clip_fraction         | 0.226       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.11        |
|    cost_value_loss       | 4.45        |
|    cost_values           | 1.56        |
|    entropy               | 0.825       |
|    entropy_loss          | 0.828       |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0.000361    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.48        |
|    n_updates             | 10890       |
|    policy_gradient_loss  | 0.0089      |
|    std                   | 0.249       |
|    value_loss            | 0.758       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2771022  |
| rollout/                 |             |
|    ep_len_mean           | 45.9        |
|    ep_rew_mean           | -23.7       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 13          |
|    time_elapsed          | 373         |
|    total_timesteps       | 2234368     |
| train/                   |             |
|    approx_kl             | 0.022058357 |
|    clip_fraction         | 0.219       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.08        |
|    cost_value_loss       | 4.19        |
|    cost_values           | 1.55        |
|    entropy               | 0.829       |
|    entropy_loss          | 0.827       |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0.0001      |
|    learning_rate         | 0.0003      |
|    loss                  | 2.62        |
|    n_updates             | 10900       |
|    policy_gradient_loss  | 0.0136      |
|    std                   | 0.249       |
|    value_loss            | 0.913       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.88110644 |
| rollout/                 |             |
|    ep_len_mean           | 46.3        |
|    ep_rew_mean           | -23.7       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 14          |
|    time_elapsed          | 408         |
|    total_timesteps       | 2236416     |
| train/                   |             |
|    approx_kl             | 0.040608086 |
|    clip_fraction         | 0.208       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.93        |
|    cost_value_loss       | 3.58        |
|    cost_values           | 1.58        |
|    entropy               | 0.828       |
|    entropy_loss          | 0.829       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0.000525    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.1         |
|    n_updates             | 10910       |
|    policy_gradient_loss  | 0.0106      |
|    std                   | 0.249       |
|    value_loss            | 0.864       |
------------------------------------------
-----------------------------------------
| avg_speed                | 2.6        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 2.6        |
| reward                   | -0.8173552 |
| rollout/                 |            |
|    ep_len_mean           | 45.7       |
|    ep_rew_mean           | -23.6      |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 15         |
|    time_elapsed          | 445        |
|    total_timesteps       | 2238464    |
| train/                   |            |
|    approx_kl             | 0.039105   |
|    clip_fraction         | 0.206      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.09       |
|    cost_value_loss       | 4.26       |
|    cost_values           | 1.54       |
|    entropy               | 0.826      |
|    entropy_loss          | 0.827      |
|    explained_variance    | 0.968      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 2.71       |
|    n_updates             | 10920      |
|    policy_gradient_loss  | 0.0108     |
|    std                   | 0.249      |
|    value_loss            | 1.17       |
-----------------------------------------
-----------------------------------------
| avg_speed                | 4.4        |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 4.4        |
| reward                   | -0.7386026 |
| rollout/                 |            |
|    ep_len_mean           | 44.8       |
|    ep_rew_mean           | -23.2      |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 16         |
|    time_elapsed          | 479        |
|    total_timesteps       | 2240512    |
| train/                   |            |
|    approx_kl             | 0.02385878 |
|    clip_fraction         | 0.208      |
|    clip_range            | 0.2        |
|    cost_returns          | 2.87       |
|    cost_value_loss       | 3.59       |
|    cost_values           | 1.56       |
|    entropy               | 0.825      |
|    entropy_loss          | 0.826      |
|    explained_variance    | 0.98       |
|    lagrangian_multiplier | 0.000191   |
|    learning_rate         | 0.0003     |
|    loss                  | 2.08       |
|    n_updates             | 10930      |
|    policy_gradient_loss  | 0.0142     |
|    std                   | 0.25       |
|    value_loss            | 0.767      |
-----------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.76731294 |
| rollout/                 |             |
|    ep_len_mean           | 43.6        |
|    ep_rew_mean           | -22.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 17          |
|    time_elapsed          | 511         |
|    total_timesteps       | 2242560     |
| train/                   |             |
|    approx_kl             | 0.044531986 |
|    clip_fraction         | 0.281       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.88        |
|    cost_value_loss       | 3.55        |
|    cost_values           | 1.51        |
|    entropy               | 0.826       |
|    entropy_loss          | 0.826       |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.96        |
|    n_updates             | 10940       |
|    policy_gradient_loss  | 0.0224      |
|    std                   | 0.25        |
|    value_loss            | 0.621       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.86043507 |
| rollout/                 |             |
|    ep_len_mean           | 42.3        |
|    ep_rew_mean           | -23         |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 18          |
|    time_elapsed          | 534         |
|    total_timesteps       | 2244608     |
| train/                   |             |
|    approx_kl             | 0.020673992 |
|    clip_fraction         | 0.213       |
|    clip_range            | 0.2         |
|    cost_returns          | 3           |
|    cost_value_loss       | 4.07        |
|    cost_values           | 1.5         |
|    entropy               | 0.823       |
|    entropy_loss          | 0.824       |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0.00149     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.03        |
|    n_updates             | 10950       |
|    policy_gradient_loss  | 0.0105      |
|    std                   | 0.25        |
|    value_loss            | 0.751       |
------------------------------------------
-----------------------------------------
| avg_speed                | 2.4        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 2.4        |
| reward                   | -0.6134725 |
| rollout/                 |            |
|    ep_len_mean           | 42.9       |
|    ep_rew_mean           | -23.4      |
| time/                    |            |
|    fps                   | 69         |
|    iterations            | 19         |
|    time_elapsed          | 558        |
|    total_timesteps       | 2246656    |
| train/                   |            |
|    approx_kl             | 0.0227467  |
|    clip_fraction         | 0.234      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.07       |
|    cost_value_loss       | 4.3        |
|    cost_values           | 1.51       |
|    entropy               | 0.823      |
|    entropy_loss          | 0.822      |
|    explained_variance    | 0.984      |
|    lagrangian_multiplier | 0.00137    |
|    learning_rate         | 0.0003     |
|    loss                  | 2.07       |
|    n_updates             | 10960      |
|    policy_gradient_loss  | 0.0151     |
|    std                   | 0.251      |
|    value_loss            | 0.583      |
-----------------------------------------
------------------------------------------
| avg_speed                | 4.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.8         |
| reward                   | -0.15710948 |
| rollout/                 |             |
|    ep_len_mean           | 44.4        |
|    ep_rew_mean           | -23.5       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 20          |
|    time_elapsed          | 585         |
|    total_timesteps       | 2248704     |
| train/                   |             |
|    approx_kl             | 0.034349866 |
|    clip_fraction         | 0.316       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.9         |
|    cost_value_loss       | 3.85        |
|    cost_values           | 1.46        |
|    entropy               | 0.819       |
|    entropy_loss          | 0.822       |
|    explained_variance    | 0.985       |
|    lagrangian_multiplier | 0.00113     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.99        |
|    n_updates             | 10970       |
|    policy_gradient_loss  | 0.027       |
|    std                   | 0.25        |
|    value_loss            | 0.597       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.81882226 |
| rollout/                 |             |
|    ep_len_mean           | 46.2        |
|    ep_rew_mean           | -23.9       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 21          |
|    time_elapsed          | 610         |
|    total_timesteps       | 2250752     |
| train/                   |             |
|    approx_kl             | 0.021811897 |
|    clip_fraction         | 0.201       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.08        |
|    cost_value_loss       | 4.59        |
|    cost_values           | 1.45        |
|    entropy               | 0.821       |
|    entropy_loss          | 0.82        |
|    explained_variance    | 0.971       |
|    lagrangian_multiplier | 0.00088     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.37        |
|    n_updates             | 10980       |
|    policy_gradient_loss  | 0.00945     |
|    std                   | 0.249       |
|    value_loss            | 1           |
------------------------------------------
------------------------------------------
| avg_speed                | 3           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3           |
| reward                   | -0.84354615 |
| rollout/                 |             |
|    ep_len_mean           | 45.9        |
|    ep_rew_mean           | -23.9       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 22          |
|    time_elapsed          | 635         |
|    total_timesteps       | 2252800     |
| train/                   |             |
|    approx_kl             | 0.052260995 |
|    clip_fraction         | 0.179       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.94        |
|    cost_value_loss       | 4.01        |
|    cost_values           | 1.46        |
|    entropy               | 0.83        |
|    entropy_loss          | 0.825       |
|    explained_variance    | 0.969       |
|    lagrangian_multiplier | 0.000418    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.42        |
|    n_updates             | 10990       |
|    policy_gradient_loss  | 0.00898     |
|    std                   | 0.248       |
|    value_loss            | 1.14        |
------------------------------------------
------------------------------------------
| avg_speed                | 3           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3           |
| reward                   | -0.91367084 |
| rollout/                 |             |
|    ep_len_mean           | 45.1        |
|    ep_rew_mean           | -23.4       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 23          |
|    time_elapsed          | 667         |
|    total_timesteps       | 2254848     |
| train/                   |             |
|    approx_kl             | 0.017889764 |
|    clip_fraction         | 0.204       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.93        |
|    cost_value_loss       | 3.9         |
|    cost_values           | 1.49        |
|    entropy               | 0.831       |
|    entropy_loss          | 0.831       |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0.000533    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.24        |
|    n_updates             | 11000       |
|    policy_gradient_loss  | 0.0102      |
|    std                   | 0.249       |
|    value_loss            | 0.76        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.59491205 |
| rollout/                 |             |
|    ep_len_mean           | 46.2        |
|    ep_rew_mean           | -23.9       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 24          |
|    time_elapsed          | 703         |
|    total_timesteps       | 2256896     |
| train/                   |             |
|    approx_kl             | 0.014448545 |
|    clip_fraction         | 0.201       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.18        |
|    cost_value_loss       | 4.94        |
|    cost_values           | 1.51        |
|    entropy               | 0.828       |
|    entropy_loss          | 0.829       |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0.00193     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.19        |
|    n_updates             | 11010       |
|    policy_gradient_loss  | 0.00419     |
|    std                   | 0.249       |
|    value_loss            | 0.957       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.38        |
| cost                     | 0           |
| is_success               | 1           |
| max_speed                | 7.38        |
| reward                   | -0.11479047 |
| rollout/                 |             |
|    ep_len_mean           | 46.4        |
|    ep_rew_mean           | -23.9       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 25          |
|    time_elapsed          | 738         |
|    total_timesteps       | 2258944     |
| train/                   |             |
|    approx_kl             | 0.034593385 |
|    clip_fraction         | 0.212       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.86        |
|    cost_value_loss       | 3.54        |
|    cost_values           | 1.54        |
|    entropy               | 0.821       |
|    entropy_loss          | 0.826       |
|    explained_variance    | 0.97        |
|    lagrangian_multiplier | 0.000448    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.22        |
|    n_updates             | 11020       |
|    policy_gradient_loss  | 0.00541     |
|    std                   | 0.25        |
|    value_loss            | 1.01        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.7940213  |
| rollout/                 |             |
|    ep_len_mean           | 45.7        |
|    ep_rew_mean           | -23.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 26          |
|    time_elapsed          | 774         |
|    total_timesteps       | 2260992     |
| train/                   |             |
|    approx_kl             | 0.028347299 |
|    clip_fraction         | 0.253       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.98        |
|    cost_value_loss       | 3.81        |
|    cost_values           | 1.57        |
|    entropy               | 0.82        |
|    entropy_loss          | 0.819       |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0.00173     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.98        |
|    n_updates             | 11030       |
|    policy_gradient_loss  | 0.0121      |
|    std                   | 0.25        |
|    value_loss            | 0.644       |
------------------------------------------
-----------------------------------------
| avg_speed                | 4          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 4          |
| reward                   | -0.84019   |
| rollout/                 |            |
|    ep_len_mean           | 46.5       |
|    ep_rew_mean           | -23.5      |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 27         |
|    time_elapsed          | 812        |
|    total_timesteps       | 2263040    |
| train/                   |            |
|    approx_kl             | 0.03764165 |
|    clip_fraction         | 0.233      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.03       |
|    cost_value_loss       | 4.01       |
|    cost_values           | 1.53       |
|    entropy               | 0.82       |
|    entropy_loss          | 0.82       |
|    explained_variance    | 0.985      |
|    lagrangian_multiplier | 0.000887   |
|    learning_rate         | 0.0003     |
|    loss                  | 2.1        |
|    n_updates             | 11040      |
|    policy_gradient_loss  | 0.0152     |
|    std                   | 0.251      |
|    value_loss            | 0.535      |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.13417432 |
| rollout/                 |             |
|    ep_len_mean           | 46.5        |
|    ep_rew_mean           | -23.6       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 28          |
|    time_elapsed          | 843         |
|    total_timesteps       | 2265088     |
| train/                   |             |
|    approx_kl             | 0.031816006 |
|    clip_fraction         | 0.201       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.05        |
|    cost_value_loss       | 4.28        |
|    cost_values           | 1.51        |
|    entropy               | 0.818       |
|    entropy_loss          | 0.818       |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0.00117     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.31        |
|    n_updates             | 11050       |
|    policy_gradient_loss  | 0.0109      |
|    std                   | 0.25        |
|    value_loss            | 0.709       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.59429145 |
| rollout/                 |             |
|    ep_len_mean           | 45.5        |
|    ep_rew_mean           | -23.4       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 29          |
|    time_elapsed          | 877         |
|    total_timesteps       | 2267136     |
| train/                   |             |
|    approx_kl             | 0.0495327   |
|    clip_fraction         | 0.248       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.88        |
|    cost_value_loss       | 3.68        |
|    cost_values           | 1.5         |
|    entropy               | 0.823       |
|    entropy_loss          | 0.82        |
|    explained_variance    | 0.972       |
|    lagrangian_multiplier | 0.000403    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.15        |
|    n_updates             | 11060       |
|    policy_gradient_loss  | 0.0086      |
|    std                   | 0.249       |
|    value_loss            | 1.04        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.4752672  |
| rollout/                 |             |
|    ep_len_mean           | 44.6        |
|    ep_rew_mean           | -23.4       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 30          |
|    time_elapsed          | 908         |
|    total_timesteps       | 2269184     |
| train/                   |             |
|    approx_kl             | 0.038979787 |
|    clip_fraction         | 0.226       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.94        |
|    cost_value_loss       | 3.83        |
|    cost_values           | 1.49        |
|    entropy               | 0.831       |
|    entropy_loss          | 0.828       |
|    explained_variance    | 0.985       |
|    lagrangian_multiplier | 0.000133    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.24        |
|    n_updates             | 11070       |
|    policy_gradient_loss  | 0.0127      |
|    std                   | 0.248       |
|    value_loss            | 0.542       |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.12130608 |
| rollout/                 |             |
|    ep_len_mean           | 46.3        |
|    ep_rew_mean           | -24         |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 31          |
|    time_elapsed          | 942         |
|    total_timesteps       | 2271232     |
| train/                   |             |
|    approx_kl             | 0.023860436 |
|    clip_fraction         | 0.201       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.05        |
|    cost_value_loss       | 4.33        |
|    cost_values           | 1.48        |
|    entropy               | 0.844       |
|    entropy_loss          | 0.838       |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0.00104     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.21        |
|    n_updates             | 11080       |
|    policy_gradient_loss  | 0.00936     |
|    std                   | 0.246       |
|    value_loss            | 0.699       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.7977021  |
| rollout/                 |             |
|    ep_len_mean           | 47.8        |
|    ep_rew_mean           | -24.2       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 32          |
|    time_elapsed          | 973         |
|    total_timesteps       | 2273280     |
| train/                   |             |
|    approx_kl             | 0.011693627 |
|    clip_fraction         | 0.19        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.27        |
|    cost_value_loss       | 5.42        |
|    cost_values           | 1.5         |
|    entropy               | 0.85        |
|    entropy_loss          | 0.848       |
|    explained_variance    | 0.971       |
|    lagrangian_multiplier | 0.000932    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.76        |
|    n_updates             | 11090       |
|    policy_gradient_loss  | 0.00704     |
|    std                   | 0.245       |
|    value_loss            | 1.06        |
------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.7723511  |
| rollout/                 |             |
|    ep_len_mean           | 47.1        |
|    ep_rew_mean           | -23.6       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 33          |
|    time_elapsed          | 997         |
|    total_timesteps       | 2275328     |
| train/                   |             |
|    approx_kl             | 0.020824611 |
|    clip_fraction         | 0.253       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.96        |
|    cost_value_loss       | 3.82        |
|    cost_values           | 1.56        |
|    entropy               | 0.855       |
|    entropy_loss          | 0.852       |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0.000515    |
|    learning_rate         | 0.0003      |
|    loss                  | 1.97        |
|    n_updates             | 11100       |
|    policy_gradient_loss  | 0.0117      |
|    std                   | 0.245       |
|    value_loss            | 0.644       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.4         |
| reward                   | -0.25050396 |
| rollout/                 |             |
|    ep_len_mean           | 45.8        |
|    ep_rew_mean           | -23.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 34          |
|    time_elapsed          | 1020        |
|    total_timesteps       | 2277376     |
| train/                   |             |
|    approx_kl             | 0.02753723  |
|    clip_fraction         | 0.246       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.86        |
|    cost_value_loss       | 3.55        |
|    cost_values           | 1.5         |
|    entropy               | 0.847       |
|    entropy_loss          | 0.853       |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0.00177     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.92        |
|    n_updates             | 11110       |
|    policy_gradient_loss  | 0.0159      |
|    std                   | 0.246       |
|    value_loss            | 0.488       |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.14854036 |
| rollout/                 |             |
|    ep_len_mean           | 46.9        |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 35          |
|    time_elapsed          | 1044        |
|    total_timesteps       | 2279424     |
| train/                   |             |
|    approx_kl             | 0.046346642 |
|    clip_fraction         | 0.209       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.19        |
|    cost_value_loss       | 4.87        |
|    cost_values           | 1.48        |
|    entropy               | 0.848       |
|    entropy_loss          | 0.846       |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0.000758    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.44        |
|    n_updates             | 11120       |
|    policy_gradient_loss  | 0.0164      |
|    std                   | 0.246       |
|    value_loss            | 0.651       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.4         |
| reward                   | -0.5443672  |
| rollout/                 |             |
|    ep_len_mean           | 48.1        |
|    ep_rew_mean           | -24         |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 36          |
|    time_elapsed          | 1068        |
|    total_timesteps       | 2281472     |
| train/                   |             |
|    approx_kl             | 0.037587497 |
|    clip_fraction         | 0.21        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.09        |
|    cost_value_loss       | 4.44        |
|    cost_values           | 1.5         |
|    entropy               | 0.848       |
|    entropy_loss          | 0.848       |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 0.00222     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.12        |
|    n_updates             | 11130       |
|    policy_gradient_loss  | 0.00562     |
|    std                   | 0.245       |
|    value_loss            | 0.764       |
------------------------------------------
------------------------------------------
| avg_speed                | 7           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7           |
| reward                   | -0.17076986 |
| rollout/                 |             |
|    ep_len_mean           | 47.5        |
|    ep_rew_mean           | -23.9       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 37          |
|    time_elapsed          | 1098        |
|    total_timesteps       | 2283520     |
| train/                   |             |
|    approx_kl             | 0.09364352  |
|    clip_fraction         | 0.277       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.98        |
|    cost_value_loss       | 4.09        |
|    cost_values           | 1.53        |
|    entropy               | 0.843       |
|    entropy_loss          | 0.846       |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0.00111     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.14        |
|    n_updates             | 11140       |
|    policy_gradient_loss  | 0.0168      |
|    std                   | 0.246       |
|    value_loss            | 0.725       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.2         |
| reward                   | -0.312219   |
| rollout/                 |             |
|    ep_len_mean           | 47.6        |
|    ep_rew_mean           | -24.1       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 38          |
|    time_elapsed          | 1127        |
|    total_timesteps       | 2285568     |
| train/                   |             |
|    approx_kl             | 0.012300663 |
|    clip_fraction         | 0.189       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.15        |
|    cost_value_loss       | 4.73        |
|    cost_values           | 1.53        |
|    entropy               | 0.842       |
|    entropy_loss          | 0.842       |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0.000302    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.46        |
|    n_updates             | 11150       |
|    policy_gradient_loss  | 0.011       |
|    std                   | 0.246       |
|    value_loss            | 0.66        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.6         |
| reward                   | -0.21686429 |
| rollout/                 |             |
|    ep_len_mean           | 47.4        |
|    ep_rew_mean           | -24         |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 39          |
|    time_elapsed          | 1161        |
|    total_timesteps       | 2287616     |
| train/                   |             |
|    approx_kl             | 0.03371769  |
|    clip_fraction         | 0.246       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.03        |
|    cost_value_loss       | 4           |
|    cost_values           | 1.53        |
|    entropy               | 0.843       |
|    entropy_loss          | 0.843       |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0.000585    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.17        |
|    n_updates             | 11160       |
|    policy_gradient_loss  | 0.00749     |
|    std                   | 0.245       |
|    value_loss            | 0.721       |
------------------------------------------
-----------------------------------------
| avg_speed                | 5          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 5          |
| reward                   | -0.4300778 |
| rollout/                 |            |
|    ep_len_mean           | 47.1       |
|    ep_rew_mean           | -24.2      |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 40         |
|    time_elapsed          | 1196       |
|    total_timesteps       | 2289664    |
| train/                   |            |
|    approx_kl             | 0.03691573 |
|    clip_fraction         | 0.215      |
|    clip_range            | 0.2        |
|    cost_returns          | 2.91       |
|    cost_value_loss       | 3.58       |
|    cost_values           | 1.52       |
|    entropy               | 0.84       |
|    entropy_loss          | 0.842      |
|    explained_variance    | 0.968      |
|    lagrangian_multiplier | 0.000568   |
|    learning_rate         | 0.0003     |
|    loss                  | 2.27       |
|    n_updates             | 11170      |
|    policy_gradient_loss  | 0.0133     |
|    std                   | 0.246      |
|    value_loss            | 1.2        |
-----------------------------------------
------------------------------------------
| avg_speed                | 7           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7           |
| reward                   | -0.32929528 |
| rollout/                 |             |
|    ep_len_mean           | 48.1        |
|    ep_rew_mean           | -24.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 41          |
|    time_elapsed          | 1228        |
|    total_timesteps       | 2291712     |
| train/                   |             |
|    approx_kl             | 0.021827783 |
|    clip_fraction         | 0.195       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.03        |
|    cost_value_loss       | 4.21        |
|    cost_values           | 1.55        |
|    entropy               | 0.84        |
|    entropy_loss          | 0.839       |
|    explained_variance    | 0.97        |
|    lagrangian_multiplier | 0.000836    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.41        |
|    n_updates             | 11180       |
|    policy_gradient_loss  | 0.00829     |
|    std                   | 0.246       |
|    value_loss            | 1.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 6           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6           |
| reward                   | -0.33399206 |
| rollout/                 |             |
|    ep_len_mean           | 49.8        |
|    ep_rew_mean           | -25.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 42          |
|    time_elapsed          | 1260        |
|    total_timesteps       | 2293760     |
| train/                   |             |
|    approx_kl             | 0.04512109  |
|    clip_fraction         | 0.23        |
|    clip_range            | 0.2         |
|    cost_returns          | 2.82        |
|    cost_value_loss       | 3.42        |
|    cost_values           | 1.55        |
|    entropy               | 0.839       |
|    entropy_loss          | 0.84        |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0.00147     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.97        |
|    n_updates             | 11190       |
|    policy_gradient_loss  | 0.0174      |
|    std                   | 0.245       |
|    value_loss            | 0.951       |
------------------------------------------
------------------------------------------
| avg_speed                | 3           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3           |
| reward                   | -0.66271067 |
| rollout/                 |             |
|    ep_len_mean           | 50.6        |
|    ep_rew_mean           | -24.7       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 43          |
|    time_elapsed          | 1297        |
|    total_timesteps       | 2295808     |
| train/                   |             |
|    approx_kl             | 0.026485372 |
|    clip_fraction         | 0.199       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.04        |
|    cost_value_loss       | 4.4         |
|    cost_values           | 1.51        |
|    entropy               | 0.841       |
|    entropy_loss          | 0.84        |
|    explained_variance    | 0.951       |
|    lagrangian_multiplier | 0.000241    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.79        |
|    n_updates             | 11200       |
|    policy_gradient_loss  | 0.0126      |
|    std                   | 0.245       |
|    value_loss            | 1.59        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.4         |
| reward                   | -0.24530193 |
| rollout/                 |             |
|    ep_len_mean           | 48.9        |
|    ep_rew_mean           | -24.2       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 44          |
|    time_elapsed          | 1329        |
|    total_timesteps       | 2297856     |
| train/                   |             |
|    approx_kl             | 0.037774216 |
|    clip_fraction         | 0.248       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.89        |
|    cost_value_loss       | 4.02        |
|    cost_values           | 1.51        |
|    entropy               | 0.836       |
|    entropy_loss          | 0.839       |
|    explained_variance    | 0.943       |
|    lagrangian_multiplier | 5.95e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.72        |
|    n_updates             | 11210       |
|    policy_gradient_loss  | 0.00949     |
|    std                   | 0.245       |
|    value_loss            | 1.87        |
------------------------------------------
------------------------------------------
| avg_speed                | 5           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5           |
| reward                   | -0.58003163 |
| rollout/                 |             |
|    ep_len_mean           | 46.7        |
|    ep_rew_mean           | -24.1       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 45          |
|    time_elapsed          | 1364        |
|    total_timesteps       | 2299904     |
| train/                   |             |
|    approx_kl             | 0.020259285 |
|    clip_fraction         | 0.181       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.94        |
|    cost_value_loss       | 4.06        |
|    cost_values           | 1.53        |
|    entropy               | 0.835       |
|    entropy_loss          | 0.835       |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0.00176     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.18        |
|    n_updates             | 11220       |
|    policy_gradient_loss  | 0.00685     |
|    std                   | 0.245       |
|    value_loss            | 0.98        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.7168824  |
| rollout/                 |             |
|    ep_len_mean           | 47.3        |
|    ep_rew_mean           | -24.5       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 46          |
|    time_elapsed          | 1399        |
|    total_timesteps       | 2301952     |
| train/                   |             |
|    approx_kl             | 0.042904824 |
|    clip_fraction         | 0.207       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.07        |
|    cost_value_loss       | 4.57        |
|    cost_values           | 1.52        |
|    entropy               | 0.834       |
|    entropy_loss          | 0.834       |
|    explained_variance    | 0.956       |
|    lagrangian_multiplier | 0.0016      |
|    learning_rate         | 0.0003      |
|    loss                  | 2.39        |
|    n_updates             | 11230       |
|    policy_gradient_loss  | 0.00943     |
|    std                   | 0.246       |
|    value_loss            | 1.55        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.85277545 |
| rollout/                 |             |
|    ep_len_mean           | 47.2        |
|    ep_rew_mean           | -24.2       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 47          |
|    time_elapsed          | 1431        |
|    total_timesteps       | 2304000     |
| train/                   |             |
|    approx_kl             | 0.027438587 |
|    clip_fraction         | 0.25        |
|    clip_range            | 0.2         |
|    cost_returns          | 2.86        |
|    cost_value_loss       | 3.6         |
|    cost_values           | 1.52        |
|    entropy               | 0.844       |
|    entropy_loss          | 0.838       |
|    explained_variance    | 0.965       |
|    lagrangian_multiplier | 0.000315    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.33        |
|    n_updates             | 11240       |
|    policy_gradient_loss  | 0.0197      |
|    std                   | 0.244       |
|    value_loss            | 1.36        |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.7655791  |
| rollout/                 |             |
|    ep_len_mean           | 45.3        |
|    ep_rew_mean           | -23.8       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 48          |
|    time_elapsed          | 1462        |
|    total_timesteps       | 2306048     |
| train/                   |             |
|    approx_kl             | 0.014876056 |
|    clip_fraction         | 0.173       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.83        |
|    cost_value_loss       | 3.23        |
|    cost_values           | 1.53        |
|    entropy               | 0.858       |
|    entropy_loss          | 0.851       |
|    explained_variance    | 0.973       |
|    lagrangian_multiplier | 0.0011      |
|    learning_rate         | 0.0003      |
|    loss                  | 1.98        |
|    n_updates             | 11250       |
|    policy_gradient_loss  | 0.007       |
|    std                   | 0.243       |
|    value_loss            | 0.965       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.5805881  |
| rollout/                 |             |
|    ep_len_mean           | 44.7        |
|    ep_rew_mean           | -23.6       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 49          |
|    time_elapsed          | 1493        |
|    total_timesteps       | 2308096     |
| train/                   |             |
|    approx_kl             | 0.055712312 |
|    clip_fraction         | 0.243       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.09        |
|    cost_value_loss       | 4.6         |
|    cost_values           | 1.54        |
|    entropy               | 0.856       |
|    entropy_loss          | 0.859       |
|    explained_variance    | 0.967       |
|    lagrangian_multiplier | 0.00027     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.81        |
|    n_updates             | 11260       |
|    policy_gradient_loss  | 0.0142      |
|    std                   | 0.243       |
|    value_loss            | 1.27        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ent-coefficient-ppol/1vjpjg9h
-----------------------------------
| avg_speed          | 8.02       |
| cost               | 1          |
| is_success         | 0          |
| max_speed          | 8.02       |
| reward             | -0.3305917 |
| rollout/           |            |
|    ep_len_mean     | 47.1       |
|    ep_rew_mean     | -24        |
| time/              |            |
|    fps             | 64         |
|    iterations      | 1          |
|    time_elapsed    | 31         |
|    total_timesteps | 2310144    |
-----------------------------------
------------------------------------------
| avg_speed                | 2.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.6         |
| reward                   | -0.84146863 |
| rollout/                 |             |
|    ep_len_mean           | 48.1        |
|    ep_rew_mean           | -24         |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 2           |
|    time_elapsed          | 61          |
|    total_timesteps       | 2312192     |
| train/                   |             |
|    approx_kl             | 0.02040174  |
|    clip_fraction         | 0.216       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.31        |
|    cost_value_loss       | 5.24        |
|    cost_values           | 1.48        |
|    entropy               | 0.856       |
|    entropy_loss          | 0.855       |
|    explained_variance    | 0.94        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.21        |
|    n_updates             | 11280       |
|    policy_gradient_loss  | 0.00892     |
|    std                   | 0.243       |
|    value_loss            | 1.88        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.7233436  |
| rollout/                 |             |
|    ep_len_mean           | 45.6        |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 3           |
|    time_elapsed          | 91          |
|    total_timesteps       | 2314240     |
| train/                   |             |
|    approx_kl             | 0.023448884 |
|    clip_fraction         | 0.197       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.18        |
|    cost_value_loss       | 4.66        |
|    cost_values           | 1.58        |
|    entropy               | 0.861       |
|    entropy_loss          | 0.858       |
|    explained_variance    | 0.959       |
|    lagrangian_multiplier | 0.00206     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.35        |
|    n_updates             | 11290       |
|    policy_gradient_loss  | 0.0085      |
|    std                   | 0.243       |
|    value_loss            | 1.37        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.46549088 |
| rollout/                 |             |
|    ep_len_mean           | 44.5        |
|    ep_rew_mean           | -23.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 4           |
|    time_elapsed          | 119         |
|    total_timesteps       | 2316288     |
| train/                   |             |
|    approx_kl             | 0.028495004 |
|    clip_fraction         | 0.209       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.04        |
|    cost_value_loss       | 4.12        |
|    cost_values           | 1.53        |
|    entropy               | 0.854       |
|    entropy_loss          | 0.859       |
|    explained_variance    | 0.969       |
|    lagrangian_multiplier | 0.000914    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.28        |
|    n_updates             | 11300       |
|    policy_gradient_loss  | 0.014       |
|    std                   | 0.244       |
|    value_loss            | 1.18        |
------------------------------------------
------------------------------------------
| avg_speed                | 6           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6           |
| reward                   | -0.3656319  |
| rollout/                 |             |
|    ep_len_mean           | 43.2        |
|    ep_rew_mean           | -22.9       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 5           |
|    time_elapsed          | 151         |
|    total_timesteps       | 2318336     |
| train/                   |             |
|    approx_kl             | 0.017715879 |
|    clip_fraction         | 0.229       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.89        |
|    cost_value_loss       | 3.56        |
|    cost_values           | 1.54        |
|    entropy               | 0.855       |
|    entropy_loss          | 0.854       |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.22        |
|    n_updates             | 11310       |
|    policy_gradient_loss  | 0.00742     |
|    std                   | 0.244       |
|    value_loss            | 1.01        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 1           |
| max_speed                | 8.03        |
| reward                   | -0.09927176 |
| rollout/                 |             |
|    ep_len_mean           | 43.5        |
|    ep_rew_mean           | -22.6       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 6           |
|    time_elapsed          | 185         |
|    total_timesteps       | 2320384     |
| train/                   |             |
|    approx_kl             | 0.036450505 |
|    clip_fraction         | 0.209       |
|    clip_range            | 0.2         |
|    cost_returns          | 3           |
|    cost_value_loss       | 4.25        |
|    cost_values           | 1.54        |
|    entropy               | 0.856       |
|    entropy_loss          | 0.856       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0.000437    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.41        |
|    n_updates             | 11320       |
|    policy_gradient_loss  | 0.0109      |
|    std                   | 0.244       |
|    value_loss            | 0.835       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 1           |
| max_speed                | 8           |
| reward                   | -0.10674222 |
| rollout/                 |             |
|    ep_len_mean           | 45.7        |
|    ep_rew_mean           | -23.2       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 7           |
|    time_elapsed          | 219         |
|    total_timesteps       | 2322432     |
| train/                   |             |
|    approx_kl             | 0.013766071 |
|    clip_fraction         | 0.208       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.98        |
|    cost_value_loss       | 4.13        |
|    cost_values           | 1.49        |
|    entropy               | 0.859       |
|    entropy_loss          | 0.857       |
|    explained_variance    | 0.972       |
|    lagrangian_multiplier | 0.000944    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.31        |
|    n_updates             | 11330       |
|    policy_gradient_loss  | 0.0107      |
|    std                   | 0.243       |
|    value_loss            | 1           |
------------------------------------------
-----------------------------------------
| avg_speed                | 5.8        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 5.8        |
| reward                   | -0.3779105 |
| rollout/                 |            |
|    ep_len_mean           | 44.2       |
|    ep_rew_mean           | -22.9      |
| time/                    |            |
|    fps                   | 64         |
|    iterations            | 8          |
|    time_elapsed          | 252        |
|    total_timesteps       | 2324480    |
| train/                   |            |
|    approx_kl             | 0.0283159  |
|    clip_fraction         | 0.182      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.03       |
|    cost_value_loss       | 4.71       |
|    cost_values           | 1.47       |
|    entropy               | 0.856      |
|    entropy_loss          | 0.857      |
|    explained_variance    | 0.963      |
|    lagrangian_multiplier | 0.000869   |
|    learning_rate         | 0.0003     |
|    loss                  | 2.54       |
|    n_updates             | 11340      |
|    policy_gradient_loss  | 0.0135     |
|    std                   | 0.244      |
|    value_loss            | 1.3        |
-----------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.62150717 |
| rollout/                 |             |
|    ep_len_mean           | 44.7        |
|    ep_rew_mean           | -23.2       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 9           |
|    time_elapsed          | 284         |
|    total_timesteps       | 2326528     |
| train/                   |             |
|    approx_kl             | 0.037394606 |
|    clip_fraction         | 0.206       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.92        |
|    cost_value_loss       | 3.77        |
|    cost_values           | 1.51        |
|    entropy               | 0.857       |
|    entropy_loss          | 0.856       |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0.00103     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.24        |
|    n_updates             | 11350       |
|    policy_gradient_loss  | 0.0126      |
|    std                   | 0.244       |
|    value_loss            | 0.901       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.2         |
| reward                   | -0.2694426  |
| rollout/                 |             |
|    ep_len_mean           | 43          |
|    ep_rew_mean           | -23         |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 10          |
|    time_elapsed          | 313         |
|    total_timesteps       | 2328576     |
| train/                   |             |
|    approx_kl             | 0.023038603 |
|    clip_fraction         | 0.218       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.07        |
|    cost_value_loss       | 4.35        |
|    cost_values           | 1.5         |
|    entropy               | 0.853       |
|    entropy_loss          | 0.855       |
|    explained_variance    | 0.97        |
|    lagrangian_multiplier | 0.000719    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.6         |
|    n_updates             | 11360       |
|    policy_gradient_loss  | 0.0088      |
|    std                   | 0.245       |
|    value_loss            | 1.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.2         |
| reward                   | -0.22728209 |
| rollout/                 |             |
|    ep_len_mean           | 43.4        |
|    ep_rew_mean           | -23.1       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 11          |
|    time_elapsed          | 337         |
|    total_timesteps       | 2330624     |
| train/                   |             |
|    approx_kl             | 0.02280241  |
|    clip_fraction         | 0.215       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.93        |
|    cost_value_loss       | 3.84        |
|    cost_values           | 1.54        |
|    entropy               | 0.853       |
|    entropy_loss          | 0.853       |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0.00148     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.97        |
|    n_updates             | 11370       |
|    policy_gradient_loss  | 0.00622     |
|    std                   | 0.245       |
|    value_loss            | 0.796       |
------------------------------------------
-----------------------------------------
| avg_speed                | 2.8        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 2.8        |
| reward                   | -0.7426014 |
| rollout/                 |            |
|    ep_len_mean           | 44.6       |
|    ep_rew_mean           | -23.4      |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 12         |
|    time_elapsed          | 360        |
|    total_timesteps       | 2332672    |
| train/                   |            |
|    approx_kl             | 0.02392731 |
|    clip_fraction         | 0.228      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.03       |
|    cost_value_loss       | 4.06       |
|    cost_values           | 1.45       |
|    entropy               | 0.861      |
|    entropy_loss          | 0.857      |
|    explained_variance    | 0.978      |
|    lagrangian_multiplier | 0.000376   |
|    learning_rate         | 0.0003     |
|    loss                  | 2.28       |
|    n_updates             | 11380      |
|    policy_gradient_loss  | 0.00918    |
|    std                   | 0.244      |
|    value_loss            | 0.771      |
-----------------------------------------
------------------------------------------
| avg_speed                | 4.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.4         |
| reward                   | -0.7621777  |
| rollout/                 |             |
|    ep_len_mean           | 45.6        |
|    ep_rew_mean           | -23.8       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 13          |
|    time_elapsed          | 384         |
|    total_timesteps       | 2334720     |
| train/                   |             |
|    approx_kl             | 0.016823007 |
|    clip_fraction         | 0.167       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.05        |
|    cost_value_loss       | 4.29        |
|    cost_values           | 1.49        |
|    entropy               | 0.861       |
|    entropy_loss          | 0.862       |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 0.00113     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.23        |
|    n_updates             | 11390       |
|    policy_gradient_loss  | 0.0075      |
|    std                   | 0.245       |
|    value_loss            | 0.786       |
------------------------------------------
------------------------------------------
| avg_speed                | 8.06        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.06        |
| reward                   | -0.35654086 |
| rollout/                 |             |
|    ep_len_mean           | 45          |
|    ep_rew_mean           | -23.6       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 14          |
|    time_elapsed          | 411         |
|    total_timesteps       | 2336768     |
| train/                   |             |
|    approx_kl             | 0.05578175  |
|    clip_fraction         | 0.224       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.11        |
|    cost_value_loss       | 4.29        |
|    cost_values           | 1.53        |
|    entropy               | 0.861       |
|    entropy_loss          | 0.861       |
|    explained_variance    | 0.969       |
|    lagrangian_multiplier | 0.000316    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.92        |
|    n_updates             | 11400       |
|    policy_gradient_loss  | 0.0101      |
|    std                   | 0.246       |
|    value_loss            | 1.15        |
------------------------------------------
-----------------------------------------
| avg_speed                | 2.6        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 2.6        |
| reward                   | -0.8649101 |
| rollout/                 |            |
|    ep_len_mean           | 44.7       |
|    ep_rew_mean           | -23.2      |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 15         |
|    time_elapsed          | 446        |
|    total_timesteps       | 2338816    |
| train/                   |            |
|    approx_kl             | 0.04481633 |
|    clip_fraction         | 0.236      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.08       |
|    cost_value_loss       | 4.31       |
|    cost_values           | 1.53       |
|    entropy               | 0.861      |
|    entropy_loss          | 0.86       |
|    explained_variance    | 0.963      |
|    lagrangian_multiplier | 0.000405   |
|    learning_rate         | 0.0003     |
|    loss                  | 2.65       |
|    n_updates             | 11410      |
|    policy_gradient_loss  | 0.0119     |
|    std                   | 0.246      |
|    value_loss            | 1.36       |
-----------------------------------------
------------------------------------------
| avg_speed                | 5.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.2         |
| reward                   | -0.29198658 |
| rollout/                 |             |
|    ep_len_mean           | 44.3        |
|    ep_rew_mean           | -23.2       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 16          |
|    time_elapsed          | 485         |
|    total_timesteps       | 2340864     |
| train/                   |             |
|    approx_kl             | 0.055811714 |
|    clip_fraction         | 0.176       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.01        |
|    cost_value_loss       | 4.09        |
|    cost_values           | 1.49        |
|    entropy               | 0.864       |
|    entropy_loss          | 0.863       |
|    explained_variance    | 0.953       |
|    lagrangian_multiplier | 0.00121     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.39        |
|    n_updates             | 11420       |
|    policy_gradient_loss  | 0.00573     |
|    std                   | 0.245       |
|    value_loss            | 1.57        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.2474711  |
| rollout/                 |             |
|    ep_len_mean           | 44.1        |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 17          |
|    time_elapsed          | 514         |
|    total_timesteps       | 2342912     |
| train/                   |             |
|    approx_kl             | 0.025599817 |
|    clip_fraction         | 0.175       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.04        |
|    cost_value_loss       | 4.21        |
|    cost_values           | 1.5         |
|    entropy               | 0.861       |
|    entropy_loss          | 0.863       |
|    explained_variance    | 0.971       |
|    lagrangian_multiplier | 0.000521    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.4         |
|    n_updates             | 11430       |
|    policy_gradient_loss  | 0.0101      |
|    std                   | 0.245       |
|    value_loss            | 0.974       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.83        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.83        |
| reward                   | -0.25802657 |
| rollout/                 |             |
|    ep_len_mean           | 44.4        |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 18          |
|    time_elapsed          | 546         |
|    total_timesteps       | 2344960     |
| train/                   |             |
|    approx_kl             | 0.019202624 |
|    clip_fraction         | 0.189       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.05        |
|    cost_value_loss       | 4           |
|    cost_values           | 1.54        |
|    entropy               | 0.857       |
|    entropy_loss          | 0.858       |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0.00192     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.01        |
|    n_updates             | 11440       |
|    policy_gradient_loss  | 0.00347     |
|    std                   | 0.245       |
|    value_loss            | 0.748       |
------------------------------------------
-----------------------------------------
| avg_speed                | 4.2        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 4.2        |
| reward                   | -0.6871349 |
| rollout/                 |            |
|    ep_len_mean           | 43.9       |
|    ep_rew_mean           | -23.3      |
| time/                    |            |
|    fps                   | 67         |
|    iterations            | 19         |
|    time_elapsed          | 578        |
|    total_timesteps       | 2347008    |
| train/                   |            |
|    approx_kl             | 0.02105796 |
|    clip_fraction         | 0.205      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.02       |
|    cost_value_loss       | 3.94       |
|    cost_values           | 1.57       |
|    entropy               | 0.841      |
|    entropy_loss          | 0.85       |
|    explained_variance    | 0.979      |
|    lagrangian_multiplier | 0.00101    |
|    learning_rate         | 0.0003     |
|    loss                  | 2.16       |
|    n_updates             | 11450      |
|    policy_gradient_loss  | 0.00808    |
|    std                   | 0.247      |
|    value_loss            | 0.76       |
-----------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.87463105 |
| rollout/                 |             |
|    ep_len_mean           | 44.6        |
|    ep_rew_mean           | -23.6       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 20          |
|    time_elapsed          | 616         |
|    total_timesteps       | 2349056     |
| train/                   |             |
|    approx_kl             | 0.022197194 |
|    clip_fraction         | 0.22        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.04        |
|    cost_value_loss       | 4.16        |
|    cost_values           | 1.54        |
|    entropy               | 0.844       |
|    entropy_loss          | 0.84        |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0.000653    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.42        |
|    n_updates             | 11460       |
|    policy_gradient_loss  | 0.0193      |
|    std                   | 0.248       |
|    value_loss            | 0.833       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.57203674 |
| rollout/                 |             |
|    ep_len_mean           | 45.2        |
|    ep_rew_mean           | -23.8       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 21          |
|    time_elapsed          | 651         |
|    total_timesteps       | 2351104     |
| train/                   |             |
|    approx_kl             | 0.026768755 |
|    clip_fraction         | 0.203       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.04        |
|    cost_value_loss       | 4.26        |
|    cost_values           | 1.52        |
|    entropy               | 0.852       |
|    entropy_loss          | 0.848       |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0.00041     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.45        |
|    n_updates             | 11470       |
|    policy_gradient_loss  | 0.00945     |
|    std                   | 0.247       |
|    value_loss            | 0.946       |
------------------------------------------
-----------------------------------------
| avg_speed                | 7.2        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.2        |
| reward                   | -0.3512472 |
| rollout/                 |            |
|    ep_len_mean           | 45         |
|    ep_rew_mean           | -23.3      |
| time/                    |            |
|    fps                   | 65         |
|    iterations            | 22         |
|    time_elapsed          | 686        |
|    total_timesteps       | 2353152    |
| train/                   |            |
|    approx_kl             | 0.02149581 |
|    clip_fraction         | 0.233      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.17       |
|    cost_value_loss       | 4.84       |
|    cost_values           | 1.53       |
|    entropy               | 0.855      |
|    entropy_loss          | 0.854      |
|    explained_variance    | 0.975      |
|    lagrangian_multiplier | 0.000261   |
|    learning_rate         | 0.0003     |
|    loss                  | 2.85       |
|    n_updates             | 11480      |
|    policy_gradient_loss  | 0.0152     |
|    std                   | 0.247      |
|    value_loss            | 0.874      |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.75        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.75        |
| reward                   | -0.3936863  |
| rollout/                 |             |
|    ep_len_mean           | 45.8        |
|    ep_rew_mean           | -23.4       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 23          |
|    time_elapsed          | 727         |
|    total_timesteps       | 2355200     |
| train/                   |             |
|    approx_kl             | 0.019401887 |
|    clip_fraction         | 0.178       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.17        |
|    cost_value_loss       | 4.51        |
|    cost_values           | 1.51        |
|    entropy               | 0.853       |
|    entropy_loss          | 0.854       |
|    explained_variance    | 0.963       |
|    lagrangian_multiplier | 0.000487    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.6         |
|    n_updates             | 11490       |
|    policy_gradient_loss  | 0.0118      |
|    std                   | 0.248       |
|    value_loss            | 1.19        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.4         |
| reward                   | -0.181525   |
| rollout/                 |             |
|    ep_len_mean           | 45.9        |
|    ep_rew_mean           | -23.9       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 24          |
|    time_elapsed          | 763         |
|    total_timesteps       | 2357248     |
| train/                   |             |
|    approx_kl             | 0.040592384 |
|    clip_fraction         | 0.211       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.27        |
|    cost_value_loss       | 5.2         |
|    cost_values           | 1.51        |
|    entropy               | 0.855       |
|    entropy_loss          | 0.854       |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0.00265     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.3         |
|    n_updates             | 11500       |
|    policy_gradient_loss  | 0.0175      |
|    std                   | 0.248       |
|    value_loss            | 0.879       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.33969834 |
| rollout/                 |             |
|    ep_len_mean           | 43.5        |
|    ep_rew_mean           | -23         |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 25          |
|    time_elapsed          | 798         |
|    total_timesteps       | 2359296     |
| train/                   |             |
|    approx_kl             | 0.022744456 |
|    clip_fraction         | 0.194       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.07        |
|    cost_value_loss       | 4.39        |
|    cost_values           | 1.49        |
|    entropy               | 0.855       |
|    entropy_loss          | 0.855       |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0.000584    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.49        |
|    n_updates             | 11510       |
|    policy_gradient_loss  | 0.0123      |
|    std                   | 0.248       |
|    value_loss            | 1.01        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.46225756 |
| rollout/                 |             |
|    ep_len_mean           | 44.8        |
|    ep_rew_mean           | -23.1       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 26          |
|    time_elapsed          | 834         |
|    total_timesteps       | 2361344     |
| train/                   |             |
|    approx_kl             | 0.07836267  |
|    clip_fraction         | 0.23        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.05        |
|    cost_value_loss       | 4.58        |
|    cost_values           | 1.48        |
|    entropy               | 0.856       |
|    entropy_loss          | 0.855       |
|    explained_variance    | 0.972       |
|    lagrangian_multiplier | 0.000371    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.48        |
|    n_updates             | 11520       |
|    policy_gradient_loss  | 0.0148      |
|    std                   | 0.248       |
|    value_loss            | 0.955       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.13385162 |
| rollout/                 |             |
|    ep_len_mean           | 45          |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 27          |
|    time_elapsed          | 861         |
|    total_timesteps       | 2363392     |
| train/                   |             |
|    approx_kl             | 0.019510068 |
|    clip_fraction         | 0.215       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.99        |
|    cost_value_loss       | 4.21        |
|    cost_values           | 1.46        |
|    entropy               | 0.851       |
|    entropy_loss          | 0.854       |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.47        |
|    n_updates             | 11530       |
|    policy_gradient_loss  | 0.0117      |
|    std                   | 0.249       |
|    value_loss            | 0.692       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.32288733 |
| rollout/                 |             |
|    ep_len_mean           | 43.3        |
|    ep_rew_mean           | -23         |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 28          |
|    time_elapsed          | 888         |
|    total_timesteps       | 2365440     |
| train/                   |             |
|    approx_kl             | 0.048089314 |
|    clip_fraction         | 0.215       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.11        |
|    cost_value_loss       | 4.59        |
|    cost_values           | 1.49        |
|    entropy               | 0.849       |
|    entropy_loss          | 0.85        |
|    explained_variance    | 0.966       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.89        |
|    n_updates             | 11540       |
|    policy_gradient_loss  | 0.014       |
|    std                   | 0.249       |
|    value_loss            | 1.18        |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.6        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.6        |
| reward                   | -0.8910221 |
| rollout/                 |            |
|    ep_len_mean           | 43.1       |
|    ep_rew_mean           | -23.1      |
| time/                    |            |
|    fps                   | 64         |
|    iterations            | 29         |
|    time_elapsed          | 915        |
|    total_timesteps       | 2367488    |
| train/                   |            |
|    approx_kl             | 0.03138403 |
|    clip_fraction         | 0.231      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.07       |
|    cost_value_loss       | 4.36       |
|    cost_values           | 1.53       |
|    entropy               | 0.85       |
|    entropy_loss          | 0.85       |
|    explained_variance    | 0.972      |
|    lagrangian_multiplier | 0.000675   |
|    learning_rate         | 0.0003     |
|    loss                  | 2.45       |
|    n_updates             | 11550      |
|    policy_gradient_loss  | 0.0104     |
|    std                   | 0.249      |
|    value_loss            | 1.05       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.35023335 |
| rollout/                 |             |
|    ep_len_mean           | 45          |
|    ep_rew_mean           | -23.8       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 30          |
|    time_elapsed          | 946         |
|    total_timesteps       | 2369536     |
| train/                   |             |
|    approx_kl             | 0.015497823 |
|    clip_fraction         | 0.193       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.1         |
|    cost_value_loss       | 4.87        |
|    cost_values           | 1.48        |
|    entropy               | 0.85        |
|    entropy_loss          | 0.85        |
|    explained_variance    | 0.969       |
|    lagrangian_multiplier | 0.00151     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.44        |
|    n_updates             | 11560       |
|    policy_gradient_loss  | 0.00977     |
|    std                   | 0.249       |
|    value_loss            | 1.06        |
------------------------------------------
-----------------------------------------
| avg_speed                | 4.2        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 4.2        |
| reward                   | -0.5136655 |
| rollout/                 |            |
|    ep_len_mean           | 44.1       |
|    ep_rew_mean           | -23.5      |
| time/                    |            |
|    fps                   | 65         |
|    iterations            | 31         |
|    time_elapsed          | 975        |
|    total_timesteps       | 2371584    |
| train/                   |            |
|    approx_kl             | 0.0336062  |
|    clip_fraction         | 0.248      |
|    clip_range            | 0.2        |
|    cost_returns          | 2.9        |
|    cost_value_loss       | 3.88       |
|    cost_values           | 1.48       |
|    entropy               | 0.856      |
|    entropy_loss          | 0.854      |
|    explained_variance    | 0.967      |
|    lagrangian_multiplier | 0.000148   |
|    learning_rate         | 0.0003     |
|    loss                  | 2.63       |
|    n_updates             | 11570      |
|    policy_gradient_loss  | 0.0148     |
|    std                   | 0.248      |
|    value_loss            | 1.14       |
-----------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.75165117 |
| rollout/                 |             |
|    ep_len_mean           | 44          |
|    ep_rew_mean           | -23.4       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 32          |
|    time_elapsed          | 1008        |
|    total_timesteps       | 2373632     |
| train/                   |             |
|    approx_kl             | 0.014102366 |
|    clip_fraction         | 0.219       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.12        |
|    cost_value_loss       | 4.68        |
|    cost_values           | 1.47        |
|    entropy               | 0.862       |
|    entropy_loss          | 0.859       |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0.000876    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.36        |
|    n_updates             | 11580       |
|    policy_gradient_loss  | 0.00823     |
|    std                   | 0.247       |
|    value_loss            | 0.81        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.19        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.19        |
| reward                   | -0.25928214 |
| rollout/                 |             |
|    ep_len_mean           | 43.9        |
|    ep_rew_mean           | -23         |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 33          |
|    time_elapsed          | 1044        |
|    total_timesteps       | 2375680     |
| train/                   |             |
|    approx_kl             | 0.026137214 |
|    clip_fraction         | 0.26        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.13        |
|    cost_value_loss       | 4.45        |
|    cost_values           | 1.52        |
|    entropy               | 0.86        |
|    entropy_loss          | 0.862       |
|    explained_variance    | 0.967       |
|    lagrangian_multiplier | 0.00121     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.29        |
|    n_updates             | 11590       |
|    policy_gradient_loss  | 0.0147      |
|    std                   | 0.247       |
|    value_loss            | 1.16        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.84399563 |
| rollout/                 |             |
|    ep_len_mean           | 44.5        |
|    ep_rew_mean           | -23.5       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 34          |
|    time_elapsed          | 1076        |
|    total_timesteps       | 2377728     |
| train/                   |             |
|    approx_kl             | 0.026035324 |
|    clip_fraction         | 0.228       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.07        |
|    cost_value_loss       | 4.2         |
|    cost_values           | 1.53        |
|    entropy               | 0.857       |
|    entropy_loss          | 0.859       |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0.000965    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.26        |
|    n_updates             | 11600       |
|    policy_gradient_loss  | 0.0127      |
|    std                   | 0.247       |
|    value_loss            | 0.707       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.6         |
| reward                   | -0.34070304 |
| rollout/                 |             |
|    ep_len_mean           | 45.2        |
|    ep_rew_mean           | -23.6       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 35          |
|    time_elapsed          | 1101        |
|    total_timesteps       | 2379776     |
| train/                   |             |
|    approx_kl             | 0.022139426 |
|    clip_fraction         | 0.22        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.07        |
|    cost_value_loss       | 4.31        |
|    cost_values           | 1.51        |
|    entropy               | 0.855       |
|    entropy_loss          | 0.855       |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0.000303    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.62        |
|    n_updates             | 11610       |
|    policy_gradient_loss  | 0.0129      |
|    std                   | 0.248       |
|    value_loss            | 1.01        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3226995  |
| rollout/                 |             |
|    ep_len_mean           | 45.4        |
|    ep_rew_mean           | -23         |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 36          |
|    time_elapsed          | 1124        |
|    total_timesteps       | 2381824     |
| train/                   |             |
|    approx_kl             | 0.024450842 |
|    clip_fraction         | 0.238       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.06        |
|    cost_value_loss       | 4.25        |
|    cost_values           | 1.52        |
|    entropy               | 0.863       |
|    entropy_loss          | 0.859       |
|    explained_variance    | 0.967       |
|    lagrangian_multiplier | 0.000748    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.44        |
|    n_updates             | 11620       |
|    policy_gradient_loss  | 0.0119      |
|    std                   | 0.246       |
|    value_loss            | 1.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.37808824 |
| rollout/                 |             |
|    ep_len_mean           | 44.5        |
|    ep_rew_mean           | -22.9       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 37          |
|    time_elapsed          | 1148        |
|    total_timesteps       | 2383872     |
| train/                   |             |
|    approx_kl             | 0.032711368 |
|    clip_fraction         | 0.196       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.11        |
|    cost_value_loss       | 4.25        |
|    cost_values           | 1.51        |
|    entropy               | 0.871       |
|    entropy_loss          | 0.867       |
|    explained_variance    | 0.96        |
|    lagrangian_multiplier | 0.000306    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.51        |
|    n_updates             | 11630       |
|    policy_gradient_loss  | 0.0132      |
|    std                   | 0.246       |
|    value_loss            | 1.21        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.34789863 |
| rollout/                 |             |
|    ep_len_mean           | 43.9        |
|    ep_rew_mean           | -22.9       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 38          |
|    time_elapsed          | 1180        |
|    total_timesteps       | 2385920     |
| train/                   |             |
|    approx_kl             | 0.021248389 |
|    clip_fraction         | 0.178       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.21        |
|    cost_value_loss       | 4.64        |
|    cost_values           | 1.53        |
|    entropy               | 0.873       |
|    entropy_loss          | 0.872       |
|    explained_variance    | 0.973       |
|    lagrangian_multiplier | 0.000317    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.5         |
|    n_updates             | 11640       |
|    policy_gradient_loss  | 0.00964     |
|    std                   | 0.246       |
|    value_loss            | 0.958       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.64964074 |
| rollout/                 |             |
|    ep_len_mean           | 44          |
|    ep_rew_mean           | -23         |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 39          |
|    time_elapsed          | 1217        |
|    total_timesteps       | 2387968     |
| train/                   |             |
|    approx_kl             | 0.02551017  |
|    clip_fraction         | 0.196       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.08        |
|    cost_value_loss       | 4.15        |
|    cost_values           | 1.53        |
|    entropy               | 0.877       |
|    entropy_loss          | 0.875       |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0.00069     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.34        |
|    n_updates             | 11650       |
|    policy_gradient_loss  | 0.0115      |
|    std                   | 0.246       |
|    value_loss            | 0.841       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.86724913 |
| rollout/                 |             |
|    ep_len_mean           | 43.5        |
|    ep_rew_mean           | -22.7       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 40          |
|    time_elapsed          | 1250        |
|    total_timesteps       | 2390016     |
| train/                   |             |
|    approx_kl             | 0.037833173 |
|    clip_fraction         | 0.257       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.08        |
|    cost_value_loss       | 4.39        |
|    cost_values           | 1.51        |
|    entropy               | 0.882       |
|    entropy_loss          | 0.88        |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0.00179     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.07        |
|    n_updates             | 11660       |
|    policy_gradient_loss  | 0.0105      |
|    std                   | 0.246       |
|    value_loss            | 0.568       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.6         |
| reward                   | -0.7099785  |
| rollout/                 |             |
|    ep_len_mean           | 42.5        |
|    ep_rew_mean           | -22.7       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 41          |
|    time_elapsed          | 1282        |
|    total_timesteps       | 2392064     |
| train/                   |             |
|    approx_kl             | 0.026120862 |
|    clip_fraction         | 0.222       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.03        |
|    cost_value_loss       | 4.22        |
|    cost_values           | 1.49        |
|    entropy               | 0.894       |
|    entropy_loss          | 0.888       |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0.00114     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.02        |
|    n_updates             | 11670       |
|    policy_gradient_loss  | 0.0131      |
|    std                   | 0.245       |
|    value_loss            | 0.665       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.7415662  |
| rollout/                 |             |
|    ep_len_mean           | 43.1        |
|    ep_rew_mean           | -23.1       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 42          |
|    time_elapsed          | 1316        |
|    total_timesteps       | 2394112     |
| train/                   |             |
|    approx_kl             | 0.016271513 |
|    clip_fraction         | 0.203       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.09        |
|    cost_value_loss       | 4.45        |
|    cost_values           | 1.51        |
|    entropy               | 0.896       |
|    entropy_loss          | 0.896       |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0.00201     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.04        |
|    n_updates             | 11680       |
|    policy_gradient_loss  | 0.0107      |
|    std                   | 0.244       |
|    value_loss            | 0.84        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.6552247  |
| rollout/                 |             |
|    ep_len_mean           | 43.3        |
|    ep_rew_mean           | -23.2       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 43          |
|    time_elapsed          | 1345        |
|    total_timesteps       | 2396160     |
| train/                   |             |
|    approx_kl             | 0.016357098 |
|    clip_fraction         | 0.206       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.19        |
|    cost_value_loss       | 4.65        |
|    cost_values           | 1.57        |
|    entropy               | 0.903       |
|    entropy_loss          | 0.9         |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0.000831    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.33        |
|    n_updates             | 11690       |
|    policy_gradient_loss  | 0.0129      |
|    std                   | 0.244       |
|    value_loss            | 0.882       |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.31038806 |
| rollout/                 |             |
|    ep_len_mean           | 44.9        |
|    ep_rew_mean           | -24.3       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 44          |
|    time_elapsed          | 1374        |
|    total_timesteps       | 2398208     |
| train/                   |             |
|    approx_kl             | 0.021192696 |
|    clip_fraction         | 0.234       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.26        |
|    cost_value_loss       | 4.8         |
|    cost_values           | 1.57        |
|    entropy               | 0.901       |
|    entropy_loss          | 0.902       |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0.00149     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.34        |
|    n_updates             | 11700       |
|    policy_gradient_loss  | 0.0138      |
|    std                   | 0.245       |
|    value_loss            | 0.849       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.8         |
| reward                   | -0.37363654 |
| rollout/                 |             |
|    ep_len_mean           | 45.4        |
|    ep_rew_mean           | -24.2       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 45          |
|    time_elapsed          | 1405        |
|    total_timesteps       | 2400256     |
| train/                   |             |
|    approx_kl             | 0.0140873   |
|    clip_fraction         | 0.179       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.24        |
|    cost_value_loss       | 4.85        |
|    cost_values           | 1.55        |
|    entropy               | 0.901       |
|    entropy_loss          | 0.901       |
|    explained_variance    | 0.971       |
|    lagrangian_multiplier | 0.00359     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.18        |
|    n_updates             | 11710       |
|    policy_gradient_loss  | 0.00493     |
|    std                   | 0.244       |
|    value_loss            | 1.03        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.6964047  |
| rollout/                 |             |
|    ep_len_mean           | 45.8        |
|    ep_rew_mean           | -24.1       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 46          |
|    time_elapsed          | 1440        |
|    total_timesteps       | 2402304     |
| train/                   |             |
|    approx_kl             | 0.025027933 |
|    clip_fraction         | 0.256       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.23        |
|    cost_value_loss       | 4.96        |
|    cost_values           | 1.53        |
|    entropy               | 0.905       |
|    entropy_loss          | 0.903       |
|    explained_variance    | 0.97        |
|    lagrangian_multiplier | 0.000295    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.84        |
|    n_updates             | 11720       |
|    policy_gradient_loss  | 0.00966     |
|    std                   | 0.243       |
|    value_loss            | 1.08        |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.6        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.6        |
| reward                   | -0.7680628 |
| rollout/                 |            |
|    ep_len_mean           | 45.2       |
|    ep_rew_mean           | -23.9      |
| time/                    |            |
|    fps                   | 65         |
|    iterations            | 47         |
|    time_elapsed          | 1476       |
|    total_timesteps       | 2404352    |
| train/                   |            |
|    approx_kl             | 0.06619927 |
|    clip_fraction         | 0.222      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.24       |
|    cost_value_loss       | 4.83       |
|    cost_values           | 1.52       |
|    entropy               | 0.909      |
|    entropy_loss          | 0.907      |
|    explained_variance    | 0.972      |
|    lagrangian_multiplier | 0.00178    |
|    learning_rate         | 0.0003     |
|    loss                  | 2.41       |
|    n_updates             | 11730      |
|    policy_gradient_loss  | 0.0114     |
|    std                   | 0.243      |
|    value_loss            | 1.1        |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.30920932 |
| rollout/                 |             |
|    ep_len_mean           | 46          |
|    ep_rew_mean           | -24         |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 48          |
|    time_elapsed          | 1512        |
|    total_timesteps       | 2406400     |
| train/                   |             |
|    approx_kl             | 0.030630376 |
|    clip_fraction         | 0.21        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.23        |
|    cost_value_loss       | 4.94        |
|    cost_values           | 1.58        |
|    entropy               | 0.905       |
|    entropy_loss          | 0.907       |
|    explained_variance    | 0.971       |
|    lagrangian_multiplier | 0.000985    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.58        |
|    n_updates             | 11740       |
|    policy_gradient_loss  | 0.0087      |
|    std                   | 0.243       |
|    value_loss            | 1.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.791272   |
| rollout/                 |             |
|    ep_len_mean           | 45.1        |
|    ep_rew_mean           | -23.7       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 49          |
|    time_elapsed          | 1548        |
|    total_timesteps       | 2408448     |
| train/                   |             |
|    approx_kl             | 0.043588944 |
|    clip_fraction         | 0.226       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.37        |
|    cost_value_loss       | 5.26        |
|    cost_values           | 1.62        |
|    entropy               | 0.897       |
|    entropy_loss          | 0.901       |
|    explained_variance    | 0.971       |
|    lagrangian_multiplier | 0.000829    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.63        |
|    n_updates             | 11750       |
|    policy_gradient_loss  | 0.00898     |
|    std                   | 0.244       |
|    value_loss            | 1.07        |
------------------------------------------
-----------------------------------
| avg_speed          | 3          |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 3          |
| reward             | -0.8901732 |
| rollout/           |            |
|    ep_len_mean     | 43.8       |
|    ep_rew_mean     | -23.3      |
| time/              |            |
|    fps             | 66         |
|    iterations      | 1          |
|    time_elapsed    | 30         |
|    total_timesteps | 2410496    |
-----------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.6298346  |
| rollout/                 |             |
|    ep_len_mean           | 43.4        |
|    ep_rew_mean           | -22.9       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 2           |
|    time_elapsed          | 60          |
|    total_timesteps       | 2412544     |
| train/                   |             |
|    approx_kl             | 0.035661347 |
|    clip_fraction         | 0.234       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.2         |
|    cost_value_loss       | 4.52        |
|    cost_values           | 1.61        |
|    entropy               | 0.888       |
|    entropy_loss          | 0.891       |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 0.00211     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.13        |
|    n_updates             | 11770       |
|    policy_gradient_loss  | 0.00884     |
|    std                   | 0.245       |
|    value_loss            | 0.786       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.39752117 |
| rollout/                 |             |
|    ep_len_mean           | 43.6        |
|    ep_rew_mean           | -23.1       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 3           |
|    time_elapsed          | 90          |
|    total_timesteps       | 2414592     |
| train/                   |             |
|    approx_kl             | 0.028486416 |
|    clip_fraction         | 0.225       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.18        |
|    cost_value_loss       | 4.67        |
|    cost_values           | 1.59        |
|    entropy               | 0.893       |
|    entropy_loss          | 0.89        |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0.00331     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.16        |
|    n_updates             | 11780       |
|    policy_gradient_loss  | 0.0118      |
|    std                   | 0.243       |
|    value_loss            | 0.676       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.8         |
| reward                   | -0.12903537 |
| rollout/                 |             |
|    ep_len_mean           | 42.8        |
|    ep_rew_mean           | -23.1       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 4           |
|    time_elapsed          | 123         |
|    total_timesteps       | 2416640     |
| train/                   |             |
|    approx_kl             | 0.023678385 |
|    clip_fraction         | 0.225       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.13        |
|    cost_value_loss       | 4.36        |
|    cost_values           | 1.55        |
|    entropy               | 0.9         |
|    entropy_loss          | 0.897       |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0.000727    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.37        |
|    n_updates             | 11790       |
|    policy_gradient_loss  | 0.00496     |
|    std                   | 0.242       |
|    value_loss            | 0.648       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.8         |
| reward                   | -0.30605486 |
| rollout/                 |             |
|    ep_len_mean           | 42.6        |
|    ep_rew_mean           | -22.8       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 5           |
|    time_elapsed          | 152         |
|    total_timesteps       | 2418688     |
| train/                   |             |
|    approx_kl             | 0.021977082 |
|    clip_fraction         | 0.156       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.11        |
|    cost_value_loss       | 4.14        |
|    cost_values           | 1.56        |
|    entropy               | 0.892       |
|    entropy_loss          | 0.897       |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0.00255     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.03        |
|    n_updates             | 11800       |
|    policy_gradient_loss  | 0.00182     |
|    std                   | 0.243       |
|    value_loss            | 0.481       |
------------------------------------------
-----------------------------------------
| avg_speed                | 1          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 1          |
| reward                   | -0.6637215 |
| rollout/                 |            |
|    ep_len_mean           | 42.8       |
|    ep_rew_mean           | -22.7      |
| time/                    |            |
|    fps                   | 69         |
|    iterations            | 6          |
|    time_elapsed          | 176        |
|    total_timesteps       | 2420736    |
| train/                   |            |
|    approx_kl             | 0.03565424 |
|    clip_fraction         | 0.218      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.02       |
|    cost_value_loss       | 3.9        |
|    cost_values           | 1.54       |
|    entropy               | 0.89       |
|    entropy_loss          | 0.891      |
|    explained_variance    | 0.983      |
|    lagrangian_multiplier | 0.000537   |
|    learning_rate         | 0.0003     |
|    loss                  | 1.97       |
|    n_updates             | 11810      |
|    policy_gradient_loss  | 0.014      |
|    std                   | 0.243      |
|    value_loss            | 0.573      |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.7722232  |
| rollout/                 |             |
|    ep_len_mean           | 43.4        |
|    ep_rew_mean           | -22.5       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 7           |
|    time_elapsed          | 201         |
|    total_timesteps       | 2422784     |
| train/                   |             |
|    approx_kl             | 0.028978646 |
|    clip_fraction         | 0.221       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.95        |
|    cost_value_loss       | 3.66        |
|    cost_values           | 1.54        |
|    entropy               | 0.891       |
|    entropy_loss          | 0.89        |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0.00125     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.94        |
|    n_updates             | 11820       |
|    policy_gradient_loss  | 0.00776     |
|    std                   | 0.242       |
|    value_loss            | 0.701       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.59001786 |
| rollout/                 |             |
|    ep_len_mean           | 44.7        |
|    ep_rew_mean           | -22.8       |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 8           |
|    time_elapsed          | 226         |
|    total_timesteps       | 2424832     |
| train/                   |             |
|    approx_kl             | 0.03793421  |
|    clip_fraction         | 0.222       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.05        |
|    cost_value_loss       | 4.14        |
|    cost_values           | 1.5         |
|    entropy               | 0.888       |
|    entropy_loss          | 0.89        |
|    explained_variance    | 0.973       |
|    lagrangian_multiplier | 0.00041     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.2         |
|    n_updates             | 11830       |
|    policy_gradient_loss  | 0.00585     |
|    std                   | 0.241       |
|    value_loss            | 0.808       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.6         |
| reward                   | -0.25852722 |
| rollout/                 |             |
|    ep_len_mean           | 44.3        |
|    ep_rew_mean           | -23.6       |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 9           |
|    time_elapsed          | 252         |
|    total_timesteps       | 2426880     |
| train/                   |             |
|    approx_kl             | 0.020319879 |
|    clip_fraction         | 0.199       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.1         |
|    cost_value_loss       | 4.04        |
|    cost_values           | 1.6         |
|    entropy               | 0.894       |
|    entropy_loss          | 0.89        |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0.00331     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.06        |
|    n_updates             | 11840       |
|    policy_gradient_loss  | 0.011       |
|    std                   | 0.239       |
|    value_loss            | 0.916       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.2         |
| reward                   | -0.22209562 |
| rollout/                 |             |
|    ep_len_mean           | 45.5        |
|    ep_rew_mean           | -23.6       |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 10          |
|    time_elapsed          | 281         |
|    total_timesteps       | 2428928     |
| train/                   |             |
|    approx_kl             | 0.019708967 |
|    clip_fraction         | 0.175       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.13        |
|    cost_value_loss       | 4.18        |
|    cost_values           | 1.56        |
|    entropy               | 0.89        |
|    entropy_loss          | 0.893       |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0.000374    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.28        |
|    n_updates             | 11850       |
|    policy_gradient_loss  | 0.00517     |
|    std                   | 0.239       |
|    value_loss            | 0.67        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.4         |
| reward                   | -0.54615575 |
| rollout/                 |             |
|    ep_len_mean           | 45.2        |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 11          |
|    time_elapsed          | 310         |
|    total_timesteps       | 2430976     |
| train/                   |             |
|    approx_kl             | 0.03773716  |
|    clip_fraction         | 0.252       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.2         |
|    cost_value_loss       | 4.6         |
|    cost_values           | 1.55        |
|    entropy               | 0.881       |
|    entropy_loss          | 0.886       |
|    explained_variance    | 0.97        |
|    lagrangian_multiplier | 0.00105     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.38        |
|    n_updates             | 11860       |
|    policy_gradient_loss  | 0.00484     |
|    std                   | 0.241       |
|    value_loss            | 1.03        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.60897696 |
| rollout/                 |             |
|    ep_len_mean           | 43.8        |
|    ep_rew_mean           | -23         |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 12          |
|    time_elapsed          | 339         |
|    total_timesteps       | 2433024     |
| train/                   |             |
|    approx_kl             | 0.029927863 |
|    clip_fraction         | 0.201       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.23        |
|    cost_value_loss       | 4.6         |
|    cost_values           | 1.63        |
|    entropy               | 0.885       |
|    entropy_loss          | 0.882       |
|    explained_variance    | 0.964       |
|    lagrangian_multiplier | 0.00131     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.47        |
|    n_updates             | 11870       |
|    policy_gradient_loss  | 0.0107      |
|    std                   | 0.24        |
|    value_loss            | 1.24        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.37119067 |
| rollout/                 |             |
|    ep_len_mean           | 43.7        |
|    ep_rew_mean           | -23.5       |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 13          |
|    time_elapsed          | 365         |
|    total_timesteps       | 2435072     |
| train/                   |             |
|    approx_kl             | 0.03334195  |
|    clip_fraction         | 0.211       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.05        |
|    cost_value_loss       | 3.97        |
|    cost_values           | 1.6         |
|    entropy               | 0.887       |
|    entropy_loss          | 0.886       |
|    explained_variance    | 0.97        |
|    lagrangian_multiplier | 0.000732    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.28        |
|    n_updates             | 11880       |
|    policy_gradient_loss  | 0.00765     |
|    std                   | 0.24        |
|    value_loss            | 1.05        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.2         |
| reward                   | -0.4527759  |
| rollout/                 |             |
|    ep_len_mean           | 43.5        |
|    ep_rew_mean           | -23.6       |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 14          |
|    time_elapsed          | 389         |
|    total_timesteps       | 2437120     |
| train/                   |             |
|    approx_kl             | 0.015681626 |
|    clip_fraction         | 0.231       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.96        |
|    cost_value_loss       | 3.76        |
|    cost_values           | 1.53        |
|    entropy               | 0.89        |
|    entropy_loss          | 0.888       |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0.001       |
|    learning_rate         | 0.0003      |
|    loss                  | 2.2         |
|    n_updates             | 11890       |
|    policy_gradient_loss  | 0.00953     |
|    std                   | 0.24        |
|    value_loss            | 0.961       |
------------------------------------------
------------------------------------------
| avg_speed                | 5           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5           |
| reward                   | -0.301982   |
| rollout/                 |             |
|    ep_len_mean           | 43.9        |
|    ep_rew_mean           | -23.5       |
| time/                    |             |
|    fps                   | 74          |
|    iterations            | 15          |
|    time_elapsed          | 412         |
|    total_timesteps       | 2439168     |
| train/                   |             |
|    approx_kl             | 0.039000012 |
|    clip_fraction         | 0.222       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.96        |
|    cost_value_loss       | 3.85        |
|    cost_values           | 1.51        |
|    entropy               | 0.888       |
|    entropy_loss          | 0.89        |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 0.0011      |
|    learning_rate         | 0.0003      |
|    loss                  | 2.05        |
|    n_updates             | 11900       |
|    policy_gradient_loss  | 0.00596     |
|    std                   | 0.24        |
|    value_loss            | 0.789       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.37497383 |
| rollout/                 |             |
|    ep_len_mean           | 42.9        |
|    ep_rew_mean           | -22.9       |
| time/                    |             |
|    fps                   | 74          |
|    iterations            | 16          |
|    time_elapsed          | 442         |
|    total_timesteps       | 2441216     |
| train/                   |             |
|    approx_kl             | 0.023639351 |
|    clip_fraction         | 0.213       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.16        |
|    cost_value_loss       | 4.67        |
|    cost_values           | 1.51        |
|    entropy               | 0.889       |
|    entropy_loss          | 0.889       |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0.000403    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.61        |
|    n_updates             | 11910       |
|    policy_gradient_loss  | 0.00312     |
|    std                   | 0.239       |
|    value_loss            | 0.957       |
------------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.6810193  |
| rollout/                 |             |
|    ep_len_mean           | 43.3        |
|    ep_rew_mean           | -22.9       |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 17          |
|    time_elapsed          | 475         |
|    total_timesteps       | 2443264     |
| train/                   |             |
|    approx_kl             | 0.024234671 |
|    clip_fraction         | 0.21        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.12        |
|    cost_value_loss       | 4.33        |
|    cost_values           | 1.58        |
|    entropy               | 0.886       |
|    entropy_loss          | 0.888       |
|    explained_variance    | 0.969       |
|    lagrangian_multiplier | 0.00196     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.24        |
|    n_updates             | 11920       |
|    policy_gradient_loss  | 0.00757     |
|    std                   | 0.239       |
|    value_loss            | 1.16        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.8         |
| reward                   | -0.14969245 |
| rollout/                 |             |
|    ep_len_mean           | 44.5        |
|    ep_rew_mean           | -23         |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 18          |
|    time_elapsed          | 506         |
|    total_timesteps       | 2445312     |
| train/                   |             |
|    approx_kl             | 0.016218979 |
|    clip_fraction         | 0.178       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.21        |
|    cost_value_loss       | 4.48        |
|    cost_values           | 1.58        |
|    entropy               | 0.888       |
|    entropy_loss          | 0.887       |
|    explained_variance    | 0.966       |
|    lagrangian_multiplier | 0.000855    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.35        |
|    n_updates             | 11930       |
|    policy_gradient_loss  | 0.00722     |
|    std                   | 0.239       |
|    value_loss            | 1.2         |
------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.3851039  |
| rollout/                 |             |
|    ep_len_mean           | 43.2        |
|    ep_rew_mean           | -22.9       |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 19          |
|    time_elapsed          | 533         |
|    total_timesteps       | 2447360     |
| train/                   |             |
|    approx_kl             | 0.032129917 |
|    clip_fraction         | 0.212       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.11        |
|    cost_value_loss       | 4.06        |
|    cost_values           | 1.57        |
|    entropy               | 0.89        |
|    entropy_loss          | 0.89        |
|    explained_variance    | 0.947       |
|    lagrangian_multiplier | 0.000952    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.35        |
|    n_updates             | 11940       |
|    policy_gradient_loss  | 0.0117      |
|    std                   | 0.239       |
|    value_loss            | 1.57        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.9113012  |
| rollout/                 |             |
|    ep_len_mean           | 44.8        |
|    ep_rew_mean           | -23.7       |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 20          |
|    time_elapsed          | 559         |
|    total_timesteps       | 2449408     |
| train/                   |             |
|    approx_kl             | 0.031268444 |
|    clip_fraction         | 0.136       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.05        |
|    cost_value_loss       | 3.82        |
|    cost_values           | 1.61        |
|    entropy               | 0.891       |
|    entropy_loss          | 0.89        |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0.00158     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.09        |
|    n_updates             | 11950       |
|    policy_gradient_loss  | -0.000931   |
|    std                   | 0.239       |
|    value_loss            | 0.866       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.77780426 |
| rollout/                 |             |
|    ep_len_mean           | 45.3        |
|    ep_rew_mean           | -24.1       |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 21          |
|    time_elapsed          | 586         |
|    total_timesteps       | 2451456     |
| train/                   |             |
|    approx_kl             | 0.041219473 |
|    clip_fraction         | 0.198       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.08        |
|    cost_value_loss       | 4.17        |
|    cost_values           | 1.55        |
|    entropy               | 0.896       |
|    entropy_loss          | 0.894       |
|    explained_variance    | 0.969       |
|    lagrangian_multiplier | 0.000682    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.44        |
|    n_updates             | 11960       |
|    policy_gradient_loss  | 0.00947     |
|    std                   | 0.238       |
|    value_loss            | 1.16        |
------------------------------------------
-----------------------------------------
| avg_speed                | 1          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 1          |
| reward                   | -0.8720816 |
| rollout/                 |            |
|    ep_len_mean           | 44.9       |
|    ep_rew_mean           | -24.1      |
| time/                    |            |
|    fps                   | 73         |
|    iterations            | 22         |
|    time_elapsed          | 612        |
|    total_timesteps       | 2453504    |
| train/                   |            |
|    approx_kl             | 0.02116273 |
|    clip_fraction         | 0.222      |
|    clip_range            | 0.2        |
|    cost_returns          | 2.84       |
|    cost_value_loss       | 3.38       |
|    cost_values           | 1.59       |
|    entropy               | 0.907      |
|    entropy_loss          | 0.902      |
|    explained_variance    | 0.979      |
|    lagrangian_multiplier | 0.000897   |
|    learning_rate         | 0.0003     |
|    loss                  | 2.03       |
|    n_updates             | 11970      |
|    policy_gradient_loss  | 0.0106     |
|    std                   | 0.236      |
|    value_loss            | 0.798      |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.68419373 |
| rollout/                 |             |
|    ep_len_mean           | 44.8        |
|    ep_rew_mean           | -23.7       |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 23          |
|    time_elapsed          | 643         |
|    total_timesteps       | 2455552     |
| train/                   |             |
|    approx_kl             | 0.03837209  |
|    clip_fraction         | 0.198       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.11        |
|    cost_value_loss       | 4.29        |
|    cost_values           | 1.53        |
|    entropy               | 0.912       |
|    entropy_loss          | 0.91        |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0.000676    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.35        |
|    n_updates             | 11980       |
|    policy_gradient_loss  | 0.00873     |
|    std                   | 0.236       |
|    value_loss            | 0.912       |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.6        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.6        |
| reward                   | -0.5915407 |
| rollout/                 |            |
|    ep_len_mean           | 43         |
|    ep_rew_mean           | -23.5      |
| time/                    |            |
|    fps                   | 73         |
|    iterations            | 24         |
|    time_elapsed          | 672        |
|    total_timesteps       | 2457600    |
| train/                   |            |
|    approx_kl             | 0.03679954 |
|    clip_fraction         | 0.211      |
|    clip_range            | 0.2        |
|    cost_returns          | 2.95       |
|    cost_value_loss       | 3.87       |
|    cost_values           | 1.54       |
|    entropy               | 0.909      |
|    entropy_loss          | 0.911      |
|    explained_variance    | 0.983      |
|    lagrangian_multiplier | 0.000155   |
|    learning_rate         | 0.0003     |
|    loss                  | 2.36       |
|    n_updates             | 11990      |
|    policy_gradient_loss  | 0.0127     |
|    std                   | 0.237      |
|    value_loss            | 0.636      |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.6         |
| reward                   | -0.38066587 |
| rollout/                 |             |
|    ep_len_mean           | 42.7        |
|    ep_rew_mean           | -22.6       |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 25          |
|    time_elapsed          | 703         |
|    total_timesteps       | 2459648     |
| train/                   |             |
|    approx_kl             | 0.015312824 |
|    clip_fraction         | 0.192       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.97        |
|    cost_value_loss       | 4.06        |
|    cost_values           | 1.49        |
|    entropy               | 0.911       |
|    entropy_loss          | 0.909       |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0.00182     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.98        |
|    n_updates             | 12000       |
|    policy_gradient_loss  | 0.0107      |
|    std                   | 0.236       |
|    value_loss            | 0.731       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.8         |
| reward                   | -0.517422   |
| rollout/                 |             |
|    ep_len_mean           | 43.6        |
|    ep_rew_mean           | -22.4       |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 26          |
|    time_elapsed          | 734         |
|    total_timesteps       | 2461696     |
| train/                   |             |
|    approx_kl             | 0.021465655 |
|    clip_fraction         | 0.199       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.92        |
|    cost_value_loss       | 3.84        |
|    cost_values           | 1.52        |
|    entropy               | 0.92        |
|    entropy_loss          | 0.915       |
|    explained_variance    | 0.967       |
|    lagrangian_multiplier | 8.88e-06    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.39        |
|    n_updates             | 12010       |
|    policy_gradient_loss  | 0.0108      |
|    std                   | 0.235       |
|    value_loss            | 1.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.2         |
| reward                   | -0.33489445 |
| rollout/                 |             |
|    ep_len_mean           | 43.5        |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 27          |
|    time_elapsed          | 759         |
|    total_timesteps       | 2463744     |
| train/                   |             |
|    approx_kl             | 0.024254266 |
|    clip_fraction         | 0.233       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.94        |
|    cost_value_loss       | 3.7         |
|    cost_values           | 1.51        |
|    entropy               | 0.926       |
|    entropy_loss          | 0.924       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 3.02e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.19        |
|    n_updates             | 12020       |
|    policy_gradient_loss  | 0.0107      |
|    std                   | 0.234       |
|    value_loss            | 0.862       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.4         |
| reward                   | -0.18413867 |
| rollout/                 |             |
|    ep_len_mean           | 43.5        |
|    ep_rew_mean           | -23.1       |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 28          |
|    time_elapsed          | 786         |
|    total_timesteps       | 2465792     |
| train/                   |             |
|    approx_kl             | 0.031490657 |
|    clip_fraction         | 0.221       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.98        |
|    cost_value_loss       | 3.99        |
|    cost_values           | 1.53        |
|    entropy               | 0.925       |
|    entropy_loss          | 0.926       |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0.00155     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.01        |
|    n_updates             | 12030       |
|    policy_gradient_loss  | 0.0133      |
|    std                   | 0.235       |
|    value_loss            | 0.633       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.2         |
| reward                   | -0.30481684 |
| rollout/                 |             |
|    ep_len_mean           | 43.7        |
|    ep_rew_mean           | -23.2       |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 29          |
|    time_elapsed          | 812         |
|    total_timesteps       | 2467840     |
| train/                   |             |
|    approx_kl             | 0.03116098  |
|    clip_fraction         | 0.194       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.95        |
|    cost_value_loss       | 3.85        |
|    cost_values           | 1.48        |
|    entropy               | 0.921       |
|    entropy_loss          | 0.923       |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0.000542    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.23        |
|    n_updates             | 12040       |
|    policy_gradient_loss  | 0.0124      |
|    std                   | 0.235       |
|    value_loss            | 0.614       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.7591762  |
| rollout/                 |             |
|    ep_len_mean           | 43.8        |
|    ep_rew_mean           | -22.6       |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 30          |
|    time_elapsed          | 842         |
|    total_timesteps       | 2469888     |
| train/                   |             |
|    approx_kl             | 0.030999193 |
|    clip_fraction         | 0.236       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.58        |
|    cost_value_loss       | 2.83        |
|    cost_values           | 1.45        |
|    entropy               | 0.921       |
|    entropy_loss          | 0.921       |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 8.18e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 1.8         |
|    n_updates             | 12050       |
|    policy_gradient_loss  | 0.0144      |
|    std                   | 0.235       |
|    value_loss            | 0.45        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.81848663 |
| rollout/                 |             |
|    ep_len_mean           | 44.5        |
|    ep_rew_mean           | -23.1       |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 31          |
|    time_elapsed          | 876         |
|    total_timesteps       | 2471936     |
| train/                   |             |
|    approx_kl             | 0.07297189  |
|    clip_fraction         | 0.232       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.94        |
|    cost_value_loss       | 4.33        |
|    cost_values           | 1.4         |
|    entropy               | 0.926       |
|    entropy_loss          | 0.922       |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0.000122    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.61        |
|    n_updates             | 12060       |
|    policy_gradient_loss  | 0.0136      |
|    std                   | 0.234       |
|    value_loss            | 0.722       |
------------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.6813932  |
| rollout/                 |             |
|    ep_len_mean           | 45.6        |
|    ep_rew_mean           | -24.2       |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 32          |
|    time_elapsed          | 904         |
|    total_timesteps       | 2473984     |
| train/                   |             |
|    approx_kl             | 0.018163238 |
|    clip_fraction         | 0.203       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.94        |
|    cost_value_loss       | 4.12        |
|    cost_values           | 1.44        |
|    entropy               | 0.93        |
|    entropy_loss          | 0.928       |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0.000664    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.2         |
|    n_updates             | 12070       |
|    policy_gradient_loss  | 0.00582     |
|    std                   | 0.234       |
|    value_loss            | 0.727       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.30555913 |
| rollout/                 |             |
|    ep_len_mean           | 46.5        |
|    ep_rew_mean           | -24.5       |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 33          |
|    time_elapsed          | 927         |
|    total_timesteps       | 2476032     |
| train/                   |             |
|    approx_kl             | 0.025399879 |
|    clip_fraction         | 0.201       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.93        |
|    cost_value_loss       | 3.98        |
|    cost_values           | 1.45        |
|    entropy               | 0.935       |
|    entropy_loss          | 0.933       |
|    explained_variance    | 0.973       |
|    lagrangian_multiplier | 0.000994    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.2         |
|    n_updates             | 12080       |
|    policy_gradient_loss  | 0.00443     |
|    std                   | 0.234       |
|    value_loss            | 0.995       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.19090547 |
| rollout/                 |             |
|    ep_len_mean           | 46.1        |
|    ep_rew_mean           | -24.2       |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 34          |
|    time_elapsed          | 956         |
|    total_timesteps       | 2478080     |
| train/                   |             |
|    approx_kl             | 0.03073395  |
|    clip_fraction         | 0.183       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.85        |
|    cost_value_loss       | 3.77        |
|    cost_values           | 1.49        |
|    entropy               | 0.938       |
|    entropy_loss          | 0.937       |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0.000467    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.31        |
|    n_updates             | 12090       |
|    policy_gradient_loss  | 0.00893     |
|    std                   | 0.234       |
|    value_loss            | 0.992       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.17460097 |
| rollout/                 |             |
|    ep_len_mean           | 47.4        |
|    ep_rew_mean           | -24.1       |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 35          |
|    time_elapsed          | 992         |
|    total_timesteps       | 2480128     |
| train/                   |             |
|    approx_kl             | 0.021518163 |
|    clip_fraction         | 0.223       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.77        |
|    cost_value_loss       | 3.53        |
|    cost_values           | 1.47        |
|    entropy               | 0.937       |
|    entropy_loss          | 0.938       |
|    explained_variance    | 0.97        |
|    lagrangian_multiplier | 0.000254    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.26        |
|    n_updates             | 12100       |
|    policy_gradient_loss  | 0.00965     |
|    std                   | 0.233       |
|    value_loss            | 1.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.17934123 |
| rollout/                 |             |
|    ep_len_mean           | 47.1        |
|    ep_rew_mean           | -23.9       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 36          |
|    time_elapsed          | 1025        |
|    total_timesteps       | 2482176     |
| train/                   |             |
|    approx_kl             | 0.04302     |
|    clip_fraction         | 0.253       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.98        |
|    cost_value_loss       | 4.41        |
|    cost_values           | 1.47        |
|    entropy               | 0.933       |
|    entropy_loss          | 0.935       |
|    explained_variance    | 0.955       |
|    lagrangian_multiplier | 0.000122    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.78        |
|    n_updates             | 12110       |
|    policy_gradient_loss  | 0.00777     |
|    std                   | 0.234       |
|    value_loss            | 1.54        |
------------------------------------------
-----------------------------------------
| avg_speed                | 6          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 6          |
| reward                   | -0.308158  |
| rollout/                 |            |
|    ep_len_mean           | 46         |
|    ep_rew_mean           | -23.6      |
| time/                    |            |
|    fps                   | 71         |
|    iterations            | 37         |
|    time_elapsed          | 1055       |
|    total_timesteps       | 2484224    |
| train/                   |            |
|    approx_kl             | 0.03551393 |
|    clip_fraction         | 0.202      |
|    clip_range            | 0.2        |
|    cost_returns          | 2.95       |
|    cost_value_loss       | 3.75       |
|    cost_values           | 1.52       |
|    entropy               | 0.937      |
|    entropy_loss          | 0.934      |
|    explained_variance    | 0.973      |
|    lagrangian_multiplier | 0.00121    |
|    learning_rate         | 0.0003     |
|    loss                  | 2.08       |
|    n_updates             | 12120      |
|    policy_gradient_loss  | 0.00958    |
|    std                   | 0.233      |
|    value_loss            | 0.952      |
-----------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.30384794 |
| rollout/                 |             |
|    ep_len_mean           | 44.5        |
|    ep_rew_mean           | -22.8       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 38          |
|    time_elapsed          | 1090        |
|    total_timesteps       | 2486272     |
| train/                   |             |
|    approx_kl             | 0.045716114 |
|    clip_fraction         | 0.226       |
|    clip_range            | 0.2         |
|    cost_returns          | 3           |
|    cost_value_loss       | 4.15        |
|    cost_values           | 1.52        |
|    entropy               | 0.933       |
|    entropy_loss          | 0.936       |
|    explained_variance    | 0.97        |
|    lagrangian_multiplier | 0.00068     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.38        |
|    n_updates             | 12130       |
|    policy_gradient_loss  | 0.00964     |
|    std                   | 0.233       |
|    value_loss            | 1.05        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.8         |
| reward                   | -0.36610088 |
| rollout/                 |             |
|    ep_len_mean           | 44.4        |
|    ep_rew_mean           | -22.7       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 39          |
|    time_elapsed          | 1123        |
|    total_timesteps       | 2488320     |
| train/                   |             |
|    approx_kl             | 0.029499121 |
|    clip_fraction         | 0.195       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.03        |
|    cost_value_loss       | 4.14        |
|    cost_values           | 1.55        |
|    entropy               | 0.921       |
|    entropy_loss          | 0.927       |
|    explained_variance    | 0.965       |
|    lagrangian_multiplier | 0.00124     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.27        |
|    n_updates             | 12140       |
|    policy_gradient_loss  | 0.00358     |
|    std                   | 0.234       |
|    value_loss            | 1.12        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.19380891 |
| rollout/                 |             |
|    ep_len_mean           | 44.2        |
|    ep_rew_mean           | -22.7       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 40          |
|    time_elapsed          | 1157        |
|    total_timesteps       | 2490368     |
| train/                   |             |
|    approx_kl             | 0.022302719 |
|    clip_fraction         | 0.216       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.11        |
|    cost_value_loss       | 4.48        |
|    cost_values           | 1.56        |
|    entropy               | 0.926       |
|    entropy_loss          | 0.921       |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0.00164     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.26        |
|    n_updates             | 12150       |
|    policy_gradient_loss  | 0.0106      |
|    std                   | 0.233       |
|    value_loss            | 0.92        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.8         |
| reward                   | -0.14997233 |
| rollout/                 |             |
|    ep_len_mean           | 43.6        |
|    ep_rew_mean           | -22.5       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 41          |
|    time_elapsed          | 1181        |
|    total_timesteps       | 2492416     |
| train/                   |             |
|    approx_kl             | 0.027215373 |
|    clip_fraction         | 0.21        |
|    clip_range            | 0.2         |
|    cost_returns          | 2.97        |
|    cost_value_loss       | 3.71        |
|    cost_values           | 1.56        |
|    entropy               | 0.929       |
|    entropy_loss          | 0.929       |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0.000426    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.27        |
|    n_updates             | 12160       |
|    policy_gradient_loss  | 0.00906     |
|    std                   | 0.234       |
|    value_loss            | 0.85        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.78391474 |
| rollout/                 |             |
|    ep_len_mean           | 43.1        |
|    ep_rew_mean           | -22.5       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 42          |
|    time_elapsed          | 1205        |
|    total_timesteps       | 2494464     |
| train/                   |             |
|    approx_kl             | 0.012095961 |
|    clip_fraction         | 0.197       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.79        |
|    cost_value_loss       | 3.22        |
|    cost_values           | 1.51        |
|    entropy               | 0.927       |
|    entropy_loss          | 0.927       |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0.00104     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.68        |
|    n_updates             | 12170       |
|    policy_gradient_loss  | 0.00855     |
|    std                   | 0.234       |
|    value_loss            | 0.647       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.20975175 |
| rollout/                 |             |
|    ep_len_mean           | 42.2        |
|    ep_rew_mean           | -22.4       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 43          |
|    time_elapsed          | 1237        |
|    total_timesteps       | 2496512     |
| train/                   |             |
|    approx_kl             | 0.026812285 |
|    clip_fraction         | 0.17        |
|    clip_range            | 0.2         |
|    cost_returns          | 2.91        |
|    cost_value_loss       | 3.55        |
|    cost_values           | 1.52        |
|    entropy               | 0.924       |
|    entropy_loss          | 0.926       |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 0.000637    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.02        |
|    n_updates             | 12180       |
|    policy_gradient_loss  | 0.00239     |
|    std                   | 0.234       |
|    value_loss            | 0.755       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.32489622 |
| rollout/                 |             |
|    ep_len_mean           | 42.9        |
|    ep_rew_mean           | -22.7       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 44          |
|    time_elapsed          | 1266        |
|    total_timesteps       | 2498560     |
| train/                   |             |
|    approx_kl             | 0.03556838  |
|    clip_fraction         | 0.222       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.94        |
|    cost_value_loss       | 3.92        |
|    cost_values           | 1.55        |
|    entropy               | 0.919       |
|    entropy_loss          | 0.921       |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0.000695    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.17        |
|    n_updates             | 12190       |
|    policy_gradient_loss  | 0.00856     |
|    std                   | 0.235       |
|    value_loss            | 0.657       |
------------------------------------------
------------------------------------------
| avg_speed                | 3           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3           |
| reward                   | -0.7916322  |
| rollout/                 |             |
|    ep_len_mean           | 45.3        |
|    ep_rew_mean           | -23.6       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 45          |
|    time_elapsed          | 1299        |
|    total_timesteps       | 2500608     |
| train/                   |             |
|    approx_kl             | 0.038260203 |
|    clip_fraction         | 0.169       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.88        |
|    cost_value_loss       | 3.71        |
|    cost_values           | 1.47        |
|    entropy               | 0.92        |
|    entropy_loss          | 0.919       |
|    explained_variance    | 0.972       |
|    lagrangian_multiplier | 0.000583    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.2         |
|    n_updates             | 12200       |
|    policy_gradient_loss  | 0.0105      |
|    std                   | 0.235       |
|    value_loss            | 0.947       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.3853014  |
| rollout/                 |             |
|    ep_len_mean           | 46.7        |
|    ep_rew_mean           | -23.7       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 46          |
|    time_elapsed          | 1331        |
|    total_timesteps       | 2502656     |
| train/                   |             |
|    approx_kl             | 0.019557942 |
|    clip_fraction         | 0.178       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.97        |
|    cost_value_loss       | 4.28        |
|    cost_values           | 1.48        |
|    entropy               | 0.915       |
|    entropy_loss          | 0.918       |
|    explained_variance    | 0.966       |
|    lagrangian_multiplier | 0.00218     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.22        |
|    n_updates             | 12210       |
|    policy_gradient_loss  | 0.00538     |
|    std                   | 0.236       |
|    value_loss            | 1.22        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.8         |
| reward                   | -0.7690623  |
| rollout/                 |             |
|    ep_len_mean           | 44          |
|    ep_rew_mean           | -23.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 47          |
|    time_elapsed          | 1359        |
|    total_timesteps       | 2504704     |
| train/                   |             |
|    approx_kl             | 0.013184221 |
|    clip_fraction         | 0.204       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.08        |
|    cost_value_loss       | 4.58        |
|    cost_values           | 1.49        |
|    entropy               | 0.911       |
|    entropy_loss          | 0.913       |
|    explained_variance    | 0.969       |
|    lagrangian_multiplier | 0.000148    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.73        |
|    n_updates             | 12220       |
|    policy_gradient_loss  | 0.0137      |
|    std                   | 0.237       |
|    value_loss            | 1.04        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.2         |
| reward                   | -0.36494952 |
| rollout/                 |             |
|    ep_len_mean           | 43.4        |
|    ep_rew_mean           | -23         |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 48          |
|    time_elapsed          | 1393        |
|    total_timesteps       | 2506752     |
| train/                   |             |
|    approx_kl             | 0.019138135 |
|    clip_fraction         | 0.209       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.77        |
|    cost_value_loss       | 3.55        |
|    cost_values           | 1.47        |
|    entropy               | 0.904       |
|    entropy_loss          | 0.908       |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0.00134     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.92        |
|    n_updates             | 12230       |
|    policy_gradient_loss  | 0.015       |
|    std                   | 0.238       |
|    value_loss            | 0.698       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.8         |
| reward                   | -0.48061392 |
| rollout/                 |             |
|    ep_len_mean           | 44.1        |
|    ep_rew_mean           | -22.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 49          |
|    time_elapsed          | 1423        |
|    total_timesteps       | 2508800     |
| train/                   |             |
|    approx_kl             | 0.028580647 |
|    clip_fraction         | 0.171       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.98        |
|    cost_value_loss       | 4.42        |
|    cost_values           | 1.43        |
|    entropy               | 0.904       |
|    entropy_loss          | 0.903       |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0.000756    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.32        |
|    n_updates             | 12240       |
|    policy_gradient_loss  | 0.00894     |
|    std                   | 0.238       |
|    value_loss            | 0.627       |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ent-coefficient-ppol/1vjpjg9h
------------------------------------
| avg_speed          | 2           |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 2           |
| reward             | -0.70859814 |
| rollout/           |             |
|    ep_len_mean     | 44.7        |
|    ep_rew_mean     | -23         |
| time/              |             |
|    fps             | 74          |
|    iterations      | 1           |
|    time_elapsed    | 27          |
|    total_timesteps | 2510848     |
------------------------------------
------------------------------------------
| avg_speed                | 6.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.4         |
| reward                   | -0.32665744 |
| rollout/                 |             |
|    ep_len_mean           | 44.6        |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 2           |
|    time_elapsed          | 55          |
|    total_timesteps       | 2512896     |
| train/                   |             |
|    approx_kl             | 0.014973141 |
|    clip_fraction         | 0.221       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.92        |
|    cost_value_loss       | 3.75        |
|    cost_values           | 1.47        |
|    entropy               | 0.902       |
|    entropy_loss          | 0.904       |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0.00057     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.28        |
|    n_updates             | 12260       |
|    policy_gradient_loss  | 0.0162      |
|    std                   | 0.238       |
|    value_loss            | 0.733       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.2         |
| reward                   | -0.3502232  |
| rollout/                 |             |
|    ep_len_mean           | 45          |
|    ep_rew_mean           | -23.6       |
| time/                    |             |
|    fps                   | 74          |
|    iterations            | 3           |
|    time_elapsed          | 82          |
|    total_timesteps       | 2514944     |
| train/                   |             |
|    approx_kl             | 0.025932066 |
|    clip_fraction         | 0.188       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.03        |
|    cost_value_loss       | 4.17        |
|    cost_values           | 1.46        |
|    entropy               | 0.899       |
|    entropy_loss          | 0.902       |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0.00103     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.16        |
|    n_updates             | 12270       |
|    policy_gradient_loss  | 0.00864     |
|    std                   | 0.238       |
|    value_loss            | 0.834       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.32213414 |
| rollout/                 |             |
|    ep_len_mean           | 45.1        |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 4           |
|    time_elapsed          | 115         |
|    total_timesteps       | 2516992     |
| train/                   |             |
|    approx_kl             | 0.014556307 |
|    clip_fraction         | 0.191       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.05        |
|    cost_value_loss       | 4.55        |
|    cost_values           | 1.47        |
|    entropy               | 0.895       |
|    entropy_loss          | 0.896       |
|    explained_variance    | 0.967       |
|    lagrangian_multiplier | 0.000284    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.76        |
|    n_updates             | 12280       |
|    policy_gradient_loss  | 0.00755     |
|    std                   | 0.238       |
|    value_loss            | 1.13        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.2         |
| reward                   | -0.5982175  |
| rollout/                 |             |
|    ep_len_mean           | 43.5        |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 5           |
|    time_elapsed          | 148         |
|    total_timesteps       | 2519040     |
| train/                   |             |
|    approx_kl             | 0.033624563 |
|    clip_fraction         | 0.199       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.04        |
|    cost_value_loss       | 4.08        |
|    cost_values           | 1.55        |
|    entropy               | 0.893       |
|    entropy_loss          | 0.894       |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0.002       |
|    learning_rate         | 0.0003      |
|    loss                  | 2.06        |
|    n_updates             | 12290       |
|    policy_gradient_loss  | 0.00946     |
|    std                   | 0.238       |
|    value_loss            | 0.7         |
------------------------------------------
------------------------------------------
| avg_speed                | 2.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.8         |
| reward                   | -0.66522133 |
| rollout/                 |             |
|    ep_len_mean           | 43.7        |
|    ep_rew_mean           | -23.4       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 6           |
|    time_elapsed          | 180         |
|    total_timesteps       | 2521088     |
| train/                   |             |
|    approx_kl             | 0.028009495 |
|    clip_fraction         | 0.197       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.02        |
|    cost_value_loss       | 4.18        |
|    cost_values           | 1.52        |
|    entropy               | 0.896       |
|    entropy_loss          | 0.895       |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0.000566    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.29        |
|    n_updates             | 12300       |
|    policy_gradient_loss  | 0.00869     |
|    std                   | 0.237       |
|    value_loss            | 0.741       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.8         |
| reward                   | -0.68206894 |
| rollout/                 |             |
|    ep_len_mean           | 43.8        |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 7           |
|    time_elapsed          | 212         |
|    total_timesteps       | 2523136     |
| train/                   |             |
|    approx_kl             | 0.019237857 |
|    clip_fraction         | 0.195       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.05        |
|    cost_value_loss       | 4.62        |
|    cost_values           | 1.48        |
|    entropy               | 0.899       |
|    entropy_loss          | 0.897       |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0.00139     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.31        |
|    n_updates             | 12310       |
|    policy_gradient_loss  | 0.00889     |
|    std                   | 0.237       |
|    value_loss            | 0.828       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.32346824 |
| rollout/                 |             |
|    ep_len_mean           | 42.8        |
|    ep_rew_mean           | -23         |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 8           |
|    time_elapsed          | 235         |
|    total_timesteps       | 2525184     |
| train/                   |             |
|    approx_kl             | 0.037102472 |
|    clip_fraction         | 0.235       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.89        |
|    cost_value_loss       | 3.88        |
|    cost_values           | 1.5         |
|    entropy               | 0.896       |
|    entropy_loss          | 0.898       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0.00218     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.96        |
|    n_updates             | 12320       |
|    policy_gradient_loss  | 0.00847     |
|    std                   | 0.237       |
|    value_loss            | 0.863       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.57203674 |
| rollout/                 |             |
|    ep_len_mean           | 44.2        |
|    ep_rew_mean           | -23.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 9           |
|    time_elapsed          | 259         |
|    total_timesteps       | 2527232     |
| train/                   |             |
|    approx_kl             | 0.028810145 |
|    clip_fraction         | 0.212       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.93        |
|    cost_value_loss       | 4.2         |
|    cost_values           | 1.45        |
|    entropy               | 0.897       |
|    entropy_loss          | 0.896       |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 0.000127    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.5         |
|    n_updates             | 12330       |
|    policy_gradient_loss  | 0.0109      |
|    std                   | 0.237       |
|    value_loss            | 0.739       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.79519093 |
| rollout/                 |             |
|    ep_len_mean           | 44.5        |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 10          |
|    time_elapsed          | 283         |
|    total_timesteps       | 2529280     |
| train/                   |             |
|    approx_kl             | 0.04072412  |
|    clip_fraction         | 0.191       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.02        |
|    cost_value_loss       | 4.18        |
|    cost_values           | 1.51        |
|    entropy               | 0.893       |
|    entropy_loss          | 0.896       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0.00142     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.15        |
|    n_updates             | 12340       |
|    policy_gradient_loss  | 0.00387     |
|    std                   | 0.236       |
|    value_loss            | 0.888       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.64715683 |
| rollout/                 |             |
|    ep_len_mean           | 43.7        |
|    ep_rew_mean           | -23.1       |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 11          |
|    time_elapsed          | 311         |
|    total_timesteps       | 2531328     |
| train/                   |             |
|    approx_kl             | 0.028452195 |
|    clip_fraction         | 0.236       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.09        |
|    cost_value_loss       | 4.28        |
|    cost_values           | 1.56        |
|    entropy               | 0.892       |
|    entropy_loss          | 0.892       |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0.000901    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.3         |
|    n_updates             | 12350       |
|    policy_gradient_loss  | 0.0281      |
|    std                   | 0.236       |
|    value_loss            | 0.656       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.4         |
| reward                   | -0.19898622 |
| rollout/                 |             |
|    ep_len_mean           | 44.6        |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 12          |
|    time_elapsed          | 343         |
|    total_timesteps       | 2533376     |
| train/                   |             |
|    approx_kl             | 0.0317473   |
|    clip_fraction         | 0.264       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.75        |
|    cost_value_loss       | 3.33        |
|    cost_values           | 1.5         |
|    entropy               | 0.897       |
|    entropy_loss          | 0.895       |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0.000403    |
|    learning_rate         | 0.0003      |
|    loss                  | 1.89        |
|    n_updates             | 12360       |
|    policy_gradient_loss  | 0.0237      |
|    std                   | 0.235       |
|    value_loss            | 0.652       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.2         |
| reward                   | -0.21440856 |
| rollout/                 |             |
|    ep_len_mean           | 44.7        |
|    ep_rew_mean           | -22.7       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 13          |
|    time_elapsed          | 374         |
|    total_timesteps       | 2535424     |
| train/                   |             |
|    approx_kl             | 0.030438233 |
|    clip_fraction         | 0.271       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.03        |
|    cost_value_loss       | 4.52        |
|    cost_values           | 1.48        |
|    entropy               | 0.895       |
|    entropy_loss          | 0.896       |
|    explained_variance    | 0.968       |
|    lagrangian_multiplier | 0.000779    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.46        |
|    n_updates             | 12370       |
|    policy_gradient_loss  | 0.00998     |
|    std                   | 0.235       |
|    value_loss            | 1.13        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.32686597 |
| rollout/                 |             |
|    ep_len_mean           | 42.8        |
|    ep_rew_mean           | -21.9       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 14          |
|    time_elapsed          | 408         |
|    total_timesteps       | 2537472     |
| train/                   |             |
|    approx_kl             | 0.036795802 |
|    clip_fraction         | 0.211       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.92        |
|    cost_value_loss       | 3.66        |
|    cost_values           | 1.53        |
|    entropy               | 0.903       |
|    entropy_loss          | 0.898       |
|    explained_variance    | 0.971       |
|    lagrangian_multiplier | 7.58e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.14        |
|    n_updates             | 12380       |
|    policy_gradient_loss  | 0.0141      |
|    std                   | 0.234       |
|    value_loss            | 0.938       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.24332961 |
| rollout/                 |             |
|    ep_len_mean           | 43.4        |
|    ep_rew_mean           | -22.3       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 15          |
|    time_elapsed          | 437         |
|    total_timesteps       | 2539520     |
| train/                   |             |
|    approx_kl             | 0.021498648 |
|    clip_fraction         | 0.184       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.16        |
|    cost_value_loss       | 4.53        |
|    cost_values           | 1.53        |
|    entropy               | 0.902       |
|    entropy_loss          | 0.904       |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0.00262     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.08        |
|    n_updates             | 12390       |
|    policy_gradient_loss  | 0.0136      |
|    std                   | 0.234       |
|    value_loss            | 0.674       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.8675673  |
| rollout/                 |             |
|    ep_len_mean           | 44.5        |
|    ep_rew_mean           | -23.2       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 16          |
|    time_elapsed          | 468         |
|    total_timesteps       | 2541568     |
| train/                   |             |
|    approx_kl             | 0.020270452 |
|    clip_fraction         | 0.201       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.16        |
|    cost_value_loss       | 4.69        |
|    cost_values           | 1.51        |
|    entropy               | 0.899       |
|    entropy_loss          | 0.901       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0.000573    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.53        |
|    n_updates             | 12400       |
|    policy_gradient_loss  | 0.00887     |
|    std                   | 0.235       |
|    value_loss            | 0.819       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.59357274 |
| rollout/                 |             |
|    ep_len_mean           | 43.7        |
|    ep_rew_mean           | -23.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 17          |
|    time_elapsed          | 496         |
|    total_timesteps       | 2543616     |
| train/                   |             |
|    approx_kl             | 0.018497566 |
|    clip_fraction         | 0.227       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.93        |
|    cost_value_loss       | 3.76        |
|    cost_values           | 1.54        |
|    entropy               | 0.901       |
|    entropy_loss          | 0.901       |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0.000727    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.13        |
|    n_updates             | 12410       |
|    policy_gradient_loss  | 0.00949     |
|    std                   | 0.235       |
|    value_loss            | 0.923       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.4         |
| reward                   | -0.3144215  |
| rollout/                 |             |
|    ep_len_mean           | 43.5        |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 18          |
|    time_elapsed          | 519         |
|    total_timesteps       | 2545664     |
| train/                   |             |
|    approx_kl             | 0.031179104 |
|    clip_fraction         | 0.249       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.14        |
|    cost_value_loss       | 4.37        |
|    cost_values           | 1.54        |
|    entropy               | 0.902       |
|    entropy_loss          | 0.902       |
|    explained_variance    | 0.966       |
|    lagrangian_multiplier | 0.000155    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.64        |
|    n_updates             | 12420       |
|    policy_gradient_loss  | 0.0137      |
|    std                   | 0.234       |
|    value_loss            | 1.25        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.8         |
| reward                   | -0.21712038 |
| rollout/                 |             |
|    ep_len_mean           | 43.3        |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 19          |
|    time_elapsed          | 544         |
|    total_timesteps       | 2547712     |
| train/                   |             |
|    approx_kl             | 0.021869954 |
|    clip_fraction         | 0.24        |
|    clip_range            | 0.2         |
|    cost_returns          | 2.91        |
|    cost_value_loss       | 3.56        |
|    cost_values           | 1.55        |
|    entropy               | 0.909       |
|    entropy_loss          | 0.905       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0.00123     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.07        |
|    n_updates             | 12430       |
|    policy_gradient_loss  | 0.0126      |
|    std                   | 0.233       |
|    value_loss            | 0.841       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.59683293 |
| rollout/                 |             |
|    ep_len_mean           | 43.3        |
|    ep_rew_mean           | -23.4       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 20          |
|    time_elapsed          | 575         |
|    total_timesteps       | 2549760     |
| train/                   |             |
|    approx_kl             | 0.0308341   |
|    clip_fraction         | 0.207       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.97        |
|    cost_value_loss       | 3.73        |
|    cost_values           | 1.55        |
|    entropy               | 0.902       |
|    entropy_loss          | 0.906       |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 0.000535    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.02        |
|    n_updates             | 12440       |
|    policy_gradient_loss  | 0.0061      |
|    std                   | 0.234       |
|    value_loss            | 0.81        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.8         |
| reward                   | -0.7690623  |
| rollout/                 |             |
|    ep_len_mean           | 44.4        |
|    ep_rew_mean           | -23.4       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 21          |
|    time_elapsed          | 610         |
|    total_timesteps       | 2551808     |
| train/                   |             |
|    approx_kl             | 0.052473605 |
|    clip_fraction         | 0.217       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.03        |
|    cost_value_loss       | 3.92        |
|    cost_values           | 1.52        |
|    entropy               | 0.897       |
|    entropy_loss          | 0.899       |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0.000485    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.17        |
|    n_updates             | 12450       |
|    policy_gradient_loss  | 0.0152      |
|    std                   | 0.234       |
|    value_loss            | 0.56        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.8         |
| reward                   | -0.32218957 |
| rollout/                 |             |
|    ep_len_mean           | 45.8        |
|    ep_rew_mean           | -23.4       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 22          |
|    time_elapsed          | 645         |
|    total_timesteps       | 2553856     |
| train/                   |             |
|    approx_kl             | 0.05864585  |
|    clip_fraction         | 0.276       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.02        |
|    cost_value_loss       | 4.16        |
|    cost_values           | 1.51        |
|    entropy               | 0.904       |
|    entropy_loss          | 0.9         |
|    explained_variance    | 0.968       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.39        |
|    n_updates             | 12460       |
|    policy_gradient_loss  | 0.0133      |
|    std                   | 0.232       |
|    value_loss            | 1.07        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.2         |
| reward                   | -0.16723269 |
| rollout/                 |             |
|    ep_len_mean           | 44.9        |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 23          |
|    time_elapsed          | 683         |
|    total_timesteps       | 2555904     |
| train/                   |             |
|    approx_kl             | 0.06952928  |
|    clip_fraction         | 0.233       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.33        |
|    cost_value_loss       | 5.41        |
|    cost_values           | 1.55        |
|    entropy               | 0.907       |
|    entropy_loss          | 0.906       |
|    explained_variance    | 0.97        |
|    lagrangian_multiplier | 0.000853    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.79        |
|    n_updates             | 12470       |
|    policy_gradient_loss  | 0.00903     |
|    std                   | 0.232       |
|    value_loss            | 1.12        |
------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.8720816  |
| rollout/                 |             |
|    ep_len_mean           | 44          |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 24          |
|    time_elapsed          | 720         |
|    total_timesteps       | 2557952     |
| train/                   |             |
|    approx_kl             | 0.018374067 |
|    clip_fraction         | 0.192       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.24        |
|    cost_value_loss       | 4.8         |
|    cost_values           | 1.57        |
|    entropy               | 0.911       |
|    entropy_loss          | 0.909       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0.00243     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.27        |
|    n_updates             | 12480       |
|    policy_gradient_loss  | 0.00936     |
|    std                   | 0.232       |
|    value_loss            | 0.85        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.1439773  |
| rollout/                 |             |
|    ep_len_mean           | 44.7        |
|    ep_rew_mean           | -23.8       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 25          |
|    time_elapsed          | 754         |
|    total_timesteps       | 2560000     |
| train/                   |             |
|    approx_kl             | 0.016344165 |
|    clip_fraction         | 0.172       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.02        |
|    cost_value_loss       | 3.94        |
|    cost_values           | 1.55        |
|    entropy               | 0.919       |
|    entropy_loss          | 0.915       |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0.000669    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.14        |
|    n_updates             | 12490       |
|    policy_gradient_loss  | 0.00264     |
|    std                   | 0.231       |
|    value_loss            | 1.01        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.30855998 |
| rollout/                 |             |
|    ep_len_mean           | 44.2        |
|    ep_rew_mean           | -23.1       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 26          |
|    time_elapsed          | 789         |
|    total_timesteps       | 2562048     |
| train/                   |             |
|    approx_kl             | 0.026471678 |
|    clip_fraction         | 0.2         |
|    clip_range            | 0.2         |
|    cost_returns          | 3.11        |
|    cost_value_loss       | 4.18        |
|    cost_values           | 1.55        |
|    entropy               | 0.926       |
|    entropy_loss          | 0.922       |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0.000865    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.21        |
|    n_updates             | 12500       |
|    policy_gradient_loss  | 0.00937     |
|    std                   | 0.23        |
|    value_loss            | 0.737       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.34509087 |
| rollout/                 |             |
|    ep_len_mean           | 43.7        |
|    ep_rew_mean           | -22.3       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 27          |
|    time_elapsed          | 823         |
|    total_timesteps       | 2564096     |
| train/                   |             |
|    approx_kl             | 0.038346477 |
|    clip_fraction         | 0.217       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.04        |
|    cost_value_loss       | 4.08        |
|    cost_values           | 1.57        |
|    entropy               | 0.93        |
|    entropy_loss          | 0.928       |
|    explained_variance    | 0.971       |
|    lagrangian_multiplier | 0.000218    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.5         |
|    n_updates             | 12510       |
|    policy_gradient_loss  | 0.00336     |
|    std                   | 0.229       |
|    value_loss            | 0.967       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.850427   |
| rollout/                 |             |
|    ep_len_mean           | 43.7        |
|    ep_rew_mean           | -22.9       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 28          |
|    time_elapsed          | 859         |
|    total_timesteps       | 2566144     |
| train/                   |             |
|    approx_kl             | 0.031876422 |
|    clip_fraction         | 0.223       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.04        |
|    cost_value_loss       | 3.75        |
|    cost_values           | 1.58        |
|    entropy               | 0.923       |
|    entropy_loss          | 0.927       |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0.000715    |
|    learning_rate         | 0.0003      |
|    loss                  | 1.98        |
|    n_updates             | 12520       |
|    policy_gradient_loss  | 0.0144      |
|    std                   | 0.23        |
|    value_loss            | 0.602       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.6         |
| reward                   | -0.31946957 |
| rollout/                 |             |
|    ep_len_mean           | 44.1        |
|    ep_rew_mean           | -23.7       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 29          |
|    time_elapsed          | 895         |
|    total_timesteps       | 2568192     |
| train/                   |             |
|    approx_kl             | 0.053109452 |
|    clip_fraction         | 0.244       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.96        |
|    cost_value_loss       | 3.73        |
|    cost_values           | 1.54        |
|    entropy               | 0.916       |
|    entropy_loss          | 0.919       |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0.000479    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.16        |
|    n_updates             | 12530       |
|    policy_gradient_loss  | 0.00447     |
|    std                   | 0.231       |
|    value_loss            | 0.685       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.2         |
| reward                   | -0.12179183 |
| rollout/                 |             |
|    ep_len_mean           | 43.9        |
|    ep_rew_mean           | -23.8       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 30          |
|    time_elapsed          | 928         |
|    total_timesteps       | 2570240     |
| train/                   |             |
|    approx_kl             | 0.016158413 |
|    clip_fraction         | 0.138       |
|    clip_range            | 0.2         |
|    cost_returns          | 3           |
|    cost_value_loss       | 4.06        |
|    cost_values           | 1.53        |
|    entropy               | 0.925       |
|    entropy_loss          | 0.919       |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0.00353     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.9         |
|    n_updates             | 12540       |
|    policy_gradient_loss  | 0.00244     |
|    std                   | 0.23        |
|    value_loss            | 0.513       |
------------------------------------------
------------------------------------------
| avg_speed                | 5           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5           |
| reward                   | -0.48527703 |
| rollout/                 |             |
|    ep_len_mean           | 44.1        |
|    ep_rew_mean           | -23.5       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 31          |
|    time_elapsed          | 962         |
|    total_timesteps       | 2572288     |
| train/                   |             |
|    approx_kl             | 0.025573868 |
|    clip_fraction         | 0.238       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.9         |
|    cost_value_loss       | 3.58        |
|    cost_values           | 1.51        |
|    entropy               | 0.929       |
|    entropy_loss          | 0.927       |
|    explained_variance    | 0.984       |
|    lagrangian_multiplier | 0.000572    |
|    learning_rate         | 0.0003      |
|    loss                  | 1.89        |
|    n_updates             | 12550       |
|    policy_gradient_loss  | 0.018       |
|    std                   | 0.229       |
|    value_loss            | 0.621       |
------------------------------------------
------------------------------------------
| avg_speed                | 5           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5           |
| reward                   | -0.5938598  |
| rollout/                 |             |
|    ep_len_mean           | 43.7        |
|    ep_rew_mean           | -22.7       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 32          |
|    time_elapsed          | 992         |
|    total_timesteps       | 2574336     |
| train/                   |             |
|    approx_kl             | 0.013859074 |
|    clip_fraction         | 0.173       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.92        |
|    cost_value_loss       | 3.79        |
|    cost_values           | 1.5         |
|    entropy               | 0.926       |
|    entropy_loss          | 0.928       |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0.00152     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.09        |
|    n_updates             | 12560       |
|    policy_gradient_loss  | 0.00726     |
|    std                   | 0.23        |
|    value_loss            | 0.803       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.7912411  |
| rollout/                 |             |
|    ep_len_mean           | 43.6        |
|    ep_rew_mean           | -22.7       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 33          |
|    time_elapsed          | 1018        |
|    total_timesteps       | 2576384     |
| train/                   |             |
|    approx_kl             | 0.020360656 |
|    clip_fraction         | 0.209       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.96        |
|    cost_value_loss       | 3.91        |
|    cost_values           | 1.55        |
|    entropy               | 0.924       |
|    entropy_loss          | 0.925       |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.5         |
|    n_updates             | 12570       |
|    policy_gradient_loss  | 0.00772     |
|    std                   | 0.23        |
|    value_loss            | 0.8         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.34387013 |
| rollout/                 |             |
|    ep_len_mean           | 43.5        |
|    ep_rew_mean           | -23.5       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 34          |
|    time_elapsed          | 1041        |
|    total_timesteps       | 2578432     |
| train/                   |             |
|    approx_kl             | 0.036731265 |
|    clip_fraction         | 0.237       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.86        |
|    cost_value_loss       | 3.38        |
|    cost_values           | 1.51        |
|    entropy               | 0.926       |
|    entropy_loss          | 0.924       |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0.00143     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.79        |
|    n_updates             | 12580       |
|    policy_gradient_loss  | 0.00512     |
|    std                   | 0.23        |
|    value_loss            | 0.731       |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -0.21727073  |
| rollout/                 |              |
|    ep_len_mean           | 45.1         |
|    ep_rew_mean           | -24          |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 35           |
|    time_elapsed          | 1065         |
|    total_timesteps       | 2580480      |
| train/                   |              |
|    approx_kl             | 0.0137565695 |
|    clip_fraction         | 0.185        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.04         |
|    cost_value_loss       | 4.22         |
|    cost_values           | 1.47         |
|    entropy               | 0.932        |
|    entropy_loss          | 0.929        |
|    explained_variance    | 0.981        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.51         |
|    n_updates             | 12590        |
|    policy_gradient_loss  | 0.0114       |
|    std                   | 0.229        |
|    value_loss            | 0.753        |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.2         |
| reward                   | -0.6698428  |
| rollout/                 |             |
|    ep_len_mean           | 44.7        |
|    ep_rew_mean           | -23.8       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 36          |
|    time_elapsed          | 1090        |
|    total_timesteps       | 2582528     |
| train/                   |             |
|    approx_kl             | 0.015249875 |
|    clip_fraction         | 0.197       |
|    clip_range            | 0.2         |
|    cost_returns          | 3           |
|    cost_value_loss       | 4.51        |
|    cost_values           | 1.47        |
|    entropy               | 0.937       |
|    entropy_loss          | 0.935       |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0.00177     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.16        |
|    n_updates             | 12600       |
|    policy_gradient_loss  | 0.00701     |
|    std                   | 0.229       |
|    value_loss            | 0.888       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.92905176 |
| rollout/                 |             |
|    ep_len_mean           | 44.8        |
|    ep_rew_mean           | -23.8       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 37          |
|    time_elapsed          | 1119        |
|    total_timesteps       | 2584576     |
| train/                   |             |
|    approx_kl             | 0.017527176 |
|    clip_fraction         | 0.197       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.04        |
|    cost_value_loss       | 4.33        |
|    cost_values           | 1.49        |
|    entropy               | 0.937       |
|    entropy_loss          | 0.937       |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0.000416    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.29        |
|    n_updates             | 12610       |
|    policy_gradient_loss  | 0.00532     |
|    std                   | 0.23        |
|    value_loss            | 0.687       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.20498838 |
| rollout/                 |             |
|    ep_len_mean           | 44.1        |
|    ep_rew_mean           | -23.6       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 38          |
|    time_elapsed          | 1144        |
|    total_timesteps       | 2586624     |
| train/                   |             |
|    approx_kl             | 0.032773446 |
|    clip_fraction         | 0.202       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.78        |
|    cost_value_loss       | 3.4         |
|    cost_values           | 1.46        |
|    entropy               | 0.943       |
|    entropy_loss          | 0.939       |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0.000934    |
|    learning_rate         | 0.0003      |
|    loss                  | 1.81        |
|    n_updates             | 12620       |
|    policy_gradient_loss  | 0.0108      |
|    std                   | 0.229       |
|    value_loss            | 0.482       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.7465798  |
| rollout/                 |             |
|    ep_len_mean           | 43          |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 39          |
|    time_elapsed          | 1168        |
|    total_timesteps       | 2588672     |
| train/                   |             |
|    approx_kl             | 0.023299888 |
|    clip_fraction         | 0.22        |
|    clip_range            | 0.2         |
|    cost_returns          | 2.88        |
|    cost_value_loss       | 3.92        |
|    cost_values           | 1.44        |
|    entropy               | 0.943       |
|    entropy_loss          | 0.943       |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0.00061     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.24        |
|    n_updates             | 12630       |
|    policy_gradient_loss  | 0.00845     |
|    std                   | 0.23        |
|    value_loss            | 0.828       |
------------------------------------------
------------------------------------------
| avg_speed                | 7           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7           |
| reward                   | -0.29359835 |
| rollout/                 |             |
|    ep_len_mean           | 44.3        |
|    ep_rew_mean           | -23.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 40          |
|    time_elapsed          | 1192        |
|    total_timesteps       | 2590720     |
| train/                   |             |
|    approx_kl             | 0.027408686 |
|    clip_fraction         | 0.208       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.94        |
|    cost_value_loss       | 3.99        |
|    cost_values           | 1.46        |
|    entropy               | 0.944       |
|    entropy_loss          | 0.943       |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0.00175     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.95        |
|    n_updates             | 12640       |
|    policy_gradient_loss  | 0.0127      |
|    std                   | 0.23        |
|    value_loss            | 0.527       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.6         |
| reward                   | -0.3273587  |
| rollout/                 |             |
|    ep_len_mean           | 44.4        |
|    ep_rew_mean           | -23.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 41          |
|    time_elapsed          | 1223        |
|    total_timesteps       | 2592768     |
| train/                   |             |
|    approx_kl             | 0.025507076 |
|    clip_fraction         | 0.167       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.98        |
|    cost_value_loss       | 4.17        |
|    cost_values           | 1.44        |
|    entropy               | 0.947       |
|    entropy_loss          | 0.947       |
|    explained_variance    | 0.971       |
|    lagrangian_multiplier | 0.000615    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.25        |
|    n_updates             | 12650       |
|    policy_gradient_loss  | 0.00409     |
|    std                   | 0.229       |
|    value_loss            | 1.03        |
------------------------------------------
------------------------------------------
| avg_speed                | 5           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5           |
| reward                   | -0.1990945  |
| rollout/                 |             |
|    ep_len_mean           | 43.1        |
|    ep_rew_mean           | -23.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 42          |
|    time_elapsed          | 1257        |
|    total_timesteps       | 2594816     |
| train/                   |             |
|    approx_kl             | 0.018154668 |
|    clip_fraction         | 0.198       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.11        |
|    cost_value_loss       | 4.54        |
|    cost_values           | 1.5         |
|    entropy               | 0.946       |
|    entropy_loss          | 0.946       |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0.00066     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.31        |
|    n_updates             | 12660       |
|    policy_gradient_loss  | 0.00996     |
|    std                   | 0.23        |
|    value_loss            | 0.952       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.6174096  |
| rollout/                 |             |
|    ep_len_mean           | 42.9        |
|    ep_rew_mean           | -23.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 43          |
|    time_elapsed          | 1291        |
|    total_timesteps       | 2596864     |
| train/                   |             |
|    approx_kl             | 0.018777596 |
|    clip_fraction         | 0.25        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.11        |
|    cost_value_loss       | 4.66        |
|    cost_values           | 1.5         |
|    entropy               | 0.944       |
|    entropy_loss          | 0.945       |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0.00195     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.06        |
|    n_updates             | 12670       |
|    policy_gradient_loss  | 0.0155      |
|    std                   | 0.23        |
|    value_loss            | 0.873       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.52368915 |
| rollout/                 |             |
|    ep_len_mean           | 43          |
|    ep_rew_mean           | -22.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 44          |
|    time_elapsed          | 1320        |
|    total_timesteps       | 2598912     |
| train/                   |             |
|    approx_kl             | 0.020156223 |
|    clip_fraction         | 0.202       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.99        |
|    cost_value_loss       | 4.19        |
|    cost_values           | 1.49        |
|    entropy               | 0.948       |
|    entropy_loss          | 0.946       |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0.00191     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.2         |
|    n_updates             | 12680       |
|    policy_gradient_loss  | 0.00827     |
|    std                   | 0.23        |
|    value_loss            | 0.892       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.79264224 |
| rollout/                 |             |
|    ep_len_mean           | 44.4        |
|    ep_rew_mean           | -23         |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 45          |
|    time_elapsed          | 1347        |
|    total_timesteps       | 2600960     |
| train/                   |             |
|    approx_kl             | 0.040552355 |
|    clip_fraction         | 0.217       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.07        |
|    cost_value_loss       | 4.12        |
|    cost_values           | 1.53        |
|    entropy               | 0.944       |
|    entropy_loss          | 0.947       |
|    explained_variance    | 0.97        |
|    lagrangian_multiplier | 0.00109     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.25        |
|    n_updates             | 12690       |
|    policy_gradient_loss  | 0.0101      |
|    std                   | 0.23        |
|    value_loss            | 1.07        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.3583532  |
| rollout/                 |             |
|    ep_len_mean           | 43.8        |
|    ep_rew_mean           | -22.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 46          |
|    time_elapsed          | 1378        |
|    total_timesteps       | 2603008     |
| train/                   |             |
|    approx_kl             | 0.031024404 |
|    clip_fraction         | 0.214       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.14        |
|    cost_value_loss       | 4.47        |
|    cost_values           | 1.51        |
|    entropy               | 0.942       |
|    entropy_loss          | 0.942       |
|    explained_variance    | 0.969       |
|    lagrangian_multiplier | 0.0011      |
|    learning_rate         | 0.0003      |
|    loss                  | 2.32        |
|    n_updates             | 12700       |
|    policy_gradient_loss  | 0.0128      |
|    std                   | 0.23        |
|    value_loss            | 1.03        |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.5849028  |
| rollout/                 |             |
|    ep_len_mean           | 41.5        |
|    ep_rew_mean           | -21.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 47          |
|    time_elapsed          | 1411        |
|    total_timesteps       | 2605056     |
| train/                   |             |
|    approx_kl             | 0.020594899 |
|    clip_fraction         | 0.213       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.07        |
|    cost_value_loss       | 4.45        |
|    cost_values           | 1.5         |
|    entropy               | 0.945       |
|    entropy_loss          | 0.944       |
|    explained_variance    | 0.971       |
|    lagrangian_multiplier | 0.00159     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.34        |
|    n_updates             | 12710       |
|    policy_gradient_loss  | 0.00446     |
|    std                   | 0.229       |
|    value_loss            | 1.04        |
------------------------------------------
------------------------------------------
| avg_speed                | 7           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7           |
| reward                   | -0.3638658  |
| rollout/                 |             |
|    ep_len_mean           | 41.6        |
|    ep_rew_mean           | -22         |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 48          |
|    time_elapsed          | 1444        |
|    total_timesteps       | 2607104     |
| train/                   |             |
|    approx_kl             | 0.036825903 |
|    clip_fraction         | 0.21        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.25        |
|    cost_value_loss       | 4.94        |
|    cost_values           | 1.55        |
|    entropy               | 0.945       |
|    entropy_loss          | 0.945       |
|    explained_variance    | 0.971       |
|    lagrangian_multiplier | 0.00173     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.26        |
|    n_updates             | 12720       |
|    policy_gradient_loss  | 0.0053      |
|    std                   | 0.228       |
|    value_loss            | 0.971       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.8         |
| reward                   | -0.20495592 |
| rollout/                 |             |
|    ep_len_mean           | 43.8        |
|    ep_rew_mean           | -22.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 49          |
|    time_elapsed          | 1473        |
|    total_timesteps       | 2609152     |
| train/                   |             |
|    approx_kl             | 0.016332086 |
|    clip_fraction         | 0.174       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.19        |
|    cost_value_loss       | 4.63        |
|    cost_values           | 1.58        |
|    entropy               | 0.946       |
|    entropy_loss          | 0.946       |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0.00239     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.23        |
|    n_updates             | 12730       |
|    policy_gradient_loss  | 0.00344     |
|    std                   | 0.228       |
|    value_loss            | 0.868       |
------------------------------------------
-----------------------------------
| avg_speed          | 6.6        |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 6.6        |
| reward             | -0.2867234 |
| rollout/           |            |
|    ep_len_mean     | 44.6       |
|    ep_rew_mean     | -23.5      |
| time/              |            |
|    fps             | 72         |
|    iterations      | 1          |
|    time_elapsed    | 28         |
|    total_timesteps | 2611200    |
-----------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.5296473  |
| rollout/                 |             |
|    ep_len_mean           | 44          |
|    ep_rew_mean           | -23.9       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 2           |
|    time_elapsed          | 60          |
|    total_timesteps       | 2613248     |
| train/                   |             |
|    approx_kl             | 0.015533309 |
|    clip_fraction         | 0.197       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.14        |
|    cost_value_loss       | 4.45        |
|    cost_values           | 1.53        |
|    entropy               | 0.943       |
|    entropy_loss          | 0.943       |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0.000569    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.66        |
|    n_updates             | 12750       |
|    policy_gradient_loss  | 0.00929     |
|    std                   | 0.229       |
|    value_loss            | 1.01        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.800612   |
| rollout/                 |             |
|    ep_len_mean           | 43.6        |
|    ep_rew_mean           | -23.5       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 3           |
|    time_elapsed          | 93          |
|    total_timesteps       | 2615296     |
| train/                   |             |
|    approx_kl             | 0.028970037 |
|    clip_fraction         | 0.203       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.05        |
|    cost_value_loss       | 4.22        |
|    cost_values           | 1.52        |
|    entropy               | 0.943       |
|    entropy_loss          | 0.943       |
|    explained_variance    | 0.972       |
|    lagrangian_multiplier | 0.000491    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.39        |
|    n_updates             | 12760       |
|    policy_gradient_loss  | 0.00767     |
|    std                   | 0.23        |
|    value_loss            | 1.11        |
------------------------------------------
-----------------------------------------
| avg_speed                | 2.4        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 2.4        |
| reward                   | -0.8833734 |
| rollout/                 |            |
|    ep_len_mean           | 43.2       |
|    ep_rew_mean           | -22.8      |
| time/                    |            |
|    fps                   | 63         |
|    iterations            | 4          |
|    time_elapsed          | 129        |
|    total_timesteps       | 2617344    |
| train/                   |            |
|    approx_kl             | 0.09139451 |
|    clip_fraction         | 0.238      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.02       |
|    cost_value_loss       | 3.97       |
|    cost_values           | 1.51       |
|    entropy               | 0.94       |
|    entropy_loss          | 0.941      |
|    explained_variance    | 0.974      |
|    lagrangian_multiplier | 0.000641   |
|    learning_rate         | 0.0003     |
|    loss                  | 2.31       |
|    n_updates             | 12770      |
|    policy_gradient_loss  | 0.0238     |
|    std                   | 0.23       |
|    value_loss            | 0.964      |
-----------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.81882226 |
| rollout/                 |             |
|    ep_len_mean           | 42.8        |
|    ep_rew_mean           | -22.6       |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 5           |
|    time_elapsed          | 163         |
|    total_timesteps       | 2619392     |
| train/                   |             |
|    approx_kl             | 0.02649999  |
|    clip_fraction         | 0.158       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.22        |
|    cost_value_loss       | 4.84        |
|    cost_values           | 1.57        |
|    entropy               | 0.95        |
|    entropy_loss          | 0.944       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0.000589    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.47        |
|    n_updates             | 12780       |
|    policy_gradient_loss  | 0.00507     |
|    std                   | 0.229       |
|    value_loss            | 0.879       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.71447176 |
| rollout/                 |             |
|    ep_len_mean           | 44.1        |
|    ep_rew_mean           | -23.4       |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 6           |
|    time_elapsed          | 198         |
|    total_timesteps       | 2621440     |
| train/                   |             |
|    approx_kl             | 0.025295533 |
|    clip_fraction         | 0.229       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.12        |
|    cost_value_loss       | 3.87        |
|    cost_values           | 1.63        |
|    entropy               | 0.954       |
|    entropy_loss          | 0.953       |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 0.00226     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.07        |
|    n_updates             | 12790       |
|    policy_gradient_loss  | 0.0106      |
|    std                   | 0.229       |
|    value_loss            | 0.772       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.13347404 |
| rollout/                 |             |
|    ep_len_mean           | 45.4        |
|    ep_rew_mean           | -23.9       |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 7           |
|    time_elapsed          | 231         |
|    total_timesteps       | 2623488     |
| train/                   |             |
|    approx_kl             | 0.0663849   |
|    clip_fraction         | 0.225       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.23        |
|    cost_value_loss       | 4.74        |
|    cost_values           | 1.61        |
|    entropy               | 0.957       |
|    entropy_loss          | 0.956       |
|    explained_variance    | 0.966       |
|    lagrangian_multiplier | 0.000543    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.82        |
|    n_updates             | 12800       |
|    policy_gradient_loss  | 0.00352     |
|    std                   | 0.229       |
|    value_loss            | 1.22        |
------------------------------------------
-----------------------------------------
| avg_speed                | 4          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 4          |
| reward                   | -0.7930507 |
| rollout/                 |            |
|    ep_len_mean           | 43.4       |
|    ep_rew_mean           | -22.9      |
| time/                    |            |
|    fps                   | 63         |
|    iterations            | 8          |
|    time_elapsed          | 258        |
|    total_timesteps       | 2625536    |
| train/                   |            |
|    approx_kl             | 0.02811462 |
|    clip_fraction         | 0.197      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.43       |
|    cost_value_loss       | 5.11       |
|    cost_values           | 1.71       |
|    entropy               | 0.959      |
|    entropy_loss          | 0.958      |
|    explained_variance    | 0.963      |
|    lagrangian_multiplier | 0.00248    |
|    learning_rate         | 0.0003     |
|    loss                  | 2.37       |
|    n_updates             | 12810      |
|    policy_gradient_loss  | 0.00892    |
|    std                   | 0.229      |
|    value_loss            | 1.3        |
-----------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.64208746 |
| rollout/                 |             |
|    ep_len_mean           | 43.5        |
|    ep_rew_mean           | -23.1       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 9           |
|    time_elapsed          | 292         |
|    total_timesteps       | 2627584     |
| train/                   |             |
|    approx_kl             | 0.01902358  |
|    clip_fraction         | 0.186       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.15        |
|    cost_value_loss       | 4.08        |
|    cost_values           | 1.68        |
|    entropy               | 0.96        |
|    entropy_loss          | 0.959       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0.000632    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.32        |
|    n_updates             | 12820       |
|    policy_gradient_loss  | 0.00769     |
|    std                   | 0.229       |
|    value_loss            | 0.861       |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 1            |
| max_speed                | 8            |
| reward                   | -0.099054836 |
| rollout/                 |              |
|    ep_len_mean           | 42           |
|    ep_rew_mean           | -22.7        |
| time/                    |              |
|    fps                   | 62           |
|    iterations            | 10           |
|    time_elapsed          | 328          |
|    total_timesteps       | 2629632      |
| train/                   |              |
|    approx_kl             | 0.02841764   |
|    clip_fraction         | 0.2          |
|    clip_range            | 0.2          |
|    cost_returns          | 3.18         |
|    cost_value_loss       | 4.33         |
|    cost_values           | 1.65         |
|    entropy               | 0.959        |
|    entropy_loss          | 0.96         |
|    explained_variance    | 0.977        |
|    lagrangian_multiplier | 0.00125      |
|    learning_rate         | 0.0003       |
|    loss                  | 2.24         |
|    n_updates             | 12830        |
|    policy_gradient_loss  | 0.00591      |
|    std                   | 0.23         |
|    value_loss            | 0.856        |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.6         |
| reward                   | -0.3274065  |
| rollout/                 |             |
|    ep_len_mean           | 42.7        |
|    ep_rew_mean           | -23.1       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 11          |
|    time_elapsed          | 355         |
|    total_timesteps       | 2631680     |
| train/                   |             |
|    approx_kl             | 0.024852067 |
|    clip_fraction         | 0.247       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.05        |
|    cost_value_loss       | 3.71        |
|    cost_values           | 1.62        |
|    entropy               | 0.959       |
|    entropy_loss          | 0.959       |
|    explained_variance    | 0.984       |
|    lagrangian_multiplier | 0.000378    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.2         |
|    n_updates             | 12840       |
|    policy_gradient_loss  | 0.0103      |
|    std                   | 0.229       |
|    value_loss            | 0.612       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.31425977 |
| rollout/                 |             |
|    ep_len_mean           | 43.5        |
|    ep_rew_mean           | -23.2       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 12          |
|    time_elapsed          | 378         |
|    total_timesteps       | 2633728     |
| train/                   |             |
|    approx_kl             | 0.022431733 |
|    clip_fraction         | 0.173       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.11        |
|    cost_value_loss       | 4.47        |
|    cost_values           | 1.53        |
|    entropy               | 0.964       |
|    entropy_loss          | 0.961       |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0.00117     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.15        |
|    n_updates             | 12850       |
|    policy_gradient_loss  | 0.00753     |
|    std                   | 0.228       |
|    value_loss            | 0.705       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.89032185 |
| rollout/                 |             |
|    ep_len_mean           | 42.4        |
|    ep_rew_mean           | -22.9       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 13          |
|    time_elapsed          | 401         |
|    total_timesteps       | 2635776     |
| train/                   |             |
|    approx_kl             | 0.014575671 |
|    clip_fraction         | 0.209       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.23        |
|    cost_value_loss       | 5.11        |
|    cost_values           | 1.55        |
|    entropy               | 0.962       |
|    entropy_loss          | 0.964       |
|    explained_variance    | 0.972       |
|    lagrangian_multiplier | 0.000608    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.83        |
|    n_updates             | 12860       |
|    policy_gradient_loss  | 0.0094      |
|    std                   | 0.229       |
|    value_loss            | 1.05        |
------------------------------------------
----------------------------------------
| avg_speed                | 6.6       |
| cost                     | 0         |
| is_success               | 0         |
| max_speed                | 6.6       |
| reward                   | -0.341359 |
| rollout/                 |           |
|    ep_len_mean           | 42.3      |
|    ep_rew_mean           | -22.8     |
| time/                    |           |
|    fps                   | 67        |
|    iterations            | 14        |
|    time_elapsed          | 425       |
|    total_timesteps       | 2637824   |
| train/                   |           |
|    approx_kl             | 0.0391147 |
|    clip_fraction         | 0.209     |
|    clip_range            | 0.2       |
|    cost_returns          | 2.98      |
|    cost_value_loss       | 3.79      |
|    cost_values           | 1.57      |
|    entropy               | 0.966     |
|    entropy_loss          | 0.963     |
|    explained_variance    | 0.979     |
|    lagrangian_multiplier | 0.000553  |
|    learning_rate         | 0.0003    |
|    loss                  | 2.23      |
|    n_updates             | 12870     |
|    policy_gradient_loss  | 0.00961   |
|    std                   | 0.229     |
|    value_loss            | 0.813     |
----------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.37376297 |
| rollout/                 |             |
|    ep_len_mean           | 42.4        |
|    ep_rew_mean           | -23.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 15          |
|    time_elapsed          | 448         |
|    total_timesteps       | 2639872     |
| train/                   |             |
|    approx_kl             | 0.031806175 |
|    clip_fraction         | 0.186       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.21        |
|    cost_value_loss       | 4.65        |
|    cost_values           | 1.57        |
|    entropy               | 0.972       |
|    entropy_loss          | 0.97        |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0.00173     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.2         |
|    n_updates             | 12880       |
|    policy_gradient_loss  | 0.00896     |
|    std                   | 0.228       |
|    value_loss            | 0.7         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.2         |
| reward                   | -0.33770117 |
| rollout/                 |             |
|    ep_len_mean           | 40.5        |
|    ep_rew_mean           | -22.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 16          |
|    time_elapsed          | 476         |
|    total_timesteps       | 2641920     |
| train/                   |             |
|    approx_kl             | 0.024107795 |
|    clip_fraction         | 0.223       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.07        |
|    cost_value_loss       | 4.33        |
|    cost_values           | 1.51        |
|    entropy               | 0.973       |
|    entropy_loss          | 0.973       |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0.00175     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.99        |
|    n_updates             | 12890       |
|    policy_gradient_loss  | 0.0142      |
|    std                   | 0.228       |
|    value_loss            | 0.527       |
------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.56260663 |
| rollout/                 |             |
|    ep_len_mean           | 40.5        |
|    ep_rew_mean           | -22.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 17          |
|    time_elapsed          | 506         |
|    total_timesteps       | 2643968     |
| train/                   |             |
|    approx_kl             | 0.0348496   |
|    clip_fraction         | 0.178       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.99        |
|    cost_value_loss       | 4.08        |
|    cost_values           | 1.49        |
|    entropy               | 0.977       |
|    entropy_loss          | 0.975       |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0.000473    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.01        |
|    n_updates             | 12900       |
|    policy_gradient_loss  | 0.0124      |
|    std                   | 0.228       |
|    value_loss            | 0.463       |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.54964656 |
| rollout/                 |             |
|    ep_len_mean           | 41.9        |
|    ep_rew_mean           | -22.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 18          |
|    time_elapsed          | 537         |
|    total_timesteps       | 2646016     |
| train/                   |             |
|    approx_kl             | 0.031106431 |
|    clip_fraction         | 0.226       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.94        |
|    cost_value_loss       | 3.88        |
|    cost_values           | 1.45        |
|    entropy               | 0.975       |
|    entropy_loss          | 0.977       |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0.00217     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.91        |
|    n_updates             | 12910       |
|    policy_gradient_loss  | 0.0113      |
|    std                   | 0.229       |
|    value_loss            | 0.524       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.33520356 |
| rollout/                 |             |
|    ep_len_mean           | 41.2        |
|    ep_rew_mean           | -22.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 19          |
|    time_elapsed          | 567         |
|    total_timesteps       | 2648064     |
| train/                   |             |
|    approx_kl             | 0.029704489 |
|    clip_fraction         | 0.209       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.02        |
|    cost_value_loss       | 4.32        |
|    cost_values           | 1.46        |
|    entropy               | 0.974       |
|    entropy_loss          | 0.974       |
|    explained_variance    | 0.984       |
|    lagrangian_multiplier | 0.00117     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.16        |
|    n_updates             | 12920       |
|    policy_gradient_loss  | 0.00874     |
|    std                   | 0.23        |
|    value_loss            | 0.569       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.35841373 |
| rollout/                 |             |
|    ep_len_mean           | 41.8        |
|    ep_rew_mean           | -22.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 20          |
|    time_elapsed          | 598         |
|    total_timesteps       | 2650112     |
| train/                   |             |
|    approx_kl             | 0.04704472  |
|    clip_fraction         | 0.243       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.98        |
|    cost_value_loss       | 4.09        |
|    cost_values           | 1.47        |
|    entropy               | 0.974       |
|    entropy_loss          | 0.974       |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0.000637    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.22        |
|    n_updates             | 12930       |
|    policy_gradient_loss  | 0.00918     |
|    std                   | 0.23        |
|    value_loss            | 0.647       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.12147247 |
| rollout/                 |             |
|    ep_len_mean           | 44          |
|    ep_rew_mean           | -24         |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 21          |
|    time_elapsed          | 632         |
|    total_timesteps       | 2652160     |
| train/                   |             |
|    approx_kl             | 0.022185171 |
|    clip_fraction         | 0.161       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.1         |
|    cost_value_loss       | 4.65        |
|    cost_values           | 1.46        |
|    entropy               | 0.981       |
|    entropy_loss          | 0.977       |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0.00115     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.24        |
|    n_updates             | 12940       |
|    policy_gradient_loss  | 0.00876     |
|    std                   | 0.23        |
|    value_loss            | 0.893       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.8         |
| reward                   | -0.49514014 |
| rollout/                 |             |
|    ep_len_mean           | 43          |
|    ep_rew_mean           | -23.5       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 22          |
|    time_elapsed          | 665         |
|    total_timesteps       | 2654208     |
| train/                   |             |
|    approx_kl             | 0.013868307 |
|    clip_fraction         | 0.151       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.07        |
|    cost_value_loss       | 4.45        |
|    cost_values           | 1.49        |
|    entropy               | 0.981       |
|    entropy_loss          | 0.982       |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0.00201     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.13        |
|    n_updates             | 12950       |
|    policy_gradient_loss  | 0.00948     |
|    std                   | 0.23        |
|    value_loss            | 0.91        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.6578824  |
| rollout/                 |             |
|    ep_len_mean           | 42.4        |
|    ep_rew_mean           | -23.4       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 23          |
|    time_elapsed          | 698         |
|    total_timesteps       | 2656256     |
| train/                   |             |
|    approx_kl             | 0.019702036 |
|    clip_fraction         | 0.254       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.02        |
|    cost_value_loss       | 4.31        |
|    cost_values           | 1.5         |
|    entropy               | 0.975       |
|    entropy_loss          | 0.979       |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 0.000672    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.26        |
|    n_updates             | 12960       |
|    policy_gradient_loss  | 0.0141      |
|    std                   | 0.232       |
|    value_loss            | 0.762       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.8         |
| reward                   | -0.55717605 |
| rollout/                 |             |
|    ep_len_mean           | 41.6        |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 24          |
|    time_elapsed          | 729         |
|    total_timesteps       | 2658304     |
| train/                   |             |
|    approx_kl             | 0.050833613 |
|    clip_fraction         | 0.236       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.93        |
|    cost_value_loss       | 4           |
|    cost_values           | 1.46        |
|    entropy               | 0.971       |
|    entropy_loss          | 0.973       |
|    explained_variance    | 0.984       |
|    lagrangian_multiplier | 0.000839    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.13        |
|    n_updates             | 12970       |
|    policy_gradient_loss  | 0.0113      |
|    std                   | 0.232       |
|    value_loss            | 0.672       |
------------------------------------------
-----------------------------------------
| avg_speed                | 4.4        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 4.4        |
| reward                   | -0.5703252 |
| rollout/                 |            |
|    ep_len_mean           | 42.6       |
|    ep_rew_mean           | -23        |
| time/                    |            |
|    fps                   | 67         |
|    iterations            | 25         |
|    time_elapsed          | 760        |
|    total_timesteps       | 2660352    |
| train/                   |            |
|    approx_kl             | 0.03032294 |
|    clip_fraction         | 0.221      |
|    clip_range            | 0.2        |
|    cost_returns          | 2.93       |
|    cost_value_loss       | 4.06       |
|    cost_values           | 1.4        |
|    entropy               | 0.967      |
|    entropy_loss          | 0.969      |
|    explained_variance    | 0.987      |
|    lagrangian_multiplier | 0.000367   |
|    learning_rate         | 0.0003     |
|    loss                  | 1.99       |
|    n_updates             | 12980      |
|    policy_gradient_loss  | 0.0098     |
|    std                   | 0.233      |
|    value_loss            | 0.516      |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.16624601 |
| rollout/                 |             |
|    ep_len_mean           | 42.2        |
|    ep_rew_mean           | -22.2       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 26          |
|    time_elapsed          | 794         |
|    total_timesteps       | 2662400     |
| train/                   |             |
|    approx_kl             | 0.06076381  |
|    clip_fraction         | 0.197       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.08        |
|    cost_value_loss       | 4.63        |
|    cost_values           | 1.44        |
|    entropy               | 0.971       |
|    entropy_loss          | 0.969       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0.00254     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.05        |
|    n_updates             | 12990       |
|    policy_gradient_loss  | 0.00993     |
|    std                   | 0.232       |
|    value_loss            | 0.814       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.19778131 |
| rollout/                 |             |
|    ep_len_mean           | 42          |
|    ep_rew_mean           | -22.3       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 27          |
|    time_elapsed          | 828         |
|    total_timesteps       | 2664448     |
| train/                   |             |
|    approx_kl             | 0.030048396 |
|    clip_fraction         | 0.231       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.05        |
|    cost_value_loss       | 4.27        |
|    cost_values           | 1.45        |
|    entropy               | 0.979       |
|    entropy_loss          | 0.975       |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0.00104     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.2         |
|    n_updates             | 13000       |
|    policy_gradient_loss  | 0.014       |
|    std                   | 0.231       |
|    value_loss            | 0.782       |
------------------------------------------
-------------------------------------------
| avg_speed                | 6            |
| cost                     | 0            |
| is_success               | 1            |
| max_speed                | 6            |
| reward                   | -0.093171455 |
| rollout/                 |              |
|    ep_len_mean           | 42.9         |
|    ep_rew_mean           | -22.8        |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 28           |
|    time_elapsed          | 859          |
|    total_timesteps       | 2666496      |
| train/                   |              |
|    approx_kl             | 0.083101064  |
|    clip_fraction         | 0.247        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.08         |
|    cost_value_loss       | 4.71         |
|    cost_values           | 1.39         |
|    entropy               | 0.98         |
|    entropy_loss          | 0.98         |
|    explained_variance    | 0.955        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.8          |
|    n_updates             | 13010        |
|    policy_gradient_loss  | 0.0148       |
|    std                   | 0.231        |
|    value_loss            | 1.44         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.20506565 |
| rollout/                 |             |
|    ep_len_mean           | 42          |
|    ep_rew_mean           | -22.3       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 29          |
|    time_elapsed          | 892         |
|    total_timesteps       | 2668544     |
| train/                   |             |
|    approx_kl             | 0.029032292 |
|    clip_fraction         | 0.179       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.87        |
|    cost_value_loss       | 3.66        |
|    cost_values           | 1.46        |
|    entropy               | 0.98        |
|    entropy_loss          | 0.98        |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0.000899    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.01        |
|    n_updates             | 13020       |
|    policy_gradient_loss  | 0.0051      |
|    std                   | 0.232       |
|    value_loss            | 0.799       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.2         |
| reward                   | -0.41452602 |
| rollout/                 |             |
|    ep_len_mean           | 41.8        |
|    ep_rew_mean           | -22.7       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 30          |
|    time_elapsed          | 923         |
|    total_timesteps       | 2670592     |
| train/                   |             |
|    approx_kl             | 0.017054196 |
|    clip_fraction         | 0.197       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.06        |
|    cost_value_loss       | 4.28        |
|    cost_values           | 1.53        |
|    entropy               | 0.984       |
|    entropy_loss          | 0.982       |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0.00201     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.02        |
|    n_updates             | 13030       |
|    policy_gradient_loss  | 0.00699     |
|    std                   | 0.231       |
|    value_loss            | 0.688       |
------------------------------------------
-----------------------------------------
| avg_speed                | 4.4        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 4.4        |
| reward                   | -0.645942  |
| rollout/                 |            |
|    ep_len_mean           | 41.5       |
|    ep_rew_mean           | -22.7      |
| time/                    |            |
|    fps                   | 66         |
|    iterations            | 31         |
|    time_elapsed          | 953        |
|    total_timesteps       | 2672640    |
| train/                   |            |
|    approx_kl             | 0.01997396 |
|    clip_fraction         | 0.207      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.02       |
|    cost_value_loss       | 4.17       |
|    cost_values           | 1.53       |
|    entropy               | 0.988      |
|    entropy_loss          | 0.986      |
|    explained_variance    | 0.982      |
|    lagrangian_multiplier | 0.00156    |
|    learning_rate         | 0.0003     |
|    loss                  | 2.11       |
|    n_updates             | 13040      |
|    policy_gradient_loss  | 0.00843    |
|    std                   | 0.23       |
|    value_loss            | 0.667      |
-----------------------------------------
------------------------------------------
| avg_speed                | 2.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.8         |
| reward                   | -0.8691702  |
| rollout/                 |             |
|    ep_len_mean           | 41.1        |
|    ep_rew_mean           | -22.2       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 32          |
|    time_elapsed          | 983         |
|    total_timesteps       | 2674688     |
| train/                   |             |
|    approx_kl             | 0.039830133 |
|    clip_fraction         | 0.211       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.09        |
|    cost_value_loss       | 4.31        |
|    cost_values           | 1.51        |
|    entropy               | 0.995       |
|    entropy_loss          | 0.991       |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0.000759    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.23        |
|    n_updates             | 13050       |
|    policy_gradient_loss  | 0.00541     |
|    std                   | 0.23        |
|    value_loss            | 0.708       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.8         |
| reward                   | -0.45371696 |
| rollout/                 |             |
|    ep_len_mean           | 41.3        |
|    ep_rew_mean           | -22.3       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 33          |
|    time_elapsed          | 1014        |
|    total_timesteps       | 2676736     |
| train/                   |             |
|    approx_kl             | 0.057182506 |
|    clip_fraction         | 0.276       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.02        |
|    cost_value_loss       | 4.1         |
|    cost_values           | 1.47        |
|    entropy               | 0.987       |
|    entropy_loss          | 0.992       |
|    explained_variance    | 0.985       |
|    lagrangian_multiplier | 0.00142     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.91        |
|    n_updates             | 13060       |
|    policy_gradient_loss  | 0.0133      |
|    std                   | 0.231       |
|    value_loss            | 0.544       |
------------------------------------------
------------------------------------------
| avg_speed                | 7           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7           |
| reward                   | -0.35230416 |
| rollout/                 |             |
|    ep_len_mean           | 41.4        |
|    ep_rew_mean           | -22.2       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 34          |
|    time_elapsed          | 1045        |
|    total_timesteps       | 2678784     |
| train/                   |             |
|    approx_kl             | 0.026539436 |
|    clip_fraction         | 0.22        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.02        |
|    cost_value_loss       | 4.21        |
|    cost_values           | 1.47        |
|    entropy               | 0.986       |
|    entropy_loss          | 0.986       |
|    explained_variance    | 0.984       |
|    lagrangian_multiplier | 0.0018      |
|    learning_rate         | 0.0003      |
|    loss                  | 2.04        |
|    n_updates             | 13070       |
|    policy_gradient_loss  | 0.0137      |
|    std                   | 0.231       |
|    value_loss            | 0.583       |
------------------------------------------
-----------------------------------------
| avg_speed                | 4.4        |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 4.4        |
| reward                   | -0.5462186 |
| rollout/                 |            |
|    ep_len_mean           | 43         |
|    ep_rew_mean           | -23        |
| time/                    |            |
|    fps                   | 66         |
|    iterations            | 35         |
|    time_elapsed          | 1079       |
|    total_timesteps       | 2680832    |
| train/                   |            |
|    approx_kl             | 0.04160746 |
|    clip_fraction         | 0.199      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.04       |
|    cost_value_loss       | 4.36       |
|    cost_values           | 1.48       |
|    entropy               | 0.992      |
|    entropy_loss          | 0.989      |
|    explained_variance    | 0.981      |
|    lagrangian_multiplier | 0.000865   |
|    learning_rate         | 0.0003     |
|    loss                  | 2.18       |
|    n_updates             | 13080      |
|    policy_gradient_loss  | 0.00654    |
|    std                   | 0.231      |
|    value_loss            | 0.698      |
-----------------------------------------
------------------------------------------
| avg_speed                | 3.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.8         |
| reward                   | -0.5194134  |
| rollout/                 |             |
|    ep_len_mean           | 43.3        |
|    ep_rew_mean           | -23         |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 36          |
|    time_elapsed          | 1103        |
|    total_timesteps       | 2682880     |
| train/                   |             |
|    approx_kl             | 0.036382392 |
|    clip_fraction         | 0.223       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.05        |
|    cost_value_loss       | 4.36        |
|    cost_values           | 1.5         |
|    entropy               | 0.995       |
|    entropy_loss          | 0.994       |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0.000986    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.33        |
|    n_updates             | 13090       |
|    policy_gradient_loss  | 0.0131      |
|    std                   | 0.231       |
|    value_loss            | 0.827       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.62343645 |
| rollout/                 |             |
|    ep_len_mean           | 42.1        |
|    ep_rew_mean           | -22.5       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 37          |
|    time_elapsed          | 1127        |
|    total_timesteps       | 2684928     |
| train/                   |             |
|    approx_kl             | 0.062461745 |
|    clip_fraction         | 0.208       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.02        |
|    cost_value_loss       | 4.07        |
|    cost_values           | 1.5         |
|    entropy               | 0.997       |
|    entropy_loss          | 0.996       |
|    explained_variance    | 0.971       |
|    lagrangian_multiplier | 0.000695    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.34        |
|    n_updates             | 13100       |
|    policy_gradient_loss  | 0.0141      |
|    std                   | 0.231       |
|    value_loss            | 0.997       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.62636137 |
| rollout/                 |             |
|    ep_len_mean           | 41.6        |
|    ep_rew_mean           | -22.5       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 38          |
|    time_elapsed          | 1155        |
|    total_timesteps       | 2686976     |
| train/                   |             |
|    approx_kl             | 0.066370115 |
|    clip_fraction         | 0.231       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.01        |
|    cost_value_loss       | 4.08        |
|    cost_values           | 1.49        |
|    entropy               | 1           |
|    entropy_loss          | 0.999       |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 0.00101     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.23        |
|    n_updates             | 13110       |
|    policy_gradient_loss  | 0.0106      |
|    std                   | 0.231       |
|    value_loss            | 0.834       |
------------------------------------------
-----------------------------------------
| avg_speed                | 1.2        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 1.2        |
| reward                   | -0.7531441 |
| rollout/                 |            |
|    ep_len_mean           | 41.5       |
|    ep_rew_mean           | -22.3      |
| time/                    |            |
|    fps                   | 67         |
|    iterations            | 39         |
|    time_elapsed          | 1180       |
|    total_timesteps       | 2689024    |
| train/                   |            |
|    approx_kl             | 0.0409382  |
|    clip_fraction         | 0.226      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.02       |
|    cost_value_loss       | 4.25       |
|    cost_values           | 1.5        |
|    entropy               | 1          |
|    entropy_loss          | 1          |
|    explained_variance    | 0.973      |
|    lagrangian_multiplier | 0.00099    |
|    learning_rate         | 0.0003     |
|    loss                  | 2.44       |
|    n_updates             | 13120      |
|    policy_gradient_loss  | 0.0127     |
|    std                   | 0.231      |
|    value_loss            | 0.98       |
-----------------------------------------
------------------------------------------
| avg_speed                | 3           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3           |
| reward                   | -0.86612475 |
| rollout/                 |             |
|    ep_len_mean           | 42.4        |
|    ep_rew_mean           | -22.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 40          |
|    time_elapsed          | 1203        |
|    total_timesteps       | 2691072     |
| train/                   |             |
|    approx_kl             | 0.02762162  |
|    clip_fraction         | 0.203       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.16        |
|    cost_value_loss       | 4.65        |
|    cost_values           | 1.49        |
|    entropy               | 1           |
|    entropy_loss          | 1           |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0.000294    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.66        |
|    n_updates             | 13130       |
|    policy_gradient_loss  | 0.0143      |
|    std                   | 0.231       |
|    value_loss            | 0.754       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.30757952 |
| rollout/                 |             |
|    ep_len_mean           | 42.4        |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 41          |
|    time_elapsed          | 1227        |
|    total_timesteps       | 2693120     |
| train/                   |             |
|    approx_kl             | 0.03828296  |
|    clip_fraction         | 0.222       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.11        |
|    cost_value_loss       | 4.44        |
|    cost_values           | 1.49        |
|    entropy               | 1           |
|    entropy_loss          | 1           |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0.00225     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.98        |
|    n_updates             | 13140       |
|    policy_gradient_loss  | 0.00867     |
|    std                   | 0.231       |
|    value_loss            | 0.784       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.8         |
| reward                   | -0.65685374 |
| rollout/                 |             |
|    ep_len_mean           | 42.6        |
|    ep_rew_mean           | -23.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 42          |
|    time_elapsed          | 1260        |
|    total_timesteps       | 2695168     |
| train/                   |             |
|    approx_kl             | 0.024097022 |
|    clip_fraction         | 0.216       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.05        |
|    cost_value_loss       | 4.09        |
|    cost_values           | 1.47        |
|    entropy               | 1.01        |
|    entropy_loss          | 1.01        |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0.00105     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.01        |
|    n_updates             | 13150       |
|    policy_gradient_loss  | 0.0106      |
|    std                   | 0.231       |
|    value_loss            | 0.554       |
------------------------------------------
------------------------------------------
| avg_speed                | 6           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6           |
| reward                   | -0.28867623 |
| rollout/                 |             |
|    ep_len_mean           | 41.9        |
|    ep_rew_mean           | -22.9       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 43          |
|    time_elapsed          | 1295        |
|    total_timesteps       | 2697216     |
| train/                   |             |
|    approx_kl             | 0.03400405  |
|    clip_fraction         | 0.257       |
|    clip_range            | 0.2         |
|    cost_returns          | 3           |
|    cost_value_loss       | 4.04        |
|    cost_values           | 1.5         |
|    entropy               | 1.02        |
|    entropy_loss          | 1.01        |
|    explained_variance    | 0.985       |
|    lagrangian_multiplier | 0.00129     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.97        |
|    n_updates             | 13160       |
|    policy_gradient_loss  | 0.0117      |
|    std                   | 0.228       |
|    value_loss            | 0.557       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.606193   |
| rollout/                 |             |
|    ep_len_mean           | 42.4        |
|    ep_rew_mean           | -23.1       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 44          |
|    time_elapsed          | 1329        |
|    total_timesteps       | 2699264     |
| train/                   |             |
|    approx_kl             | 0.016208736 |
|    clip_fraction         | 0.22        |
|    clip_range            | 0.2         |
|    cost_returns          | 2.93        |
|    cost_value_loss       | 3.79        |
|    cost_values           | 1.48        |
|    entropy               | 1.03        |
|    entropy_loss          | 1.02        |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0.00018     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.12        |
|    n_updates             | 13170       |
|    policy_gradient_loss  | 0.00894     |
|    std                   | 0.227       |
|    value_loss            | 0.657       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.4         |
| reward                   | -0.32199585 |
| rollout/                 |             |
|    ep_len_mean           | 43.8        |
|    ep_rew_mean           | -23.4       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 45          |
|    time_elapsed          | 1368        |
|    total_timesteps       | 2701312     |
| train/                   |             |
|    approx_kl             | 0.024817467 |
|    clip_fraction         | 0.231       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.03        |
|    cost_value_loss       | 4.22        |
|    cost_values           | 1.48        |
|    entropy               | 1.03        |
|    entropy_loss          | 1.03        |
|    explained_variance    | 0.985       |
|    lagrangian_multiplier | 0.000562    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.15        |
|    n_updates             | 13180       |
|    policy_gradient_loss  | 0.0153      |
|    std                   | 0.226       |
|    value_loss            | 0.573       |
------------------------------------------
------------------------------------------
| avg_speed                | 7           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7           |
| reward                   | -0.35972267 |
| rollout/                 |             |
|    ep_len_mean           | 43.2        |
|    ep_rew_mean           | -23.2       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 46          |
|    time_elapsed          | 1403        |
|    total_timesteps       | 2703360     |
| train/                   |             |
|    approx_kl             | 0.037753746 |
|    clip_fraction         | 0.24        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.2         |
|    cost_value_loss       | 5           |
|    cost_values           | 1.51        |
|    entropy               | 1.02        |
|    entropy_loss          | 1.03        |
|    explained_variance    | 0.969       |
|    lagrangian_multiplier | 0.000415    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.65        |
|    n_updates             | 13190       |
|    policy_gradient_loss  | 0.00675     |
|    std                   | 0.227       |
|    value_loss            | 1.15        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.31601253 |
| rollout/                 |             |
|    ep_len_mean           | 42          |
|    ep_rew_mean           | -22.5       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 47          |
|    time_elapsed          | 1439        |
|    total_timesteps       | 2705408     |
| train/                   |             |
|    approx_kl             | 0.021162074 |
|    clip_fraction         | 0.245       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.99        |
|    cost_value_loss       | 3.81        |
|    cost_values           | 1.55        |
|    entropy               | 1.02        |
|    entropy_loss          | 1.02        |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0.00114     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.03        |
|    n_updates             | 13200       |
|    policy_gradient_loss  | 0.0158      |
|    std                   | 0.228       |
|    value_loss            | 0.802       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.79367524 |
| rollout/                 |             |
|    ep_len_mean           | 41.8        |
|    ep_rew_mean           | -22.1       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 48          |
|    time_elapsed          | 1470        |
|    total_timesteps       | 2707456     |
| train/                   |             |
|    approx_kl             | 0.083129674 |
|    clip_fraction         | 0.213       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.16        |
|    cost_value_loss       | 4.72        |
|    cost_values           | 1.49        |
|    entropy               | 1.02        |
|    entropy_loss          | 1.02        |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0.0014      |
|    learning_rate         | 0.0003      |
|    loss                  | 2.35        |
|    n_updates             | 13210       |
|    policy_gradient_loss  | 0.0128      |
|    std                   | 0.228       |
|    value_loss            | 0.865       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.2         |
| reward                   | -0.78068316 |
| rollout/                 |             |
|    ep_len_mean           | 40.4        |
|    ep_rew_mean           | -21.9       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 49          |
|    time_elapsed          | 1501        |
|    total_timesteps       | 2709504     |
| train/                   |             |
|    approx_kl             | 0.02949085  |
|    clip_fraction         | 0.167       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.05        |
|    cost_value_loss       | 4.17        |
|    cost_values           | 1.54        |
|    entropy               | 1.02        |
|    entropy_loss          | 1.02        |
|    explained_variance    | 0.971       |
|    lagrangian_multiplier | 0.000469    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.24        |
|    n_updates             | 13220       |
|    policy_gradient_loss  | 0.011       |
|    std                   | 0.228       |
|    value_loss            | 0.986       |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ent-coefficient-ppol/1vjpjg9h
------------------------------------
| avg_speed          | 6.4         |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 6.4         |
| reward             | -0.31102142 |
| rollout/           |             |
|    ep_len_mean     | 40.7        |
|    ep_rew_mean     | -22.2       |
| time/              |             |
|    fps             | 63          |
|    iterations      | 1           |
|    time_elapsed    | 32          |
|    total_timesteps | 2711552     |
------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.7613854  |
| rollout/                 |             |
|    ep_len_mean           | 39.8        |
|    ep_rew_mean           | -22.3       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 2           |
|    time_elapsed          | 64          |
|    total_timesteps       | 2713600     |
| train/                   |             |
|    approx_kl             | 0.041390438 |
|    clip_fraction         | 0.196       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.08        |
|    cost_value_loss       | 4.46        |
|    cost_values           | 1.49        |
|    entropy               | 1.03        |
|    entropy_loss          | 1.03        |
|    explained_variance    | 0.984       |
|    lagrangian_multiplier | 0.00187     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.19        |
|    n_updates             | 13240       |
|    policy_gradient_loss  | 0.0102      |
|    std                   | 0.227       |
|    value_loss            | 0.633       |
------------------------------------------
-----------------------------------------
| avg_speed                | 3.8        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 3.8        |
| reward                   | -0.7948209 |
| rollout/                 |            |
|    ep_len_mean           | 40.1       |
|    ep_rew_mean           | -22.5      |
| time/                    |            |
|    fps                   | 63         |
|    iterations            | 3          |
|    time_elapsed          | 97         |
|    total_timesteps       | 2715648    |
| train/                   |            |
|    approx_kl             | 0.01563881 |
|    clip_fraction         | 0.186      |
|    clip_range            | 0.2        |
|    cost_returns          | 2.9        |
|    cost_value_loss       | 3.71       |
|    cost_values           | 1.48       |
|    entropy               | 1.02       |
|    entropy_loss          | 1.02       |
|    explained_variance    | 0.987      |
|    lagrangian_multiplier | 0.000621   |
|    learning_rate         | 0.0003     |
|    loss                  | 1.89       |
|    n_updates             | 13250      |
|    policy_gradient_loss  | 0.0105     |
|    std                   | 0.228      |
|    value_loss            | 0.502      |
-----------------------------------------
------------------------------------------
| avg_speed                | 6.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.4         |
| reward                   | -0.29360285 |
| rollout/                 |             |
|    ep_len_mean           | 41.6        |
|    ep_rew_mean           | -22.6       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 4           |
|    time_elapsed          | 128         |
|    total_timesteps       | 2717696     |
| train/                   |             |
|    approx_kl             | 0.06612402  |
|    clip_fraction         | 0.211       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.83        |
|    cost_value_loss       | 3.67        |
|    cost_values           | 1.4         |
|    entropy               | 1.03        |
|    entropy_loss          | 1.03        |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0.00112     |
|    learning_rate         | 0.0003      |
|    loss                  | 2           |
|    n_updates             | 13260       |
|    policy_gradient_loss  | 0.0111      |
|    std                   | 0.227       |
|    value_loss            | 0.889       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.54033476 |
| rollout/                 |             |
|    ep_len_mean           | 42.4        |
|    ep_rew_mean           | -22.5       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 5           |
|    time_elapsed          | 159         |
|    total_timesteps       | 2719744     |
| train/                   |             |
|    approx_kl             | 0.028486943 |
|    clip_fraction         | 0.189       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.96        |
|    cost_value_loss       | 4.13        |
|    cost_values           | 1.42        |
|    entropy               | 1.03        |
|    entropy_loss          | 1.03        |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0.000334    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.25        |
|    n_updates             | 13270       |
|    policy_gradient_loss  | 0.00629     |
|    std                   | 0.227       |
|    value_loss            | 0.752       |
------------------------------------------
-----------------------------------------
| avg_speed                | 2.4        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 2.4        |
| reward                   | -0.7073532 |
| rollout/                 |            |
|    ep_len_mean           | 41.6       |
|    ep_rew_mean           | -22.3      |
| time/                    |            |
|    fps                   | 64         |
|    iterations            | 6          |
|    time_elapsed          | 190        |
|    total_timesteps       | 2721792    |
| train/                   |            |
|    approx_kl             | 0.02765722 |
|    clip_fraction         | 0.178      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.07       |
|    cost_value_loss       | 4.37       |
|    cost_values           | 1.49       |
|    entropy               | 1.03       |
|    entropy_loss          | 1.03       |
|    explained_variance    | 0.968      |
|    lagrangian_multiplier | 0.00104    |
|    learning_rate         | 0.0003     |
|    loss                  | 2.37       |
|    n_updates             | 13280      |
|    policy_gradient_loss  | 0.00186    |
|    std                   | 0.227      |
|    value_loss            | 1.11       |
-----------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.27766567 |
| rollout/                 |             |
|    ep_len_mean           | 40.6        |
|    ep_rew_mean           | -21.9       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 7           |
|    time_elapsed          | 219         |
|    total_timesteps       | 2723840     |
| train/                   |             |
|    approx_kl             | 0.026325878 |
|    clip_fraction         | 0.235       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.92        |
|    cost_value_loss       | 3.65        |
|    cost_values           | 1.55        |
|    entropy               | 1.02        |
|    entropy_loss          | 1.02        |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0.000658    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.05        |
|    n_updates             | 13290       |
|    policy_gradient_loss  | 0.00898     |
|    std                   | 0.228       |
|    value_loss            | 0.752       |
------------------------------------------
------------------------------------------
| avg_speed                | 7           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7           |
| reward                   | -0.29748118 |
| rollout/                 |             |
|    ep_len_mean           | 40.7        |
|    ep_rew_mean           | -22.3       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 8           |
|    time_elapsed          | 249         |
|    total_timesteps       | 2725888     |
| train/                   |             |
|    approx_kl             | 0.020008769 |
|    clip_fraction         | 0.199       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.1         |
|    cost_value_loss       | 4.47        |
|    cost_values           | 1.45        |
|    entropy               | 1.03        |
|    entropy_loss          | 1.02        |
|    explained_variance    | 0.985       |
|    lagrangian_multiplier | 0.000921    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.22        |
|    n_updates             | 13300       |
|    policy_gradient_loss  | 0.0108      |
|    std                   | 0.228       |
|    value_loss            | 0.54        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.64587563 |
| rollout/                 |             |
|    ep_len_mean           | 41.9        |
|    ep_rew_mean           | -22.9       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 9           |
|    time_elapsed          | 280         |
|    total_timesteps       | 2727936     |
| train/                   |             |
|    approx_kl             | 0.030873258 |
|    clip_fraction         | 0.206       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.92        |
|    cost_value_loss       | 3.68        |
|    cost_values           | 1.48        |
|    entropy               | 1.02        |
|    entropy_loss          | 1.02        |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 5.9e-05     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.04        |
|    n_updates             | 13310       |
|    policy_gradient_loss  | 0.0102      |
|    std                   | 0.228       |
|    value_loss            | 0.64        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.81848663 |
| rollout/                 |             |
|    ep_len_mean           | 42.3        |
|    ep_rew_mean           | -22.8       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 10          |
|    time_elapsed          | 311         |
|    total_timesteps       | 2729984     |
| train/                   |             |
|    approx_kl             | 0.021085525 |
|    clip_fraction         | 0.212       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.87        |
|    cost_value_loss       | 3.72        |
|    cost_values           | 1.43        |
|    entropy               | 1.02        |
|    entropy_loss          | 1.02        |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0.000352    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.19        |
|    n_updates             | 13320       |
|    policy_gradient_loss  | 0.00418     |
|    std                   | 0.228       |
|    value_loss            | 0.812       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.8759144  |
| rollout/                 |             |
|    ep_len_mean           | 42.1        |
|    ep_rew_mean           | -22         |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 11          |
|    time_elapsed          | 342         |
|    total_timesteps       | 2732032     |
| train/                   |             |
|    approx_kl             | 0.015554846 |
|    clip_fraction         | 0.157       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.93        |
|    cost_value_loss       | 3.86        |
|    cost_values           | 1.42        |
|    entropy               | 1.01        |
|    entropy_loss          | 1.02        |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0.000771    |
|    learning_rate         | 0.0003      |
|    loss                  | 1.94        |
|    n_updates             | 13330       |
|    policy_gradient_loss  | 0.00916     |
|    std                   | 0.229       |
|    value_loss            | 0.717       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.8         |
| reward                   | -0.51568174 |
| rollout/                 |             |
|    ep_len_mean           | 42.5        |
|    ep_rew_mean           | -22.8       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 12          |
|    time_elapsed          | 369         |
|    total_timesteps       | 2734080     |
| train/                   |             |
|    approx_kl             | 0.020066923 |
|    clip_fraction         | 0.209       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.01        |
|    cost_value_loss       | 4.19        |
|    cost_values           | 1.45        |
|    entropy               | 1.01        |
|    entropy_loss          | 1.01        |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0.0022      |
|    learning_rate         | 0.0003      |
|    loss                  | 1.99        |
|    n_updates             | 13340       |
|    policy_gradient_loss  | 0.00865     |
|    std                   | 0.23        |
|    value_loss            | 0.738       |
------------------------------------------
-----------------------------------------
| avg_speed                | 3.8        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 3.8        |
| reward                   | -0.7696143 |
| rollout/                 |            |
|    ep_len_mean           | 41.9       |
|    ep_rew_mean           | -23.1      |
| time/                    |            |
|    fps                   | 67         |
|    iterations            | 13         |
|    time_elapsed          | 393        |
|    total_timesteps       | 2736128    |
| train/                   |            |
|    approx_kl             | 0.01903895 |
|    clip_fraction         | 0.174      |
|    clip_range            | 0.2        |
|    cost_returns          | 2.9        |
|    cost_value_loss       | 3.94       |
|    cost_values           | 1.42       |
|    entropy               | 1.02       |
|    entropy_loss          | 1.01       |
|    explained_variance    | 0.982      |
|    lagrangian_multiplier | 0.00168    |
|    learning_rate         | 0.0003     |
|    loss                  | 1.9        |
|    n_updates             | 13350      |
|    policy_gradient_loss  | 0.00773    |
|    std                   | 0.229      |
|    value_loss            | 0.663      |
-----------------------------------------
------------------------------------------
| avg_speed                | 3.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.8         |
| reward                   | -0.59006304 |
| rollout/                 |             |
|    ep_len_mean           | 42.1        |
|    ep_rew_mean           | -23.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 14          |
|    time_elapsed          | 417         |
|    total_timesteps       | 2738176     |
| train/                   |             |
|    approx_kl             | 0.034589898 |
|    clip_fraction         | 0.206       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.88        |
|    cost_value_loss       | 3.79        |
|    cost_values           | 1.43        |
|    entropy               | 1.01        |
|    entropy_loss          | 1.01        |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0.000921    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.06        |
|    n_updates             | 13360       |
|    policy_gradient_loss  | 0.00716     |
|    std                   | 0.23        |
|    value_loss            | 0.92        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.8         |
| reward                   | -0.59884435 |
| rollout/                 |             |
|    ep_len_mean           | 41.8        |
|    ep_rew_mean           | -23.1       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 15          |
|    time_elapsed          | 443         |
|    total_timesteps       | 2740224     |
| train/                   |             |
|    approx_kl             | 0.033543404 |
|    clip_fraction         | 0.225       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.92        |
|    cost_value_loss       | 3.8         |
|    cost_values           | 1.46        |
|    entropy               | 1.01        |
|    entropy_loss          | 1.01        |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0.000263    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.17        |
|    n_updates             | 13370       |
|    policy_gradient_loss  | 0.0154      |
|    std                   | 0.23        |
|    value_loss            | 0.738       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.6         |
| reward                   | -0.35348257 |
| rollout/                 |             |
|    ep_len_mean           | 41.9        |
|    ep_rew_mean           | -22.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 16          |
|    time_elapsed          | 475         |
|    total_timesteps       | 2742272     |
| train/                   |             |
|    approx_kl             | 0.027093805 |
|    clip_fraction         | 0.233       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.77        |
|    cost_value_loss       | 3.29        |
|    cost_values           | 1.42        |
|    entropy               | 1           |
|    entropy_loss          | 1           |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.91        |
|    n_updates             | 13380       |
|    policy_gradient_loss  | 0.01        |
|    std                   | 0.231       |
|    value_loss            | 0.649       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.3492322  |
| rollout/                 |             |
|    ep_len_mean           | 43.1        |
|    ep_rew_mean           | -23         |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 17          |
|    time_elapsed          | 507         |
|    total_timesteps       | 2744320     |
| train/                   |             |
|    approx_kl             | 0.019616745 |
|    clip_fraction         | 0.177       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.17        |
|    cost_value_loss       | 4.65        |
|    cost_values           | 1.44        |
|    entropy               | 1           |
|    entropy_loss          | 1           |
|    explained_variance    | 0.967       |
|    lagrangian_multiplier | 0.000587    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.29        |
|    n_updates             | 13390       |
|    policy_gradient_loss  | 0.00558     |
|    std                   | 0.231       |
|    value_loss            | 1.06        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.4         |
| reward                   | -0.29265383 |
| rollout/                 |             |
|    ep_len_mean           | 41.7        |
|    ep_rew_mean           | -22.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 18          |
|    time_elapsed          | 539         |
|    total_timesteps       | 2746368     |
| train/                   |             |
|    approx_kl             | 0.04766588  |
|    clip_fraction         | 0.192       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.04        |
|    cost_value_loss       | 4.07        |
|    cost_values           | 1.52        |
|    entropy               | 0.999       |
|    entropy_loss          | 1           |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0.00233     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.06        |
|    n_updates             | 13400       |
|    policy_gradient_loss  | 0.00358     |
|    std                   | 0.231       |
|    value_loss            | 0.889       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.2         |
| reward                   | -0.28518385 |
| rollout/                 |             |
|    ep_len_mean           | 42.2        |
|    ep_rew_mean           | -23         |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 19          |
|    time_elapsed          | 573         |
|    total_timesteps       | 2748416     |
| train/                   |             |
|    approx_kl             | 0.022111733 |
|    clip_fraction         | 0.222       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.87        |
|    cost_value_loss       | 3.44        |
|    cost_values           | 1.45        |
|    entropy               | 1           |
|    entropy_loss          | 1           |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 0.00146     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.92        |
|    n_updates             | 13410       |
|    policy_gradient_loss  | 0.00139     |
|    std                   | 0.231       |
|    value_loss            | 0.76        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.8126183  |
| rollout/                 |             |
|    ep_len_mean           | 42.7        |
|    ep_rew_mean           | -23.6       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 20          |
|    time_elapsed          | 605         |
|    total_timesteps       | 2750464     |
| train/                   |             |
|    approx_kl             | 0.017834567 |
|    clip_fraction         | 0.163       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.82        |
|    cost_value_loss       | 3.6         |
|    cost_values           | 1.4         |
|    entropy               | 1.01        |
|    entropy_loss          | 1           |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0.00177     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.89        |
|    n_updates             | 13420       |
|    policy_gradient_loss  | 0.003       |
|    std                   | 0.231       |
|    value_loss            | 0.701       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.79619116 |
| rollout/                 |             |
|    ep_len_mean           | 42.1        |
|    ep_rew_mean           | -23.1       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 21          |
|    time_elapsed          | 637         |
|    total_timesteps       | 2752512     |
| train/                   |             |
|    approx_kl             | 0.025327846 |
|    clip_fraction         | 0.257       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.82        |
|    cost_value_loss       | 3.95        |
|    cost_values           | 1.34        |
|    entropy               | 1.01        |
|    entropy_loss          | 1.01        |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0.00159     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.89        |
|    n_updates             | 13430       |
|    policy_gradient_loss  | 0.0197      |
|    std                   | 0.231       |
|    value_loss            | 0.698       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.2         |
| reward                   | -0.37313762 |
| rollout/                 |             |
|    ep_len_mean           | 41.3        |
|    ep_rew_mean           | -22.5       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 22          |
|    time_elapsed          | 669         |
|    total_timesteps       | 2754560     |
| train/                   |             |
|    approx_kl             | 0.022067837 |
|    clip_fraction         | 0.204       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.78        |
|    cost_value_loss       | 3.83        |
|    cost_values           | 1.31        |
|    entropy               | 1.02        |
|    entropy_loss          | 1.01        |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0.000876    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.04        |
|    n_updates             | 13440       |
|    policy_gradient_loss  | 0.0083      |
|    std                   | 0.23        |
|    value_loss            | 0.758       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.8140044  |
| rollout/                 |             |
|    ep_len_mean           | 41.2        |
|    ep_rew_mean           | -22.3       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 23          |
|    time_elapsed          | 697         |
|    total_timesteps       | 2756608     |
| train/                   |             |
|    approx_kl             | 0.014828261 |
|    clip_fraction         | 0.202       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.9         |
|    cost_value_loss       | 3.86        |
|    cost_values           | 1.36        |
|    entropy               | 1.02        |
|    entropy_loss          | 1.02        |
|    explained_variance    | 0.985       |
|    lagrangian_multiplier | 0.000373    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.02        |
|    n_updates             | 13450       |
|    policy_gradient_loss  | 0.00976     |
|    std                   | 0.23        |
|    value_loss            | 0.53        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.68419373 |
| rollout/                 |             |
|    ep_len_mean           | 42.4        |
|    ep_rew_mean           | -22.7       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 24          |
|    time_elapsed          | 724         |
|    total_timesteps       | 2758656     |
| train/                   |             |
|    approx_kl             | 0.02576859  |
|    clip_fraction         | 0.193       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.99        |
|    cost_value_loss       | 4.18        |
|    cost_values           | 1.44        |
|    entropy               | 1.01        |
|    entropy_loss          | 1.02        |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0.000805    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.26        |
|    n_updates             | 13460       |
|    policy_gradient_loss  | 0.00866     |
|    std                   | 0.23        |
|    value_loss            | 0.831       |
------------------------------------------
-----------------------------------------
| avg_speed                | 6.2        |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 6.2        |
| reward                   | -0.3063728 |
| rollout/                 |            |
|    ep_len_mean           | 42.2       |
|    ep_rew_mean           | -23.1      |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 25         |
|    time_elapsed          | 752        |
|    total_timesteps       | 2760704    |
| train/                   |            |
|    approx_kl             | 0.0556781  |
|    clip_fraction         | 0.213      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.11       |
|    cost_value_loss       | 4.69       |
|    cost_values           | 1.49       |
|    entropy               | 1.02       |
|    entropy_loss          | 1.02       |
|    explained_variance    | 0.973      |
|    lagrangian_multiplier | 0.00187    |
|    learning_rate         | 0.0003     |
|    loss                  | 2.21       |
|    n_updates             | 13470      |
|    policy_gradient_loss  | 0.0159     |
|    std                   | 0.229      |
|    value_loss            | 0.967      |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.8198299  |
| rollout/                 |             |
|    ep_len_mean           | 41.9        |
|    ep_rew_mean           | -22.4       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 26          |
|    time_elapsed          | 787         |
|    total_timesteps       | 2762752     |
| train/                   |             |
|    approx_kl             | 0.011498179 |
|    clip_fraction         | 0.21        |
|    clip_range            | 0.2         |
|    cost_returns          | 2.98        |
|    cost_value_loss       | 3.97        |
|    cost_values           | 1.48        |
|    entropy               | 1.02        |
|    entropy_loss          | 1.02        |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0.0019      |
|    learning_rate         | 0.0003      |
|    loss                  | 1.92        |
|    n_updates             | 13480       |
|    policy_gradient_loss  | 0.0124      |
|    std                   | 0.229       |
|    value_loss            | 0.671       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.5744095  |
| rollout/                 |             |
|    ep_len_mean           | 41.3        |
|    ep_rew_mean           | -21.8       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 27          |
|    time_elapsed          | 819         |
|    total_timesteps       | 2764800     |
| train/                   |             |
|    approx_kl             | 0.037433483 |
|    clip_fraction         | 0.207       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.08        |
|    cost_value_loss       | 4.68        |
|    cost_values           | 1.47        |
|    entropy               | 1.03        |
|    entropy_loss          | 1.02        |
|    explained_variance    | 0.966       |
|    lagrangian_multiplier | 0.00164     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.29        |
|    n_updates             | 13490       |
|    policy_gradient_loss  | 0.00982     |
|    std                   | 0.229       |
|    value_loss            | 1.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.56705135 |
| rollout/                 |             |
|    ep_len_mean           | 41.5        |
|    ep_rew_mean           | -22.5       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 28          |
|    time_elapsed          | 853         |
|    total_timesteps       | 2766848     |
| train/                   |             |
|    approx_kl             | 0.029943937 |
|    clip_fraction         | 0.194       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.03        |
|    cost_value_loss       | 4.39        |
|    cost_values           | 1.47        |
|    entropy               | 1.03        |
|    entropy_loss          | 1.03        |
|    explained_variance    | 0.973       |
|    lagrangian_multiplier | 0.000474    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.4         |
|    n_updates             | 13500       |
|    policy_gradient_loss  | 0.00509     |
|    std                   | 0.228       |
|    value_loss            | 0.998       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.63651633 |
| rollout/                 |             |
|    ep_len_mean           | 41.9        |
|    ep_rew_mean           | -22.9       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 29          |
|    time_elapsed          | 887         |
|    total_timesteps       | 2768896     |
| train/                   |             |
|    approx_kl             | 0.02377794  |
|    clip_fraction         | 0.205       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.2         |
|    cost_value_loss       | 4.85        |
|    cost_values           | 1.49        |
|    entropy               | 1.03        |
|    entropy_loss          | 1.03        |
|    explained_variance    | 0.972       |
|    lagrangian_multiplier | 0.00165     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.42        |
|    n_updates             | 13510       |
|    policy_gradient_loss  | 0.0103      |
|    std                   | 0.229       |
|    value_loss            | 1.01        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.37289405 |
| rollout/                 |             |
|    ep_len_mean           | 42.3        |
|    ep_rew_mean           | -22.8       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 30          |
|    time_elapsed          | 923         |
|    total_timesteps       | 2770944     |
| train/                   |             |
|    approx_kl             | 0.018979833 |
|    clip_fraction         | 0.24        |
|    clip_range            | 0.2         |
|    cost_returns          | 2.86        |
|    cost_value_loss       | 3.61        |
|    cost_values           | 1.48        |
|    entropy               | 1.04        |
|    entropy_loss          | 1.03        |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0.000484    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.07        |
|    n_updates             | 13520       |
|    policy_gradient_loss  | 0.00922     |
|    std                   | 0.228       |
|    value_loss            | 0.665       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 1           |
| max_speed                | 8           |
| reward                   | -0.11401288 |
| rollout/                 |             |
|    ep_len_mean           | 42.3        |
|    ep_rew_mean           | -22.4       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 31          |
|    time_elapsed          | 956         |
|    total_timesteps       | 2772992     |
| train/                   |             |
|    approx_kl             | 0.024260756 |
|    clip_fraction         | 0.188       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.26        |
|    cost_value_loss       | 5.24        |
|    cost_values           | 1.5         |
|    entropy               | 1.04        |
|    entropy_loss          | 1.04        |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0.000998    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.56        |
|    n_updates             | 13530       |
|    policy_gradient_loss  | 0.00582     |
|    std                   | 0.227       |
|    value_loss            | 0.853       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.18002646 |
| rollout/                 |             |
|    ep_len_mean           | 41.7        |
|    ep_rew_mean           | -22.2       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 32          |
|    time_elapsed          | 989         |
|    total_timesteps       | 2775040     |
| train/                   |             |
|    approx_kl             | 0.03465506  |
|    clip_fraction         | 0.205       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.08        |
|    cost_value_loss       | 4.29        |
|    cost_values           | 1.53        |
|    entropy               | 1.05        |
|    entropy_loss          | 1.04        |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0.00198     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.09        |
|    n_updates             | 13540       |
|    policy_gradient_loss  | 0.014       |
|    std                   | 0.226       |
|    value_loss            | 0.807       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.71447176 |
| rollout/                 |             |
|    ep_len_mean           | 42          |
|    ep_rew_mean           | -22.5       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 33          |
|    time_elapsed          | 1021        |
|    total_timesteps       | 2777088     |
| train/                   |             |
|    approx_kl             | 0.020905785 |
|    clip_fraction         | 0.216       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.11        |
|    cost_value_loss       | 4.44        |
|    cost_values           | 1.48        |
|    entropy               | 1.05        |
|    entropy_loss          | 1.05        |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 0.00127     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.29        |
|    n_updates             | 13550       |
|    policy_gradient_loss  | 0.00732     |
|    std                   | 0.225       |
|    value_loss            | 0.754       |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.54964656 |
| rollout/                 |             |
|    ep_len_mean           | 43.8        |
|    ep_rew_mean           | -23.5       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 34          |
|    time_elapsed          | 1044        |
|    total_timesteps       | 2779136     |
| train/                   |             |
|    approx_kl             | 0.01669452  |
|    clip_fraction         | 0.238       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.05        |
|    cost_value_loss       | 4.71        |
|    cost_values           | 1.44        |
|    entropy               | 1.05        |
|    entropy_loss          | 1.05        |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 0.00101     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.38        |
|    n_updates             | 13560       |
|    policy_gradient_loss  | 0.00843     |
|    std                   | 0.225       |
|    value_loss            | 0.781       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.9070134  |
| rollout/                 |             |
|    ep_len_mean           | 43.4        |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 35          |
|    time_elapsed          | 1068        |
|    total_timesteps       | 2781184     |
| train/                   |             |
|    approx_kl             | 0.023441613 |
|    clip_fraction         | 0.217       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.28        |
|    cost_value_loss       | 5.13        |
|    cost_values           | 1.48        |
|    entropy               | 1.05        |
|    entropy_loss          | 1.05        |
|    explained_variance    | 0.971       |
|    lagrangian_multiplier | 0.00107     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.71        |
|    n_updates             | 13570       |
|    policy_gradient_loss  | -0.00011    |
|    std                   | 0.224       |
|    value_loss            | 1.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.7918867  |
| rollout/                 |             |
|    ep_len_mean           | 42.1        |
|    ep_rew_mean           | -22.9       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 36          |
|    time_elapsed          | 1101        |
|    total_timesteps       | 2783232     |
| train/                   |             |
|    approx_kl             | 0.027305963 |
|    clip_fraction         | 0.226       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.94        |
|    cost_value_loss       | 4.08        |
|    cost_values           | 1.48        |
|    entropy               | 1.05        |
|    entropy_loss          | 1.05        |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0.000816    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.2         |
|    n_updates             | 13580       |
|    policy_gradient_loss  | 0.0114      |
|    std                   | 0.224       |
|    value_loss            | 0.828       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2198749  |
| rollout/                 |             |
|    ep_len_mean           | 41.8        |
|    ep_rew_mean           | -23         |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 37          |
|    time_elapsed          | 1137        |
|    total_timesteps       | 2785280     |
| train/                   |             |
|    approx_kl             | 0.021391256 |
|    clip_fraction         | 0.192       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.08        |
|    cost_value_loss       | 4.72        |
|    cost_values           | 1.43        |
|    entropy               | 1.06        |
|    entropy_loss          | 1.06        |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0.000584    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.31        |
|    n_updates             | 13590       |
|    policy_gradient_loss  | 0.0102      |
|    std                   | 0.223       |
|    value_loss            | 0.457       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.47064278 |
| rollout/                 |             |
|    ep_len_mean           | 40.9        |
|    ep_rew_mean           | -22.2       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 38          |
|    time_elapsed          | 1162        |
|    total_timesteps       | 2787328     |
| train/                   |             |
|    approx_kl             | 0.024835337 |
|    clip_fraction         | 0.241       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.07        |
|    cost_value_loss       | 4.59        |
|    cost_values           | 1.43        |
|    entropy               | 1.07        |
|    entropy_loss          | 1.07        |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0.00069     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.28        |
|    n_updates             | 13600       |
|    policy_gradient_loss  | 0.015       |
|    std                   | 0.223       |
|    value_loss            | 0.696       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3528809  |
| rollout/                 |             |
|    ep_len_mean           | 40.9        |
|    ep_rew_mean           | -21.8       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 39          |
|    time_elapsed          | 1185        |
|    total_timesteps       | 2789376     |
| train/                   |             |
|    approx_kl             | 0.039867766 |
|    clip_fraction         | 0.185       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.04        |
|    cost_value_loss       | 4.54        |
|    cost_values           | 1.41        |
|    entropy               | 1.06        |
|    entropy_loss          | 1.07        |
|    explained_variance    | 0.984       |
|    lagrangian_multiplier | 0.000101    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.48        |
|    n_updates             | 13610       |
|    policy_gradient_loss  | 0.0136      |
|    std                   | 0.224       |
|    value_loss            | 0.584       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.7925409  |
| rollout/                 |             |
|    ep_len_mean           | 41.6        |
|    ep_rew_mean           | -22.3       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 40          |
|    time_elapsed          | 1209        |
|    total_timesteps       | 2791424     |
| train/                   |             |
|    approx_kl             | 0.011574991 |
|    clip_fraction         | 0.203       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.09        |
|    cost_value_loss       | 4.77        |
|    cost_values           | 1.4         |
|    entropy               | 1.06        |
|    entropy_loss          | 1.06        |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0.000984    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.32        |
|    n_updates             | 13620       |
|    policy_gradient_loss  | 0.0111      |
|    std                   | 0.224       |
|    value_loss            | 0.654       |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.6        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.6        |
| reward                   | -0.7168824 |
| rollout/                 |            |
|    ep_len_mean           | 42.3       |
|    ep_rew_mean           | -22.7      |
| time/                    |            |
|    fps                   | 67         |
|    iterations            | 41         |
|    time_elapsed          | 1236       |
|    total_timesteps       | 2793472    |
| train/                   |            |
|    approx_kl             | 0.03702063 |
|    clip_fraction         | 0.223      |
|    clip_range            | 0.2        |
|    cost_returns          | 2.92       |
|    cost_value_loss       | 4.11       |
|    cost_values           | 1.43       |
|    entropy               | 1.07       |
|    entropy_loss          | 1.07       |
|    explained_variance    | 0.979      |
|    lagrangian_multiplier | 0.0008     |
|    learning_rate         | 0.0003     |
|    loss                  | 2.23       |
|    n_updates             | 13630      |
|    policy_gradient_loss  | 0.0132     |
|    std                   | 0.224      |
|    value_loss            | 0.776      |
-----------------------------------------
------------------------------------------
| avg_speed                | 5           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5           |
| reward                   | -0.532324   |
| rollout/                 |             |
|    ep_len_mean           | 41.9        |
|    ep_rew_mean           | -22.9       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 42          |
|    time_elapsed          | 1269        |
|    total_timesteps       | 2795520     |
| train/                   |             |
|    approx_kl             | 0.028673053 |
|    clip_fraction         | 0.212       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.07        |
|    cost_value_loss       | 4.65        |
|    cost_values           | 1.41        |
|    entropy               | 1.06        |
|    entropy_loss          | 1.07        |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0.00052     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.38        |
|    n_updates             | 13640       |
|    policy_gradient_loss  | 0.00637     |
|    std                   | 0.225       |
|    value_loss            | 0.711       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.6         |
| reward                   | -0.37647757 |
| rollout/                 |             |
|    ep_len_mean           | 40.2        |
|    ep_rew_mean           | -22.2       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 43          |
|    time_elapsed          | 1300        |
|    total_timesteps       | 2797568     |
| train/                   |             |
|    approx_kl             | 0.02876538  |
|    clip_fraction         | 0.188       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.98        |
|    cost_value_loss       | 4.22        |
|    cost_values           | 1.41        |
|    entropy               | 1.06        |
|    entropy_loss          | 1.06        |
|    explained_variance    | 0.984       |
|    lagrangian_multiplier | 0.00217     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.95        |
|    n_updates             | 13650       |
|    policy_gradient_loss  | 0.00745     |
|    std                   | 0.226       |
|    value_loss            | 0.616       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.88454556 |
| rollout/                 |             |
|    ep_len_mean           | 39.6        |
|    ep_rew_mean           | -21.8       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 44          |
|    time_elapsed          | 1337        |
|    total_timesteps       | 2799616     |
| train/                   |             |
|    approx_kl             | 0.007889628 |
|    clip_fraction         | 0.265       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.96        |
|    cost_value_loss       | 4.15        |
|    cost_values           | 1.42        |
|    entropy               | 1.06        |
|    entropy_loss          | 1.06        |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0.00012     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.26        |
|    n_updates             | 13660       |
|    policy_gradient_loss  | 0.0224      |
|    std                   | 0.226       |
|    value_loss            | 0.486       |
------------------------------------------
------------------------------------------
| avg_speed                | 6           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6           |
| reward                   | -0.3348105  |
| rollout/                 |             |
|    ep_len_mean           | 41          |
|    ep_rew_mean           | -22         |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 45          |
|    time_elapsed          | 1372        |
|    total_timesteps       | 2801664     |
| train/                   |             |
|    approx_kl             | 0.043721482 |
|    clip_fraction         | 0.244       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.98        |
|    cost_value_loss       | 4.17        |
|    cost_values           | 1.41        |
|    entropy               | 1.06        |
|    entropy_loss          | 1.06        |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0.000156    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.12        |
|    n_updates             | 13670       |
|    policy_gradient_loss  | 0.00986     |
|    std                   | 0.226       |
|    value_loss            | 0.582       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.16729677 |
| rollout/                 |             |
|    ep_len_mean           | 41.5        |
|    ep_rew_mean           | -22.1       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 46          |
|    time_elapsed          | 1404        |
|    total_timesteps       | 2803712     |
| train/                   |             |
|    approx_kl             | 0.056187496 |
|    clip_fraction         | 0.239       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.05        |
|    cost_value_loss       | 4.46        |
|    cost_values           | 1.4         |
|    entropy               | 1.06        |
|    entropy_loss          | 1.06        |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0.00125     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.29        |
|    n_updates             | 13680       |
|    policy_gradient_loss  | 0.0225      |
|    std                   | 0.226       |
|    value_loss            | 0.742       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.77667624 |
| rollout/                 |             |
|    ep_len_mean           | 41.5        |
|    ep_rew_mean           | -22.3       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 47          |
|    time_elapsed          | 1438        |
|    total_timesteps       | 2805760     |
| train/                   |             |
|    approx_kl             | 0.01906211  |
|    clip_fraction         | 0.167       |
|    clip_range            | 0.2         |
|    cost_returns          | 3           |
|    cost_value_loss       | 4.35        |
|    cost_values           | 1.38        |
|    entropy               | 1.06        |
|    entropy_loss          | 1.06        |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.47        |
|    n_updates             | 13690       |
|    policy_gradient_loss  | 0.00684     |
|    std                   | 0.226       |
|    value_loss            | 0.631       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.39073208 |
| rollout/                 |             |
|    ep_len_mean           | 41.5        |
|    ep_rew_mean           | -22.5       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 48          |
|    time_elapsed          | 1474        |
|    total_timesteps       | 2807808     |
| train/                   |             |
|    approx_kl             | 0.034625173 |
|    clip_fraction         | 0.226       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.94        |
|    cost_value_loss       | 3.94        |
|    cost_values           | 1.42        |
|    entropy               | 1.06        |
|    entropy_loss          | 1.06        |
|    explained_variance    | 0.967       |
|    lagrangian_multiplier | 0.000217    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.6         |
|    n_updates             | 13700       |
|    policy_gradient_loss  | 0.00766     |
|    std                   | 0.227       |
|    value_loss            | 1.18        |
------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.77493626 |
| rollout/                 |             |
|    ep_len_mean           | 41.9        |
|    ep_rew_mean           | -22.8       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 49          |
|    time_elapsed          | 1509        |
|    total_timesteps       | 2809856     |
| train/                   |             |
|    approx_kl             | 0.018819924 |
|    clip_fraction         | 0.198       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.03        |
|    cost_value_loss       | 4.23        |
|    cost_values           | 1.46        |
|    entropy               | 1.06        |
|    entropy_loss          | 1.06        |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0.00108     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.22        |
|    n_updates             | 13710       |
|    policy_gradient_loss  | 0.00549     |
|    std                   | 0.226       |
|    value_loss            | 0.91        |
------------------------------------------
------------------------------------
| avg_speed          | 0.2         |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.2         |
| reward             | -0.84387267 |
| rollout/           |             |
|    ep_len_mean     | 41.6        |
|    ep_rew_mean     | -22.5       |
| time/              |             |
|    fps             | 63          |
|    iterations      | 1           |
|    time_elapsed    | 32          |
|    total_timesteps | 2811904     |
------------------------------------
------------------------------------------
| avg_speed                | 7.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.4         |
| reward                   | -0.16313227 |
| rollout/                 |             |
|    ep_len_mean           | 41.1        |
|    ep_rew_mean           | -22.3       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 2           |
|    time_elapsed          | 64          |
|    total_timesteps       | 2813952     |
| train/                   |             |
|    approx_kl             | 0.019394603 |
|    clip_fraction         | 0.229       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.97        |
|    cost_value_loss       | 3.86        |
|    cost_values           | 1.47        |
|    entropy               | 1.07        |
|    entropy_loss          | 1.07        |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0.000467    |
|    learning_rate         | 0.0003      |
|    loss                  | 1.95        |
|    n_updates             | 13730       |
|    policy_gradient_loss  | 0.0154      |
|    std                   | 0.225       |
|    value_loss            | 0.643       |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.4        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.4        |
| reward                   | -0.7954075 |
| rollout/                 |            |
|    ep_len_mean           | 41.9       |
|    ep_rew_mean           | -22.6      |
| time/                    |            |
|    fps                   | 63         |
|    iterations            | 3          |
|    time_elapsed          | 96         |
|    total_timesteps       | 2816000    |
| train/                   |            |
|    approx_kl             | 0.03315305 |
|    clip_fraction         | 0.215      |
|    clip_range            | 0.2        |
|    cost_returns          | 2.82       |
|    cost_value_loss       | 3.4        |
|    cost_values           | 1.44       |
|    entropy               | 1.07       |
|    entropy_loss          | 1.07       |
|    explained_variance    | 0.975      |
|    lagrangian_multiplier | 0.00121    |
|    learning_rate         | 0.0003     |
|    loss                  | 1.93       |
|    n_updates             | 13740      |
|    policy_gradient_loss  | 0.0115     |
|    std                   | 0.225      |
|    value_loss            | 0.926      |
-----------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.8581075  |
| rollout/                 |             |
|    ep_len_mean           | 41.5        |
|    ep_rew_mean           | -22.5       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 4           |
|    time_elapsed          | 125         |
|    total_timesteps       | 2818048     |
| train/                   |             |
|    approx_kl             | 0.019280622 |
|    clip_fraction         | 0.216       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.03        |
|    cost_value_loss       | 4.35        |
|    cost_values           | 1.42        |
|    entropy               | 1.08        |
|    entropy_loss          | 1.07        |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0.00102     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.17        |
|    n_updates             | 13750       |
|    policy_gradient_loss  | 0.0169      |
|    std                   | 0.224       |
|    value_loss            | 0.823       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.4         |
| reward                   | -0.6590822  |
| rollout/                 |             |
|    ep_len_mean           | 42.1        |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 5           |
|    time_elapsed          | 154         |
|    total_timesteps       | 2820096     |
| train/                   |             |
|    approx_kl             | 0.024605256 |
|    clip_fraction         | 0.21        |
|    clip_range            | 0.2         |
|    cost_returns          | 2.76        |
|    cost_value_loss       | 3.43        |
|    cost_values           | 1.42        |
|    entropy               | 1.08        |
|    entropy_loss          | 1.08        |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 2.07e-06    |
|    learning_rate         | 0.0003      |
|    loss                  | 1.9         |
|    n_updates             | 13760       |
|    policy_gradient_loss  | 0.00827     |
|    std                   | 0.225       |
|    value_loss            | 0.821       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.5216522  |
| rollout/                 |             |
|    ep_len_mean           | 42          |
|    ep_rew_mean           | -23.4       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 6           |
|    time_elapsed          | 191         |
|    total_timesteps       | 2822144     |
| train/                   |             |
|    approx_kl             | 0.023580208 |
|    clip_fraction         | 0.19        |
|    clip_range            | 0.2         |
|    cost_returns          | 2.95        |
|    cost_value_loss       | 3.81        |
|    cost_values           | 1.44        |
|    entropy               | 1.08        |
|    entropy_loss          | 1.08        |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0.00254     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.97        |
|    n_updates             | 13770       |
|    policy_gradient_loss  | 0.00847     |
|    std                   | 0.224       |
|    value_loss            | 0.901       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.6842222  |
| rollout/                 |             |
|    ep_len_mean           | 41.9        |
|    ep_rew_mean           | -22.8       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 7           |
|    time_elapsed          | 224         |
|    total_timesteps       | 2824192     |
| train/                   |             |
|    approx_kl             | 0.021010462 |
|    clip_fraction         | 0.234       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.99        |
|    cost_value_loss       | 4.31        |
|    cost_values           | 1.44        |
|    entropy               | 1.09        |
|    entropy_loss          | 1.09        |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0.000381    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.44        |
|    n_updates             | 13780       |
|    policy_gradient_loss  | 0.0102      |
|    std                   | 0.223       |
|    value_loss            | 0.778       |
------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.77493626 |
| rollout/                 |             |
|    ep_len_mean           | 42.3        |
|    ep_rew_mean           | -22.8       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 8           |
|    time_elapsed          | 257         |
|    total_timesteps       | 2826240     |
| train/                   |             |
|    approx_kl             | 0.02796307  |
|    clip_fraction         | 0.21        |
|    clip_range            | 0.2         |
|    cost_returns          | 2.79        |
|    cost_value_loss       | 3.3         |
|    cost_values           | 1.45        |
|    entropy               | 1.08        |
|    entropy_loss          | 1.08        |
|    explained_variance    | 0.973       |
|    lagrangian_multiplier | 0.0006      |
|    learning_rate         | 0.0003      |
|    loss                  | 1.93        |
|    n_updates             | 13790       |
|    policy_gradient_loss  | 0.0107      |
|    std                   | 0.224       |
|    value_loss            | 0.931       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.76581323 |
| rollout/                 |             |
|    ep_len_mean           | 42.4        |
|    ep_rew_mean           | -22.9       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 9           |
|    time_elapsed          | 281         |
|    total_timesteps       | 2828288     |
| train/                   |             |
|    approx_kl             | 0.027581055 |
|    clip_fraction         | 0.246       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.05        |
|    cost_value_loss       | 4.26        |
|    cost_values           | 1.46        |
|    entropy               | 1.07        |
|    entropy_loss          | 1.08        |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0.0018      |
|    learning_rate         | 0.0003      |
|    loss                  | 1.99        |
|    n_updates             | 13800       |
|    policy_gradient_loss  | 0.0183      |
|    std                   | 0.225       |
|    value_loss            | 0.94        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.5218511  |
| rollout/                 |             |
|    ep_len_mean           | 42.8        |
|    ep_rew_mean           | -22.9       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 10          |
|    time_elapsed          | 304         |
|    total_timesteps       | 2830336     |
| train/                   |             |
|    approx_kl             | 0.029640755 |
|    clip_fraction         | 0.231       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.88        |
|    cost_value_loss       | 3.89        |
|    cost_values           | 1.43        |
|    entropy               | 1.06        |
|    entropy_loss          | 1.07        |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0.00112     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.08        |
|    n_updates             | 13810       |
|    policy_gradient_loss  | 0.0118      |
|    std                   | 0.225       |
|    value_loss            | 0.805       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.2         |
| reward                   | -0.23912826 |
| rollout/                 |             |
|    ep_len_mean           | 43.3        |
|    ep_rew_mean           | -23.5       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 11          |
|    time_elapsed          | 332         |
|    total_timesteps       | 2832384     |
| train/                   |             |
|    approx_kl             | 0.039197315 |
|    clip_fraction         | 0.235       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.02        |
|    cost_value_loss       | 4.48        |
|    cost_values           | 1.41        |
|    entropy               | 1.07        |
|    entropy_loss          | 1.06        |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0.000919    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.24        |
|    n_updates             | 13820       |
|    policy_gradient_loss  | 0.00338     |
|    std                   | 0.225       |
|    value_loss            | 0.948       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.48200476 |
| rollout/                 |             |
|    ep_len_mean           | 42.4        |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 12          |
|    time_elapsed          | 362         |
|    total_timesteps       | 2834432     |
| train/                   |             |
|    approx_kl             | 0.025842253 |
|    clip_fraction         | 0.225       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.92        |
|    cost_value_loss       | 3.75        |
|    cost_values           | 1.46        |
|    entropy               | 1.07        |
|    entropy_loss          | 1.07        |
|    explained_variance    | 0.965       |
|    lagrangian_multiplier | 0.00105     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.18        |
|    n_updates             | 13830       |
|    policy_gradient_loss  | 0.00501     |
|    std                   | 0.224       |
|    value_loss            | 1.3         |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.8949746  |
| rollout/                 |             |
|    ep_len_mean           | 41.7        |
|    ep_rew_mean           | -23         |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 13          |
|    time_elapsed          | 393         |
|    total_timesteps       | 2836480     |
| train/                   |             |
|    approx_kl             | 0.031908058 |
|    clip_fraction         | 0.225       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.98        |
|    cost_value_loss       | 3.92        |
|    cost_values           | 1.5         |
|    entropy               | 1.07        |
|    entropy_loss          | 1.07        |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0.00111     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.14        |
|    n_updates             | 13840       |
|    policy_gradient_loss  | 0.00963     |
|    std                   | 0.225       |
|    value_loss            | 1.02        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.4         |
| reward                   | -0.27558193 |
| rollout/                 |             |
|    ep_len_mean           | 43.2        |
|    ep_rew_mean           | -23.2       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 14          |
|    time_elapsed          | 422         |
|    total_timesteps       | 2838528     |
| train/                   |             |
|    approx_kl             | 0.01885112  |
|    clip_fraction         | 0.229       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.91        |
|    cost_value_loss       | 3.81        |
|    cost_values           | 1.49        |
|    entropy               | 1.06        |
|    entropy_loss          | 1.06        |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0.00109     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.12        |
|    n_updates             | 13850       |
|    policy_gradient_loss  | 0.00655     |
|    std                   | 0.226       |
|    value_loss            | 0.797       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.17638572 |
| rollout/                 |             |
|    ep_len_mean           | 43.3        |
|    ep_rew_mean           | -23         |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 15          |
|    time_elapsed          | 445         |
|    total_timesteps       | 2840576     |
| train/                   |             |
|    approx_kl             | 0.018790334 |
|    clip_fraction         | 0.245       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.93        |
|    cost_value_loss       | 4.06        |
|    cost_values           | 1.48        |
|    entropy               | 1.06        |
|    entropy_loss          | 1.06        |
|    explained_variance    | 0.954       |
|    lagrangian_multiplier | 0.000448    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.45        |
|    n_updates             | 13860       |
|    policy_gradient_loss  | 0.0103      |
|    std                   | 0.226       |
|    value_loss            | 1.52        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.12638588 |
| rollout/                 |             |
|    ep_len_mean           | 42.4        |
|    ep_rew_mean           | -22.6       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 16          |
|    time_elapsed          | 471         |
|    total_timesteps       | 2842624     |
| train/                   |             |
|    approx_kl             | 0.031213969 |
|    clip_fraction         | 0.223       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.04        |
|    cost_value_loss       | 4.04        |
|    cost_values           | 1.5         |
|    entropy               | 1.06        |
|    entropy_loss          | 1.06        |
|    explained_variance    | 0.973       |
|    lagrangian_multiplier | 0.000231    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.52        |
|    n_updates             | 13870       |
|    policy_gradient_loss  | 0.011       |
|    std                   | 0.227       |
|    value_loss            | 0.952       |
------------------------------------------
-----------------------------------------
| avg_speed                | 2          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 2          |
| reward                   | -0.6797877 |
| rollout/                 |            |
|    ep_len_mean           | 42.1       |
|    ep_rew_mean           | -22.7      |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 17         |
|    time_elapsed          | 507        |
|    total_timesteps       | 2844672    |
| train/                   |            |
|    approx_kl             | 0.02725885 |
|    clip_fraction         | 0.231      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.17       |
|    cost_value_loss       | 4.84       |
|    cost_values           | 1.5        |
|    entropy               | 1.06       |
|    entropy_loss          | 1.06       |
|    explained_variance    | 0.978      |
|    lagrangian_multiplier | 0.000229   |
|    learning_rate         | 0.0003     |
|    loss                  | 2.64       |
|    n_updates             | 13880      |
|    policy_gradient_loss  | 0.00765    |
|    std                   | 0.226      |
|    value_loss            | 0.827      |
-----------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.55220544 |
| rollout/                 |             |
|    ep_len_mean           | 41.3        |
|    ep_rew_mean           | -22.4       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 18          |
|    time_elapsed          | 545         |
|    total_timesteps       | 2846720     |
| train/                   |             |
|    approx_kl             | 0.03682793  |
|    clip_fraction         | 0.222       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.02        |
|    cost_value_loss       | 4.13        |
|    cost_values           | 1.48        |
|    entropy               | 1.06        |
|    entropy_loss          | 1.06        |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0.00117     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.14        |
|    n_updates             | 13890       |
|    policy_gradient_loss  | 0.0108      |
|    std                   | 0.226       |
|    value_loss            | 0.682       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.29787904 |
| rollout/                 |             |
|    ep_len_mean           | 41.1        |
|    ep_rew_mean           | -22.4       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 19          |
|    time_elapsed          | 576         |
|    total_timesteps       | 2848768     |
| train/                   |             |
|    approx_kl             | 0.028853133 |
|    clip_fraction         | 0.235       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.88        |
|    cost_value_loss       | 3.64        |
|    cost_values           | 1.43        |
|    entropy               | 1.07        |
|    entropy_loss          | 1.06        |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0.00128     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.97        |
|    n_updates             | 13900       |
|    policy_gradient_loss  | 0.0125      |
|    std                   | 0.226       |
|    value_loss            | 0.784       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.8         |
| reward                   | -0.8044772  |
| rollout/                 |             |
|    ep_len_mean           | 41          |
|    ep_rew_mean           | -22.7       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 20          |
|    time_elapsed          | 604         |
|    total_timesteps       | 2850816     |
| train/                   |             |
|    approx_kl             | 0.044497494 |
|    clip_fraction         | 0.179       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.01        |
|    cost_value_loss       | 4.32        |
|    cost_values           | 1.44        |
|    entropy               | 1.07        |
|    entropy_loss          | 1.07        |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0.000958    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.11        |
|    n_updates             | 13910       |
|    policy_gradient_loss  | 0.00956     |
|    std                   | 0.226       |
|    value_loss            | 0.503       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.59693265 |
| rollout/                 |             |
|    ep_len_mean           | 40.6        |
|    ep_rew_mean           | -22.3       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 21          |
|    time_elapsed          | 634         |
|    total_timesteps       | 2852864     |
| train/                   |             |
|    approx_kl             | 0.042493347 |
|    clip_fraction         | 0.22        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.1         |
|    cost_value_loss       | 4.53        |
|    cost_values           | 1.45        |
|    entropy               | 1.08        |
|    entropy_loss          | 1.07        |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0.00237     |
|    learning_rate         | 0.0003      |
|    loss                  | 2           |
|    n_updates             | 13920       |
|    policy_gradient_loss  | 0.0138      |
|    std                   | 0.225       |
|    value_loss            | 0.45        |
------------------------------------------
-----------------------------------------
| avg_speed                | 1.4        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 1.4        |
| reward                   | -0.7021983 |
| rollout/                 |            |
|    ep_len_mean           | 41.3       |
|    ep_rew_mean           | -22.7      |
| time/                    |            |
|    fps                   | 67         |
|    iterations            | 22         |
|    time_elapsed          | 665        |
|    total_timesteps       | 2854912    |
| train/                   |            |
|    approx_kl             | 0.03669613 |
|    clip_fraction         | 0.224      |
|    clip_range            | 0.2        |
|    cost_returns          | 2.88       |
|    cost_value_loss       | 3.77       |
|    cost_values           | 1.46       |
|    entropy               | 1.07       |
|    entropy_loss          | 1.07       |
|    explained_variance    | 0.986      |
|    lagrangian_multiplier | 0.0022     |
|    learning_rate         | 0.0003     |
|    loss                  | 1.93       |
|    n_updates             | 13930      |
|    policy_gradient_loss  | 0.0117     |
|    std                   | 0.226      |
|    value_loss            | 0.499      |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.37777042 |
| rollout/                 |             |
|    ep_len_mean           | 42.8        |
|    ep_rew_mean           | -23         |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 23          |
|    time_elapsed          | 693         |
|    total_timesteps       | 2856960     |
| train/                   |             |
|    approx_kl             | 0.021204565 |
|    clip_fraction         | 0.223       |
|    clip_range            | 0.2         |
|    cost_returns          | 3           |
|    cost_value_loss       | 4.39        |
|    cost_values           | 1.4         |
|    entropy               | 1.07        |
|    entropy_loss          | 1.07        |
|    explained_variance    | 0.985       |
|    lagrangian_multiplier | 0.00241     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.94        |
|    n_updates             | 13940       |
|    policy_gradient_loss  | 0.00918     |
|    std                   | 0.226       |
|    value_loss            | 0.573       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.81060624 |
| rollout/                 |             |
|    ep_len_mean           | 42.3        |
|    ep_rew_mean           | -22.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 24          |
|    time_elapsed          | 721         |
|    total_timesteps       | 2859008     |
| train/                   |             |
|    approx_kl             | 0.024563704 |
|    clip_fraction         | 0.243       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.11        |
|    cost_value_loss       | 4.87        |
|    cost_values           | 1.42        |
|    entropy               | 1.07        |
|    entropy_loss          | 1.07        |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0.00119     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.38        |
|    n_updates             | 13950       |
|    policy_gradient_loss  | 0.00698     |
|    std                   | 0.227       |
|    value_loss            | 0.665       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.2         |
| reward                   | -0.19482064 |
| rollout/                 |             |
|    ep_len_mean           | 42.1        |
|    ep_rew_mean           | -22.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 25          |
|    time_elapsed          | 749         |
|    total_timesteps       | 2861056     |
| train/                   |             |
|    approx_kl             | 0.01728024  |
|    clip_fraction         | 0.227       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.1         |
|    cost_value_loss       | 4.62        |
|    cost_values           | 1.45        |
|    entropy               | 1.07        |
|    entropy_loss          | 1.07        |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0.00205     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.04        |
|    n_updates             | 13960       |
|    policy_gradient_loss  | 0.00996     |
|    std                   | 0.227       |
|    value_loss            | 0.465       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.8         |
| reward                   | -0.6951141  |
| rollout/                 |             |
|    ep_len_mean           | 42.7        |
|    ep_rew_mean           | -23.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 26          |
|    time_elapsed          | 779         |
|    total_timesteps       | 2863104     |
| train/                   |             |
|    approx_kl             | 0.017749876 |
|    clip_fraction         | 0.174       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.05        |
|    cost_value_loss       | 4.57        |
|    cost_values           | 1.42        |
|    entropy               | 1.07        |
|    entropy_loss          | 1.07        |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0.00357     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.9         |
|    n_updates             | 13970       |
|    policy_gradient_loss  | 0.00728     |
|    std                   | 0.227       |
|    value_loss            | 0.482       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.8         |
| cost                     | 0           |
| is_success               | 1           |
| max_speed                | 6.8         |
| reward                   | -0.08238052 |
| rollout/                 |             |
|    ep_len_mean           | 43.5        |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 27          |
|    time_elapsed          | 805         |
|    total_timesteps       | 2865152     |
| train/                   |             |
|    approx_kl             | 0.034081258 |
|    clip_fraction         | 0.238       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.96        |
|    cost_value_loss       | 4.36        |
|    cost_values           | 1.38        |
|    entropy               | 1.07        |
|    entropy_loss          | 1.07        |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0.000282    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.47        |
|    n_updates             | 13980       |
|    policy_gradient_loss  | 0.0151      |
|    std                   | 0.227       |
|    value_loss            | 0.516       |
------------------------------------------
-----------------------------------------
| avg_speed                | 5          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 5          |
| reward                   | -0.5855367 |
| rollout/                 |            |
|    ep_len_mean           | 44.3       |
|    ep_rew_mean           | -22.9      |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 28         |
|    time_elapsed          | 833        |
|    total_timesteps       | 2867200    |
| train/                   |            |
|    approx_kl             | 0.01685753 |
|    clip_fraction         | 0.215      |
|    clip_range            | 0.2        |
|    cost_returns          | 2.99       |
|    cost_value_loss       | 4.34       |
|    cost_values           | 1.39       |
|    entropy               | 1.07       |
|    entropy_loss          | 1.07       |
|    explained_variance    | 0.98       |
|    lagrangian_multiplier | 0.000295   |
|    learning_rate         | 0.0003     |
|    loss                  | 2.44       |
|    n_updates             | 13990      |
|    policy_gradient_loss  | 0.00396    |
|    std                   | 0.227      |
|    value_loss            | 0.721      |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.657517   |
| rollout/                 |             |
|    ep_len_mean           | 44.4        |
|    ep_rew_mean           | -22.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 29          |
|    time_elapsed          | 861         |
|    total_timesteps       | 2869248     |
| train/                   |             |
|    approx_kl             | 0.027169606 |
|    clip_fraction         | 0.195       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.25        |
|    cost_value_loss       | 5.28        |
|    cost_values           | 1.47        |
|    entropy               | 1.07        |
|    entropy_loss          | 1.07        |
|    explained_variance    | 0.971       |
|    lagrangian_multiplier | 0.00139     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.48        |
|    n_updates             | 14000       |
|    policy_gradient_loss  | 0.00912     |
|    std                   | 0.228       |
|    value_loss            | 0.999       |
------------------------------------------
-----------------------------------------
| avg_speed                | 5.4        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 5.4        |
| reward                   | -0.4353918 |
| rollout/                 |            |
|    ep_len_mean           | 44.4       |
|    ep_rew_mean           | -23.1      |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 30         |
|    time_elapsed          | 892        |
|    total_timesteps       | 2871296    |
| train/                   |            |
|    approx_kl             | 0.03386421 |
|    clip_fraction         | 0.24       |
|    clip_range            | 0.2        |
|    cost_returns          | 3.15       |
|    cost_value_loss       | 5          |
|    cost_values           | 1.5        |
|    entropy               | 1.06       |
|    entropy_loss          | 1.06       |
|    explained_variance    | 0.961      |
|    lagrangian_multiplier | 0.00186    |
|    learning_rate         | 0.0003     |
|    loss                  | 2.38       |
|    n_updates             | 14010      |
|    policy_gradient_loss  | 0.012      |
|    std                   | 0.229      |
|    value_loss            | 1.14       |
-----------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.7674762  |
| rollout/                 |             |
|    ep_len_mean           | 42.3        |
|    ep_rew_mean           | -22.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 31          |
|    time_elapsed          | 926         |
|    total_timesteps       | 2873344     |
| train/                   |             |
|    approx_kl             | 0.015417276 |
|    clip_fraction         | 0.199       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.04        |
|    cost_value_loss       | 4.18        |
|    cost_values           | 1.47        |
|    entropy               | 1.06        |
|    entropy_loss          | 1.06        |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0.000154    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.37        |
|    n_updates             | 14020       |
|    policy_gradient_loss  | 0.0157      |
|    std                   | 0.228       |
|    value_loss            | 0.689       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.7829959  |
| rollout/                 |             |
|    ep_len_mean           | 42.1        |
|    ep_rew_mean           | -23         |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 32          |
|    time_elapsed          | 958         |
|    total_timesteps       | 2875392     |
| train/                   |             |
|    approx_kl             | 0.014682768 |
|    clip_fraction         | 0.214       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.96        |
|    cost_value_loss       | 4.28        |
|    cost_values           | 1.42        |
|    entropy               | 1.06        |
|    entropy_loss          | 1.06        |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0.00186     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.93        |
|    n_updates             | 14030       |
|    policy_gradient_loss  | 0.0128      |
|    std                   | 0.229       |
|    value_loss            | 0.526       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3295617  |
| rollout/                 |             |
|    ep_len_mean           | 41.6        |
|    ep_rew_mean           | -23.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 33          |
|    time_elapsed          | 990         |
|    total_timesteps       | 2877440     |
| train/                   |             |
|    approx_kl             | 0.038912974 |
|    clip_fraction         | 0.231       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.11        |
|    cost_value_loss       | 4.77        |
|    cost_values           | 1.43        |
|    entropy               | 1.05        |
|    entropy_loss          | 1.06        |
|    explained_variance    | 0.985       |
|    lagrangian_multiplier | 8.89e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.57        |
|    n_updates             | 14040       |
|    policy_gradient_loss  | 0.00951     |
|    std                   | 0.23        |
|    value_loss            | 0.596       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.4         |
| reward                   | -0.7646067  |
| rollout/                 |             |
|    ep_len_mean           | 41.3        |
|    ep_rew_mean           | -22.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 34          |
|    time_elapsed          | 1018        |
|    total_timesteps       | 2879488     |
| train/                   |             |
|    approx_kl             | 0.037892584 |
|    clip_fraction         | 0.2         |
|    clip_range            | 0.2         |
|    cost_returns          | 2.9         |
|    cost_value_loss       | 4.13        |
|    cost_values           | 1.39        |
|    entropy               | 1.04        |
|    entropy_loss          | 1.05        |
|    explained_variance    | 0.981       |
|    lagrangian_multiplier | 0.00102     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.98        |
|    n_updates             | 14050       |
|    policy_gradient_loss  | 0.00401     |
|    std                   | 0.231       |
|    value_loss            | 0.677       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.2         |
| reward                   | -0.72720015 |
| rollout/                 |             |
|    ep_len_mean           | 40.8        |
|    ep_rew_mean           | -22.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 35          |
|    time_elapsed          | 1046        |
|    total_timesteps       | 2881536     |
| train/                   |             |
|    approx_kl             | 0.030245857 |
|    clip_fraction         | 0.228       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.9         |
|    cost_value_loss       | 4.09        |
|    cost_values           | 1.4         |
|    entropy               | 1.04        |
|    entropy_loss          | 1.04        |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0.000756    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.17        |
|    n_updates             | 14060       |
|    policy_gradient_loss  | 0.0177      |
|    std                   | 0.231       |
|    value_loss            | 0.619       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.7867229  |
| rollout/                 |             |
|    ep_len_mean           | 42.1        |
|    ep_rew_mean           | -22.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 36          |
|    time_elapsed          | 1069        |
|    total_timesteps       | 2883584     |
| train/                   |             |
|    approx_kl             | 0.025032818 |
|    clip_fraction         | 0.223       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.96        |
|    cost_value_loss       | 4.15        |
|    cost_values           | 1.39        |
|    entropy               | 1.04        |
|    entropy_loss          | 1.04        |
|    explained_variance    | 0.982       |
|    lagrangian_multiplier | 0.000583    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.12        |
|    n_updates             | 14070       |
|    policy_gradient_loss  | 0.0118      |
|    std                   | 0.232       |
|    value_loss            | 0.693       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.6         |
| reward                   | -0.44621044 |
| rollout/                 |             |
|    ep_len_mean           | 42.8        |
|    ep_rew_mean           | -22.8       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 37          |
|    time_elapsed          | 1093        |
|    total_timesteps       | 2885632     |
| train/                   |             |
|    approx_kl             | 0.05265732  |
|    clip_fraction         | 0.204       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.07        |
|    cost_value_loss       | 4.68        |
|    cost_values           | 1.41        |
|    entropy               | 1.04        |
|    entropy_loss          | 1.04        |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0.000697    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.35        |
|    n_updates             | 14080       |
|    policy_gradient_loss  | 0.00451     |
|    std                   | 0.231       |
|    value_loss            | 0.851       |
------------------------------------------
-----------------------------------------
| avg_speed                | 3.4        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 3.4        |
| reward                   | -0.8610154 |
| rollout/                 |            |
|    ep_len_mean           | 41.4       |
|    ep_rew_mean           | -22.9      |
| time/                    |            |
|    fps                   | 69         |
|    iterations            | 38         |
|    time_elapsed          | 1117       |
|    total_timesteps       | 2887680    |
| train/                   |            |
|    approx_kl             | 0.0564754  |
|    clip_fraction         | 0.189      |
|    clip_range            | 0.2        |
|    cost_returns          | 2.98       |
|    cost_value_loss       | 4.31       |
|    cost_values           | 1.47       |
|    entropy               | 1.04       |
|    entropy_loss          | 1.04       |
|    explained_variance    | 0.979      |
|    lagrangian_multiplier | 0.00172    |
|    learning_rate         | 0.0003     |
|    loss                  | 2.15       |
|    n_updates             | 14090      |
|    policy_gradient_loss  | 0.00518    |
|    std                   | 0.231      |
|    value_loss            | 0.817      |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.33523357 |
| rollout/                 |             |
|    ep_len_mean           | 41.8        |
|    ep_rew_mean           | -23.4       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 39          |
|    time_elapsed          | 1141        |
|    total_timesteps       | 2889728     |
| train/                   |             |
|    approx_kl             | 0.024618436 |
|    clip_fraction         | 0.204       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.07        |
|    cost_value_loss       | 4.42        |
|    cost_values           | 1.46        |
|    entropy               | 1.04        |
|    entropy_loss          | 1.04        |
|    explained_variance    | 0.984       |
|    lagrangian_multiplier | 0.0017      |
|    learning_rate         | 0.0003      |
|    loss                  | 2.23        |
|    n_updates             | 14100       |
|    policy_gradient_loss  | 0.0108      |
|    std                   | 0.23        |
|    value_loss            | 0.613       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.8         |
| reward                   | -0.32568544 |
| rollout/                 |             |
|    ep_len_mean           | 42.6        |
|    ep_rew_mean           | -23.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 40          |
|    time_elapsed          | 1166        |
|    total_timesteps       | 2891776     |
| train/                   |             |
|    approx_kl             | 0.030016687 |
|    clip_fraction         | 0.247       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.01        |
|    cost_value_loss       | 4.21        |
|    cost_values           | 1.43        |
|    entropy               | 1.05        |
|    entropy_loss          | 1.05        |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0.000319    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.4         |
|    n_updates             | 14110       |
|    policy_gradient_loss  | 0.0076      |
|    std                   | 0.229       |
|    value_loss            | 0.892       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.2         |
| reward                   | -0.90037394 |
| rollout/                 |             |
|    ep_len_mean           | 42.7        |
|    ep_rew_mean           | -23.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 41          |
|    time_elapsed          | 1191        |
|    total_timesteps       | 2893824     |
| train/                   |             |
|    approx_kl             | 0.05194414  |
|    clip_fraction         | 0.241       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.22        |
|    cost_value_loss       | 5.27        |
|    cost_values           | 1.43        |
|    entropy               | 1.05        |
|    entropy_loss          | 1.05        |
|    explained_variance    | 0.977       |
|    lagrangian_multiplier | 0.00107     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.46        |
|    n_updates             | 14120       |
|    policy_gradient_loss  | 0.018       |
|    std                   | 0.229       |
|    value_loss            | 0.829       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.7310925  |
| rollout/                 |             |
|    ep_len_mean           | 43.6        |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 42          |
|    time_elapsed          | 1216        |
|    total_timesteps       | 2895872     |
| train/                   |             |
|    approx_kl             | 0.022541663 |
|    clip_fraction         | 0.205       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.04        |
|    cost_value_loss       | 4.38        |
|    cost_values           | 1.44        |
|    entropy               | 1.05        |
|    entropy_loss          | 1.05        |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0.00251     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.99        |
|    n_updates             | 14130       |
|    policy_gradient_loss  | 0.0136      |
|    std                   | 0.228       |
|    value_loss            | 0.8         |
------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.4630939  |
| rollout/                 |             |
|    ep_len_mean           | 42.9        |
|    ep_rew_mean           | -22.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 43          |
|    time_elapsed          | 1241        |
|    total_timesteps       | 2897920     |
| train/                   |             |
|    approx_kl             | 0.022238383 |
|    clip_fraction         | 0.216       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.97        |
|    cost_value_loss       | 4.48        |
|    cost_values           | 1.46        |
|    entropy               | 1.06        |
|    entropy_loss          | 1.06        |
|    explained_variance    | 0.962       |
|    lagrangian_multiplier | 0.00105     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.29        |
|    n_updates             | 14140       |
|    policy_gradient_loss  | 0.01        |
|    std                   | 0.227       |
|    value_loss            | 1.21        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.2         |
| reward                   | -0.8548258  |
| rollout/                 |             |
|    ep_len_mean           | 42          |
|    ep_rew_mean           | -22.5       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 44          |
|    time_elapsed          | 1266        |
|    total_timesteps       | 2899968     |
| train/                   |             |
|    approx_kl             | 0.018432483 |
|    clip_fraction         | 0.185       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.02        |
|    cost_value_loss       | 4.44        |
|    cost_values           | 1.47        |
|    entropy               | 1.06        |
|    entropy_loss          | 1.06        |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0.0012      |
|    learning_rate         | 0.0003      |
|    loss                  | 2.31        |
|    n_updates             | 14150       |
|    policy_gradient_loss  | 0.00959     |
|    std                   | 0.227       |
|    value_loss            | 0.78        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.55508655 |
| rollout/                 |             |
|    ep_len_mean           | 41.2        |
|    ep_rew_mean           | -22.6       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 45          |
|    time_elapsed          | 1292        |
|    total_timesteps       | 2902016     |
| train/                   |             |
|    approx_kl             | 0.020527892 |
|    clip_fraction         | 0.213       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.12        |
|    cost_value_loss       | 4.7         |
|    cost_values           | 1.45        |
|    entropy               | 1.06        |
|    entropy_loss          | 1.06        |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 0.00027     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.65        |
|    n_updates             | 14160       |
|    policy_gradient_loss  | 0.0109      |
|    std                   | 0.227       |
|    value_loss            | 0.816       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.66406286 |
| rollout/                 |             |
|    ep_len_mean           | 41.6        |
|    ep_rew_mean           | -22.4       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 46          |
|    time_elapsed          | 1320        |
|    total_timesteps       | 2904064     |
| train/                   |             |
|    approx_kl             | 0.04150445  |
|    clip_fraction         | 0.227       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.81        |
|    cost_value_loss       | 3.63        |
|    cost_values           | 1.43        |
|    entropy               | 1.07        |
|    entropy_loss          | 1.07        |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0.00016     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.98        |
|    n_updates             | 14170       |
|    policy_gradient_loss  | 0.00719     |
|    std                   | 0.225       |
|    value_loss            | 0.672       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.4         |
| reward                   | -0.31928152 |
| rollout/                 |             |
|    ep_len_mean           | 41.3        |
|    ep_rew_mean           | -21.9       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 47          |
|    time_elapsed          | 1348        |
|    total_timesteps       | 2906112     |
| train/                   |             |
|    approx_kl             | 0.022931663 |
|    clip_fraction         | 0.194       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.08        |
|    cost_value_loss       | 4.56        |
|    cost_values           | 1.43        |
|    entropy               | 1.08        |
|    entropy_loss          | 1.07        |
|    explained_variance    | 0.973       |
|    lagrangian_multiplier | 0.000863    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.43        |
|    n_updates             | 14180       |
|    policy_gradient_loss  | 0.00892     |
|    std                   | 0.224       |
|    value_loss            | 0.944       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.2         |
| reward                   | -0.54652333 |
| rollout/                 |             |
|    ep_len_mean           | 39.9        |
|    ep_rew_mean           | -21.8       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 48          |
|    time_elapsed          | 1376        |
|    total_timesteps       | 2908160     |
| train/                   |             |
|    approx_kl             | 0.03034255  |
|    clip_fraction         | 0.199       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.1         |
|    cost_value_loss       | 4.47        |
|    cost_values           | 1.47        |
|    entropy               | 1.08        |
|    entropy_loss          | 1.08        |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0.000756    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.34        |
|    n_updates             | 14190       |
|    policy_gradient_loss  | 0.00496     |
|    std                   | 0.224       |
|    value_loss            | 0.592       |
------------------------------------------
-----------------------------------------
| avg_speed                | 4.2        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 4.2        |
| reward                   | -0.4742535 |
| rollout/                 |            |
|    ep_len_mean           | 39.7       |
|    ep_rew_mean           | -21.6      |
| time/                    |            |
|    fps                   | 71         |
|    iterations            | 49         |
|    time_elapsed          | 1401       |
|    total_timesteps       | 2910208    |
| train/                   |            |
|    approx_kl             | 0.09781904 |
|    clip_fraction         | 0.256      |
|    clip_range            | 0.2        |
|    cost_returns          | 2.93       |
|    cost_value_loss       | 3.91       |
|    cost_values           | 1.45       |
|    entropy               | 1.07       |
|    entropy_loss          | 1.07       |
|    explained_variance    | 0.987      |
|    lagrangian_multiplier | 0.00159    |
|    learning_rate         | 0.0003     |
|    loss                  | 1.93       |
|    n_updates             | 14200      |
|    policy_gradient_loss  | 0.0196     |
|    std                   | 0.225      |
|    value_loss            | 0.504      |
-----------------------------------------
Directory already exists: tests/PPOL_New/models/ent-coefficient-ppol/1vjpjg9h
------------------------------------
| avg_speed          | 8           |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8           |
| reward             | -0.13331899 |
| rollout/           |             |
|    ep_len_mean     | 41.7        |
|    ep_rew_mean     | -22.5       |
| time/              |             |
|    fps             | 71          |
|    iterations      | 1           |
|    time_elapsed    | 28          |
|    total_timesteps | 2912256     |
------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.7153874  |
| rollout/                 |             |
|    ep_len_mean           | 42.4        |
|    ep_rew_mean           | -22.8       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 2           |
|    time_elapsed          | 61          |
|    total_timesteps       | 2914304     |
| train/                   |             |
|    approx_kl             | 0.029858306 |
|    clip_fraction         | 0.216       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.12        |
|    cost_value_loss       | 4.87        |
|    cost_values           | 1.37        |
|    entropy               | 1.07        |
|    entropy_loss          | 1.07        |
|    explained_variance    | 0.968       |
|    lagrangian_multiplier | 0.00132     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.39        |
|    n_updates             | 14220       |
|    policy_gradient_loss  | 0.0178      |
|    std                   | 0.226       |
|    value_loss            | 1.1         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.7434198  |
| rollout/                 |             |
|    ep_len_mean           | 39.7        |
|    ep_rew_mean           | -21.7       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 3           |
|    time_elapsed          | 93          |
|    total_timesteps       | 2916352     |
| train/                   |             |
|    approx_kl             | 0.025645822 |
|    clip_fraction         | 0.204       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.84        |
|    cost_value_loss       | 3.65        |
|    cost_values           | 1.41        |
|    entropy               | 1.07        |
|    entropy_loss          | 1.07        |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0.000979    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.03        |
|    n_updates             | 14230       |
|    policy_gradient_loss  | 0.00784     |
|    std                   | 0.225       |
|    value_loss            | 0.927       |
------------------------------------------
------------------------------------------
| avg_speed                | 5           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5           |
| reward                   | -0.5586402  |
| rollout/                 |             |
|    ep_len_mean           | 39.9        |
|    ep_rew_mean           | -22.1       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 4           |
|    time_elapsed          | 128         |
|    total_timesteps       | 2918400     |
| train/                   |             |
|    approx_kl             | 0.032318354 |
|    clip_fraction         | 0.203       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.07        |
|    cost_value_loss       | 4.28        |
|    cost_values           | 1.45        |
|    entropy               | 1.06        |
|    entropy_loss          | 1.06        |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0.000467    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.33        |
|    n_updates             | 14240       |
|    policy_gradient_loss  | 0.0118      |
|    std                   | 0.225       |
|    value_loss            | 0.783       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.4         |
| reward                   | -0.58014977 |
| rollout/                 |             |
|    ep_len_mean           | 40.4        |
|    ep_rew_mean           | -22.7       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 5           |
|    time_elapsed          | 162         |
|    total_timesteps       | 2920448     |
| train/                   |             |
|    approx_kl             | 0.04870347  |
|    clip_fraction         | 0.179       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.9         |
|    cost_value_loss       | 3.74        |
|    cost_values           | 1.47        |
|    entropy               | 1.07        |
|    entropy_loss          | 1.06        |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0.000213    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.15        |
|    n_updates             | 14250       |
|    policy_gradient_loss  | 0.0122      |
|    std                   | 0.225       |
|    value_loss            | 0.61        |
------------------------------------------
-----------------------------------------
| avg_speed                | 3.8        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 3.8        |
| reward                   | -0.8410839 |
| rollout/                 |            |
|    ep_len_mean           | 40.6       |
|    ep_rew_mean           | -22.8      |
| time/                    |            |
|    fps                   | 62         |
|    iterations            | 6          |
|    time_elapsed          | 197        |
|    total_timesteps       | 2922496    |
| train/                   |            |
|    approx_kl             | 0.03582728 |
|    clip_fraction         | 0.197      |
|    clip_range            | 0.2        |
|    cost_returns          | 2.97       |
|    cost_value_loss       | 4.06       |
|    cost_values           | 1.45       |
|    entropy               | 1.08       |
|    entropy_loss          | 1.07       |
|    explained_variance    | 0.99       |
|    lagrangian_multiplier | 0.00167    |
|    learning_rate         | 0.0003     |
|    loss                  | 1.91       |
|    n_updates             | 14260      |
|    policy_gradient_loss  | 0.0134     |
|    std                   | 0.224      |
|    value_loss            | 0.384      |
-----------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.68272346 |
| rollout/                 |             |
|    ep_len_mean           | 41.1        |
|    ep_rew_mean           | -23.1       |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 7           |
|    time_elapsed          | 232         |
|    total_timesteps       | 2924544     |
| train/                   |             |
|    approx_kl             | 0.027900098 |
|    clip_fraction         | 0.259       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.95        |
|    cost_value_loss       | 4.21        |
|    cost_values           | 1.41        |
|    entropy               | 1.07        |
|    entropy_loss          | 1.08        |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0.000601    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.06        |
|    n_updates             | 14270       |
|    policy_gradient_loss  | 0.0108      |
|    std                   | 0.225       |
|    value_loss            | 0.546       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.8833734  |
| rollout/                 |             |
|    ep_len_mean           | 41          |
|    ep_rew_mean           | -22.9       |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 8           |
|    time_elapsed          | 266         |
|    total_timesteps       | 2926592     |
| train/                   |             |
|    approx_kl             | 0.019406281 |
|    clip_fraction         | 0.222       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.95        |
|    cost_value_loss       | 4.14        |
|    cost_values           | 1.41        |
|    entropy               | 1.08        |
|    entropy_loss          | 1.07        |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 8.85e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.32        |
|    n_updates             | 14280       |
|    policy_gradient_loss  | 0.00838     |
|    std                   | 0.224       |
|    value_loss            | 0.55        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 1            |
| max_speed                | 8            |
| reward                   | -0.045845687 |
| rollout/                 |              |
|    ep_len_mean           | 41.4         |
|    ep_rew_mean           | -22.6        |
| time/                    |              |
|    fps                   | 61           |
|    iterations            | 9            |
|    time_elapsed          | 301          |
|    total_timesteps       | 2928640      |
| train/                   |              |
|    approx_kl             | 0.014802855  |
|    clip_fraction         | 0.16         |
|    clip_range            | 0.2          |
|    cost_returns          | 2.92         |
|    cost_value_loss       | 3.93         |
|    cost_values           | 1.42         |
|    entropy               | 1.08         |
|    entropy_loss          | 1.08         |
|    explained_variance    | 0.979        |
|    lagrangian_multiplier | 0.000464     |
|    learning_rate         | 0.0003       |
|    loss                  | 2.05         |
|    n_updates             | 14290        |
|    policy_gradient_loss  | 0.00258      |
|    std                   | 0.223        |
|    value_loss            | 0.714        |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.7892145  |
| rollout/                 |             |
|    ep_len_mean           | 43.3        |
|    ep_rew_mean           | -23.5       |
| time/                    |             |
|    fps                   | 61          |
|    iterations            | 10          |
|    time_elapsed          | 334         |
|    total_timesteps       | 2930688     |
| train/                   |             |
|    approx_kl             | 0.050850537 |
|    clip_fraction         | 0.229       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.08        |
|    cost_value_loss       | 4.33        |
|    cost_values           | 1.45        |
|    entropy               | 1.08        |
|    entropy_loss          | 1.08        |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0.00148     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.32        |
|    n_updates             | 14300       |
|    policy_gradient_loss  | 0.0099      |
|    std                   | 0.224       |
|    value_loss            | 0.795       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.5669043  |
| rollout/                 |             |
|    ep_len_mean           | 42          |
|    ep_rew_mean           | -22.6       |
| time/                    |             |
|    fps                   | 62          |
|    iterations            | 11          |
|    time_elapsed          | 357         |
|    total_timesteps       | 2932736     |
| train/                   |             |
|    approx_kl             | 0.027346548 |
|    clip_fraction         | 0.204       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.12        |
|    cost_value_loss       | 4.82        |
|    cost_values           | 1.43        |
|    entropy               | 1.08        |
|    entropy_loss          | 1.08        |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0.00132     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.33        |
|    n_updates             | 14310       |
|    policy_gradient_loss  | 0.00742     |
|    std                   | 0.223       |
|    value_loss            | 0.862       |
------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.5970982  |
| rollout/                 |             |
|    ep_len_mean           | 40.7        |
|    ep_rew_mean           | -22.2       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 12          |
|    time_elapsed          | 385         |
|    total_timesteps       | 2934784     |
| train/                   |             |
|    approx_kl             | 0.033952586 |
|    clip_fraction         | 0.202       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.89        |
|    cost_value_loss       | 3.73        |
|    cost_values           | 1.45        |
|    entropy               | 1.08        |
|    entropy_loss          | 1.08        |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0.000705    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.04        |
|    n_updates             | 14320       |
|    policy_gradient_loss  | 0.0145      |
|    std                   | 0.223       |
|    value_loss            | 0.716       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.81142163 |
| rollout/                 |             |
|    ep_len_mean           | 41.4        |
|    ep_rew_mean           | -22.5       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 13          |
|    time_elapsed          | 415         |
|    total_timesteps       | 2936832     |
| train/                   |             |
|    approx_kl             | 0.04909089  |
|    clip_fraction         | 0.222       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.86        |
|    cost_value_loss       | 3.71        |
|    cost_values           | 1.43        |
|    entropy               | 1.08        |
|    entropy_loss          | 1.08        |
|    explained_variance    | 0.984       |
|    lagrangian_multiplier | 0.000497    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.06        |
|    n_updates             | 14330       |
|    policy_gradient_loss  | 0.0113      |
|    std                   | 0.224       |
|    value_loss            | 0.623       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.6         |
| reward                   | -0.79250836 |
| rollout/                 |             |
|    ep_len_mean           | 41.8        |
|    ep_rew_mean           | -23         |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 14          |
|    time_elapsed          | 449         |
|    total_timesteps       | 2938880     |
| train/                   |             |
|    approx_kl             | 0.021611655 |
|    clip_fraction         | 0.228       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.89        |
|    cost_value_loss       | 3.98        |
|    cost_values           | 1.41        |
|    entropy               | 1.08        |
|    entropy_loss          | 1.08        |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0.00141     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.94        |
|    n_updates             | 14340       |
|    policy_gradient_loss  | 0.00832     |
|    std                   | 0.224       |
|    value_loss            | 0.807       |
------------------------------------------
------------------------------------------
| avg_speed                | 5           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5           |
| reward                   | -0.36382645 |
| rollout/                 |             |
|    ep_len_mean           | 41.2        |
|    ep_rew_mean           | -23.3       |
| time/                    |             |
|    fps                   | 63          |
|    iterations            | 15          |
|    time_elapsed          | 480         |
|    total_timesteps       | 2940928     |
| train/                   |             |
|    approx_kl             | 0.029245194 |
|    clip_fraction         | 0.189       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.89        |
|    cost_value_loss       | 4.01        |
|    cost_values           | 1.36        |
|    entropy               | 1.08        |
|    entropy_loss          | 1.08        |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0.0013      |
|    learning_rate         | 0.0003      |
|    loss                  | 2.05        |
|    n_updates             | 14350       |
|    policy_gradient_loss  | 0.00403     |
|    std                   | 0.223       |
|    value_loss            | 0.814       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.6         |
| reward                   | -0.30723712 |
| rollout/                 |             |
|    ep_len_mean           | 40          |
|    ep_rew_mean           | -22.5       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 16          |
|    time_elapsed          | 510         |
|    total_timesteps       | 2942976     |
| train/                   |             |
|    approx_kl             | 0.039122216 |
|    clip_fraction         | 0.192       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.91        |
|    cost_value_loss       | 4.12        |
|    cost_values           | 1.38        |
|    entropy               | 1.09        |
|    entropy_loss          | 1.08        |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.44        |
|    n_updates             | 14360       |
|    policy_gradient_loss  | 0.0133      |
|    std                   | 0.222       |
|    value_loss            | 0.549       |
------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.80032885 |
| rollout/                 |             |
|    ep_len_mean           | 40          |
|    ep_rew_mean           | -22         |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 17          |
|    time_elapsed          | 534         |
|    total_timesteps       | 2945024     |
| train/                   |             |
|    approx_kl             | 0.034323186 |
|    clip_fraction         | 0.229       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.85        |
|    cost_value_loss       | 3.73        |
|    cost_values           | 1.39        |
|    entropy               | 1.08        |
|    entropy_loss          | 1.08        |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0.0011      |
|    learning_rate         | 0.0003      |
|    loss                  | 1.9         |
|    n_updates             | 14370       |
|    policy_gradient_loss  | 0.0105      |
|    std                   | 0.222       |
|    value_loss            | 0.476       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.6760788  |
| rollout/                 |             |
|    ep_len_mean           | 40.8        |
|    ep_rew_mean           | -22.4       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 18          |
|    time_elapsed          | 558         |
|    total_timesteps       | 2947072     |
| train/                   |             |
|    approx_kl             | 0.028202089 |
|    clip_fraction         | 0.2         |
|    clip_range            | 0.2         |
|    cost_returns          | 2.88        |
|    cost_value_loss       | 3.64        |
|    cost_values           | 1.43        |
|    entropy               | 1.07        |
|    entropy_loss          | 1.08        |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0.00198     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.83        |
|    n_updates             | 14380       |
|    policy_gradient_loss  | 0.00544     |
|    std                   | 0.223       |
|    value_loss            | 0.613       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.6         |
| reward                   | -0.26107213 |
| rollout/                 |             |
|    ep_len_mean           | 39.8        |
|    ep_rew_mean           | -22.4       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 19          |
|    time_elapsed          | 583         |
|    total_timesteps       | 2949120     |
| train/                   |             |
|    approx_kl             | 0.019227259 |
|    clip_fraction         | 0.18        |
|    clip_range            | 0.2         |
|    cost_returns          | 2.95        |
|    cost_value_loss       | 3.86        |
|    cost_values           | 1.44        |
|    entropy               | 1.08        |
|    entropy_loss          | 1.07        |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0.00108     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.87        |
|    n_updates             | 14390       |
|    policy_gradient_loss  | 0.00392     |
|    std                   | 0.223       |
|    value_loss            | 0.536       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.5886169  |
| rollout/                 |             |
|    ep_len_mean           | 39.9        |
|    ep_rew_mean           | -22.4       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 20          |
|    time_elapsed          | 616         |
|    total_timesteps       | 2951168     |
| train/                   |             |
|    approx_kl             | 0.038817402 |
|    clip_fraction         | 0.238       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.85        |
|    cost_value_loss       | 3.4         |
|    cost_values           | 1.44        |
|    entropy               | 1.08        |
|    entropy_loss          | 1.08        |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0.000166    |
|    learning_rate         | 0.0003      |
|    loss                  | 1.9         |
|    n_updates             | 14400       |
|    policy_gradient_loss  | 0.0105      |
|    std                   | 0.223       |
|    value_loss            | 0.357       |
------------------------------------------
-----------------------------------------
| avg_speed                | 5.2        |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 5.2        |
| reward                   | -0.5838999 |
| rollout/                 |            |
|    ep_len_mean           | 41.1       |
|    ep_rew_mean           | -22.3      |
| time/                    |            |
|    fps                   | 66         |
|    iterations            | 21         |
|    time_elapsed          | 645        |
|    total_timesteps       | 2953216    |
| train/                   |            |
|    approx_kl             | 0.03142436 |
|    clip_fraction         | 0.275      |
|    clip_range            | 0.2        |
|    cost_returns          | 2.96       |
|    cost_value_loss       | 3.86       |
|    cost_values           | 1.43       |
|    entropy               | 1.07       |
|    entropy_loss          | 1.07       |
|    explained_variance    | 0.986      |
|    lagrangian_multiplier | 0.000132   |
|    learning_rate         | 0.0003     |
|    loss                  | 2.1        |
|    n_updates             | 14410      |
|    policy_gradient_loss  | 0.0144     |
|    std                   | 0.223      |
|    value_loss            | 0.536      |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.6         |
| reward                   | -0.25579074 |
| rollout/                 |             |
|    ep_len_mean           | 41          |
|    ep_rew_mean           | -22.1       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 22          |
|    time_elapsed          | 676         |
|    total_timesteps       | 2955264     |
| train/                   |             |
|    approx_kl             | 0.043573055 |
|    clip_fraction         | 0.181       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.8         |
|    cost_value_loss       | 3.24        |
|    cost_values           | 1.47        |
|    entropy               | 1.06        |
|    entropy_loss          | 1.07        |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 0.000588    |
|    learning_rate         | 0.0003      |
|    loss                  | 1.98        |
|    n_updates             | 14420       |
|    policy_gradient_loss  | 0.00854     |
|    std                   | 0.224       |
|    value_loss            | 0.741       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.2095526  |
| rollout/                 |             |
|    ep_len_mean           | 40.8        |
|    ep_rew_mean           | -22.3       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 23          |
|    time_elapsed          | 708         |
|    total_timesteps       | 2957312     |
| train/                   |             |
|    approx_kl             | 0.044043913 |
|    clip_fraction         | 0.231       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.78        |
|    cost_value_loss       | 3.16        |
|    cost_values           | 1.44        |
|    entropy               | 1.05        |
|    entropy_loss          | 1.06        |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0.000274    |
|    learning_rate         | 0.0003      |
|    loss                  | 1.95        |
|    n_updates             | 14430       |
|    policy_gradient_loss  | 0.0131      |
|    std                   | 0.225       |
|    value_loss            | 0.566       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.7157713  |
| rollout/                 |             |
|    ep_len_mean           | 41.3        |
|    ep_rew_mean           | -22.2       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 24          |
|    time_elapsed          | 740         |
|    total_timesteps       | 2959360     |
| train/                   |             |
|    approx_kl             | 0.026531588 |
|    clip_fraction         | 0.201       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.82        |
|    cost_value_loss       | 3.54        |
|    cost_values           | 1.41        |
|    entropy               | 1.05        |
|    entropy_loss          | 1.05        |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0.000524    |
|    learning_rate         | 0.0003      |
|    loss                  | 1.9         |
|    n_updates             | 14440       |
|    policy_gradient_loss  | 0.00629     |
|    std                   | 0.225       |
|    value_loss            | 0.506       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.2         |
| reward                   | -0.68877053 |
| rollout/                 |             |
|    ep_len_mean           | 41.5        |
|    ep_rew_mean           | -22.3       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 25          |
|    time_elapsed          | 775         |
|    total_timesteps       | 2961408     |
| train/                   |             |
|    approx_kl             | 0.034502167 |
|    clip_fraction         | 0.178       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.03        |
|    cost_value_loss       | 4.2         |
|    cost_values           | 1.46        |
|    entropy               | 1.05        |
|    entropy_loss          | 1.05        |
|    explained_variance    | 0.974       |
|    lagrangian_multiplier | 0.00291     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.97        |
|    n_updates             | 14450       |
|    policy_gradient_loss  | 0.0116      |
|    std                   | 0.225       |
|    value_loss            | 0.881       |
------------------------------------------
------------------------------------------
| avg_speed                | 5.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.2         |
| reward                   | -0.20937718 |
| rollout/                 |             |
|    ep_len_mean           | 40.7        |
|    ep_rew_mean           | -22.5       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 26          |
|    time_elapsed          | 809         |
|    total_timesteps       | 2963456     |
| train/                   |             |
|    approx_kl             | 0.032569956 |
|    clip_fraction         | 0.22        |
|    clip_range            | 0.2         |
|    cost_returns          | 2.79        |
|    cost_value_loss       | 3.41        |
|    cost_values           | 1.43        |
|    entropy               | 1.05        |
|    entropy_loss          | 1.05        |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0.00105     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.85        |
|    n_updates             | 14460       |
|    policy_gradient_loss  | 0.0103      |
|    std                   | 0.226       |
|    value_loss            | 0.624       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.4         |
| reward                   | -0.33942735 |
| rollout/                 |             |
|    ep_len_mean           | 40.1        |
|    ep_rew_mean           | -21.9       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 27          |
|    time_elapsed          | 841         |
|    total_timesteps       | 2965504     |
| train/                   |             |
|    approx_kl             | 0.039218675 |
|    clip_fraction         | 0.226       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.9         |
|    cost_value_loss       | 3.75        |
|    cost_values           | 1.42        |
|    entropy               | 1.05        |
|    entropy_loss          | 1.05        |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.19        |
|    n_updates             | 14470       |
|    policy_gradient_loss  | 0.013       |
|    std                   | 0.225       |
|    value_loss            | 0.469       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.6         |
| reward                   | -0.3104134  |
| rollout/                 |             |
|    ep_len_mean           | 40.9        |
|    ep_rew_mean           | -22.1       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 28          |
|    time_elapsed          | 873         |
|    total_timesteps       | 2967552     |
| train/                   |             |
|    approx_kl             | 0.043389708 |
|    clip_fraction         | 0.188       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.91        |
|    cost_value_loss       | 3.68        |
|    cost_values           | 1.43        |
|    entropy               | 1.07        |
|    entropy_loss          | 1.06        |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0.000576    |
|    learning_rate         | 0.0003      |
|    loss                  | 1.89        |
|    n_updates             | 14480       |
|    policy_gradient_loss  | 0.00877     |
|    std                   | 0.223       |
|    value_loss            | 0.46        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.7334594  |
| rollout/                 |             |
|    ep_len_mean           | 40.4        |
|    ep_rew_mean           | -22         |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 29          |
|    time_elapsed          | 906         |
|    total_timesteps       | 2969600     |
| train/                   |             |
|    approx_kl             | 0.020149784 |
|    clip_fraction         | 0.212       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.92        |
|    cost_value_loss       | 3.97        |
|    cost_values           | 1.43        |
|    entropy               | 1.07        |
|    entropy_loss          | 1.07        |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0.000294    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.33        |
|    n_updates             | 14490       |
|    policy_gradient_loss  | 0.00992     |
|    std                   | 0.223       |
|    value_loss            | 0.791       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.88256377 |
| rollout/                 |             |
|    ep_len_mean           | 40.4        |
|    ep_rew_mean           | -22.1       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 30          |
|    time_elapsed          | 940         |
|    total_timesteps       | 2971648     |
| train/                   |             |
|    approx_kl             | 0.030573174 |
|    clip_fraction         | 0.235       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.74        |
|    cost_value_loss       | 3           |
|    cost_values           | 1.45        |
|    entropy               | 1.06        |
|    entropy_loss          | 1.07        |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0.000807    |
|    learning_rate         | 0.0003      |
|    loss                  | 1.64        |
|    n_updates             | 14500       |
|    policy_gradient_loss  | 0.0112      |
|    std                   | 0.223       |
|    value_loss            | 0.561       |
------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.3088537 |
| rollout/                 |            |
|    ep_len_mean           | 40.4       |
|    ep_rew_mean           | -22.6      |
| time/                    |            |
|    fps                   | 64         |
|    iterations            | 31         |
|    time_elapsed          | 977        |
|    total_timesteps       | 2973696    |
| train/                   |            |
|    approx_kl             | 0.01981607 |
|    clip_fraction         | 0.205      |
|    clip_range            | 0.2        |
|    cost_returns          | 2.87       |
|    cost_value_loss       | 3.67       |
|    cost_values           | 1.39       |
|    entropy               | 1.06       |
|    entropy_loss          | 1.06       |
|    explained_variance    | 0.983      |
|    lagrangian_multiplier | 0.000739   |
|    learning_rate         | 0.0003     |
|    loss                  | 1.97       |
|    n_updates             | 14510      |
|    policy_gradient_loss  | 0.0147     |
|    std                   | 0.224      |
|    value_loss            | 0.628      |
-----------------------------------------
------------------------------------------
| avg_speed                | 5.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.6         |
| reward                   | -0.34766752 |
| rollout/                 |             |
|    ep_len_mean           | 39.3        |
|    ep_rew_mean           | -22.3       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 32          |
|    time_elapsed          | 1013        |
|    total_timesteps       | 2975744     |
| train/                   |             |
|    approx_kl             | 0.02923147  |
|    clip_fraction         | 0.249       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.91        |
|    cost_value_loss       | 3.91        |
|    cost_values           | 1.39        |
|    entropy               | 1.05        |
|    entropy_loss          | 1.05        |
|    explained_variance    | 0.991       |
|    lagrangian_multiplier | 0.000944    |
|    learning_rate         | 0.0003      |
|    loss                  | 1.93        |
|    n_updates             | 14520       |
|    policy_gradient_loss  | 0.014       |
|    std                   | 0.224       |
|    value_loss            | 0.32        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.2         |
| reward                   | -0.35782877 |
| rollout/                 |             |
|    ep_len_mean           | 40.2        |
|    ep_rew_mean           | -22.4       |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 33          |
|    time_elapsed          | 1047        |
|    total_timesteps       | 2977792     |
| train/                   |             |
|    approx_kl             | 0.053894974 |
|    clip_fraction         | 0.244       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.79        |
|    cost_value_loss       | 3.49        |
|    cost_values           | 1.38        |
|    entropy               | 1.04        |
|    entropy_loss          | 1.05        |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0.000515    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.01        |
|    n_updates             | 14530       |
|    policy_gradient_loss  | 0.00947     |
|    std                   | 0.225       |
|    value_loss            | 0.443       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.73728377 |
| rollout/                 |             |
|    ep_len_mean           | 40.8        |
|    ep_rew_mean           | -22         |
| time/                    |             |
|    fps                   | 64          |
|    iterations            | 34          |
|    time_elapsed          | 1073        |
|    total_timesteps       | 2979840     |
| train/                   |             |
|    approx_kl             | 0.057577148 |
|    clip_fraction         | 0.26        |
|    clip_range            | 0.2         |
|    cost_returns          | 2.88        |
|    cost_value_loss       | 3.85        |
|    cost_values           | 1.37        |
|    entropy               | 1.04        |
|    entropy_loss          | 1.04        |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0.000271    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.31        |
|    n_updates             | 14540       |
|    policy_gradient_loss  | 0.00929     |
|    std                   | 0.225       |
|    value_loss            | 0.697       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.2         |
| reward                   | -0.6688121  |
| rollout/                 |             |
|    ep_len_mean           | 41.1        |
|    ep_rew_mean           | -22.2       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 35          |
|    time_elapsed          | 1097        |
|    total_timesteps       | 2981888     |
| train/                   |             |
|    approx_kl             | 0.027985789 |
|    clip_fraction         | 0.203       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.81        |
|    cost_value_loss       | 3.62        |
|    cost_values           | 1.38        |
|    entropy               | 1.04        |
|    entropy_loss          | 1.04        |
|    explained_variance    | 0.975       |
|    lagrangian_multiplier | 0.000577    |
|    learning_rate         | 0.0003      |
|    loss                  | 2           |
|    n_updates             | 14550       |
|    policy_gradient_loss  | 0.00915     |
|    std                   | 0.225       |
|    value_loss            | 0.778       |
------------------------------------------
------------------------------------------
| avg_speed                | 6.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.8         |
| reward                   | -0.29691866 |
| rollout/                 |             |
|    ep_len_mean           | 40.8        |
|    ep_rew_mean           | -22.2       |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 36          |
|    time_elapsed          | 1121        |
|    total_timesteps       | 2983936     |
| train/                   |             |
|    approx_kl             | 0.049966857 |
|    clip_fraction         | 0.219       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.73        |
|    cost_value_loss       | 3.39        |
|    cost_values           | 1.38        |
|    entropy               | 1.05        |
|    entropy_loss          | 1.05        |
|    explained_variance    | 0.984       |
|    lagrangian_multiplier | 6.56e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.05        |
|    n_updates             | 14560       |
|    policy_gradient_loss  | 0.00911     |
|    std                   | 0.225       |
|    value_loss            | 0.582       |
------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 1          |
| max_speed                | 8          |
| reward                   | -0.0820996 |
| rollout/                 |            |
|    ep_len_mean           | 40.1       |
|    ep_rew_mean           | -22        |
| time/                    |            |
|    fps                   | 66         |
|    iterations            | 37         |
|    time_elapsed          | 1146       |
|    total_timesteps       | 2985984    |
| train/                   |            |
|    approx_kl             | 0.02545925 |
|    clip_fraction         | 0.229      |
|    clip_range            | 0.2        |
|    cost_returns          | 2.93       |
|    cost_value_loss       | 3.95       |
|    cost_values           | 1.42       |
|    entropy               | 1.04       |
|    entropy_loss          | 1.05       |
|    explained_variance    | 0.98       |
|    lagrangian_multiplier | 0.000394   |
|    learning_rate         | 0.0003     |
|    loss                  | 2.04       |
|    n_updates             | 14570      |
|    policy_gradient_loss  | 0.00963    |
|    std                   | 0.225      |
|    value_loss            | 0.679      |
-----------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.5849028  |
| rollout/                 |             |
|    ep_len_mean           | 40.4        |
|    ep_rew_mean           | -22         |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 38          |
|    time_elapsed          | 1175        |
|    total_timesteps       | 2988032     |
| train/                   |             |
|    approx_kl             | 0.025423588 |
|    clip_fraction         | 0.24        |
|    clip_range            | 0.2         |
|    cost_returns          | 2.93        |
|    cost_value_loss       | 3.85        |
|    cost_values           | 1.44        |
|    entropy               | 1.05        |
|    entropy_loss          | 1.04        |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0.00179     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.87        |
|    n_updates             | 14580       |
|    policy_gradient_loss  | 0.0111      |
|    std                   | 0.226       |
|    value_loss            | 0.502       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.8         |
| reward                   | -0.72607404 |
| rollout/                 |             |
|    ep_len_mean           | 40.6        |
|    ep_rew_mean           | -22.4       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 39          |
|    time_elapsed          | 1201        |
|    total_timesteps       | 2990080     |
| train/                   |             |
|    approx_kl             | 0.039256744 |
|    clip_fraction         | 0.221       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.89        |
|    cost_value_loss       | 3.7         |
|    cost_values           | 1.43        |
|    entropy               | 1.05        |
|    entropy_loss          | 1.05        |
|    explained_variance    | 0.98        |
|    lagrangian_multiplier | 0.000637    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.1         |
|    n_updates             | 14590       |
|    policy_gradient_loss  | 0.0125      |
|    std                   | 0.224       |
|    value_loss            | 0.665       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.2         |
| reward                   | -0.27098772 |
| rollout/                 |             |
|    ep_len_mean           | 40.4        |
|    ep_rew_mean           | -22.7       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 40          |
|    time_elapsed          | 1231        |
|    total_timesteps       | 2992128     |
| train/                   |             |
|    approx_kl             | 0.015359158 |
|    clip_fraction         | 0.214       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.78        |
|    cost_value_loss       | 3.37        |
|    cost_values           | 1.39        |
|    entropy               | 1.05        |
|    entropy_loss          | 1.05        |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0.00113     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.81        |
|    n_updates             | 14600       |
|    policy_gradient_loss  | 0.00798     |
|    std                   | 0.225       |
|    value_loss            | 0.433       |
------------------------------------------
------------------------------------------
| avg_speed                | 7.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.2         |
| reward                   | -0.36938158 |
| rollout/                 |             |
|    ep_len_mean           | 40.3        |
|    ep_rew_mean           | -22.2       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 41          |
|    time_elapsed          | 1262        |
|    total_timesteps       | 2994176     |
| train/                   |             |
|    approx_kl             | 0.019613592 |
|    clip_fraction         | 0.172       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.81        |
|    cost_value_loss       | 3.73        |
|    cost_values           | 1.35        |
|    entropy               | 1.05        |
|    entropy_loss          | 1.05        |
|    explained_variance    | 0.984       |
|    lagrangian_multiplier | 3.54e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.17        |
|    n_updates             | 14610       |
|    policy_gradient_loss  | 0.00931     |
|    std                   | 0.226       |
|    value_loss            | 0.577       |
------------------------------------------
------------------------------------------
| avg_speed                | 2.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.8         |
| reward                   | -0.79464257 |
| rollout/                 |             |
|    ep_len_mean           | 40.4        |
|    ep_rew_mean           | -22.1       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 42          |
|    time_elapsed          | 1289        |
|    total_timesteps       | 2996224     |
| train/                   |             |
|    approx_kl             | 0.022903575 |
|    clip_fraction         | 0.202       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.77        |
|    cost_value_loss       | 3.37        |
|    cost_values           | 1.38        |
|    entropy               | 1.05        |
|    entropy_loss          | 1.05        |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.06        |
|    n_updates             | 14620       |
|    policy_gradient_loss  | 0.0022      |
|    std                   | 0.227       |
|    value_loss            | 0.592       |
------------------------------------------
-----------------------------------------
| avg_speed                | 1.2        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 1.2        |
| reward                   | -0.8984576 |
| rollout/                 |            |
|    ep_len_mean           | 39.9       |
|    ep_rew_mean           | -21.9      |
| time/                    |            |
|    fps                   | 67         |
|    iterations            | 43         |
|    time_elapsed          | 1312       |
|    total_timesteps       | 2998272    |
| train/                   |            |
|    approx_kl             | 0.01932635 |
|    clip_fraction         | 0.208      |
|    clip_range            | 0.2        |
|    cost_returns          | 2.84       |
|    cost_value_loss       | 3.58       |
|    cost_values           | 1.41       |
|    entropy               | 1.04       |
|    entropy_loss          | 1.04       |
|    explained_variance    | 0.988      |
|    lagrangian_multiplier | 0.000741   |
|    learning_rate         | 0.0003     |
|    loss                  | 1.91       |
|    n_updates             | 14630      |
|    policy_gradient_loss  | 0.0104     |
|    std                   | 0.228      |
|    value_loss            | 0.463      |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.55917174 |
| rollout/                 |             |
|    ep_len_mean           | 40.5        |
|    ep_rew_mean           | -22.5       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 44          |
|    time_elapsed          | 1336        |
|    total_timesteps       | 3000320     |
| train/                   |             |
|    approx_kl             | 0.028773189 |
|    clip_fraction         | 0.19        |
|    clip_range            | 0.2         |
|    cost_returns          | 2.85        |
|    cost_value_loss       | 3.71        |
|    cost_values           | 1.37        |
|    entropy               | 1.04        |
|    entropy_loss          | 1.04        |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0.000568    |
|    learning_rate         | 0.0003      |
|    loss                  | 1.99        |
|    n_updates             | 14640       |
|    policy_gradient_loss  | 0.0103      |
|    std                   | 0.228       |
|    value_loss            | 0.432       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.64056563 |
| rollout/                 |             |
|    ep_len_mean           | 40.8        |
|    ep_rew_mean           | -22.7       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 45          |
|    time_elapsed          | 1366        |
|    total_timesteps       | 3002368     |
| train/                   |             |
|    approx_kl             | 0.022680545 |
|    clip_fraction         | 0.209       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.94        |
|    cost_value_loss       | 4.18        |
|    cost_values           | 1.37        |
|    entropy               | 1.04        |
|    entropy_loss          | 1.04        |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0.00249     |
|    learning_rate         | 0.0003      |
|    loss                  | 1.91        |
|    n_updates             | 14650       |
|    policy_gradient_loss  | 0.00519     |
|    std                   | 0.228       |
|    value_loss            | 0.552       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.8923724  |
| rollout/                 |             |
|    ep_len_mean           | 40.3        |
|    ep_rew_mean           | -22.4       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 46          |
|    time_elapsed          | 1404        |
|    total_timesteps       | 3004416     |
| train/                   |             |
|    approx_kl             | 0.020455923 |
|    clip_fraction         | 0.182       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.73        |
|    cost_value_loss       | 3.23        |
|    cost_values           | 1.38        |
|    entropy               | 1.05        |
|    entropy_loss          | 1.05        |
|    explained_variance    | 0.979       |
|    lagrangian_multiplier | 0.000301    |
|    learning_rate         | 0.0003      |
|    loss                  | 1.99        |
|    n_updates             | 14660       |
|    policy_gradient_loss  | 0.00342     |
|    std                   | 0.227       |
|    value_loss            | 0.756       |
------------------------------------------
------------------------------------------
| avg_speed                | 4.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.4         |
| reward                   | -0.73379177 |
| rollout/                 |             |
|    ep_len_mean           | 41.3        |
|    ep_rew_mean           | -22.5       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 47          |
|    time_elapsed          | 1441        |
|    total_timesteps       | 3006464     |
| train/                   |             |
|    approx_kl             | 0.02340197  |
|    clip_fraction         | 0.221       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.66        |
|    cost_value_loss       | 3.12        |
|    cost_values           | 1.37        |
|    entropy               | 1.06        |
|    entropy_loss          | 1.05        |
|    explained_variance    | 0.984       |
|    lagrangian_multiplier | 0.000861    |
|    learning_rate         | 0.0003      |
|    loss                  | 1.72        |
|    n_updates             | 14670       |
|    policy_gradient_loss  | 0.00768     |
|    std                   | 0.226       |
|    value_loss            | 0.598       |
------------------------------------------
------------------------------------------
| avg_speed                | 1.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.8         |
| reward                   | -0.8527506  |
| rollout/                 |             |
|    ep_len_mean           | 42.1        |
|    ep_rew_mean           | -22.8       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 48          |
|    time_elapsed          | 1475        |
|    total_timesteps       | 3008512     |
| train/                   |             |
|    approx_kl             | 0.055551585 |
|    clip_fraction         | 0.218       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.85        |
|    cost_value_loss       | 3.85        |
|    cost_values           | 1.34        |
|    entropy               | 1.06        |
|    entropy_loss          | 1.06        |
|    explained_variance    | 0.978       |
|    lagrangian_multiplier | 0.000901    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.12        |
|    n_updates             | 14680       |
|    policy_gradient_loss  | 0.00984     |
|    std                   | 0.226       |
|    value_loss            | 0.742       |
------------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.7419854  |
| rollout/                 |             |
|    ep_len_mean           | 41          |
|    ep_rew_mean           | -22.2       |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 49          |
|    time_elapsed          | 1512        |
|    total_timesteps       | 3010560     |
| train/                   |             |
|    approx_kl             | 0.024689894 |
|    clip_fraction         | 0.218       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.81        |
|    cost_value_loss       | 3.77        |
|    cost_values           | 1.36        |
|    entropy               | 1.06        |
|    entropy_loss          | 1.06        |
|    explained_variance    | 0.984       |
|    lagrangian_multiplier | 8.37e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 2.07        |
|    n_updates             | 14690       |
|    policy_gradient_loss  | 0.0178      |
|    std                   | 0.226       |
|    value_loss            | 0.601       |
------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.8672491312026978
Final reward: -0.8675673007965088
Final reward: -0.8682858943939209
Final reward: -0.8696715235710144
Final reward: -0.8720815777778625
Final reward: -0.8759143948554993
Final reward: -0.8815228343009949
Final reward: -0.889083743095398
Final reward: -0.8984339237213135
Final reward: -0.9089066982269287
Final reward: -0.919227659702301
Final reward: -0.9275497198104858
Final reward: -0.9317024946212769
Final reward: -0.9356585144996643
Final reward: -0.9343704581260681
Final reward: -0.9235994219779968
Final reward: -0.9067947864532471
Final reward: -0.8871597051620483
Final reward: -0.8650311231613159
Final reward: -0.8411509394645691
Final reward: -0.8155328631401062
Final reward: -0.7879176735877991
Final reward: -0.7590755224227905
Final reward: -0.7296983003616333
Final reward: -0.695888102054596
Final reward: -0.6610764265060425
Final reward: -0.6244601607322693
Final reward: -0.5816158652305603
Final reward: -0.5392635464668274
Final reward: -0.4862736463546753
Final reward: -0.42145270109176636
Final reward: -0.3831111788749695
Final reward: -0.33104097843170166
Final reward: -0.23336872458457947
Final reward: -0.3117537498474121
Final reward: -0.33263322710990906
Final reward: -0.2797069847583771
Final reward: -0.1319546401500702
Final reward: -0.21123184263706207
Final reward: -0.3219374716281891
Final reward: -0.3627963066101074
Final reward: -0.31018513441085815
Final reward: -0.04723959043622017
Final reward: -0.7925409078598022
Final reward: -0.7928889989852905
Final reward: -0.7936752438545227
Final reward: -0.7951909303665161
Final reward: -0.7978259325027466
Final reward: -0.8020137548446655
Final reward: -0.8081352114677429
Final reward: -0.8163760304450989
Final reward: -0.8265491724014282
Final reward: -0.8379208445549011
Final reward: -0.8491051197052002
Final reward: -0.8581075072288513
Final reward: -0.8625946044921875
Final reward: -0.8668661117553711
Final reward: -0.8666182160377502
Final reward: -0.8548224568367004
Final reward: -0.836085319519043
Final reward: -0.8144169449806213
Final reward: -0.7908875942230225
Final reward: -0.765556275844574
Final reward: -0.7378007769584656
Final reward: -0.7067689299583435
Final reward: -0.6729288101196289
Final reward: -0.6346391439437866
Final reward: -0.5951916575431824
Final reward: -0.5498873591423035
Final reward: -0.5034385323524475
Final reward: -0.46892017126083374
Final reward: -0.41756272315979004
Final reward: -0.3622724711894989
Final reward: -0.2873537242412567
Final reward: -0.2911030352115631
Final reward: -0.34525349736213684
Final reward: -0.35418596863746643
Final reward: -0.23694173991680145
Final reward: -0.17256900668144226
Final reward: -0.27025702595710754
Final reward: -0.3445533514022827
Final reward: -0.344506174325943
Final reward: -0.17533119022846222
Final reward: -0.21051162481307983
Final reward: -0.3224884271621704
Final reward: -0.3607431650161743
Final reward: -0.3239564299583435
Final reward: -0.12775610387325287
Final reward: -0.2037534862756729
Final reward: -0.3105640709400177
Final reward: -0.3459317982196808
Final reward: -0.32990971207618713
Final reward: -0.1149376928806305
Final reward: -0.7668905258178711
Final reward: -0.7672502994537354
Final reward: -0.7680627703666687
Final reward: -0.7696288824081421
Final reward: -0.772351086139679
Final reward: -0.7766762375831604
Final reward: -0.782995879650116
Final reward: -0.7914984822273254
Final reward: -0.8019872307777405
Final reward: -0.8137022256851196
Final reward: -0.8252148032188416
Final reward: -0.8344749808311462
Final reward: -0.839088499546051
Final reward: -0.8434789776802063
Final reward: -0.8437912464141846
Final reward: -0.830689013004303
Final reward: -0.8113983273506165
Final reward: -0.7891797423362732
Final reward: -0.7648184895515442
Final reward: -0.7380793690681458
Final reward: -0.7082809805870056
Final reward: -0.67604660987854
Final reward: -0.6408937573432922
Final reward: -0.6010579466819763
Final reward: -0.557295024394989
Final reward: -0.5106916427612305
Final reward: -0.4758494198322296
Final reward: -0.4350230097770691
Final reward: -0.3877470791339874
Final reward: -0.3194795846939087
Final reward: -0.25409629940986633
Final reward: -0.33744344115257263
Final reward: -0.36547723412513733
Final reward: -0.32191964983940125
Final reward: -0.15640364587306976
Final reward: -0.2000029981136322
Final reward: -0.31424686312675476
Final reward: -0.36868754029273987
Final reward: -0.32869604229927063
Final reward: -0.13849297165870667
Final reward: -0.23662233352661133
Final reward: -0.35410642623901367
Final reward: -0.38352736830711365
Final reward: -0.3029487133026123
Final reward: -0.111429363489151
Final reward: -0.5178040862083435
Final reward: -0.5183367729187012
Final reward: -0.5195386409759521
Final reward: -0.521851122379303
Final reward: -0.5258576273918152
Final reward: -0.5321898460388184
Final reward: -0.5413709878921509
Final reward: -0.5535972118377686
Final reward: -0.5684923529624939
Final reward: -0.584902822971344
Final reward: -0.6008157134056091
Final reward: -0.6134725213050842
Final reward: -0.6197333931922913
Final reward: -0.6256650686264038
Final reward: -0.6207782626152039
Final reward: -0.6045233011245728
Final reward: -0.5817624926567078
Final reward: -0.5526072382926941
Final reward: -0.5186406373977661
Final reward: -0.47966060042381287
Final reward: -0.43851712346076965
Final reward: -0.3871923089027405
Final reward: -0.3437514305114746
Final reward: -0.28589457273483276
Final reward: -0.20315352082252502
Final reward: -0.27707400918006897
Final reward: -0.31423282623291016
Final reward: -0.3461398184299469
Final reward: -0.3012335002422333
Final reward: -0.12500296533107758
Final reward: -0.15398083627223969
Final reward: -0.2484995424747467
Final reward: -0.3290570378303528
Final reward: -0.3500763475894928
Final reward: -0.28700047731399536
Final reward: -0.08772886544466019
Final reward: -0.5216522216796875
Final reward: -0.5221810340881348
Final reward: -0.5233740210533142
Final reward: -0.5256696343421936
Final reward: -0.5296472907066345
Final reward: -0.5359346866607666
Final reward: -0.5450527667999268
Final reward: -0.5571982264518738
Final reward: -0.5719996094703674
Final reward: -0.5883122682571411
Final reward: -0.6041353344917297
Final reward: -0.617136538028717
Final reward: -0.6257430911064148
Final reward: -0.6306300163269043
Final reward: -0.6317057013511658
Final reward: -0.6296346187591553
Final reward: -0.6241641044616699
Final reward: -0.6179668307304382
Final reward: -0.6063497066497803
Final reward: -0.5899257063865662
Final reward: -0.5677568316459656
Final reward: -0.5427193641662598
Final reward: -0.5148568749427795
Final reward: -0.4825810492038727
Final reward: -0.44142699241638184
Final reward: -0.39297452569007874
Final reward: -0.33121219277381897
Final reward: -0.29015326499938965
Final reward: -0.2097785919904709
Final reward: -0.29266157746315
Final reward: -0.33212411403656006
Final reward: -0.3265542984008789
Final reward: -0.20154376327991486
Final reward: -0.17188186943531036
Final reward: -0.2247498780488968
Final reward: -0.3235754668712616
Final reward: -0.33809566497802734
Final reward: -0.29355520009994507
Final reward: -0.17545725405216217
Final reward: -0.23207692801952362
Final reward: -0.26825955510139465
Final reward: -0.3220714032649994
Final reward: -0.2881597578525543
Final reward: -0.16746161878108978
Final reward: -0.22092537581920624
Final reward: -0.294221431016922
Final reward: -0.3450614809989929
Final reward: -0.2886808514595032
Final reward: -0.12462548166513443
Final reward: -0.21530789136886597
Final reward: -0.3223685920238495
Final reward: -0.3468579947948456
Final reward: -0.27142536640167236
Final reward: -0.16299612820148468
Final reward: -0.2105145901441574
Final reward: -0.32109424471855164
Final reward: -0.33598604798316956
Final reward: -0.23730827867984772
Final reward: -0.18944256007671356
Final reward: -0.24775171279907227
Final reward: -0.32897502183914185
Final reward: -0.30329081416130066
Final reward: -0.08409018814563751
Final reward: -0.712826132774353
Final reward: -0.7132131457328796
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.7140870690345764
Final reward: -0.7157713174819946
Final reward: -0.7186976075172424
Final reward: -0.7233436107635498
Final reward: -0.7301250100135803
Final reward: -0.7392359972000122
Final reward: -0.7504555583000183
Final reward: -0.7629622220993042
Final reward: -0.7752286791801453
Final reward: -0.7850786447525024
Final reward: -0.7899807095527649
Final reward: -0.7946425676345825
Final reward: -0.7935449481010437
Final reward: -0.7804549336433411
Final reward: -0.7605306506156921
Final reward: -0.7368054389953613
Final reward: -0.7104659676551819
Final reward: -0.681271493434906
Final reward: -0.6494537591934204
Final reward: -0.6133028268814087
Final reward: -0.574359118938446
Final reward: -0.5302187204360962
Final reward: -0.4854018986225128
Final reward: -0.44957292079925537
Final reward: -0.40813615918159485
Final reward: -0.35657528042793274
Final reward: -0.28532475233078003
Final reward: -0.28243616223335266
Final reward: -0.3339962065219879
Final reward: -0.3453339636325836
Final reward: -0.23797829449176788
Final reward: -0.16762733459472656
Final reward: -0.22373810410499573
Final reward: -0.33233726024627686
Final reward: -0.3611953556537628
Final reward: -0.3135545551776886
Final reward: -0.11379344016313553
Final reward: -0.712826132774353
Final reward: -0.7132131457328796
Final reward: -0.7140870690345764
Final reward: -0.7157713174819946
Final reward: -0.7186976075172424
Final reward: -0.7233436107635498
Final reward: -0.7301250100135803
Final reward: -0.7392359972000122
Final reward: -0.7504555583000183
Final reward: -0.7629622220993042
Final reward: -0.7752286791801453
Final reward: -0.7850786447525024
Final reward: -0.7899807095527649
Final reward: -0.7946425676345825
Final reward: -0.7942426204681396
Final reward: -0.7808215022087097
Final reward: -0.7603452205657959
Final reward: -0.7363412380218506
Final reward: -0.7097786664962769
Final reward: -0.6808537244796753
Final reward: -0.6485087871551514
Final reward: -0.6127697825431824
Final reward: -0.5739618539810181
Final reward: -0.5307443141937256
Final reward: -0.48536452651023865
Final reward: -0.4489867091178894
Final reward: -0.41002172231674194
Final reward: -0.3572861850261688
Final reward: -0.2918303310871124
Final reward: -0.2811206877231598
Final reward: -0.3377225399017334
Final reward: -0.3535577654838562
Final reward: -0.27554845809936523
Final reward: -0.09577000141143799
Final reward: -0.5216522216796875
Final reward: -0.5221810340881348
Final reward: -0.5233740210533142
Final reward: -0.5256696343421936
Final reward: -0.5296472907066345
Final reward: -0.5359346866607666
Final reward: -0.5450527667999268
Final reward: -0.5571982264518738
Final reward: -0.5719996094703674
Final reward: -0.5883122682571411
Final reward: -0.6041353344917297
Final reward: -0.6168751120567322
Final reward: -0.6243758797645569
Final reward: -0.6286172866821289
Final reward: -0.6281588673591614
Final reward: -0.6245336532592773
Final reward: -0.6171408891677856
Final reward: -0.6105271577835083
Final reward: -0.597546398639679
Final reward: -0.5791455507278442
Final reward: -0.5587067604064941
Final reward: -0.5349520444869995
Final reward: -0.5054385662078857
Final reward: -0.4729451835155487
Final reward: -0.4305989742279053
Final reward: -0.3820778727531433
Final reward: -0.3271847069263458
Final reward: -0.28410252928733826
Final reward: -0.2108810842037201
Final reward: -0.2994278073310852
Final reward: -0.33373749256134033
Final reward: -0.3308198153972626
Final reward: -0.21539320051670074
Final reward: -0.157463937997818
Final reward: -0.2123587280511856
Final reward: -0.3282409906387329
Final reward: -0.3640015721321106
Final reward: -0.31085988879203796
Final reward: -0.07142002880573273
Final reward: -0.795060396194458
Final reward: -0.7954074740409851
Final reward: -0.7961911559104919
Final reward: -0.7977020740509033
Final reward: -0.8003288507461548
Final reward: -0.8045035600662231
Final reward: -0.8106062412261963
Final reward: -0.8188222646713257
Final reward: -0.8289653658866882
Final reward: -0.8403043150901794
Final reward: -0.8514572978019714
Final reward: -0.8604350686073303
Final reward: -0.8649101257324219
Final reward: -0.8691701889038086
Final reward: -0.8673664331436157
Final reward: -0.854642391204834
Final reward: -0.8379308581352234
Final reward: -0.8160718083381653
Final reward: -0.7928445339202881
Final reward: -0.768414318561554
Final reward: -0.7417654395103455
Final reward: -0.7145113945007324
Final reward: -0.6831746697425842
Final reward: -0.6500484943389893
Final reward: -0.6170382499694824
Final reward: -0.5765970945358276
Final reward: -0.53602135181427
Final reward: -0.49183884263038635
Final reward: -0.438375860452652
Final reward: -0.37658652663230896
Final reward: -0.32378190755844116
Final reward: -0.24332119524478912
Final reward: -0.2908170521259308
Final reward: -0.34225353598594666
Final reward: -0.33641472458839417
Final reward: -0.19705793261528015
Final reward: -0.16914580762386322
Final reward: -0.27396637201309204
Final reward: -0.34633898735046387
Final reward: -0.3273617923259735
Final reward: -0.1314138025045395
Final reward: -0.1982991248369217
Final reward: -0.3307829797267914
Final reward: -0.3629351854324341
Final reward: -0.3261748254299164
Final reward: -0.11299476027488708
Final reward: -0.8173867464065552
Final reward: -0.8177242875099182
Final reward: -0.8184866309165955
Final reward: -0.8199564814567566
Final reward: -0.822512149810791
Final reward: -0.8265748620033264
Final reward: -0.8325157761573792
Final reward: -0.8405176401138306
Final reward: -0.8504019975662231
Final reward: -0.8614588379859924
Final reward: -0.8723413944244385
Final reward: -0.881106436252594
Final reward: -0.8854770064353943
Final reward: -0.8896386027336121
Final reward: -0.8899346590042114
Final reward: -0.8777981400489807
Final reward: -0.8594770431518555
Final reward: -0.8383453488349915
Final reward: -0.8154169321060181
Final reward: -0.7906097173690796
Final reward: -0.7635787725448608
Final reward: -0.7336325645446777
Final reward: -0.7007094621658325
Final reward: -0.6649599671363831
Final reward: -0.6256997585296631
Final reward: -0.5820567011833191
Final reward: -0.5390092730522156
Final reward: -0.5021299123764038
Final reward: -0.46291056275367737
Final reward: -0.413989782333374
Final reward: -0.35956263542175293
Final reward: -0.2659509778022766
Final reward: -0.31760990619659424
Final reward: -0.34316709637641907
Final reward: -0.31607845425605774
Final reward: -0.13774994015693665
Final reward: -0.2293427288532257
Final reward: -0.29303160309791565
Final reward: -0.3462272882461548
Final reward: -0.30038657784461975
Final reward: -0.08454177528619766
Final reward: -0.8900118470191956
Final reward: -0.8903218507766724
Final reward: -0.8910220861434937
Final reward: -0.8923724293708801
Final reward: -0.8947213292121887
Final reward: -0.8984575867652893
Final reward: -0.9039261937141418
Final reward: -0.9113011956214905
Final reward: -0.9204257726669312
Final reward: -0.9306510090827942
Final reward: -0.9407334923744202
Final reward: -0.9488669633865356
Final reward: -0.9529268145561218
Final reward: -0.9567950963973999
Final reward: -0.9569395780563354
Final reward: -0.9454880952835083
Final reward: -0.9281901121139526
Final reward: -0.9089293479919434
Final reward: -0.8874317407608032
Final reward: -0.864107072353363
Final reward: -0.8386874794960022
Final reward: -0.8121621608734131
Final reward: -0.7832038998603821
Final reward: -0.7536330223083496
Final reward: -0.7190342545509338
Final reward: -0.6855902671813965
Final reward: -0.6482661366462708
Final reward: -0.6117429733276367
Final reward: -0.5689874291419983
Final reward: -0.5209963321685791
Final reward: -0.4660240709781647
Final reward: -0.41758808493614197
Final reward: -0.36987820267677307
Final reward: -0.2967625558376312
Final reward: -0.2714212238788605
Final reward: -0.32958218455314636
Final reward: -0.3220701217651367
Final reward: -0.1680847704410553
Final reward: -0.21200095117092133
Final reward: -0.29678767919540405
Final reward: -0.3559604585170746
Final reward: -0.32001766562461853
Final reward: -0.08433512598276138
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.6229936480522156
Final reward: -0.623436450958252
Final reward: -0.6244360208511353
Final reward: -0.6263613700866699
Final reward: -0.6297032833099365
Final reward: -0.6350008249282837
Final reward: -0.6427149772644043
Final reward: -0.6530466079711914
Final reward: -0.6657203435897827
Final reward: -0.6797876954078674
Final reward: -0.6935268640518188
Final reward: -0.704520046710968
Final reward: -0.7099785208702087
Final reward: -0.7151620984077454
Final reward: -0.7122626304626465
Final reward: -0.6986584663391113
Final reward: -0.6770957708358765
Final reward: -0.6512371301651001
Final reward: -0.6207408308982849
Final reward: -0.587429940700531
Final reward: -0.5518908500671387
Final reward: -0.5101773738861084
Final reward: -0.4654677212238312
Final reward: -0.4227096736431122
Final reward: -0.3822402358055115
Final reward: -0.33507370948791504
Final reward: -0.27126193046569824
Final reward: -0.2744101285934448
Final reward: -0.3251870572566986
Final reward: -0.3412739634513855
Final reward: -0.2695674002170563
Final reward: -0.09167543053627014
Final reward: -0.4776202142238617
Final reward: -0.4781976640224457
Final reward: -0.4795001447200775
Final reward: -0.4820047616958618
Final reward: -0.48633962869644165
Final reward: -0.4931795001029968
Final reward: -0.5030730962753296
Final reward: -0.5162071585655212
Final reward: -0.5321499109268188
Final reward: -0.5496465563774109
Final reward: -0.5665505528450012
Final reward: -0.5799556374549866
Final reward: -0.586574375629425
Final reward: -0.5928269028663635
Final reward: -0.5872600674629211
Final reward: -0.5698850154876709
Final reward: -0.5464751124382019
Final reward: -0.5146889686584473
Final reward: -0.48021745681762695
Final reward: -0.44151899218559265
Final reward: -0.3924654424190521
Final reward: -0.3345571756362915
Final reward: -0.28813183307647705
Final reward: -0.22040601074695587
Final reward: -0.25764596462249756
Final reward: -0.3190879225730896
Final reward: -0.34330806136131287
Final reward: -0.3462364077568054
Final reward: -0.2455563098192215
Final reward: -0.09294965863227844
Final reward: -0.6841937303543091
Final reward: -0.6845969557762146
Final reward: -0.6855073571205139
Final reward: -0.6872616410255432
Final reward: -0.6903088092803955
Final reward: -0.6951445937156677
Final reward: -0.702198326587677
Final reward: -0.7116669416427612
Final reward: -0.7233142852783203
Final reward: -0.7362821102142334
Final reward: -0.7489856481552124
Final reward: -0.7591761946678162
Final reward: -0.7642443776130676
Final reward: -0.7690622806549072
Final reward: -0.7678150534629822
Final reward: -0.7544852495193481
Final reward: -0.7334424257278442
Final reward: -0.7090258002281189
Final reward: -0.6817365884780884
Final reward: -0.6514372229576111
Final reward: -0.6168972849845886
Final reward: -0.5801156759262085
Final reward: -0.540118932723999
Final reward: -0.4939552843570709
Final reward: -0.44903385639190674
Final reward: -0.41110751032829285
Final reward: -0.36258798837661743
Final reward: -0.2963089644908905
Final reward: -0.24775944650173187
Final reward: -0.319227010011673
Final reward: -0.34220942854881287
Final reward: -0.3020615577697754
Final reward: -0.1185479611158371
Final reward: -0.7403519749641418
Final reward: -0.7407246232032776
Final reward: -0.7415661811828613
Final reward: -0.7431881427764893
Final reward: -0.7460068464279175
Final reward: -0.7504838705062866
Final reward: -0.7570221424102783
Final reward: -0.7658132314682007
Final reward: -0.7766489386558533
Final reward: -0.788740336894989
Final reward: -0.8006119728088379
Final reward: -0.8101533651351929
Final reward: -0.8149045705795288
Final reward: -0.8194246888160706
Final reward: -0.8191483616828918
Final reward: -0.8054900169372559
Final reward: -0.7861077189445496
Final reward: -0.7630367279052734
Final reward: -0.7378435134887695
Final reward: -0.7096959352493286
Final reward: -0.6788728833198547
Final reward: -0.6445846557617188
Final reward: -0.6081439852714539
Final reward: -0.5667692422866821
Final reward: -0.525033712387085
Final reward: -0.4890283942222595
Final reward: -0.4548512399196625
Final reward: -0.4125536382198334
Final reward: -0.35281896591186523
Final reward: -0.27342692017555237
Final reward: -0.31333786249160767
Final reward: -0.35032403469085693
Final reward: -0.35540270805358887
Final reward: -0.23850123584270477
Final reward: -0.17553555965423584
Final reward: -0.2694458067417145
Final reward: -0.34771183133125305
Final reward: -0.3551623523235321
Final reward: -0.21266093850135803
Final reward: -0.20776504278182983
Final reward: -0.3084236979484558
Final reward: -0.36313536763191223
Final reward: -0.3039814531803131
Final reward: -0.10459138453006744
Final reward: -0.7668905258178711
Final reward: -0.7672502994537354
Final reward: -0.7680627703666687
Final reward: -0.7696288824081421
Final reward: -0.772351086139679
Final reward: -0.7766762375831604
Final reward: -0.782995879650116
Final reward: -0.7914984822273254
Final reward: -0.8019872307777405
Final reward: -0.8137022256851196
Final reward: -0.8252148032188416
Final reward: -0.8344749808311462
Final reward: -0.839088499546051
Final reward: -0.8434789776802063
Final reward: -0.8428729772567749
Final reward: -0.8306472301483154
Final reward: -0.8117469549179077
Final reward: -0.789462149143219
Final reward: -0.7650206089019775
Final reward: -0.7383459806442261
Final reward: -0.7089099884033203
Final reward: -0.6762034296989441
Final reward: -0.6405555605888367
Final reward: -0.6012904644012451
Final reward: -0.5589917898178101
Final reward: -0.5113922357559204
Final reward: -0.47174203395843506
Final reward: -0.43370822072029114
Final reward: -0.38004761934280396
Final reward: -0.3182660937309265
Final reward: -0.2539385259151459
Final reward: -0.3261265754699707
Final reward: -0.3429218828678131
Final reward: -0.28153619170188904
Final reward: -0.09604933857917786
Final reward: -0.5900178551673889
Final reward: -0.5904853940010071
Final reward: -0.5915406942367554
Final reward: -0.593572735786438
Final reward: -0.597098171710968
Final reward: -0.60268235206604
Final reward: -0.6108047962188721
Final reward: -0.6216670274734497
Final reward: -0.6349673867225647
Final reward: -0.649700939655304
Final reward: -0.6640628576278687
Final reward: -0.6755357384681702
Final reward: -0.6812264919281006
Final reward: -0.6866271495819092
Final reward: -0.6835376620292664
Final reward: -0.6686604619026184
Final reward: -0.6472995281219482
Final reward: -0.6191666126251221
Final reward: -0.5880131125450134
Final reward: -0.5537112951278687
Final reward: -0.5149301290512085
Final reward: -0.47190749645233154
Final reward: -0.4225822985172272
Final reward: -0.3798101544380188
Final reward: -0.3306634724140167
Final reward: -0.2690274119377136
Final reward: -0.24690324068069458
Final reward: -0.3115381896495819
Final reward: -0.3373836874961853
Final reward: -0.31362080574035645
Final reward: -0.1670299768447876
Final reward: -0.1739100217819214
Final reward: -0.22354984283447266
Final reward: -0.3281850218772888
Final reward: -0.3623201549053192
Final reward: -0.32004624605178833
Final reward: -0.14792613685131073
Final reward: -0.20187272131443024
Final reward: -0.28346842527389526
Final reward: -0.34600701928138733
Final reward: -0.31483423709869385
Final reward: -0.05331558734178543
Final reward: -0.6543096303939819
Final reward: -0.654731273651123
Final reward: -0.655683159828186
Final reward: -0.6575170159339905
Final reward: -0.660701334476471
Final reward: -0.6657522320747375
Final reward: -0.6731140613555908
Final reward: -0.6829859614372253
Final reward: -0.6951140761375427
Final reward: -0.7085981369018555
Final reward: -0.7217891216278076
Final reward: -0.7323582172393799
Final reward: -0.7376106977462769
Final reward: -0.7426013946533203
Final reward: -0.741200864315033
Final reward: -0.7265824675559998
Final reward: -0.7053340077400208
Final reward: -0.679720401763916
Final reward: -0.651771068572998
Final reward: -0.6200266480445862
Final reward: -0.5857213139533997
Final reward: -0.5466073155403137
Final reward: -0.5022550821304321
Final reward: -0.46258795261383057
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.426909863948822
Final reward: -0.3847602307796478
Final reward: -0.32888472080230713
Final reward: -0.2493206262588501
Final reward: -0.30314573645591736
Final reward: -0.33827903866767883
Final reward: -0.3460785150527954
Final reward: -0.26009228825569153
Final reward: -0.1212269738316536
Final reward: -0.22237204015254974
Final reward: -0.3350215554237366
Final reward: -0.37594476342201233
Final reward: -0.3303889334201813
Final reward: -0.17956794798374176
Final reward: -0.19205181300640106
Final reward: -0.29801976680755615
Final reward: -0.3624490797519684
Final reward: -0.3070683479309082
Final reward: -0.0689086839556694
Final reward: -0.7156263589859009
Final reward: -0.7160118818283081
Final reward: -0.7168824076652527
Final reward: -0.7185600996017456
Final reward: -0.7214750647544861
Final reward: -0.7261033058166504
Final reward: -0.7328591346740723
Final reward: -0.7419365644454956
Final reward: -0.7531158924102783
Final reward: -0.765579104423523
Final reward: -0.7778042554855347
Final reward: -0.7876220941543579
Final reward: -0.7925083637237549
Final reward: -0.7971554398536682
Final reward: -0.7928441166877747
Final reward: -0.780403196811676
Final reward: -0.7627960443496704
Final reward: -0.7407485842704773
Final reward: -0.7167714834213257
Final reward: -0.690989077091217
Final reward: -0.6638137698173523
Final reward: -0.6336969137191772
Final reward: -0.6011183261871338
Final reward: -0.5672370195388794
Final reward: -0.5314939618110657
Final reward: -0.49099424481391907
Final reward: -0.448524534702301
Final reward: -0.3905302584171295
Final reward: -0.3317418396472931
Final reward: -0.2766895592212677
Final reward: -0.22937855124473572
Final reward: -0.32389432191848755
Final reward: -0.35786357522010803
Final reward: -0.3258441984653473
Final reward: -0.1672050654888153
Final reward: -0.17632120847702026
Final reward: -0.2679091691970825
Final reward: -0.3395881950855255
Final reward: -0.32976460456848145
Final reward: -0.1545531004667282
Final reward: -0.20221005380153656
Final reward: -0.3166886866092682
Final reward: -0.36595016717910767
Final reward: -0.3035886883735657
Final reward: -0.07199286669492722
Final reward: -0.712826132774353
Final reward: -0.7132131457328796
Final reward: -0.7140870690345764
Final reward: -0.7157713174819946
Final reward: -0.7186976075172424
Final reward: -0.7233436107635498
Final reward: -0.7301250100135803
Final reward: -0.7392359972000122
Final reward: -0.7504555583000183
Final reward: -0.7629622220993042
Final reward: -0.7752286791801453
Final reward: -0.7850786447525024
Final reward: -0.7899807095527649
Final reward: -0.7946425676345825
Final reward: -0.7930830717086792
Final reward: -0.7811996340751648
Final reward: -0.7607848644256592
Final reward: -0.736846387386322
Final reward: -0.7102495431900024
Final reward: -0.6814142465591431
Final reward: -0.6487679481506348
Final reward: -0.613979160785675
Final reward: -0.574842095375061
Final reward: -0.5327010154724121
Final reward: -0.4929746091365814
Final reward: -0.45500123500823975
Final reward: -0.4137178659439087
Final reward: -0.3618408739566803
Final reward: -0.2873906195163727
Final reward: -0.2791402339935303
Final reward: -0.3310072422027588
Final reward: -0.34697866439819336
Final reward: -0.2645913064479828
Final reward: -0.12365324050188065
Final reward: -0.20849326252937317
Final reward: -0.3277607262134552
Final reward: -0.3675108850002289
Final reward: -0.3222009539604187
Final reward: -0.1220923587679863
Final reward: -0.20936621725559235
Final reward: -0.33657747507095337
Final reward: -0.3672555983066559
Final reward: -0.3049481213092804
Final reward: -0.11031462252140045
Final reward: -0.6573591828346252
Final reward: -0.6577788591384888
Final reward: -0.6587263345718384
Final reward: -0.6605517268180847
Final reward: -0.66372150182724
Final reward: -0.6687495708465576
Final reward: -0.6760787963867188
Final reward: -0.6859080791473389
Final reward: -0.6979853510856628
Final reward: -0.7114150524139404
Final reward: -0.724554717540741
Final reward: -0.7350839972496033
Final reward: -0.740317165851593
Final reward: -0.7444700598716736
Final reward: -0.7386332154273987
Final reward: -0.7265059947967529
Final reward: -0.7106143832206726
Final reward: -0.6888473033905029
Final reward: -0.6638484597206116
Final reward: -0.6382584571838379
Final reward: -0.6093146800994873
Final reward: -0.5800612568855286
Final reward: -0.5481276512145996
Final reward: -0.5142421126365662
Final reward: -0.47496289014816284
Final reward: -0.43069684505462646
Final reward: -0.37811046838760376
Final reward: -0.3110312819480896
Final reward: -0.2477506548166275
Final reward: -0.23639735579490662
Final reward: -0.3250320553779602
Final reward: -0.35587969422340393
Final reward: -0.34797799587249756
Final reward: -0.21606691181659698
Final reward: -0.11890065670013428
Final reward: -0.8198298811912537
Final reward: -0.8201664686203003
Final reward: -0.8209265470504761
Final reward: -0.8223919868469238
Final reward: -0.8249401450157166
Final reward: -0.8289909362792969
Final reward: -0.8349146842956543
Final reward: -0.8428937196731567
Final reward: -0.8527505993843079
Final reward: -0.8637773394584656
Final reward: -0.8746310472488403
Final reward: -0.8833733797073364
Final reward: -0.8877328038215637
Final reward: -0.8918838500976562
Final reward: -0.8907956480979919
Final reward: -0.8783628344535828
Final reward: -0.8608947992324829
Final reward: -0.8402373790740967
Final reward: -0.8178341388702393
Final reward: -0.7922553420066833
Final reward: -0.7655506134033203
Final reward: -0.7372990250587463
Final reward: -0.7087424993515015
Final reward: -0.6756210327148438
Final reward: -0.641621470451355
Final reward: -0.6069586277008057
Final reward: -0.5647032856941223
Final reward: -0.522189199924469
Final reward: -0.4693119525909424
Final reward: -0.4114534258842468
Final reward: -0.35789936780929565
Final reward: -0.30118927359580994
Final reward: -0.2269698679447174
Final reward: -0.3305734395980835
Final reward: -0.36355847120285034
Final reward: -0.3437277376651764
Final reward: -0.19387146830558777
Final reward: -0.17144809663295746
Final reward: -0.31008943915367126
Final reward: -0.37229302525520325
Final reward: -0.32798880338668823
Final reward: -0.12250838428735733
Final reward: -0.22738400101661682
Final reward: -0.34825363755226135
Final reward: -0.3742832839488983
Final reward: -0.3410288393497467
Final reward: -0.14466632902622223
Final reward: -0.22467242181301117
Final reward: -0.34755587577819824
Final reward: -0.3794683814048767
Final reward: -0.34812936186790466
Final reward: -0.16288606822490692
Final reward: -0.21160155534744263
Final reward: -0.3396988809108734
Final reward: -0.3912908434867859
Final reward: -0.3304692208766937
Final reward: -0.12292464077472687
Final reward: -0.23914219439029694
Final reward: -0.3578380346298218
Final reward: -0.3953547477722168
Final reward: -0.33252647519111633
Final reward: -0.1384667009115219
Final reward: -0.2110833078622818
Final reward: -0.33947432041168213
Final reward: -0.3742675185203552
Final reward: -0.33627405762672424
Final reward: -0.13606992363929749
Final reward: -0.21780528128147125
Final reward: -0.34325993061065674
Final reward: -0.37861645221710205
Final reward: -0.3252072036266327
Final reward: -0.10063358396291733
Final reward: -0.6229936480522156
Final reward: -0.623436450958252
Final reward: -0.6244360208511353
Final reward: -0.6263613700866699
Final reward: -0.6297032833099365
Final reward: -0.6350008249282837
Final reward: -0.6427149772644043
Final reward: -0.6530466079711914
Final reward: -0.6657203435897827
Final reward: -0.6797876954078674
Final reward: -0.6935268640518188
Final reward: -0.704520046710968
Final reward: -0.7099785208702087
Final reward: -0.7151620984077454
Final reward: -0.713383674621582
Final reward: -0.6985307335853577
Final reward: -0.6762624382972717
Final reward: -0.6500749588012695
Final reward: -0.619935929775238
Final reward: -0.5872038006782532
Final reward: -0.5503650307655334
Final reward: -0.5108678936958313
Final reward: -0.464328795671463
Final reward: -0.42302384972572327
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.38266777992248535
Final reward: -0.33158111572265625
Final reward: -0.25650399923324585
Final reward: -0.27898547053337097
Final reward: -0.331467866897583
Final reward: -0.34795522689819336
Final reward: -0.2896571457386017
Final reward: -0.06286873668432236
Final reward: -0.8438726663589478
Final reward: -0.8441995978355408
Final reward: -0.8449380993843079
Final reward: -0.8463619947433472
Final reward: -0.8488381505012512
Final reward: -0.8527754545211792
Final reward: -0.85853511095047
Final reward: -0.866296648979187
Final reward: -0.8758901357650757
Final reward: -0.8866292238235474
Final reward: -0.8972064852714539
Final reward: -0.9057309031486511
Final reward: -0.909983217716217
Final reward: -0.9140332341194153
Final reward: -0.9136360883712769
Final reward: -0.9012944102287292
Final reward: -0.8841435313224792
Final reward: -0.8637025356292725
Final reward: -0.8410835862159729
Final reward: -0.8166400790214539
Final reward: -0.7901857495307922
Final reward: -0.7620886564254761
Final reward: -0.7313957810401917
Final reward: -0.7003757357597351
Final reward: -0.6689431667327881
Final reward: -0.63430255651474
Final reward: -0.5959703326225281
Final reward: -0.5523443222045898
Final reward: -0.5048259496688843
Final reward: -0.44965046644210815
Final reward: -0.3948328197002411
Final reward: -0.3454744815826416
Final reward: -0.2665678560733795
Final reward: -0.2859545648097992
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                   avg_speed ‚ñà‚ñÅ‚ñÉ‚ñÉ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÑ‚ñà‚ñÜ‚ñà‚ñà‚ñà‚ñÇ‚ñà‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÅ‚ñÉ‚ñÖ‚ñÅ‚ñÜ‚ñà‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÉ‚ñÑ‚ñà
wandb:                        cost ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                  is_success ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                   max_speed ‚ñà‚ñÅ‚ñÉ‚ñÉ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÑ‚ñà‚ñÜ‚ñà‚ñà‚ñà‚ñÇ‚ñà‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÅ‚ñÉ‚ñÖ‚ñÅ‚ñÜ‚ñà‚ñÅ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÉ‚ñÑ‚ñà
wandb:                      reward ‚ñÅ‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÖ‚ñÜ‚ñà
wandb:             train/approx_kl ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÖ‚ñÇ‚ñÉ‚ñà‚ñÉ
wandb:         train/clip_fraction ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÉ‚ñÖ‚ñÇ‚ñÉ‚ñÖ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñÖ‚ñà‚ñÜ‚ñá‚ñá‚ñÜ
wandb:            train/clip_range ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:          train/cost_returns ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:       train/cost_value_loss ‚ñÅ‚ñÅ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñà‚ñÖ‚ñá‚ñÜ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ
wandb:           train/cost_values ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ
wandb:               train/entropy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:          train/entropy_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:    train/explained_variance ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb: train/lagrangian_multiplier ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÑ‚ñá‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÅ
wandb:         train/learning_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                  train/loss ‚ñÜ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:             train/n_updates ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:  train/policy_gradient_loss ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñà‚ñá‚ñá‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñà‚ñá
wandb:                   train/std ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:            train/value_loss ‚ñá‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                   avg_speed 4.0
wandb:                        cost 0
wandb:                  is_success 0
wandb:                   max_speed 4.0
wandb:                      reward -0.74199
wandb:             train/approx_kl 0.02469
wandb:         train/clip_fraction 0.21797
wandb:            train/clip_range 0.2
wandb:          train/cost_returns 2.81028
wandb:       train/cost_value_loss 3.76879
wandb:           train/cost_values 1.35741
wandb:               train/entropy 1.06263
wandb:          train/entropy_loss 1.06123
wandb:    train/explained_variance 0.98436
wandb: train/lagrangian_multiplier 8e-05
wandb:         train/learning_rate 0.0003
wandb:                  train/loss 2.06984
wandb:             train/n_updates 14690
wandb:  train/policy_gradient_loss 0.01779
wandb:                   train/std 0.22599
wandb:            train/value_loss 0.60108
wandb: 
wandb: üöÄ View run glowing-bao-30 at: https://wandb.ai/ecrl/ent-coefficient-ppol/runs/1vjpjg9h
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240213_210829-1vjpjg9h/logs
