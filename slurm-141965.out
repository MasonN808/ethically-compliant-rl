wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20240222_193145-2fzzfvlw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floating-kumquat-20
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/ppol-extra-obs
wandb: üöÄ View run at https://wandb.ai/ecrl/ppol-extra-obs/runs/2fzzfvlw
/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/gymnasium/utils/passive_env_checker.py:164: UserWarning: [33mWARN: The obs returned by the `reset()` method was expecting numpy array dtype to be float64, actual type: int64[0m
  logger.warn(
Using cpu device
-----------------------------------
| avg_speed          | 0.319      |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 0.319      |
| reward             | -0.3973252 |
| rollout/           |            |
|    ep_len_mean     | 1e+03      |
|    ep_rew_mean     | -1.24e+03  |
| time/              |            |
|    fps             | 85         |
|    iterations      | 1          |
|    time_elapsed    | 24         |
|    total_timesteps | 2048       |
-----------------------------------
-------------------------------------------
| avg_speed                | 7.77         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.77         |
| reward                   | -2.4059153   |
| rollout/                 |              |
|    ep_len_mean           | 811          |
|    ep_rew_mean           | -888         |
| time/                    |              |
|    fps                   | 77           |
|    iterations            | 2            |
|    time_elapsed          | 53           |
|    total_timesteps       | 4096         |
| train/                   |              |
|    approx_kl             | 0.0030606044 |
|    clip_fraction         | 0.0252       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.195        |
|    cost_value_loss       | 2.53         |
|    cost_values           | 0.0746       |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.00132      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 202          |
|    n_updates             | 10           |
|    policy_gradient_loss  | -0.00215     |
|    std                   | 0.998        |
|    value_loss            | 428          |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8.01       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.01       |
| reward                   | -1.5331995 |
| rollout/                 |            |
|    ep_len_mean           | 874        |
|    ep_rew_mean           | -1.04e+03  |
| time/                    |            |
|    fps                   | 72         |
|    iterations            | 3          |
|    time_elapsed          | 84         |
|    total_timesteps       | 6144       |
| train/                   |            |
|    approx_kl             | 0.00574793 |
|    clip_fraction         | 0.0457     |
|    clip_range            | 0.2        |
|    cost_returns          | 0.993      |
|    cost_value_loss       | 9.8        |
|    cost_values           | 0.255      |
|    entropy               | -2.83      |
|    entropy_loss          | -2.83      |
|    explained_variance    | 0.0723     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 151        |
|    n_updates             | 20         |
|    policy_gradient_loss  | -0.0035    |
|    std                   | 0.996      |
|    value_loss            | 336        |
-----------------------------------------
-------------------------------------------
| avg_speed                | 7.27         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.27         |
| reward                   | -1.0098538   |
| rollout/                 |              |
|    ep_len_mean           | 906          |
|    ep_rew_mean           | -1.02e+03    |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 4            |
|    time_elapsed          | 115          |
|    total_timesteps       | 8192         |
| train/                   |              |
|    approx_kl             | 0.0056902883 |
|    clip_fraction         | 0.0572       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.12         |
|    cost_value_loss       | 7.07         |
|    cost_values           | 0.609        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.103        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 185          |
|    n_updates             | 30           |
|    policy_gradient_loss  | -0.00385     |
|    std                   | 0.999        |
|    value_loss            | 401          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.47         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.47         |
| reward                   | -1.5845525   |
| rollout/                 |              |
|    ep_len_mean           | 874          |
|    ep_rew_mean           | -923         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 5            |
|    time_elapsed          | 147          |
|    total_timesteps       | 10240        |
| train/                   |              |
|    approx_kl             | 0.0027986835 |
|    clip_fraction         | 0.0108       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.35         |
|    cost_value_loss       | 6.41         |
|    cost_values           | 0.851        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.0944       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 101          |
|    n_updates             | 40           |
|    policy_gradient_loss  | -0.00274     |
|    std                   | 0.998        |
|    value_loss            | 200          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.06         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.06         |
| reward                   | -0.84246343  |
| rollout/                 |              |
|    ep_len_mean           | 893          |
|    ep_rew_mean           | -968         |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 6            |
|    time_elapsed          | 184          |
|    total_timesteps       | 12288        |
| train/                   |              |
|    approx_kl             | 0.0027462547 |
|    clip_fraction         | 0.0156       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.76         |
|    cost_value_loss       | 6.49         |
|    cost_values           | 0.943        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.119        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 104          |
|    n_updates             | 50           |
|    policy_gradient_loss  | -0.00268     |
|    std                   | 1            |
|    value_loss            | 210          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.63         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.63         |
| reward                   | -1.1847944   |
| rollout/                 |              |
|    ep_len_mean           | 908          |
|    ep_rew_mean           | -940         |
| time/                    |              |
|    fps                   | 64           |
|    iterations            | 7            |
|    time_elapsed          | 221          |
|    total_timesteps       | 14336        |
| train/                   |              |
|    approx_kl             | 0.0053894757 |
|    clip_fraction         | 0.0351       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.26         |
|    cost_value_loss       | 12.6         |
|    cost_values           | 0.975        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.107        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 162          |
|    n_updates             | 60           |
|    policy_gradient_loss  | -0.00281     |
|    std                   | 1.01         |
|    value_loss            | 339          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.11         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.11         |
| reward                   | -0.76725125  |
| rollout/                 |              |
|    ep_len_mean           | 919          |
|    ep_rew_mean           | -924         |
| time/                    |              |
|    fps                   | 63           |
|    iterations            | 8            |
|    time_elapsed          | 259          |
|    total_timesteps       | 16384        |
| train/                   |              |
|    approx_kl             | 0.0049808947 |
|    clip_fraction         | 0.04         |
|    clip_range            | 0.2          |
|    cost_returns          | 1.67         |
|    cost_value_loss       | 6.36         |
|    cost_values           | 0.983        |
|    entropy               | -2.87        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.0863       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 79.7         |
|    n_updates             | 70           |
|    policy_gradient_loss  | -0.00377     |
|    std                   | 1.02         |
|    value_loss            | 164          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.31         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.31         |
| reward                   | -1.2281379   |
| rollout/                 |              |
|    ep_len_mean           | 927          |
|    ep_rew_mean           | -911         |
| time/                    |              |
|    fps                   | 60           |
|    iterations            | 9            |
|    time_elapsed          | 303          |
|    total_timesteps       | 18432        |
| train/                   |              |
|    approx_kl             | 0.0040065655 |
|    clip_fraction         | 0.044        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.56         |
|    cost_value_loss       | 5.27         |
|    cost_values           | 0.977        |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.121        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 65.5         |
|    n_updates             | 80           |
|    policy_gradient_loss  | -0.00347     |
|    std                   | 1.02         |
|    value_loss            | 136          |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.61        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.61        |
| reward                   | -0.5926146  |
| rollout/                 |             |
|    ep_len_mean           | 934         |
|    ep_rew_mean           | -947        |
| time/                    |             |
|    fps                   | 59          |
|    iterations            | 10          |
|    time_elapsed          | 344         |
|    total_timesteps       | 20480       |
| train/                   |             |
|    approx_kl             | 0.004664057 |
|    clip_fraction         | 0.0461      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.51        |
|    cost_value_loss       | 14.6        |
|    cost_values           | 0.985       |
|    entropy               | -2.88       |
|    entropy_loss          | -2.87       |
|    explained_variance    | 0.0746      |
|    lagrangian_multiplier | 0.000213    |
|    learning_rate         | 0.0003      |
|    loss                  | 97.1        |
|    n_updates             | 90          |
|    policy_gradient_loss  | -0.00308    |
|    std                   | 1.02        |
|    value_loss            | 219         |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.76         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.76         |
| reward                   | -1.1595737   |
| rollout/                 |              |
|    ep_len_mean           | 940          |
|    ep_rew_mean           | -923         |
| time/                    |              |
|    fps                   | 57           |
|    iterations            | 11           |
|    time_elapsed          | 389          |
|    total_timesteps       | 22528        |
| train/                   |              |
|    approx_kl             | 0.0038935184 |
|    clip_fraction         | 0.0393       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.11         |
|    cost_value_loss       | 22.6         |
|    cost_values           | 0.991        |
|    entropy               | -2.88        |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.0486       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 223          |
|    n_updates             | 100          |
|    policy_gradient_loss  | -0.00345     |
|    std                   | 1.02         |
|    value_loss            | 413          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -1.9460235  |
| rollout/                 |             |
|    ep_len_mean           | 945         |
|    ep_rew_mean           | -927        |
| time/                    |             |
|    fps                   | 56          |
|    iterations            | 12          |
|    time_elapsed          | 438         |
|    total_timesteps       | 24576       |
| train/                   |             |
|    approx_kl             | 0.004484874 |
|    clip_fraction         | 0.0172      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.25        |
|    cost_value_loss       | 2.16        |
|    cost_values           | 0.988       |
|    entropy               | -2.87       |
|    entropy_loss          | -2.87       |
|    explained_variance    | 0.0404      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 66.4        |
|    n_updates             | 110         |
|    policy_gradient_loss  | -0.00406    |
|    std                   | 1.02        |
|    value_loss            | 139         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -1.2011286   |
| rollout/                 |              |
|    ep_len_mean           | 949          |
|    ep_rew_mean           | -954         |
| time/                    |              |
|    fps                   | 54           |
|    iterations            | 13           |
|    time_elapsed          | 487          |
|    total_timesteps       | 26624        |
| train/                   |              |
|    approx_kl             | 0.0012236703 |
|    clip_fraction         | 0.014        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.43         |
|    cost_value_loss       | 2.99         |
|    cost_values           | 0.987        |
|    entropy               | -2.88        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.0529       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 157          |
|    n_updates             | 120          |
|    policy_gradient_loss  | -0.00222     |
|    std                   | 1.02         |
|    value_loss            | 320          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.504        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.504        |
| reward                   | -0.30648848  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -943         |
| time/                    |              |
|    fps                   | 52           |
|    iterations            | 14           |
|    time_elapsed          | 541          |
|    total_timesteps       | 28672        |
| train/                   |              |
|    approx_kl             | 0.0021502483 |
|    clip_fraction         | 0.00693      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.72         |
|    cost_value_loss       | 6            |
|    cost_values           | 0.988        |
|    entropy               | -2.89        |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.0335       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 185          |
|    n_updates             | 130          |
|    policy_gradient_loss  | -0.00276     |
|    std                   | 1.03         |
|    value_loss            | 360          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.27         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.27         |
| reward                   | -0.39432678  |
| rollout/                 |              |
|    ep_len_mean           | 957          |
|    ep_rew_mean           | -937         |
| time/                    |              |
|    fps                   | 51           |
|    iterations            | 15           |
|    time_elapsed          | 593          |
|    total_timesteps       | 30720        |
| train/                   |              |
|    approx_kl             | 0.0029378824 |
|    clip_fraction         | 0.0111       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.29         |
|    cost_value_loss       | 2.31         |
|    cost_values           | 0.988        |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.0358       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 72.4         |
|    n_updates             | 140          |
|    policy_gradient_loss  | -0.00238     |
|    std                   | 1.03         |
|    value_loss            | 157          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.22         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.22         |
| reward                   | -1.2467692   |
| rollout/                 |              |
|    ep_len_mean           | 936          |
|    ep_rew_mean           | -922         |
| time/                    |              |
|    fps                   | 50           |
|    iterations            | 16           |
|    time_elapsed          | 654          |
|    total_timesteps       | 32768        |
| train/                   |              |
|    approx_kl             | 0.0043670796 |
|    clip_fraction         | 0.0255       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.51         |
|    cost_value_loss       | 3.81         |
|    cost_values           | 0.988        |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.0449       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 79.5         |
|    n_updates             | 150          |
|    policy_gradient_loss  | -0.00381     |
|    std                   | 1.03         |
|    value_loss            | 159          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.3773212  |
| rollout/                 |             |
|    ep_len_mean           | 941         |
|    ep_rew_mean           | -923        |
| time/                    |             |
|    fps                   | 48          |
|    iterations            | 17          |
|    time_elapsed          | 710         |
|    total_timesteps       | 34816       |
| train/                   |             |
|    approx_kl             | 0.003348956 |
|    clip_fraction         | 0.0218      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.64        |
|    cost_value_loss       | 5.99        |
|    cost_values           | 0.992       |
|    entropy               | -2.91       |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.0165      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 129         |
|    n_updates             | 160         |
|    policy_gradient_loss  | -0.00427    |
|    std                   | 1.04        |
|    value_loss            | 265         |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.5          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 1.5          |
| reward                   | -0.2737095   |
| rollout/                 |              |
|    ep_len_mean           | 944          |
|    ep_rew_mean           | -917         |
| time/                    |              |
|    fps                   | 47           |
|    iterations            | 18           |
|    time_elapsed          | 777          |
|    total_timesteps       | 36864        |
| train/                   |              |
|    approx_kl             | 0.0023794915 |
|    clip_fraction         | 0.00391      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.41         |
|    cost_value_loss       | 16.6         |
|    cost_values           | 0.993        |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.0729       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 118          |
|    n_updates             | 170          |
|    policy_gradient_loss  | -0.00153     |
|    std                   | 1.04         |
|    value_loss            | 237          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.46         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.46         |
| reward                   | -0.61051637  |
| rollout/                 |              |
|    ep_len_mean           | 947          |
|    ep_rew_mean           | -902         |
| time/                    |              |
|    fps                   | 46           |
|    iterations            | 19           |
|    time_elapsed          | 845          |
|    total_timesteps       | 38912        |
| train/                   |              |
|    approx_kl             | 0.0038358073 |
|    clip_fraction         | 0.0258       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.63         |
|    cost_value_loss       | 3.76         |
|    cost_values           | 0.991        |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.0351       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 58.6         |
|    n_updates             | 180          |
|    policy_gradient_loss  | -0.00384     |
|    std                   | 1.03         |
|    value_loss            | 127          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.79        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.79        |
| reward                   | -1.2024221  |
| rollout/                 |             |
|    ep_len_mean           | 929         |
|    ep_rew_mean           | -891        |
| time/                    |             |
|    fps                   | 45          |
|    iterations            | 20          |
|    time_elapsed          | 909         |
|    total_timesteps       | 40960       |
| train/                   |             |
|    approx_kl             | 0.003566957 |
|    clip_fraction         | 0.0282      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.15        |
|    cost_value_loss       | 6           |
|    cost_values           | 0.995       |
|    entropy               | -2.91       |
|    entropy_loss          | -2.91       |
|    explained_variance    | -0.0435     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 27.9        |
|    n_updates             | 190         |
|    policy_gradient_loss  | -0.00361    |
|    std                   | 1.03        |
|    value_loss            | 55.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.41        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.41        |
| reward                   | -0.54779196 |
| rollout/                 |             |
|    ep_len_mean           | 934         |
|    ep_rew_mean           | -899        |
| time/                    |             |
|    fps                   | 43          |
|    iterations            | 21          |
|    time_elapsed          | 988         |
|    total_timesteps       | 43008       |
| train/                   |             |
|    approx_kl             | 0.002424671 |
|    clip_fraction         | 0.0152      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.36        |
|    cost_value_loss       | 4.69        |
|    cost_values           | 0.99        |
|    entropy               | -2.91       |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.0532      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 150         |
|    n_updates             | 200         |
|    policy_gradient_loss  | -0.00205    |
|    std                   | 1.04        |
|    value_loss            | 298         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0731       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0731       |
| reward                   | -0.46483234  |
| rollout/                 |              |
|    ep_len_mean           | 937          |
|    ep_rew_mean           | -901         |
| time/                    |              |
|    fps                   | 42           |
|    iterations            | 22           |
|    time_elapsed          | 1065         |
|    total_timesteps       | 45056        |
| train/                   |              |
|    approx_kl             | 0.0046246517 |
|    clip_fraction         | 0.0409       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.62         |
|    cost_value_loss       | 5.92         |
|    cost_values           | 0.999        |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.0135       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 104          |
|    n_updates             | 210          |
|    policy_gradient_loss  | -0.00419     |
|    std                   | 1.04         |
|    value_loss            | 224          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.246        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.246        |
| reward                   | -0.39861318  |
| rollout/                 |              |
|    ep_len_mean           | 939          |
|    ep_rew_mean           | -900         |
| time/                    |              |
|    fps                   | 41           |
|    iterations            | 23           |
|    time_elapsed          | 1138         |
|    total_timesteps       | 47104        |
| train/                   |              |
|    approx_kl             | 0.0040837987 |
|    clip_fraction         | 0.0389       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.17         |
|    cost_value_loss       | 1.51         |
|    cost_values           | 0.99         |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.013        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 79.4         |
|    n_updates             | 220          |
|    policy_gradient_loss  | -0.0036      |
|    std                   | 1.04         |
|    value_loss            | 169          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.42         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.42         |
| reward                   | -0.36375356  |
| rollout/                 |              |
|    ep_len_mean           | 942          |
|    ep_rew_mean           | -896         |
| time/                    |              |
|    fps                   | 40           |
|    iterations            | 24           |
|    time_elapsed          | 1221         |
|    total_timesteps       | 49152        |
| train/                   |              |
|    approx_kl             | 0.0034822603 |
|    clip_fraction         | 0.019        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.91         |
|    cost_value_loss       | 6.98         |
|    cost_values           | 0.998        |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.0173       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 69.7         |
|    n_updates             | 230          |
|    policy_gradient_loss  | -0.00363     |
|    std                   | 1.04         |
|    value_loss            | 140          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.746       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.746       |
| reward                   | -0.7653949  |
| rollout/                 |             |
|    ep_len_mean           | 944         |
|    ep_rew_mean           | -896        |
| time/                    |             |
|    fps                   | 39          |
|    iterations            | 25          |
|    time_elapsed          | 1308        |
|    total_timesteps       | 51200       |
| train/                   |             |
|    approx_kl             | 0.002280665 |
|    clip_fraction         | 0.00732     |
|    clip_range            | 0.2         |
|    cost_returns          | 2           |
|    cost_value_loss       | 9.48        |
|    cost_values           | 1           |
|    entropy               | -2.9        |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.0182      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 54.3        |
|    n_updates             | 240         |
|    policy_gradient_loss  | -0.00305    |
|    std                   | 1.03        |
|    value_loss            | 108         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.506        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.506        |
| reward                   | -0.47177044  |
| rollout/                 |              |
|    ep_len_mean           | 946          |
|    ep_rew_mean           | -901         |
| time/                    |              |
|    fps                   | 38           |
|    iterations            | 26           |
|    time_elapsed          | 1387         |
|    total_timesteps       | 53248        |
| train/                   |              |
|    approx_kl             | 0.0038996174 |
|    clip_fraction         | 0.0539       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.99         |
|    cost_value_loss       | 8.37         |
|    cost_values           | 1            |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.0115       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 74.6         |
|    n_updates             | 250          |
|    policy_gradient_loss  | -0.00559     |
|    std                   | 1.03         |
|    value_loss            | 157          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.16         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.16         |
| reward                   | -0.85339177  |
| rollout/                 |              |
|    ep_len_mean           | 932          |
|    ep_rew_mean           | -878         |
| time/                    |              |
|    fps                   | 37           |
|    iterations            | 27           |
|    time_elapsed          | 1470         |
|    total_timesteps       | 55296        |
| train/                   |              |
|    approx_kl             | 0.0033080277 |
|    clip_fraction         | 0.0174       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.987        |
|    cost_value_loss       | 0.959        |
|    cost_values           | 0.987        |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.00571      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 105          |
|    n_updates             | 260          |
|    policy_gradient_loss  | -0.00195     |
|    std                   | 1.04         |
|    value_loss            | 216          |
-------------------------------------------
-----------------------------------------
| avg_speed                | 1          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 1          |
| reward                   | -0.452021  |
| rollout/                 |            |
|    ep_len_mean           | 935        |
|    ep_rew_mean           | -876       |
| time/                    |            |
|    fps                   | 36         |
|    iterations            | 28         |
|    time_elapsed          | 1561       |
|    total_timesteps       | 57344      |
| train/                   |            |
|    approx_kl             | 0.00488035 |
|    clip_fraction         | 0.0524     |
|    clip_range            | 0.2        |
|    cost_returns          | 2.06       |
|    cost_value_loss       | 7.4        |
|    cost_values           | 1          |
|    entropy               | -2.9       |
|    entropy_loss          | -2.91      |
|    explained_variance    | 0.000429   |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 29.7       |
|    n_updates             | 270        |
|    policy_gradient_loss  | -0.00477   |
|    std                   | 1.03       |
|    value_loss            | 63         |
-----------------------------------------
-------------------------------------------
| avg_speed                | 1.51         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.51         |
| reward                   | -0.813343    |
| rollout/                 |              |
|    ep_len_mean           | 937          |
|    ep_rew_mean           | -865         |
| time/                    |              |
|    fps                   | 35           |
|    iterations            | 29           |
|    time_elapsed          | 1659         |
|    total_timesteps       | 59392        |
| train/                   |              |
|    approx_kl             | 0.0043140636 |
|    clip_fraction         | 0.0231       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.28         |
|    cost_value_loss       | 11.2         |
|    cost_values           | 1            |
|    entropy               | -2.91        |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.0163       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 55.5         |
|    n_updates             | 280          |
|    policy_gradient_loss  | -0.00343     |
|    std                   | 1.04         |
|    value_loss            | 111          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.459       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.459       |
| reward                   | -0.45708483 |
| rollout/                 |             |
|    ep_len_mean           | 939         |
|    ep_rew_mean           | -857        |
| time/                    |             |
|    fps                   | 34          |
|    iterations            | 30          |
|    time_elapsed          | 1756        |
|    total_timesteps       | 61440       |
| train/                   |             |
|    approx_kl             | 0.005074639 |
|    clip_fraction         | 0.0493      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.28        |
|    cost_value_loss       | 8.85        |
|    cost_values           | 1           |
|    entropy               | -2.91       |
|    entropy_loss          | -2.91       |
|    explained_variance    | -0.0566     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17.7        |
|    n_updates             | 290         |
|    policy_gradient_loss  | -0.00651    |
|    std                   | 1.04        |
|    value_loss            | 30          |
------------------------------------------
------------------------------------------
| avg_speed                | 5.3         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.3         |
| reward                   | -0.89457667 |
| rollout/                 |             |
|    ep_len_mean           | 940         |
|    ep_rew_mean           | -850        |
| time/                    |             |
|    fps                   | 34          |
|    iterations            | 31          |
|    time_elapsed          | 1854        |
|    total_timesteps       | 63488       |
| train/                   |             |
|    approx_kl             | 0.004757043 |
|    clip_fraction         | 0.0437      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.56        |
|    cost_value_loss       | 13.3        |
|    cost_values           | 1           |
|    entropy               | -2.92       |
|    entropy_loss          | -2.91       |
|    explained_variance    | -0.0187     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 20.5        |
|    n_updates             | 300         |
|    policy_gradient_loss  | -0.00678    |
|    std                   | 1.04        |
|    value_loss            | 31.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.725       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.725       |
| reward                   | -0.53546077 |
| rollout/                 |             |
|    ep_len_mean           | 922         |
|    ep_rew_mean           | -832        |
| time/                    |             |
|    fps                   | 33          |
|    iterations            | 32          |
|    time_elapsed          | 1949        |
|    total_timesteps       | 65536       |
| train/                   |             |
|    approx_kl             | 0.004209402 |
|    clip_fraction         | 0.0374      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.8         |
|    cost_value_loss       | 18.4        |
|    cost_values           | 1           |
|    entropy               | -2.92       |
|    entropy_loss          | -2.92       |
|    explained_variance    | 0.0395      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 25.3        |
|    n_updates             | 310         |
|    policy_gradient_loss  | -0.00384    |
|    std                   | 1.04        |
|    value_loss            | 40.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.28        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.28        |
| reward                   | -0.52264726 |
| rollout/                 |             |
|    ep_len_mean           | 924         |
|    ep_rew_mean           | -824        |
| time/                    |             |
|    fps                   | 33          |
|    iterations            | 33          |
|    time_elapsed          | 2047        |
|    total_timesteps       | 67584       |
| train/                   |             |
|    approx_kl             | 0.003378105 |
|    clip_fraction         | 0.0337      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.68        |
|    cost_value_loss       | 16.6        |
|    cost_values           | 1           |
|    entropy               | -2.92       |
|    entropy_loss          | -2.92       |
|    explained_variance    | 0.006       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 77.8        |
|    n_updates             | 320         |
|    policy_gradient_loss  | -0.00442    |
|    std                   | 1.04        |
|    value_loss            | 153         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.183        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.183        |
| reward                   | -0.43765366  |
| rollout/                 |              |
|    ep_len_mean           | 926          |
|    ep_rew_mean           | -824         |
| time/                    |              |
|    fps                   | 32           |
|    iterations            | 34           |
|    time_elapsed          | 2151         |
|    total_timesteps       | 69632        |
| train/                   |              |
|    approx_kl             | 0.0034603712 |
|    clip_fraction         | 0.0214       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.7          |
|    cost_value_loss       | 15.3         |
|    cost_values           | 1.05         |
|    entropy               | -2.94        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.0123       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.2         |
|    n_updates             | 330          |
|    policy_gradient_loss  | -0.00281     |
|    std                   | 1.05         |
|    value_loss            | 16.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.19         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 1.19         |
| reward                   | -0.3621649   |
| rollout/                 |              |
|    ep_len_mean           | 928          |
|    ep_rew_mean           | -822         |
| time/                    |              |
|    fps                   | 31           |
|    iterations            | 35           |
|    time_elapsed          | 2260         |
|    total_timesteps       | 71680        |
| train/                   |              |
|    approx_kl             | 0.0034975037 |
|    clip_fraction         | 0.0295       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.93         |
|    cost_value_loss       | 5.25         |
|    cost_values           | 1.04         |
|    entropy               | -2.95        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.00471      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 78.8         |
|    n_updates             | 340          |
|    policy_gradient_loss  | -0.00334     |
|    std                   | 1.06         |
|    value_loss            | 141          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.13         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.13         |
| reward                   | -0.8696934   |
| rollout/                 |              |
|    ep_len_mean           | 930          |
|    ep_rew_mean           | -819         |
| time/                    |              |
|    fps                   | 31           |
|    iterations            | 36           |
|    time_elapsed          | 2370         |
|    total_timesteps       | 73728        |
| train/                   |              |
|    approx_kl             | 0.0036912034 |
|    clip_fraction         | 0.027        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.45         |
|    cost_value_loss       | 4.21         |
|    cost_values           | 0.997        |
|    entropy               | -2.96        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.00489      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 38.8         |
|    n_updates             | 350          |
|    policy_gradient_loss  | -0.00416     |
|    std                   | 1.07         |
|    value_loss            | 74.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.32        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.32        |
| reward                   | -0.33279637 |
| rollout/                 |             |
|    ep_len_mean           | 931         |
|    ep_rew_mean           | -822        |
| time/                    |             |
|    fps                   | 30          |
|    iterations            | 37          |
|    time_elapsed          | 2482        |
|    total_timesteps       | 75776       |
| train/                   |             |
|    approx_kl             | 0.006076566 |
|    clip_fraction         | 0.0589      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.74        |
|    cost_value_loss       | 6.13        |
|    cost_values           | 1           |
|    entropy               | -2.96       |
|    entropy_loss          | -2.96       |
|    explained_variance    | 0.00541     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 32.4        |
|    n_updates             | 360         |
|    policy_gradient_loss  | -0.00502    |
|    std                   | 1.06        |
|    value_loss            | 63.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -1.3059099   |
| rollout/                 |              |
|    ep_len_mean           | 933          |
|    ep_rew_mean           | -820         |
| time/                    |              |
|    fps                   | 30           |
|    iterations            | 38           |
|    time_elapsed          | 2593         |
|    total_timesteps       | 77824        |
| train/                   |              |
|    approx_kl             | 0.0051471516 |
|    clip_fraction         | 0.0272       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.7          |
|    cost_value_loss       | 6.72         |
|    cost_values           | 1            |
|    entropy               | -2.96        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.006        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 54           |
|    n_updates             | 370          |
|    policy_gradient_loss  | -0.00444     |
|    std                   | 1.07         |
|    value_loss            | 107          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.419       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.419       |
| reward                   | -0.4104058  |
| rollout/                 |             |
|    ep_len_mean           | 935         |
|    ep_rew_mean           | -828        |
| time/                    |             |
|    fps                   | 29          |
|    iterations            | 39          |
|    time_elapsed          | 2710        |
|    total_timesteps       | 79872       |
| train/                   |             |
|    approx_kl             | 0.002532745 |
|    clip_fraction         | 0.0122      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.09        |
|    cost_value_loss       | 0.935       |
|    cost_values           | 0.998       |
|    entropy               | -2.96       |
|    entropy_loss          | -2.96       |
|    explained_variance    | 0.00408     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 43.1        |
|    n_updates             | 380         |
|    policy_gradient_loss  | -0.00272    |
|    std                   | 1.06        |
|    value_loss            | 87.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.612        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.612        |
| reward                   | -0.29525807  |
| rollout/                 |              |
|    ep_len_mean           | 936          |
|    ep_rew_mean           | -823         |
| time/                    |              |
|    fps                   | 28           |
|    iterations            | 40           |
|    time_elapsed          | 2831         |
|    total_timesteps       | 81920        |
| train/                   |              |
|    approx_kl             | 0.0024213274 |
|    clip_fraction         | 0.0138       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.74         |
|    cost_value_loss       | 8.33         |
|    cost_values           | 1            |
|    entropy               | -2.96        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.00353      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 103          |
|    n_updates             | 390          |
|    policy_gradient_loss  | -0.00146     |
|    std                   | 1.06         |
|    value_loss            | 201          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.73         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 2.73         |
| reward                   | -0.42168248  |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -820         |
| time/                    |              |
|    fps                   | 28           |
|    iterations            | 41           |
|    time_elapsed          | 2952         |
|    total_timesteps       | 83968        |
| train/                   |              |
|    approx_kl             | 0.0050569177 |
|    clip_fraction         | 0.0266       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.8          |
|    cost_value_loss       | 5.65         |
|    cost_values           | 1            |
|    entropy               | -2.97        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.011        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21           |
|    n_updates             | 400          |
|    policy_gradient_loss  | -0.00352     |
|    std                   | 1.07         |
|    value_loss            | 36.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.2802446  |
| rollout/                 |             |
|    ep_len_mean           | 939         |
|    ep_rew_mean           | -820        |
| time/                    |             |
|    fps                   | 27          |
|    iterations            | 42          |
|    time_elapsed          | 3075        |
|    total_timesteps       | 86016       |
| train/                   |             |
|    approx_kl             | 0.005016759 |
|    clip_fraction         | 0.0307      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.16        |
|    cost_value_loss       | 11.3        |
|    cost_values           | 1           |
|    entropy               | -2.97       |
|    entropy_loss          | -2.97       |
|    explained_variance    | 0.0184      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 30.6        |
|    n_updates             | 410         |
|    policy_gradient_loss  | -0.0038     |
|    std                   | 1.07        |
|    value_loss            | 53          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.85531914  |
| rollout/                 |              |
|    ep_len_mean           | 940          |
|    ep_rew_mean           | -821         |
| time/                    |              |
|    fps                   | 27           |
|    iterations            | 43           |
|    time_elapsed          | 3193         |
|    total_timesteps       | 88064        |
| train/                   |              |
|    approx_kl             | 0.0038616466 |
|    clip_fraction         | 0.0244       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.16         |
|    cost_value_loss       | 2.54         |
|    cost_values           | 0.997        |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.00387      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 48           |
|    n_updates             | 420          |
|    policy_gradient_loss  | -0.0039      |
|    std                   | 1.07         |
|    value_loss            | 104          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.1476251   |
| rollout/                 |              |
|    ep_len_mean           | 942          |
|    ep_rew_mean           | -824         |
| time/                    |              |
|    fps                   | 27           |
|    iterations            | 44           |
|    time_elapsed          | 3316         |
|    total_timesteps       | 90112        |
| train/                   |              |
|    approx_kl             | 0.0033397193 |
|    clip_fraction         | 0.0265       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.08         |
|    cost_value_loss       | 1.26         |
|    cost_values           | 0.995        |
|    entropy               | -2.98        |
|    entropy_loss          | -2.98        |
|    explained_variance    | 0.00172      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 48.3         |
|    n_updates             | 430          |
|    policy_gradient_loss  | -0.00475     |
|    std                   | 1.07         |
|    value_loss            | 94.8         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8.04       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.04       |
| reward                   | -1.1612428 |
| rollout/                 |            |
|    ep_len_mean           | 934        |
|    ep_rew_mean           | -818       |
| time/                    |            |
|    fps                   | 26         |
|    iterations            | 45         |
|    time_elapsed          | 3443       |
|    total_timesteps       | 92160      |
| train/                   |            |
|    approx_kl             | 0.00440484 |
|    clip_fraction         | 0.0357     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.42       |
|    cost_value_loss       | 4.95       |
|    cost_values           | 1          |
|    entropy               | -2.98      |
|    entropy_loss          | -2.98      |
|    explained_variance    | 0.00794    |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 46.3       |
|    n_updates             | 440        |
|    policy_gradient_loss  | -0.00456   |
|    std                   | 1.07       |
|    value_loss            | 98         |
-----------------------------------------
-------------------------------------------
| avg_speed                | 7.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.82         |
| reward                   | -0.7154175   |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -822         |
| time/                    |              |
|    fps                   | 26           |
|    iterations            | 46           |
|    time_elapsed          | 3576         |
|    total_timesteps       | 94208        |
| train/                   |              |
|    approx_kl             | 0.0066522746 |
|    clip_fraction         | 0.0489       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.38         |
|    cost_value_loss       | 2.71         |
|    cost_values           | 0.999        |
|    entropy               | -2.98        |
|    entropy_loss          | -2.98        |
|    explained_variance    | 0.022        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 52.5         |
|    n_updates             | 450          |
|    policy_gradient_loss  | -0.00364     |
|    std                   | 1.07         |
|    value_loss            | 107          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.7361057   |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -813         |
| time/                    |              |
|    fps                   | 25           |
|    iterations            | 47           |
|    time_elapsed          | 3711         |
|    total_timesteps       | 96256        |
| train/                   |              |
|    approx_kl             | 0.0049722716 |
|    clip_fraction         | 0.038        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.71         |
|    cost_value_loss       | 6.6          |
|    cost_values           | 1            |
|    entropy               | -2.98        |
|    entropy_loss          | -2.98        |
|    explained_variance    | 0.0155       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 59.4         |
|    n_updates             | 460          |
|    policy_gradient_loss  | -0.00519     |
|    std                   | 1.07         |
|    value_loss            | 122          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.75         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.75         |
| reward                   | -0.7604048   |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -820         |
| time/                    |              |
|    fps                   | 25           |
|    iterations            | 48           |
|    time_elapsed          | 3850         |
|    total_timesteps       | 98304        |
| train/                   |              |
|    approx_kl             | 0.0059999805 |
|    clip_fraction         | 0.0268       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.2          |
|    cost_value_loss       | 12.8         |
|    cost_values           | 1.01         |
|    entropy               | -2.98        |
|    entropy_loss          | -2.98        |
|    explained_variance    | 0.00835      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 25.1         |
|    n_updates             | 470          |
|    policy_gradient_loss  | -0.00244     |
|    std                   | 1.07         |
|    value_loss            | 44.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.9061533   |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -807         |
| time/                    |              |
|    fps                   | 25           |
|    iterations            | 49           |
|    time_elapsed          | 3989         |
|    total_timesteps       | 100352       |
| train/                   |              |
|    approx_kl             | 0.0032609291 |
|    clip_fraction         | 0.0207       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.79         |
|    cost_value_loss       | 8.52         |
|    cost_values           | 1            |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.00477      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 58.2         |
|    n_updates             | 480          |
|    policy_gradient_loss  | -0.00349     |
|    std                   | 1.07         |
|    value_loss            | 116          |
-------------------------------------------
Directory created: tests/PPOL_New/models/ppol-extra-obs/2fzzfvlw
-----------------------------------
| avg_speed          | 7.81       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 7.81       |
| reward             | -1.0356379 |
| rollout/           |            |
|    ep_len_mean     | 943        |
|    ep_rew_mean     | -803       |
| time/              |            |
|    fps             | 14         |
|    iterations      | 1          |
|    time_elapsed    | 142        |
|    total_timesteps | 102400     |
-----------------------------------
------------------------------------------
| avg_speed                | 7.88        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.88        |
| reward                   | -0.8488812  |
| rollout/                 |             |
|    ep_len_mean           | 943         |
|    ep_rew_mean           | -801        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 2           |
|    time_elapsed          | 295         |
|    total_timesteps       | 104448      |
| train/                   |             |
|    approx_kl             | 0.005485795 |
|    clip_fraction         | 0.0333      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.82        |
|    cost_value_loss       | 8.83        |
|    cost_values           | 1           |
|    entropy               | -2.97       |
|    entropy_loss          | -2.97       |
|    explained_variance    | 0.0102      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 40.8        |
|    n_updates             | 500         |
|    policy_gradient_loss  | -0.00498    |
|    std                   | 1.07        |
|    value_loss            | 76.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -1.5782572   |
| rollout/                 |              |
|    ep_len_mean           | 949          |
|    ep_rew_mean           | -804         |
| time/                    |              |
|    fps                   | 14           |
|    iterations            | 3            |
|    time_elapsed          | 436          |
|    total_timesteps       | 106496       |
| train/                   |              |
|    approx_kl             | 0.0060014795 |
|    clip_fraction         | 0.0569       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.47         |
|    cost_value_loss       | 13.3         |
|    cost_values           | 1.04         |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.0137       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.8         |
|    n_updates             | 510          |
|    policy_gradient_loss  | -0.00501     |
|    std                   | 1.07         |
|    value_loss            | 17.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.83513653  |
| rollout/                 |              |
|    ep_len_mean           | 949          |
|    ep_rew_mean           | -811         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 4            |
|    time_elapsed          | 587          |
|    total_timesteps       | 108544       |
| train/                   |              |
|    approx_kl             | 0.0048632575 |
|    clip_fraction         | 0.0502       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.15         |
|    cost_value_loss       | 0.844        |
|    cost_values           | 0.992        |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.00302      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 100          |
|    n_updates             | 520          |
|    policy_gradient_loss  | -0.00469     |
|    std                   | 1.07         |
|    value_loss            | 207          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.55         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.55         |
| reward                   | -0.51939076  |
| rollout/                 |              |
|    ep_len_mean           | 949          |
|    ep_rew_mean           | -813         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 5            |
|    time_elapsed          | 746          |
|    total_timesteps       | 110592       |
| train/                   |              |
|    approx_kl             | 0.0039597726 |
|    clip_fraction         | 0.0367       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.85         |
|    cost_value_loss       | 9.49         |
|    cost_values           | 0.969        |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.00629      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 53.5         |
|    n_updates             | 530          |
|    policy_gradient_loss  | -0.00554     |
|    std                   | 1.07         |
|    value_loss            | 109          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.381        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.381        |
| reward                   | -0.34391233  |
| rollout/                 |              |
|    ep_len_mean           | 949          |
|    ep_rew_mean           | -815         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 6            |
|    time_elapsed          | 899          |
|    total_timesteps       | 112640       |
| train/                   |              |
|    approx_kl             | 0.0038939328 |
|    clip_fraction         | 0.0302       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.48         |
|    cost_value_loss       | 5.01         |
|    cost_values           | 1            |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.00386      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 65.1         |
|    n_updates             | 540          |
|    policy_gradient_loss  | -0.00443     |
|    std                   | 1.07         |
|    value_loss            | 135          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.35         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.35         |
| reward                   | -0.821342    |
| rollout/                 |              |
|    ep_len_mean           | 949          |
|    ep_rew_mean           | -803         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 7            |
|    time_elapsed          | 1071         |
|    total_timesteps       | 114688       |
| train/                   |              |
|    approx_kl             | 0.0047131064 |
|    clip_fraction         | 0.0345       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.42         |
|    cost_value_loss       | 3.08         |
|    cost_values           | 0.999        |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.00452      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 38.3         |
|    n_updates             | 550          |
|    policy_gradient_loss  | -0.00435     |
|    std                   | 1.07         |
|    value_loss            | 75.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.06         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.06         |
| reward                   | -0.79025316  |
| rollout/                 |              |
|    ep_len_mean           | 940          |
|    ep_rew_mean           | -806         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 8            |
|    time_elapsed          | 1227         |
|    total_timesteps       | 116736       |
| train/                   |              |
|    approx_kl             | 0.0065455534 |
|    clip_fraction         | 0.0756       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.69         |
|    cost_value_loss       | 4.75         |
|    cost_values           | 1            |
|    entropy               | -2.96        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.0149       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11           |
|    n_updates             | 560          |
|    policy_gradient_loss  | -0.00676     |
|    std                   | 1.06         |
|    value_loss            | 19.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.85        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.85        |
| reward                   | -0.98349756 |
| rollout/                 |             |
|    ep_len_mean           | 940         |
|    ep_rew_mean           | -808        |
| time/                    |             |
|    fps                   | 13          |
|    iterations            | 9           |
|    time_elapsed          | 1406        |
|    total_timesteps       | 118784      |
| train/                   |             |
|    approx_kl             | 0.00441268  |
|    clip_fraction         | 0.0298      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.3         |
|    cost_value_loss       | 2.61        |
|    cost_values           | 0.995       |
|    entropy               | -2.96       |
|    entropy_loss          | -2.96       |
|    explained_variance    | 0.00427     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 102         |
|    n_updates             | 570         |
|    policy_gradient_loss  | -0.00317    |
|    std                   | 1.06        |
|    value_loss            | 210         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.49172428  |
| rollout/                 |              |
|    ep_len_mean           | 940          |
|    ep_rew_mean           | -809         |
| time/                    |              |
|    fps                   | 13           |
|    iterations            | 10           |
|    time_elapsed          | 1565         |
|    total_timesteps       | 120832       |
| train/                   |              |
|    approx_kl             | 0.0047729523 |
|    clip_fraction         | 0.0446       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.16         |
|    cost_value_loss       | 1.52         |
|    cost_values           | 0.999        |
|    entropy               | -2.96        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.00475      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 101          |
|    n_updates             | 580          |
|    policy_gradient_loss  | -0.0057      |
|    std                   | 1.06         |
|    value_loss            | 206          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.2093627   |
| rollout/                 |              |
|    ep_len_mean           | 936          |
|    ep_rew_mean           | -808         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 11           |
|    time_elapsed          | 1747         |
|    total_timesteps       | 122880       |
| train/                   |              |
|    approx_kl             | 0.0050259866 |
|    clip_fraction         | 0.0308       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.58         |
|    cost_value_loss       | 7.45         |
|    cost_values           | 1            |
|    entropy               | -2.95        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.0071       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 83           |
|    n_updates             | 590          |
|    policy_gradient_loss  | -0.00531     |
|    std                   | 1.06         |
|    value_loss            | 175          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.82484734 |
| rollout/                 |             |
|    ep_len_mean           | 936         |
|    ep_rew_mean           | -811        |
| time/                    |             |
|    fps                   | 12          |
|    iterations            | 12          |
|    time_elapsed          | 1918        |
|    total_timesteps       | 124928      |
| train/                   |             |
|    approx_kl             | 0.00312055  |
|    clip_fraction         | 0.0234      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.48        |
|    cost_value_loss       | 3.17        |
|    cost_values           | 1           |
|    entropy               | -2.95       |
|    entropy_loss          | -2.95       |
|    explained_variance    | 0.00409     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 66.9        |
|    n_updates             | 600         |
|    policy_gradient_loss  | -0.00357    |
|    std                   | 1.06        |
|    value_loss            | 134         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.89         |
| reward                   | -1.5397873   |
| rollout/                 |              |
|    ep_len_mean           | 944          |
|    ep_rew_mean           | -812         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 13           |
|    time_elapsed          | 2094         |
|    total_timesteps       | 126976       |
| train/                   |              |
|    approx_kl             | 0.0054144254 |
|    clip_fraction         | 0.0329       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.8          |
|    cost_value_loss       | 7.98         |
|    cost_values           | 1            |
|    entropy               | -2.95        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.00649      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 43.7         |
|    n_updates             | 610          |
|    policy_gradient_loss  | -0.0044      |
|    std                   | 1.06         |
|    value_loss            | 77.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.9919979  |
| rollout/                 |             |
|    ep_len_mean           | 944         |
|    ep_rew_mean           | -821        |
| time/                    |             |
|    fps                   | 12          |
|    iterations            | 14          |
|    time_elapsed          | 2281        |
|    total_timesteps       | 129024      |
| train/                   |             |
|    approx_kl             | 0.005975523 |
|    clip_fraction         | 0.0425      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.37        |
|    cost_value_loss       | 1.56        |
|    cost_values           | 0.999       |
|    entropy               | -2.95       |
|    entropy_loss          | -2.95       |
|    explained_variance    | 0.00641     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 27.3        |
|    n_updates             | 620         |
|    policy_gradient_loss  | -0.00525    |
|    std                   | 1.06        |
|    value_loss            | 56.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.9978496   |
| rollout/                 |              |
|    ep_len_mean           | 944          |
|    ep_rew_mean           | -819         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 15           |
|    time_elapsed          | 2455         |
|    total_timesteps       | 131072       |
| train/                   |              |
|    approx_kl             | 0.0050701937 |
|    clip_fraction         | 0.0293       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.42         |
|    cost_value_loss       | 3.52         |
|    cost_values           | 1            |
|    entropy               | -2.95        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.00448      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 96.1         |
|    n_updates             | 630          |
|    policy_gradient_loss  | -0.00469     |
|    std                   | 1.06         |
|    value_loss            | 194          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.4965439  |
| rollout/                 |             |
|    ep_len_mean           | 944         |
|    ep_rew_mean           | -825        |
| time/                    |             |
|    fps                   | 12          |
|    iterations            | 16          |
|    time_elapsed          | 2643        |
|    total_timesteps       | 133120      |
| train/                   |             |
|    approx_kl             | 0.007502526 |
|    clip_fraction         | 0.0564      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.37        |
|    cost_value_loss       | 1.94        |
|    cost_values           | 1           |
|    entropy               | -2.95       |
|    entropy_loss          | -2.95       |
|    explained_variance    | 0.00669     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.1        |
|    n_updates             | 640         |
|    policy_gradient_loss  | -0.0085     |
|    std                   | 1.06        |
|    value_loss            | 28.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.4541637   |
| rollout/                 |              |
|    ep_len_mean           | 944          |
|    ep_rew_mean           | -827         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 17           |
|    time_elapsed          | 2829         |
|    total_timesteps       | 135168       |
| train/                   |              |
|    approx_kl             | 0.0032205726 |
|    clip_fraction         | 0.0306       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.37         |
|    cost_value_loss       | 3.34         |
|    cost_values           | 0.998        |
|    entropy               | -2.94        |
|    entropy_loss          | -2.95        |
|    explained_variance    | 0.00568      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 50.7         |
|    n_updates             | 650          |
|    policy_gradient_loss  | -0.00446     |
|    std                   | 1.05         |
|    value_loss            | 103          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.99         |
| reward                   | -0.31110922  |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -839         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 18           |
|    time_elapsed          | 3016         |
|    total_timesteps       | 137216       |
| train/                   |              |
|    approx_kl             | 0.0035279554 |
|    clip_fraction         | 0.0574       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.13         |
|    cost_value_loss       | 1.21         |
|    cost_values           | 1            |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.00466      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 52.1         |
|    n_updates             | 660          |
|    policy_gradient_loss  | -0.0059      |
|    std                   | 1.05         |
|    value_loss            | 109          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.17         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.17         |
| reward                   | -0.5601729   |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -842         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 19           |
|    time_elapsed          | 3214         |
|    total_timesteps       | 139264       |
| train/                   |              |
|    approx_kl             | 0.0054448918 |
|    clip_fraction         | 0.0314       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.16         |
|    cost_value_loss       | 1.89         |
|    cost_values           | 0.999        |
|    entropy               | -2.93        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.00426      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 63.1         |
|    n_updates             | 670          |
|    policy_gradient_loss  | -0.00561     |
|    std                   | 1.05         |
|    value_loss            | 134          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.339        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.339        |
| reward                   | -0.5446537   |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -841         |
| time/                    |              |
|    fps                   | 12           |
|    iterations            | 20           |
|    time_elapsed          | 3406         |
|    total_timesteps       | 141312       |
| train/                   |              |
|    approx_kl             | 0.0045623044 |
|    clip_fraction         | 0.0498       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.16         |
|    cost_value_loss       | 2.76         |
|    cost_values           | 0.997        |
|    entropy               | -2.93        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.00418      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 52           |
|    n_updates             | 680          |
|    policy_gradient_loss  | -0.00412     |
|    std                   | 1.05         |
|    value_loss            | 113          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.31         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.31         |
| reward                   | -0.6624175   |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -847         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 21           |
|    time_elapsed          | 3606         |
|    total_timesteps       | 143360       |
| train/                   |              |
|    approx_kl             | 0.0039872965 |
|    clip_fraction         | 0.0298       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.29         |
|    cost_value_loss       | 3.42         |
|    cost_values           | 0.999        |
|    entropy               | -2.94        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.00395      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 77.8         |
|    n_updates             | 690          |
|    policy_gradient_loss  | -0.0041      |
|    std                   | 1.05         |
|    value_loss            | 160          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.85         |
| reward                   | -0.6834839   |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -852         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 22           |
|    time_elapsed          | 3812         |
|    total_timesteps       | 145408       |
| train/                   |              |
|    approx_kl             | 0.0053946483 |
|    clip_fraction         | 0.045        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.3          |
|    cost_value_loss       | 3.53         |
|    cost_values           | 0.995        |
|    entropy               | -2.93        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.00848      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 40.3         |
|    n_updates             | 700          |
|    policy_gradient_loss  | -0.00545     |
|    std                   | 1.05         |
|    value_loss            | 83.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5388754  |
| rollout/                 |             |
|    ep_len_mean           | 943         |
|    ep_rew_mean           | -853        |
| time/                    |             |
|    fps                   | 11          |
|    iterations            | 23          |
|    time_elapsed          | 4022        |
|    total_timesteps       | 147456      |
| train/                   |             |
|    approx_kl             | 0.004589191 |
|    clip_fraction         | 0.0174      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.07        |
|    cost_value_loss       | 1.43        |
|    cost_values           | 0.999       |
|    entropy               | -2.92       |
|    entropy_loss          | -2.93       |
|    explained_variance    | 0.00528     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 44.7        |
|    n_updates             | 710         |
|    policy_gradient_loss  | -0.00363    |
|    std                   | 1.04        |
|    value_loss            | 95.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.1518896   |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -856         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 24           |
|    time_elapsed          | 4233         |
|    total_timesteps       | 149504       |
| train/                   |              |
|    approx_kl             | 0.0049582627 |
|    clip_fraction         | 0.0349       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.31         |
|    cost_value_loss       | 3.71         |
|    cost_values           | 0.997        |
|    entropy               | -2.91        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.00919      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 36.5         |
|    n_updates             | 720          |
|    policy_gradient_loss  | -0.00485     |
|    std                   | 1.04         |
|    value_loss            | 74.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -0.7982206  |
| rollout/                 |             |
|    ep_len_mean           | 953         |
|    ep_rew_mean           | -866        |
| time/                    |             |
|    fps                   | 11          |
|    iterations            | 25          |
|    time_elapsed          | 4438        |
|    total_timesteps       | 151552      |
| train/                   |             |
|    approx_kl             | 0.005239605 |
|    clip_fraction         | 0.0513      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.31        |
|    cost_value_loss       | 1.68        |
|    cost_values           | 0.999       |
|    entropy               | -2.91       |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.00562     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17.9        |
|    n_updates             | 730         |
|    policy_gradient_loss  | -0.00624    |
|    std                   | 1.04        |
|    value_loss            | 36.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.9281277   |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -867         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 26           |
|    time_elapsed          | 4652         |
|    total_timesteps       | 153600       |
| train/                   |              |
|    approx_kl             | 0.0045425654 |
|    clip_fraction         | 0.0264       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.39         |
|    cost_value_loss       | 2.92         |
|    cost_values           | 0.998        |
|    entropy               | -2.9         |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.00741      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 23.2         |
|    n_updates             | 740          |
|    policy_gradient_loss  | -0.00446     |
|    std                   | 1.03         |
|    value_loss            | 44.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -1.0403707  |
| rollout/                 |             |
|    ep_len_mean           | 953         |
|    ep_rew_mean           | -872        |
| time/                    |             |
|    fps                   | 11          |
|    iterations            | 27          |
|    time_elapsed          | 4867        |
|    total_timesteps       | 155648      |
| train/                   |             |
|    approx_kl             | 0.009393845 |
|    clip_fraction         | 0.091       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.81        |
|    cost_value_loss       | 3.26        |
|    cost_values           | 1.12        |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | 0.0165      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.61        |
|    n_updates             | 750         |
|    policy_gradient_loss  | -0.00794    |
|    std                   | 1.03        |
|    value_loss            | 6.7         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.75        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.75        |
| reward                   | -0.79391354 |
| rollout/                 |             |
|    ep_len_mean           | 953         |
|    ep_rew_mean           | -877        |
| time/                    |             |
|    fps                   | 11          |
|    iterations            | 28          |
|    time_elapsed          | 5081        |
|    total_timesteps       | 157696      |
| train/                   |             |
|    approx_kl             | 0.005505952 |
|    clip_fraction         | 0.0625      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.79        |
|    cost_value_loss       | 3.45        |
|    cost_values           | 1.18        |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | 0.00624     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17.1        |
|    n_updates             | 760         |
|    policy_gradient_loss  | -0.00523    |
|    std                   | 1.03        |
|    value_loss            | 32.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -0.82686335  |
| rollout/                 |              |
|    ep_len_mean           | 953          |
|    ep_rew_mean           | -876         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 29           |
|    time_elapsed          | 5302         |
|    total_timesteps       | 159744       |
| train/                   |              |
|    approx_kl             | 0.0065546217 |
|    clip_fraction         | 0.0495       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.41         |
|    cost_value_loss       | 2.69         |
|    cost_values           | 0.995        |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.00703      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.4         |
|    n_updates             | 770          |
|    policy_gradient_loss  | -0.00622     |
|    std                   | 1.03         |
|    value_loss            | 24.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.85         |
| reward                   | -0.95733744  |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -880         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 30           |
|    time_elapsed          | 5520         |
|    total_timesteps       | 161792       |
| train/                   |              |
|    approx_kl             | 0.0055570276 |
|    clip_fraction         | 0.0564       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.44         |
|    cost_value_loss       | 2.07         |
|    cost_values           | 1            |
|    entropy               | -2.89        |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.00843      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.1         |
|    n_updates             | 780          |
|    policy_gradient_loss  | -0.00736     |
|    std                   | 1.03         |
|    value_loss            | 18.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.87         |
| reward                   | -0.7756926   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -892         |
| time/                    |              |
|    fps                   | 11           |
|    iterations            | 31           |
|    time_elapsed          | 5740         |
|    total_timesteps       | 163840       |
| train/                   |              |
|    approx_kl             | 0.0064089578 |
|    clip_fraction         | 0.0674       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.55         |
|    cost_value_loss       | 2.52         |
|    cost_values           | 1.02         |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.0157       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.3         |
|    n_updates             | 790          |
|    policy_gradient_loss  | -0.00923     |
|    std                   | 1.03         |
|    value_loss            | 22.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -0.92386967  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -896         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 32           |
|    time_elapsed          | 5964         |
|    total_timesteps       | 165888       |
| train/                   |              |
|    approx_kl             | 0.0051027047 |
|    clip_fraction         | 0.0408       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.19         |
|    cost_value_loss       | 1.77         |
|    cost_values           | 0.988        |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.007        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.9         |
|    n_updates             | 800          |
|    policy_gradient_loss  | -0.00458     |
|    std                   | 1.03         |
|    value_loss            | 40.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.904645   |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -894        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 33          |
|    time_elapsed          | 6193        |
|    total_timesteps       | 167936      |
| train/                   |             |
|    approx_kl             | 0.012791503 |
|    clip_fraction         | 0.0836      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.27        |
|    cost_value_loss       | 2.2         |
|    cost_values           | 1.04        |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | 0.0061      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.71        |
|    n_updates             | 810         |
|    policy_gradient_loss  | -0.00802    |
|    std                   | 1.03        |
|    value_loss            | 8           |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0828472   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -893         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 34           |
|    time_elapsed          | 6420         |
|    total_timesteps       | 169984       |
| train/                   |              |
|    approx_kl             | 0.0044181217 |
|    clip_fraction         | 0.0701       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.14         |
|    cost_value_loss       | 0.786        |
|    cost_values           | 1.02         |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.00478      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.39         |
|    n_updates             | 820          |
|    policy_gradient_loss  | -0.0019      |
|    std                   | 1.03         |
|    value_loss            | 17.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.89298254  |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -895         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 35           |
|    time_elapsed          | 6643         |
|    total_timesteps       | 172032       |
| train/                   |              |
|    approx_kl             | 0.0051756366 |
|    clip_fraction         | 0.0434       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.16         |
|    cost_value_loss       | 1.88         |
|    cost_values           | 0.992        |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.0152       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.94         |
|    n_updates             | 830          |
|    policy_gradient_loss  | -0.00543     |
|    std                   | 1.02         |
|    value_loss            | 18.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.4182978   |
| rollout/                 |              |
|    ep_len_mean           | 969          |
|    ep_rew_mean           | -897         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 36           |
|    time_elapsed          | 6879         |
|    total_timesteps       | 174080       |
| train/                   |              |
|    approx_kl             | 0.0057043885 |
|    clip_fraction         | 0.055        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.52         |
|    cost_value_loss       | 3.17         |
|    cost_values           | 1            |
|    entropy               | -2.88        |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.00881      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.67         |
|    n_updates             | 840          |
|    policy_gradient_loss  | -0.007       |
|    std                   | 1.02         |
|    value_loss            | 18.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.9527773  |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -894        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 37          |
|    time_elapsed          | 7114        |
|    total_timesteps       | 176128      |
| train/                   |             |
|    approx_kl             | 0.004666499 |
|    clip_fraction         | 0.0349      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.09        |
|    cost_value_loss       | 0.857       |
|    cost_values           | 0.99        |
|    entropy               | -2.88       |
|    entropy_loss          | -2.88       |
|    explained_variance    | 0.00674     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 27          |
|    n_updates             | 850         |
|    policy_gradient_loss  | -0.00522    |
|    std                   | 1.02        |
|    value_loss            | 57.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.2726626  |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -895        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 38          |
|    time_elapsed          | 7343        |
|    total_timesteps       | 178176      |
| train/                   |             |
|    approx_kl             | 0.008446902 |
|    clip_fraction         | 0.0865      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.51        |
|    cost_value_loss       | 2.7         |
|    cost_values           | 1.01        |
|    entropy               | -2.88       |
|    entropy_loss          | -2.88       |
|    explained_variance    | 0.0133      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9           |
|    n_updates             | 860         |
|    policy_gradient_loss  | -0.009      |
|    std                   | 1.02        |
|    value_loss            | 15.8        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8.05       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.05       |
| reward                   | -1.2602744 |
| rollout/                 |            |
|    ep_len_mean           | 962        |
|    ep_rew_mean           | -896       |
| time/                    |            |
|    fps                   | 10         |
|    iterations            | 39         |
|    time_elapsed          | 7574       |
|    total_timesteps       | 180224     |
| train/                   |            |
|    approx_kl             | 0.00458531 |
|    clip_fraction         | 0.0258     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.23       |
|    cost_value_loss       | 1.88       |
|    cost_values           | 0.992      |
|    entropy               | -2.88      |
|    entropy_loss          | -2.88      |
|    explained_variance    | 0.0101     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 14.7       |
|    n_updates             | 870        |
|    policy_gradient_loss  | -0.00494   |
|    std                   | 1.02       |
|    value_loss            | 29.5       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.2372873  |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -901        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 40          |
|    time_elapsed          | 7790        |
|    total_timesteps       | 182272      |
| train/                   |             |
|    approx_kl             | 0.005847153 |
|    clip_fraction         | 0.0416      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.3         |
|    cost_value_loss       | 1.95        |
|    cost_values           | 1           |
|    entropy               | -2.87       |
|    entropy_loss          | -2.88       |
|    explained_variance    | 0.00792     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 27.6        |
|    n_updates             | 880         |
|    policy_gradient_loss  | -0.00555    |
|    std                   | 1.02        |
|    value_loss            | 60.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.956154    |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -901         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 41           |
|    time_elapsed          | 8004         |
|    total_timesteps       | 184320       |
| train/                   |              |
|    approx_kl             | 0.0039071282 |
|    clip_fraction         | 0.0249       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.35         |
|    cost_value_loss       | 4.38         |
|    cost_values           | 0.998        |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.025        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.6         |
|    n_updates             | 890          |
|    policy_gradient_loss  | -0.00418     |
|    std                   | 1.02         |
|    value_loss            | 39.2         |
-------------------------------------------
wandb: Network error (ReadTimeout), entering retry loop.
-------------------------------------------
| avg_speed                | 7.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.85         |
| reward                   | -0.8023461   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -897         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 42           |
|    time_elapsed          | 8257         |
|    total_timesteps       | 186368       |
| train/                   |              |
|    approx_kl             | 0.0071810074 |
|    clip_fraction         | 0.0668       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.27         |
|    cost_value_loss       | 2.32         |
|    cost_values           | 1            |
|    entropy               | -2.89        |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.0093       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.2         |
|    n_updates             | 900          |
|    policy_gradient_loss  | -0.00678     |
|    std                   | 1.03         |
|    value_loss            | 26.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.06         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.06         |
| reward                   | -0.8363853   |
| rollout/                 |              |
|    ep_len_mean           | 971          |
|    ep_rew_mean           | -901         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 43           |
|    time_elapsed          | 8510         |
|    total_timesteps       | 188416       |
| train/                   |              |
|    approx_kl             | 0.0076031573 |
|    clip_fraction         | 0.0814       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.23         |
|    cost_value_loss       | 1.5          |
|    cost_values           | 1.02         |
|    entropy               | -2.88        |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.0211       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.89         |
|    n_updates             | 910          |
|    policy_gradient_loss  | -0.0065      |
|    std                   | 1.02         |
|    value_loss            | 8.48         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.46316653 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -896        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 44          |
|    time_elapsed          | 8766        |
|    total_timesteps       | 190464      |
| train/                   |             |
|    approx_kl             | 0.008536654 |
|    clip_fraction         | 0.111       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.36        |
|    cost_value_loss       | 0.951       |
|    cost_values           | 1.25        |
|    entropy               | -2.86       |
|    entropy_loss          | -2.87       |
|    explained_variance    | 0.0118      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.66        |
|    n_updates             | 920         |
|    policy_gradient_loss  | -0.00524    |
|    std                   | 1.01        |
|    value_loss            | 6.06        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.86822206 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -892        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 45          |
|    time_elapsed          | 9027        |
|    total_timesteps       | 192512      |
| train/                   |             |
|    approx_kl             | 0.00704673  |
|    clip_fraction         | 0.0724      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.79        |
|    cost_value_loss       | 2.86        |
|    cost_values           | 1.45        |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.126       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.01        |
|    n_updates             | 930         |
|    policy_gradient_loss  | -0.00376    |
|    std                   | 1.01        |
|    value_loss            | 4.23        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.6589737  |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -894        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 46          |
|    time_elapsed          | 9284        |
|    total_timesteps       | 194560      |
| train/                   |             |
|    approx_kl             | 0.005187791 |
|    clip_fraction         | 0.0309      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.12        |
|    cost_value_loss       | 4.94        |
|    cost_values           | 1.48        |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.308       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.91        |
|    n_updates             | 940         |
|    policy_gradient_loss  | -0.00291    |
|    std                   | 1.01        |
|    value_loss            | 11.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.77         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.77         |
| reward                   | -0.74731463  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -886         |
| time/                    |              |
|    fps                   | 10           |
|    iterations            | 47           |
|    time_elapsed          | 9546         |
|    total_timesteps       | 196608       |
| train/                   |              |
|    approx_kl             | 0.0055968133 |
|    clip_fraction         | 0.0216       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.02         |
|    cost_value_loss       | 2            |
|    cost_values           | 1.51         |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.198        |
|    lagrangian_multiplier | 0.000556     |
|    learning_rate         | 0.0003       |
|    loss                  | 18.7         |
|    n_updates             | 950          |
|    policy_gradient_loss  | -0.00132     |
|    std                   | 1.01         |
|    value_loss            | 54.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.2066457  |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -888        |
| time/                    |             |
|    fps                   | 10          |
|    iterations            | 48          |
|    time_elapsed          | 9809        |
|    total_timesteps       | 198656      |
| train/                   |             |
|    approx_kl             | 0.009351229 |
|    clip_fraction         | 0.0388      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.27        |
|    cost_value_loss       | 3.76        |
|    cost_values           | 1.46        |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.127       |
|    lagrangian_multiplier | 0.000782    |
|    learning_rate         | 0.0003      |
|    loss                  | 19.3        |
|    n_updates             | 960         |
|    policy_gradient_loss  | -0.00494    |
|    std                   | 1.01        |
|    value_loss            | 59.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.84487003  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -902         |
| time/                    |              |
|    fps                   | 9            |
|    iterations            | 49           |
|    time_elapsed          | 10068        |
|    total_timesteps       | 200704       |
| train/                   |              |
|    approx_kl             | 0.0056188013 |
|    clip_fraction         | 0.0194       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.42         |
|    cost_value_loss       | 3.13         |
|    cost_values           | 0.727        |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.39         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 32.1         |
|    n_updates             | 970          |
|    policy_gradient_loss  | -0.00271     |
|    std                   | 1.01         |
|    value_loss            | 64.8         |
-------------------------------------------
-----------------------------------
| avg_speed          | 8.02       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8.02       |
| reward             | -0.7488911 |
| rollout/           |            |
|    ep_len_mean     | 958        |
|    ep_rew_mean     | -895       |
| time/              |            |
|    fps             | 7          |
|    iterations      | 1          |
|    time_elapsed    | 267        |
|    total_timesteps | 202752     |
-----------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.7471685   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -889         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 2            |
|    time_elapsed          | 533          |
|    total_timesteps       | 204800       |
| train/                   |              |
|    approx_kl             | 0.0055425204 |
|    clip_fraction         | 0.0386       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.96         |
|    cost_value_loss       | 12.7         |
|    cost_values           | 0.666        |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.419        |
|    lagrangian_multiplier | 0.00385      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.48         |
|    n_updates             | 990          |
|    policy_gradient_loss  | -0.00495     |
|    std                   | 1.01         |
|    value_loss            | 24.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -0.5391798   |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -884         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 3            |
|    time_elapsed          | 797          |
|    total_timesteps       | 206848       |
| train/                   |              |
|    approx_kl             | 0.0036812096 |
|    clip_fraction         | 0.0191       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.24         |
|    cost_value_loss       | 21.6         |
|    cost_values           | 0.998        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.626        |
|    lagrangian_multiplier | 0.00617      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.39         |
|    n_updates             | 1000         |
|    policy_gradient_loss  | -0.00366     |
|    std                   | 1.01         |
|    value_loss            | 4.34         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.54783744  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -881         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 4            |
|    time_elapsed          | 1079         |
|    total_timesteps       | 208896       |
| train/                   |              |
|    approx_kl             | 0.0033936817 |
|    clip_fraction         | 0.0085       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.16         |
|    cost_value_loss       | 8.72         |
|    cost_values           | 1.02         |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.516        |
|    lagrangian_multiplier | 0.0012       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.79         |
|    n_updates             | 1010         |
|    policy_gradient_loss  | -0.00164     |
|    std                   | 1.01         |
|    value_loss            | 24.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.89530665 |
| rollout/                 |             |
|    ep_len_mean           | 958         |
|    ep_rew_mean           | -886        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 5           |
|    time_elapsed          | 1351        |
|    total_timesteps       | 210944      |
| train/                   |             |
|    approx_kl             | 0.004697461 |
|    clip_fraction         | 0.042       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.7         |
|    cost_value_loss       | 2.99        |
|    cost_values           | 0.948       |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.65        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.21        |
|    n_updates             | 1020        |
|    policy_gradient_loss  | -0.00547    |
|    std                   | 1.01        |
|    value_loss            | 14.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -0.6527847   |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -877         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 6            |
|    time_elapsed          | 1634         |
|    total_timesteps       | 212992       |
| train/                   |              |
|    approx_kl             | 0.0040732035 |
|    clip_fraction         | 0.0111       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.35         |
|    cost_value_loss       | 2.48         |
|    cost_values           | 0.686        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.541        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 33.6         |
|    n_updates             | 1030         |
|    policy_gradient_loss  | -0.00247     |
|    std                   | 1.01         |
|    value_loss            | 61.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0486273   |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -870         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 7            |
|    time_elapsed          | 1913         |
|    total_timesteps       | 215040       |
| train/                   |              |
|    approx_kl             | 0.0043484084 |
|    clip_fraction         | 0.0137       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.43         |
|    cost_value_loss       | 11.2         |
|    cost_values           | 0.793        |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.389        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.86         |
|    n_updates             | 1040         |
|    policy_gradient_loss  | -0.00312     |
|    std                   | 1            |
|    value_loss            | 25.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.5774861  |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -866        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 8           |
|    time_elapsed          | 2199        |
|    total_timesteps       | 217088      |
| train/                   |             |
|    approx_kl             | 0.004151906 |
|    clip_fraction         | 0.00664     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.33        |
|    cost_value_loss       | 3.26        |
|    cost_values           | 0.724       |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.688       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21.8        |
|    n_updates             | 1050        |
|    policy_gradient_loss  | -0.00192    |
|    std                   | 1           |
|    value_loss            | 40.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.75         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.75         |
| reward                   | -0.8509119   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -864         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 9            |
|    time_elapsed          | 2479         |
|    total_timesteps       | 219136       |
| train/                   |              |
|    approx_kl             | 0.0024917275 |
|    clip_fraction         | 0.0042       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.86         |
|    cost_value_loss       | 16.7         |
|    cost_values           | 0.527        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.755        |
|    lagrangian_multiplier | 5.23e-05     |
|    learning_rate         | 0.0003       |
|    loss                  | 23.4         |
|    n_updates             | 1060         |
|    policy_gradient_loss  | -0.00264     |
|    std                   | 1            |
|    value_loss            | 32.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.72406054  |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -860         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 10           |
|    time_elapsed          | 2772         |
|    total_timesteps       | 221184       |
| train/                   |              |
|    approx_kl             | 0.0038118516 |
|    clip_fraction         | 0.0199       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.96         |
|    cost_value_loss       | 7.74         |
|    cost_values           | 0.923        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.807        |
|    lagrangian_multiplier | 0.000422     |
|    learning_rate         | 0.0003       |
|    loss                  | 5.34         |
|    n_updates             | 1070         |
|    policy_gradient_loss  | -0.00364     |
|    std                   | 0.997        |
|    value_loss            | 5.39         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -0.3674011   |
| rollout/                 |              |
|    ep_len_mean           | 965          |
|    ep_rew_mean           | -858         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 11           |
|    time_elapsed          | 3055         |
|    total_timesteps       | 223232       |
| train/                   |              |
|    approx_kl             | 0.0048977747 |
|    clip_fraction         | 0.0349       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.77         |
|    cost_value_loss       | 11.3         |
|    cost_values           | 0.658        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.819        |
|    lagrangian_multiplier | 0.000956     |
|    learning_rate         | 0.0003       |
|    loss                  | 8.2          |
|    n_updates             | 1080         |
|    policy_gradient_loss  | -0.00468     |
|    std                   | 0.998        |
|    value_loss            | 12.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.33        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.33        |
| reward                   | -0.55919707 |
| rollout/                 |             |
|    ep_len_mean           | 948         |
|    ep_rew_mean           | -833        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 12          |
|    time_elapsed          | 3348        |
|    total_timesteps       | 225280      |
| train/                   |             |
|    approx_kl             | 0.003930537 |
|    clip_fraction         | 0.0221      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.85        |
|    cost_value_loss       | 3.53        |
|    cost_values           | 1.09        |
|    entropy               | -2.84       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.265       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.33        |
|    n_updates             | 1090        |
|    policy_gradient_loss  | -0.00294    |
|    std                   | 0.999       |
|    value_loss            | 6.16        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.4591103   |
| rollout/                 |              |
|    ep_len_mean           | 939          |
|    ep_rew_mean           | -817         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 13           |
|    time_elapsed          | 3639         |
|    total_timesteps       | 227328       |
| train/                   |              |
|    approx_kl             | 0.0028835738 |
|    clip_fraction         | 0.00576      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.3          |
|    cost_value_loss       | 3.27         |
|    cost_values           | 0.689        |
|    entropy               | -2.84        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.64         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.7         |
|    n_updates             | 1100         |
|    policy_gradient_loss  | -0.00296     |
|    std                   | 0.999        |
|    value_loss            | 42.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.90326124  |
| rollout/                 |              |
|    ep_len_mean           | 939          |
|    ep_rew_mean           | -814         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 14           |
|    time_elapsed          | 3946         |
|    total_timesteps       | 229376       |
| train/                   |              |
|    approx_kl             | 0.0042818217 |
|    clip_fraction         | 0.0233       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.33         |
|    cost_value_loss       | 2            |
|    cost_values           | 0.659        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.796        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.4         |
|    n_updates             | 1110         |
|    policy_gradient_loss  | -0.00266     |
|    std                   | 0.998        |
|    value_loss            | 23.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.9813192  |
| rollout/                 |             |
|    ep_len_mean           | 933         |
|    ep_rew_mean           | -801        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 15          |
|    time_elapsed          | 4243        |
|    total_timesteps       | 231424      |
| train/                   |             |
|    approx_kl             | 0.004117317 |
|    clip_fraction         | 0.00879     |
|    clip_range            | 0.2         |
|    cost_returns          | 1.18        |
|    cost_value_loss       | 5.52        |
|    cost_values           | 0.489       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.824       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.6        |
|    n_updates             | 1120        |
|    policy_gradient_loss  | -0.00144    |
|    std                   | 0.997       |
|    value_loss            | 25.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.938        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.938        |
| reward                   | -0.5154411   |
| rollout/                 |              |
|    ep_len_mean           | 933          |
|    ep_rew_mean           | -785         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 16           |
|    time_elapsed          | 4544         |
|    total_timesteps       | 233472       |
| train/                   |              |
|    approx_kl             | 0.0035644001 |
|    clip_fraction         | 0.0216       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.27         |
|    cost_value_loss       | 2.46         |
|    cost_values           | 0.661        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.728        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.6         |
|    n_updates             | 1130         |
|    policy_gradient_loss  | -0.00374     |
|    std                   | 0.998        |
|    value_loss            | 31.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.1          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.1          |
| reward                   | -0.51628363  |
| rollout/                 |              |
|    ep_len_mean           | 942          |
|    ep_rew_mean           | -788         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 17           |
|    time_elapsed          | 4858         |
|    total_timesteps       | 235520       |
| train/                   |              |
|    approx_kl             | 0.0061085904 |
|    clip_fraction         | 0.0264       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.52         |
|    cost_value_loss       | 3.26         |
|    cost_values           | 0.771        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.703        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.04         |
|    n_updates             | 1140         |
|    policy_gradient_loss  | -0.00396     |
|    std                   | 0.998        |
|    value_loss            | 11.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.38         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.38         |
| reward                   | -0.7730777   |
| rollout/                 |              |
|    ep_len_mean           | 942          |
|    ep_rew_mean           | -784         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 18           |
|    time_elapsed          | 5157         |
|    total_timesteps       | 237568       |
| train/                   |              |
|    approx_kl             | 0.0031688237 |
|    clip_fraction         | 0.0282       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.34         |
|    cost_value_loss       | 1.92         |
|    cost_values           | 0.75         |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.873        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.25         |
|    n_updates             | 1150         |
|    policy_gradient_loss  | -0.00609     |
|    std                   | 0.994        |
|    value_loss            | 11           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -0.489484    |
| rollout/                 |              |
|    ep_len_mean           | 942          |
|    ep_rew_mean           | -778         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 19           |
|    time_elapsed          | 5459         |
|    total_timesteps       | 239616       |
| train/                   |              |
|    approx_kl             | 0.0040555215 |
|    clip_fraction         | 0.0369       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.72         |
|    cost_value_loss       | 10.3         |
|    cost_values           | 0.638        |
|    entropy               | -2.82        |
|    entropy_loss          | -2.82        |
|    explained_variance    | 0.812        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27.1         |
|    n_updates             | 1160         |
|    policy_gradient_loss  | -0.00439     |
|    std                   | 0.993        |
|    value_loss            | 41.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.27        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.27        |
| reward                   | -0.70856494 |
| rollout/                 |             |
|    ep_len_mean           | 942         |
|    ep_rew_mean           | -770        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 20          |
|    time_elapsed          | 5775        |
|    total_timesteps       | 241664      |
| train/                   |             |
|    approx_kl             | 0.005103117 |
|    clip_fraction         | 0.0427      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.32        |
|    cost_value_loss       | 3.92        |
|    cost_values           | 0.613       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.896       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.56        |
|    n_updates             | 1170        |
|    policy_gradient_loss  | -0.00479    |
|    std                   | 0.994       |
|    value_loss            | 13.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.71        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.71        |
| reward                   | -0.5480106  |
| rollout/                 |             |
|    ep_len_mean           | 942         |
|    ep_rew_mean           | -768        |
| time/                    |             |
|    fps                   | 7           |
|    iterations            | 21          |
|    time_elapsed          | 6084        |
|    total_timesteps       | 243712      |
| train/                   |             |
|    approx_kl             | 0.005270086 |
|    clip_fraction         | 0.0202      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.18        |
|    cost_value_loss       | 8.33        |
|    cost_values           | 0.866       |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.888       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.06        |
|    n_updates             | 1180        |
|    policy_gradient_loss  | -0.0037     |
|    std                   | 0.998       |
|    value_loss            | 9.33        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.6          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.6          |
| reward                   | -0.8056439   |
| rollout/                 |              |
|    ep_len_mean           | 942          |
|    ep_rew_mean           | -764         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 22           |
|    time_elapsed          | 6395         |
|    total_timesteps       | 245760       |
| train/                   |              |
|    approx_kl             | 0.0046182596 |
|    clip_fraction         | 0.019        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.54         |
|    cost_value_loss       | 3.02         |
|    cost_values           | 0.907        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.884        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.29         |
|    n_updates             | 1190         |
|    policy_gradient_loss  | -0.00237     |
|    std                   | 0.998        |
|    value_loss            | 6.67         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0060189   |
| rollout/                 |              |
|    ep_len_mean           | 942          |
|    ep_rew_mean           | -763         |
| time/                    |              |
|    fps                   | 7            |
|    iterations            | 23           |
|    time_elapsed          | 6723         |
|    total_timesteps       | 247808       |
| train/                   |              |
|    approx_kl             | 0.0063072713 |
|    clip_fraction         | 0.0237       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.27         |
|    cost_value_loss       | 1.75         |
|    cost_values           | 0.827        |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.855        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.22         |
|    n_updates             | 1200         |
|    policy_gradient_loss  | -0.0039      |
|    std                   | 0.997        |
|    value_loss            | 12.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.43         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4.43         |
| reward                   | -0.608091    |
| rollout/                 |              |
|    ep_len_mean           | 934          |
|    ep_rew_mean           | -755         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 24           |
|    time_elapsed          | 7057         |
|    total_timesteps       | 249856       |
| train/                   |              |
|    approx_kl             | 0.0051649157 |
|    clip_fraction         | 0.0583       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.18         |
|    cost_value_loss       | 4.25         |
|    cost_values           | 1.04         |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.485        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.77         |
|    n_updates             | 1210         |
|    policy_gradient_loss  | -0.00545     |
|    std                   | 0.994        |
|    value_loss            | 6.2          |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.34        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.34        |
| reward                   | -0.5403616  |
| rollout/                 |             |
|    ep_len_mean           | 934         |
|    ep_rew_mean           | -753        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 25          |
|    time_elapsed          | 7400        |
|    total_timesteps       | 251904      |
| train/                   |             |
|    approx_kl             | 0.005747944 |
|    clip_fraction         | 0.0241      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.87        |
|    cost_value_loss       | 4.71        |
|    cost_values           | 0.859       |
|    entropy               | -2.82       |
|    entropy_loss          | -2.82       |
|    explained_variance    | 0.772       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 22.3        |
|    n_updates             | 1220        |
|    policy_gradient_loss  | -0.00435    |
|    std                   | 0.992       |
|    value_loss            | 41.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.69        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.69        |
| reward                   | -0.48507106 |
| rollout/                 |             |
|    ep_len_mean           | 934         |
|    ep_rew_mean           | -753        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 26          |
|    time_elapsed          | 7728        |
|    total_timesteps       | 253952      |
| train/                   |             |
|    approx_kl             | 0.004706963 |
|    clip_fraction         | 0.0333      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.4         |
|    cost_value_loss       | 3.44        |
|    cost_values           | 0.657       |
|    entropy               | -2.82       |
|    entropy_loss          | -2.82       |
|    explained_variance    | 0.905       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.32        |
|    n_updates             | 1230        |
|    policy_gradient_loss  | -0.00587    |
|    std                   | 0.989       |
|    value_loss            | 8.1         |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.2          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 2.2          |
| reward                   | -0.53870565  |
| rollout/                 |              |
|    ep_len_mean           | 934          |
|    ep_rew_mean           | -753         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 27           |
|    time_elapsed          | 8054         |
|    total_timesteps       | 256000       |
| train/                   |              |
|    approx_kl             | 0.0071610054 |
|    clip_fraction         | 0.0716       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.41         |
|    cost_value_loss       | 7.45         |
|    cost_values           | 0.63         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.943        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.45         |
|    n_updates             | 1240         |
|    policy_gradient_loss  | -0.00843     |
|    std                   | 0.987        |
|    value_loss            | 8.98         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.52         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.52         |
| reward                   | -0.35993156  |
| rollout/                 |              |
|    ep_len_mean           | 934          |
|    ep_rew_mean           | -750         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 28           |
|    time_elapsed          | 8374         |
|    total_timesteps       | 258048       |
| train/                   |              |
|    approx_kl             | 0.0051587997 |
|    clip_fraction         | 0.03         |
|    clip_range            | 0.2          |
|    cost_returns          | 2.08         |
|    cost_value_loss       | 17.4         |
|    cost_values           | 0.7          |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.918        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.9         |
|    n_updates             | 1250         |
|    policy_gradient_loss  | -0.00489     |
|    std                   | 0.987        |
|    value_loss            | 11.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.8         |
| reward                   | -0.6454724  |
| rollout/                 |             |
|    ep_len_mean           | 934         |
|    ep_rew_mean           | -746        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 29          |
|    time_elapsed          | 8705        |
|    total_timesteps       | 260096      |
| train/                   |             |
|    approx_kl             | 0.006315858 |
|    clip_fraction         | 0.0251      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.31        |
|    cost_value_loss       | 3.98        |
|    cost_values           | 0.741       |
|    entropy               | -2.81       |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0.925       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.73        |
|    n_updates             | 1260        |
|    policy_gradient_loss  | -0.00365    |
|    std                   | 0.985       |
|    value_loss            | 9.82        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.78        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.78        |
| reward                   | -0.7627398  |
| rollout/                 |             |
|    ep_len_mean           | 934         |
|    ep_rew_mean           | -744        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 30          |
|    time_elapsed          | 9043        |
|    total_timesteps       | 262144      |
| train/                   |             |
|    approx_kl             | 0.002832253 |
|    clip_fraction         | 0.0226      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.6         |
|    cost_value_loss       | 12.5        |
|    cost_values           | 0.997       |
|    entropy               | -2.8        |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0.589       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.9         |
|    n_updates             | 1270        |
|    policy_gradient_loss  | -0.00348    |
|    std                   | 0.983       |
|    value_loss            | 6.55        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.94         |
| reward                   | -0.48883483  |
| rollout/                 |              |
|    ep_len_mean           | 934          |
|    ep_rew_mean           | -739         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 31           |
|    time_elapsed          | 9379         |
|    total_timesteps       | 264192       |
| train/                   |              |
|    approx_kl             | 0.0053798947 |
|    clip_fraction         | 0.0297       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.91         |
|    cost_value_loss       | 3.97         |
|    cost_values           | 1.07         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.832        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4            |
|    n_updates             | 1280         |
|    policy_gradient_loss  | -0.00435     |
|    std                   | 0.984        |
|    value_loss            | 4.7          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.62677443 |
| rollout/                 |             |
|    ep_len_mean           | 934         |
|    ep_rew_mean           | -735        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 32          |
|    time_elapsed          | 9718        |
|    total_timesteps       | 266240      |
| train/                   |             |
|    approx_kl             | 0.004614325 |
|    clip_fraction         | 0.0204      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.27        |
|    cost_value_loss       | 8.22        |
|    cost_values           | 1.09        |
|    entropy               | -2.81       |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0.749       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.7         |
|    n_updates             | 1290        |
|    policy_gradient_loss  | -0.00243    |
|    std                   | 0.986       |
|    value_loss            | 8.44        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.84         |
| reward                   | -0.68821764  |
| rollout/                 |              |
|    ep_len_mean           | 916          |
|    ep_rew_mean           | -711         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 33           |
|    time_elapsed          | 10065        |
|    total_timesteps       | 268288       |
| train/                   |              |
|    approx_kl             | 0.0061855647 |
|    clip_fraction         | 0.0749       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.93         |
|    cost_value_loss       | 2.81         |
|    cost_values           | 1.21         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.228        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.12         |
|    n_updates             | 1300         |
|    policy_gradient_loss  | -0.00748     |
|    std                   | 0.988        |
|    value_loss            | 3.42         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.67         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 6.67         |
| reward                   | -0.55079365  |
| rollout/                 |              |
|    ep_len_mean           | 916          |
|    ep_rew_mean           | -704         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 34           |
|    time_elapsed          | 10410        |
|    total_timesteps       | 270336       |
| train/                   |              |
|    approx_kl             | 0.0060480186 |
|    clip_fraction         | 0.0739       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.96         |
|    cost_value_loss       | 10.2         |
|    cost_values           | 1.38         |
|    entropy               | -2.81        |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.11         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.9         |
|    n_updates             | 1310         |
|    policy_gradient_loss  | -0.00314     |
|    std                   | 0.985        |
|    value_loss            | 33.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.65        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.65        |
| reward                   | -0.40744954 |
| rollout/                 |             |
|    ep_len_mean           | 923         |
|    ep_rew_mean           | -704        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 35          |
|    time_elapsed          | 10770       |
|    total_timesteps       | 272384      |
| train/                   |             |
|    approx_kl             | 0.004513285 |
|    clip_fraction         | 0.0477      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.66        |
|    cost_value_loss       | 8.23        |
|    cost_values           | 1.18        |
|    entropy               | -2.8        |
|    entropy_loss          | -2.8        |
|    explained_variance    | 0.895       |
|    lagrangian_multiplier | 9.46e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 7.84        |
|    n_updates             | 1320        |
|    policy_gradient_loss  | -0.00647    |
|    std                   | 0.984       |
|    value_loss            | 7.88        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.99        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.99        |
| reward                   | -0.7635152  |
| rollout/                 |             |
|    ep_len_mean           | 923         |
|    ep_rew_mean           | -696        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 36          |
|    time_elapsed          | 11114       |
|    total_timesteps       | 274432      |
| train/                   |             |
|    approx_kl             | 0.008188781 |
|    clip_fraction         | 0.0701      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.87        |
|    cost_value_loss       | 2.5         |
|    cost_values           | 1.15        |
|    entropy               | -2.8        |
|    entropy_loss          | -2.8        |
|    explained_variance    | 0.873       |
|    lagrangian_multiplier | 0.000686    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.88        |
|    n_updates             | 1330        |
|    policy_gradient_loss  | -0.00789    |
|    std                   | 0.982       |
|    value_loss            | 8.55        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.62        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.62        |
| reward                   | -0.51108277 |
| rollout/                 |             |
|    ep_len_mean           | 923         |
|    ep_rew_mean           | -691        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 37          |
|    time_elapsed          | 11469       |
|    total_timesteps       | 276480      |
| train/                   |             |
|    approx_kl             | 0.005338127 |
|    clip_fraction         | 0.028       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.76        |
|    cost_value_loss       | 9.9         |
|    cost_values           | 1.05        |
|    entropy               | -2.8        |
|    entropy_loss          | -2.8        |
|    explained_variance    | 0.927       |
|    lagrangian_multiplier | 0.00215     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.14        |
|    n_updates             | 1340        |
|    policy_gradient_loss  | -0.00411    |
|    std                   | 0.982       |
|    value_loss            | 7.43        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.66        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.66        |
| reward                   | -0.667979   |
| rollout/                 |             |
|    ep_len_mean           | 923         |
|    ep_rew_mean           | -689        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 38          |
|    time_elapsed          | 11835       |
|    total_timesteps       | 278528      |
| train/                   |             |
|    approx_kl             | 0.007012197 |
|    clip_fraction         | 0.0786      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.5         |
|    cost_value_loss       | 30.2        |
|    cost_values           | 1.12        |
|    entropy               | -2.8        |
|    entropy_loss          | -2.8        |
|    explained_variance    | 0.806       |
|    lagrangian_multiplier | 0.00246     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.39        |
|    n_updates             | 1350        |
|    policy_gradient_loss  | -0.0107     |
|    std                   | 0.981       |
|    value_loss            | 10.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.06        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.06        |
| reward                   | -0.74279493 |
| rollout/                 |             |
|    ep_len_mean           | 923         |
|    ep_rew_mean           | -688        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 39          |
|    time_elapsed          | 12189       |
|    total_timesteps       | 280576      |
| train/                   |             |
|    approx_kl             | 0.009074042 |
|    clip_fraction         | 0.0366      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.72        |
|    cost_value_loss       | 26.5        |
|    cost_values           | 1.06        |
|    entropy               | -2.8        |
|    entropy_loss          | -2.8        |
|    explained_variance    | 0.911       |
|    lagrangian_multiplier | 0.00498     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.39        |
|    n_updates             | 1360        |
|    policy_gradient_loss  | -0.00408    |
|    std                   | 0.981       |
|    value_loss            | 7.96        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.63222677 |
| rollout/                 |             |
|    ep_len_mean           | 923         |
|    ep_rew_mean           | -687        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 40          |
|    time_elapsed          | 12554       |
|    total_timesteps       | 282624      |
| train/                   |             |
|    approx_kl             | 0.006691128 |
|    clip_fraction         | 0.0629      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.17        |
|    cost_value_loss       | 8.33        |
|    cost_values           | 0.922       |
|    entropy               | -2.8        |
|    entropy_loss          | -2.8        |
|    explained_variance    | 0.855       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.7         |
|    n_updates             | 1370        |
|    policy_gradient_loss  | -0.0064     |
|    std                   | 0.98        |
|    value_loss            | 11          |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.1392674  |
| rollout/                 |             |
|    ep_len_mean           | 923         |
|    ep_rew_mean           | -688        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 41          |
|    time_elapsed          | 12908       |
|    total_timesteps       | 284672      |
| train/                   |             |
|    approx_kl             | 0.004611979 |
|    clip_fraction         | 0.036       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.52        |
|    cost_value_loss       | 24          |
|    cost_values           | 0.963       |
|    entropy               | -2.79       |
|    entropy_loss          | -2.79       |
|    explained_variance    | 0.952       |
|    lagrangian_multiplier | 0.00478     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.31        |
|    n_updates             | 1380        |
|    policy_gradient_loss  | -0.00409    |
|    std                   | 0.976       |
|    value_loss            | 5.22        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.91        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.91        |
| reward                   | -0.79571515 |
| rollout/                 |             |
|    ep_len_mean           | 923         |
|    ep_rew_mean           | -689        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 42          |
|    time_elapsed          | 13287       |
|    total_timesteps       | 286720      |
| train/                   |             |
|    approx_kl             | 0.006153281 |
|    clip_fraction         | 0.0425      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.54        |
|    cost_value_loss       | 5.17        |
|    cost_values           | 0.564       |
|    entropy               | -2.79       |
|    entropy_loss          | -2.79       |
|    explained_variance    | 0.942       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.1        |
|    n_updates             | 1390        |
|    policy_gradient_loss  | -0.00401    |
|    std                   | 0.975       |
|    value_loss            | 24          |
------------------------------------------
------------------------------------------
| avg_speed                | 6.95        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.95        |
| reward                   | -0.2935216  |
| rollout/                 |             |
|    ep_len_mean           | 928         |
|    ep_rew_mean           | -685        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 43          |
|    time_elapsed          | 13662       |
|    total_timesteps       | 288768      |
| train/                   |             |
|    approx_kl             | 0.005744136 |
|    clip_fraction         | 0.0333      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.74        |
|    cost_value_loss       | 3.14        |
|    cost_values           | 0.794       |
|    entropy               | -2.78       |
|    entropy_loss          | -2.79       |
|    explained_variance    | 0.898       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.23        |
|    n_updates             | 1400        |
|    policy_gradient_loss  | -0.00467    |
|    std                   | 0.973       |
|    value_loss            | 14.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -0.50008553  |
| rollout/                 |              |
|    ep_len_mean           | 928          |
|    ep_rew_mean           | -681         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 44           |
|    time_elapsed          | 14047        |
|    total_timesteps       | 290816       |
| train/                   |              |
|    approx_kl             | 0.0042888075 |
|    clip_fraction         | 0.0228       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.42         |
|    cost_value_loss       | 20.8         |
|    cost_values           | 1.04         |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.392        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.7         |
|    n_updates             | 1410         |
|    policy_gradient_loss  | -0.00334     |
|    std                   | 0.972        |
|    value_loss            | 24.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -0.63986856  |
| rollout/                 |              |
|    ep_len_mean           | 928          |
|    ep_rew_mean           | -668         |
| time/                    |              |
|    fps                   | 6            |
|    iterations            | 45           |
|    time_elapsed          | 14437        |
|    total_timesteps       | 292864       |
| train/                   |              |
|    approx_kl             | 0.0043413667 |
|    clip_fraction         | 0.0323       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.94         |
|    cost_value_loss       | 27.7         |
|    cost_values           | 1.23         |
|    entropy               | -2.78        |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.325        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14           |
|    n_updates             | 1420         |
|    policy_gradient_loss  | -0.00551     |
|    std                   | 0.972        |
|    value_loss            | 4            |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.37        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.37        |
| reward                   | -0.53824204 |
| rollout/                 |             |
|    ep_len_mean           | 928         |
|    ep_rew_mean           | -658        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 46          |
|    time_elapsed          | 14822       |
|    total_timesteps       | 294912      |
| train/                   |             |
|    approx_kl             | 0.005931691 |
|    clip_fraction         | 0.0323      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.23        |
|    cost_value_loss       | 7.19        |
|    cost_values           | 1.07        |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.942       |
|    lagrangian_multiplier | 0.000318    |
|    learning_rate         | 0.0003      |
|    loss                  | 8.01        |
|    n_updates             | 1430        |
|    policy_gradient_loss  | -0.00379    |
|    std                   | 0.972       |
|    value_loss            | 11.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.42        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.42        |
| reward                   | -0.40465072 |
| rollout/                 |             |
|    ep_len_mean           | 922         |
|    ep_rew_mean           | -649        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 47          |
|    time_elapsed          | 15219       |
|    total_timesteps       | 296960      |
| train/                   |             |
|    approx_kl             | 0.007577883 |
|    clip_fraction         | 0.0752      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.73        |
|    cost_value_loss       | 2.64        |
|    cost_values           | 1.1         |
|    entropy               | -2.77       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.62        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.58        |
|    n_updates             | 1440        |
|    policy_gradient_loss  | -0.00769    |
|    std                   | 0.969       |
|    value_loss            | 7.14        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.34        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.34        |
| reward                   | -0.610728   |
| rollout/                 |             |
|    ep_len_mean           | 922         |
|    ep_rew_mean           | -648        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 48          |
|    time_elapsed          | 15616       |
|    total_timesteps       | 299008      |
| train/                   |             |
|    approx_kl             | 0.003973035 |
|    clip_fraction         | 0.0271      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.44        |
|    cost_value_loss       | 6.43        |
|    cost_values           | 1.2         |
|    entropy               | -2.77       |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0.437       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 18.1        |
|    n_updates             | 1450        |
|    policy_gradient_loss  | -0.00261    |
|    std                   | 0.965       |
|    value_loss            | 19.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.26        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.26        |
| reward                   | -0.58253235 |
| rollout/                 |             |
|    ep_len_mean           | 922         |
|    ep_rew_mean           | -646        |
| time/                    |             |
|    fps                   | 6           |
|    iterations            | 49          |
|    time_elapsed          | 16002       |
|    total_timesteps       | 301056      |
| train/                   |             |
|    approx_kl             | 0.00833596  |
|    clip_fraction         | 0.0464      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.53        |
|    cost_value_loss       | 7.05        |
|    cost_values           | 0.99        |
|    entropy               | -2.76       |
|    entropy_loss          | -2.76       |
|    explained_variance    | 0.939       |
|    lagrangian_multiplier | 0.000419    |
|    learning_rate         | 0.0003      |
|    loss                  | 6.25        |
|    n_updates             | 1460        |
|    policy_gradient_loss  | -0.00588    |
|    std                   | 0.963       |
|    value_loss            | 8.34        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/2fzzfvlw
------------------------------------
| avg_speed          | 4.17        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 4.17        |
| reward             | -0.83456415 |
| rollout/           |             |
|    ep_len_mean     | 922         |
|    ep_rew_mean     | -635        |
| time/              |             |
|    fps             | 5           |
|    iterations      | 1           |
|    time_elapsed    | 387         |
|    total_timesteps | 303104      |
------------------------------------
------------------------------------------
| avg_speed                | 7.42        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.42        |
| reward                   | -0.633594   |
| rollout/                 |             |
|    ep_len_mean           | 930         |
|    ep_rew_mean           | -638        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 2           |
|    time_elapsed          | 775         |
|    total_timesteps       | 305152      |
| train/                   |             |
|    approx_kl             | 0.004158744 |
|    clip_fraction         | 0.00781     |
|    clip_range            | 0.2         |
|    cost_returns          | 6.48        |
|    cost_value_loss       | 57.6        |
|    cost_values           | 1.42        |
|    entropy               | -2.76       |
|    entropy_loss          | -2.76       |
|    explained_variance    | 0.693       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 28.1        |
|    n_updates             | 1480        |
|    policy_gradient_loss  | -0.00256    |
|    std                   | 0.96        |
|    value_loss            | 5.79        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.54         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.54         |
| reward                   | -0.41002494  |
| rollout/                 |              |
|    ep_len_mean           | 930          |
|    ep_rew_mean           | -632         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 3            |
|    time_elapsed          | 1177         |
|    total_timesteps       | 307200       |
| train/                   |              |
|    approx_kl             | 0.0050385776 |
|    clip_fraction         | 0.0654       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.21         |
|    cost_value_loss       | 2.42         |
|    cost_values           | 1.6          |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.544        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.17         |
|    n_updates             | 1490         |
|    policy_gradient_loss  | -0.00595     |
|    std                   | 0.963        |
|    value_loss            | 4.93         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.83        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.83        |
| reward                   | -0.9223404  |
| rollout/                 |             |
|    ep_len_mean           | 930         |
|    ep_rew_mean           | -625        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 4           |
|    time_elapsed          | 1596        |
|    total_timesteps       | 309248      |
| train/                   |             |
|    approx_kl             | 0.006852009 |
|    clip_fraction         | 0.0512      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.82        |
|    cost_value_loss       | 24.3        |
|    cost_values           | 1.8         |
|    entropy               | -2.76       |
|    entropy_loss          | -2.76       |
|    explained_variance    | 0.765       |
|    lagrangian_multiplier | 0.00427     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.48        |
|    n_updates             | 1500        |
|    policy_gradient_loss  | -0.00482    |
|    std                   | 0.964       |
|    value_loss            | 4.35        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.8955338  |
| rollout/                 |             |
|    ep_len_mean           | 930         |
|    ep_rew_mean           | -625        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 5           |
|    time_elapsed          | 1994        |
|    total_timesteps       | 311296      |
| train/                   |             |
|    approx_kl             | 0.006304341 |
|    clip_fraction         | 0.0842      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.59        |
|    cost_value_loss       | 2.41        |
|    cost_values           | 1.85        |
|    entropy               | -2.76       |
|    entropy_loss          | -2.76       |
|    explained_variance    | 0.744       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.03        |
|    n_updates             | 1510        |
|    policy_gradient_loss  | -0.00937    |
|    std                   | 0.961       |
|    value_loss            | 4.39        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.28         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.28         |
| reward                   | -0.6348627   |
| rollout/                 |              |
|    ep_len_mean           | 930          |
|    ep_rew_mean           | -622         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 6            |
|    time_elapsed          | 2355         |
|    total_timesteps       | 313344       |
| train/                   |              |
|    approx_kl             | 0.0025129768 |
|    clip_fraction         | 0.0161       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.62         |
|    cost_value_loss       | 1.62         |
|    cost_values           | 1.09         |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.862        |
|    lagrangian_multiplier | 0.000413     |
|    learning_rate         | 0.0003       |
|    loss                  | 4.35         |
|    n_updates             | 1520         |
|    policy_gradient_loss  | -0.00198     |
|    std                   | 0.959        |
|    value_loss            | 12           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.21         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.21         |
| reward                   | -0.3673366   |
| rollout/                 |              |
|    ep_len_mean           | 930          |
|    ep_rew_mean           | -619         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 7            |
|    time_elapsed          | 2728         |
|    total_timesteps       | 315392       |
| train/                   |              |
|    approx_kl             | 0.0042835567 |
|    clip_fraction         | 0.0397       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.51         |
|    cost_value_loss       | 8            |
|    cost_values           | 0.898        |
|    entropy               | -2.76        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.932        |
|    lagrangian_multiplier | 0.000148     |
|    learning_rate         | 0.0003       |
|    loss                  | 4.91         |
|    n_updates             | 1530         |
|    policy_gradient_loss  | -0.00469     |
|    std                   | 0.961        |
|    value_loss            | 3.78         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.9          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 2.9          |
| reward                   | -0.5278181   |
| rollout/                 |              |
|    ep_len_mean           | 930          |
|    ep_rew_mean           | -616         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 8            |
|    time_elapsed          | 3093         |
|    total_timesteps       | 317440       |
| train/                   |              |
|    approx_kl             | 0.0037002699 |
|    clip_fraction         | 0.0281       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.68         |
|    cost_value_loss       | 32.9         |
|    cost_values           | 1.28         |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.709        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.6         |
|    n_updates             | 1540         |
|    policy_gradient_loss  | -0.00379     |
|    std                   | 0.961        |
|    value_loss            | 4.26         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.92        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.92        |
| reward                   | -0.4764157  |
| rollout/                 |             |
|    ep_len_mean           | 946         |
|    ep_rew_mean           | -626        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 9           |
|    time_elapsed          | 3453        |
|    total_timesteps       | 319488      |
| train/                   |             |
|    approx_kl             | 0.006020047 |
|    clip_fraction         | 0.0461      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.23        |
|    cost_value_loss       | 16.1        |
|    cost_values           | 1.83        |
|    entropy               | -2.75       |
|    entropy_loss          | -2.75       |
|    explained_variance    | 0.713       |
|    lagrangian_multiplier | 0.00199     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.19        |
|    n_updates             | 1550        |
|    policy_gradient_loss  | -0.00419    |
|    std                   | 0.959       |
|    value_loss            | 4.06        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.68         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.68         |
| reward                   | -0.49955976  |
| rollout/                 |              |
|    ep_len_mean           | 946          |
|    ep_rew_mean           | -624         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 10           |
|    time_elapsed          | 3832         |
|    total_timesteps       | 321536       |
| train/                   |              |
|    approx_kl             | 0.0046270853 |
|    clip_fraction         | 0.0333       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.13         |
|    cost_value_loss       | 17.9         |
|    cost_values           | 2.35         |
|    entropy               | -2.74        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.627        |
|    lagrangian_multiplier | 0.00325      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.89         |
|    n_updates             | 1560         |
|    policy_gradient_loss  | -0.00389     |
|    std                   | 0.952        |
|    value_loss            | 3.29         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.21        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.21        |
| reward                   | -0.49873823 |
| rollout/                 |             |
|    ep_len_mean           | 956         |
|    ep_rew_mean           | -626        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 11          |
|    time_elapsed          | 4211        |
|    total_timesteps       | 323584      |
| train/                   |             |
|    approx_kl             | 0.005953677 |
|    clip_fraction         | 0.051       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.55        |
|    cost_value_loss       | 5.7         |
|    cost_values           | 2           |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | 0.737       |
|    lagrangian_multiplier | 0.00153     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.36        |
|    n_updates             | 1570        |
|    policy_gradient_loss  | -0.00416    |
|    std                   | 0.95        |
|    value_loss            | 7.39        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0782       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0782       |
| reward                   | -0.31944314  |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -623         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 12           |
|    time_elapsed          | 4583         |
|    total_timesteps       | 325632       |
| train/                   |              |
|    approx_kl             | 0.0053957594 |
|    clip_fraction         | 0.0167       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.93         |
|    cost_value_loss       | 41.1         |
|    cost_values           | 1.49         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.867        |
|    lagrangian_multiplier | 0.00341      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.71         |
|    n_updates             | 1580         |
|    policy_gradient_loss  | -0.00234     |
|    std                   | 0.948        |
|    value_loss            | 4.13         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.355        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.355        |
| reward                   | -0.47314817  |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -618         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 13           |
|    time_elapsed          | 4959         |
|    total_timesteps       | 327680       |
| train/                   |              |
|    approx_kl             | 0.0038636532 |
|    clip_fraction         | 0.0138       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.77         |
|    cost_value_loss       | 28.5         |
|    cost_values           | 0.938        |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.965        |
|    lagrangian_multiplier | 0.00116      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.5         |
|    n_updates             | 1590         |
|    policy_gradient_loss  | -0.00219     |
|    std                   | 0.948        |
|    value_loss            | 6.82         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.8         |
| reward                   | -0.5059706  |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -612        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 14          |
|    time_elapsed          | 5328        |
|    total_timesteps       | 329728      |
| train/                   |             |
|    approx_kl             | 0.004411983 |
|    clip_fraction         | 0.0156      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.59        |
|    cost_value_loss       | 3.46        |
|    cost_values           | 0.73        |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | 0.948       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.58        |
|    n_updates             | 1600        |
|    policy_gradient_loss  | -0.00247    |
|    std                   | 0.948       |
|    value_loss            | 6           |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.95         |
| reward                   | -0.67048043  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -605         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 15           |
|    time_elapsed          | 5686         |
|    total_timesteps       | 331776       |
| train/                   |              |
|    approx_kl             | 0.0037510218 |
|    clip_fraction         | 0.0083       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.8         |
|    cost_value_loss       | 116          |
|    cost_values           | 1.34         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.183        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 55.4         |
|    n_updates             | 1610         |
|    policy_gradient_loss  | -0.00216     |
|    std                   | 0.947        |
|    value_loss            | 2.74         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.62         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.62         |
| reward                   | -0.48491937  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -596         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 16           |
|    time_elapsed          | 6052         |
|    total_timesteps       | 333824       |
| train/                   |              |
|    approx_kl             | 0.0034573912 |
|    clip_fraction         | 0.0264       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.49         |
|    cost_value_loss       | 7.46         |
|    cost_values           | 1.07         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.89         |
|    lagrangian_multiplier | 0.001        |
|    learning_rate         | 0.0003       |
|    loss                  | 12.1         |
|    n_updates             | 1620         |
|    policy_gradient_loss  | -0.00327     |
|    std                   | 0.945        |
|    value_loss            | 19.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.34        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.34        |
| reward                   | -0.29055864 |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -587        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 17          |
|    time_elapsed          | 6416        |
|    total_timesteps       | 335872      |
| train/                   |             |
|    approx_kl             | 0.005802662 |
|    clip_fraction         | 0.0715      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.72        |
|    cost_value_loss       | 16.3        |
|    cost_values           | 1.51        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.614       |
|    lagrangian_multiplier | 0.000208    |
|    learning_rate         | 0.0003      |
|    loss                  | 9.43        |
|    n_updates             | 1630        |
|    policy_gradient_loss  | -0.00897    |
|    std                   | 0.942       |
|    value_loss            | 5.46        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.000574    |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.000574    |
| reward                   | -0.64880663 |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -583        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 18          |
|    time_elapsed          | 6796        |
|    total_timesteps       | 337920      |
| train/                   |             |
|    approx_kl             | 0.001966766 |
|    clip_fraction         | 0.00742     |
|    clip_range            | 0.2         |
|    cost_returns          | 5.69        |
|    cost_value_loss       | 40.4        |
|    cost_values           | 2.13        |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | 0.138       |
|    lagrangian_multiplier | 0.00345     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.3         |
|    n_updates             | 1640        |
|    policy_gradient_loss  | -0.00194    |
|    std                   | 0.941       |
|    value_loss            | 1.76        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.11         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.11         |
| reward                   | -0.41849425  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -584         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 19           |
|    time_elapsed          | 7135         |
|    total_timesteps       | 339968       |
| train/                   |              |
|    approx_kl             | 0.0031243758 |
|    clip_fraction         | 0.0299       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.35         |
|    cost_value_loss       | 42.7         |
|    cost_values           | 2.15         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.205        |
|    lagrangian_multiplier | 0.00395      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.39         |
|    n_updates             | 1650         |
|    policy_gradient_loss  | -0.00434     |
|    std                   | 0.939        |
|    value_loss            | 2.61         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.599        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.599        |
| reward                   | -0.6732001   |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -577         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 20           |
|    time_elapsed          | 7476         |
|    total_timesteps       | 342016       |
| train/                   |              |
|    approx_kl             | 0.0017719603 |
|    clip_fraction         | 0.00151      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.57         |
|    cost_value_loss       | 49.3         |
|    cost_values           | 1.75         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.935        |
|    lagrangian_multiplier | 0.00668      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.16         |
|    n_updates             | 1660         |
|    policy_gradient_loss  | -0.00138     |
|    std                   | 0.938        |
|    value_loss            | 7.28         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 0.094      |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 0.094      |
| reward                   | -0.4638324 |
| rollout/                 |            |
|    ep_len_mean           | 954        |
|    ep_rew_mean           | -575       |
| time/                    |            |
|    fps                   | 5          |
|    iterations            | 21         |
|    time_elapsed          | 7815       |
|    total_timesteps       | 344064     |
| train/                   |            |
|    approx_kl             | 0.00335536 |
|    clip_fraction         | 0.0292     |
|    clip_range            | 0.2        |
|    cost_returns          | 7.2        |
|    cost_value_loss       | 65.8       |
|    cost_values           | 1.39       |
|    entropy               | -2.71      |
|    entropy_loss          | -2.71      |
|    explained_variance    | -0.278     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 33         |
|    n_updates             | 1670       |
|    policy_gradient_loss  | -0.00432   |
|    std                   | 0.939      |
|    value_loss            | 2.75       |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.176       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.176       |
| reward                   | -0.57385266 |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -576        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 22          |
|    time_elapsed          | 8158        |
|    total_timesteps       | 346112      |
| train/                   |             |
|    approx_kl             | 0.00486626  |
|    clip_fraction         | 0.0313      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.03        |
|    cost_value_loss       | 37          |
|    cost_values           | 1.66        |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | -1.09       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 19.1        |
|    n_updates             | 1680        |
|    policy_gradient_loss  | -0.00309    |
|    std                   | 0.94        |
|    value_loss            | 8.16        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.82         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 1.82         |
| reward                   | -0.26334947  |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -574         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 23           |
|    time_elapsed          | 8499         |
|    total_timesteps       | 348160       |
| train/                   |              |
|    approx_kl             | 0.0014432766 |
|    clip_fraction         | 0.00254      |
|    clip_range            | 0.2          |
|    cost_returns          | 11.7         |
|    cost_value_loss       | 124          |
|    cost_values           | 2.17         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.217        |
|    lagrangian_multiplier | 0.00313      |
|    learning_rate         | 0.0003       |
|    loss                  | 24.4         |
|    n_updates             | 1690         |
|    policy_gradient_loss  | -0.000994    |
|    std                   | 0.939        |
|    value_loss            | 3.63         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.39        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.39        |
| reward                   | -0.70743996 |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -565        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 24          |
|    time_elapsed          | 8843        |
|    total_timesteps       | 350208      |
| train/                   |             |
|    approx_kl             | 0.006396952 |
|    clip_fraction         | 0.0434      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.97        |
|    cost_value_loss       | 63.4        |
|    cost_values           | 2.61        |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | 0.582       |
|    lagrangian_multiplier | 0.00982     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.05        |
|    n_updates             | 1700        |
|    policy_gradient_loss  | -0.00487    |
|    std                   | 0.941       |
|    value_loss            | 2.91        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.734       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.734       |
| reward                   | -0.4048996  |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -564        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 25          |
|    time_elapsed          | 9191        |
|    total_timesteps       | 352256      |
| train/                   |             |
|    approx_kl             | 0.004948198 |
|    clip_fraction         | 0.028       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.46        |
|    cost_value_loss       | 25.6        |
|    cost_values           | 2.59        |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | 0.729       |
|    lagrangian_multiplier | 0.00476     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.87        |
|    n_updates             | 1710        |
|    policy_gradient_loss  | -0.00224    |
|    std                   | 0.941       |
|    value_loss            | 3.58        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.85         |
| reward                   | -0.73297304  |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -559         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 26           |
|    time_elapsed          | 9541         |
|    total_timesteps       | 354304       |
| train/                   |              |
|    approx_kl             | 0.0072499188 |
|    clip_fraction         | 0.174        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.97         |
|    cost_value_loss       | 14.8         |
|    cost_values           | 1.85         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.944        |
|    lagrangian_multiplier | 0.0246       |
|    learning_rate         | 0.0003       |
|    loss                  | 2.35         |
|    n_updates             | 1720         |
|    policy_gradient_loss  | 0.00726      |
|    std                   | 0.941        |
|    value_loss            | 6.31         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.163       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.163       |
| reward                   | -0.46273762 |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -560        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 27          |
|    time_elapsed          | 9902        |
|    total_timesteps       | 356352      |
| train/                   |             |
|    approx_kl             | 0.00401199  |
|    clip_fraction         | 0.0279      |
|    clip_range            | 0.2         |
|    cost_returns          | 7           |
|    cost_value_loss       | 60.8        |
|    cost_values           | 1.73        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.71       |
|    explained_variance    | 0.616       |
|    lagrangian_multiplier | 0.000828    |
|    learning_rate         | 0.0003      |
|    loss                  | 24.6        |
|    n_updates             | 1730        |
|    policy_gradient_loss  | -0.00477    |
|    std                   | 0.942       |
|    value_loss            | 7.91        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.6         |
| reward                   | -0.46169582 |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -557        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 28          |
|    time_elapsed          | 10259       |
|    total_timesteps       | 358400      |
| train/                   |             |
|    approx_kl             | 0.006247374 |
|    clip_fraction         | 0.022       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.6         |
|    cost_value_loss       | 22.9        |
|    cost_values           | 1.51        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.924       |
|    lagrangian_multiplier | 0.002       |
|    learning_rate         | 0.0003      |
|    loss                  | 6.74        |
|    n_updates             | 1740        |
|    policy_gradient_loss  | -0.00204    |
|    std                   | 0.943       |
|    value_loss            | 2.63        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.24         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.24         |
| reward                   | -0.63252246  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -552         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 29           |
|    time_elapsed          | 10619        |
|    total_timesteps       | 360448       |
| train/                   |              |
|    approx_kl             | 0.0040904107 |
|    clip_fraction         | 0.0403       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.52         |
|    cost_value_loss       | 51.5         |
|    cost_values           | 1.73         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.563        |
|    lagrangian_multiplier | 0.00053      |
|    learning_rate         | 0.0003       |
|    loss                  | 25           |
|    n_updates             | 1750         |
|    policy_gradient_loss  | -0.00377     |
|    std                   | 0.941        |
|    value_loss            | 5.73         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.77         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 2.77         |
| reward                   | -0.66598237  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -549         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 30           |
|    time_elapsed          | 10977        |
|    total_timesteps       | 362496       |
| train/                   |              |
|    approx_kl             | 0.0063589383 |
|    clip_fraction         | 0.0521       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.15         |
|    cost_value_loss       | 10.3         |
|    cost_values           | 2.03         |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.206        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.3         |
|    n_updates             | 1760         |
|    policy_gradient_loss  | -0.00449     |
|    std                   | 0.938        |
|    value_loss            | 14.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.596       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.596       |
| reward                   | -0.39112133 |
| rollout/                 |             |
|    ep_len_mean           | 976         |
|    ep_rew_mean           | -562        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 31          |
|    time_elapsed          | 11335       |
|    total_timesteps       | 364544      |
| train/                   |             |
|    approx_kl             | 0.004962909 |
|    clip_fraction         | 0.0467      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.38        |
|    cost_value_loss       | 50.9        |
|    cost_values           | 2.26        |
|    entropy               | -2.7        |
|    entropy_loss          | -2.7        |
|    explained_variance    | 0.392       |
|    lagrangian_multiplier | 0.00649     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.93        |
|    n_updates             | 1770        |
|    policy_gradient_loss  | -0.00522    |
|    std                   | 0.935       |
|    value_loss            | 4.24        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.51        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 2.51        |
| reward                   | -0.3071117  |
| rollout/                 |             |
|    ep_len_mean           | 969         |
|    ep_rew_mean           | -555        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 32          |
|    time_elapsed          | 11693       |
|    total_timesteps       | 366592      |
| train/                   |             |
|    approx_kl             | 0.005171978 |
|    clip_fraction         | 0.00889     |
|    clip_range            | 0.2         |
|    cost_returns          | 4.23        |
|    cost_value_loss       | 21          |
|    cost_values           | 1.58        |
|    entropy               | -2.7        |
|    entropy_loss          | -2.7        |
|    explained_variance    | 0.962       |
|    lagrangian_multiplier | 0.00322     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.72        |
|    n_updates             | 1780        |
|    policy_gradient_loss  | -0.00156    |
|    std                   | 0.934       |
|    value_loss            | 2.27        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.38         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 3.38         |
| reward                   | -0.5280687   |
| rollout/                 |              |
|    ep_len_mean           | 967          |
|    ep_rew_mean           | -551         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 33           |
|    time_elapsed          | 12049        |
|    total_timesteps       | 368640       |
| train/                   |              |
|    approx_kl             | 0.0038927677 |
|    clip_fraction         | 0.0161       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.68         |
|    cost_value_loss       | 17.3         |
|    cost_values           | 1.4          |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.0901       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.8         |
|    n_updates             | 1790         |
|    policy_gradient_loss  | -0.00152     |
|    std                   | 0.934        |
|    value_loss            | 14.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.57         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.57         |
| reward                   | -0.6218255   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -545         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 34           |
|    time_elapsed          | 12406        |
|    total_timesteps       | 370688       |
| train/                   |              |
|    approx_kl             | 0.0060112723 |
|    clip_fraction         | 0.0467       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.67         |
|    cost_value_loss       | 27.4         |
|    cost_values           | 1.44         |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.699        |
|    lagrangian_multiplier | 0.00188      |
|    learning_rate         | 0.0003       |
|    loss                  | 11.8         |
|    n_updates             | 1800         |
|    policy_gradient_loss  | -0.00409     |
|    std                   | 0.934        |
|    value_loss            | 13.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.12        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.12        |
| reward                   | -0.58701956 |
| rollout/                 |             |
|    ep_len_mean           | 961         |
|    ep_rew_mean           | -543        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 35          |
|    time_elapsed          | 12761       |
|    total_timesteps       | 372736      |
| train/                   |             |
|    approx_kl             | 0.00732079  |
|    clip_fraction         | 0.0586      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.41        |
|    cost_value_loss       | 29.6        |
|    cost_values           | 1.6         |
|    entropy               | -2.7        |
|    entropy_loss          | -2.7        |
|    explained_variance    | 0.181       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17.7        |
|    n_updates             | 1810        |
|    policy_gradient_loss  | -0.00401    |
|    std                   | 0.934       |
|    value_loss            | 13.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.57972324  |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -540         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 36           |
|    time_elapsed          | 13120        |
|    total_timesteps       | 374784       |
| train/                   |              |
|    approx_kl             | 0.0051485337 |
|    clip_fraction         | 0.0371       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.68         |
|    cost_value_loss       | 47.8         |
|    cost_values           | 2.07         |
|    entropy               | -2.7         |
|    entropy_loss          | -2.7         |
|    explained_variance    | -0.76        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 25.4         |
|    n_updates             | 1820         |
|    policy_gradient_loss  | -0.0042      |
|    std                   | 0.934        |
|    value_loss            | 4.23         |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.501         |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.501         |
| reward                   | -0.31447926   |
| rollout/                 |               |
|    ep_len_mean           | 959           |
|    ep_rew_mean           | -535          |
| time/                    |               |
|    fps                   | 5             |
|    iterations            | 37            |
|    time_elapsed          | 13479         |
|    total_timesteps       | 376832        |
| train/                   |               |
|    approx_kl             | 0.00023079864 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 3.35          |
|    cost_value_loss       | 13.2          |
|    cost_values           | 1.8           |
|    entropy               | -2.7          |
|    entropy_loss          | -2.7          |
|    explained_variance    | 0.706         |
|    lagrangian_multiplier | 0.0427        |
|    learning_rate         | 0.0003        |
|    loss                  | 2.29          |
|    n_updates             | 1830          |
|    policy_gradient_loss  | 7.73e-05      |
|    std                   | 0.933         |
|    value_loss            | 14.3          |
--------------------------------------------
------------------------------------------
| avg_speed                | 2.78        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.78        |
| reward                   | -0.31200197 |
| rollout/                 |             |
|    ep_len_mean           | 959         |
|    ep_rew_mean           | -534        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 38          |
|    time_elapsed          | 13844       |
|    total_timesteps       | 378880      |
| train/                   |             |
|    approx_kl             | 0.004041361 |
|    clip_fraction         | 0.0289      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.7         |
|    cost_value_loss       | 23.2        |
|    cost_values           | 1.29        |
|    entropy               | -2.68       |
|    entropy_loss          | -2.69       |
|    explained_variance    | 0.498       |
|    lagrangian_multiplier | 0.00147     |
|    learning_rate         | 0.0003      |
|    loss                  | 11.4        |
|    n_updates             | 1840        |
|    policy_gradient_loss  | -0.00355    |
|    std                   | 0.927       |
|    value_loss            | 13.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.906        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.906        |
| reward                   | -0.55991805  |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -522         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 39           |
|    time_elapsed          | 14211        |
|    total_timesteps       | 380928       |
| train/                   |              |
|    approx_kl             | 0.0018297967 |
|    clip_fraction         | 0.0102       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.19         |
|    cost_value_loss       | 40.2         |
|    cost_values           | 1.1          |
|    entropy               | -2.68        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0.906        |
|    lagrangian_multiplier | 0.0026       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.74         |
|    n_updates             | 1850         |
|    policy_gradient_loss  | -0.00223     |
|    std                   | 0.926        |
|    value_loss            | 2.96         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.5907885  |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -521        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 40          |
|    time_elapsed          | 14576       |
|    total_timesteps       | 382976      |
| train/                   |             |
|    approx_kl             | 0.005756635 |
|    clip_fraction         | 0.0204      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.84        |
|    cost_value_loss       | 10.3        |
|    cost_values           | 0.91        |
|    entropy               | -2.68       |
|    entropy_loss          | -2.68       |
|    explained_variance    | 0.821       |
|    lagrangian_multiplier | 0.00231     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.31        |
|    n_updates             | 1860        |
|    policy_gradient_loss  | -0.00205    |
|    std                   | 0.926       |
|    value_loss            | 13.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.9          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.9          |
| reward                   | -0.62837553  |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -525         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 41           |
|    time_elapsed          | 14940        |
|    total_timesteps       | 385024       |
| train/                   |              |
|    approx_kl             | 0.0030254894 |
|    clip_fraction         | 0.0324       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.22         |
|    cost_value_loss       | 25.7         |
|    cost_values           | 0.834        |
|    entropy               | -2.68        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0.885        |
|    lagrangian_multiplier | 3.34e-05     |
|    learning_rate         | 0.0003       |
|    loss                  | 11.2         |
|    n_updates             | 1870         |
|    policy_gradient_loss  | -0.00313     |
|    std                   | 0.926        |
|    value_loss            | 3.32         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0115       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0115       |
| reward                   | -0.7406653   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -524         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 42           |
|    time_elapsed          | 15313        |
|    total_timesteps       | 387072       |
| train/                   |              |
|    approx_kl             | 0.0046998244 |
|    clip_fraction         | 0.0228       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.81         |
|    cost_value_loss       | 20.4         |
|    cost_values           | 0.796        |
|    entropy               | -2.68        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0.967        |
|    lagrangian_multiplier | 0.000574     |
|    learning_rate         | 0.0003       |
|    loss                  | 9.35         |
|    n_updates             | 1880         |
|    policy_gradient_loss  | -0.00308     |
|    std                   | 0.925        |
|    value_loss            | 1.94         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -0.9496906   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -523         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 43           |
|    time_elapsed          | 15690        |
|    total_timesteps       | 389120       |
| train/                   |              |
|    approx_kl             | 0.0050293775 |
|    clip_fraction         | 0.0366       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.5          |
|    cost_value_loss       | 35.7         |
|    cost_values           | 1.17         |
|    entropy               | -2.67        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0.755        |
|    lagrangian_multiplier | 0.00205      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.44         |
|    n_updates             | 1890         |
|    policy_gradient_loss  | -0.00356     |
|    std                   | 0.922        |
|    value_loss            | 5.87         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.92        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.92        |
| reward                   | -0.5337593  |
| rollout/                 |             |
|    ep_len_mean           | 956         |
|    ep_rew_mean           | -519        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 44          |
|    time_elapsed          | 16064       |
|    total_timesteps       | 391168      |
| train/                   |             |
|    approx_kl             | 0.006642706 |
|    clip_fraction         | 0.0459      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.73        |
|    cost_value_loss       | 27.1        |
|    cost_values           | 1.22        |
|    entropy               | -2.67       |
|    entropy_loss          | -2.67       |
|    explained_variance    | 0.901       |
|    lagrangian_multiplier | 0.00665     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.16        |
|    n_updates             | 1900        |
|    policy_gradient_loss  | -0.00436    |
|    std                   | 0.923       |
|    value_loss            | 6.25        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.67         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.67         |
| reward                   | -0.5023964   |
| rollout/                 |              |
|    ep_len_mean           | 961          |
|    ep_rew_mean           | -523         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 45           |
|    time_elapsed          | 16442        |
|    total_timesteps       | 393216       |
| train/                   |              |
|    approx_kl             | 0.0039768107 |
|    clip_fraction         | 0.0129       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.79         |
|    cost_value_loss       | 21           |
|    cost_values           | 1.04         |
|    entropy               | -2.68        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0.838        |
|    lagrangian_multiplier | 0.00277      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.49         |
|    n_updates             | 1910         |
|    policy_gradient_loss  | -0.00212     |
|    std                   | 0.924        |
|    value_loss            | 12.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.769       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.769       |
| reward                   | -0.18603957 |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -513        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 46          |
|    time_elapsed          | 16823       |
|    total_timesteps       | 395264      |
| train/                   |             |
|    approx_kl             | 0.003262483 |
|    clip_fraction         | 0.0149      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.87        |
|    cost_value_loss       | 20.9        |
|    cost_values           | 0.878       |
|    entropy               | -2.67       |
|    entropy_loss          | -2.67       |
|    explained_variance    | 0.976       |
|    lagrangian_multiplier | 0.000201    |
|    learning_rate         | 0.0003      |
|    loss                  | 10.8        |
|    n_updates             | 1920        |
|    policy_gradient_loss  | -0.0033     |
|    std                   | 0.921       |
|    value_loss            | 1.98        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.36         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.36         |
| reward                   | -0.5260935   |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -510         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 47           |
|    time_elapsed          | 17202        |
|    total_timesteps       | 397312       |
| train/                   |              |
|    approx_kl             | 0.0023989128 |
|    clip_fraction         | 0.0263       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.87         |
|    cost_value_loss       | 10.2         |
|    cost_values           | 0.752        |
|    entropy               | -2.67        |
|    entropy_loss          | -2.67        |
|    explained_variance    | 0.861        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.1         |
|    n_updates             | 1930         |
|    policy_gradient_loss  | -0.00175     |
|    std                   | 0.92         |
|    value_loss            | 15.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.55        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.55        |
| reward                   | -0.38506347 |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -509        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 48          |
|    time_elapsed          | 17587       |
|    total_timesteps       | 399360      |
| train/                   |             |
|    approx_kl             | 0.011240589 |
|    clip_fraction         | 0.0614      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.15        |
|    cost_value_loss       | 14.1        |
|    cost_values           | 1.08        |
|    entropy               | -2.66       |
|    entropy_loss          | -2.67       |
|    explained_variance    | 0.887       |
|    lagrangian_multiplier | 0.00359     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.61        |
|    n_updates             | 1940        |
|    policy_gradient_loss  | -0.00503    |
|    std                   | 0.919       |
|    value_loss            | 3.2         |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.29         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.29         |
| reward                   | -0.69061613  |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -505         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 49           |
|    time_elapsed          | 17970        |
|    total_timesteps       | 401408       |
| train/                   |              |
|    approx_kl             | 0.0067740697 |
|    clip_fraction         | 0.0881       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.75         |
|    cost_value_loss       | 27.8         |
|    cost_values           | 1            |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.937        |
|    lagrangian_multiplier | 0.0059       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.65         |
|    n_updates             | 1950         |
|    policy_gradient_loss  | -0.00368     |
|    std                   | 0.918        |
|    value_loss            | 1.99         |
-------------------------------------------
-----------------------------------
| avg_speed          | 2.26       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 2.26       |
| reward             | -0.6473237 |
| rollout/           |            |
|    ep_len_mean     | 951        |
|    ep_rew_mean     | -504       |
| time/              |            |
|    fps             | 5          |
|    iterations      | 1          |
|    time_elapsed    | 384        |
|    total_timesteps | 403456     |
-----------------------------------
------------------------------------------
| avg_speed                | 0.267       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.267       |
| reward                   | -0.726186   |
| rollout/                 |             |
|    ep_len_mean           | 951         |
|    ep_rew_mean           | -500        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 2           |
|    time_elapsed          | 768         |
|    total_timesteps       | 405504      |
| train/                   |             |
|    approx_kl             | 0.005392279 |
|    clip_fraction         | 0.039       |
|    clip_range            | 0.2         |
|    cost_returns          | 7.42        |
|    cost_value_loss       | 77.3        |
|    cost_values           | 1.78        |
|    entropy               | -2.65       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0.85        |
|    lagrangian_multiplier | 0.00801     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.78        |
|    n_updates             | 1970        |
|    policy_gradient_loss  | -0.00615    |
|    std                   | 0.912       |
|    value_loss            | 3.07        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.332        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.332        |
| reward                   | -0.30516395  |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -496         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 3            |
|    time_elapsed          | 1143         |
|    total_timesteps       | 407552       |
| train/                   |              |
|    approx_kl             | 0.0027664471 |
|    clip_fraction         | 0.0163       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.29         |
|    cost_value_loss       | 44.2         |
|    cost_values           | 1.81         |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.814        |
|    lagrangian_multiplier | 0.00702      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.83         |
|    n_updates             | 1980         |
|    policy_gradient_loss  | -0.000469    |
|    std                   | 0.906        |
|    value_loss            | 4.03         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.344       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.344       |
| reward                   | -0.45228744 |
| rollout/                 |             |
|    ep_len_mean           | 943         |
|    ep_rew_mean           | -489        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 4           |
|    time_elapsed          | 1519        |
|    total_timesteps       | 409600      |
| train/                   |             |
|    approx_kl             | 0.003941804 |
|    clip_fraction         | 0.0556      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.24        |
|    cost_value_loss       | 53          |
|    cost_values           | 1.78        |
|    entropy               | -2.63       |
|    entropy_loss          | -2.63       |
|    explained_variance    | 0.798       |
|    lagrangian_multiplier | 0.00624     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.06        |
|    n_updates             | 1990        |
|    policy_gradient_loss  | -0.00338    |
|    std                   | 0.902       |
|    value_loss            | 4.73        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.53         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.53         |
| reward                   | -0.7225568   |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -489         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 5            |
|    time_elapsed          | 1898         |
|    total_timesteps       | 411648       |
| train/                   |              |
|    approx_kl             | 0.0032885436 |
|    clip_fraction         | 0.0442       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.61         |
|    cost_value_loss       | 65.7         |
|    cost_values           | 1.57         |
|    entropy               | -2.62        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.818        |
|    lagrangian_multiplier | 0.00941      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.2          |
|    n_updates             | 2000         |
|    policy_gradient_loss  | -0.00281     |
|    std                   | 0.901        |
|    value_loss            | 15.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.14         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.14         |
| reward                   | -0.5543404   |
| rollout/                 |              |
|    ep_len_mean           | 943          |
|    ep_rew_mean           | -486         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 6            |
|    time_elapsed          | 2280         |
|    total_timesteps       | 413696       |
| train/                   |              |
|    approx_kl             | 0.0037436448 |
|    clip_fraction         | 0.0266       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.57         |
|    cost_value_loss       | 52.5         |
|    cost_values           | 1.27         |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.85         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 26.7         |
|    n_updates             | 2010         |
|    policy_gradient_loss  | -0.00431     |
|    std                   | 0.901        |
|    value_loss            | 3.8          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.4          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.4          |
| reward                   | -0.36019632  |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -484         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 7            |
|    time_elapsed          | 2665         |
|    total_timesteps       | 415744       |
| train/                   |              |
|    approx_kl             | 0.0026623607 |
|    clip_fraction         | 0.00303      |
|    clip_range            | 0.2          |
|    cost_returns          | 8.61         |
|    cost_value_loss       | 80.4         |
|    cost_values           | 1.76         |
|    entropy               | -2.63        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.65         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 40.2         |
|    n_updates             | 2020         |
|    policy_gradient_loss  | -0.00126     |
|    std                   | 0.903        |
|    value_loss            | 10           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.91         |
| reward                   | -0.74819595  |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -485         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 8            |
|    time_elapsed          | 3052         |
|    total_timesteps       | 417792       |
| train/                   |              |
|    approx_kl             | 0.0058887564 |
|    clip_fraction         | 0.051        |
|    clip_range            | 0.2          |
|    cost_returns          | 7.08         |
|    cost_value_loss       | 54.9         |
|    cost_values           | 2.14         |
|    entropy               | -2.63        |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.535        |
|    lagrangian_multiplier | 0.00476      |
|    learning_rate         | 0.0003       |
|    loss                  | 11.4         |
|    n_updates             | 2030         |
|    policy_gradient_loss  | -0.00844     |
|    std                   | 0.902        |
|    value_loss            | 13.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.78        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.78        |
| reward                   | -0.68656105 |
| rollout/                 |             |
|    ep_len_mean           | 938         |
|    ep_rew_mean           | -484        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 9           |
|    time_elapsed          | 3438        |
|    total_timesteps       | 419840      |
| train/                   |             |
|    approx_kl             | 0.003930804 |
|    clip_fraction         | 0.0116      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.93        |
|    cost_value_loss       | 81.3        |
|    cost_values           | 2.59        |
|    entropy               | -2.62       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0.837       |
|    lagrangian_multiplier | 0.0112      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.61        |
|    n_updates             | 2040        |
|    policy_gradient_loss  | -0.00348    |
|    std                   | 0.898       |
|    value_loss            | 4.53        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.442       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.442       |
| reward                   | -0.19703624 |
| rollout/                 |             |
|    ep_len_mean           | 938         |
|    ep_rew_mean           | -485        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 10          |
|    time_elapsed          | 3828        |
|    total_timesteps       | 421888      |
| train/                   |             |
|    approx_kl             | 0.008809567 |
|    clip_fraction         | 0.127       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.54        |
|    cost_value_loss       | 3.72        |
|    cost_values           | 1.86        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.916       |
|    lagrangian_multiplier | 0.123       |
|    learning_rate         | 0.0003      |
|    loss                  | 1.85        |
|    n_updates             | 2050        |
|    policy_gradient_loss  | 0.000899    |
|    std                   | 0.895       |
|    value_loss            | 5.22        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.17         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.17         |
| reward                   | -0.5200636   |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -487         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 11           |
|    time_elapsed          | 4220         |
|    total_timesteps       | 423936       |
| train/                   |              |
|    approx_kl             | 0.0053921593 |
|    clip_fraction         | 0.0359       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.93         |
|    cost_value_loss       | 15.8         |
|    cost_values           | 1.1          |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.789        |
|    lagrangian_multiplier | 0.002        |
|    learning_rate         | 0.0003       |
|    loss                  | 6.42         |
|    n_updates             | 2060         |
|    policy_gradient_loss  | -0.00494     |
|    std                   | 0.894        |
|    value_loss            | 7.48         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.76         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.76         |
| reward                   | -0.32453105  |
| rollout/                 |              |
|    ep_len_mean           | 918          |
|    ep_rew_mean           | -475         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 12           |
|    time_elapsed          | 4617         |
|    total_timesteps       | 425984       |
| train/                   |              |
|    approx_kl             | 0.0026925541 |
|    clip_fraction         | 0.0156       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.01         |
|    cost_value_loss       | 63.4         |
|    cost_values           | 1.33         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.576        |
|    lagrangian_multiplier | 0.000896     |
|    learning_rate         | 0.0003       |
|    loss                  | 21.8         |
|    n_updates             | 2070         |
|    policy_gradient_loss  | -0.00245     |
|    std                   | 0.894        |
|    value_loss            | 4.98         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.17        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.17        |
| reward                   | -0.548517   |
| rollout/                 |             |
|    ep_len_mean           | 918         |
|    ep_rew_mean           | -475        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 13          |
|    time_elapsed          | 5016        |
|    total_timesteps       | 428032      |
| train/                   |             |
|    approx_kl             | 0.004323748 |
|    clip_fraction         | 0.0416      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.44        |
|    cost_value_loss       | 17.2        |
|    cost_values           | 1.23        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.62        |
|    lagrangian_multiplier | 0.00335     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.88        |
|    n_updates             | 2080        |
|    policy_gradient_loss  | -0.00516    |
|    std                   | 0.894       |
|    value_loss            | 26.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.601       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.601       |
| reward                   | -0.5072805  |
| rollout/                 |             |
|    ep_len_mean           | 918         |
|    ep_rew_mean           | -476        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 14          |
|    time_elapsed          | 5414        |
|    total_timesteps       | 430080      |
| train/                   |             |
|    approx_kl             | 0.003925559 |
|    clip_fraction         | 0.0263      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.78        |
|    cost_value_loss       | 61          |
|    cost_values           | 1.16        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.874       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 32.6        |
|    n_updates             | 2090        |
|    policy_gradient_loss  | -0.00391    |
|    std                   | 0.895       |
|    value_loss            | 3.36        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0469       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0469       |
| reward                   | -0.48301962  |
| rollout/                 |              |
|    ep_len_mean           | 918          |
|    ep_rew_mean           | -475         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 15           |
|    time_elapsed          | 5810         |
|    total_timesteps       | 432128       |
| train/                   |              |
|    approx_kl             | 0.0036654766 |
|    clip_fraction         | 0.0061       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.09         |
|    cost_value_loss       | 84.5         |
|    cost_values           | 1.6          |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.285        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 43.4         |
|    n_updates             | 2100         |
|    policy_gradient_loss  | -0.00229     |
|    std                   | 0.893        |
|    value_loss            | 5.67         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.358        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.358        |
| reward                   | -0.5994169   |
| rollout/                 |              |
|    ep_len_mean           | 918          |
|    ep_rew_mean           | -478         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 16           |
|    time_elapsed          | 6212         |
|    total_timesteps       | 434176       |
| train/                   |              |
|    approx_kl             | 0.0036551696 |
|    clip_fraction         | 0.0151       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.71         |
|    cost_value_loss       | 34.7         |
|    cost_values           | 1.39         |
|    entropy               | -2.6         |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0.857        |
|    lagrangian_multiplier | 0.000276     |
|    learning_rate         | 0.0003       |
|    loss                  | 16.4         |
|    n_updates             | 2110         |
|    policy_gradient_loss  | -0.00351     |
|    std                   | 0.891        |
|    value_loss            | 3.09         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.15        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.15        |
| reward                   | -0.50821066 |
| rollout/                 |             |
|    ep_len_mean           | 918         |
|    ep_rew_mean           | -474        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 17          |
|    time_elapsed          | 6616        |
|    total_timesteps       | 436224      |
| train/                   |             |
|    approx_kl             | 0.005057548 |
|    clip_fraction         | 0.0358      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.29        |
|    cost_value_loss       | 92.3        |
|    cost_values           | 1.6         |
|    entropy               | -2.6        |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0.675       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 45.9        |
|    n_updates             | 2120        |
|    policy_gradient_loss  | -0.00329    |
|    std                   | 0.89        |
|    value_loss            | 2.75        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.475        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.475        |
| reward                   | -0.47393128  |
| rollout/                 |              |
|    ep_len_mean           | 917          |
|    ep_rew_mean           | -472         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 18           |
|    time_elapsed          | 7026         |
|    total_timesteps       | 438272       |
| train/                   |              |
|    approx_kl             | 0.0039453744 |
|    clip_fraction         | 0.0218       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.77         |
|    cost_value_loss       | 96.7         |
|    cost_values           | 2.02         |
|    entropy               | -2.6         |
|    entropy_loss          | -2.6         |
|    explained_variance    | 0.514        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 48.8         |
|    n_updates             | 2130         |
|    policy_gradient_loss  | -0.00372     |
|    std                   | 0.889        |
|    value_loss            | 3.36         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.522       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.522       |
| reward                   | -0.65693676 |
| rollout/                 |             |
|    ep_len_mean           | 917         |
|    ep_rew_mean           | -468        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 19          |
|    time_elapsed          | 7436        |
|    total_timesteps       | 440320      |
| train/                   |             |
|    approx_kl             | 0.004978087 |
|    clip_fraction         | 0.00811     |
|    clip_range            | 0.2         |
|    cost_returns          | 10.5        |
|    cost_value_loss       | 96.6        |
|    cost_values           | 2.55        |
|    entropy               | -2.59       |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0.409       |
|    lagrangian_multiplier | 0.0148      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.58        |
|    n_updates             | 2140        |
|    policy_gradient_loss  | -0.00113    |
|    std                   | 0.886       |
|    value_loss            | 13          |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.487        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.487        |
| reward                   | -0.6471091   |
| rollout/                 |              |
|    ep_len_mean           | 914          |
|    ep_rew_mean           | -467         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 20           |
|    time_elapsed          | 7848         |
|    total_timesteps       | 442368       |
| train/                   |              |
|    approx_kl             | 0.0033359323 |
|    clip_fraction         | 0.0353       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.21         |
|    cost_value_loss       | 62.1         |
|    cost_values           | 2.8          |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.558        |
|    lagrangian_multiplier | 0.00851      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.09         |
|    n_updates             | 2150         |
|    policy_gradient_loss  | -0.0036      |
|    std                   | 0.884        |
|    value_loss            | 7.27         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.5         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.5         |
| reward                   | -0.60978717 |
| rollout/                 |             |
|    ep_len_mean           | 914         |
|    ep_rew_mean           | -465        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 21          |
|    time_elapsed          | 8258        |
|    total_timesteps       | 444416      |
| train/                   |             |
|    approx_kl             | 0.005102288 |
|    clip_fraction         | 0.0396      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.68        |
|    cost_value_loss       | 41.1        |
|    cost_values           | 2.74        |
|    entropy               | -2.58       |
|    entropy_loss          | -2.59       |
|    explained_variance    | 0.0809      |
|    lagrangian_multiplier | 0.00862     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.84        |
|    n_updates             | 2160        |
|    policy_gradient_loss  | -0.00358    |
|    std                   | 0.882       |
|    value_loss            | 13.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.43        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.43        |
| reward                   | -0.3738334  |
| rollout/                 |             |
|    ep_len_mean           | 914         |
|    ep_rew_mean           | -463        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 22          |
|    time_elapsed          | 8673        |
|    total_timesteps       | 446464      |
| train/                   |             |
|    approx_kl             | 0.005115405 |
|    clip_fraction         | 0.0427      |
|    clip_range            | 0.2         |
|    cost_returns          | 10.4        |
|    cost_value_loss       | 95.8        |
|    cost_values           | 2.68        |
|    entropy               | -2.58       |
|    entropy_loss          | -2.58       |
|    explained_variance    | -0.312      |
|    lagrangian_multiplier | 0.0162      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.58        |
|    n_updates             | 2170        |
|    policy_gradient_loss  | -0.00262    |
|    std                   | 0.881       |
|    value_loss            | 1.63        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.33         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 2.33         |
| reward                   | -0.3945248   |
| rollout/                 |              |
|    ep_len_mean           | 913          |
|    ep_rew_mean           | -461         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 23           |
|    time_elapsed          | 9084         |
|    total_timesteps       | 448512       |
| train/                   |              |
|    approx_kl             | 0.0028626213 |
|    clip_fraction         | 0.0515       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.6         |
|    cost_value_loss       | 105          |
|    cost_values           | 2.85         |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.562        |
|    lagrangian_multiplier | 0.0153       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.23         |
|    n_updates             | 2180         |
|    policy_gradient_loss  | -0.00436     |
|    std                   | 0.882        |
|    value_loss            | 3.19         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.67        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.67        |
| reward                   | -0.23521748 |
| rollout/                 |             |
|    ep_len_mean           | 913         |
|    ep_rew_mean           | -460        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 24          |
|    time_elapsed          | 9498        |
|    total_timesteps       | 450560      |
| train/                   |             |
|    approx_kl             | 0.00966985  |
|    clip_fraction         | 0.0401      |
|    clip_range            | 0.2         |
|    cost_returns          | 9           |
|    cost_value_loss       | 74.6        |
|    cost_values           | 2.86        |
|    entropy               | -2.58       |
|    entropy_loss          | -2.58       |
|    explained_variance    | 0.551       |
|    lagrangian_multiplier | 0.0106      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.29        |
|    n_updates             | 2190        |
|    policy_gradient_loss  | -0.00154    |
|    std                   | 0.88        |
|    value_loss            | 12.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0734      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0734      |
| reward                   | -0.45916218 |
| rollout/                 |             |
|    ep_len_mean           | 916         |
|    ep_rew_mean           | -463        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 25          |
|    time_elapsed          | 9916        |
|    total_timesteps       | 452608      |
| train/                   |             |
|    approx_kl             | 0.004566766 |
|    clip_fraction         | 0.0469      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.52        |
|    cost_value_loss       | 38.2        |
|    cost_values           | 2.69        |
|    entropy               | -2.57       |
|    entropy_loss          | -2.57       |
|    explained_variance    | 0.36        |
|    lagrangian_multiplier | 0.00629     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.31        |
|    n_updates             | 2200        |
|    policy_gradient_loss  | -0.00624    |
|    std                   | 0.877       |
|    value_loss            | 3.01        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.332        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.332        |
| reward                   | -0.39370283  |
| rollout/                 |              |
|    ep_len_mean           | 916          |
|    ep_rew_mean           | -462         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 26           |
|    time_elapsed          | 10334        |
|    total_timesteps       | 454656       |
| train/                   |              |
|    approx_kl             | 0.0054144263 |
|    clip_fraction         | 0.0434       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.3         |
|    cost_value_loss       | 115          |
|    cost_values           | 2.73         |
|    entropy               | -2.56        |
|    entropy_loss          | -2.57        |
|    explained_variance    | 0.737        |
|    lagrangian_multiplier | 0.0168       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.38         |
|    n_updates             | 2210         |
|    policy_gradient_loss  | -0.00195     |
|    std                   | 0.875        |
|    value_loss            | 2.91         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0456       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0456       |
| reward                   | -0.6711122   |
| rollout/                 |              |
|    ep_len_mean           | 916          |
|    ep_rew_mean           | -457         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 27           |
|    time_elapsed          | 10757        |
|    total_timesteps       | 456704       |
| train/                   |              |
|    approx_kl             | 0.0073134378 |
|    clip_fraction         | 0.0583       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.58         |
|    cost_value_loss       | 81.4         |
|    cost_values           | 2.79         |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0.667        |
|    lagrangian_multiplier | 0.0131       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.89         |
|    n_updates             | 2220         |
|    policy_gradient_loss  | -0.00632     |
|    std                   | 0.874        |
|    value_loss            | 1.73         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.179        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.179        |
| reward                   | -0.3571229   |
| rollout/                 |              |
|    ep_len_mean           | 923          |
|    ep_rew_mean           | -462         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 28           |
|    time_elapsed          | 11182        |
|    total_timesteps       | 458752       |
| train/                   |              |
|    approx_kl             | 0.0048102904 |
|    clip_fraction         | 0.0252       |
|    clip_range            | 0.2          |
|    cost_returns          | 11           |
|    cost_value_loss       | 106          |
|    cost_values           | 2.79         |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0.796        |
|    lagrangian_multiplier | 0.00882      |
|    learning_rate         | 0.0003       |
|    loss                  | 12.2         |
|    n_updates             | 2230         |
|    policy_gradient_loss  | -0.00192     |
|    std                   | 0.871        |
|    value_loss            | 2.91         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.147       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.147       |
| reward                   | -0.44548774 |
| rollout/                 |             |
|    ep_len_mean           | 926         |
|    ep_rew_mean           | -462        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 29          |
|    time_elapsed          | 11612       |
|    total_timesteps       | 460800      |
| train/                   |             |
|    approx_kl             | 0.010353873 |
|    clip_fraction         | 0.0578      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.5        |
|    cost_value_loss       | 133         |
|    cost_values           | 2.79        |
|    entropy               | -2.54       |
|    entropy_loss          | -2.55       |
|    explained_variance    | 0.921       |
|    lagrangian_multiplier | 0.0248      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.6         |
|    n_updates             | 2240        |
|    policy_gradient_loss  | -0.005      |
|    std                   | 0.865       |
|    value_loss            | 2.03        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0469       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0469       |
| reward                   | -0.40655443  |
| rollout/                 |              |
|    ep_len_mean           | 926          |
|    ep_rew_mean           | -462         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 30           |
|    time_elapsed          | 12037        |
|    total_timesteps       | 462848       |
| train/                   |              |
|    approx_kl             | 0.0047465777 |
|    clip_fraction         | 0.0308       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.3         |
|    cost_value_loss       | 91.5         |
|    cost_values           | 2.9          |
|    entropy               | -2.55        |
|    entropy_loss          | -2.54        |
|    explained_variance    | -1.1         |
|    lagrangian_multiplier | 0.0143       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.84         |
|    n_updates             | 2250         |
|    policy_gradient_loss  | -0.00249     |
|    std                   | 0.867        |
|    value_loss            | 2.01         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.518        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.518        |
| reward                   | -0.45814857  |
| rollout/                 |              |
|    ep_len_mean           | 931          |
|    ep_rew_mean           | -464         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 31           |
|    time_elapsed          | 12491        |
|    total_timesteps       | 464896       |
| train/                   |              |
|    approx_kl             | 0.0059180604 |
|    clip_fraction         | 0.0497       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.9          |
|    cost_value_loss       | 36.1         |
|    cost_values           | 2.9          |
|    entropy               | -2.53        |
|    entropy_loss          | -2.54        |
|    explained_variance    | 0.399        |
|    lagrangian_multiplier | 0.00452      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.05         |
|    n_updates             | 2260         |
|    policy_gradient_loss  | -0.00178     |
|    std                   | 0.861        |
|    value_loss            | 3.02         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.5         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 1.5         |
| reward                   | -0.3850484  |
| rollout/                 |             |
|    ep_len_mean           | 924         |
|    ep_rew_mean           | -459        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 32          |
|    time_elapsed          | 12948       |
|    total_timesteps       | 466944      |
| train/                   |             |
|    approx_kl             | 0.002680406 |
|    clip_fraction         | 0.0551      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.4        |
|    cost_value_loss       | 117         |
|    cost_values           | 2.97        |
|    entropy               | -2.53       |
|    entropy_loss          | -2.53       |
|    explained_variance    | 0.0735      |
|    lagrangian_multiplier | 0.0234      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.57        |
|    n_updates             | 2270        |
|    policy_gradient_loss  | -0.00116    |
|    std                   | 0.859       |
|    value_loss            | 1.83        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.328       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.328       |
| reward                   | -0.35236955 |
| rollout/                 |             |
|    ep_len_mean           | 924         |
|    ep_rew_mean           | -458        |
| time/                    |             |
|    fps                   | 5           |
|    iterations            | 33          |
|    time_elapsed          | 13405       |
|    total_timesteps       | 468992      |
| train/                   |             |
|    approx_kl             | 0.003282286 |
|    clip_fraction         | 0.0359      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.12        |
|    cost_value_loss       | 71.6        |
|    cost_values           | 2.96        |
|    entropy               | -2.53       |
|    entropy_loss          | -2.53       |
|    explained_variance    | -0.0784     |
|    lagrangian_multiplier | 0.0104      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.14        |
|    n_updates             | 2280        |
|    policy_gradient_loss  | -0.00295    |
|    std                   | 0.86        |
|    value_loss            | 13.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.05         |
| reward                   | -0.65961456  |
| rollout/                 |              |
|    ep_len_mean           | 923          |
|    ep_rew_mean           | -454         |
| time/                    |              |
|    fps                   | 5            |
|    iterations            | 34           |
|    time_elapsed          | 13876        |
|    total_timesteps       | 471040       |
| train/                   |              |
|    approx_kl             | 0.0062443716 |
|    clip_fraction         | 0.0479       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.46         |
|    cost_value_loss       | 71.5         |
|    cost_values           | 2.98         |
|    entropy               | -2.53        |
|    entropy_loss          | -2.53        |
|    explained_variance    | 0.118        |
|    lagrangian_multiplier | 0.0135       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.26         |
|    n_updates             | 2290         |
|    policy_gradient_loss  | -0.0043      |
|    std                   | 0.861        |
|    value_loss            | 4.56         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.22        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.22        |
| reward                   | -0.2581903  |
| rollout/                 |             |
|    ep_len_mean           | 927         |
|    ep_rew_mean           | -456        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 35          |
|    time_elapsed          | 14338       |
|    total_timesteps       | 473088      |
| train/                   |             |
|    approx_kl             | 0.006505617 |
|    clip_fraction         | 0.0836      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.54        |
|    cost_value_loss       | 41.2        |
|    cost_values           | 2.7         |
|    entropy               | -2.53       |
|    entropy_loss          | -2.53       |
|    explained_variance    | 0.759       |
|    lagrangian_multiplier | 0.00806     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.99        |
|    n_updates             | 2300        |
|    policy_gradient_loss  | -0.000941   |
|    std                   | 0.86        |
|    value_loss            | 10          |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.47         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.47         |
| reward                   | -0.7103868   |
| rollout/                 |              |
|    ep_len_mean           | 927          |
|    ep_rew_mean           | -451         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 36           |
|    time_elapsed          | 14806        |
|    total_timesteps       | 475136       |
| train/                   |              |
|    approx_kl             | 0.0054665995 |
|    clip_fraction         | 0.0288       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.22         |
|    cost_value_loss       | 37           |
|    cost_values           | 2.32         |
|    entropy               | -2.53        |
|    entropy_loss          | -2.53        |
|    explained_variance    | 0.904        |
|    lagrangian_multiplier | 0.00658      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.57         |
|    n_updates             | 2310         |
|    policy_gradient_loss  | -0.000331    |
|    std                   | 0.859        |
|    value_loss            | 4.52         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 3.02        |
| reward                   | -0.46564746 |
| rollout/                 |             |
|    ep_len_mean           | 927         |
|    ep_rew_mean           | -451        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 37          |
|    time_elapsed          | 15282       |
|    total_timesteps       | 477184      |
| train/                   |             |
|    approx_kl             | 0.006250376 |
|    clip_fraction         | 0.0484      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.89        |
|    cost_value_loss       | 62          |
|    cost_values           | 2.41        |
|    entropy               | -2.53       |
|    entropy_loss          | -2.53       |
|    explained_variance    | 0.473       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 34.2        |
|    n_updates             | 2320        |
|    policy_gradient_loss  | -0.00511    |
|    std                   | 0.858       |
|    value_loss            | 10.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.478        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.478        |
| reward                   | -0.6095275   |
| rollout/                 |              |
|    ep_len_mean           | 927          |
|    ep_rew_mean           | -454         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 38           |
|    time_elapsed          | 15752        |
|    total_timesteps       | 479232       |
| train/                   |              |
|    approx_kl             | 0.0030339332 |
|    clip_fraction         | 0.00371      |
|    clip_range            | 0.2          |
|    cost_returns          | 10.9         |
|    cost_value_loss       | 94.1         |
|    cost_values           | 2.78         |
|    entropy               | -2.52        |
|    entropy_loss          | -2.53        |
|    explained_variance    | -0.0619      |
|    lagrangian_multiplier | 0.0175       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.56         |
|    n_updates             | 2330         |
|    policy_gradient_loss  | -0.00155     |
|    std                   | 0.857        |
|    value_loss            | 6.87         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0301       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0301       |
| reward                   | -0.31458858  |
| rollout/                 |              |
|    ep_len_mean           | 927          |
|    ep_rew_mean           | -453         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 39           |
|    time_elapsed          | 16226        |
|    total_timesteps       | 481280       |
| train/                   |              |
|    approx_kl             | 0.0032566425 |
|    clip_fraction         | 0.00513      |
|    clip_range            | 0.2          |
|    cost_returns          | 13.2         |
|    cost_value_loss       | 130          |
|    cost_values           | 2.95         |
|    entropy               | -2.52        |
|    entropy_loss          | -2.52        |
|    explained_variance    | 0.066        |
|    lagrangian_multiplier | 0.0222       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.1          |
|    n_updates             | 2340         |
|    policy_gradient_loss  | -0.00174     |
|    std                   | 0.853        |
|    value_loss            | 3.54         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0974      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0974      |
| reward                   | -0.56559795 |
| rollout/                 |             |
|    ep_len_mean           | 926         |
|    ep_rew_mean           | -450        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 40          |
|    time_elapsed          | 16706       |
|    total_timesteps       | 483328      |
| train/                   |             |
|    approx_kl             | 0.001970109 |
|    clip_fraction         | 0.0467      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.4        |
|    cost_value_loss       | 183         |
|    cost_values           | 2.99        |
|    entropy               | -2.51       |
|    entropy_loss          | -2.51       |
|    explained_variance    | -0.635      |
|    lagrangian_multiplier | 0.0351      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.79        |
|    n_updates             | 2350        |
|    policy_gradient_loss  | -0.00163    |
|    std                   | 0.852       |
|    value_loss            | 4.19        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.19        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 1.19        |
| reward                   | -0.32045883 |
| rollout/                 |             |
|    ep_len_mean           | 926         |
|    ep_rew_mean           | -446        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 41          |
|    time_elapsed          | 17182       |
|    total_timesteps       | 485376      |
| train/                   |             |
|    approx_kl             | 0.005143817 |
|    clip_fraction         | 0.0585      |
|    clip_range            | 0.2         |
|    cost_returns          | 11          |
|    cost_value_loss       | 102         |
|    cost_values           | 2.96        |
|    entropy               | -2.51       |
|    entropy_loss          | -2.51       |
|    explained_variance    | 0.201       |
|    lagrangian_multiplier | 0.0157      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.76        |
|    n_updates             | 2360        |
|    policy_gradient_loss  | -0.00417    |
|    std                   | 0.853       |
|    value_loss            | 12.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.333       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.333       |
| reward                   | -0.58749455 |
| rollout/                 |             |
|    ep_len_mean           | 934         |
|    ep_rew_mean           | -448        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 42          |
|    time_elapsed          | 17665       |
|    total_timesteps       | 487424      |
| train/                   |             |
|    approx_kl             | 0.004337992 |
|    clip_fraction         | 0.0329      |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 86.5        |
|    cost_values           | 2.97        |
|    entropy               | -2.51       |
|    entropy_loss          | -2.51       |
|    explained_variance    | 0.622       |
|    lagrangian_multiplier | 0.0133      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.77        |
|    n_updates             | 2370        |
|    policy_gradient_loss  | -0.00323    |
|    std                   | 0.851       |
|    value_loss            | 2.71        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.85         |
| reward                   | -0.60789007  |
| rollout/                 |              |
|    ep_len_mean           | 934          |
|    ep_rew_mean           | -452         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 43           |
|    time_elapsed          | 18156        |
|    total_timesteps       | 489472       |
| train/                   |              |
|    approx_kl             | 0.0069740675 |
|    clip_fraction         | 0.051        |
|    clip_range            | 0.2          |
|    cost_returns          | 7.31         |
|    cost_value_loss       | 59.2         |
|    cost_values           | 2.83         |
|    entropy               | -2.49        |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0.759        |
|    lagrangian_multiplier | 0.00967      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.67         |
|    n_updates             | 2380         |
|    policy_gradient_loss  | -0.00202     |
|    std                   | 0.844        |
|    value_loss            | 2.33         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.335       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.335       |
| reward                   | -0.5581449  |
| rollout/                 |             |
|    ep_len_mean           | 934         |
|    ep_rew_mean           | -452        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 44          |
|    time_elapsed          | 18634       |
|    total_timesteps       | 491520      |
| train/                   |             |
|    approx_kl             | 0.007992411 |
|    clip_fraction         | 0.102       |
|    clip_range            | 0.2         |
|    cost_returns          | 15.7        |
|    cost_value_loss       | 197         |
|    cost_values           | 2.88        |
|    entropy               | -2.49       |
|    entropy_loss          | -2.49       |
|    explained_variance    | 0.914       |
|    lagrangian_multiplier | 0.0243      |
|    learning_rate         | 0.0003      |
|    loss                  | 10.2        |
|    n_updates             | 2390        |
|    policy_gradient_loss  | 0.00701     |
|    std                   | 0.841       |
|    value_loss            | 3.54        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.168       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.168       |
| reward                   | -0.33735275 |
| rollout/                 |             |
|    ep_len_mean           | 934         |
|    ep_rew_mean           | -453        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 45          |
|    time_elapsed          | 19114       |
|    total_timesteps       | 493568      |
| train/                   |             |
|    approx_kl             | 0.004134898 |
|    clip_fraction         | 0.0406      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.9        |
|    cost_value_loss       | 129         |
|    cost_values           | 2.92        |
|    entropy               | -2.49       |
|    entropy_loss          | -2.48       |
|    explained_variance    | 0.726       |
|    lagrangian_multiplier | 0.0146      |
|    learning_rate         | 0.0003      |
|    loss                  | 10.3        |
|    n_updates             | 2400        |
|    policy_gradient_loss  | -0.00195    |
|    std                   | 0.841       |
|    value_loss            | 1.98        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.179        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.179        |
| reward                   | -0.38543597  |
| rollout/                 |              |
|    ep_len_mean           | 936          |
|    ep_rew_mean           | -452         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 46           |
|    time_elapsed          | 19596        |
|    total_timesteps       | 495616       |
| train/                   |              |
|    approx_kl             | 0.0059294114 |
|    clip_fraction         | 0.0584       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.8         |
|    cost_value_loss       | 121          |
|    cost_values           | 2.94         |
|    entropy               | -2.48        |
|    entropy_loss          | -2.48        |
|    explained_variance    | 0.178        |
|    lagrangian_multiplier | 0.0156       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.31         |
|    n_updates             | 2410         |
|    policy_gradient_loss  | -0.0059      |
|    std                   | 0.837        |
|    value_loss            | 1.79         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.139       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.139       |
| reward                   | -0.16816907 |
| rollout/                 |             |
|    ep_len_mean           | 936         |
|    ep_rew_mean           | -452        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 47          |
|    time_elapsed          | 20086       |
|    total_timesteps       | 497664      |
| train/                   |             |
|    approx_kl             | 0.003360135 |
|    clip_fraction         | 0.0282      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.98        |
|    cost_value_loss       | 64.6        |
|    cost_values           | 2.89        |
|    entropy               | -2.48       |
|    entropy_loss          | -2.47       |
|    explained_variance    | 0.325       |
|    lagrangian_multiplier | 0.01        |
|    learning_rate         | 0.0003      |
|    loss                  | 7.79        |
|    n_updates             | 2420        |
|    policy_gradient_loss  | -0.00279    |
|    std                   | 0.838       |
|    value_loss            | 1.34        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.495       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.495       |
| reward                   | -0.2902392  |
| rollout/                 |             |
|    ep_len_mean           | 926         |
|    ep_rew_mean           | -442        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 48          |
|    time_elapsed          | 20580       |
|    total_timesteps       | 499712      |
| train/                   |             |
|    approx_kl             | 0.006514514 |
|    clip_fraction         | 0.0927      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.12        |
|    cost_value_loss       | 33.7        |
|    cost_values           | 2.9         |
|    entropy               | -2.48       |
|    entropy_loss          | -2.48       |
|    explained_variance    | 0.494       |
|    lagrangian_multiplier | 0.00608     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.45        |
|    n_updates             | 2430        |
|    policy_gradient_loss  | -0.0037     |
|    std                   | 0.84        |
|    value_loss            | 2.58        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.106        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.106        |
| reward                   | -0.5307812   |
| rollout/                 |              |
|    ep_len_mean           | 926          |
|    ep_rew_mean           | -440         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 49           |
|    time_elapsed          | 21069        |
|    total_timesteps       | 501760       |
| train/                   |              |
|    approx_kl             | 0.0066222614 |
|    clip_fraction         | 0.0792       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.37         |
|    cost_value_loss       | 46.5         |
|    cost_values           | 2.89         |
|    entropy               | -2.48        |
|    entropy_loss          | -2.48        |
|    explained_variance    | 0.695        |
|    lagrangian_multiplier | 0.00698      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.65         |
|    n_updates             | 2440         |
|    policy_gradient_loss  | -0.00419     |
|    std                   | 0.839        |
|    value_loss            | 13.5         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/2fzzfvlw
------------------------------------
| avg_speed          | 0.289       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.289       |
| reward             | -0.35286427 |
| rollout/           |             |
|    ep_len_mean     | 926         |
|    ep_rew_mean     | -439        |
| time/              |             |
|    fps             | 4           |
|    iterations      | 1           |
|    time_elapsed    | 497         |
|    total_timesteps | 503808      |
------------------------------------
-------------------------------------------
| avg_speed                | 0.0189       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0189       |
| reward                   | -0.50939286  |
| rollout/                 |              |
|    ep_len_mean           | 921          |
|    ep_rew_mean           | -436         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 2            |
|    time_elapsed          | 999          |
|    total_timesteps       | 505856       |
| train/                   |              |
|    approx_kl             | 0.0069728666 |
|    clip_fraction         | 0.0913       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.56         |
|    cost_value_loss       | 52.9         |
|    cost_values           | 2.96         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.48        |
|    explained_variance    | 0.311        |
|    lagrangian_multiplier | 0.00904      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.54         |
|    n_updates             | 2460         |
|    policy_gradient_loss  | -0.00754     |
|    std                   | 0.836        |
|    value_loss            | 3.32         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.167        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.167        |
| reward                   | -0.6965482   |
| rollout/                 |              |
|    ep_len_mean           | 926          |
|    ep_rew_mean           | -437         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 3            |
|    time_elapsed          | 1496         |
|    total_timesteps       | 507904       |
| train/                   |              |
|    approx_kl             | 0.0017278059 |
|    clip_fraction         | 0.00234      |
|    clip_range            | 0.2          |
|    cost_returns          | 14.6         |
|    cost_value_loss       | 169          |
|    cost_values           | 2.99         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.506        |
|    lagrangian_multiplier | 0.0247       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.17         |
|    n_updates             | 2470         |
|    policy_gradient_loss  | 0.000198     |
|    std                   | 0.835        |
|    value_loss            | 6.83         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.81         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 1.81         |
| reward                   | -0.46635368  |
| rollout/                 |              |
|    ep_len_mean           | 926          |
|    ep_rew_mean           | -438         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 4            |
|    time_elapsed          | 1994         |
|    total_timesteps       | 509952       |
| train/                   |              |
|    approx_kl             | 0.0038677168 |
|    clip_fraction         | 0.0235       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.1         |
|    cost_value_loss       | 103          |
|    cost_values           | 2.86         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | -1.98        |
|    lagrangian_multiplier | 0.0156       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.29         |
|    n_updates             | 2480         |
|    policy_gradient_loss  | -0.00244     |
|    std                   | 0.835        |
|    value_loss            | 3.36         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.739        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.739        |
| reward                   | -0.27309892  |
| rollout/                 |              |
|    ep_len_mean           | 926          |
|    ep_rew_mean           | -433         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 5            |
|    time_elapsed          | 2505         |
|    total_timesteps       | 512000       |
| train/                   |              |
|    approx_kl             | 0.0034366455 |
|    clip_fraction         | 0.0408       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.95         |
|    cost_value_loss       | 59.8         |
|    cost_values           | 2.74         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.884        |
|    lagrangian_multiplier | 0.00851      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.63         |
|    n_updates             | 2490         |
|    policy_gradient_loss  | -0.00274     |
|    std                   | 0.836        |
|    value_loss            | 1.58         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.167       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.167       |
| reward                   | -0.57904243 |
| rollout/                 |             |
|    ep_len_mean           | 918         |
|    ep_rew_mean           | -429        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 6           |
|    time_elapsed          | 3007        |
|    total_timesteps       | 514048      |
| train/                   |             |
|    approx_kl             | 0.005141269 |
|    clip_fraction         | 0.0335      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.1        |
|    cost_value_loss       | 130         |
|    cost_values           | 2.86        |
|    entropy               | -2.47       |
|    entropy_loss          | -2.47       |
|    explained_variance    | 0.642       |
|    lagrangian_multiplier | 0.015       |
|    learning_rate         | 0.0003      |
|    loss                  | 10.3        |
|    n_updates             | 2500        |
|    policy_gradient_loss  | -0.00256    |
|    std                   | 0.834       |
|    value_loss            | 1.26        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00737      |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.00737      |
| reward                   | -0.5214303   |
| rollout/                 |              |
|    ep_len_mean           | 918          |
|    ep_rew_mean           | -431         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 7            |
|    time_elapsed          | 3518         |
|    total_timesteps       | 516096       |
| train/                   |              |
|    approx_kl             | 0.0046302127 |
|    clip_fraction         | 0.0386       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.5          |
|    cost_value_loss       | 66.3         |
|    cost_values           | 2.77         |
|    entropy               | -2.46        |
|    entropy_loss          | -2.46        |
|    explained_variance    | 0.792        |
|    lagrangian_multiplier | 0.00588      |
|    learning_rate         | 0.0003       |
|    loss                  | 12.3         |
|    n_updates             | 2510         |
|    policy_gradient_loss  | -0.00268     |
|    std                   | 0.833        |
|    value_loss            | 14.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.144       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.144       |
| reward                   | -0.2172137  |
| rollout/                 |             |
|    ep_len_mean           | 928         |
|    ep_rew_mean           | -434        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 8           |
|    time_elapsed          | 4031        |
|    total_timesteps       | 518144      |
| train/                   |             |
|    approx_kl             | 0.009515537 |
|    clip_fraction         | 0.0263      |
|    clip_range            | 0.2         |
|    cost_returns          | 14.7        |
|    cost_value_loss       | 173         |
|    cost_values           | 2.78        |
|    entropy               | -2.46       |
|    entropy_loss          | -2.46       |
|    explained_variance    | -0.0772     |
|    lagrangian_multiplier | 0.0169      |
|    learning_rate         | 0.0003      |
|    loss                  | 11.4        |
|    n_updates             | 2520        |
|    policy_gradient_loss  | -0.00215    |
|    std                   | 0.831       |
|    value_loss            | 3.25        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.547        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.547        |
| reward                   | -0.46599516  |
| rollout/                 |              |
|    ep_len_mean           | 937          |
|    ep_rew_mean           | -435         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 9            |
|    time_elapsed          | 4538         |
|    total_timesteps       | 520192       |
| train/                   |              |
|    approx_kl             | 0.0057554953 |
|    clip_fraction         | 0.0246       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.7          |
|    cost_value_loss       | 30.4         |
|    cost_values           | 2.84         |
|    entropy               | -2.46        |
|    entropy_loss          | -2.46        |
|    explained_variance    | 0.3          |
|    lagrangian_multiplier | 0.00431      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.77         |
|    n_updates             | 2530         |
|    policy_gradient_loss  | -0.00289     |
|    std                   | 0.83         |
|    value_loss            | 5.54         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0242      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0242      |
| reward                   | -0.5562648  |
| rollout/                 |             |
|    ep_len_mean           | 946         |
|    ep_rew_mean           | -435        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 10          |
|    time_elapsed          | 5047        |
|    total_timesteps       | 522240      |
| train/                   |             |
|    approx_kl             | 0.010213402 |
|    clip_fraction         | 0.0624      |
|    clip_range            | 0.2         |
|    cost_returns          | 11          |
|    cost_value_loss       | 106         |
|    cost_values           | 2.87        |
|    entropy               | -2.46       |
|    entropy_loss          | -2.46       |
|    explained_variance    | -0.0278     |
|    lagrangian_multiplier | 0.0138      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.87        |
|    n_updates             | 2540        |
|    policy_gradient_loss  | -0.006      |
|    std                   | 0.833       |
|    value_loss            | 1.29        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0526      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0526      |
| reward                   | -0.554794   |
| rollout/                 |             |
|    ep_len_mean           | 946         |
|    ep_rew_mean           | -434        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 11          |
|    time_elapsed          | 5553        |
|    total_timesteps       | 524288      |
| train/                   |             |
|    approx_kl             | 0.005823369 |
|    clip_fraction         | 0.0261      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.19        |
|    cost_value_loss       | 73.9        |
|    cost_values           | 2.86        |
|    entropy               | -2.46       |
|    entropy_loss          | -2.46       |
|    explained_variance    | 0.586       |
|    lagrangian_multiplier | 0.0114      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.03        |
|    n_updates             | 2550        |
|    policy_gradient_loss  | -0.00258    |
|    std                   | 0.833       |
|    value_loss            | 0.876       |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.46         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.46         |
| reward                   | -0.36596256  |
| rollout/                 |              |
|    ep_len_mean           | 937          |
|    ep_rew_mean           | -429         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 12           |
|    time_elapsed          | 6078         |
|    total_timesteps       | 526336       |
| train/                   |              |
|    approx_kl             | 0.0019996162 |
|    clip_fraction         | 0.027        |
|    clip_range            | 0.2          |
|    cost_returns          | 8.43         |
|    cost_value_loss       | 79           |
|    cost_values           | 2.89         |
|    entropy               | -2.46        |
|    entropy_loss          | -2.46        |
|    explained_variance    | -1.42        |
|    lagrangian_multiplier | 0.0109       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.91         |
|    n_updates             | 2560         |
|    policy_gradient_loss  | -0.000779    |
|    std                   | 0.83         |
|    value_loss            | 4.12         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0201       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0201       |
| reward                   | -0.43896744  |
| rollout/                 |              |
|    ep_len_mean           | 932          |
|    ep_rew_mean           | -422         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 13           |
|    time_elapsed          | 6593         |
|    total_timesteps       | 528384       |
| train/                   |              |
|    approx_kl             | 0.0030950885 |
|    clip_fraction         | 0.0063       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.5         |
|    cost_value_loss       | 172          |
|    cost_values           | 3            |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0.112        |
|    lagrangian_multiplier | 0.0333       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.81         |
|    n_updates             | 2570         |
|    policy_gradient_loss  | -0.00145     |
|    std                   | 0.828        |
|    value_loss            | 10.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0199       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0199       |
| reward                   | -0.33298448  |
| rollout/                 |              |
|    ep_len_mean           | 932          |
|    ep_rew_mean           | -421         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 14           |
|    time_elapsed          | 7111         |
|    total_timesteps       | 530432       |
| train/                   |              |
|    approx_kl             | 0.0032361043 |
|    clip_fraction         | 0.00562      |
|    clip_range            | 0.2          |
|    cost_returns          | 11.7         |
|    cost_value_loss       | 123          |
|    cost_values           | 2.98         |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | -0.595       |
|    lagrangian_multiplier | 0.0194       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.89         |
|    n_updates             | 2580         |
|    policy_gradient_loss  | -0.00141     |
|    std                   | 0.827        |
|    value_loss            | 13           |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.177       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.177       |
| reward                   | -0.46581087 |
| rollout/                 |             |
|    ep_len_mean           | 933         |
|    ep_rew_mean           | -422        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 15          |
|    time_elapsed          | 7625        |
|    total_timesteps       | 532480      |
| train/                   |             |
|    approx_kl             | 0.004164083 |
|    clip_fraction         | 0.0264      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.94        |
|    cost_value_loss       | 82.2        |
|    cost_values           | 2.98        |
|    entropy               | -2.45       |
|    entropy_loss          | -2.45       |
|    explained_variance    | 0.182       |
|    lagrangian_multiplier | 0.0149      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.25        |
|    n_updates             | 2590        |
|    policy_gradient_loss  | -0.00187    |
|    std                   | 0.828       |
|    value_loss            | 1.28        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0395       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0395       |
| reward                   | -0.21725854  |
| rollout/                 |              |
|    ep_len_mean           | 927          |
|    ep_rew_mean           | -421         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 16           |
|    time_elapsed          | 8152         |
|    total_timesteps       | 534528       |
| train/                   |              |
|    approx_kl             | 0.0062800706 |
|    clip_fraction         | 0.0434       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.8         |
|    cost_value_loss       | 178          |
|    cost_values           | 2.99         |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0.279        |
|    lagrangian_multiplier | 0.017        |
|    learning_rate         | 0.0003       |
|    loss                  | 12           |
|    n_updates             | 2600         |
|    policy_gradient_loss  | -0.00375     |
|    std                   | 0.828        |
|    value_loss            | 0.905        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0933      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0933      |
| reward                   | -0.35568443 |
| rollout/                 |             |
|    ep_len_mean           | 927         |
|    ep_rew_mean           | -419        |
| time/                    |             |
|    fps                   | 4           |
|    iterations            | 17          |
|    time_elapsed          | 8677        |
|    total_timesteps       | 536576      |
| train/                   |             |
|    approx_kl             | 0.004312948 |
|    clip_fraction         | 0.0115      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.6        |
|    cost_value_loss       | 153         |
|    cost_values           | 2.99        |
|    entropy               | -2.45       |
|    entropy_loss          | -2.45       |
|    explained_variance    | -0.0156     |
|    lagrangian_multiplier | 0.0218      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.43        |
|    n_updates             | 2610        |
|    policy_gradient_loss  | -0.00147    |
|    std                   | 0.827       |
|    value_loss            | 11          |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0304       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0304       |
| reward                   | -0.60163945  |
| rollout/                 |              |
|    ep_len_mean           | 927          |
|    ep_rew_mean           | -416         |
| time/                    |              |
|    fps                   | 4            |
|    iterations            | 18           |
|    time_elapsed          | 9199         |
|    total_timesteps       | 538624       |
| train/                   |              |
|    approx_kl             | 0.0023413547 |
|    clip_fraction         | 0.0169       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.5         |
|    cost_value_loss       | 162          |
|    cost_values           | 2.99         |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0.263        |
|    lagrangian_multiplier | 0.0234       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.32         |
|    n_updates             | 2620         |
|    policy_gradient_loss  | -0.00154     |
|    std                   | 0.828        |
|    value_loss            | 5.31         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.258        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.258        |
| reward                   | -0.42389292  |
| rollout/                 |              |
|    ep_len_mean           | 927          |
|    ep_rew_mean           | -418         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 19           |
|    time_elapsed          | 9731         |
|    total_timesteps       | 540672       |
| train/                   |              |
|    approx_kl             | 0.0038936832 |
|    clip_fraction         | 0.0325       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.6         |
|    cost_value_loss       | 190          |
|    cost_values           | 2.99         |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0.841        |
|    lagrangian_multiplier | 0.0202       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.8         |
|    n_updates             | 2630         |
|    policy_gradient_loss  | -0.0027      |
|    std                   | 0.828        |
|    value_loss            | 1.91         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.219        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.219        |
| reward                   | -0.33838898  |
| rollout/                 |              |
|    ep_len_mean           | 919          |
|    ep_rew_mean           | -415         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 20           |
|    time_elapsed          | 10262        |
|    total_timesteps       | 542720       |
| train/                   |              |
|    approx_kl             | 0.0031496983 |
|    clip_fraction         | 0.0273       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.5         |
|    cost_value_loss       | 175          |
|    cost_values           | 2.95         |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0.48         |
|    lagrangian_multiplier | 0.022        |
|    learning_rate         | 0.0003       |
|    loss                  | 9.91         |
|    n_updates             | 2640         |
|    policy_gradient_loss  | -0.00231     |
|    std                   | 0.827        |
|    value_loss            | 3.09         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.211       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.211       |
| reward                   | -0.3156723  |
| rollout/                 |             |
|    ep_len_mean           | 919         |
|    ep_rew_mean           | -413        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 21          |
|    time_elapsed          | 10798       |
|    total_timesteps       | 544768      |
| train/                   |             |
|    approx_kl             | 0.003675826 |
|    clip_fraction         | 0.0173      |
|    clip_range            | 0.2         |
|    cost_returns          | 16.8        |
|    cost_value_loss       | 211         |
|    cost_values           | 2.97        |
|    entropy               | -2.45       |
|    entropy_loss          | -2.45       |
|    explained_variance    | -0.335      |
|    lagrangian_multiplier | 0.0301      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.51        |
|    n_updates             | 2650        |
|    policy_gradient_loss  | -0.00181    |
|    std                   | 0.828       |
|    value_loss            | 8.81        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.174        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.174        |
| reward                   | -0.5493578   |
| rollout/                 |              |
|    ep_len_mean           | 919          |
|    ep_rew_mean           | -412         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 22           |
|    time_elapsed          | 11341        |
|    total_timesteps       | 546816       |
| train/                   |              |
|    approx_kl             | 0.0036007904 |
|    clip_fraction         | 0.0061       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.8         |
|    cost_value_loss       | 185          |
|    cost_values           | 2.99         |
|    entropy               | -2.46        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0.561        |
|    lagrangian_multiplier | 0.0161       |
|    learning_rate         | 0.0003       |
|    loss                  | 13           |
|    n_updates             | 2660         |
|    policy_gradient_loss  | -0.00103     |
|    std                   | 0.83         |
|    value_loss            | 4.02         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.103        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.103        |
| reward                   | -0.22238924  |
| rollout/                 |              |
|    ep_len_mean           | 919          |
|    ep_rew_mean           | -413         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 23           |
|    time_elapsed          | 11888        |
|    total_timesteps       | 548864       |
| train/                   |              |
|    approx_kl             | 0.0068984106 |
|    clip_fraction         | 0.0238       |
|    clip_range            | 0.2          |
|    cost_returns          | 16.8         |
|    cost_value_loss       | 216          |
|    cost_values           | 2.99         |
|    entropy               | -2.46        |
|    entropy_loss          | -2.46        |
|    explained_variance    | 0.735        |
|    lagrangian_multiplier | 0.0144       |
|    learning_rate         | 0.0003       |
|    loss                  | 15.8         |
|    n_updates             | 2670         |
|    policy_gradient_loss  | -0.0037      |
|    std                   | 0.83         |
|    value_loss            | 1.23         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.08        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.08        |
| reward                   | -0.32284826 |
| rollout/                 |             |
|    ep_len_mean           | 919         |
|    ep_rew_mean           | -410        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 24          |
|    time_elapsed          | 12425       |
|    total_timesteps       | 550912      |
| train/                   |             |
|    approx_kl             | 0.001228688 |
|    clip_fraction         | 0.00972     |
|    clip_range            | 0.2         |
|    cost_returns          | 14          |
|    cost_value_loss       | 155         |
|    cost_values           | 3           |
|    entropy               | -2.46       |
|    entropy_loss          | -2.46       |
|    explained_variance    | 0.491       |
|    lagrangian_multiplier | 0.0258      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.1         |
|    n_updates             | 2680        |
|    policy_gradient_loss  | 2.2e-06     |
|    std                   | 0.83        |
|    value_loss            | 2.91        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0295      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0295      |
| reward                   | -0.52480847 |
| rollout/                 |             |
|    ep_len_mean           | 919         |
|    ep_rew_mean           | -408        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 25          |
|    time_elapsed          | 12964       |
|    total_timesteps       | 552960      |
| train/                   |             |
|    approx_kl             | 0.005511643 |
|    clip_fraction         | 0.0391      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.77        |
|    cost_value_loss       | 59.2        |
|    cost_values           | 2.86        |
|    entropy               | -2.47       |
|    entropy_loss          | -2.46       |
|    explained_variance    | -1.48       |
|    lagrangian_multiplier | 0.00831     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.92        |
|    n_updates             | 2690        |
|    policy_gradient_loss  | -0.00201    |
|    std                   | 0.834       |
|    value_loss            | 1.33        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0603       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0603       |
| reward                   | -0.30891323  |
| rollout/                 |              |
|    ep_len_mean           | 919          |
|    ep_rew_mean           | -406         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 26           |
|    time_elapsed          | 13505        |
|    total_timesteps       | 555008       |
| train/                   |              |
|    approx_kl             | 0.0020126388 |
|    clip_fraction         | 0.00522      |
|    clip_range            | 0.2          |
|    cost_returns          | 13.6         |
|    cost_value_loss       | 148          |
|    cost_values           | 2.94         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.567        |
|    lagrangian_multiplier | 0.0218       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.91         |
|    n_updates             | 2700         |
|    policy_gradient_loss  | 1.65e-05     |
|    std                   | 0.836        |
|    value_loss            | 2.11         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.181        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.181        |
| reward                   | -0.48996064  |
| rollout/                 |              |
|    ep_len_mean           | 919          |
|    ep_rew_mean           | -406         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 27           |
|    time_elapsed          | 14047        |
|    total_timesteps       | 557056       |
| train/                   |              |
|    approx_kl             | 0.0069492985 |
|    clip_fraction         | 0.0504       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.8         |
|    cost_value_loss       | 175          |
|    cost_values           | 2.99         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.718        |
|    lagrangian_multiplier | 0.0272       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.64         |
|    n_updates             | 2710         |
|    policy_gradient_loss  | -0.0043      |
|    std                   | 0.836        |
|    value_loss            | 0.905        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0888       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0888       |
| reward                   | -0.36020544  |
| rollout/                 |              |
|    ep_len_mean           | 928          |
|    ep_rew_mean           | -411         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 28           |
|    time_elapsed          | 14599        |
|    total_timesteps       | 559104       |
| train/                   |              |
|    approx_kl             | 0.0037341146 |
|    clip_fraction         | 0.0211       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.4         |
|    cost_value_loss       | 129          |
|    cost_values           | 2.94         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.566        |
|    lagrangian_multiplier | 0.0175       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.07         |
|    n_updates             | 2720         |
|    policy_gradient_loss  | -0.00197     |
|    std                   | 0.834        |
|    value_loss            | 2.03         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.408       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.408       |
| reward                   | -0.40723628 |
| rollout/                 |             |
|    ep_len_mean           | 928         |
|    ep_rew_mean           | -407        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 29          |
|    time_elapsed          | 15148       |
|    total_timesteps       | 561152      |
| train/                   |             |
|    approx_kl             | 0.005713695 |
|    clip_fraction         | 0.13        |
|    clip_range            | 0.2         |
|    cost_returns          | 15.8        |
|    cost_value_loss       | 190         |
|    cost_values           | 2.99        |
|    entropy               | -2.46       |
|    entropy_loss          | -2.46       |
|    explained_variance    | 0.474       |
|    lagrangian_multiplier | 0.0358      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.9         |
|    n_updates             | 2730        |
|    policy_gradient_loss  | -0.00502    |
|    std                   | 0.832       |
|    value_loss            | 0.984       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.12        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.12        |
| reward                   | -0.25318095 |
| rollout/                 |             |
|    ep_len_mean           | 931         |
|    ep_rew_mean           | -408        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 30          |
|    time_elapsed          | 15700       |
|    total_timesteps       | 563200      |
| train/                   |             |
|    approx_kl             | 0.00449482  |
|    clip_fraction         | 0.00645     |
|    clip_range            | 0.2         |
|    cost_returns          | 11.2        |
|    cost_value_loss       | 124         |
|    cost_values           | 2.99        |
|    entropy               | -2.46       |
|    entropy_loss          | -2.46       |
|    explained_variance    | 0.347       |
|    lagrangian_multiplier | 0.0189      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.65        |
|    n_updates             | 2740        |
|    policy_gradient_loss  | -0.000971   |
|    std                   | 0.832       |
|    value_loss            | 3.45        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.182       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.182       |
| reward                   | -0.47631985 |
| rollout/                 |             |
|    ep_len_mean           | 931         |
|    ep_rew_mean           | -400        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 31          |
|    time_elapsed          | 16255       |
|    total_timesteps       | 565248      |
| train/                   |             |
|    approx_kl             | 0.003768419 |
|    clip_fraction         | 0.00513     |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 109         |
|    cost_values           | 2.96        |
|    entropy               | -2.46       |
|    entropy_loss          | -2.46       |
|    explained_variance    | -5.01       |
|    lagrangian_multiplier | 0.0139      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.6         |
|    n_updates             | 2750        |
|    policy_gradient_loss  | -0.00147    |
|    std                   | 0.832       |
|    value_loss            | 3.21        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0383      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0383      |
| reward                   | -0.321272   |
| rollout/                 |             |
|    ep_len_mean           | 931         |
|    ep_rew_mean           | -401        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 32          |
|    time_elapsed          | 16815       |
|    total_timesteps       | 567296      |
| train/                   |             |
|    approx_kl             | 0.008170385 |
|    clip_fraction         | 0.0482      |
|    clip_range            | 0.2         |
|    cost_returns          | 11          |
|    cost_value_loss       | 109         |
|    cost_values           | 2.98        |
|    entropy               | -2.46       |
|    entropy_loss          | -2.46       |
|    explained_variance    | 0.153       |
|    lagrangian_multiplier | 0.0149      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.93        |
|    n_updates             | 2760        |
|    policy_gradient_loss  | -0.00455    |
|    std                   | 0.831       |
|    value_loss            | 2.47        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.112        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.112        |
| reward                   | -0.26759836  |
| rollout/                 |              |
|    ep_len_mean           | 931          |
|    ep_rew_mean           | -401         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 33           |
|    time_elapsed          | 17359        |
|    total_timesteps       | 569344       |
| train/                   |              |
|    approx_kl             | 0.0025496744 |
|    clip_fraction         | 0.00205      |
|    clip_range            | 0.2          |
|    cost_returns          | 18.6         |
|    cost_value_loss       | 250          |
|    cost_values           | 3            |
|    entropy               | -2.46        |
|    entropy_loss          | -2.46        |
|    explained_variance    | -1.18        |
|    lagrangian_multiplier | 0.00365      |
|    learning_rate         | 0.0003       |
|    loss                  | 46.4         |
|    n_updates             | 2770         |
|    policy_gradient_loss  | -0.00038     |
|    std                   | 0.831        |
|    value_loss            | 3.2          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.178        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.178        |
| reward                   | -0.5470546   |
| rollout/                 |              |
|    ep_len_mean           | 931          |
|    ep_rew_mean           | -394         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 34           |
|    time_elapsed          | 17922        |
|    total_timesteps       | 571392       |
| train/                   |              |
|    approx_kl             | 0.0076088402 |
|    clip_fraction         | 0.0881       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.3         |
|    cost_value_loss       | 138          |
|    cost_values           | 2.97         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.46        |
|    explained_variance    | -0.102       |
|    lagrangian_multiplier | 0.0162       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.96         |
|    n_updates             | 2780         |
|    policy_gradient_loss  | -0.00729     |
|    std                   | 0.835        |
|    value_loss            | 0.457        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0669       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0669       |
| reward                   | -0.45669872  |
| rollout/                 |              |
|    ep_len_mean           | 931          |
|    ep_rew_mean           | -392         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 35           |
|    time_elapsed          | 18481        |
|    total_timesteps       | 573440       |
| train/                   |              |
|    approx_kl             | 0.0050607957 |
|    clip_fraction         | 0.0126       |
|    clip_range            | 0.2          |
|    cost_returns          | 17.1         |
|    cost_value_loss       | 221          |
|    cost_values           | 3            |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.573        |
|    lagrangian_multiplier | 0.00774      |
|    learning_rate         | 0.0003       |
|    loss                  | 24.8         |
|    n_updates             | 2790         |
|    policy_gradient_loss  | -0.0027      |
|    std                   | 0.836        |
|    value_loss            | 1.46         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.375        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.375        |
| reward                   | -0.3208564   |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -394         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 36           |
|    time_elapsed          | 19046        |
|    total_timesteps       | 575488       |
| train/                   |              |
|    approx_kl             | 0.0028231218 |
|    clip_fraction         | 0.0019       |
|    clip_range            | 0.2          |
|    cost_returns          | 18.2         |
|    cost_value_loss       | 243          |
|    cost_values           | 3            |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.724        |
|    lagrangian_multiplier | 0.0298       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.4         |
|    n_updates             | 2800         |
|    policy_gradient_loss  | -0.000923    |
|    std                   | 0.836        |
|    value_loss            | 2.9          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.117        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.117        |
| reward                   | -0.43152243  |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -392         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 37           |
|    time_elapsed          | 19613        |
|    total_timesteps       | 577536       |
| train/                   |              |
|    approx_kl             | 0.0017216294 |
|    clip_fraction         | 0.0043       |
|    clip_range            | 0.2          |
|    cost_returns          | 16.8         |
|    cost_value_loss       | 211          |
|    cost_values           | 2.99         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | -4.49        |
|    lagrangian_multiplier | 0.0384       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.84         |
|    n_updates             | 2810         |
|    policy_gradient_loss  | -0.00134     |
|    std                   | 0.835        |
|    value_loss            | 0.714        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.197        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.197        |
| reward                   | -0.34350777  |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -393         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 38           |
|    time_elapsed          | 20191        |
|    total_timesteps       | 579584       |
| train/                   |              |
|    approx_kl             | 0.0026300186 |
|    clip_fraction         | 0.0136       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.9         |
|    cost_value_loss       | 130          |
|    cost_values           | 2.82         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.817        |
|    lagrangian_multiplier | 0.0154       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.2         |
|    n_updates             | 2820         |
|    policy_gradient_loss  | -0.000736    |
|    std                   | 0.834        |
|    value_loss            | 2.4          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.248       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.248       |
| reward                   | -0.37776726 |
| rollout/                 |             |
|    ep_len_mean           | 938         |
|    ep_rew_mean           | -390        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 39          |
|    time_elapsed          | 20765       |
|    total_timesteps       | 581632      |
| train/                   |             |
|    approx_kl             | 0.007939783 |
|    clip_fraction         | 0.0521      |
|    clip_range            | 0.2         |
|    cost_returns          | 18.2        |
|    cost_value_loss       | 241         |
|    cost_values           | 2.92        |
|    entropy               | -2.47       |
|    entropy_loss          | -2.47       |
|    explained_variance    | 0.489       |
|    lagrangian_multiplier | 0.0024      |
|    learning_rate         | 0.0003      |
|    loss                  | 54.6        |
|    n_updates             | 2830        |
|    policy_gradient_loss  | -0.00291    |
|    std                   | 0.833       |
|    value_loss            | 0.655       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0859      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0859      |
| reward                   | -0.46223608 |
| rollout/                 |             |
|    ep_len_mean           | 938         |
|    ep_rew_mean           | -385        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 40          |
|    time_elapsed          | 21329       |
|    total_timesteps       | 583680      |
| train/                   |             |
|    approx_kl             | 0.0086459   |
|    clip_fraction         | 0.0532      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.3        |
|    cost_value_loss       | 182         |
|    cost_values           | 3           |
|    entropy               | -2.46       |
|    entropy_loss          | -2.46       |
|    explained_variance    | -1.4        |
|    lagrangian_multiplier | 0.00802     |
|    learning_rate         | 0.0003      |
|    loss                  | 20.7        |
|    n_updates             | 2840        |
|    policy_gradient_loss  | -0.00521    |
|    std                   | 0.833       |
|    value_loss            | 1.44        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.01         |
| reward                   | -0.351825    |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -385         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 41           |
|    time_elapsed          | 21900        |
|    total_timesteps       | 585728       |
| train/                   |              |
|    approx_kl             | 0.0067875283 |
|    clip_fraction         | 0.0629       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.9         |
|    cost_value_loss       | 186          |
|    cost_values           | 2.99         |
|    entropy               | -2.46        |
|    entropy_loss          | -2.46        |
|    explained_variance    | 0.767        |
|    lagrangian_multiplier | 0.03         |
|    learning_rate         | 0.0003       |
|    loss                  | 8.34         |
|    n_updates             | 2850         |
|    policy_gradient_loss  | -0.00513     |
|    std                   | 0.829        |
|    value_loss            | 0.649        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0766       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0766       |
| reward                   | -0.5152364   |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -382         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 42           |
|    time_elapsed          | 22474        |
|    total_timesteps       | 587776       |
| train/                   |              |
|    approx_kl             | 0.0053340564 |
|    clip_fraction         | 0.0652       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.61         |
|    cost_value_loss       | 45.4         |
|    cost_values           | 2.97         |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0.827        |
|    lagrangian_multiplier | 0.00653      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.87         |
|    n_updates             | 2860         |
|    policy_gradient_loss  | -0.00432     |
|    std                   | 0.827        |
|    value_loss            | 0.46         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.11        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.11        |
| reward                   | -0.47985113 |
| rollout/                 |             |
|    ep_len_mean           | 938         |
|    ep_rew_mean           | -384        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 43          |
|    time_elapsed          | 23050       |
|    total_timesteps       | 589824      |
| train/                   |             |
|    approx_kl             | 0.007954799 |
|    clip_fraction         | 0.0394      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.2        |
|    cost_value_loss       | 179         |
|    cost_values           | 2.99        |
|    entropy               | -2.45       |
|    entropy_loss          | -2.45       |
|    explained_variance    | 0.888       |
|    lagrangian_multiplier | 0.0265      |
|    learning_rate         | 0.0003      |
|    loss                  | 9           |
|    n_updates             | 2870        |
|    policy_gradient_loss  | -0.00033    |
|    std                   | 0.826       |
|    value_loss            | 0.932       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.258        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.258        |
| reward                   | -0.4659845   |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -383         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 44           |
|    time_elapsed          | 23630        |
|    total_timesteps       | 591872       |
| train/                   |              |
|    approx_kl             | 0.0071323263 |
|    clip_fraction         | 0.0514       |
|    clip_range            | 0.2          |
|    cost_returns          | 10.6         |
|    cost_value_loss       | 115          |
|    cost_values           | 2.96         |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0.981        |
|    lagrangian_multiplier | 0.0174       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.43         |
|    n_updates             | 2880         |
|    policy_gradient_loss  | -0.00556     |
|    std                   | 0.829        |
|    value_loss            | 0.771        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.178       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.178       |
| reward                   | -0.31451777 |
| rollout/                 |             |
|    ep_len_mean           | 948         |
|    ep_rew_mean           | -389        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 45          |
|    time_elapsed          | 24209       |
|    total_timesteps       | 593920      |
| train/                   |             |
|    approx_kl             | 0.006425077 |
|    clip_fraction         | 0.0432      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.29        |
|    cost_value_loss       | 22.8        |
|    cost_values           | 2.89        |
|    entropy               | -2.46       |
|    entropy_loss          | -2.46       |
|    explained_variance    | 0.583       |
|    lagrangian_multiplier | 0.00248     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.03        |
|    n_updates             | 2890        |
|    policy_gradient_loss  | -0.00261    |
|    std                   | 0.831       |
|    value_loss            | 0.923       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.259       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.259       |
| reward                   | -0.29670215 |
| rollout/                 |             |
|    ep_len_mean           | 951         |
|    ep_rew_mean           | -392        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 46          |
|    time_elapsed          | 24788       |
|    total_timesteps       | 595968      |
| train/                   |             |
|    approx_kl             | 0.011141567 |
|    clip_fraction         | 0.108       |
|    clip_range            | 0.2         |
|    cost_returns          | 8.71        |
|    cost_value_loss       | 71.3        |
|    cost_values           | 2.95        |
|    entropy               | -2.46       |
|    entropy_loss          | -2.46       |
|    explained_variance    | 0.315       |
|    lagrangian_multiplier | 0.0107      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.31        |
|    n_updates             | 2900        |
|    policy_gradient_loss  | -0.00403    |
|    std                   | 0.83        |
|    value_loss            | 0.137       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.132       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.132       |
| reward                   | -0.44550547 |
| rollout/                 |             |
|    ep_len_mean           | 957         |
|    ep_rew_mean           | -396        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 47          |
|    time_elapsed          | 25373       |
|    total_timesteps       | 598016      |
| train/                   |             |
|    approx_kl             | 0.004860605 |
|    clip_fraction         | 0.0397      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.7        |
|    cost_value_loss       | 156         |
|    cost_values           | 2.99        |
|    entropy               | -2.46       |
|    entropy_loss          | -2.46       |
|    explained_variance    | 0.896       |
|    lagrangian_multiplier | 0.0176      |
|    learning_rate         | 0.0003      |
|    loss                  | 10.6        |
|    n_updates             | 2910        |
|    policy_gradient_loss  | -0.00244    |
|    std                   | 0.833       |
|    value_loss            | 0.569       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.353       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.353       |
| reward                   | -0.3764652  |
| rollout/                 |             |
|    ep_len_mean           | 957         |
|    ep_rew_mean           | -395        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 48          |
|    time_elapsed          | 25953       |
|    total_timesteps       | 600064      |
| train/                   |             |
|    approx_kl             | 0.009639982 |
|    clip_fraction         | 0.0488      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.51        |
|    cost_value_loss       | 101         |
|    cost_values           | 2.95        |
|    entropy               | -2.46       |
|    entropy_loss          | -2.46       |
|    explained_variance    | 0.968       |
|    lagrangian_multiplier | 0.0115      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.62        |
|    n_updates             | 2920        |
|    policy_gradient_loss  | -0.00327    |
|    std                   | 0.833       |
|    value_loss            | 0.719       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.127        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.127        |
| reward                   | -0.37550092  |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -398         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 49           |
|    time_elapsed          | 26528        |
|    total_timesteps       | 602112       |
| train/                   |              |
|    approx_kl             | 0.0040210034 |
|    clip_fraction         | 0.0191       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.2         |
|    cost_value_loss       | 113          |
|    cost_values           | 2.98         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.839        |
|    lagrangian_multiplier | 0.0143       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.66         |
|    n_updates             | 2930         |
|    policy_gradient_loss  | -0.00104     |
|    std                   | 0.834        |
|    value_loss            | 0.791        |
-------------------------------------------
------------------------------------
| avg_speed          | 0.223       |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 0.223       |
| reward             | -0.38361165 |
| rollout/           |             |
|    ep_len_mean     | 962         |
|    ep_rew_mean     | -395        |
| time/              |             |
|    fps             | 3           |
|    iterations      | 1           |
|    time_elapsed    | 595         |
|    total_timesteps | 604160      |
------------------------------------
-------------------------------------------
| avg_speed                | 0.00359      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00359      |
| reward                   | -0.5491975   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -390         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 2            |
|    time_elapsed          | 1185         |
|    total_timesteps       | 606208       |
| train/                   |              |
|    approx_kl             | 0.0045956513 |
|    clip_fraction         | 0.0776       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.8          |
|    cost_value_loss       | 112          |
|    cost_values           | 2.96         |
|    entropy               | -2.46        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.574        |
|    lagrangian_multiplier | 0.0135       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.48         |
|    n_updates             | 2950         |
|    policy_gradient_loss  | -0.00541     |
|    std                   | 0.832        |
|    value_loss            | 1.45         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0222       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0222       |
| reward                   | -0.4310166   |
| rollout/                 |              |
|    ep_len_mean           | 962          |
|    ep_rew_mean           | -391         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 3            |
|    time_elapsed          | 1771         |
|    total_timesteps       | 608256       |
| train/                   |              |
|    approx_kl             | 0.0068155173 |
|    clip_fraction         | 0.0284       |
|    clip_range            | 0.2          |
|    cost_returns          | 17.3         |
|    cost_value_loss       | 223          |
|    cost_values           | 2.95         |
|    entropy               | -2.46        |
|    entropy_loss          | -2.46        |
|    explained_variance    | 0.604        |
|    lagrangian_multiplier | 0.0271       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.2         |
|    n_updates             | 2960         |
|    policy_gradient_loss  | -0.00422     |
|    std                   | 0.831        |
|    value_loss            | 0.49         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.16         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.16         |
| reward                   | -0.45962384  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -391         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 4            |
|    time_elapsed          | 2365         |
|    total_timesteps       | 610304       |
| train/                   |              |
|    approx_kl             | 0.0049203015 |
|    clip_fraction         | 0.0207       |
|    clip_range            | 0.2          |
|    cost_returns          | 13           |
|    cost_value_loss       | 151          |
|    cost_values           | 2.93         |
|    entropy               | -2.46        |
|    entropy_loss          | -2.46        |
|    explained_variance    | 0.981        |
|    lagrangian_multiplier | 0.021        |
|    learning_rate         | 0.0003       |
|    loss                  | 9.54         |
|    n_updates             | 2970         |
|    policy_gradient_loss  | -0.00321     |
|    std                   | 0.831        |
|    value_loss            | 0.406        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0268      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0268      |
| reward                   | -0.25328174 |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -388        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 5           |
|    time_elapsed          | 2957        |
|    total_timesteps       | 612352      |
| train/                   |             |
|    approx_kl             | 0.012071511 |
|    clip_fraction         | 0.0987      |
|    clip_range            | 0.2         |
|    cost_returns          | 10.8        |
|    cost_value_loss       | 117         |
|    cost_values           | 2.96        |
|    entropy               | -2.47       |
|    entropy_loss          | -2.46       |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0.0176      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.47        |
|    n_updates             | 2980        |
|    policy_gradient_loss  | -0.00345    |
|    std                   | 0.833       |
|    value_loss            | 0.4         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00422      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00422      |
| reward                   | -0.4451193   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -386         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 6            |
|    time_elapsed          | 3544         |
|    total_timesteps       | 614400       |
| train/                   |              |
|    approx_kl             | 0.0037056457 |
|    clip_fraction         | 0.00981      |
|    clip_range            | 0.2          |
|    cost_returns          | 15.9         |
|    cost_value_loss       | 193          |
|    cost_values           | 2.99         |
|    entropy               | -2.47        |
|    entropy_loss          | -2.47        |
|    explained_variance    | 0.77         |
|    lagrangian_multiplier | 0.0103       |
|    learning_rate         | 0.0003       |
|    loss                  | 18.4         |
|    n_updates             | 2990         |
|    policy_gradient_loss  | -0.00131     |
|    std                   | 0.834        |
|    value_loss            | 1.28         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 0.165      |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.165      |
| reward                   | -0.506633  |
| rollout/                 |            |
|    ep_len_mean           | 970        |
|    ep_rew_mean           | -387       |
| time/                    |            |
|    fps                   | 3          |
|    iterations            | 7          |
|    time_elapsed          | 4144       |
|    total_timesteps       | 616448     |
| train/                   |            |
|    approx_kl             | 0.00928811 |
|    clip_fraction         | 0.0705     |
|    clip_range            | 0.2        |
|    cost_returns          | 8.33       |
|    cost_value_loss       | 65.7       |
|    cost_values           | 2.97       |
|    entropy               | -2.47      |
|    entropy_loss          | -2.47      |
|    explained_variance    | 0.957      |
|    lagrangian_multiplier | 0.00999    |
|    learning_rate         | 0.0003     |
|    loss                  | 8          |
|    n_updates             | 3000       |
|    policy_gradient_loss  | -0.00758   |
|    std                   | 0.833      |
|    value_loss            | 1.15       |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.211       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.211       |
| reward                   | -0.4096037  |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -389        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 8           |
|    time_elapsed          | 4746        |
|    total_timesteps       | 618496      |
| train/                   |             |
|    approx_kl             | 0.008548872 |
|    clip_fraction         | 0.0413      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.42        |
|    cost_value_loss       | 103         |
|    cost_values           | 2.9         |
|    entropy               | -2.46       |
|    entropy_loss          | -2.46       |
|    explained_variance    | 0.934       |
|    lagrangian_multiplier | 0.0133      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.94        |
|    n_updates             | 3010        |
|    policy_gradient_loss  | -0.00283    |
|    std                   | 0.833       |
|    value_loss            | 0.446       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0164      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0164      |
| reward                   | -0.47409877 |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -387        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 9           |
|    time_elapsed          | 5354        |
|    total_timesteps       | 620544      |
| train/                   |             |
|    approx_kl             | 0.007004558 |
|    clip_fraction         | 0.0385      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.21        |
|    cost_value_loss       | 32.8        |
|    cost_values           | 2.88        |
|    entropy               | -2.46       |
|    entropy_loss          | -2.46       |
|    explained_variance    | 0.96        |
|    lagrangian_multiplier | 0.00522     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.77        |
|    n_updates             | 3020        |
|    policy_gradient_loss  | -0.000515   |
|    std                   | 0.829       |
|    value_loss            | 0.451       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0957      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0957      |
| reward                   | -0.5217855  |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -386        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 10          |
|    time_elapsed          | 5960        |
|    total_timesteps       | 622592      |
| train/                   |             |
|    approx_kl             | 0.006174743 |
|    clip_fraction         | 0.0353      |
|    clip_range            | 0.2         |
|    cost_returns          | 17.1        |
|    cost_value_loss       | 219         |
|    cost_values           | 2.98        |
|    entropy               | -2.45       |
|    entropy_loss          | -2.45       |
|    explained_variance    | 0.799       |
|    lagrangian_multiplier | 0.0153      |
|    learning_rate         | 0.0003      |
|    loss                  | 15.1        |
|    n_updates             | 3030        |
|    policy_gradient_loss  | -0.00264    |
|    std                   | 0.827       |
|    value_loss            | 1.02        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0152      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0152      |
| reward                   | -0.25361845 |
| rollout/                 |             |
|    ep_len_mean           | 979         |
|    ep_rew_mean           | -389        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 11          |
|    time_elapsed          | 6564        |
|    total_timesteps       | 624640      |
| train/                   |             |
|    approx_kl             | 0.010992432 |
|    clip_fraction         | 0.0528      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.3        |
|    cost_value_loss       | 191         |
|    cost_values           | 2.98        |
|    entropy               | -2.44       |
|    entropy_loss          | -2.45       |
|    explained_variance    | 0.988       |
|    lagrangian_multiplier | 0.0274      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.15        |
|    n_updates             | 3040        |
|    policy_gradient_loss  | -0.00491    |
|    std                   | 0.823       |
|    value_loss            | 0.456       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.285       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.285       |
| reward                   | -0.23423485 |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -392        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 12          |
|    time_elapsed          | 7162        |
|    total_timesteps       | 626688      |
| train/                   |             |
|    approx_kl             | 0.008247571 |
|    clip_fraction         | 0.0417      |
|    clip_range            | 0.2         |
|    cost_returns          | 14          |
|    cost_value_loss       | 173         |
|    cost_values           | 2.98        |
|    entropy               | -2.44       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 0.969       |
|    lagrangian_multiplier | 0.0187      |
|    learning_rate         | 0.0003      |
|    loss                  | 10.8        |
|    n_updates             | 3050        |
|    policy_gradient_loss  | -0.00363    |
|    std                   | 0.821       |
|    value_loss            | 0.781       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.239       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.239       |
| reward                   | -0.4015148  |
| rollout/                 |             |
|    ep_len_mean           | 984         |
|    ep_rew_mean           | -391        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 13          |
|    time_elapsed          | 7769        |
|    total_timesteps       | 628736      |
| train/                   |             |
|    approx_kl             | 0.008779886 |
|    clip_fraction         | 0.0691      |
|    clip_range            | 0.2         |
|    cost_returns          | 15.4        |
|    cost_value_loss       | 182         |
|    cost_values           | 2.99        |
|    entropy               | -2.44       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0.014       |
|    learning_rate         | 0.0003      |
|    loss                  | 13.4        |
|    n_updates             | 3060        |
|    policy_gradient_loss  | -0.0067     |
|    std                   | 0.822       |
|    value_loss            | 0.297       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.00687      |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.00687      |
| reward                   | -0.42933664  |
| rollout/                 |              |
|    ep_len_mean           | 984          |
|    ep_rew_mean           | -390         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 14           |
|    time_elapsed          | 8389         |
|    total_timesteps       | 630784       |
| train/                   |              |
|    approx_kl             | 0.0097132465 |
|    clip_fraction         | 0.038        |
|    clip_range            | 0.2          |
|    cost_returns          | 17.2         |
|    cost_value_loss       | 217          |
|    cost_values           | 3            |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0.984        |
|    lagrangian_multiplier | 0.0394       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.96         |
|    n_updates             | 3070         |
|    policy_gradient_loss  | -0.00286     |
|    std                   | 0.821        |
|    value_loss            | 0.598        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.207        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.207        |
| reward                   | -0.29601574  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -393         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 15           |
|    time_elapsed          | 8997         |
|    total_timesteps       | 632832       |
| train/                   |              |
|    approx_kl             | 0.0036988752 |
|    clip_fraction         | 0.0417       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.4         |
|    cost_value_loss       | 123          |
|    cost_values           | 2.97         |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0.198        |
|    lagrangian_multiplier | 0.0146       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.1         |
|    n_updates             | 3080         |
|    policy_gradient_loss  | -0.00423     |
|    std                   | 0.822        |
|    value_loss            | 0.524        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.308        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.308        |
| reward                   | -0.284509    |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -391         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 16           |
|    time_elapsed          | 9604         |
|    total_timesteps       | 634880       |
| train/                   |              |
|    approx_kl             | 0.0042124637 |
|    clip_fraction         | 0.0308       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.5         |
|    cost_value_loss       | 115          |
|    cost_values           | 2.98         |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0.947        |
|    lagrangian_multiplier | 0.021        |
|    learning_rate         | 0.0003       |
|    loss                  | 7.64         |
|    n_updates             | 3090         |
|    policy_gradient_loss  | -0.00194     |
|    std                   | 0.822        |
|    value_loss            | 0.659        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0686       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0686       |
| reward                   | -0.5268359   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -388         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 17           |
|    time_elapsed          | 10222        |
|    total_timesteps       | 636928       |
| train/                   |              |
|    approx_kl             | 0.0068081683 |
|    clip_fraction         | 0.137        |
|    clip_range            | 0.2          |
|    cost_returns          | 11.5         |
|    cost_value_loss       | 113          |
|    cost_values           | 2.99         |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0.944        |
|    lagrangian_multiplier | 0.0166       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.52         |
|    n_updates             | 3100         |
|    policy_gradient_loss  | -0.00979     |
|    std                   | 0.823        |
|    value_loss            | 0.325        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0587       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0587       |
| reward                   | -0.44930905  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -387         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 18           |
|    time_elapsed          | 10845        |
|    total_timesteps       | 638976       |
| train/                   |              |
|    approx_kl             | 0.0069319513 |
|    clip_fraction         | 0.0617       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.6         |
|    cost_value_loss       | 172          |
|    cost_values           | 3            |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0.941        |
|    lagrangian_multiplier | 0.0382       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.96         |
|    n_updates             | 3110         |
|    policy_gradient_loss  | -0.00252     |
|    std                   | 0.823        |
|    value_loss            | 1.04         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0604       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0604       |
| reward                   | -0.36642995  |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -387         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 19           |
|    time_elapsed          | 11462        |
|    total_timesteps       | 641024       |
| train/                   |              |
|    approx_kl             | 0.0019550358 |
|    clip_fraction         | 0.00161      |
|    clip_range            | 0.2          |
|    cost_returns          | 16.1         |
|    cost_value_loss       | 203          |
|    cost_values           | 3            |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0.813        |
|    lagrangian_multiplier | 0.00432      |
|    learning_rate         | 0.0003       |
|    loss                  | 32.9         |
|    n_updates             | 3120         |
|    policy_gradient_loss  | -0.000763    |
|    std                   | 0.823        |
|    value_loss            | 0.665        |
-------------------------------------------
-----------------------------------------
| avg_speed                | 0.325      |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 0.325      |
| reward                   | -0.534431  |
| rollout/                 |            |
|    ep_len_mean           | 1e+03      |
|    ep_rew_mean           | -387       |
| time/                    |            |
|    fps                   | 3          |
|    iterations            | 20         |
|    time_elapsed          | 12079      |
|    total_timesteps       | 643072     |
| train/                   |            |
|    approx_kl             | 0.00572778 |
|    clip_fraction         | 0.0295     |
|    clip_range            | 0.2        |
|    cost_returns          | 14.1       |
|    cost_value_loss       | 160        |
|    cost_values           | 3          |
|    entropy               | -2.44      |
|    entropy_loss          | -2.44      |
|    explained_variance    | 0.822      |
|    lagrangian_multiplier | 0.0101     |
|    learning_rate         | 0.0003     |
|    loss                  | 15.8       |
|    n_updates             | 3130       |
|    policy_gradient_loss  | -0.003     |
|    std                   | 0.824      |
|    value_loss            | 0.697      |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.113       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.113       |
| reward                   | -0.65002155 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -387        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 21          |
|    time_elapsed          | 12706       |
|    total_timesteps       | 645120      |
| train/                   |             |
|    approx_kl             | 0.005332743 |
|    clip_fraction         | 0.0107      |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 109         |
|    cost_values           | 2.98        |
|    entropy               | -2.44       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 0.956       |
|    lagrangian_multiplier | 0.0166      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.1         |
|    n_updates             | 3140        |
|    policy_gradient_loss  | -0.00075    |
|    std                   | 0.824       |
|    value_loss            | 1.07        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.264       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.264       |
| reward                   | -0.42250404 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -393        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 22          |
|    time_elapsed          | 13329       |
|    total_timesteps       | 647168      |
| train/                   |             |
|    approx_kl             | 0.005595524 |
|    clip_fraction         | 0.053       |
|    clip_range            | 0.2         |
|    cost_returns          | 11.6        |
|    cost_value_loss       | 125         |
|    cost_values           | 2.97        |
|    entropy               | -2.44       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 0.99        |
|    lagrangian_multiplier | 0.0166      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.54        |
|    n_updates             | 3150        |
|    policy_gradient_loss  | -0.00462    |
|    std                   | 0.823       |
|    value_loss            | 2.2         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -1.5408533   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -396         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 23           |
|    time_elapsed          | 13958        |
|    total_timesteps       | 649216       |
| train/                   |              |
|    approx_kl             | 0.0017963375 |
|    clip_fraction         | 0.0342       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.9         |
|    cost_value_loss       | 163          |
|    cost_values           | 2.81         |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0.842        |
|    lagrangian_multiplier | 0.019        |
|    learning_rate         | 0.0003       |
|    loss                  | 10.3         |
|    n_updates             | 3160         |
|    policy_gradient_loss  | 0.000382     |
|    std                   | 0.823        |
|    value_loss            | 9.32         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0536       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0536       |
| reward                   | -0.30866665  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -405         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 24           |
|    time_elapsed          | 14582        |
|    total_timesteps       | 651264       |
| train/                   |              |
|    approx_kl             | 0.0033393414 |
|    clip_fraction         | 0.0437       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.53         |
|    cost_value_loss       | 50           |
|    cost_values           | 2.12         |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0.869        |
|    lagrangian_multiplier | 0.0781       |
|    learning_rate         | 0.0003       |
|    loss                  | 2.78         |
|    n_updates             | 3170         |
|    policy_gradient_loss  | 0.00035      |
|    std                   | 0.823        |
|    value_loss            | 20.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.31         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.31         |
| reward                   | -0.40079176  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -403         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 25           |
|    time_elapsed          | 15212        |
|    total_timesteps       | 653312       |
| train/                   |              |
|    approx_kl             | 0.0027633212 |
|    clip_fraction         | 0.0101       |
|    clip_range            | 0.2          |
|    cost_returns          | 14.1         |
|    cost_value_loss       | 189          |
|    cost_values           | 2.14         |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0.893        |
|    lagrangian_multiplier | 0.0016       |
|    learning_rate         | 0.0003       |
|    loss                  | 51.7         |
|    n_updates             | 3180         |
|    policy_gradient_loss  | -0.00299     |
|    std                   | 0.822        |
|    value_loss            | 1.77         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0124      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0124      |
| reward                   | -0.27067393 |
| rollout/                 |             |
|    ep_len_mean           | 997         |
|    ep_rew_mean           | -403        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 26          |
|    time_elapsed          | 15848       |
|    total_timesteps       | 655360      |
| train/                   |             |
|    approx_kl             | 0.002569398 |
|    clip_fraction         | 0.00122     |
|    clip_range            | 0.2         |
|    cost_returns          | 14.8        |
|    cost_value_loss       | 191         |
|    cost_values           | 2.5         |
|    entropy               | -2.44       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 0.876       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 96.9        |
|    n_updates             | 3190        |
|    policy_gradient_loss  | -0.00159    |
|    std                   | 0.822       |
|    value_loss            | 1.41        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.106        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.106        |
| reward                   | -0.41717643  |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -397         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 27           |
|    time_elapsed          | 16477        |
|    total_timesteps       | 657408       |
| train/                   |              |
|    approx_kl             | 0.0059144124 |
|    clip_fraction         | 0.0114       |
|    clip_range            | 0.2          |
|    cost_returns          | 12           |
|    cost_value_loss       | 139          |
|    cost_values           | 2.88         |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0.833        |
|    lagrangian_multiplier | 0.0138       |
|    learning_rate         | 0.0003       |
|    loss                  | 11.8         |
|    n_updates             | 3200         |
|    policy_gradient_loss  | -0.00078     |
|    std                   | 0.821        |
|    value_loss            | 8.79         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.105        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.105        |
| reward                   | -0.35682583  |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -399         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 28           |
|    time_elapsed          | 17104        |
|    total_timesteps       | 659456       |
| train/                   |              |
|    approx_kl             | 0.0013938393 |
|    clip_fraction         | 0.000732     |
|    clip_range            | 0.2          |
|    cost_returns          | 14.8         |
|    cost_value_loss       | 192          |
|    cost_values           | 2.75         |
|    entropy               | -2.43        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0.0338       |
|    lagrangian_multiplier | 0.015        |
|    learning_rate         | 0.0003       |
|    loss                  | 13.6         |
|    n_updates             | 3210         |
|    policy_gradient_loss  | -0.000916    |
|    std                   | 0.82         |
|    value_loss            | 2.11         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.442        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.442        |
| reward                   | -0.41578233  |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -398         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 29           |
|    time_elapsed          | 17745        |
|    total_timesteps       | 661504       |
| train/                   |              |
|    approx_kl             | 0.0014947345 |
|    clip_fraction         | 0.000928     |
|    clip_range            | 0.2          |
|    cost_returns          | 15.9         |
|    cost_value_loss       | 198          |
|    cost_values           | 2.88         |
|    entropy               | -2.43        |
|    entropy_loss          | -2.43        |
|    explained_variance    | -1.7         |
|    lagrangian_multiplier | 0.0139       |
|    learning_rate         | 0.0003       |
|    loss                  | 14.6         |
|    n_updates             | 3220         |
|    policy_gradient_loss  | -0.000402    |
|    std                   | 0.82         |
|    value_loss            | 3.4          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.274        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.274        |
| reward                   | -0.4604073   |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -399         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 30           |
|    time_elapsed          | 18382        |
|    total_timesteps       | 663552       |
| train/                   |              |
|    approx_kl             | 0.0028757993 |
|    clip_fraction         | 0.00513      |
|    clip_range            | 0.2          |
|    cost_returns          | 15.1         |
|    cost_value_loss       | 186          |
|    cost_values           | 2.97         |
|    entropy               | -2.43        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0.869        |
|    lagrangian_multiplier | 0.0226       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.3         |
|    n_updates             | 3230         |
|    policy_gradient_loss  | -0.0025      |
|    std                   | 0.82         |
|    value_loss            | 0.678        |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -1.1267772  |
| rollout/                 |             |
|    ep_len_mean           | 997         |
|    ep_rew_mean           | -400        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 31          |
|    time_elapsed          | 19026       |
|    total_timesteps       | 665600      |
| train/                   |             |
|    approx_kl             | 0.007950263 |
|    clip_fraction         | 0.0672      |
|    clip_range            | 0.2         |
|    cost_returns          | 17.1        |
|    cost_value_loss       | 223         |
|    cost_values           | 3           |
|    entropy               | -2.43       |
|    entropy_loss          | -2.43       |
|    explained_variance    | 0.958       |
|    lagrangian_multiplier | 0.0431      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.74        |
|    n_updates             | 3240        |
|    policy_gradient_loss  | -0.00331    |
|    std                   | 0.82        |
|    value_loss            | 0.453       |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.04         |
| reward                   | -0.9434045   |
| rollout/                 |              |
|    ep_len_mean           | 997          |
|    ep_rew_mean           | -402         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 32           |
|    time_elapsed          | 19667        |
|    total_timesteps       | 667648       |
| train/                   |              |
|    approx_kl             | 0.0014446648 |
|    clip_fraction         | 0.00596      |
|    clip_range            | 0.2          |
|    cost_returns          | 9.59         |
|    cost_value_loss       | 110          |
|    cost_values           | 2.55         |
|    entropy               | -2.43        |
|    entropy_loss          | -2.43        |
|    explained_variance    | 0.876        |
|    lagrangian_multiplier | 0.116        |
|    learning_rate         | 0.0003       |
|    loss                  | 3.31         |
|    n_updates             | 3250         |
|    policy_gradient_loss  | -0.000415    |
|    std                   | 0.82         |
|    value_loss            | 7.43         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.305       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.305       |
| reward                   | -0.14781632 |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -404        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 33          |
|    time_elapsed          | 20315       |
|    total_timesteps       | 669696      |
| train/                   |             |
|    approx_kl             | 0.005478104 |
|    clip_fraction         | 0.0198      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.88        |
|    cost_value_loss       | 127         |
|    cost_values           | 1.82        |
|    entropy               | -2.43       |
|    entropy_loss          | -2.43       |
|    explained_variance    | 0.922       |
|    lagrangian_multiplier | 0.0102      |
|    learning_rate         | 0.0003      |
|    loss                  | 12.4        |
|    n_updates             | 3260        |
|    policy_gradient_loss  | -0.00538    |
|    std                   | 0.82        |
|    value_loss            | 5.48        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.143       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.143       |
| reward                   | -0.53423667 |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -399        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 34          |
|    time_elapsed          | 20961       |
|    total_timesteps       | 671744      |
| train/                   |             |
|    approx_kl             | 0.008633477 |
|    clip_fraction         | 0.0409      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.89        |
|    cost_value_loss       | 101         |
|    cost_values           | 1.78        |
|    entropy               | -2.43       |
|    entropy_loss          | -2.43       |
|    explained_variance    | 0.91        |
|    lagrangian_multiplier | 0.0113      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.98        |
|    n_updates             | 3270        |
|    policy_gradient_loss  | -0.00376    |
|    std                   | 0.818       |
|    value_loss            | 7.46        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.101       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.101       |
| reward                   | -0.43083477 |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -400        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 35          |
|    time_elapsed          | 21620       |
|    total_timesteps       | 673792      |
| train/                   |             |
|    approx_kl             | 0.005262049 |
|    clip_fraction         | 0.024       |
|    clip_range            | 0.2         |
|    cost_returns          | 10          |
|    cost_value_loss       | 130         |
|    cost_values           | 2           |
|    entropy               | -2.42       |
|    entropy_loss          | -2.43       |
|    explained_variance    | 0.857       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 62.2        |
|    n_updates             | 3280        |
|    policy_gradient_loss  | -0.00364    |
|    std                   | 0.816       |
|    value_loss            | 2.13        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.399        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.399        |
| reward                   | -0.36355412  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -403         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 36           |
|    time_elapsed          | 22264        |
|    total_timesteps       | 675840       |
| train/                   |              |
|    approx_kl             | 0.0011077591 |
|    clip_fraction         | 0.00132      |
|    clip_range            | 0.2          |
|    cost_returns          | 10.4         |
|    cost_value_loss       | 123          |
|    cost_values           | 2.35         |
|    entropy               | -2.43        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 0.889        |
|    lagrangian_multiplier | 0.00287      |
|    learning_rate         | 0.0003       |
|    loss                  | 24.4         |
|    n_updates             | 3290         |
|    policy_gradient_loss  | -0.000664    |
|    std                   | 0.816        |
|    value_loss            | 2.47         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0468       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0468       |
| reward                   | -0.5918035   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -402         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 37           |
|    time_elapsed          | 22906        |
|    total_timesteps       | 677888       |
| train/                   |              |
|    approx_kl             | 0.0047515864 |
|    clip_fraction         | 0.0259       |
|    clip_range            | 0.2          |
|    cost_returns          | 13.9         |
|    cost_value_loss       | 170          |
|    cost_values           | 2.81         |
|    entropy               | -2.43        |
|    entropy_loss          | -2.43        |
|    explained_variance    | 0.979        |
|    lagrangian_multiplier | 0.0218       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.44         |
|    n_updates             | 3300         |
|    policy_gradient_loss  | -0.00398     |
|    std                   | 0.817        |
|    value_loss            | 1.27         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0144       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0144       |
| reward                   | -0.39095286  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -403         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 38           |
|    time_elapsed          | 23561        |
|    total_timesteps       | 679936       |
| train/                   |              |
|    approx_kl             | 0.0018471971 |
|    clip_fraction         | 0.0434       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.12         |
|    cost_value_loss       | 90.6         |
|    cost_values           | 2.95         |
|    entropy               | -2.42        |
|    entropy_loss          | -2.43        |
|    explained_variance    | 0.973        |
|    lagrangian_multiplier | 0.0114       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.02         |
|    n_updates             | 3310         |
|    policy_gradient_loss  | -0.00244     |
|    std                   | 0.815        |
|    value_loss            | 0.643        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.316        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.316        |
| reward                   | -0.49229383  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -404         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 39           |
|    time_elapsed          | 24214        |
|    total_timesteps       | 681984       |
| train/                   |              |
|    approx_kl             | 0.0047876234 |
|    clip_fraction         | 0.015        |
|    clip_range            | 0.2          |
|    cost_returns          | 17.2         |
|    cost_value_loss       | 224          |
|    cost_values           | 2.8          |
|    entropy               | -2.42        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0.00776      |
|    learning_rate         | 0.0003       |
|    loss                  | 24.5         |
|    n_updates             | 3320         |
|    policy_gradient_loss  | -0.00108     |
|    std                   | 0.813        |
|    value_loss            | 0.841        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.127        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.127        |
| reward                   | -0.3308239   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -405         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 40           |
|    time_elapsed          | 24872        |
|    total_timesteps       | 684032       |
| train/                   |              |
|    approx_kl             | 0.0043450985 |
|    clip_fraction         | 0.0344       |
|    clip_range            | 0.2          |
|    cost_returns          | 18.3         |
|    cost_value_loss       | 241          |
|    cost_values           | 2.98         |
|    entropy               | -2.42        |
|    entropy_loss          | -2.42        |
|    explained_variance    | -4.16        |
|    lagrangian_multiplier | 0.0225       |
|    learning_rate         | 0.0003       |
|    loss                  | 12.2         |
|    n_updates             | 3330         |
|    policy_gradient_loss  | -0.00293     |
|    std                   | 0.814        |
|    value_loss            | 1.41         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.185        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.185        |
| reward                   | -0.24267666  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -406         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 41           |
|    time_elapsed          | 25532        |
|    total_timesteps       | 686080       |
| train/                   |              |
|    approx_kl             | 0.0017827862 |
|    clip_fraction         | 0.00103      |
|    clip_range            | 0.2          |
|    cost_returns          | 15           |
|    cost_value_loss       | 183          |
|    cost_values           | 2.96         |
|    entropy               | -2.42        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 0.307        |
|    lagrangian_multiplier | 0.0205       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.5         |
|    n_updates             | 3340         |
|    policy_gradient_loss  | -0.000632    |
|    std                   | 0.815        |
|    value_loss            | 1.27         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.239        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.239        |
| reward                   | -0.28074262  |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -408         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 42           |
|    time_elapsed          | 26195        |
|    total_timesteps       | 688128       |
| train/                   |              |
|    approx_kl             | 0.0019300766 |
|    clip_fraction         | 0.0153       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.95         |
|    cost_value_loss       | 87.2         |
|    cost_values           | 2.98         |
|    entropy               | -2.42        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 0.695        |
|    lagrangian_multiplier | 0.012        |
|    learning_rate         | 0.0003       |
|    loss                  | 8.77         |
|    n_updates             | 3350         |
|    policy_gradient_loss  | -0.00197     |
|    std                   | 0.815        |
|    value_loss            | 1.08         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0296      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0296      |
| reward                   | -0.21561603 |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -407        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 43          |
|    time_elapsed          | 26860       |
|    total_timesteps       | 690176      |
| train/                   |             |
|    approx_kl             | 0.006920186 |
|    clip_fraction         | 0.0774      |
|    clip_range            | 0.2         |
|    cost_returns          | 11          |
|    cost_value_loss       | 128         |
|    cost_values           | 2.5         |
|    entropy               | -2.42       |
|    entropy_loss          | -2.42       |
|    explained_variance    | 0.95        |
|    lagrangian_multiplier | 0.219       |
|    learning_rate         | 0.0003      |
|    loss                  | 3.02        |
|    n_updates             | 3360        |
|    policy_gradient_loss  | 0.00628     |
|    std                   | 0.815       |
|    value_loss            | 9.43        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.99         |
| reward                   | -0.9551148   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -406         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 44           |
|    time_elapsed          | 27526        |
|    total_timesteps       | 692224       |
| train/                   |              |
|    approx_kl             | 0.0032697646 |
|    clip_fraction         | 0.0135       |
|    clip_range            | 0.2          |
|    cost_returns          | 9.28         |
|    cost_value_loss       | 98.7         |
|    cost_values           | 2.33         |
|    entropy               | -2.42        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 0.98         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 46.9         |
|    n_updates             | 3370         |
|    policy_gradient_loss  | -0.00305     |
|    std                   | 0.815        |
|    value_loss            | 0.752        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.201       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.201       |
| reward                   | -0.52365416 |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -409        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 45          |
|    time_elapsed          | 28196       |
|    total_timesteps       | 694272      |
| train/                   |             |
|    approx_kl             | 0.001641514 |
|    clip_fraction         | 0.0021      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.63        |
|    cost_value_loss       | 37.8        |
|    cost_values           | 2.16        |
|    entropy               | -2.42       |
|    entropy_loss          | -2.42       |
|    explained_variance    | 0.953       |
|    lagrangian_multiplier | 0.0725      |
|    learning_rate         | 0.0003      |
|    loss                  | 2.42        |
|    n_updates             | 3380        |
|    policy_gradient_loss  | -0.00331    |
|    std                   | 0.814       |
|    value_loss            | 4.43        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.00554     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00554     |
| reward                   | -0.20763387 |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -410        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 46          |
|    time_elapsed          | 28851       |
|    total_timesteps       | 696320      |
| train/                   |             |
|    approx_kl             | 0.006250393 |
|    clip_fraction         | 0.0244      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.24        |
|    cost_value_loss       | 60.5        |
|    cost_values           | 1.53        |
|    entropy               | -2.42       |
|    entropy_loss          | -2.42       |
|    explained_variance    | 0.963       |
|    lagrangian_multiplier | 0.000772    |
|    learning_rate         | 0.0003      |
|    loss                  | 20.3        |
|    n_updates             | 3390        |
|    policy_gradient_loss  | -0.00389    |
|    std                   | 0.815       |
|    value_loss            | 3.4         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.173        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.173        |
| reward                   | -0.3235539   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -405         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 47           |
|    time_elapsed          | 29512        |
|    total_timesteps       | 698368       |
| train/                   |              |
|    approx_kl             | 0.0032305783 |
|    clip_fraction         | 0.00278      |
|    clip_range            | 0.2          |
|    cost_returns          | 9.45         |
|    cost_value_loss       | 117          |
|    cost_values           | 1.77         |
|    entropy               | -2.42        |
|    entropy_loss          | -2.42        |
|    explained_variance    | 0.875        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 60.6         |
|    n_updates             | 3400         |
|    policy_gradient_loss  | -0.000927    |
|    std                   | 0.815        |
|    value_loss            | 3.23         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.182       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.182       |
| reward                   | -0.41511744 |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -405        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 48          |
|    time_elapsed          | 30175       |
|    total_timesteps       | 700416      |
| train/                   |             |
|    approx_kl             | 0.011205901 |
|    clip_fraction         | 0.0771      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.67        |
|    cost_value_loss       | 0.638       |
|    cost_values           | 1.91        |
|    entropy               | -2.42       |
|    entropy_loss          | -2.42       |
|    explained_variance    | 0.941       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.508       |
|    n_updates             | 3410        |
|    policy_gradient_loss  | -0.000969   |
|    std                   | 0.813       |
|    value_loss            | 1.3         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0306      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0306      |
| reward                   | -0.56283504 |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -405        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 49          |
|    time_elapsed          | 30844       |
|    total_timesteps       | 702464      |
| train/                   |             |
|    approx_kl             | 0.004988651 |
|    clip_fraction         | 0.0612      |
|    clip_range            | 0.2         |
|    cost_returns          | 16.1        |
|    cost_value_loss       | 222         |
|    cost_values           | 1.97        |
|    entropy               | -2.41       |
|    entropy_loss          | -2.41       |
|    explained_variance    | 0.679       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 109         |
|    n_updates             | 3420        |
|    policy_gradient_loss  | 0.00295     |
|    std                   | 0.811       |
|    value_loss            | 1.45        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ppol-extra-obs/2fzzfvlw
------------------------------------
| avg_speed          | 0.36        |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 0.36        |
| reward             | -0.42108282 |
| rollout/           |             |
|    ep_len_mean     | 993         |
|    ep_rew_mean     | -408        |
| time/              |             |
|    fps             | 3           |
|    iterations      | 1           |
|    time_elapsed    | 668         |
|    total_timesteps | 704512      |
------------------------------------
------------------------------------------
| avg_speed                | 0.388       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.388       |
| reward                   | -0.3157126  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -407        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 2           |
|    time_elapsed          | 1345        |
|    total_timesteps       | 706560      |
| train/                   |             |
|    approx_kl             | 0.006400954 |
|    clip_fraction         | 0.039       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.51        |
|    cost_value_loss       | 22          |
|    cost_values           | 2.36        |
|    entropy               | -2.4        |
|    entropy_loss          | -2.41       |
|    explained_variance    | 0.965       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.8        |
|    n_updates             | 3440        |
|    policy_gradient_loss  | -0.00198    |
|    std                   | 0.806       |
|    value_loss            | 1.05        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.201       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.201       |
| reward                   | -0.49196234 |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -402        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 3           |
|    time_elapsed          | 2017        |
|    total_timesteps       | 708608      |
| train/                   |             |
|    approx_kl             | 0.0043328   |
|    clip_fraction         | 0.0365      |
|    clip_range            | 0.2         |
|    cost_returns          | 10.1        |
|    cost_value_loss       | 112         |
|    cost_values           | 2.69        |
|    entropy               | -2.39       |
|    entropy_loss          | -2.39       |
|    explained_variance    | 0.526       |
|    lagrangian_multiplier | 0.0113      |
|    learning_rate         | 0.0003      |
|    loss                  | 10.2        |
|    n_updates             | 3450        |
|    policy_gradient_loss  | -0.00063    |
|    std                   | 0.803       |
|    value_loss            | 0.616       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.191       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.191       |
| reward                   | -0.35748196 |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -403        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 4           |
|    time_elapsed          | 2690        |
|    total_timesteps       | 710656      |
| train/                   |             |
|    approx_kl             | 0.008365613 |
|    clip_fraction         | 0.0399      |
|    clip_range            | 0.2         |
|    cost_returns          | 13.2        |
|    cost_value_loss       | 157         |
|    cost_values           | 2.96        |
|    entropy               | -2.39       |
|    entropy_loss          | -2.39       |
|    explained_variance    | 0.824       |
|    lagrangian_multiplier | 0.0176      |
|    learning_rate         | 0.0003      |
|    loss                  | 10.2        |
|    n_updates             | 3460        |
|    policy_gradient_loss  | -0.00155    |
|    std                   | 0.802       |
|    value_loss            | 0.9         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.297        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.297        |
| reward                   | -0.1958595   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -403         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 5            |
|    time_elapsed          | 3368         |
|    total_timesteps       | 712704       |
| train/                   |              |
|    approx_kl             | 0.0027223574 |
|    clip_fraction         | 0.0488       |
|    clip_range            | 0.2          |
|    cost_returns          | 11.8         |
|    cost_value_loss       | 134          |
|    cost_values           | 2.95         |
|    entropy               | -2.39        |
|    entropy_loss          | -2.39        |
|    explained_variance    | 0.978        |
|    lagrangian_multiplier | 0.0138       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.6         |
|    n_updates             | 3470         |
|    policy_gradient_loss  | -0.00413     |
|    std                   | 0.801        |
|    value_loss            | 0.53         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.163       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.163       |
| reward                   | -0.35826603 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -398        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 6           |
|    time_elapsed          | 4048        |
|    total_timesteps       | 714752      |
| train/                   |             |
|    approx_kl             | 0.004774601 |
|    clip_fraction         | 0.0399      |
|    clip_range            | 0.2         |
|    cost_returns          | 10.6        |
|    cost_value_loss       | 111         |
|    cost_values           | 2.97        |
|    entropy               | -2.38       |
|    entropy_loss          | -2.38       |
|    explained_variance    | 0.876       |
|    lagrangian_multiplier | 0.0132      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.79        |
|    n_updates             | 3480        |
|    policy_gradient_loss  | -0.00258    |
|    std                   | 0.798       |
|    value_loss            | 0.473       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0883      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0883      |
| reward                   | -0.40425548 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -396        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 7           |
|    time_elapsed          | 4730        |
|    total_timesteps       | 716800      |
| train/                   |             |
|    approx_kl             | 0.003992633 |
|    clip_fraction         | 0.0212      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.8        |
|    cost_value_loss       | 128         |
|    cost_values           | 2.99        |
|    entropy               | -2.38       |
|    entropy_loss          | -2.38       |
|    explained_variance    | 0.359       |
|    lagrangian_multiplier | 0.0199      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.55        |
|    n_updates             | 3490        |
|    policy_gradient_loss  | -0.00189    |
|    std                   | 0.797       |
|    value_loss            | 4.83        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.067       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.067       |
| reward                   | -0.27366695 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -396        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 8           |
|    time_elapsed          | 5427        |
|    total_timesteps       | 718848      |
| train/                   |             |
|    approx_kl             | 0.006012492 |
|    clip_fraction         | 0.0686      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.9        |
|    cost_value_loss       | 140         |
|    cost_values           | 2.97        |
|    entropy               | -2.37       |
|    entropy_loss          | -2.38       |
|    explained_variance    | 0.949       |
|    lagrangian_multiplier | 0.0142      |
|    learning_rate         | 0.0003      |
|    loss                  | 10.9        |
|    n_updates             | 3500        |
|    policy_gradient_loss  | -0.00377    |
|    std                   | 0.795       |
|    value_loss            | 0.121       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0549       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0549       |
| reward                   | -0.44172698  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -393         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 9            |
|    time_elapsed          | 6105         |
|    total_timesteps       | 720896       |
| train/                   |              |
|    approx_kl             | 0.0045353705 |
|    clip_fraction         | 0.049        |
|    clip_range            | 0.2          |
|    cost_returns          | 7.92         |
|    cost_value_loss       | 74.8         |
|    cost_values           | 2.96         |
|    entropy               | -2.38        |
|    entropy_loss          | -2.38        |
|    explained_variance    | 0.98         |
|    lagrangian_multiplier | 0.0104       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.91         |
|    n_updates             | 3510         |
|    policy_gradient_loss  | -0.00294     |
|    std                   | 0.796        |
|    value_loss            | 0.25         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0426      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0426      |
| reward                   | -0.20037138 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -392        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 10          |
|    time_elapsed          | 6794        |
|    total_timesteps       | 722944      |
| train/                   |             |
|    approx_kl             | 0.012402969 |
|    clip_fraction         | 0.0537      |
|    clip_range            | 0.2         |
|    cost_returns          | 11.1        |
|    cost_value_loss       | 125         |
|    cost_values           | 2.93        |
|    entropy               | -2.38       |
|    entropy_loss          | -2.38       |
|    explained_variance    | -0.723      |
|    lagrangian_multiplier | 0.0165      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.31        |
|    n_updates             | 3520        |
|    policy_gradient_loss  | -0.00285    |
|    std                   | 0.798       |
|    value_loss            | 0.967       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.173       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.173       |
| reward                   | -0.3778969  |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -392        |
| time/                    |             |
|    fps                   | 3           |
|    iterations            | 11          |
|    time_elapsed          | 7487        |
|    total_timesteps       | 724992      |
| train/                   |             |
|    approx_kl             | 0.005961294 |
|    clip_fraction         | 0.0493      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.09        |
|    cost_value_loss       | 59.9        |
|    cost_values           | 2.71        |
|    entropy               | -2.39       |
|    entropy_loss          | -2.39       |
|    explained_variance    | 0.891       |
|    lagrangian_multiplier | 0.00674     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.9         |
|    n_updates             | 3530        |
|    policy_gradient_loss  | -0.00402    |
|    std                   | 0.8         |
|    value_loss            | 1.7         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.017        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.017        |
| reward                   | -0.49550146  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -393         |
| time/                    |              |
|    fps                   | 3            |
|    iterations            | 12           |
|    time_elapsed          | 8172         |
|    total_timesteps       | 727040       |
| train/                   |              |
|    approx_kl             | 0.0038601388 |
|    clip_fraction         | 0.0308       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.28         |
|    cost_value_loss       | 18.4         |
|    cost_values           | 2.29         |
|    entropy               | -2.38        |
|    entropy_loss          | -2.38        |
|    explained_variance    | 0.61         |
|    lagrangian_multiplier | 0.000298     |
|    learning_rate         | 0.0003       |
|    loss                  | 8.61         |
|    n_updates             | 3540         |
|    policy_gradient_loss  | -0.00284     |
|    std                   | 0.797        |
|    value_loss            | 1.39         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.112       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.112       |
| reward                   | -0.51517344 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -395        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 13          |
|    time_elapsed          | 8878        |
|    total_timesteps       | 729088      |
| train/                   |             |
|    approx_kl             | 0.006521675 |
|    clip_fraction         | 0.0459      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.19        |
|    cost_value_loss       | 63.6        |
|    cost_values           | 2.41        |
|    entropy               | -2.37       |
|    entropy_loss          | -2.37       |
|    explained_variance    | 0.928       |
|    lagrangian_multiplier | 0.00528     |
|    learning_rate         | 0.0003      |
|    loss                  | 10.5        |
|    n_updates             | 3550        |
|    policy_gradient_loss  | -0.00326    |
|    std                   | 0.794       |
|    value_loss            | 0.473       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.2          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.2          |
| reward                   | -0.329893    |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -396         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 14           |
|    time_elapsed          | 9586         |
|    total_timesteps       | 731136       |
| train/                   |              |
|    approx_kl             | 0.0074170427 |
|    clip_fraction         | 0.0566       |
|    clip_range            | 0.2          |
|    cost_returns          | 16.2         |
|    cost_value_loss       | 209          |
|    cost_values           | 2.57         |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.884        |
|    lagrangian_multiplier | 0.00172      |
|    learning_rate         | 0.0003       |
|    loss                  | 54.5         |
|    n_updates             | 3560         |
|    policy_gradient_loss  | -0.00294     |
|    std                   | 0.794        |
|    value_loss            | 0.407        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.107        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.107        |
| reward                   | -0.376793    |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -398         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 15           |
|    time_elapsed          | 10284        |
|    total_timesteps       | 733184       |
| train/                   |              |
|    approx_kl             | 0.0023416139 |
|    clip_fraction         | 0.0226       |
|    clip_range            | 0.2          |
|    cost_returns          | 15.6         |
|    cost_value_loss       | 198          |
|    cost_values           | 2.84         |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.962        |
|    lagrangian_multiplier | 0.0265       |
|    learning_rate         | 0.0003       |
|    loss                  | 9.56         |
|    n_updates             | 3570         |
|    policy_gradient_loss  | -0.00217     |
|    std                   | 0.794        |
|    value_loss            | 0.564        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.139       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.139       |
| reward                   | -0.32203373 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -397        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 16          |
|    time_elapsed          | 10979       |
|    total_timesteps       | 735232      |
| train/                   |             |
|    approx_kl             | 0.0049764   |
|    clip_fraction         | 0.0325      |
|    clip_range            | 0.2         |
|    cost_returns          | 8.67        |
|    cost_value_loss       | 91.2        |
|    cost_values           | 2.79        |
|    entropy               | -2.37       |
|    entropy_loss          | -2.37       |
|    explained_variance    | 0.987       |
|    lagrangian_multiplier | 0.0145      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.86        |
|    n_updates             | 3580        |
|    policy_gradient_loss  | -0.00501    |
|    std                   | 0.793       |
|    value_loss            | 0.347       |
------------------------------------------
------------------------------------------
| avg_speed                | 3.39        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.39        |
| reward                   | -0.92637753 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -397        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 17          |
|    time_elapsed          | 11682       |
|    total_timesteps       | 737280      |
| train/                   |             |
|    approx_kl             | 0.005769831 |
|    clip_fraction         | 0.0511      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.73        |
|    cost_value_loss       | 14.7        |
|    cost_values           | 2.44        |
|    entropy               | -2.37       |
|    entropy_loss          | -2.37       |
|    explained_variance    | -0.244      |
|    lagrangian_multiplier | 0.000945    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.57        |
|    n_updates             | 3590        |
|    policy_gradient_loss  | -0.00344    |
|    std                   | 0.791       |
|    value_loss            | 1.14        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.139        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.139        |
| reward                   | -0.23552014  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -401         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 18           |
|    time_elapsed          | 12379        |
|    total_timesteps       | 739328       |
| train/                   |              |
|    approx_kl             | 0.0043367837 |
|    clip_fraction         | 0.0356       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.74         |
|    cost_value_loss       | 8.46         |
|    cost_values           | 2.09         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.909        |
|    lagrangian_multiplier | 0.037        |
|    learning_rate         | 0.0003       |
|    loss                  | 2.06         |
|    n_updates             | 3600         |
|    policy_gradient_loss  | 0.000105     |
|    std                   | 0.791        |
|    value_loss            | 4.6          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.175        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.175        |
| reward                   | -0.4511891   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -400         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 19           |
|    time_elapsed          | 13083        |
|    total_timesteps       | 741376       |
| train/                   |              |
|    approx_kl             | 0.0052437745 |
|    clip_fraction         | 0.0261       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.37         |
|    cost_value_loss       | 53.9         |
|    cost_values           | 1.45         |
|    entropy               | -2.37        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.979        |
|    lagrangian_multiplier | 0.00211      |
|    learning_rate         | 0.0003       |
|    loss                  | 14.3         |
|    n_updates             | 3610         |
|    policy_gradient_loss  | -0.00309     |
|    std                   | 0.792        |
|    value_loss            | 2.14         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.174       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.174       |
| reward                   | -0.22451816 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -399        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 20          |
|    time_elapsed          | 13792       |
|    total_timesteps       | 743424      |
| train/                   |             |
|    approx_kl             | 0.002804527 |
|    clip_fraction         | 0.0146      |
|    clip_range            | 0.2         |
|    cost_returns          | 7.15        |
|    cost_value_loss       | 82          |
|    cost_values           | 1.66        |
|    entropy               | -2.36       |
|    entropy_loss          | -2.37       |
|    explained_variance    | 0.94        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 42.2        |
|    n_updates             | 3620        |
|    policy_gradient_loss  | -0.00193    |
|    std                   | 0.791       |
|    value_loss            | 1.54        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.63         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.63         |
| reward                   | -0.9201796   |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -395         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 21           |
|    time_elapsed          | 14496        |
|    total_timesteps       | 745472       |
| train/                   |              |
|    approx_kl             | 0.0055368207 |
|    clip_fraction         | 0.0211       |
|    clip_range            | 0.2          |
|    cost_returns          | 16.4         |
|    cost_value_loss       | 227          |
|    cost_values           | 2.01         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.92         |
|    lagrangian_multiplier | 0.00339      |
|    learning_rate         | 0.0003       |
|    loss                  | 42.2         |
|    n_updates             | 3630         |
|    policy_gradient_loss  | -0.00273     |
|    std                   | 0.79         |
|    value_loss            | 1.98         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.199        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.199        |
| reward                   | -0.36634365  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -396         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 22           |
|    time_elapsed          | 15203        |
|    total_timesteps       | 747520       |
| train/                   |              |
|    approx_kl             | 0.0022616684 |
|    clip_fraction         | 0.00376      |
|    clip_range            | 0.2          |
|    cost_returns          | 6.24         |
|    cost_value_loss       | 62.4         |
|    cost_values           | 1.95         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.982        |
|    lagrangian_multiplier | 0.0274       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.14         |
|    n_updates             | 3640         |
|    policy_gradient_loss  | -0.00258     |
|    std                   | 0.79         |
|    value_loss            | 3.65         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.615        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.615        |
| reward                   | -0.46728408  |
| rollout/                 |              |
|    ep_len_mean           | 983          |
|    ep_rew_mean           | -388         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 23           |
|    time_elapsed          | 15918        |
|    total_timesteps       | 749568       |
| train/                   |              |
|    approx_kl             | 0.0043931836 |
|    clip_fraction         | 0.0516       |
|    clip_range            | 0.2          |
|    cost_returns          | 7.16         |
|    cost_value_loss       | 75.1         |
|    cost_values           | 1.52         |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.982        |
|    lagrangian_multiplier | 0.0077       |
|    learning_rate         | 0.0003       |
|    loss                  | 8.97         |
|    n_updates             | 3650         |
|    policy_gradient_loss  | -0.0049      |
|    std                   | 0.792        |
|    value_loss            | 0.684        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.131       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.131       |
| reward                   | -0.38402027 |
| rollout/                 |             |
|    ep_len_mean           | 983         |
|    ep_rew_mean           | -390        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 24          |
|    time_elapsed          | 16630       |
|    total_timesteps       | 751616      |
| train/                   |             |
|    approx_kl             | 0.008242215 |
|    clip_fraction         | 0.0777      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.95        |
|    cost_value_loss       | 33.3        |
|    cost_values           | 1.71        |
|    entropy               | -2.38       |
|    entropy_loss          | -2.37       |
|    explained_variance    | 0.729       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.5        |
|    n_updates             | 3660        |
|    policy_gradient_loss  | -0.00471    |
|    std                   | 0.796       |
|    value_loss            | 1.75        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.196        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.196        |
| reward                   | -0.35748827  |
| rollout/                 |              |
|    ep_len_mean           | 988          |
|    ep_rew_mean           | -392         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 25           |
|    time_elapsed          | 17342        |
|    total_timesteps       | 753664       |
| train/                   |              |
|    approx_kl             | 0.0048163305 |
|    clip_fraction         | 0.0552       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.51         |
|    cost_value_loss       | 55.7         |
|    cost_values           | 1.95         |
|    entropy               | -2.38        |
|    entropy_loss          | -2.38        |
|    explained_variance    | 0.909        |
|    lagrangian_multiplier | 0.00131      |
|    learning_rate         | 0.0003       |
|    loss                  | 19.5         |
|    n_updates             | 3670         |
|    policy_gradient_loss  | -0.00583     |
|    std                   | 0.797        |
|    value_loss            | 1.48         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.125       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.125       |
| reward                   | -0.52295005 |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -392        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 26          |
|    time_elapsed          | 18060       |
|    total_timesteps       | 755712      |
| train/                   |             |
|    approx_kl             | 0.003404811 |
|    clip_fraction         | 0.0417      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.35        |
|    cost_value_loss       | 5.27        |
|    cost_values           | 2.12        |
|    entropy               | -2.39       |
|    entropy_loss          | -2.38       |
|    explained_variance    | 0.983       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.64        |
|    n_updates             | 3680        |
|    policy_gradient_loss  | -0.00269    |
|    std                   | 0.799       |
|    value_loss            | 0.575       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.129       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.129       |
| reward                   | -0.3191422  |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -394        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 27          |
|    time_elapsed          | 18776       |
|    total_timesteps       | 757760      |
| train/                   |             |
|    approx_kl             | 0.006360582 |
|    clip_fraction         | 0.0568      |
|    clip_range            | 0.2         |
|    cost_returns          | 9.07        |
|    cost_value_loss       | 110         |
|    cost_values           | 2.32        |
|    entropy               | -2.39       |
|    entropy_loss          | -2.39       |
|    explained_variance    | 0.896       |
|    lagrangian_multiplier | 0.00892     |
|    learning_rate         | 0.0003      |
|    loss                  | 12.1        |
|    n_updates             | 3690        |
|    policy_gradient_loss  | 0.00124     |
|    std                   | 0.799       |
|    value_loss            | 6.85        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.153        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.153        |
| reward                   | -0.48531833  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -393         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 28           |
|    time_elapsed          | 19501        |
|    total_timesteps       | 759808       |
| train/                   |              |
|    approx_kl             | 0.0019488212 |
|    clip_fraction         | 0.00693      |
|    clip_range            | 0.2          |
|    cost_returns          | 14.7         |
|    cost_value_loss       | 191          |
|    cost_values           | 2.51         |
|    entropy               | -2.38        |
|    entropy_loss          | -2.38        |
|    explained_variance    | 0.968        |
|    lagrangian_multiplier | 0.00958      |
|    learning_rate         | 0.0003       |
|    loss                  | 18           |
|    n_updates             | 3700         |
|    policy_gradient_loss  | -0.00129     |
|    std                   | 0.797        |
|    value_loss            | 0.859        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0243       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0243       |
| reward                   | -0.39502436  |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -393         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 29           |
|    time_elapsed          | 20228        |
|    total_timesteps       | 761856       |
| train/                   |              |
|    approx_kl             | 0.0035036674 |
|    clip_fraction         | 0.0501       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.02         |
|    cost_value_loss       | 82.6         |
|    cost_values           | 2.61         |
|    entropy               | -2.38        |
|    entropy_loss          | -2.38        |
|    explained_variance    | 0.277        |
|    lagrangian_multiplier | 0.0115       |
|    learning_rate         | 0.0003       |
|    loss                  | 7.86         |
|    n_updates             | 3710         |
|    policy_gradient_loss  | -0.00465     |
|    std                   | 0.799        |
|    value_loss            | 0.897        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0493       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0493       |
| reward                   | -0.5301307   |
| rollout/                 |              |
|    ep_len_mean           | 978          |
|    ep_rew_mean           | -393         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 30           |
|    time_elapsed          | 20960        |
|    total_timesteps       | 763904       |
| train/                   |              |
|    approx_kl             | 0.0010194317 |
|    clip_fraction         | 0.0224       |
|    clip_range            | 0.2          |
|    cost_returns          | 12.8         |
|    cost_value_loss       | 150          |
|    cost_values           | 2.74         |
|    entropy               | -2.39        |
|    entropy_loss          | -2.39        |
|    explained_variance    | 0.973        |
|    lagrangian_multiplier | 0.0177       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.2         |
|    n_updates             | 3720         |
|    policy_gradient_loss  | -0.000107    |
|    std                   | 0.799        |
|    value_loss            | 0.51         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.129       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.129       |
| reward                   | -0.56791395 |
| rollout/                 |             |
|    ep_len_mean           | 978         |
|    ep_rew_mean           | -392        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 31          |
|    time_elapsed          | 21686       |
|    total_timesteps       | 765952      |
| train/                   |             |
|    approx_kl             | 0.003551511 |
|    clip_fraction         | 0.0272      |
|    clip_range            | 0.2         |
|    cost_returns          | 12.9        |
|    cost_value_loss       | 156         |
|    cost_values           | 2.91        |
|    entropy               | -2.38       |
|    entropy_loss          | -2.38       |
|    explained_variance    | 0.993       |
|    lagrangian_multiplier | 0.023       |
|    learning_rate         | 0.0003      |
|    loss                  | 9.01        |
|    n_updates             | 3730        |
|    policy_gradient_loss  | -0.00184    |
|    std                   | 0.798       |
|    value_loss            | 0.246       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.1         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.1         |
| reward                   | -0.21353394 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -398        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 32          |
|    time_elapsed          | 22417       |
|    total_timesteps       | 768000      |
| train/                   |             |
|    approx_kl             | 0.008705598 |
|    clip_fraction         | 0.0461      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.38        |
|    cost_value_loss       | 0.189       |
|    cost_values           | 2.57        |
|    entropy               | -2.38       |
|    entropy_loss          | -2.38       |
|    explained_variance    | 0.958       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.173       |
|    n_updates             | 3740        |
|    policy_gradient_loss  | -0.000837   |
|    std                   | 0.795       |
|    value_loss            | 0.774       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0292      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0292      |
| reward                   | -0.20500852 |
| rollout/                 |             |
|    ep_len_mean           | 982         |
|    ep_rew_mean           | -398        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 33          |
|    time_elapsed          | 23146       |
|    total_timesteps       | 770048      |
| train/                   |             |
|    approx_kl             | 0.009627993 |
|    clip_fraction         | 0.187       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.98        |
|    cost_value_loss       | 26.4        |
|    cost_values           | 2.17        |
|    entropy               | -2.38       |
|    entropy_loss          | -2.38       |
|    explained_variance    | 0.945       |
|    lagrangian_multiplier | 0.00329     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.34        |
|    n_updates             | 3750        |
|    policy_gradient_loss  | 0.00842     |
|    std                   | 0.795       |
|    value_loss            | 0.711       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.118        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.118        |
| reward                   | -0.1978453   |
| rollout/                 |              |
|    ep_len_mean           | 982          |
|    ep_rew_mean           | -397         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 34           |
|    time_elapsed          | 23867        |
|    total_timesteps       | 772096       |
| train/                   |              |
|    approx_kl             | 0.0047360044 |
|    clip_fraction         | 0.0453       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.82         |
|    cost_value_loss       | 47.8         |
|    cost_values           | 2.34         |
|    entropy               | -2.38        |
|    entropy_loss          | -2.38        |
|    explained_variance    | 0.951        |
|    lagrangian_multiplier | 0.000113     |
|    learning_rate         | 0.0003       |
|    loss                  | 22.3         |
|    n_updates             | 3760         |
|    policy_gradient_loss  | 0.000219     |
|    std                   | 0.795        |
|    value_loss            | 0.756        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0397      |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.0397      |
| reward                   | -0.48138815 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -391        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 35          |
|    time_elapsed          | 24593       |
|    total_timesteps       | 774144      |
| train/                   |             |
|    approx_kl             | 0.003472037 |
|    clip_fraction         | 0.0443      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.72        |
|    cost_value_loss       | 35.8        |
|    cost_values           | 2.3         |
|    entropy               | -2.37       |
|    entropy_loss          | -2.38       |
|    explained_variance    | 0.989       |
|    lagrangian_multiplier | 0.00563     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.11        |
|    n_updates             | 3770        |
|    policy_gradient_loss  | -0.00232    |
|    std                   | 0.794       |
|    value_loss            | 0.445       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.116       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.116       |
| reward                   | -0.25271577 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -390        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 36          |
|    time_elapsed          | 25322       |
|    total_timesteps       | 776192      |
| train/                   |             |
|    approx_kl             | 0.006396518 |
|    clip_fraction         | 0.0883      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.08        |
|    cost_value_loss       | 51.7        |
|    cost_values           | 2.45        |
|    entropy               | -2.37       |
|    entropy_loss          | -2.37       |
|    explained_variance    | 0.906       |
|    lagrangian_multiplier | 0.00211     |
|    learning_rate         | 0.0003      |
|    loss                  | 13.4        |
|    n_updates             | 3780        |
|    policy_gradient_loss  | -0.00388    |
|    std                   | 0.792       |
|    value_loss            | 4.24        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.181        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.181        |
| reward                   | -0.46250004  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -385         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 37           |
|    time_elapsed          | 26061        |
|    total_timesteps       | 778240       |
| train/                   |              |
|    approx_kl             | 0.0056760237 |
|    clip_fraction         | 0.0509       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.27         |
|    cost_value_loss       | 49           |
|    cost_values           | 2.69         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.975        |
|    lagrangian_multiplier | 0.00612      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.99         |
|    n_updates             | 3790         |
|    policy_gradient_loss  | -0.00423     |
|    std                   | 0.79         |
|    value_loss            | 0.637        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0055      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0055      |
| reward                   | -0.43837088 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -388        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 38          |
|    time_elapsed          | 26803       |
|    total_timesteps       | 780288      |
| train/                   |             |
|    approx_kl             | 0.005557742 |
|    clip_fraction         | 0.036       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.44        |
|    cost_value_loss       | 32.2        |
|    cost_values           | 2.68        |
|    entropy               | -2.37       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.907       |
|    lagrangian_multiplier | 0.00428     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.69        |
|    n_updates             | 3800        |
|    policy_gradient_loss  | -0.00332    |
|    std                   | 0.791       |
|    value_loss            | 0.852       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.0704      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0704      |
| reward                   | -0.46265042 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -387        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 39          |
|    time_elapsed          | 27546       |
|    total_timesteps       | 782336      |
| train/                   |             |
|    approx_kl             | 0.011151845 |
|    clip_fraction         | 0.0989      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.96        |
|    cost_value_loss       | 20.8        |
|    cost_values           | 2.62        |
|    entropy               | -2.36       |
|    entropy_loss          | -2.37       |
|    explained_variance    | 0.958       |
|    lagrangian_multiplier | 0.00131     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.17        |
|    n_updates             | 3810        |
|    policy_gradient_loss  | -0.00759    |
|    std                   | 0.79        |
|    value_loss            | 0.157       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0991       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0991       |
| reward                   | -0.5741051   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -388         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 40           |
|    time_elapsed          | 28286        |
|    total_timesteps       | 784384       |
| train/                   |              |
|    approx_kl             | 0.0049296557 |
|    clip_fraction         | 0.0232       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.48         |
|    cost_value_loss       | 1.37         |
|    cost_values           | 2.65         |
|    entropy               | -2.37        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.902        |
|    lagrangian_multiplier | 9.14e-05     |
|    learning_rate         | 0.0003       |
|    loss                  | 0.636        |
|    n_updates             | 3820         |
|    policy_gradient_loss  | -0.00181     |
|    std                   | 0.791        |
|    value_loss            | 1.28         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.032        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.032        |
| reward                   | -0.22177985  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -388         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 41           |
|    time_elapsed          | 29044        |
|    total_timesteps       | 786432       |
| train/                   |              |
|    approx_kl             | 0.0048021544 |
|    clip_fraction         | 0.137        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.12         |
|    cost_value_loss       | 0.458        |
|    cost_values           | 2.35         |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.869        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.712        |
|    n_updates             | 3830         |
|    policy_gradient_loss  | -0.00364     |
|    std                   | 0.791        |
|    value_loss            | 5.14         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0176       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0176       |
| reward                   | -0.19460481  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -385         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 42           |
|    time_elapsed          | 29787        |
|    total_timesteps       | 788480       |
| train/                   |              |
|    approx_kl             | 0.0058085537 |
|    clip_fraction         | 0.0333       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.07         |
|    cost_value_loss       | 37.2         |
|    cost_values           | 2.29         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.991        |
|    lagrangian_multiplier | 0.00202      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.1         |
|    n_updates             | 3840         |
|    policy_gradient_loss  | -0.00385     |
|    std                   | 0.789        |
|    value_loss            | 0.288        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.146       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.146       |
| reward                   | -0.3779416  |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -381        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 43          |
|    time_elapsed          | 30539       |
|    total_timesteps       | 790528      |
| train/                   |             |
|    approx_kl             | 0.007917542 |
|    clip_fraction         | 0.0232      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.93        |
|    cost_value_loss       | 0.152       |
|    cost_values           | 2.26        |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.745       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 0.125       |
|    n_updates             | 3850        |
|    policy_gradient_loss  | -0.00166    |
|    std                   | 0.788       |
|    value_loss            | 0.57        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.275       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.275       |
| reward                   | -0.47653443 |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -382        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 44          |
|    time_elapsed          | 31291       |
|    total_timesteps       | 792576      |
| train/                   |             |
|    approx_kl             | 0.009501627 |
|    clip_fraction         | 0.101       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.55        |
|    cost_value_loss       | 7.2         |
|    cost_values           | 2.1         |
|    entropy               | -2.35       |
|    entropy_loss          | -2.35       |
|    explained_variance    | 0.992       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.2         |
|    n_updates             | 3860        |
|    policy_gradient_loss  | -0.000912   |
|    std                   | 0.785       |
|    value_loss            | 0.358       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.892        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.892        |
| reward                   | -0.47628123  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -386         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 45           |
|    time_elapsed          | 32051        |
|    total_timesteps       | 794624       |
| train/                   |              |
|    approx_kl             | 0.0073470413 |
|    clip_fraction         | 0.0764       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.16         |
|    cost_value_loss       | 3.35         |
|    cost_values           | 1.87         |
|    entropy               | -2.35        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 0.784        |
|    lagrangian_multiplier | 0.00108      |
|    learning_rate         | 0.0003       |
|    loss                  | 1.79         |
|    n_updates             | 3870         |
|    policy_gradient_loss  | 0.00275      |
|    std                   | 0.785        |
|    value_loss            | 1.6          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.117        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.117        |
| reward                   | -0.47680587  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -388         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 46           |
|    time_elapsed          | 32812        |
|    total_timesteps       | 796672       |
| train/                   |              |
|    approx_kl             | 0.0077099735 |
|    clip_fraction         | 0.202        |
|    clip_range            | 0.2          |
|    cost_returns          | 1.52         |
|    cost_value_loss       | 0.0747       |
|    cost_values           | 1.68         |
|    entropy               | -2.36        |
|    entropy_loss          | -2.35        |
|    explained_variance    | 0.993        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0204       |
|    n_updates             | 3880         |
|    policy_gradient_loss  | -0.00956     |
|    std                   | 0.787        |
|    value_loss            | 0.14         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.00205     |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.00205     |
| reward                   | -0.53568083 |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -387        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 47          |
|    time_elapsed          | 33573       |
|    total_timesteps       | 798720      |
| train/                   |             |
|    approx_kl             | 0.008739907 |
|    clip_fraction         | 0.106       |
|    clip_range            | 0.2         |
|    cost_returns          | 8.01        |
|    cost_value_loss       | 106         |
|    cost_values           | 1.49        |
|    entropy               | -2.37       |
|    entropy_loss          | -2.36       |
|    explained_variance    | -0.401      |
|    lagrangian_multiplier | 0.0133      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.66        |
|    n_updates             | 3890        |
|    policy_gradient_loss  | -0.00204    |
|    std                   | 0.791       |
|    value_loss            | 1.2         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.229        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.229        |
| reward                   | -0.47632805  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -385         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 48           |
|    time_elapsed          | 34334        |
|    total_timesteps       | 800768       |
| train/                   |              |
|    approx_kl             | 0.0093800975 |
|    clip_fraction         | 0.097        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.48         |
|    cost_value_loss       | 18.8         |
|    cost_values           | 1.37         |
|    entropy               | -2.38        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.977        |
|    lagrangian_multiplier | 0.00198      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.17         |
|    n_updates             | 3900         |
|    policy_gradient_loss  | -0.00946     |
|    std                   | 0.794        |
|    value_loss            | 0.547        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.115        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.115        |
| reward                   | -0.33856925  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -386         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 49           |
|    time_elapsed          | 35100        |
|    total_timesteps       | 802816       |
| train/                   |              |
|    approx_kl             | 0.0042546513 |
|    clip_fraction         | 0.0116       |
|    clip_range            | 0.2          |
|    cost_returns          | 8.23         |
|    cost_value_loss       | 108          |
|    cost_values           | 1.68         |
|    entropy               | -2.38        |
|    entropy_loss          | -2.38        |
|    explained_variance    | 0.989        |
|    lagrangian_multiplier | 0.00356      |
|    learning_rate         | 0.0003       |
|    loss                  | 18.7         |
|    n_updates             | 3910         |
|    policy_gradient_loss  | -0.00189     |
|    std                   | 0.794        |
|    value_loss            | 0.294        |
-------------------------------------------
------------------------------------
| avg_speed          | 0.0774      |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 0.0774      |
| reward             | -0.25642875 |
| rollout/           |             |
|    ep_len_mean     | 970         |
|    ep_rew_mean     | -387        |
| time/              |             |
|    fps             | 2           |
|    iterations      | 1           |
|    time_elapsed    | 762         |
|    total_timesteps | 804864      |
------------------------------------
------------------------------------------
| avg_speed                | 0.109       |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 0.109       |
| reward                   | -0.22603472 |
| rollout/                 |             |
|    ep_len_mean           | 970         |
|    ep_rew_mean           | -388        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 2           |
|    time_elapsed          | 1541        |
|    total_timesteps       | 806912      |
| train/                   |             |
|    approx_kl             | 0.009376323 |
|    clip_fraction         | 0.105       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.33        |
|    cost_value_loss       | 33.4        |
|    cost_values           | 1.24        |
|    entropy               | -2.38       |
|    entropy_loss          | -2.37       |
|    explained_variance    | 0.257       |
|    lagrangian_multiplier | 0.00439     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.79        |
|    n_updates             | 3930        |
|    policy_gradient_loss  | -0.011      |
|    std                   | 0.794       |
|    value_loss            | 0.834       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.141        |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.141        |
| reward                   | -0.39144832  |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -389         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 3            |
|    time_elapsed          | 2313         |
|    total_timesteps       | 808960       |
| train/                   |              |
|    approx_kl             | 0.0051455544 |
|    clip_fraction         | 0.0269       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.4          |
|    cost_value_loss       | 74.8         |
|    cost_values           | 1.38         |
|    entropy               | -2.38        |
|    entropy_loss          | -2.38        |
|    explained_variance    | -0.376       |
|    lagrangian_multiplier | 0.00744      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.47         |
|    n_updates             | 3940         |
|    policy_gradient_loss  | -0.0022      |
|    std                   | 0.794        |
|    value_loss            | 2.51         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.25         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.25         |
| reward                   | -0.3946214   |
| rollout/                 |              |
|    ep_len_mean           | 970          |
|    ep_rew_mean           | -391         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 4            |
|    time_elapsed          | 3101         |
|    total_timesteps       | 811008       |
| train/                   |              |
|    approx_kl             | 0.0060495073 |
|    clip_fraction         | 0.0515       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.41         |
|    cost_value_loss       | 29.1         |
|    cost_values           | 1.23         |
|    entropy               | -2.38        |
|    entropy_loss          | -2.38        |
|    explained_variance    | -1.64        |
|    lagrangian_multiplier | 0.002        |
|    learning_rate         | 0.0003       |
|    loss                  | 8.63         |
|    n_updates             | 3950         |
|    policy_gradient_loss  | -0.00336     |
|    std                   | 0.796        |
|    value_loss            | 1.86         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.0437      |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.0437      |
| reward                   | -0.5028852  |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -397        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 5           |
|    time_elapsed          | 3877        |
|    total_timesteps       | 813056      |
| train/                   |             |
|    approx_kl             | 0.004151812 |
|    clip_fraction         | 0.0261      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.28        |
|    cost_value_loss       | 66.9        |
|    cost_values           | 1.3         |
|    entropy               | -2.38       |
|    entropy_loss          | -2.38       |
|    explained_variance    | 0.698       |
|    lagrangian_multiplier | 9.35e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 32.5        |
|    n_updates             | 3960        |
|    policy_gradient_loss  | -0.00262    |
|    std                   | 0.796       |
|    value_loss            | 1.05        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0886       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0886       |
| reward                   | -0.47086158  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -398         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 6            |
|    time_elapsed          | 4656         |
|    total_timesteps       | 815104       |
| train/                   |              |
|    approx_kl             | 0.0066063064 |
|    clip_fraction         | 0.0811       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.38         |
|    cost_value_loss       | 1.07         |
|    cost_values           | 1.35         |
|    entropy               | -2.38        |
|    entropy_loss          | -2.38        |
|    explained_variance    | 0.874        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.652        |
|    n_updates             | 3970         |
|    policy_gradient_loss  | 0.000412     |
|    std                   | 0.798        |
|    value_loss            | 0.585        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0409       |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 0.0409       |
| reward                   | -0.3247656   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -399         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 7            |
|    time_elapsed          | 5433         |
|    total_timesteps       | 817152       |
| train/                   |              |
|    approx_kl             | 0.0021021133 |
|    clip_fraction         | 0.0331       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.88         |
|    cost_value_loss       | 7.27         |
|    cost_values           | 1.44         |
|    entropy               | -2.39        |
|    entropy_loss          | -2.39        |
|    explained_variance    | 0.944        |
|    lagrangian_multiplier | 0.000473     |
|    learning_rate         | 0.0003       |
|    loss                  | 4.05         |
|    n_updates             | 3980         |
|    policy_gradient_loss  | -0.00206     |
|    std                   | 0.801        |
|    value_loss            | 0.365        |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0161       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0161       |
| reward                   | -0.43526557  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -402         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 8            |
|    time_elapsed          | 6223         |
|    total_timesteps       | 819200       |
| train/                   |              |
|    approx_kl             | 0.0020592832 |
|    clip_fraction         | 0.00776      |
|    clip_range            | 0.2          |
|    cost_returns          | 5.52         |
|    cost_value_loss       | 67.7         |
|    cost_values           | 1.48         |
|    entropy               | -2.39        |
|    entropy_loss          | -2.39        |
|    explained_variance    | 0.941        |
|    lagrangian_multiplier | 0.00406      |
|    learning_rate         | 0.0003       |
|    loss                  | 11.5         |
|    n_updates             | 3990         |
|    policy_gradient_loss  | -0.000818    |
|    std                   | 0.801        |
|    value_loss            | 0.583        |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.194       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.194       |
| reward                   | -0.46672344 |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -403        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 9           |
|    time_elapsed          | 6991        |
|    total_timesteps       | 821248      |
| train/                   |             |
|    approx_kl             | 0.003919902 |
|    clip_fraction         | 0.0312      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.23        |
|    cost_value_loss       | 47.6        |
|    cost_values           | 1.43        |
|    entropy               | -2.4        |
|    entropy_loss          | -2.39       |
|    explained_variance    | 0.996       |
|    lagrangian_multiplier | 0.00653     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.46        |
|    n_updates             | 4000        |
|    policy_gradient_loss  | -0.0031     |
|    std                   | 0.803       |
|    value_loss            | 0.176       |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.0567       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0567       |
| reward                   | -0.40904886  |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -404         |
| time/                    |              |
|    fps                   | 2            |
|    iterations            | 10           |
|    time_elapsed          | 7773         |
|    total_timesteps       | 823296       |
| train/                   |              |
|    approx_kl             | 0.0129637765 |
|    clip_fraction         | 0.0711       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.97         |
|    cost_value_loss       | 0.0218       |
|    cost_values           | 1.03         |
|    entropy               | -2.39        |
|    entropy_loss          | -2.4         |
|    explained_variance    | 0.992        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 0.0104       |
|    n_updates             | 4010         |
|    policy_gradient_loss  | -0.00347     |
|    std                   | 0.802        |
|    value_loss            | 0.0647       |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.157       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.157       |
| reward                   | -0.5314972  |
| rollout/                 |             |
|    ep_len_mean           | 980         |
|    ep_rew_mean           | -405        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 11          |
|    time_elapsed          | 8568        |
|    total_timesteps       | 825344      |
| train/                   |             |
|    approx_kl             | 0.005361338 |
|    clip_fraction         | 0.0351      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.95        |
|    cost_value_loss       | 14.4        |
|    cost_values           | 1.08        |
|    entropy               | -2.39       |
|    entropy_loss          | -2.39       |
|    explained_variance    | 0.965       |
|    lagrangian_multiplier | 0.00182     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.06        |
|    n_updates             | 4020        |
|    policy_gradient_loss  | -0.00307    |
|    std                   | 0.799       |
|    value_loss            | 0.532       |
------------------------------------------
------------------------------------------
| avg_speed                | 0.00278     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00278     |
| reward                   | -0.36487716 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -399        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 12          |
|    time_elapsed          | 9354        |
|    total_timesteps       | 827392      |
| train/                   |             |
|    approx_kl             | 0.011741545 |
|    clip_fraction         | 0.107       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.27        |
|    cost_value_loss       | 5.37        |
|    cost_values           | 0.737       |
|    entropy               | -2.39       |
|    entropy_loss          | -2.39       |
|    explained_variance    | 0.677       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.07        |
|    n_updates             | 4030        |
|    policy_gradient_loss  | -0.00453    |
|    std                   | 0.8         |
|    value_loss            | 1.01        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.203       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.203       |
| reward                   | -0.37849027 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -399        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 13          |
|    time_elapsed          | 10154       |
|    total_timesteps       | 829440      |
| train/                   |             |
|    approx_kl             | 0.006975111 |
|    clip_fraction         | 0.0352      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.87        |
|    cost_value_loss       | 59.8        |
|    cost_values           | 0.889       |
|    entropy               | -2.39       |
|    entropy_loss          | -2.39       |
|    explained_variance    | 0.63        |
|    lagrangian_multiplier | 0.0099      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.78        |
|    n_updates             | 4040        |
|    policy_gradient_loss  | -0.00165    |
|    std                   | 0.802       |
|    value_loss            | 4.27        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.00486     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00486     |
| reward                   | -0.46351328 |
| rollout/                 |             |
|    ep_len_mean           | 971         |
|    ep_rew_mean           | -398        |
| time/                    |             |
|    fps                   | 2           |
|    iterations            | 14          |
|    time_elapsed          | 10949       |
|    total_timesteps       | 831488      |
| train/                   |             |
|    approx_kl             | 0.004173349 |
|    clip_fraction         | 0.0699      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.75        |
|    cost_value_loss       | 27          |
|    cost_values           | 1.08        |
|    entropy               | -2.4        |
|    entropy_loss          | -2.39       |
|    explained_variance    | 0.986       |
|    lagrangian_multiplier | 0.00257     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.03        |
|    n_updates             | 4050        |
|    policy_gradient_loss  | -0.00349    |
|    std                   | 0.804       |
|    value_loss            | 0.189       |
------------------------------------------
slurmstepd: error: *** JOB 141965 ON ddpg.ist.berkeley.edu CANCELLED AT 2024-02-24T19:31:50 DUE TO TIME LIMIT ***
slurmstepd: error: *** STEP 141965.0 ON ddpg.ist.berkeley.edu CANCELLED AT 2024-02-24T19:31:50 DUE TO TIME LIMIT ***
