wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.3 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20240213_121132-vlorgroe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run abundant-dragon-29
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/ent-coefficient-ppol
wandb: üöÄ View run at https://wandb.ai/ecrl/ent-coefficient-ppol/runs/vlorgroe
Using cpu device
------------------------------------
| avg_speed          | 0.313       |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 0.313       |
| reward             | -0.78667814 |
| rollout/           |             |
|    ep_len_mean     | 1e+03       |
|    ep_rew_mean     | -1.93e+03   |
| time/              |             |
|    fps             | 70          |
|    iterations      | 1           |
|    time_elapsed    | 29          |
|    total_timesteps | 2048        |
------------------------------------
-------------------------------------------
| avg_speed                | 1.47         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.47         |
| reward                   | -1.0948756   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.72e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 2            |
|    time_elapsed          | 60           |
|    total_timesteps       | 4096         |
| train/                   |              |
|    approx_kl             | 0.0051510492 |
|    clip_fraction         | 0.054        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.175        |
|    cost_value_loss       | 0.12         |
|    cost_values           | 0.0845       |
|    entropy               | -2.85        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.000638     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 605          |
|    n_updates             | 10           |
|    policy_gradient_loss  | -0.00582     |
|    std                   | 1.01         |
|    value_loss            | 1.26e+03     |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.05        |
| reward                   | -0.95383304 |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.51e+03   |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 3           |
|    time_elapsed          | 91          |
|    total_timesteps       | 6144        |
| train/                   |             |
|    approx_kl             | 0.002477863 |
|    clip_fraction         | 0.0176      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.216       |
|    cost_value_loss       | 0.543       |
|    cost_values           | 0.0799      |
|    entropy               | -2.86       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.0851      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 374         |
|    n_updates             | 20          |
|    policy_gradient_loss  | -0.00234    |
|    std                   | 1.01        |
|    value_loss            | 754         |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.19         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.19         |
| reward                   | -0.94445235  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.38e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 4            |
|    time_elapsed          | 122          |
|    total_timesteps       | 8192         |
| train/                   |              |
|    approx_kl             | 0.0042813653 |
|    clip_fraction         | 0.0463       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.128        |
|    cost_value_loss       | 0.112        |
|    cost_values           | 0.103        |
|    entropy               | -2.86        |
|    entropy_loss          | -2.86        |
|    explained_variance    | -0.0865      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 150          |
|    n_updates             | 30           |
|    policy_gradient_loss  | -0.00506     |
|    std                   | 1.01         |
|    value_loss            | 311          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.771       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.771       |
| reward                   | -0.6963381  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.33e+03   |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 5           |
|    time_elapsed          | 153         |
|    total_timesteps       | 10240       |
| train/                   |             |
|    approx_kl             | 0.003228564 |
|    clip_fraction         | 0.0395      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.823       |
|    cost_value_loss       | 3.75        |
|    cost_values           | 0.333       |
|    entropy               | -2.87       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.0445      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 158         |
|    n_updates             | 40          |
|    policy_gradient_loss  | -0.00493    |
|    std                   | 1.02        |
|    value_loss            | 335         |
------------------------------------------
------------------------------------------
| avg_speed                | 5.88        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.88        |
| reward                   | -0.7337352  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.33e+03   |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 6           |
|    time_elapsed          | 184         |
|    total_timesteps       | 12288       |
| train/                   |             |
|    approx_kl             | 0.004173347 |
|    clip_fraction         | 0.0299      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.366       |
|    cost_value_loss       | 0.227       |
|    cost_values           | 0.404       |
|    entropy               | -2.88       |
|    entropy_loss          | -2.87       |
|    explained_variance    | -0.221      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 159         |
|    n_updates             | 50          |
|    policy_gradient_loss  | -0.00412    |
|    std                   | 1.02        |
|    value_loss            | 359         |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.12         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.12         |
| reward                   | -0.7955238   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.28e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 7            |
|    time_elapsed          | 215          |
|    total_timesteps       | 14336        |
| train/                   |              |
|    approx_kl             | 0.0032518404 |
|    clip_fraction         | 0.0231       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.3          |
|    cost_value_loss       | 0.476        |
|    cost_values           | 0.247        |
|    entropy               | -2.88        |
|    entropy_loss          | -2.88        |
|    explained_variance    | -0.629       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 278          |
|    n_updates             | 60           |
|    policy_gradient_loss  | -0.00463     |
|    std                   | 1.02         |
|    value_loss            | 583          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.512        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.512        |
| reward                   | -0.78841066  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.25e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 8            |
|    time_elapsed          | 246          |
|    total_timesteps       | 16384        |
| train/                   |              |
|    approx_kl             | 0.0049260077 |
|    clip_fraction         | 0.0271       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.363        |
|    cost_value_loss       | 0.373        |
|    cost_values           | 0.361        |
|    entropy               | -2.88        |
|    entropy_loss          | -2.88        |
|    explained_variance    | -1.02        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 124          |
|    n_updates             | 70           |
|    policy_gradient_loss  | -0.00409     |
|    std                   | 1.02         |
|    value_loss            | 270          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.16         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.16         |
| reward                   | -0.8317201   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 9            |
|    time_elapsed          | 277          |
|    total_timesteps       | 18432        |
| train/                   |              |
|    approx_kl             | 0.0054105483 |
|    clip_fraction         | 0.0223       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.569        |
|    cost_value_loss       | 1.2          |
|    cost_values           | 0.501        |
|    entropy               | -2.88        |
|    entropy_loss          | -2.88        |
|    explained_variance    | -0.464       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 127          |
|    n_updates             | 80           |
|    policy_gradient_loss  | -0.00442     |
|    std                   | 1.02         |
|    value_loss            | 284          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.54         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.54         |
| reward                   | -1.6966218   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.19e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 10           |
|    time_elapsed          | 308          |
|    total_timesteps       | 20480        |
| train/                   |              |
|    approx_kl             | 0.0051627704 |
|    clip_fraction         | 0.0235       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.716        |
|    cost_value_loss       | 0.798        |
|    cost_values           | 0.628        |
|    entropy               | -2.88        |
|    entropy_loss          | -2.88        |
|    explained_variance    | -0.269       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 62.1         |
|    n_updates             | 90           |
|    policy_gradient_loss  | -0.00361     |
|    std                   | 1.02         |
|    value_loss            | 147          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.84         |
| reward                   | -1.372707    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 11           |
|    time_elapsed          | 340          |
|    total_timesteps       | 22528        |
| train/                   |              |
|    approx_kl             | 0.0045650937 |
|    clip_fraction         | 0.0221       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.686        |
|    cost_value_loss       | 0.664        |
|    cost_values           | 0.7          |
|    entropy               | -2.88        |
|    entropy_loss          | -2.88        |
|    explained_variance    | -0.154       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 143          |
|    n_updates             | 100          |
|    policy_gradient_loss  | -0.00376     |
|    std                   | 1.02         |
|    value_loss            | 322          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.68         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.68         |
| reward                   | -1.399021    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 12           |
|    time_elapsed          | 371          |
|    total_timesteps       | 24576        |
| train/                   |              |
|    approx_kl             | 0.0032860725 |
|    clip_fraction         | 0.0134       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.773        |
|    cost_value_loss       | 1.54         |
|    cost_values           | 0.751        |
|    entropy               | -2.88        |
|    entropy_loss          | -2.88        |
|    explained_variance    | -0.525       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 86.7         |
|    n_updates             | 110          |
|    policy_gradient_loss  | -0.00243     |
|    std                   | 1.02         |
|    value_loss            | 209          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.03         |
| reward                   | -1.7445102   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.17e+03    |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 13           |
|    time_elapsed          | 403          |
|    total_timesteps       | 26624        |
| train/                   |              |
|    approx_kl             | 0.0031639047 |
|    clip_fraction         | 0.0105       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.721        |
|    cost_value_loss       | 0.0102       |
|    cost_values           | 0.755        |
|    entropy               | -2.88        |
|    entropy_loss          | -2.88        |
|    explained_variance    | -0.000205    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 178          |
|    n_updates             | 120          |
|    policy_gradient_loss  | -0.00314     |
|    std                   | 1.02         |
|    value_loss            | 403          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.25         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.25         |
| reward                   | -1.7200556   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.18e+03    |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 14           |
|    time_elapsed          | 435          |
|    total_timesteps       | 28672        |
| train/                   |              |
|    approx_kl             | 0.0063688373 |
|    clip_fraction         | 0.0385       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.665        |
|    cost_value_loss       | 0.47         |
|    cost_values           | 0.67         |
|    entropy               | -2.88        |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.0113       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 151          |
|    n_updates             | 130          |
|    policy_gradient_loss  | -0.00549     |
|    std                   | 1.02         |
|    value_loss            | 323          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.75         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.75         |
| reward                   | -2.3542182   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.21e+03    |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 15           |
|    time_elapsed          | 466          |
|    total_timesteps       | 30720        |
| train/                   |              |
|    approx_kl             | 0.0031414588 |
|    clip_fraction         | 0.00542      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.717        |
|    cost_value_loss       | 0.944        |
|    cost_values           | 0.714        |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | -0.36        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 181          |
|    n_updates             | 140          |
|    policy_gradient_loss  | -0.00151     |
|    std                   | 1.03         |
|    value_loss            | 396          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.76        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.76        |
| reward                   | -2.8627732  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.25e+03   |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 16          |
|    time_elapsed          | 498         |
|    total_timesteps       | 32768       |
| train/                   |             |
|    approx_kl             | 0.002546357 |
|    clip_fraction         | 0.00347     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.532       |
|    cost_value_loss       | 0.0202      |
|    cost_values           | 0.608       |
|    entropy               | -2.89       |
|    entropy_loss          | -2.89       |
|    explained_variance    | -0.377      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 379         |
|    n_updates             | 150         |
|    policy_gradient_loss  | -0.00107    |
|    std                   | 1.03        |
|    value_loss            | 830         |
------------------------------------------
------------------------------------------
| avg_speed                | 5.32        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.32        |
| reward                   | -2.4067326  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.31e+03   |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 17          |
|    time_elapsed          | 529         |
|    total_timesteps       | 34816       |
| train/                   |             |
|    approx_kl             | 0.007044203 |
|    clip_fraction         | 0.0423      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.455       |
|    cost_value_loss       | 0.0387      |
|    cost_values           | 0.466       |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | 0.0305      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 460         |
|    n_updates             | 160         |
|    policy_gradient_loss  | -0.00516    |
|    std                   | 1.03        |
|    value_loss            | 951         |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.26         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.26         |
| reward                   | -1.7916198   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.32e+03    |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 18           |
|    time_elapsed          | 559          |
|    total_timesteps       | 36864        |
| train/                   |              |
|    approx_kl             | 0.0047272258 |
|    clip_fraction         | 0.0138       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.41         |
|    cost_value_loss       | 0.0757       |
|    cost_values           | 0.419        |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.0604       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 555          |
|    n_updates             | 170          |
|    policy_gradient_loss  | -0.00265     |
|    std                   | 1.03         |
|    value_loss            | 1.14e+03     |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.57        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.57        |
| reward                   | -1.7129221  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.32e+03   |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 19          |
|    time_elapsed          | 590         |
|    total_timesteps       | 38912       |
| train/                   |             |
|    approx_kl             | 0.006220619 |
|    clip_fraction         | 0.0359      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.586       |
|    cost_value_loss       | 0.909       |
|    cost_values           | 0.558       |
|    entropy               | -2.9        |
|    entropy_loss          | -2.89       |
|    explained_variance    | 0.0561      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 233         |
|    n_updates             | 180         |
|    policy_gradient_loss  | -0.00419    |
|    std                   | 1.03        |
|    value_loss            | 500         |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.93         |
| reward                   | -2.0631068   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.31e+03    |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 20           |
|    time_elapsed          | 621          |
|    total_timesteps       | 40960        |
| train/                   |              |
|    approx_kl             | 0.0059187906 |
|    clip_fraction         | 0.0284       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.85         |
|    cost_value_loss       | 1.86         |
|    cost_values           | 0.813        |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.0563       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 152          |
|    n_updates             | 190          |
|    policy_gradient_loss  | -0.00355     |
|    std                   | 1.03         |
|    value_loss            | 331          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.9          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.9          |
| reward                   | -0.8814786   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.32e+03    |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 21           |
|    time_elapsed          | 653          |
|    total_timesteps       | 43008        |
| train/                   |              |
|    approx_kl             | 0.0058571217 |
|    clip_fraction         | 0.0355       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.825        |
|    cost_value_loss       | 0.332        |
|    cost_values           | 0.819        |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.0595       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 177          |
|    n_updates             | 200          |
|    policy_gradient_loss  | -0.00424     |
|    std                   | 1.03         |
|    value_loss            | 389          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0592       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0592       |
| reward                   | -0.8213884   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.3e+03     |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 22           |
|    time_elapsed          | 685          |
|    total_timesteps       | 45056        |
| train/                   |              |
|    approx_kl             | 0.0025960533 |
|    clip_fraction         | 0.00347      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.56         |
|    cost_value_loss       | 0.0376       |
|    cost_values           | 0.69         |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | -1.53        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 172          |
|    n_updates             | 210          |
|    policy_gradient_loss  | -0.00199     |
|    std                   | 1.03         |
|    value_loss            | 458          |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.04        |
| reward                   | -0.808561   |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.29e+03   |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 23          |
|    time_elapsed          | 714         |
|    total_timesteps       | 47104       |
| train/                   |             |
|    approx_kl             | 0.003972021 |
|    clip_fraction         | 0.0361      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.726       |
|    cost_value_loss       | 0.752       |
|    cost_values           | 0.714       |
|    entropy               | -2.9        |
|    entropy_loss          | -2.89       |
|    explained_variance    | -0.275      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 101         |
|    n_updates             | 220         |
|    policy_gradient_loss  | -0.00431    |
|    std                   | 1.03        |
|    value_loss            | 219         |
------------------------------------------
------------------------------------------
| avg_speed                | 1.63        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.63        |
| reward                   | -1.1643926  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.28e+03   |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 24          |
|    time_elapsed          | 745         |
|    total_timesteps       | 49152       |
| train/                   |             |
|    approx_kl             | 0.004987264 |
|    clip_fraction         | 0.0318      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.28        |
|    cost_value_loss       | 5.7         |
|    cost_values           | 0.877       |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | -0.398      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 79.7        |
|    n_updates             | 230         |
|    policy_gradient_loss  | -0.006      |
|    std                   | 1.03        |
|    value_loss            | 175         |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.303        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.303        |
| reward                   | -1.186269    |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 25           |
|    time_elapsed          | 776          |
|    total_timesteps       | 51200        |
| train/                   |              |
|    approx_kl             | 0.0029824262 |
|    clip_fraction         | 0.0147       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.23         |
|    cost_value_loss       | 1.8          |
|    cost_values           | 0.943        |
|    entropy               | -2.9         |
|    entropy_loss          | -2.9         |
|    explained_variance    | -0.101       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 84           |
|    n_updates             | 240          |
|    policy_gradient_loss  | -0.00244     |
|    std                   | 1.03         |
|    value_loss            | 180          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.56         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 2.56         |
| reward                   | -0.39034927  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 26           |
|    time_elapsed          | 807          |
|    total_timesteps       | 53248        |
| train/                   |              |
|    approx_kl             | 0.0036258255 |
|    clip_fraction         | 0.021        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.939        |
|    cost_value_loss       | 0.994        |
|    cost_values           | 0.872        |
|    entropy               | -2.91        |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.00238      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 125          |
|    n_updates             | 250          |
|    policy_gradient_loss  | -0.00261     |
|    std                   | 1.03         |
|    value_loss            | 264          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.88         |
| reward                   | -1.7008623   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 27           |
|    time_elapsed          | 839          |
|    total_timesteps       | 55296        |
| train/                   |              |
|    approx_kl             | 0.0030466374 |
|    clip_fraction         | 0.00928      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.833        |
|    cost_value_loss       | 0.365        |
|    cost_values           | 0.879        |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | -0.0729      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 132          |
|    n_updates             | 260          |
|    policy_gradient_loss  | -0.00194     |
|    std                   | 1.04         |
|    value_loss            | 283          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0444       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0444       |
| reward                   | -1.2091242   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.26e+03    |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 28           |
|    time_elapsed          | 870          |
|    total_timesteps       | 57344        |
| train/                   |              |
|    approx_kl             | 0.0042209653 |
|    clip_fraction         | 0.044        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.48         |
|    cost_value_loss       | 19.5         |
|    cost_values           | 0.989        |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | -0.0595      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 111          |
|    n_updates             | 270          |
|    policy_gradient_loss  | -0.00605     |
|    std                   | 1.04         |
|    value_loss            | 214          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.329       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.329       |
| reward                   | -0.8280613  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.27e+03   |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 29          |
|    time_elapsed          | 902         |
|    total_timesteps       | 59392       |
| train/                   |             |
|    approx_kl             | 0.006276211 |
|    clip_fraction         | 0.0304      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.838       |
|    cost_value_loss       | 0.0365      |
|    cost_values           | 0.922       |
|    entropy               | -2.93       |
|    entropy_loss          | -2.93       |
|    explained_variance    | 0.00197     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 154         |
|    n_updates             | 280         |
|    policy_gradient_loss  | -0.00478    |
|    std                   | 1.05        |
|    value_loss            | 312         |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.35         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.35         |
| reward                   | -0.49681953  |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.27e+03    |
| time/                    |              |
|    fps                   | 65           |
|    iterations            | 30           |
|    time_elapsed          | 933          |
|    total_timesteps       | 61440        |
| train/                   |              |
|    approx_kl             | 0.0031211036 |
|    clip_fraction         | 0.00576      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.713        |
|    cost_value_loss       | 0.0228       |
|    cost_values           | 0.848        |
|    entropy               | -2.93        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.0048       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 310          |
|    n_updates             | 290          |
|    policy_gradient_loss  | -0.00199     |
|    std                   | 1.05         |
|    value_loss            | 655          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.75        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.75        |
| reward                   | -2.419629   |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.28e+03   |
| time/                    |             |
|    fps                   | 65          |
|    iterations            | 31          |
|    time_elapsed          | 963         |
|    total_timesteps       | 63488       |
| train/                   |             |
|    approx_kl             | 0.005200651 |
|    clip_fraction         | 0.0559      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.42        |
|    cost_value_loss       | 5.94        |
|    cost_values           | 0.921       |
|    entropy               | -2.95       |
|    entropy_loss          | -2.94       |
|    explained_variance    | 0.00377     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 83.9        |
|    n_updates             | 300         |
|    policy_gradient_loss  | -0.00638    |
|    std                   | 1.06        |
|    value_loss            | 173         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.36        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.36        |
| reward                   | -2.3670201  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.3e+03    |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 32          |
|    time_elapsed          | 992         |
|    total_timesteps       | 65536       |
| train/                   |             |
|    approx_kl             | 0.005670529 |
|    clip_fraction         | 0.0474      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.837       |
|    cost_value_loss       | 0.192       |
|    cost_values           | 0.923       |
|    entropy               | -2.96       |
|    entropy_loss          | -2.96       |
|    explained_variance    | -0.00108    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 471         |
|    n_updates             | 310         |
|    policy_gradient_loss  | -0.00561    |
|    std                   | 1.06        |
|    value_loss            | 944         |
------------------------------------------
-----------------------------------------
| avg_speed                | 7.76       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.76       |
| reward                   | -2.0153697 |
| rollout/                 |            |
|    ep_len_mean           | 1e+03      |
|    ep_rew_mean           | -1.32e+03  |
| time/                    |            |
|    fps                   | 66         |
|    iterations            | 33         |
|    time_elapsed          | 1022       |
|    total_timesteps       | 67584      |
| train/                   |            |
|    approx_kl             | 0.00428278 |
|    clip_fraction         | 0.0387     |
|    clip_range            | 0.2        |
|    cost_returns          | 0.741      |
|    cost_value_loss       | 0.0253     |
|    cost_values           | 0.884      |
|    entropy               | -2.97      |
|    entropy_loss          | -2.96      |
|    explained_variance    | 0.00726    |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 390        |
|    n_updates             | 320        |
|    policy_gradient_loss  | -0.00479   |
|    std                   | 1.07       |
|    value_loss            | 797        |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.163       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.163       |
| reward                   | -0.6862879  |
| rollout/                 |             |
|    ep_len_mean           | 1e+03       |
|    ep_rew_mean           | -1.33e+03   |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 34          |
|    time_elapsed          | 1053        |
|    total_timesteps       | 69632       |
| train/                   |             |
|    approx_kl             | 0.004070018 |
|    clip_fraction         | 0.0313      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.692       |
|    cost_value_loss       | 0.0254      |
|    cost_values           | 0.836       |
|    entropy               | -2.97       |
|    entropy_loss          | -2.97       |
|    explained_variance    | 0.0595      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 460         |
|    n_updates             | 330         |
|    policy_gradient_loss  | -0.00507    |
|    std                   | 1.07        |
|    value_loss            | 981         |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.95         |
| reward                   | -1.8838984   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.32e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 35           |
|    time_elapsed          | 1083         |
|    total_timesteps       | 71680        |
| train/                   |              |
|    approx_kl             | 0.0036222318 |
|    clip_fraction         | 0.00654      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.671        |
|    cost_value_loss       | 0.0181       |
|    cost_values           | 0.788        |
|    entropy               | -2.96        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.0129       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 265          |
|    n_updates             | 340          |
|    policy_gradient_loss  | -0.00243     |
|    std                   | 1.06         |
|    value_loss            | 538          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.3          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.3          |
| reward                   | -1.7997602   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.32e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 36           |
|    time_elapsed          | 1113         |
|    total_timesteps       | 73728        |
| train/                   |              |
|    approx_kl             | 0.0059090746 |
|    clip_fraction         | 0.0441       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.682        |
|    cost_value_loss       | 0.235        |
|    cost_values           | 0.735        |
|    entropy               | -2.96        |
|    entropy_loss          | -2.96        |
|    explained_variance    | -0.0793      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 158          |
|    n_updates             | 350          |
|    policy_gradient_loss  | -0.00491     |
|    std                   | 1.06         |
|    value_loss            | 327          |
-------------------------------------------
-----------------------------------------
| avg_speed                | 5.76       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 5.76       |
| reward                   | -2.8045616 |
| rollout/                 |            |
|    ep_len_mean           | 990        |
|    ep_rew_mean           | -1.31e+03  |
| time/                    |            |
|    fps                   | 66         |
|    iterations            | 37         |
|    time_elapsed          | 1143       |
|    total_timesteps       | 75776      |
| train/                   |            |
|    approx_kl             | 0.00584547 |
|    clip_fraction         | 0.027      |
|    clip_range            | 0.2        |
|    cost_returns          | 0.59       |
|    cost_value_loss       | 0.015      |
|    cost_values           | 0.699      |
|    entropy               | -2.96      |
|    entropy_loss          | -2.96      |
|    explained_variance    | -0.0188    |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 224        |
|    n_updates             | 360        |
|    policy_gradient_loss  | -0.00356   |
|    std                   | 1.06       |
|    value_loss            | 467        |
-----------------------------------------
-------------------------------------------
| avg_speed                | 3.44         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.44         |
| reward                   | -1.4342277   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.32e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 38           |
|    time_elapsed          | 1173         |
|    total_timesteps       | 77824        |
| train/                   |              |
|    approx_kl             | 0.0032723893 |
|    clip_fraction         | 0.0227       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.655        |
|    cost_value_loss       | 0.328        |
|    cost_values           | 0.665        |
|    entropy               | -2.97        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.00213      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 148          |
|    n_updates             | 370          |
|    policy_gradient_loss  | -0.00404     |
|    std                   | 1.07         |
|    value_loss            | 327          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -1.7038206   |
| rollout/                 |              |
|    ep_len_mean           | 990          |
|    ep_rew_mean           | -1.33e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 39           |
|    time_elapsed          | 1204         |
|    total_timesteps       | 79872        |
| train/                   |              |
|    approx_kl             | 0.0057839737 |
|    clip_fraction         | 0.0413       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.623        |
|    cost_value_loss       | 0.221        |
|    cost_values           | 0.654        |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.0165       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 264          |
|    n_updates             | 380          |
|    policy_gradient_loss  | -0.00625     |
|    std                   | 1.07         |
|    value_loss            | 545          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.05         |
| reward                   | -2.3329947   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.34e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 40           |
|    time_elapsed          | 1235         |
|    total_timesteps       | 81920        |
| train/                   |              |
|    approx_kl             | 0.0042223753 |
|    clip_fraction         | 0.0222       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.554        |
|    cost_value_loss       | 0.0443       |
|    cost_values           | 0.631        |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.00793      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 248          |
|    n_updates             | 390          |
|    policy_gradient_loss  | -0.00316     |
|    std                   | 1.07         |
|    value_loss            | 521          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -2.7827208   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.34e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 41           |
|    time_elapsed          | 1267         |
|    total_timesteps       | 83968        |
| train/                   |              |
|    approx_kl             | 0.0052669896 |
|    clip_fraction         | 0.036        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.558        |
|    cost_value_loss       | 0.183        |
|    cost_values           | 0.602        |
|    entropy               | -2.98        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.00482      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 567          |
|    n_updates             | 400          |
|    policy_gradient_loss  | -0.00414     |
|    std                   | 1.07         |
|    value_loss            | 1.19e+03     |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.1          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.1          |
| reward                   | -1.8298134   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.36e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 42           |
|    time_elapsed          | 1299         |
|    total_timesteps       | 86016        |
| train/                   |              |
|    approx_kl             | 0.0036021546 |
|    clip_fraction         | 0.0117       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.741        |
|    cost_value_loss       | 2.32         |
|    cost_values           | 0.613        |
|    entropy               | -2.97        |
|    entropy_loss          | -2.98        |
|    explained_variance    | 0.00558      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 302          |
|    n_updates             | 410          |
|    policy_gradient_loss  | -0.00225     |
|    std                   | 1.07         |
|    value_loss            | 591          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.68         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.68         |
| reward                   | -2.3605516   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.36e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 43           |
|    time_elapsed          | 1331         |
|    total_timesteps       | 88064        |
| train/                   |              |
|    approx_kl             | 0.0067701014 |
|    clip_fraction         | 0.0404       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.56         |
|    cost_value_loss       | 0.0606       |
|    cost_values           | 0.638        |
|    entropy               | -2.98        |
|    entropy_loss          | -2.98        |
|    explained_variance    | -0.000131    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 216          |
|    n_updates             | 420          |
|    policy_gradient_loss  | -0.00622     |
|    std                   | 1.07         |
|    value_loss            | 458          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.81         |
| reward                   | -2.3881443   |
| rollout/                 |              |
|    ep_len_mean           | 991          |
|    ep_rew_mean           | -1.37e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 44           |
|    time_elapsed          | 1361         |
|    total_timesteps       | 90112        |
| train/                   |              |
|    approx_kl             | 0.0039592045 |
|    clip_fraction         | 0.0325       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.574        |
|    cost_value_loss       | 0.223        |
|    cost_values           | 0.607        |
|    entropy               | -2.98        |
|    entropy_loss          | -2.98        |
|    explained_variance    | 0.00696      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 230          |
|    n_updates             | 430          |
|    policy_gradient_loss  | -0.00373     |
|    std                   | 1.07         |
|    value_loss            | 486          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.31         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.31         |
| reward                   | -2.3802445   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.37e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 45           |
|    time_elapsed          | 1391         |
|    total_timesteps       | 92160        |
| train/                   |              |
|    approx_kl             | 0.0044616787 |
|    clip_fraction         | 0.0312       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.716        |
|    cost_value_loss       | 0.726        |
|    cost_values           | 0.605        |
|    entropy               | -2.99        |
|    entropy_loss          | -2.98        |
|    explained_variance    | -0.16        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 204          |
|    n_updates             | 440          |
|    policy_gradient_loss  | -0.00298     |
|    std                   | 1.08         |
|    value_loss            | 449          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.712        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.712        |
| reward                   | -1.9560751   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.38e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 46           |
|    time_elapsed          | 1421         |
|    total_timesteps       | 94208        |
| train/                   |              |
|    approx_kl             | 0.0055119535 |
|    clip_fraction         | 0.0421       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.591        |
|    cost_value_loss       | 0.165        |
|    cost_values           | 0.635        |
|    entropy               | -3           |
|    entropy_loss          | -2.99        |
|    explained_variance    | 0.000131     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 300          |
|    n_updates             | 450          |
|    policy_gradient_loss  | -0.00356     |
|    std                   | 1.08         |
|    value_loss            | 609          |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.366       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.366       |
| reward                   | -0.89426905 |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -1.38e+03   |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 47          |
|    time_elapsed          | 1452        |
|    total_timesteps       | 96256       |
| train/                   |             |
|    approx_kl             | 0.004216707 |
|    clip_fraction         | 0.0519      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.678       |
|    cost_value_loss       | 0.557       |
|    cost_values           | 0.634       |
|    entropy               | -3          |
|    entropy_loss          | -3          |
|    explained_variance    | -0.000991   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 194         |
|    n_updates             | 460         |
|    policy_gradient_loss  | -0.00522    |
|    std                   | 1.09        |
|    value_loss            | 392         |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.09         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.09         |
| reward                   | -0.834645    |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.39e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 48           |
|    time_elapsed          | 1483         |
|    total_timesteps       | 98304        |
| train/                   |              |
|    approx_kl             | 0.0060030855 |
|    clip_fraction         | 0.0423       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.525        |
|    cost_value_loss       | 0.0153       |
|    cost_values           | 0.632        |
|    entropy               | -3           |
|    entropy_loss          | -3           |
|    explained_variance    | -0.0836      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 182          |
|    n_updates             | 470          |
|    policy_gradient_loss  | -0.00379     |
|    std                   | 1.09         |
|    value_loss            | 391          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.05         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 4.05         |
| reward                   | -0.43018952  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.4e+03     |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 49           |
|    time_elapsed          | 1514         |
|    total_timesteps       | 100352       |
| train/                   |              |
|    approx_kl             | 0.0039329985 |
|    clip_fraction         | 0.036        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.65         |
|    cost_value_loss       | 0.564        |
|    cost_values           | 0.604        |
|    entropy               | -3           |
|    entropy_loss          | -3           |
|    explained_variance    | 0.00496      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 240          |
|    n_updates             | 480          |
|    policy_gradient_loss  | -0.00439     |
|    std                   | 1.08         |
|    value_loss            | 502          |
-------------------------------------------
Directory created: tests/PPOL_New/models/ent-coefficient-ppol/vlorgroe
-----------------------------------
| avg_speed          | 2.6        |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 2.6        |
| reward             | -1.0056413 |
| rollout/           |            |
|    ep_len_mean     | 992        |
|    ep_rew_mean     | -1.39e+03  |
| time/              |            |
|    fps             | 71         |
|    iterations      | 1          |
|    time_elapsed    | 28         |
|    total_timesteps | 102400     |
-----------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.81         |
| reward                   | -0.9368837   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.39e+03    |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 2            |
|    time_elapsed          | 58           |
|    total_timesteps       | 104448       |
| train/                   |              |
|    approx_kl             | 0.0049411133 |
|    clip_fraction         | 0.0366       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.594        |
|    cost_value_loss       | 0.37         |
|    cost_values           | 0.59         |
|    entropy               | -3.01        |
|    entropy_loss          | -3           |
|    explained_variance    | 0.00303      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 207          |
|    n_updates             | 500          |
|    policy_gradient_loss  | -0.0046      |
|    std                   | 1.09         |
|    value_loss            | 421          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.16         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.16         |
| reward                   | -0.7823348   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.4e+03     |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 3            |
|    time_elapsed          | 89           |
|    total_timesteps       | 106496       |
| train/                   |              |
|    approx_kl             | 0.0041642897 |
|    clip_fraction         | 0.0284       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.496        |
|    cost_value_loss       | 0.0234       |
|    cost_values           | 0.571        |
|    entropy               | -3.01        |
|    entropy_loss          | -3.01        |
|    explained_variance    | 3.93e-06     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 182          |
|    n_updates             | 510          |
|    policy_gradient_loss  | -0.00326     |
|    std                   | 1.09         |
|    value_loss            | 387          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.27         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.27         |
| reward                   | -1.4076478   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.4e+03     |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 4            |
|    time_elapsed          | 119          |
|    total_timesteps       | 108544       |
| train/                   |              |
|    approx_kl             | 0.0057532084 |
|    clip_fraction         | 0.0309       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.537        |
|    cost_value_loss       | 0.308        |
|    cost_values           | 0.537        |
|    entropy               | -3.01        |
|    entropy_loss          | -3.01        |
|    explained_variance    | -0.0096      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 127          |
|    n_updates             | 520          |
|    policy_gradient_loss  | -0.00407     |
|    std                   | 1.09         |
|    value_loss            | 251          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.91         |
| reward                   | -1.0740283   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.41e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 5            |
|    time_elapsed          | 150          |
|    total_timesteps       | 110592       |
| train/                   |              |
|    approx_kl             | 0.0038829113 |
|    clip_fraction         | 0.028        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.52         |
|    cost_value_loss       | 0.185        |
|    cost_values           | 0.53         |
|    entropy               | -3.01        |
|    entropy_loss          | -3.01        |
|    explained_variance    | 0.00239      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 81.5         |
|    n_updates             | 530          |
|    policy_gradient_loss  | -0.00307     |
|    std                   | 1.09         |
|    value_loss            | 171          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.96         |
| reward                   | -1.6316543   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.4e+03     |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 6            |
|    time_elapsed          | 182          |
|    total_timesteps       | 112640       |
| train/                   |              |
|    approx_kl             | 0.0039801477 |
|    clip_fraction         | 0.0358       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.446        |
|    cost_value_loss       | 0.0157       |
|    cost_values           | 0.501        |
|    entropy               | -3           |
|    entropy_loss          | -3.01        |
|    explained_variance    | -0.00234     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 130          |
|    n_updates             | 540          |
|    policy_gradient_loss  | -0.00384     |
|    std                   | 1.09         |
|    value_loss            | 269          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.17         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.17         |
| reward                   | -0.7232401   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.41e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 7            |
|    time_elapsed          | 214          |
|    total_timesteps       | 114688       |
| train/                   |              |
|    approx_kl             | 0.0051368373 |
|    clip_fraction         | 0.0458       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.512        |
|    cost_value_loss       | 0.367        |
|    cost_values           | 0.483        |
|    entropy               | -3           |
|    entropy_loss          | -3           |
|    explained_variance    | 0.00763      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 71.3         |
|    n_updates             | 550          |
|    policy_gradient_loss  | -0.00423     |
|    std                   | 1.08         |
|    value_loss            | 145          |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.49        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.49        |
| reward                   | -0.9750249  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -1.41e+03   |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 8           |
|    time_elapsed          | 245         |
|    total_timesteps       | 116736      |
| train/                   |             |
|    approx_kl             | 0.004898123 |
|    clip_fraction         | 0.0352      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.623       |
|    cost_value_loss       | 1.03        |
|    cost_values           | 0.539       |
|    entropy               | -3          |
|    entropy_loss          | -3          |
|    explained_variance    | -0.0233     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 134         |
|    n_updates             | 560         |
|    policy_gradient_loss  | -0.0045     |
|    std                   | 1.08        |
|    value_loss            | 287         |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.59         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.59         |
| reward                   | -1.2083795   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.41e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 9            |
|    time_elapsed          | 276          |
|    total_timesteps       | 118784       |
| train/                   |              |
|    approx_kl             | 0.0063707093 |
|    clip_fraction         | 0.0645       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.593        |
|    cost_value_loss       | 0.24         |
|    cost_values           | 0.595        |
|    entropy               | -3.02        |
|    entropy_loss          | -3.01        |
|    explained_variance    | 0.000337     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 38.9         |
|    n_updates             | 570          |
|    policy_gradient_loss  | -0.00601     |
|    std                   | 1.09         |
|    value_loss            | 84           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.99         |
| reward                   | -1.5069865   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.41e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 10           |
|    time_elapsed          | 306          |
|    total_timesteps       | 120832       |
| train/                   |              |
|    approx_kl             | 0.0050043366 |
|    clip_fraction         | 0.0371       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.8          |
|    cost_value_loss       | 1.22         |
|    cost_values           | 0.683        |
|    entropy               | -3.02        |
|    entropy_loss          | -3.02        |
|    explained_variance    | -0.00483     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 49.5         |
|    n_updates             | 580          |
|    policy_gradient_loss  | -0.00532     |
|    std                   | 1.1          |
|    value_loss            | 104          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.12         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.12         |
| reward                   | -1.2315845   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.42e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 11           |
|    time_elapsed          | 337          |
|    total_timesteps       | 122880       |
| train/                   |              |
|    approx_kl             | 0.0042382823 |
|    clip_fraction         | 0.0473       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.931        |
|    cost_value_loss       | 0.779        |
|    cost_values           | 0.856        |
|    entropy               | -3.02        |
|    entropy_loss          | -3.02        |
|    explained_variance    | 0.00321      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 62.1         |
|    n_updates             | 590          |
|    policy_gradient_loss  | -0.00649     |
|    std                   | 1.09         |
|    value_loss            | 125          |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.84        |
| reward                   | -1.0361391  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -1.42e+03   |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 12          |
|    time_elapsed          | 368         |
|    total_timesteps       | 124928      |
| train/                   |             |
|    approx_kl             | 0.002882858 |
|    clip_fraction         | 0.0199      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.796       |
|    cost_value_loss       | 0.106       |
|    cost_values           | 0.887       |
|    entropy               | -3.01       |
|    entropy_loss          | -3.01       |
|    explained_variance    | -0.0044     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 110         |
|    n_updates             | 600         |
|    policy_gradient_loss  | -0.00286    |
|    std                   | 1.09        |
|    value_loss            | 227         |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.41         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.41         |
| reward                   | -1.7466049   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.41e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 13           |
|    time_elapsed          | 398          |
|    total_timesteps       | 126976       |
| train/                   |              |
|    approx_kl             | 0.0062689246 |
|    clip_fraction         | 0.0624       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.784        |
|    cost_value_loss       | 0.335        |
|    cost_values           | 0.8          |
|    entropy               | -3.01        |
|    entropy_loss          | -3.01        |
|    explained_variance    | -0.00313     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 24.6         |
|    n_updates             | 610          |
|    policy_gradient_loss  | -0.00637     |
|    std                   | 1.09         |
|    value_loss            | 53.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.58        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.58        |
| reward                   | -2.4009714  |
| rollout/                 |             |
|    ep_len_mean           | 992         |
|    ep_rew_mean           | -1.41e+03   |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 14          |
|    time_elapsed          | 428         |
|    total_timesteps       | 129024      |
| train/                   |             |
|    approx_kl             | 0.006157582 |
|    clip_fraction         | 0.0529      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.663       |
|    cost_value_loss       | 0.0448      |
|    cost_values           | 0.728       |
|    entropy               | -3.02       |
|    entropy_loss          | -3.01       |
|    explained_variance    | 0.00176     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 62          |
|    n_updates             | 620         |
|    policy_gradient_loss  | -0.00634    |
|    std                   | 1.09        |
|    value_loss            | 126         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.44         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.44         |
| reward                   | -0.59603196  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.4e+03     |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 15           |
|    time_elapsed          | 458          |
|    total_timesteps       | 131072       |
| train/                   |              |
|    approx_kl             | 0.0051971544 |
|    clip_fraction         | 0.0479       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.649        |
|    cost_value_loss       | 0.222        |
|    cost_values           | 0.658        |
|    entropy               | -3.04        |
|    entropy_loss          | -3.03        |
|    explained_variance    | -0.00991     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 103          |
|    n_updates             | 630          |
|    policy_gradient_loss  | -0.00706     |
|    std                   | 1.1          |
|    value_loss            | 226          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.84         |
| reward                   | -1.3232883   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.39e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 16           |
|    time_elapsed          | 489          |
|    total_timesteps       | 133120       |
| train/                   |              |
|    approx_kl             | 0.0035942984 |
|    clip_fraction         | 0.0294       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.63         |
|    cost_value_loss       | 0.346        |
|    cost_values           | 0.641        |
|    entropy               | -3.05        |
|    entropy_loss          | -3.04        |
|    explained_variance    | -0.00477     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 84.6         |
|    n_updates             | 640          |
|    policy_gradient_loss  | -0.00487     |
|    std                   | 1.11         |
|    value_loss            | 187          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.48         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.48         |
| reward                   | -1.5434691   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.38e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 17           |
|    time_elapsed          | 520          |
|    total_timesteps       | 135168       |
| train/                   |              |
|    approx_kl             | 0.0042693987 |
|    clip_fraction         | 0.0351       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.552        |
|    cost_value_loss       | 0.0448       |
|    cost_values           | 0.607        |
|    entropy               | -3.05        |
|    entropy_loss          | -3.05        |
|    explained_variance    | 0.0012       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 186          |
|    n_updates             | 650          |
|    policy_gradient_loss  | -0.00519     |
|    std                   | 1.11         |
|    value_loss            | 357          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.94         |
| reward                   | -1.2254374   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.38e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 18           |
|    time_elapsed          | 550          |
|    total_timesteps       | 137216       |
| train/                   |              |
|    approx_kl             | 0.0050454587 |
|    clip_fraction         | 0.0375       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.619        |
|    cost_value_loss       | 0.48         |
|    cost_values           | 0.583        |
|    entropy               | -3.05        |
|    entropy_loss          | -3.05        |
|    explained_variance    | -0.0841      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 154          |
|    n_updates             | 660          |
|    policy_gradient_loss  | -0.00545     |
|    std                   | 1.11         |
|    value_loss            | 325          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.2101562  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -1.36e+03   |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 19          |
|    time_elapsed          | 580         |
|    total_timesteps       | 139264      |
| train/                   |             |
|    approx_kl             | 0.007549823 |
|    clip_fraction         | 0.0535      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.492       |
|    cost_value_loss       | 0.00626     |
|    cost_values           | 0.544       |
|    entropy               | -3.06       |
|    entropy_loss          | -3.05       |
|    explained_variance    | -0.00346    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 47          |
|    n_updates             | 670         |
|    policy_gradient_loss  | -0.00569    |
|    std                   | 1.12        |
|    value_loss            | 99.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.78        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.78        |
| reward                   | -1.3386065  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.35e+03   |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 20          |
|    time_elapsed          | 612         |
|    total_timesteps       | 141312      |
| train/                   |             |
|    approx_kl             | 0.005208873 |
|    clip_fraction         | 0.0361      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.464       |
|    cost_value_loss       | 0.222       |
|    cost_values           | 0.47        |
|    entropy               | -3.07       |
|    entropy_loss          | -3.06       |
|    explained_variance    | -0.000475   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 39.5        |
|    n_updates             | 680         |
|    policy_gradient_loss  | -0.00405    |
|    std                   | 1.12        |
|    value_loss            | 83.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.41        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.41        |
| reward                   | -0.83181113 |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.35e+03   |
| time/                    |             |
|    fps                   | 66          |
|    iterations            | 21          |
|    time_elapsed          | 643         |
|    total_timesteps       | 143360      |
| train/                   |             |
|    approx_kl             | 0.006717417 |
|    clip_fraction         | 0.0706      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.12        |
|    cost_value_loss       | 8.1         |
|    cost_values           | 0.8         |
|    entropy               | -3.08       |
|    entropy_loss          | -3.07       |
|    explained_variance    | -0.000189   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 56          |
|    n_updates             | 690         |
|    policy_gradient_loss  | -0.0035     |
|    std                   | 1.13        |
|    value_loss            | 101         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.78         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.78         |
| reward                   | -1.4543693   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.35e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 22           |
|    time_elapsed          | 673          |
|    total_timesteps       | 145408       |
| train/                   |              |
|    approx_kl             | 0.0043082214 |
|    clip_fraction         | 0.0459       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.01         |
|    cost_value_loss       | 1.04         |
|    cost_values           | 0.934        |
|    entropy               | -3.08        |
|    entropy_loss          | -3.08        |
|    explained_variance    | -0.00331     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 71.2         |
|    n_updates             | 700          |
|    policy_gradient_loss  | -0.00384     |
|    std                   | 1.13         |
|    value_loss            | 164          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.92031044  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.36e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 23           |
|    time_elapsed          | 704          |
|    total_timesteps       | 147456       |
| train/                   |              |
|    approx_kl             | 0.0066102063 |
|    clip_fraction         | 0.0514       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.837        |
|    cost_value_loss       | 0.0551       |
|    cost_values           | 0.925        |
|    entropy               | -3.09        |
|    entropy_loss          | -3.08        |
|    explained_variance    | -0.00694     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 40.6         |
|    n_updates             | 710          |
|    policy_gradient_loss  | -0.00586     |
|    std                   | 1.13         |
|    value_loss            | 88.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.13         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.13         |
| reward                   | -1.3942667   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.36e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 24           |
|    time_elapsed          | 736          |
|    total_timesteps       | 149504       |
| train/                   |              |
|    approx_kl             | 0.0045723976 |
|    clip_fraction         | 0.0454       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.726        |
|    cost_value_loss       | 0.0412       |
|    cost_values           | 0.799        |
|    entropy               | -3.08        |
|    entropy_loss          | -3.08        |
|    explained_variance    | 0.00137      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 79           |
|    n_updates             | 720          |
|    policy_gradient_loss  | -0.00461     |
|    std                   | 1.13         |
|    value_loss            | 169          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.85         |
| reward                   | -0.83233094  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.36e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 25           |
|    time_elapsed          | 767          |
|    total_timesteps       | 151552       |
| train/                   |              |
|    approx_kl             | 0.0034165527 |
|    clip_fraction         | 0.0296       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.789        |
|    cost_value_loss       | 0.757        |
|    cost_values           | 0.756        |
|    entropy               | -3.07        |
|    entropy_loss          | -3.08        |
|    explained_variance    | -4.65e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 80.1         |
|    n_updates             | 730          |
|    policy_gradient_loss  | -0.00407     |
|    std                   | 1.12         |
|    value_loss            | 176          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.05         |
| reward                   | -0.94276386  |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.36e+03    |
| time/                    |              |
|    fps                   | 66           |
|    iterations            | 26           |
|    time_elapsed          | 798          |
|    total_timesteps       | 153600       |
| train/                   |              |
|    approx_kl             | 0.0069973078 |
|    clip_fraction         | 0.0604       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.75         |
|    cost_value_loss       | 0.629        |
|    cost_values           | 0.767        |
|    entropy               | -3.08        |
|    entropy_loss          | -3.08        |
|    explained_variance    | 0.00192      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 60.7         |
|    n_updates             | 740          |
|    policy_gradient_loss  | -0.00645     |
|    std                   | 1.13         |
|    value_loss            | 125          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.69         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.69         |
| reward                   | -0.5907066   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.36e+03    |
| time/                    |              |
|    fps                   | 67           |
|    iterations            | 27           |
|    time_elapsed          | 823          |
|    total_timesteps       | 155648       |
| train/                   |              |
|    approx_kl             | 0.0051705977 |
|    clip_fraction         | 0.0456       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.708        |
|    cost_value_loss       | 0.412        |
|    cost_values           | 0.722        |
|    entropy               | -3.08        |
|    entropy_loss          | -3.08        |
|    explained_variance    | -0.00478     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 21.5         |
|    n_updates             | 750          |
|    policy_gradient_loss  | -0.00416     |
|    std                   | 1.13         |
|    value_loss            | 43.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.75        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.75        |
| reward                   | -1.4642028  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.34e+03   |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 28          |
|    time_elapsed          | 847         |
|    total_timesteps       | 157696      |
| train/                   |             |
|    approx_kl             | 0.006566929 |
|    clip_fraction         | 0.0599      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.887       |
|    cost_value_loss       | 1.49        |
|    cost_values           | 0.829       |
|    entropy               | -3.08       |
|    entropy_loss          | -3.08       |
|    explained_variance    | -0.0011     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 19.2        |
|    n_updates             | 760         |
|    policy_gradient_loss  | -0.00553    |
|    std                   | 1.13        |
|    value_loss            | 41.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.72         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.72         |
| reward                   | -1.6729373   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.35e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 29           |
|    time_elapsed          | 870          |
|    total_timesteps       | 159744       |
| train/                   |              |
|    approx_kl             | 0.0049161557 |
|    clip_fraction         | 0.0387       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.15         |
|    cost_value_loss       | 1.12         |
|    cost_values           | 0.943        |
|    entropy               | -3.07        |
|    entropy_loss          | -3.08        |
|    explained_variance    | 0.000999     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 28.8         |
|    n_updates             | 770          |
|    policy_gradient_loss  | -0.00523     |
|    std                   | 1.12         |
|    value_loss            | 62.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.12         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.12         |
| reward                   | -1.4178559   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.34e+03    |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 30           |
|    time_elapsed          | 893          |
|    total_timesteps       | 161792       |
| train/                   |              |
|    approx_kl             | 0.0051093353 |
|    clip_fraction         | 0.0513       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.966        |
|    cost_value_loss       | 0.631        |
|    cost_values           | 0.884        |
|    entropy               | -3.07        |
|    entropy_loss          | -3.07        |
|    explained_variance    | -0.00493     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 56.2         |
|    n_updates             | 780          |
|    policy_gradient_loss  | -0.00519     |
|    std                   | 1.13         |
|    value_loss            | 123          |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.38        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.38        |
| reward                   | -1.3435366  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.32e+03   |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 31          |
|    time_elapsed          | 916         |
|    total_timesteps       | 163840      |
| train/                   |             |
|    approx_kl             | 0.004583556 |
|    clip_fraction         | 0.0452      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.746       |
|    cost_value_loss       | 0.0722      |
|    cost_values           | 0.834       |
|    entropy               | -3.07       |
|    entropy_loss          | -3.07       |
|    explained_variance    | -0.000669   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 43.7        |
|    n_updates             | 790         |
|    policy_gradient_loss  | -0.00444    |
|    std                   | 1.12        |
|    value_loss            | 95.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.4229977   |
| rollout/                 |              |
|    ep_len_mean           | 981          |
|    ep_rew_mean           | -1.3e+03     |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 32           |
|    time_elapsed          | 939          |
|    total_timesteps       | 165888       |
| train/                   |              |
|    approx_kl             | 0.0050313314 |
|    clip_fraction         | 0.0448       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.05         |
|    cost_value_loss       | 2.2          |
|    cost_values           | 0.893        |
|    entropy               | -3.07        |
|    entropy_loss          | -3.07        |
|    explained_variance    | -0.000408    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 26.1         |
|    n_updates             | 800          |
|    policy_gradient_loss  | -0.00559     |
|    std                   | 1.12         |
|    value_loss            | 54.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -2.6076283  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.29e+03   |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 33          |
|    time_elapsed          | 962         |
|    total_timesteps       | 167936      |
| train/                   |             |
|    approx_kl             | 0.005760285 |
|    clip_fraction         | 0.0527      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.25        |
|    cost_value_loss       | 2.6         |
|    cost_values           | 0.959       |
|    entropy               | -3.08       |
|    entropy_loss          | -3.07       |
|    explained_variance    | 0.000117    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 23.2        |
|    n_updates             | 810         |
|    policy_gradient_loss  | -0.00655    |
|    std                   | 1.13        |
|    value_loss            | 45.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -1.2413505  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.3e+03    |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 34          |
|    time_elapsed          | 985         |
|    total_timesteps       | 169984      |
| train/                   |             |
|    approx_kl             | 0.004774052 |
|    clip_fraction         | 0.0393      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.904       |
|    cost_value_loss       | 0.604       |
|    cost_values           | 0.943       |
|    entropy               | -3.08       |
|    entropy_loss          | -3.08       |
|    explained_variance    | -0.000151   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 105         |
|    n_updates             | 820         |
|    policy_gradient_loss  | -0.00446    |
|    std                   | 1.13        |
|    value_loss            | 217         |
------------------------------------------
-----------------------------------------
| avg_speed                | 6.72       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 6.72       |
| reward                   | -1.3425287 |
| rollout/                 |            |
|    ep_len_mean           | 981        |
|    ep_rew_mean           | -1.29e+03  |
| time/                    |            |
|    fps                   | 71         |
|    iterations            | 35         |
|    time_elapsed          | 1008       |
|    total_timesteps       | 172032     |
| train/                   |            |
|    approx_kl             | 0.00404644 |
|    clip_fraction         | 0.034      |
|    clip_range            | 0.2        |
|    cost_returns          | 1.18       |
|    cost_value_loss       | 3.04       |
|    cost_values           | 0.949      |
|    entropy               | -3.09      |
|    entropy_loss          | -3.08      |
|    explained_variance    | -0.000234  |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 53.8       |
|    n_updates             | 830        |
|    policy_gradient_loss  | -0.00465   |
|    std                   | 1.13       |
|    value_loss            | 117        |
-----------------------------------------
------------------------------------------
| avg_speed                | 3.86        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.86        |
| reward                   | -1.3179003  |
| rollout/                 |             |
|    ep_len_mean           | 981         |
|    ep_rew_mean           | -1.28e+03   |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 36          |
|    time_elapsed          | 1031        |
|    total_timesteps       | 174080      |
| train/                   |             |
|    approx_kl             | 0.007301037 |
|    clip_fraction         | 0.0607      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.03        |
|    cost_value_loss       | 0.953       |
|    cost_values           | 0.965       |
|    entropy               | -3.08       |
|    entropy_loss          | -3.08       |
|    explained_variance    | -8.51e-05   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 27.4        |
|    n_updates             | 840         |
|    policy_gradient_loss  | -0.0081     |
|    std                   | 1.13        |
|    value_loss            | 57.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.77        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.77        |
| reward                   | -1.2682867  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -1.28e+03   |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 37          |
|    time_elapsed          | 1054        |
|    total_timesteps       | 176128      |
| train/                   |             |
|    approx_kl             | 0.005470099 |
|    clip_fraction         | 0.055       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.02        |
|    cost_value_loss       | 0.731       |
|    cost_values           | 0.958       |
|    entropy               | -3.08       |
|    entropy_loss          | -3.08       |
|    explained_variance    | -0.000446   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.7        |
|    n_updates             | 850         |
|    policy_gradient_loss  | -0.00542    |
|    std                   | 1.13        |
|    value_loss            | 22.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.596       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.596       |
| reward                   | -0.7540253  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -1.26e+03   |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 38          |
|    time_elapsed          | 1077        |
|    total_timesteps       | 178176      |
| train/                   |             |
|    approx_kl             | 0.006249422 |
|    clip_fraction         | 0.0726      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.87        |
|    cost_value_loss       | 7.24        |
|    cost_values           | 1.03        |
|    entropy               | -3.09       |
|    entropy_loss          | -3.08       |
|    explained_variance    | -0.000528   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 35.6        |
|    n_updates             | 860         |
|    policy_gradient_loss  | -0.00844    |
|    std                   | 1.14        |
|    value_loss            | 69.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.3         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.3         |
| reward                   | -0.5277637  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -1.24e+03   |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 39          |
|    time_elapsed          | 1100        |
|    total_timesteps       | 180224      |
| train/                   |             |
|    approx_kl             | 0.006612464 |
|    clip_fraction         | 0.0704      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.37        |
|    cost_value_loss       | 2.49        |
|    cost_values           | 0.992       |
|    entropy               | -3.08       |
|    entropy_loss          | -3.09       |
|    explained_variance    | -0.00037    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 24.3        |
|    n_updates             | 870         |
|    policy_gradient_loss  | -0.0075     |
|    std                   | 1.13        |
|    value_loss            | 49.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.574        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.574        |
| reward                   | -0.84779865  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -1.24e+03    |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 40           |
|    time_elapsed          | 1123         |
|    total_timesteps       | 182272       |
| train/                   |              |
|    approx_kl             | 0.0056709675 |
|    clip_fraction         | 0.0481       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.1          |
|    cost_value_loss       | 0.99         |
|    cost_values           | 0.972        |
|    entropy               | -3.08        |
|    entropy_loss          | -3.08        |
|    explained_variance    | -7.68e-05    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 28.2         |
|    n_updates             | 880          |
|    policy_gradient_loss  | -0.00507     |
|    std                   | 1.13         |
|    value_loss            | 57.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.58        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.58        |
| reward                   | -0.69808847 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -1.22e+03   |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 41          |
|    time_elapsed          | 1146        |
|    total_timesteps       | 184320      |
| train/                   |             |
|    approx_kl             | 0.00455609  |
|    clip_fraction         | 0.0307      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.949       |
|    cost_value_loss       | 0.308       |
|    cost_values           | 0.992       |
|    entropy               | -3.07       |
|    entropy_loss          | -3.08       |
|    explained_variance    | -0.000109   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 32.5        |
|    n_updates             | 890         |
|    policy_gradient_loss  | -0.00488    |
|    std                   | 1.13        |
|    value_loss            | 65.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.9          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.9          |
| reward                   | -0.64003444  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -1.22e+03    |
| time/                    |              |
|    fps                   | 73           |
|    iterations            | 42           |
|    time_elapsed          | 1169         |
|    total_timesteps       | 186368       |
| train/                   |              |
|    approx_kl             | 0.0041034147 |
|    clip_fraction         | 0.0397       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.852        |
|    cost_value_loss       | 0.0863       |
|    cost_values           | 0.932        |
|    entropy               | -3.08        |
|    entropy_loss          | -3.07        |
|    explained_variance    | -7.8e-05     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 23.5         |
|    n_updates             | 900          |
|    policy_gradient_loss  | -0.00486     |
|    std                   | 1.13         |
|    value_loss            | 49.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.8          |
| reward                   | -0.64545214  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -1.2e+03     |
| time/                    |              |
|    fps                   | 73           |
|    iterations            | 43           |
|    time_elapsed          | 1192         |
|    total_timesteps       | 188416       |
| train/                   |              |
|    approx_kl             | 0.0055969437 |
|    clip_fraction         | 0.045        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.962        |
|    cost_value_loss       | 0.672        |
|    cost_values           | 0.898        |
|    entropy               | -3.08        |
|    entropy_loss          | -3.08        |
|    explained_variance    | 6.87e-05     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 35.7         |
|    n_updates             | 910          |
|    policy_gradient_loss  | -0.00563     |
|    std                   | 1.13         |
|    value_loss            | 68.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.32        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.32        |
| reward                   | -0.86184365 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -1.19e+03   |
| time/                    |             |
|    fps                   | 74          |
|    iterations            | 44          |
|    time_elapsed          | 1215        |
|    total_timesteps       | 190464      |
| train/                   |             |
|    approx_kl             | 0.004387965 |
|    clip_fraction         | 0.0657      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.14        |
|    cost_value_loss       | 10.7        |
|    cost_values           | 1.59        |
|    entropy               | -3.09       |
|    entropy_loss          | -3.09       |
|    explained_variance    | -0.000332   |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 18.5        |
|    n_updates             | 920         |
|    policy_gradient_loss  | -0.0053     |
|    std                   | 1.14        |
|    value_loss            | 26.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.9         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.9         |
| reward                   | -0.8481803  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -1.17e+03   |
| time/                    |             |
|    fps                   | 74          |
|    iterations            | 45          |
|    time_elapsed          | 1238        |
|    total_timesteps       | 192512      |
| train/                   |             |
|    approx_kl             | 0.009841933 |
|    clip_fraction         | 0.287       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.69        |
|    cost_value_loss       | 0.104       |
|    cost_values           | 1.72        |
|    entropy               | -3.1        |
|    entropy_loss          | -3.1        |
|    explained_variance    | -0.00012    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 27.8        |
|    n_updates             | 930         |
|    policy_gradient_loss  | 0.0178      |
|    std                   | 1.14        |
|    value_loss            | 58.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.96737546 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -1.16e+03   |
| time/                    |             |
|    fps                   | 74          |
|    iterations            | 46          |
|    time_elapsed          | 1260        |
|    total_timesteps       | 194560      |
| train/                   |             |
|    approx_kl             | 0.005358337 |
|    clip_fraction         | 0.0403      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.91        |
|    cost_value_loss       | 5.33        |
|    cost_values           | 1.26        |
|    entropy               | -3.1        |
|    entropy_loss          | -3.1        |
|    explained_variance    | -0.00134    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.5         |
|    n_updates             | 940         |
|    policy_gradient_loss  | -0.00571    |
|    std                   | 1.14        |
|    value_loss            | 6.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.35        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.35        |
| reward                   | -1.4580159  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -1.14e+03   |
| time/                    |             |
|    fps                   | 74          |
|    iterations            | 47          |
|    time_elapsed          | 1283        |
|    total_timesteps       | 196608      |
| train/                   |             |
|    approx_kl             | 0.007263164 |
|    clip_fraction         | 0.0695      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.34        |
|    cost_value_loss       | 0.554       |
|    cost_values           | 1.23        |
|    entropy               | -3.11       |
|    entropy_loss          | -3.11       |
|    explained_variance    | 0.000479    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.9        |
|    n_updates             | 950         |
|    policy_gradient_loss  | -0.00702    |
|    std                   | 1.15        |
|    value_loss            | 28          |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.46         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.46         |
| reward                   | -0.6618593   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -1.13e+03    |
| time/                    |              |
|    fps                   | 75           |
|    iterations            | 48           |
|    time_elapsed          | 1306         |
|    total_timesteps       | 198656       |
| train/                   |              |
|    approx_kl             | 0.0043098973 |
|    clip_fraction         | 0.0353       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.09         |
|    cost_value_loss       | 0.996        |
|    cost_values           | 0.972        |
|    entropy               | -3.12        |
|    entropy_loss          | -3.12        |
|    explained_variance    | -0.000511    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.39         |
|    n_updates             | 960          |
|    policy_gradient_loss  | -0.00388     |
|    std                   | 1.15         |
|    value_loss            | 20           |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.04        |
| reward                   | -1.2468354  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -1.12e+03   |
| time/                    |             |
|    fps                   | 75          |
|    iterations            | 49          |
|    time_elapsed          | 1330        |
|    total_timesteps       | 200704      |
| train/                   |             |
|    approx_kl             | 0.005847783 |
|    clip_fraction         | 0.0485      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.894       |
|    cost_value_loss       | 0.155       |
|    cost_values           | 0.982       |
|    entropy               | -3.12       |
|    entropy_loss          | -3.12       |
|    explained_variance    | -0.0015     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 68.4        |
|    n_updates             | 970         |
|    policy_gradient_loss  | -0.00624    |
|    std                   | 1.15        |
|    value_loss            | 130         |
------------------------------------------
-----------------------------------
| avg_speed          | 4.67       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 4.67       |
| reward             | -1.1141297 |
| rollout/           |            |
|    ep_len_mean     | 989        |
|    ep_rew_mean     | -1.11e+03  |
| time/              |            |
|    fps             | 90         |
|    iterations      | 1          |
|    time_elapsed    | 22         |
|    total_timesteps | 202752     |
-----------------------------------
-------------------------------------------
| avg_speed                | 3.31         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.31         |
| reward                   | -1.0784088   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 86           |
|    iterations            | 2            |
|    time_elapsed          | 47           |
|    total_timesteps       | 204800       |
| train/                   |              |
|    approx_kl             | 0.0043723024 |
|    clip_fraction         | 0.0332       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.04         |
|    cost_value_loss       | 0.779        |
|    cost_values           | 0.986        |
|    entropy               | -3.12        |
|    entropy_loss          | -3.12        |
|    explained_variance    | -0.000876    |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 60.9         |
|    n_updates             | 990          |
|    policy_gradient_loss  | -0.00477     |
|    std                   | 1.15         |
|    value_loss            | 119          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.42         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.42         |
| reward                   | -0.98148644  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -1.1e+03     |
| time/                    |              |
|    fps                   | 85           |
|    iterations            | 3            |
|    time_elapsed          | 71           |
|    total_timesteps       | 206848       |
| train/                   |              |
|    approx_kl             | 0.0031873665 |
|    clip_fraction         | 0.0268       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.04         |
|    cost_value_loss       | 0.613        |
|    cost_values           | 0.989        |
|    entropy               | -3.12        |
|    entropy_loss          | -3.12        |
|    explained_variance    | 0.000132     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 61.2         |
|    n_updates             | 1000         |
|    policy_gradient_loss  | -0.00559     |
|    std                   | 1.15         |
|    value_loss            | 116          |
-------------------------------------------
-----------------------------------------
| avg_speed                | 0.046      |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.046      |
| reward                   | -1.3677839 |
| rollout/                 |            |
|    ep_len_mean           | 989        |
|    ep_rew_mean           | -1.09e+03  |
| time/                    |            |
|    fps                   | 84         |
|    iterations            | 4          |
|    time_elapsed          | 97         |
|    total_timesteps       | 208896     |
| train/                   |            |
|    approx_kl             | 0.00522579 |
|    clip_fraction         | 0.0502     |
|    clip_range            | 0.2        |
|    cost_returns          | 0.938      |
|    cost_value_loss       | 0.354      |
|    cost_values           | 0.98       |
|    entropy               | -3.12      |
|    entropy_loss          | -3.12      |
|    explained_variance    | 0.00035    |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 7.13       |
|    n_updates             | 1010       |
|    policy_gradient_loss  | -0.00607   |
|    std                   | 1.15       |
|    value_loss            | 15.3       |
-----------------------------------------
-----------------------------------------
| avg_speed                | 6.63       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 6.63       |
| reward                   | -1.1698029 |
| rollout/                 |            |
|    ep_len_mean           | 989        |
|    ep_rew_mean           | -1.09e+03  |
| time/                    |            |
|    fps                   | 83         |
|    iterations            | 5          |
|    time_elapsed          | 122        |
|    total_timesteps       | 210944     |
| train/                   |            |
|    approx_kl             | 0.00488848 |
|    clip_fraction         | 0.0314     |
|    clip_range            | 0.2        |
|    cost_returns          | 0.888      |
|    cost_value_loss       | 0.249      |
|    cost_values           | 0.934      |
|    entropy               | -3.12      |
|    entropy_loss          | -3.12      |
|    explained_variance    | 0.000395   |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 45.8       |
|    n_updates             | 1020       |
|    policy_gradient_loss  | -0.0048    |
|    std                   | 1.15       |
|    value_loss            | 92.9       |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.6         |
| reward                   | -0.49648115 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -1.08e+03   |
| time/                    |             |
|    fps                   | 83          |
|    iterations            | 6           |
|    time_elapsed          | 146         |
|    total_timesteps       | 212992      |
| train/                   |             |
|    approx_kl             | 0.003549543 |
|    clip_fraction         | 0.0181      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.03        |
|    cost_value_loss       | 1.2         |
|    cost_values           | 0.941       |
|    entropy               | -3.13       |
|    entropy_loss          | -3.13       |
|    explained_variance    | 0.0009      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 25.7        |
|    n_updates             | 1030        |
|    policy_gradient_loss  | -0.00367    |
|    std                   | 1.16        |
|    value_loss            | 56.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.65        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.65        |
| reward                   | -1.4312729  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -1.08e+03   |
| time/                    |             |
|    fps                   | 82          |
|    iterations            | 7           |
|    time_elapsed          | 173         |
|    total_timesteps       | 215040      |
| train/                   |             |
|    approx_kl             | 0.008420929 |
|    clip_fraction         | 0.0599      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.826       |
|    cost_value_loss       | 0.0492      |
|    cost_values           | 0.888       |
|    entropy               | -3.12       |
|    entropy_loss          | -3.13       |
|    explained_variance    | 0.000802    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.79        |
|    n_updates             | 1040        |
|    policy_gradient_loss  | -0.00627    |
|    std                   | 1.15        |
|    value_loss            | 15.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.54        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.54        |
| reward                   | -1.5811425  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -1.08e+03   |
| time/                    |             |
|    fps                   | 81          |
|    iterations            | 8           |
|    time_elapsed          | 199         |
|    total_timesteps       | 217088      |
| train/                   |             |
|    approx_kl             | 0.004175019 |
|    clip_fraction         | 0.0505      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.696       |
|    cost_value_loss       | 0.0527      |
|    cost_values           | 0.79        |
|    entropy               | -3.12       |
|    entropy_loss          | -3.12       |
|    explained_variance    | 0.00102     |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 19.8        |
|    n_updates             | 1050        |
|    policy_gradient_loss  | -0.000171   |
|    std                   | 1.15        |
|    value_loss            | 42.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 4.57         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.57         |
| reward                   | -1.5837353   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -1.08e+03    |
| time/                    |              |
|    fps                   | 81           |
|    iterations            | 9            |
|    time_elapsed          | 225          |
|    total_timesteps       | 219136       |
| train/                   |              |
|    approx_kl             | 0.0052874405 |
|    clip_fraction         | 0.0437       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.711        |
|    cost_value_loss       | 0.246        |
|    cost_values           | 0.722        |
|    entropy               | -3.11        |
|    entropy_loss          | -3.12        |
|    explained_variance    | 0.00163      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.8         |
|    n_updates             | 1060         |
|    policy_gradient_loss  | -0.00556     |
|    std                   | 1.15         |
|    value_loss            | 29.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -1.138301    |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -1.08e+03    |
| time/                    |              |
|    fps                   | 81           |
|    iterations            | 10           |
|    time_elapsed          | 250          |
|    total_timesteps       | 221184       |
| train/                   |              |
|    approx_kl             | 0.0047410545 |
|    clip_fraction         | 0.111        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.756        |
|    cost_value_loss       | 0.354        |
|    cost_values           | 0.729        |
|    entropy               | -3.12        |
|    entropy_loss          | -3.12        |
|    explained_variance    | 0.000801     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.5         |
|    n_updates             | 1070         |
|    policy_gradient_loss  | 0.00231      |
|    std                   | 1.15         |
|    value_loss            | 30.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.769        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.769        |
| reward                   | -0.8135573   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -1.08e+03    |
| time/                    |              |
|    fps                   | 81           |
|    iterations            | 11           |
|    time_elapsed          | 275          |
|    total_timesteps       | 223232       |
| train/                   |              |
|    approx_kl             | 0.0025797214 |
|    clip_fraction         | 0.015        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.701        |
|    cost_value_loss       | 0.133        |
|    cost_values           | 0.729        |
|    entropy               | -3.13        |
|    entropy_loss          | -3.13        |
|    explained_variance    | 0.000348     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12           |
|    n_updates             | 1080         |
|    policy_gradient_loss  | -0.00273     |
|    std                   | 1.16         |
|    value_loss            | 24.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.62        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.62        |
| reward                   | -0.22914228 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -1.07e+03   |
| time/                    |             |
|    fps                   | 81          |
|    iterations            | 12          |
|    time_elapsed          | 300         |
|    total_timesteps       | 225280      |
| train/                   |             |
|    approx_kl             | 0.004060041 |
|    clip_fraction         | 0.0291      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.689       |
|    cost_value_loss       | 0.249       |
|    cost_values           | 0.696       |
|    entropy               | -3.13       |
|    entropy_loss          | -3.13       |
|    explained_variance    | 0.000585    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 21.2        |
|    n_updates             | 1090        |
|    policy_gradient_loss  | -0.00411    |
|    std                   | 1.16        |
|    value_loss            | 47.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.468        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.468        |
| reward                   | -0.88703924  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -1.07e+03    |
| time/                    |              |
|    fps                   | 82           |
|    iterations            | 13           |
|    time_elapsed          | 323          |
|    total_timesteps       | 227328       |
| train/                   |              |
|    approx_kl             | 0.0034915677 |
|    clip_fraction         | 0.0183       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.99         |
|    cost_value_loss       | 9            |
|    cost_values           | 0.933        |
|    entropy               | -3.13        |
|    entropy_loss          | -3.13        |
|    explained_variance    | 0.00336      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15           |
|    n_updates             | 1100         |
|    policy_gradient_loss  | -0.00264     |
|    std                   | 1.16         |
|    value_loss            | 25.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.83         |
| reward                   | -1.0035775   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -1.06e+03    |
| time/                    |              |
|    fps                   | 82           |
|    iterations            | 14           |
|    time_elapsed          | 346          |
|    total_timesteps       | 229376       |
| train/                   |              |
|    approx_kl             | 0.0033680205 |
|    clip_fraction         | 0.0169       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.16         |
|    cost_value_loss       | 1.35         |
|    cost_values           | 0.986        |
|    entropy               | -3.13        |
|    entropy_loss          | -3.13        |
|    explained_variance    | -0.00149     |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 28.5         |
|    n_updates             | 1110         |
|    policy_gradient_loss  | -0.00236     |
|    std                   | 1.16         |
|    value_loss            | 56.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.19         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.19         |
| reward                   | -1.2073584   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -1.06e+03    |
| time/                    |              |
|    fps                   | 83           |
|    iterations            | 15           |
|    time_elapsed          | 369          |
|    total_timesteps       | 231424       |
| train/                   |              |
|    approx_kl             | 0.0038935188 |
|    clip_fraction         | 0.0338       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.98         |
|    cost_value_loss       | 0.408        |
|    cost_values           | 0.969        |
|    entropy               | -3.13        |
|    entropy_loss          | -3.13        |
|    explained_variance    | 0.00444      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.4         |
|    n_updates             | 1120         |
|    policy_gradient_loss  | -0.00532     |
|    std                   | 1.16         |
|    value_loss            | 28.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.53        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.53        |
| reward                   | -0.5392184  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -1.05e+03   |
| time/                    |             |
|    fps                   | 83          |
|    iterations            | 16          |
|    time_elapsed          | 392         |
|    total_timesteps       | 233472      |
| train/                   |             |
|    approx_kl             | 0.005484017 |
|    clip_fraction         | 0.0237      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.949       |
|    cost_value_loss       | 0.473       |
|    cost_values           | 0.971       |
|    entropy               | -3.13       |
|    entropy_loss          | -3.13       |
|    explained_variance    | 0.000659    |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 33.8        |
|    n_updates             | 1130        |
|    policy_gradient_loss  | -0.00316    |
|    std                   | 1.16        |
|    value_loss            | 72.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.89         |
| reward                   | -0.6738574   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -1.04e+03    |
| time/                    |              |
|    fps                   | 83           |
|    iterations            | 17           |
|    time_elapsed          | 416          |
|    total_timesteps       | 235520       |
| train/                   |              |
|    approx_kl             | 0.0027046807 |
|    clip_fraction         | 0.00508      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.17         |
|    cost_value_loss       | 1.31         |
|    cost_values           | 0.988        |
|    entropy               | -3.13        |
|    entropy_loss          | -3.13        |
|    explained_variance    | 0.0144       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 23.3         |
|    n_updates             | 1140         |
|    policy_gradient_loss  | -0.00139     |
|    std                   | 1.16         |
|    value_loss            | 50.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.1029294  |
| rollout/                 |             |
|    ep_len_mean           | 993         |
|    ep_rew_mean           | -1.05e+03   |
| time/                    |             |
|    fps                   | 83          |
|    iterations            | 18          |
|    time_elapsed          | 439         |
|    total_timesteps       | 237568      |
| train/                   |             |
|    approx_kl             | 0.005393938 |
|    clip_fraction         | 0.0196      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.72        |
|    cost_value_loss       | 3.63        |
|    cost_values           | 0.995       |
|    entropy               | -3.13       |
|    entropy_loss          | -3.13       |
|    explained_variance    | -1.6        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 39.2        |
|    n_updates             | 1150        |
|    policy_gradient_loss  | -0.00275    |
|    std                   | 1.16        |
|    value_loss            | 90.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.19         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.19         |
| reward                   | -0.7352421   |
| rollout/                 |              |
|    ep_len_mean           | 993          |
|    ep_rew_mean           | -1.05e+03    |
| time/                    |              |
|    fps                   | 84           |
|    iterations            | 19           |
|    time_elapsed          | 463          |
|    total_timesteps       | 239616       |
| train/                   |              |
|    approx_kl             | 0.0036646444 |
|    clip_fraction         | 0.0329       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.18         |
|    cost_value_loss       | 0.966        |
|    cost_values           | 1.01         |
|    entropy               | -3.14        |
|    entropy_loss          | -3.14        |
|    explained_variance    | 0.0156       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.1         |
|    n_updates             | 1160         |
|    policy_gradient_loss  | -0.00415     |
|    std                   | 1.16         |
|    value_loss            | 32.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.17         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.17         |
| reward                   | -0.9930367   |
| rollout/                 |              |
|    ep_len_mean           | 1e+03        |
|    ep_rew_mean           | -1.05e+03    |
| time/                    |              |
|    fps                   | 84           |
|    iterations            | 20           |
|    time_elapsed          | 486          |
|    total_timesteps       | 241664       |
| train/                   |              |
|    approx_kl             | 0.0077513773 |
|    clip_fraction         | 0.0685       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.44         |
|    cost_value_loss       | 5.01         |
|    cost_values           | 1.26         |
|    entropy               | -3.15        |
|    entropy_loss          | -3.15        |
|    explained_variance    | 0.0244       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.23         |
|    n_updates             | 1170         |
|    policy_gradient_loss  | -0.00541     |
|    std                   | 1.17         |
|    value_loss            | 10.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.45         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.45         |
| reward                   | -0.85282403  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.04e+03    |
| time/                    |              |
|    fps                   | 84           |
|    iterations            | 21           |
|    time_elapsed          | 509          |
|    total_timesteps       | 243712       |
| train/                   |              |
|    approx_kl             | 0.0064715724 |
|    clip_fraction         | 0.0456       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.56         |
|    cost_value_loss       | 1.54         |
|    cost_values           | 1.36         |
|    entropy               | -3.15        |
|    entropy_loss          | -3.15        |
|    explained_variance    | -0.0851      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.89         |
|    n_updates             | 1180         |
|    policy_gradient_loss  | -0.00606     |
|    std                   | 1.17         |
|    value_loss            | 17.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.04         |
| reward                   | -0.7645434   |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.03e+03    |
| time/                    |              |
|    fps                   | 84           |
|    iterations            | 22           |
|    time_elapsed          | 533          |
|    total_timesteps       | 245760       |
| train/                   |              |
|    approx_kl             | 0.0046466133 |
|    clip_fraction         | 0.0448       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.31         |
|    cost_value_loss       | 0.371        |
|    cost_values           | 1.25         |
|    entropy               | -3.13        |
|    entropy_loss          | -3.14        |
|    explained_variance    | 0.00162      |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 32           |
|    n_updates             | 1190         |
|    policy_gradient_loss  | -0.00362     |
|    std                   | 1.16         |
|    value_loss            | 60.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.37         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.37         |
| reward                   | -0.51225686  |
| rollout/                 |              |
|    ep_len_mean           | 992          |
|    ep_rew_mean           | -1.02e+03    |
| time/                    |              |
|    fps                   | 84           |
|    iterations            | 23           |
|    time_elapsed          | 556          |
|    total_timesteps       | 247808       |
| train/                   |              |
|    approx_kl             | 0.0076154275 |
|    clip_fraction         | 0.0451       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.966        |
|    cost_value_loss       | 0.0677       |
|    cost_values           | 0.981        |
|    entropy               | -3.1         |
|    entropy_loss          | -3.12        |
|    explained_variance    | 0.244        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.48         |
|    n_updates             | 1200         |
|    policy_gradient_loss  | -0.00537     |
|    std                   | 1.14         |
|    value_loss            | 5.04         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.94         |
| reward                   | -0.65300065  |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 84           |
|    iterations            | 24           |
|    time_elapsed          | 580          |
|    total_timesteps       | 249856       |
| train/                   |              |
|    approx_kl             | 0.0050751707 |
|    clip_fraction         | 0.0484       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.3          |
|    cost_value_loss       | 2.11         |
|    cost_values           | 0.995        |
|    entropy               | -3.1         |
|    entropy_loss          | -3.1         |
|    explained_variance    | -0.611       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.4         |
|    n_updates             | 1210         |
|    policy_gradient_loss  | -0.000926    |
|    std                   | 1.14         |
|    value_loss            | 30.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -1.9608583   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 84           |
|    iterations            | 25           |
|    time_elapsed          | 603          |
|    total_timesteps       | 251904       |
| train/                   |              |
|    approx_kl             | 0.0006957621 |
|    clip_fraction         | 0.000195     |
|    clip_range            | 0.2          |
|    cost_returns          | 1.43         |
|    cost_value_loss       | 2.67         |
|    cost_values           | 0.952        |
|    entropy               | -3.1         |
|    entropy_loss          | -3.1         |
|    explained_variance    | 0.221        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 32.3         |
|    n_updates             | 1220         |
|    policy_gradient_loss  | -0.0019      |
|    std                   | 1.14         |
|    value_loss            | 133          |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.88936484 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -1.01e+03   |
| time/                    |             |
|    fps                   | 84          |
|    iterations            | 26          |
|    time_elapsed          | 627         |
|    total_timesteps       | 253952      |
| train/                   |             |
|    approx_kl             | 0.005357858 |
|    clip_fraction         | 0.0259      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.36        |
|    cost_value_loss       | 2.24        |
|    cost_values           | 0.962       |
|    entropy               | -3.1        |
|    entropy_loss          | -3.1        |
|    explained_variance    | 0.376       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 20.1        |
|    n_updates             | 1230        |
|    policy_gradient_loss  | -0.00353    |
|    std                   | 1.14        |
|    value_loss            | 40          |
------------------------------------------
------------------------------------------
| avg_speed                | 7.66        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.66        |
| reward                   | -2.1241477  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -1e+03      |
| time/                    |             |
|    fps                   | 85          |
|    iterations            | 27          |
|    time_elapsed          | 650         |
|    total_timesteps       | 256000      |
| train/                   |             |
|    approx_kl             | 0.004787991 |
|    clip_fraction         | 0.0126      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.02        |
|    cost_value_loss       | 0.448       |
|    cost_values           | 0.955       |
|    entropy               | -3.1        |
|    entropy_loss          | -3.1        |
|    explained_variance    | 0.772       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.1        |
|    n_updates             | 1240        |
|    policy_gradient_loss  | -0.0055     |
|    std                   | 1.14        |
|    value_loss            | 27.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.67         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.67         |
| reward                   | -2.6939206   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 85           |
|    iterations            | 28           |
|    time_elapsed          | 673          |
|    total_timesteps       | 258048       |
| train/                   |              |
|    approx_kl             | 0.0004948294 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 0.562        |
|    cost_value_loss       | 0.524        |
|    cost_values           | 0.535        |
|    entropy               | -3.1         |
|    entropy_loss          | -3.1         |
|    explained_variance    | 0.802        |
|    lagrangian_multiplier | 0.0205       |
|    learning_rate         | 0.0003       |
|    loss                  | 4.19         |
|    n_updates             | 1250         |
|    policy_gradient_loss  | -0.000739    |
|    std                   | 1.14         |
|    value_loss            | 233          |
-------------------------------------------
--------------------------------------------
| avg_speed                | 0.736         |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 0.736         |
| reward                   | -0.8628523    |
| rollout/                 |               |
|    ep_len_mean           | 989           |
|    ep_rew_mean           | -1.02e+03     |
| time/                    |               |
|    fps                   | 85            |
|    iterations            | 29            |
|    time_elapsed          | 696           |
|    total_timesteps       | 260096        |
| train/                   |               |
|    approx_kl             | 2.0489184e-05 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.201         |
|    cost_value_loss       | 0.117         |
|    cost_values           | 0.259         |
|    entropy               | -3.1          |
|    entropy_loss          | -3.1          |
|    explained_variance    | 0.591         |
|    lagrangian_multiplier | 0.00212       |
|    learning_rate         | 0.0003        |
|    loss                  | 13.4          |
|    n_updates             | 1260          |
|    policy_gradient_loss  | -0.000194     |
|    std                   | 1.14          |
|    value_loss            | 230           |
--------------------------------------------
------------------------------------------
| avg_speed                | 0.375       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.375       |
| reward                   | -0.6137962  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -1.04e+03   |
| time/                    |             |
|    fps                   | 85          |
|    iterations            | 30          |
|    time_elapsed          | 719         |
|    total_timesteps       | 262144      |
| train/                   |             |
|    approx_kl             | 0.000284245 |
|    clip_fraction         | 0           |
|    clip_range            | 0.2         |
|    cost_returns          | 0.643       |
|    cost_value_loss       | 0.538       |
|    cost_values           | 0.55        |
|    entropy               | -3.1        |
|    entropy_loss          | -3.1        |
|    explained_variance    | 0.451       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 110         |
|    n_updates             | 1270        |
|    policy_gradient_loss  | -0.000759   |
|    std                   | 1.14        |
|    value_loss            | 240         |
------------------------------------------
--------------------------------------------
| avg_speed                | 1.44          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 1.44          |
| reward                   | -0.51041704   |
| rollout/                 |               |
|    ep_len_mean           | 989           |
|    ep_rew_mean           | -1.04e+03     |
| time/                    |               |
|    fps                   | 85            |
|    iterations            | 31            |
|    time_elapsed          | 742           |
|    total_timesteps       | 264192        |
| train/                   |               |
|    approx_kl             | 0.00017665201 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 0.652         |
|    cost_value_loss       | 0.615         |
|    cost_values           | 0.57          |
|    entropy               | -3.1          |
|    entropy_loss          | -3.1          |
|    explained_variance    | 0.186         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 257           |
|    n_updates             | 1280          |
|    policy_gradient_loss  | -0.000498     |
|    std                   | 1.14          |
|    value_loss            | 526           |
--------------------------------------------
--------------------------------------------
| avg_speed                | 6.55          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 6.55          |
| reward                   | -1.3532354    |
| rollout/                 |               |
|    ep_len_mean           | 989           |
|    ep_rew_mean           | -1.04e+03     |
| time/                    |               |
|    fps                   | 85            |
|    iterations            | 32            |
|    time_elapsed          | 765           |
|    total_timesteps       | 266240        |
| train/                   |               |
|    approx_kl             | 0.00025281805 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.4           |
|    cost_value_loss       | 7.21          |
|    cost_values           | 0.634         |
|    entropy               | -3.1          |
|    entropy_loss          | -3.1          |
|    explained_variance    | 0.384         |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 13.2          |
|    n_updates             | 1290          |
|    policy_gradient_loss  | -0.000674     |
|    std                   | 1.14          |
|    value_loss            | 54            |
--------------------------------------------
--------------------------------------------
| avg_speed                | 1.69          |
| cost                     | 0             |
| is_success               | 0             |
| max_speed                | 1.69          |
| reward                   | -0.4062559    |
| rollout/                 |               |
|    ep_len_mean           | 989           |
|    ep_rew_mean           | -1.04e+03     |
| time/                    |               |
|    fps                   | 85            |
|    iterations            | 33            |
|    time_elapsed          | 788           |
|    total_timesteps       | 268288        |
| train/                   |               |
|    approx_kl             | 0.00047387503 |
|    clip_fraction         | 0             |
|    clip_range            | 0.2           |
|    cost_returns          | 1.27          |
|    cost_value_loss       | 7.33          |
|    cost_values           | 0.699         |
|    entropy               | -3.1          |
|    entropy_loss          | -3.1          |
|    explained_variance    | -0.346        |
|    lagrangian_multiplier | 0             |
|    learning_rate         | 0.0003        |
|    loss                  | 8.66          |
|    n_updates             | 1300          |
|    policy_gradient_loss  | -0.00107      |
|    std                   | 1.14          |
|    value_loss            | 41.1          |
--------------------------------------------
------------------------------------------
| avg_speed                | 3.48        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.48        |
| reward                   | -1.7392517  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -1.04e+03   |
| time/                    |             |
|    fps                   | 85          |
|    iterations            | 34          |
|    time_elapsed          | 811         |
|    total_timesteps       | 270336      |
| train/                   |             |
|    approx_kl             | 0.006320475 |
|    clip_fraction         | 0.0208      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.63        |
|    cost_value_loss       | 0.0263      |
|    cost_values           | 0.778       |
|    entropy               | -3.1        |
|    entropy_loss          | -3.1        |
|    explained_variance    | 0.862       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 20.6        |
|    n_updates             | 1310        |
|    policy_gradient_loss  | -0.00458    |
|    std                   | 1.14        |
|    value_loss            | 45.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.01        |
| reward                   | -1.5434206  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -1.04e+03   |
| time/                    |             |
|    fps                   | 85          |
|    iterations            | 35          |
|    time_elapsed          | 834         |
|    total_timesteps       | 272384      |
| train/                   |             |
|    approx_kl             | 0.001899587 |
|    clip_fraction         | 0.000928    |
|    clip_range            | 0.2         |
|    cost_returns          | 0.711       |
|    cost_value_loss       | 0.132       |
|    cost_values           | 0.787       |
|    entropy               | -3.1        |
|    entropy_loss          | -3.1        |
|    explained_variance    | 0.74        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.1        |
|    n_updates             | 1320        |
|    policy_gradient_loss  | -0.00149    |
|    std                   | 1.14        |
|    value_loss            | 35.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.45        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.45        |
| reward                   | -1.0596006  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -1.05e+03   |
| time/                    |             |
|    fps                   | 85          |
|    iterations            | 36          |
|    time_elapsed          | 858         |
|    total_timesteps       | 274432      |
| train/                   |             |
|    approx_kl             | 0.003016178 |
|    clip_fraction         | 0.00581     |
|    clip_range            | 0.2         |
|    cost_returns          | 0.635       |
|    cost_value_loss       | 0.116       |
|    cost_values           | 0.694       |
|    entropy               | -3.1        |
|    entropy_loss          | -3.1        |
|    explained_variance    | 0.822       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.3        |
|    n_updates             | 1330        |
|    policy_gradient_loss  | -0.00149    |
|    std                   | 1.14        |
|    value_loss            | 34.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.8         |
| reward                   | -0.9297764  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -1.05e+03   |
| time/                    |             |
|    fps                   | 85          |
|    iterations            | 37          |
|    time_elapsed          | 881         |
|    total_timesteps       | 276480      |
| train/                   |             |
|    approx_kl             | 0.005504178 |
|    clip_fraction         | 0.0167      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.659       |
|    cost_value_loss       | 0.643       |
|    cost_values           | 0.602       |
|    entropy               | -3.1        |
|    entropy_loss          | -3.1        |
|    explained_variance    | 0.033       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 22          |
|    n_updates             | 1340        |
|    policy_gradient_loss  | -0.00311    |
|    std                   | 1.14        |
|    value_loss            | 43.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.36        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.36        |
| reward                   | -0.79935414 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -1.06e+03   |
| time/                    |             |
|    fps                   | 86          |
|    iterations            | 38          |
|    time_elapsed          | 904         |
|    total_timesteps       | 278528      |
| train/                   |             |
|    approx_kl             | 0.00501993  |
|    clip_fraction         | 0.0215      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.668       |
|    cost_value_loss       | 0.46        |
|    cost_values           | 0.646       |
|    entropy               | -3.1        |
|    entropy_loss          | -3.1        |
|    explained_variance    | 0.0545      |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 17.6        |
|    n_updates             | 1350        |
|    policy_gradient_loss  | -0.00325    |
|    std                   | 1.14        |
|    value_loss            | 38.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -1.5434674   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -1.06e+03    |
| time/                    |              |
|    fps                   | 86           |
|    iterations            | 39           |
|    time_elapsed          | 928          |
|    total_timesteps       | 280576       |
| train/                   |              |
|    approx_kl             | 0.0010796692 |
|    clip_fraction         | 4.88e-05     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.707        |
|    cost_value_loss       | 0.629        |
|    cost_values           | 0.664        |
|    entropy               | -3.11        |
|    entropy_loss          | -3.1         |
|    explained_variance    | 0.0112       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 97.7         |
|    n_updates             | 1360         |
|    policy_gradient_loss  | -0.00156     |
|    std                   | 1.14         |
|    value_loss            | 212          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.92         |
| reward                   | -1.4168283   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -1.06e+03    |
| time/                    |              |
|    fps                   | 86           |
|    iterations            | 40           |
|    time_elapsed          | 951          |
|    total_timesteps       | 282624       |
| train/                   |              |
|    approx_kl             | 0.0043548048 |
|    clip_fraction         | 0.0382       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.04         |
|    cost_value_loss       | 2.21         |
|    cost_values           | 0.858        |
|    entropy               | -3.11        |
|    entropy_loss          | -3.11        |
|    explained_variance    | 0.0329       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.2         |
|    n_updates             | 1370         |
|    policy_gradient_loss  | -0.00442     |
|    std                   | 1.14         |
|    value_loss            | 32.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.00503     |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.00503     |
| reward                   | -1.3538221  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -1.06e+03   |
| time/                    |             |
|    fps                   | 86          |
|    iterations            | 41          |
|    time_elapsed          | 974         |
|    total_timesteps       | 284672      |
| train/                   |             |
|    approx_kl             | 0.004812763 |
|    clip_fraction         | 0.0101      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.908       |
|    cost_value_loss       | 0.323       |
|    cost_values           | 0.794       |
|    entropy               | -3.1        |
|    entropy_loss          | -3.11       |
|    explained_variance    | 0.709       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.4        |
|    n_updates             | 1380        |
|    policy_gradient_loss  | -0.00271    |
|    std                   | 1.14        |
|    value_loss            | 34.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -1.0282334   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -1.07e+03    |
| time/                    |              |
|    fps                   | 86           |
|    iterations            | 42           |
|    time_elapsed          | 998          |
|    total_timesteps       | 286720       |
| train/                   |              |
|    approx_kl             | 0.0011269354 |
|    clip_fraction         | 0.000146     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.66         |
|    cost_value_loss       | 0.148        |
|    cost_values           | 0.717        |
|    entropy               | -3.11        |
|    entropy_loss          | -3.1         |
|    explained_variance    | 0.53         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 79.1         |
|    n_updates             | 1390         |
|    policy_gradient_loss  | -0.000748    |
|    std                   | 1.14         |
|    value_loss            | 154          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.96         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.96         |
| reward                   | -1.3521209   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -1.07e+03    |
| time/                    |              |
|    fps                   | 86           |
|    iterations            | 43           |
|    time_elapsed          | 1021         |
|    total_timesteps       | 288768       |
| train/                   |              |
|    approx_kl             | 0.0048750937 |
|    clip_fraction         | 0.035        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.683        |
|    cost_value_loss       | 0.0193       |
|    cost_values           | 0.805        |
|    entropy               | -3.11        |
|    entropy_loss          | -3.11        |
|    explained_variance    | 0.703        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 23.2         |
|    n_updates             | 1400         |
|    policy_gradient_loss  | -0.0047      |
|    std                   | 1.14         |
|    value_loss            | 48.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.1725248  |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -1.07e+03   |
| time/                    |             |
|    fps                   | 86          |
|    iterations            | 44          |
|    time_elapsed          | 1045        |
|    total_timesteps       | 290816      |
| train/                   |             |
|    approx_kl             | 0.005251131 |
|    clip_fraction         | 0.0411      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.02        |
|    cost_value_loss       | 1.56        |
|    cost_values           | 0.774       |
|    entropy               | -3.11       |
|    entropy_loss          | -3.11       |
|    explained_variance    | 0.476       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.19        |
|    n_updates             | 1410        |
|    policy_gradient_loss  | -0.00478    |
|    std                   | 1.15        |
|    value_loss            | 16.2        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8.02       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.02       |
| reward                   | -1.208652  |
| rollout/                 |            |
|    ep_len_mean           | 989        |
|    ep_rew_mean           | -1.07e+03  |
| time/                    |            |
|    fps                   | 86         |
|    iterations            | 45         |
|    time_elapsed          | 1069       |
|    total_timesteps       | 292864     |
| train/                   |            |
|    approx_kl             | 0.00349278 |
|    clip_fraction         | 0.00791    |
|    clip_range            | 0.2        |
|    cost_returns          | 1.09       |
|    cost_value_loss       | 1.25       |
|    cost_values           | 0.884      |
|    entropy               | -3.12      |
|    entropy_loss          | -3.12      |
|    explained_variance    | 0.737      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 16.6       |
|    n_updates             | 1420       |
|    policy_gradient_loss  | -0.00177   |
|    std                   | 1.15       |
|    value_loss            | 40.3       |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.46        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.46        |
| reward                   | -0.73854256 |
| rollout/                 |             |
|    ep_len_mean           | 989         |
|    ep_rew_mean           | -1.07e+03   |
| time/                    |             |
|    fps                   | 86          |
|    iterations            | 46          |
|    time_elapsed          | 1095        |
|    total_timesteps       | 294912      |
| train/                   |             |
|    approx_kl             | 0.005331746 |
|    clip_fraction         | 0.0415      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.25        |
|    cost_value_loss       | 1.88        |
|    cost_values           | 0.932       |
|    entropy               | -3.11       |
|    entropy_loss          | -3.12       |
|    explained_variance    | 0.801       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.35        |
|    n_updates             | 1430        |
|    policy_gradient_loss  | -0.00596    |
|    std                   | 1.15        |
|    value_loss            | 14.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -1.2127393   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -1.07e+03    |
| time/                    |              |
|    fps                   | 85           |
|    iterations            | 47           |
|    time_elapsed          | 1120         |
|    total_timesteps       | 296960       |
| train/                   |              |
|    approx_kl             | 0.0041720294 |
|    clip_fraction         | 0.0311       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.03         |
|    cost_value_loss       | 0.77         |
|    cost_values           | 0.895        |
|    entropy               | -3.11        |
|    entropy_loss          | -3.11        |
|    explained_variance    | 0.659        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.04         |
|    n_updates             | 1440         |
|    policy_gradient_loss  | -0.00462     |
|    std                   | 1.15         |
|    value_loss            | 16.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.75         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.75         |
| reward                   | -1.0506672   |
| rollout/                 |              |
|    ep_len_mean           | 989          |
|    ep_rew_mean           | -1.07e+03    |
| time/                    |              |
|    fps                   | 85           |
|    iterations            | 48           |
|    time_elapsed          | 1148         |
|    total_timesteps       | 299008       |
| train/                   |              |
|    approx_kl             | 0.0074288053 |
|    clip_fraction         | 0.032        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.861        |
|    cost_value_loss       | 0.264        |
|    cost_values           | 0.864        |
|    entropy               | -3.11        |
|    entropy_loss          | -3.11        |
|    explained_variance    | -0.6         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.08         |
|    n_updates             | 1450         |
|    policy_gradient_loss  | -0.00373     |
|    std                   | 1.15         |
|    value_loss            | 17.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.14         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.14         |
| reward                   | -1.0613067   |
| rollout/                 |              |
|    ep_len_mean           | 980          |
|    ep_rew_mean           | -1.06e+03    |
| time/                    |              |
|    fps                   | 85           |
|    iterations            | 49           |
|    time_elapsed          | 1176         |
|    total_timesteps       | 301056       |
| train/                   |              |
|    approx_kl             | 0.0058384934 |
|    clip_fraction         | 0.042        |
|    clip_range            | 0.2          |
|    cost_returns          | 0.965        |
|    cost_value_loss       | 0.864        |
|    cost_values           | 0.893        |
|    entropy               | -3.11        |
|    entropy_loss          | -3.12        |
|    explained_variance    | 0.85         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.59         |
|    n_updates             | 1460         |
|    policy_gradient_loss  | -0.00439     |
|    std                   | 1.15         |
|    value_loss            | 10.2         |
-------------------------------------------
-----------------------------------
| avg_speed          | 6.18       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 6.18       |
| reward             | -1.0644761 |
| rollout/           |            |
|    ep_len_mean     | 972        |
|    ep_rew_mean     | -1.05e+03  |
| time/              |            |
|    fps             | 74         |
|    iterations      | 1          |
|    time_elapsed    | 27         |
|    total_timesteps | 303104     |
-----------------------------------
------------------------------------------
| avg_speed                | 6.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.01        |
| reward                   | -1.1146545  |
| rollout/                 |             |
|    ep_len_mean           | 972         |
|    ep_rew_mean           | -1.06e+03   |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 2           |
|    time_elapsed          | 56          |
|    total_timesteps       | 305152      |
| train/                   |             |
|    approx_kl             | 0.004094154 |
|    clip_fraction         | 0.013       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.977       |
|    cost_value_loss       | 1.1         |
|    cost_values           | 0.769       |
|    entropy               | -3.11       |
|    entropy_loss          | -3.11       |
|    explained_variance    | 0.519       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 30.2        |
|    n_updates             | 1480        |
|    policy_gradient_loss  | -0.00299    |
|    std                   | 1.15        |
|    value_loss            | 72          |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.21         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.21         |
| reward                   | -0.49710095  |
| rollout/                 |              |
|    ep_len_mean           | 958          |
|    ep_rew_mean           | -1.04e+03    |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 3            |
|    time_elapsed          | 86           |
|    total_timesteps       | 307200       |
| train/                   |              |
|    approx_kl             | 0.0014429078 |
|    clip_fraction         | 0.000342     |
|    clip_range            | 0.2          |
|    cost_returns          | 0.808        |
|    cost_value_loss       | 0.278        |
|    cost_values           | 0.827        |
|    entropy               | -3.11        |
|    entropy_loss          | -3.11        |
|    explained_variance    | 0.589        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 12.5         |
|    n_updates             | 1490         |
|    policy_gradient_loss  | -0.000923    |
|    std                   | 1.15         |
|    value_loss            | 47.6         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 7.94       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.94       |
| reward                   | -1.1469332 |
| rollout/                 |            |
|    ep_len_mean           | 951        |
|    ep_rew_mean           | -1.03e+03  |
| time/                    |            |
|    fps                   | 70         |
|    iterations            | 4          |
|    time_elapsed          | 115        |
|    total_timesteps       | 309248     |
| train/                   |            |
|    approx_kl             | 0.00238589 |
|    clip_fraction         | 0.00947    |
|    clip_range            | 0.2        |
|    cost_returns          | 1.26       |
|    cost_value_loss       | 1.77       |
|    cost_values           | 0.856      |
|    entropy               | -3.11      |
|    entropy_loss          | -3.11      |
|    explained_variance    | 0.736      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 55.4       |
|    n_updates             | 1500       |
|    policy_gradient_loss  | -0.00254   |
|    std                   | 1.15       |
|    value_loss            | 90.3       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 1.08         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.08         |
| reward                   | -0.7487807   |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -1.02e+03    |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 5            |
|    time_elapsed          | 145          |
|    total_timesteps       | 311296       |
| train/                   |              |
|    approx_kl             | 0.0029453428 |
|    clip_fraction         | 0.00249      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.99         |
|    cost_value_loss       | 0.91         |
|    cost_values           | 0.852        |
|    entropy               | -3.12        |
|    entropy_loss          | -3.12        |
|    explained_variance    | 0.094        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 34.2         |
|    n_updates             | 1510         |
|    policy_gradient_loss  | -0.00277     |
|    std                   | 1.15         |
|    value_loss            | 63           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.509        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.509        |
| reward                   | -0.5768823   |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -1.02e+03    |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 6            |
|    time_elapsed          | 175          |
|    total_timesteps       | 313344       |
| train/                   |              |
|    approx_kl             | 0.0052164798 |
|    clip_fraction         | 0.0296       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.36         |
|    cost_value_loss       | 2.05         |
|    cost_values           | 0.903        |
|    entropy               | -3.12        |
|    entropy_loss          | -3.12        |
|    explained_variance    | 0.95         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.26         |
|    n_updates             | 1520         |
|    policy_gradient_loss  | -0.0039      |
|    std                   | 1.15         |
|    value_loss            | 14           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.623        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.623        |
| reward                   | -0.6283893   |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 7            |
|    time_elapsed          | 204          |
|    total_timesteps       | 315392       |
| train/                   |              |
|    approx_kl             | 0.0059804255 |
|    clip_fraction         | 0.0387       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.18         |
|    cost_value_loss       | 0.781        |
|    cost_values           | 0.968        |
|    entropy               | -3.12        |
|    entropy_loss          | -3.12        |
|    explained_variance    | -0.128       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.75         |
|    n_updates             | 1530         |
|    policy_gradient_loss  | -0.00466     |
|    std                   | 1.15         |
|    value_loss            | 4.15         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.15         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.15         |
| reward                   | -0.87543863  |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -1.02e+03    |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 8            |
|    time_elapsed          | 233          |
|    total_timesteps       | 317440       |
| train/                   |              |
|    approx_kl             | 0.0067851315 |
|    clip_fraction         | 0.07         |
|    clip_range            | 0.2          |
|    cost_returns          | 1.39         |
|    cost_value_loss       | 1.86         |
|    cost_values           | 0.939        |
|    entropy               | -3.12        |
|    entropy_loss          | -3.12        |
|    explained_variance    | 0.669        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.05         |
|    n_updates             | 1540         |
|    policy_gradient_loss  | -0.00692     |
|    std                   | 1.15         |
|    value_loss            | 10.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.24         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.24         |
| reward                   | -0.8392939   |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -1.03e+03    |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 9            |
|    time_elapsed          | 262          |
|    total_timesteps       | 319488       |
| train/                   |              |
|    approx_kl             | 0.0034064236 |
|    clip_fraction         | 0.00854      |
|    clip_range            | 0.2          |
|    cost_returns          | 0.925        |
|    cost_value_loss       | 0.428        |
|    cost_values           | 0.903        |
|    entropy               | -3.12        |
|    entropy_loss          | -3.12        |
|    explained_variance    | 0.751        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 163          |
|    n_updates             | 1550         |
|    policy_gradient_loss  | -0.0032      |
|    std                   | 1.15         |
|    value_loss            | 330          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.83         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.83         |
| reward                   | -1.3330276   |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -1.03e+03    |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 10           |
|    time_elapsed          | 291          |
|    total_timesteps       | 321536       |
| train/                   |              |
|    approx_kl             | 0.0051528877 |
|    clip_fraction         | 0.0256       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.863        |
|    cost_value_loss       | 0.323        |
|    cost_values           | 0.859        |
|    entropy               | -3.12        |
|    entropy_loss          | -3.12        |
|    explained_variance    | 0.445        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 20.1         |
|    n_updates             | 1560         |
|    policy_gradient_loss  | -0.00503     |
|    std                   | 1.15         |
|    value_loss            | 44.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -0.76860774  |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -1.03e+03    |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 11           |
|    time_elapsed          | 320          |
|    total_timesteps       | 323584       |
| train/                   |              |
|    approx_kl             | 0.0041362373 |
|    clip_fraction         | 0.0124       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.07         |
|    cost_value_loss       | 0.702        |
|    cost_values           | 0.923        |
|    entropy               | -3.12        |
|    entropy_loss          | -3.12        |
|    explained_variance    | 0.893        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.4          |
|    n_updates             | 1570         |
|    policy_gradient_loss  | -0.0016      |
|    std                   | 1.15         |
|    value_loss            | 15.4         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.0392       |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.0392       |
| reward                   | -0.73792017  |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -1.02e+03    |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 12           |
|    time_elapsed          | 350          |
|    total_timesteps       | 325632       |
| train/                   |              |
|    approx_kl             | 0.0059146867 |
|    clip_fraction         | 0.0354       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.23         |
|    cost_value_loss       | 1.77         |
|    cost_values           | 0.947        |
|    entropy               | -3.12        |
|    entropy_loss          | -3.12        |
|    explained_variance    | 0.556        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.1         |
|    n_updates             | 1580         |
|    policy_gradient_loss  | -0.00603     |
|    std                   | 1.15         |
|    value_loss            | 29.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.723       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.723       |
| reward                   | -0.4213906  |
| rollout/                 |             |
|    ep_len_mean           | 951         |
|    ep_rew_mean           | -1.01e+03   |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 13          |
|    time_elapsed          | 379         |
|    total_timesteps       | 327680      |
| train/                   |             |
|    approx_kl             | 0.005074265 |
|    clip_fraction         | 0.0355      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.861       |
|    cost_value_loss       | 0.189       |
|    cost_values           | 0.916       |
|    entropy               | -3.13       |
|    entropy_loss          | -3.12       |
|    explained_variance    | 0.921       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.71        |
|    n_updates             | 1590        |
|    policy_gradient_loss  | -0.00552    |
|    std                   | 1.15        |
|    value_loss            | 20.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.34         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.34         |
| reward                   | -0.7619707   |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 14           |
|    time_elapsed          | 410          |
|    total_timesteps       | 329728       |
| train/                   |              |
|    approx_kl             | 0.0053322837 |
|    clip_fraction         | 0.0588       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.961        |
|    cost_value_loss       | 0.645        |
|    cost_values           | 0.925        |
|    entropy               | -3.11        |
|    entropy_loss          | -3.12        |
|    explained_variance    | 0.984        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.93         |
|    n_updates             | 1600         |
|    policy_gradient_loss  | -0.00643     |
|    std                   | 1.14         |
|    value_loss            | 3.77         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.88         |
| reward                   | -0.82063276  |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -1e+03       |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 15           |
|    time_elapsed          | 440          |
|    total_timesteps       | 331776       |
| train/                   |              |
|    approx_kl             | 0.0040963273 |
|    clip_fraction         | 0.0427       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.861        |
|    cost_value_loss       | 0.362        |
|    cost_values           | 0.865        |
|    entropy               | -3.1         |
|    entropy_loss          | -3.1         |
|    explained_variance    | 0.98         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.76         |
|    n_updates             | 1610         |
|    policy_gradient_loss  | -0.00613     |
|    std                   | 1.14         |
|    value_loss            | 8.25         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -1.1580125  |
| rollout/                 |             |
|    ep_len_mean           | 951         |
|    ep_rew_mean           | -1.01e+03   |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 16          |
|    time_elapsed          | 470         |
|    total_timesteps       | 333824      |
| train/                   |             |
|    approx_kl             | 0.010113045 |
|    clip_fraction         | 0.0504      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.31        |
|    cost_value_loss       | 3.72        |
|    cost_values           | 0.849       |
|    entropy               | -3.1        |
|    entropy_loss          | -3.1        |
|    explained_variance    | 0.818       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.81        |
|    n_updates             | 1620        |
|    policy_gradient_loss  | -0.00778    |
|    std                   | 1.14        |
|    value_loss            | 14.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.38         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.38         |
| reward                   | -0.6400843   |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -1e+03       |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 17           |
|    time_elapsed          | 500          |
|    total_timesteps       | 335872       |
| train/                   |              |
|    approx_kl             | 0.0056350203 |
|    clip_fraction         | 0.0178       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.895        |
|    cost_value_loss       | 0.0153       |
|    cost_values           | 0.934        |
|    entropy               | -3.1         |
|    entropy_loss          | -3.1         |
|    explained_variance    | 0.77         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 19.1         |
|    n_updates             | 1630         |
|    policy_gradient_loss  | -0.00213     |
|    std                   | 1.14         |
|    value_loss            | 47.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.89         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.89         |
| reward                   | -0.7479371   |
| rollout/                 |              |
|    ep_len_mean           | 951          |
|    ep_rew_mean           | -1e+03       |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 18           |
|    time_elapsed          | 530          |
|    total_timesteps       | 337920       |
| train/                   |              |
|    approx_kl             | 0.0044635423 |
|    clip_fraction         | 0.0246       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.964        |
|    cost_value_loss       | 1.33         |
|    cost_values           | 0.84         |
|    entropy               | -3.09        |
|    entropy_loss          | -3.1         |
|    explained_variance    | 0.967        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.76         |
|    n_updates             | 1640         |
|    policy_gradient_loss  | -0.00389     |
|    std                   | 1.14         |
|    value_loss            | 5.04         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.2          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.2          |
| reward                   | -0.79467386  |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 19           |
|    time_elapsed          | 560          |
|    total_timesteps       | 339968       |
| train/                   |              |
|    approx_kl             | 0.0043451823 |
|    clip_fraction         | 0.0453       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.46         |
|    cost_value_loss       | 9.45         |
|    cost_values           | 1.1          |
|    entropy               | -3.1         |
|    entropy_loss          | -3.1         |
|    explained_variance    | 0.971        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.13         |
|    n_updates             | 1650         |
|    policy_gradient_loss  | -0.0053      |
|    std                   | 1.14         |
|    value_loss            | 7.37         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.63         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.63         |
| reward                   | -0.3502868   |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -1.01e+03    |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 20           |
|    time_elapsed          | 590          |
|    total_timesteps       | 342016       |
| train/                   |              |
|    approx_kl             | 0.0046945075 |
|    clip_fraction         | 0.0141       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.94         |
|    cost_value_loss       | 5.27         |
|    cost_values           | 1.01         |
|    entropy               | -3.1         |
|    entropy_loss          | -3.1         |
|    explained_variance    | 0.842        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 22           |
|    n_updates             | 1660         |
|    policy_gradient_loss  | -0.00295     |
|    std                   | 1.14         |
|    value_loss            | 43.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.72        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.72        |
| reward                   | -1.2812266  |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -1.01e+03   |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 21          |
|    time_elapsed          | 620         |
|    total_timesteps       | 344064      |
| train/                   |             |
|    approx_kl             | 0.006328838 |
|    clip_fraction         | 0.0208      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.09        |
|    cost_value_loss       | 1.26        |
|    cost_values           | 0.877       |
|    entropy               | -3.11       |
|    entropy_loss          | -3.1        |
|    explained_variance    | 0.854       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.06        |
|    n_updates             | 1670        |
|    policy_gradient_loss  | -0.00285    |
|    std                   | 1.14        |
|    value_loss            | 12.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.126       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.126       |
| reward                   | -0.75183815 |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -1.01e+03   |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 22          |
|    time_elapsed          | 649         |
|    total_timesteps       | 346112      |
| train/                   |             |
|    approx_kl             | 0.004668412 |
|    clip_fraction         | 0.058       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.923       |
|    cost_value_loss       | 0.311       |
|    cost_values           | 0.893       |
|    entropy               | -3.11       |
|    entropy_loss          | -3.11       |
|    explained_variance    | 0.954       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.18        |
|    n_updates             | 1680        |
|    policy_gradient_loss  | -0.00799    |
|    std                   | 1.14        |
|    value_loss            | 6.93        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.18        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.18        |
| reward                   | -0.87704974 |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -1.01e+03   |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 23          |
|    time_elapsed          | 678         |
|    total_timesteps       | 348160      |
| train/                   |             |
|    approx_kl             | 0.006107541 |
|    clip_fraction         | 0.0162      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.22        |
|    cost_value_loss       | 1.55        |
|    cost_values           | 0.917       |
|    entropy               | -3.1        |
|    entropy_loss          | -3.1        |
|    explained_variance    | 0.665       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.53        |
|    n_updates             | 1690        |
|    policy_gradient_loss  | -0.00218    |
|    std                   | 1.14        |
|    value_loss            | 15.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.9         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.9         |
| reward                   | -1.1686151  |
| rollout/                 |             |
|    ep_len_mean           | 962         |
|    ep_rew_mean           | -1.01e+03   |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 24          |
|    time_elapsed          | 707         |
|    total_timesteps       | 350208      |
| train/                   |             |
|    approx_kl             | 0.008437833 |
|    clip_fraction         | 0.0751      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.12        |
|    cost_value_loss       | 1.08        |
|    cost_values           | 0.905       |
|    entropy               | -3.09       |
|    entropy_loss          | -3.1        |
|    explained_variance    | 0.848       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.25        |
|    n_updates             | 1700        |
|    policy_gradient_loss  | -0.00952    |
|    std                   | 1.14        |
|    value_loss            | 12.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.79        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.79        |
| reward                   | -0.7245156  |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -998        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 25          |
|    time_elapsed          | 737         |
|    total_timesteps       | 352256      |
| train/                   |             |
|    approx_kl             | 0.010018989 |
|    clip_fraction         | 0.115       |
|    clip_range            | 0.2         |
|    cost_returns          | 0.891       |
|    cost_value_loss       | 0.365       |
|    cost_values           | 0.866       |
|    entropy               | -3.08       |
|    entropy_loss          | -3.09       |
|    explained_variance    | 0.685       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.63        |
|    n_updates             | 1710        |
|    policy_gradient_loss  | -0.0138     |
|    std                   | 1.13        |
|    value_loss            | 6.62        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -1.0151418   |
| rollout/                 |              |
|    ep_len_mean           | 954          |
|    ep_rew_mean           | -984         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 26           |
|    time_elapsed          | 766          |
|    total_timesteps       | 354304       |
| train/                   |              |
|    approx_kl             | 0.0057763755 |
|    clip_fraction         | 0.0422       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.26         |
|    cost_value_loss       | 1.34         |
|    cost_values           | 0.963        |
|    entropy               | -3.08        |
|    entropy_loss          | -3.08        |
|    explained_variance    | 0.606        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 25.2         |
|    n_updates             | 1720         |
|    policy_gradient_loss  | -0.00403     |
|    std                   | 1.13         |
|    value_loss            | 55.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.58        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.58        |
| reward                   | -0.9617562  |
| rollout/                 |             |
|    ep_len_mean           | 954         |
|    ep_rew_mean           | -970        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 27          |
|    time_elapsed          | 796         |
|    total_timesteps       | 356352      |
| train/                   |             |
|    approx_kl             | 0.005018023 |
|    clip_fraction         | 0.0381      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.974       |
|    cost_value_loss       | 0.55        |
|    cost_values           | 0.929       |
|    entropy               | -3.07       |
|    entropy_loss          | -3.07       |
|    explained_variance    | 0.786       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.06        |
|    n_updates             | 1730        |
|    policy_gradient_loss  | -0.00485    |
|    std                   | 1.12        |
|    value_loss            | 10.4        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8.04       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.04       |
| reward                   | -0.7512149 |
| rollout/                 |            |
|    ep_len_mean           | 954        |
|    ep_rew_mean           | -944       |
| time/                    |            |
|    fps                   | 69         |
|    iterations            | 28         |
|    time_elapsed          | 827        |
|    total_timesteps       | 358400     |
| train/                   |            |
|    approx_kl             | 0.00944115 |
|    clip_fraction         | 0.11       |
|    clip_range            | 0.2        |
|    cost_returns          | 0.901      |
|    cost_value_loss       | 0.199      |
|    cost_values           | 0.911      |
|    entropy               | -3.09      |
|    entropy_loss          | -3.08      |
|    explained_variance    | 0.0246     |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 4.31       |
|    n_updates             | 1740       |
|    policy_gradient_loss  | -0.00691   |
|    std                   | 1.13       |
|    value_loss            | 8.56       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 7.47         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.47         |
| reward                   | -1.2742015   |
| rollout/                 |              |
|    ep_len_mean           | 940          |
|    ep_rew_mean           | -924         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 29           |
|    time_elapsed          | 857          |
|    total_timesteps       | 360448       |
| train/                   |              |
|    approx_kl             | 0.0062177703 |
|    clip_fraction         | 0.0617       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.28         |
|    cost_value_loss       | 1.36         |
|    cost_values           | 0.97         |
|    entropy               | -3.09        |
|    entropy_loss          | -3.09        |
|    explained_variance    | 0.137        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.73         |
|    n_updates             | 1750         |
|    policy_gradient_loss  | -0.000434    |
|    std                   | 1.13         |
|    value_loss            | 16.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.339       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.339       |
| reward                   | -0.63776755 |
| rollout/                 |             |
|    ep_len_mean           | 940         |
|    ep_rew_mean           | -919        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 30          |
|    time_elapsed          | 887         |
|    total_timesteps       | 362496      |
| train/                   |             |
|    approx_kl             | 0.005573768 |
|    clip_fraction         | 0.0244      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.71        |
|    cost_value_loss       | 2.43        |
|    cost_values           | 0.957       |
|    entropy               | -3.09       |
|    entropy_loss          | -3.09       |
|    explained_variance    | 0.198       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 43.1        |
|    n_updates             | 1760        |
|    policy_gradient_loss  | -0.0021     |
|    std                   | 1.13        |
|    value_loss            | 91.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.564        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.564        |
| reward                   | -0.8925396   |
| rollout/                 |              |
|    ep_len_mean           | 940          |
|    ep_rew_mean           | -912         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 31           |
|    time_elapsed          | 916          |
|    total_timesteps       | 364544       |
| train/                   |              |
|    approx_kl             | 0.0022808583 |
|    clip_fraction         | 0.00571      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.67         |
|    cost_value_loss       | 5.5          |
|    cost_values           | 0.897        |
|    entropy               | -3.09        |
|    entropy_loss          | -3.09        |
|    explained_variance    | 0.876        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27.3         |
|    n_updates             | 1770         |
|    policy_gradient_loss  | -0.0025      |
|    std                   | 1.13         |
|    value_loss            | 56.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.57        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.57        |
| reward                   | -0.78141075 |
| rollout/                 |             |
|    ep_len_mean           | 940         |
|    ep_rew_mean           | -903        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 32          |
|    time_elapsed          | 946         |
|    total_timesteps       | 366592      |
| train/                   |             |
|    approx_kl             | 0.004409546 |
|    clip_fraction         | 0.0232      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.26        |
|    cost_value_loss       | 1.78        |
|    cost_values           | 0.981       |
|    entropy               | -3.09       |
|    entropy_loss          | -3.09       |
|    explained_variance    | 0.881       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.53        |
|    n_updates             | 1780        |
|    policy_gradient_loss  | -0.00315    |
|    std                   | 1.13        |
|    value_loss            | 2           |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.69         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.69         |
| reward                   | -0.8634184   |
| rollout/                 |              |
|    ep_len_mean           | 940          |
|    ep_rew_mean           | -893         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 33           |
|    time_elapsed          | 976          |
|    total_timesteps       | 368640       |
| train/                   |              |
|    approx_kl             | 0.0041238004 |
|    clip_fraction         | 0.0126       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.88         |
|    cost_value_loss       | 5.76         |
|    cost_values           | 0.968        |
|    entropy               | -3.08        |
|    entropy_loss          | -3.09        |
|    explained_variance    | 0.889        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.9          |
|    n_updates             | 1790         |
|    policy_gradient_loss  | -0.00356     |
|    std                   | 1.13         |
|    value_loss            | 6.18         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.820803    |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -880         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 34           |
|    time_elapsed          | 1005         |
|    total_timesteps       | 370688       |
| train/                   |              |
|    approx_kl             | 0.0013854892 |
|    clip_fraction         | 0.000586     |
|    clip_range            | 0.2          |
|    cost_returns          | 3.46         |
|    cost_value_loss       | 22.1         |
|    cost_values           | 1.01         |
|    entropy               | -3.08        |
|    entropy_loss          | -3.08        |
|    explained_variance    | 0.715        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.7         |
|    n_updates             | 1800         |
|    policy_gradient_loss  | -0.00112     |
|    std                   | 1.13         |
|    value_loss            | 4.53         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.68         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.68         |
| reward                   | -0.7438626   |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -866         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 35           |
|    time_elapsed          | 1034         |
|    total_timesteps       | 372736       |
| train/                   |              |
|    approx_kl             | 0.0007356625 |
|    clip_fraction         | 0            |
|    clip_range            | 0.2          |
|    cost_returns          | 1.13         |
|    cost_value_loss       | 1            |
|    cost_values           | 0.94         |
|    entropy               | -3.08        |
|    entropy_loss          | -3.08        |
|    explained_variance    | 0.783        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.6         |
|    n_updates             | 1810         |
|    policy_gradient_loss  | -0.000604    |
|    std                   | 1.13         |
|    value_loss            | 31.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.754        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.754        |
| reward                   | -0.73122793  |
| rollout/                 |              |
|    ep_len_mean           | 935          |
|    ep_rew_mean           | -859         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 36           |
|    time_elapsed          | 1062         |
|    total_timesteps       | 374784       |
| train/                   |              |
|    approx_kl             | 0.0034719221 |
|    clip_fraction         | 0.00991      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.1          |
|    cost_value_loss       | 1.5          |
|    cost_values           | 0.861        |
|    entropy               | -3.08        |
|    entropy_loss          | -3.08        |
|    explained_variance    | 0.925        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.03         |
|    n_updates             | 1820         |
|    policy_gradient_loss  | -0.00295     |
|    std                   | 1.13         |
|    value_loss            | 7.92         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.53        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.53        |
| reward                   | -0.95029867 |
| rollout/                 |             |
|    ep_len_mean           | 926         |
|    ep_rew_mean           | -836        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 37          |
|    time_elapsed          | 1091        |
|    total_timesteps       | 376832      |
| train/                   |             |
|    approx_kl             | 0.005142836 |
|    clip_fraction         | 0.0473      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.887       |
|    cost_value_loss       | 0.306       |
|    cost_values           | 0.911       |
|    entropy               | -3.07       |
|    entropy_loss          | -3.08       |
|    explained_variance    | 0.798       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.51        |
|    n_updates             | 1830        |
|    policy_gradient_loss  | -0.00482    |
|    std                   | 1.12        |
|    value_loss            | 9.76        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.984        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.984        |
| reward                   | -0.7518973   |
| rollout/                 |              |
|    ep_len_mean           | 926          |
|    ep_rew_mean           | -828         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 38           |
|    time_elapsed          | 1120         |
|    total_timesteps       | 378880       |
| train/                   |              |
|    approx_kl             | 0.0010172634 |
|    clip_fraction         | 0.00107      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.42         |
|    cost_value_loss       | 2.8          |
|    cost_values           | 0.932        |
|    entropy               | -3.06        |
|    entropy_loss          | -3.07        |
|    explained_variance    | 0.717        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.7         |
|    n_updates             | 1840         |
|    policy_gradient_loss  | -0.000107    |
|    std                   | 1.12         |
|    value_loss            | 33.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.6176186  |
| rollout/                 |             |
|    ep_len_mean           | 926         |
|    ep_rew_mean           | -825        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 39          |
|    time_elapsed          | 1149        |
|    total_timesteps       | 380928      |
| train/                   |             |
|    approx_kl             | 0.007225864 |
|    clip_fraction         | 0.0215      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.968       |
|    cost_value_loss       | 0.499       |
|    cost_values           | 0.908       |
|    entropy               | -3.07       |
|    entropy_loss          | -3.06       |
|    explained_variance    | 0.921       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.75        |
|    n_updates             | 1850        |
|    policy_gradient_loss  | -0.00334    |
|    std                   | 1.12        |
|    value_loss            | 5.74        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.19        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.19        |
| reward                   | -0.96248776 |
| rollout/                 |             |
|    ep_len_mean           | 926         |
|    ep_rew_mean           | -818        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 40          |
|    time_elapsed          | 1178        |
|    total_timesteps       | 382976      |
| train/                   |             |
|    approx_kl             | 0.004642522 |
|    clip_fraction         | 0.0198      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.66        |
|    cost_value_loss       | 12.6        |
|    cost_values           | 1.01        |
|    entropy               | -3.06       |
|    entropy_loss          | -3.07       |
|    explained_variance    | 0.956       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 7.87        |
|    n_updates             | 1860        |
|    policy_gradient_loss  | -0.00373    |
|    std                   | 1.12        |
|    value_loss            | 3.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.42444107 |
| rollout/                 |             |
|    ep_len_mean           | 926         |
|    ep_rew_mean           | -816        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 41          |
|    time_elapsed          | 1209        |
|    total_timesteps       | 385024      |
| train/                   |             |
|    approx_kl             | 0.005599614 |
|    clip_fraction         | 0.0212      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.36        |
|    cost_value_loss       | 2.24        |
|    cost_values           | 0.908       |
|    entropy               | -3.06       |
|    entropy_loss          | -3.06       |
|    explained_variance    | 0.921       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.76        |
|    n_updates             | 1870        |
|    policy_gradient_loss  | -0.00378    |
|    std                   | 1.12        |
|    value_loss            | 8.18        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.8158269   |
| rollout/                 |              |
|    ep_len_mean           | 921          |
|    ep_rew_mean           | -813         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 42           |
|    time_elapsed          | 1239         |
|    total_timesteps       | 387072       |
| train/                   |              |
|    approx_kl             | 0.0033474728 |
|    clip_fraction         | 0.00522      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.74         |
|    cost_value_loss       | 4.36         |
|    cost_values           | 0.921        |
|    entropy               | -3.06        |
|    entropy_loss          | -3.06        |
|    explained_variance    | 0.853        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 7.24         |
|    n_updates             | 1880         |
|    policy_gradient_loss  | -0.0026      |
|    std                   | 1.12         |
|    value_loss            | 12.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.9562547   |
| rollout/                 |              |
|    ep_len_mean           | 921          |
|    ep_rew_mean           | -806         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 43           |
|    time_elapsed          | 1270         |
|    total_timesteps       | 389120       |
| train/                   |              |
|    approx_kl             | 0.0058501423 |
|    clip_fraction         | 0.0329       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.38         |
|    cost_value_loss       | 3.43         |
|    cost_values           | 0.861        |
|    entropy               | -3.06        |
|    entropy_loss          | -3.06        |
|    explained_variance    | 0.809        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.5         |
|    n_updates             | 1890         |
|    policy_gradient_loss  | -0.00342     |
|    std                   | 1.12         |
|    value_loss            | 27.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -0.9284976   |
| rollout/                 |              |
|    ep_len_mean           | 921          |
|    ep_rew_mean           | -801         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 44           |
|    time_elapsed          | 1299         |
|    total_timesteps       | 391168       |
| train/                   |              |
|    approx_kl             | 0.0061450237 |
|    clip_fraction         | 0.0592       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.13         |
|    cost_value_loss       | 1.42         |
|    cost_values           | 0.917        |
|    entropy               | -3.06        |
|    entropy_loss          | -3.06        |
|    explained_variance    | 0.605        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.49         |
|    n_updates             | 1900         |
|    policy_gradient_loss  | -0.00644     |
|    std                   | 1.12         |
|    value_loss            | 12.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.544        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.544        |
| reward                   | -0.7135616   |
| rollout/                 |              |
|    ep_len_mean           | 930          |
|    ep_rew_mean           | -806         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 45           |
|    time_elapsed          | 1329         |
|    total_timesteps       | 393216       |
| train/                   |              |
|    approx_kl             | 0.0058020945 |
|    clip_fraction         | 0.0434       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.867        |
|    cost_value_loss       | 0.283        |
|    cost_values           | 0.875        |
|    entropy               | -3.05        |
|    entropy_loss          | -3.06        |
|    explained_variance    | 0.273        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.39         |
|    n_updates             | 1910         |
|    policy_gradient_loss  | -0.00466     |
|    std                   | 1.11         |
|    value_loss            | 5.45         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.98         |
| reward                   | -0.74301535  |
| rollout/                 |              |
|    ep_len_mean           | 930          |
|    ep_rew_mean           | -796         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 46           |
|    time_elapsed          | 1359         |
|    total_timesteps       | 395264       |
| train/                   |              |
|    approx_kl             | 0.0033784418 |
|    clip_fraction         | 0.0113       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.6          |
|    cost_value_loss       | 3.84         |
|    cost_values           | 0.885        |
|    entropy               | -3.05        |
|    entropy_loss          | -3.05        |
|    explained_variance    | 0.946        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.05         |
|    n_updates             | 1920         |
|    policy_gradient_loss  | -0.00178     |
|    std                   | 1.11         |
|    value_loss            | 10.9         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8.01       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.01       |
| reward                   | -0.9757654 |
| rollout/                 |            |
|    ep_len_mean           | 938        |
|    ep_rew_mean           | -797       |
| time/                    |            |
|    fps                   | 69         |
|    iterations            | 47         |
|    time_elapsed          | 1389       |
|    total_timesteps       | 397312     |
| train/                   |            |
|    approx_kl             | 0.00420884 |
|    clip_fraction         | 0.0126     |
|    clip_range            | 0.2        |
|    cost_returns          | 1.92       |
|    cost_value_loss       | 7.28       |
|    cost_values           | 0.881      |
|    entropy               | -3.05      |
|    entropy_loss          | -3.05      |
|    explained_variance    | 0.928      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 10.3       |
|    n_updates             | 1930       |
|    policy_gradient_loss  | -0.00264   |
|    std                   | 1.11       |
|    value_loss            | 14.9       |
-----------------------------------------
------------------------------------------
| avg_speed                | 1.7         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.7         |
| reward                   | -0.6563764  |
| rollout/                 |             |
|    ep_len_mean           | 938         |
|    ep_rew_mean           | -793        |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 48          |
|    time_elapsed          | 1419        |
|    total_timesteps       | 399360      |
| train/                   |             |
|    approx_kl             | 0.005186994 |
|    clip_fraction         | 0.0289      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.17        |
|    cost_value_loss       | 5.56        |
|    cost_values           | 0.962       |
|    entropy               | -3.05       |
|    entropy_loss          | -3.05       |
|    explained_variance    | 0.914       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.71        |
|    n_updates             | 1940        |
|    policy_gradient_loss  | -0.00448    |
|    std                   | 1.11        |
|    value_loss            | 5.16        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.288        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.288        |
| reward                   | -0.6708529   |
| rollout/                 |              |
|    ep_len_mean           | 946          |
|    ep_rew_mean           | -795         |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 49           |
|    time_elapsed          | 1448         |
|    total_timesteps       | 401408       |
| train/                   |              |
|    approx_kl             | 0.0040935967 |
|    clip_fraction         | 0.0497       |
|    clip_range            | 0.2          |
|    cost_returns          | 0.805        |
|    cost_value_loss       | 0.0883       |
|    cost_values           | 0.859        |
|    entropy               | -3.02        |
|    entropy_loss          | -3.04        |
|    explained_variance    | 0.958        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 1.84         |
|    n_updates             | 1950         |
|    policy_gradient_loss  | -0.00602     |
|    std                   | 1.09         |
|    value_loss            | 4.17         |
-------------------------------------------
-----------------------------------
| avg_speed          | 6.02       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 6.02       |
| reward             | -0.6362671 |
| rollout/           |            |
|    ep_len_mean     | 952        |
|    ep_rew_mean     | -797       |
| time/              |            |
|    fps             | 73         |
|    iterations      | 1          |
|    time_elapsed    | 27         |
|    total_timesteps | 403456     |
-----------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.717836   |
| rollout/                 |             |
|    ep_len_mean           | 960         |
|    ep_rew_mean           | -799        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 2           |
|    time_elapsed          | 58          |
|    total_timesteps       | 405504      |
| train/                   |             |
|    approx_kl             | 0.004405546 |
|    clip_fraction         | 0.0386      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.28        |
|    cost_value_loss       | 5.95        |
|    cost_values           | 0.972       |
|    entropy               | -2.99       |
|    entropy_loss          | -3          |
|    explained_variance    | 0.973       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.65        |
|    n_updates             | 1970        |
|    policy_gradient_loss  | -0.00422    |
|    std                   | 1.08        |
|    value_loss            | 8.33        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.59         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.59         |
| reward                   | -0.6443777   |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -799         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 3            |
|    time_elapsed          | 86           |
|    total_timesteps       | 407552       |
| train/                   |              |
|    approx_kl             | 0.0061567724 |
|    clip_fraction         | 0.0191       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.39         |
|    cost_value_loss       | 1.77         |
|    cost_values           | 0.978        |
|    entropy               | -2.99        |
|    entropy_loss          | -2.99        |
|    explained_variance    | 0.943        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.07         |
|    n_updates             | 1980         |
|    policy_gradient_loss  | -0.00202     |
|    std                   | 1.08         |
|    value_loss            | 12.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.75         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.75         |
| reward                   | -0.8348136   |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -800         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 4            |
|    time_elapsed          | 115          |
|    total_timesteps       | 409600       |
| train/                   |              |
|    approx_kl             | 0.0064804307 |
|    clip_fraction         | 0.0533       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.07         |
|    cost_value_loss       | 0.865        |
|    cost_values           | 0.867        |
|    entropy               | -3           |
|    entropy_loss          | -2.99        |
|    explained_variance    | 0.882        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.39         |
|    n_updates             | 1990         |
|    policy_gradient_loss  | -0.00747     |
|    std                   | 1.08         |
|    value_loss            | 7.11         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.58         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.58         |
| reward                   | -1.3105713   |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -801         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 5            |
|    time_elapsed          | 143          |
|    total_timesteps       | 411648       |
| train/                   |              |
|    approx_kl             | 0.0040731807 |
|    clip_fraction         | 0.0306       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.56         |
|    cost_value_loss       | 2.88         |
|    cost_values           | 0.958        |
|    entropy               | -3           |
|    entropy_loss          | -3           |
|    explained_variance    | 0.852        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.88         |
|    n_updates             | 2000         |
|    policy_gradient_loss  | -0.00328     |
|    std                   | 1.08         |
|    value_loss            | 5.66         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.91         |
| reward                   | -0.93672705  |
| rollout/                 |              |
|    ep_len_mean           | 960          |
|    ep_rew_mean           | -785         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 6            |
|    time_elapsed          | 171          |
|    total_timesteps       | 413696       |
| train/                   |              |
|    approx_kl             | 0.0032394093 |
|    clip_fraction         | 0.00776      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.29         |
|    cost_value_loss       | 2.14         |
|    cost_values           | 0.917        |
|    entropy               | -2.99        |
|    entropy_loss          | -2.99        |
|    explained_variance    | 0.929        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.11         |
|    n_updates             | 2010         |
|    policy_gradient_loss  | -0.00254     |
|    std                   | 1.08         |
|    value_loss            | 10.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.87506384 |
| rollout/                 |             |
|    ep_len_mean           | 952         |
|    ep_rew_mean           | -768        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 7           |
|    time_elapsed          | 200         |
|    total_timesteps       | 415744      |
| train/                   |             |
|    approx_kl             | 0.009767617 |
|    clip_fraction         | 0.0944      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.9         |
|    cost_value_loss       | 7.57        |
|    cost_values           | 0.897       |
|    entropy               | -2.99       |
|    entropy_loss          | -2.99       |
|    explained_variance    | 0.966       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.98        |
|    n_updates             | 2020        |
|    policy_gradient_loss  | -0.00953    |
|    std                   | 1.08        |
|    value_loss            | 6.16        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -0.87224996  |
| rollout/                 |              |
|    ep_len_mean           | 952          |
|    ep_rew_mean           | -764         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 8            |
|    time_elapsed          | 229          |
|    total_timesteps       | 417792       |
| train/                   |              |
|    approx_kl             | 0.0037083498 |
|    clip_fraction         | 0.0157       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.77         |
|    cost_value_loss       | 3.76         |
|    cost_values           | 0.922        |
|    entropy               | -2.99        |
|    entropy_loss          | -2.99        |
|    explained_variance    | 0.769        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.1         |
|    n_updates             | 2030         |
|    policy_gradient_loss  | -0.00313     |
|    std                   | 1.08         |
|    value_loss            | 25.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -0.84292126 |
| rollout/                 |             |
|    ep_len_mean           | 945         |
|    ep_rew_mean           | -754        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 9           |
|    time_elapsed          | 258         |
|    total_timesteps       | 419840      |
| train/                   |             |
|    approx_kl             | 0.003331759 |
|    clip_fraction         | 0.0288      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.52        |
|    cost_value_loss       | 2.62        |
|    cost_values           | 0.978       |
|    entropy               | -3          |
|    entropy_loss          | -2.99       |
|    explained_variance    | 0.696       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.29        |
|    n_updates             | 2040        |
|    policy_gradient_loss  | -0.00316    |
|    std                   | 1.08        |
|    value_loss            | 7.6         |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.73         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.73         |
| reward                   | -0.17251462  |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -747         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 10           |
|    time_elapsed          | 287          |
|    total_timesteps       | 421888       |
| train/                   |              |
|    approx_kl             | 0.0026538444 |
|    clip_fraction         | 0.00239      |
|    clip_range            | 0.2          |
|    cost_returns          | 1.33         |
|    cost_value_loss       | 1.52         |
|    cost_values           | 0.959        |
|    entropy               | -3           |
|    entropy_loss          | -3           |
|    explained_variance    | 0.813        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.4         |
|    n_updates             | 2050         |
|    policy_gradient_loss  | -0.00139     |
|    std                   | 1.08         |
|    value_loss            | 25           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 2.7          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.7          |
| reward                   | -0.9510558   |
| rollout/                 |              |
|    ep_len_mean           | 929          |
|    ep_rew_mean           | -740         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 11           |
|    time_elapsed          | 315          |
|    total_timesteps       | 423936       |
| train/                   |              |
|    approx_kl             | 0.0035822988 |
|    clip_fraction         | 0.00732      |
|    clip_range            | 0.2          |
|    cost_returns          | 2.39         |
|    cost_value_loss       | 6.47         |
|    cost_values           | 0.986        |
|    entropy               | -3           |
|    entropy_loss          | -3           |
|    explained_variance    | 0.803        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.7         |
|    n_updates             | 2060         |
|    policy_gradient_loss  | -0.00166     |
|    std                   | 1.08         |
|    value_loss            | 47           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -1.0223848  |
| rollout/                 |             |
|    ep_len_mean           | 929         |
|    ep_rew_mean           | -737        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 12          |
|    time_elapsed          | 343         |
|    total_timesteps       | 425984      |
| train/                   |             |
|    approx_kl             | 0.006757018 |
|    clip_fraction         | 0.032       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.8         |
|    cost_value_loss       | 3.1         |
|    cost_values           | 0.971       |
|    entropy               | -3          |
|    entropy_loss          | -3          |
|    explained_variance    | 0.859       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 13.1        |
|    n_updates             | 2070        |
|    policy_gradient_loss  | -0.00478    |
|    std                   | 1.08        |
|    value_loss            | 23.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6409601   |
| rollout/                 |              |
|    ep_len_mean           | 929          |
|    ep_rew_mean           | -727         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 13           |
|    time_elapsed          | 372          |
|    total_timesteps       | 428032       |
| train/                   |              |
|    approx_kl             | 0.0045133517 |
|    clip_fraction         | 0.0377       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.34         |
|    cost_value_loss       | 1.24         |
|    cost_values           | 0.95         |
|    entropy               | -2.99        |
|    entropy_loss          | -2.99        |
|    explained_variance    | 0.617        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.75         |
|    n_updates             | 2080         |
|    policy_gradient_loss  | -0.00461     |
|    std                   | 1.08         |
|    value_loss            | 12.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.61        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.61        |
| reward                   | -0.6212191  |
| rollout/                 |             |
|    ep_len_mean           | 929         |
|    ep_rew_mean           | -729        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 14          |
|    time_elapsed          | 399         |
|    total_timesteps       | 430080      |
| train/                   |             |
|    approx_kl             | 0.007507354 |
|    clip_fraction         | 0.0472      |
|    clip_range            | 0.2         |
|    cost_returns          | 0.896       |
|    cost_value_loss       | 0.212       |
|    cost_values           | 0.92        |
|    entropy               | -2.99       |
|    entropy_loss          | -2.99       |
|    explained_variance    | 0.15        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.68        |
|    n_updates             | 2090        |
|    policy_gradient_loss  | -0.00416    |
|    std                   | 1.08        |
|    value_loss            | 5.28        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.45         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.45         |
| reward                   | -0.88165975  |
| rollout/                 |              |
|    ep_len_mean           | 924          |
|    ep_rew_mean           | -718         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 15           |
|    time_elapsed          | 427          |
|    total_timesteps       | 432128       |
| train/                   |              |
|    approx_kl             | 0.0062239496 |
|    clip_fraction         | 0.0705       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.35         |
|    cost_value_loss       | 1.84         |
|    cost_values           | 0.913        |
|    entropy               | -2.99        |
|    entropy_loss          | -2.99        |
|    explained_variance    | 0.716        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.88         |
|    n_updates             | 2100         |
|    policy_gradient_loss  | -0.000777    |
|    std                   | 1.08         |
|    value_loss            | 11.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.46         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.46         |
| reward                   | -0.36276644  |
| rollout/                 |              |
|    ep_len_mean           | 924          |
|    ep_rew_mean           | -713         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 16           |
|    time_elapsed          | 456          |
|    total_timesteps       | 434176       |
| train/                   |              |
|    approx_kl             | 0.0049098283 |
|    clip_fraction         | 0.0323       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.51         |
|    cost_value_loss       | 2.11         |
|    cost_values           | 0.977        |
|    entropy               | -2.99        |
|    entropy_loss          | -2.99        |
|    explained_variance    | 0.671        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.9          |
|    n_updates             | 2110         |
|    policy_gradient_loss  | -0.00331     |
|    std                   | 1.08         |
|    value_loss            | 38.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.61787015  |
| rollout/                 |              |
|    ep_len_mean           | 924          |
|    ep_rew_mean           | -709         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 17           |
|    time_elapsed          | 484          |
|    total_timesteps       | 436224       |
| train/                   |              |
|    approx_kl             | 0.0034179778 |
|    clip_fraction         | 0.0177       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.77         |
|    cost_value_loss       | 3.44         |
|    cost_values           | 0.962        |
|    entropy               | -2.98        |
|    entropy_loss          | -2.99        |
|    explained_variance    | 0.892        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.08         |
|    n_updates             | 2120         |
|    policy_gradient_loss  | -0.00285     |
|    std                   | 1.08         |
|    value_loss            | 8.2          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.67         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.67         |
| reward                   | -0.52321136  |
| rollout/                 |              |
|    ep_len_mean           | 924          |
|    ep_rew_mean           | -707         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 18           |
|    time_elapsed          | 512          |
|    total_timesteps       | 438272       |
| train/                   |              |
|    approx_kl             | 0.0035989606 |
|    clip_fraction         | 0.0347       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.14         |
|    cost_value_loss       | 6.74         |
|    cost_values           | 1.04         |
|    entropy               | -2.98        |
|    entropy_loss          | -2.98        |
|    explained_variance    | 0.87         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.33         |
|    n_updates             | 2130         |
|    policy_gradient_loss  | -0.00376     |
|    std                   | 1.07         |
|    value_loss            | 7.23         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.8          |
| reward                   | -0.74596095  |
| rollout/                 |              |
|    ep_len_mean           | 924          |
|    ep_rew_mean           | -703         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 19           |
|    time_elapsed          | 541          |
|    total_timesteps       | 440320       |
| train/                   |              |
|    approx_kl             | 0.0040839594 |
|    clip_fraction         | 0.0233       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.67         |
|    cost_value_loss       | 2.42         |
|    cost_values           | 1.04         |
|    entropy               | -2.98        |
|    entropy_loss          | -2.98        |
|    explained_variance    | 0.83         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.49         |
|    n_updates             | 2140         |
|    policy_gradient_loss  | -0.0026      |
|    std                   | 1.07         |
|    value_loss            | 8.97         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.782412   |
| rollout/                 |             |
|    ep_len_mean           | 924         |
|    ep_rew_mean           | -697        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 20          |
|    time_elapsed          | 569         |
|    total_timesteps       | 442368      |
| train/                   |             |
|    approx_kl             | 0.009806125 |
|    clip_fraction         | 0.0723      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.34        |
|    cost_value_loss       | 1.02        |
|    cost_values           | 0.977       |
|    entropy               | -2.97       |
|    entropy_loss          | -2.98       |
|    explained_variance    | 0.949       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.49        |
|    n_updates             | 2150        |
|    policy_gradient_loss  | -0.0076     |
|    std                   | 1.07        |
|    value_loss            | 3.04        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.62         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.62         |
| reward                   | -0.8725491   |
| rollout/                 |              |
|    ep_len_mean           | 932          |
|    ep_rew_mean           | -700         |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 21           |
|    time_elapsed          | 596          |
|    total_timesteps       | 444416       |
| train/                   |              |
|    approx_kl             | 0.0043658335 |
|    clip_fraction         | 0.0272       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.76         |
|    cost_value_loss       | 2.65         |
|    cost_values           | 1.09         |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.0444       |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.92         |
|    n_updates             | 2160         |
|    policy_gradient_loss  | -0.00409     |
|    std                   | 1.07         |
|    value_loss            | 10.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.45        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.45        |
| reward                   | -0.67152196 |
| rollout/                 |             |
|    ep_len_mean           | 924         |
|    ep_rew_mean           | -690        |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 22          |
|    time_elapsed          | 624         |
|    total_timesteps       | 446464      |
| train/                   |             |
|    approx_kl             | 0.010055912 |
|    clip_fraction         | 0.154       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.06        |
|    cost_value_loss       | 2.62        |
|    cost_values           | 1.43        |
|    entropy               | -2.97       |
|    entropy_loss          | -2.97       |
|    explained_variance    | 0.551       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.32        |
|    n_updates             | 2170        |
|    policy_gradient_loss  | -0.0136     |
|    std                   | 1.07        |
|    value_loss            | 6.09        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.88        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.88        |
| reward                   | -0.73113674 |
| rollout/                 |             |
|    ep_len_mean           | 924         |
|    ep_rew_mean           | -686        |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 23          |
|    time_elapsed          | 653         |
|    total_timesteps       | 448512      |
| train/                   |             |
|    approx_kl             | 0.004523639 |
|    clip_fraction         | 0.0292      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.21        |
|    cost_value_loss       | 3.76        |
|    cost_values           | 1.34        |
|    entropy               | -2.97       |
|    entropy_loss          | -2.97       |
|    explained_variance    | 0.5         |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 23.5        |
|    n_updates             | 2180        |
|    policy_gradient_loss  | -0.000861   |
|    std                   | 1.07        |
|    value_loss            | 46.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.9         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.9         |
| reward                   | -0.46725076 |
| rollout/                 |             |
|    ep_len_mean           | 924         |
|    ep_rew_mean           | -684        |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 24          |
|    time_elapsed          | 681         |
|    total_timesteps       | 450560      |
| train/                   |             |
|    approx_kl             | 0.003401618 |
|    clip_fraction         | 0.0315      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.71        |
|    cost_value_loss       | 3.48        |
|    cost_values           | 1.11        |
|    entropy               | -2.97       |
|    entropy_loss          | -2.97       |
|    explained_variance    | 0.837       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.76        |
|    n_updates             | 2190        |
|    policy_gradient_loss  | -0.00334    |
|    std                   | 1.07        |
|    value_loss            | 5.34        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.53188056  |
| rollout/                 |              |
|    ep_len_mean           | 924          |
|    ep_rew_mean           | -682         |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 25           |
|    time_elapsed          | 710          |
|    total_timesteps       | 452608       |
| train/                   |              |
|    approx_kl             | 0.0070262514 |
|    clip_fraction         | 0.0563       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.81         |
|    cost_value_loss       | 3.66         |
|    cost_values           | 0.954        |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.822        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.48         |
|    n_updates             | 2200         |
|    policy_gradient_loss  | -0.00628     |
|    std                   | 1.07         |
|    value_loss            | 4.7          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.6          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.6          |
| reward                   | -0.6924345   |
| rollout/                 |              |
|    ep_len_mean           | 938          |
|    ep_rew_mean           | -691         |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 26           |
|    time_elapsed          | 738          |
|    total_timesteps       | 454656       |
| train/                   |              |
|    approx_kl             | 0.0057409634 |
|    clip_fraction         | 0.0531       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.06         |
|    cost_value_loss       | 0.481        |
|    cost_values           | 0.935        |
|    entropy               | -2.97        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.788        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.37         |
|    n_updates             | 2210         |
|    policy_gradient_loss  | -0.00635     |
|    std                   | 1.07         |
|    value_loss            | 11.7         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.8968219  |
| rollout/                 |             |
|    ep_len_mean           | 931         |
|    ep_rew_mean           | -684        |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 27          |
|    time_elapsed          | 766         |
|    total_timesteps       | 456704      |
| train/                   |             |
|    approx_kl             | 0.005532938 |
|    clip_fraction         | 0.0421      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.16        |
|    cost_value_loss       | 0.725       |
|    cost_values           | 0.957       |
|    entropy               | -2.97       |
|    entropy_loss          | -2.97       |
|    explained_variance    | 0.779       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.13        |
|    n_updates             | 2220        |
|    policy_gradient_loss  | -0.00505    |
|    std                   | 1.07        |
|    value_loss            | 5.42        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.82         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.82         |
| reward                   | -0.5811576   |
| rollout/                 |              |
|    ep_len_mean           | 931          |
|    ep_rew_mean           | -682         |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 28           |
|    time_elapsed          | 795          |
|    total_timesteps       | 458752       |
| train/                   |              |
|    approx_kl             | 0.0063578812 |
|    clip_fraction         | 0.0453       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.61         |
|    cost_value_loss       | 2.83         |
|    cost_values           | 0.944        |
|    entropy               | -2.96        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.486        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10           |
|    n_updates             | 2230         |
|    policy_gradient_loss  | -0.00413     |
|    std                   | 1.07         |
|    value_loss            | 25           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.87         |
| reward                   | -0.9203683   |
| rollout/                 |              |
|    ep_len_mean           | 931          |
|    ep_rew_mean           | -681         |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 29           |
|    time_elapsed          | 824          |
|    total_timesteps       | 460800       |
| train/                   |              |
|    approx_kl             | 0.0055106487 |
|    clip_fraction         | 0.038        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.44         |
|    cost_value_loss       | 5.47         |
|    cost_values           | 1.12         |
|    entropy               | -2.96        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.334        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 30.5         |
|    n_updates             | 2240         |
|    policy_gradient_loss  | -0.00226     |
|    std                   | 1.06         |
|    value_loss            | 27.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.5219757   |
| rollout/                 |              |
|    ep_len_mean           | 931          |
|    ep_rew_mean           | -682         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 30           |
|    time_elapsed          | 853          |
|    total_timesteps       | 462848       |
| train/                   |              |
|    approx_kl             | 0.0060427776 |
|    clip_fraction         | 0.0266       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.66         |
|    cost_value_loss       | 1.88         |
|    cost_values           | 1.22         |
|    entropy               | -2.96        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.806        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 2.89         |
|    n_updates             | 2250         |
|    policy_gradient_loss  | -0.00184     |
|    std                   | 1.06         |
|    value_loss            | 5.74         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.69299674 |
| rollout/                 |             |
|    ep_len_mean           | 935         |
|    ep_rew_mean           | -683        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 31          |
|    time_elapsed          | 882         |
|    total_timesteps       | 464896      |
| train/                   |             |
|    approx_kl             | 0.008854438 |
|    clip_fraction         | 0.0791      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.08        |
|    cost_value_loss       | 3.44        |
|    cost_values           | 1.4         |
|    entropy               | -2.96       |
|    entropy_loss          | -2.96       |
|    explained_variance    | 0.783       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.93        |
|    n_updates             | 2260        |
|    policy_gradient_loss  | -0.00694    |
|    std                   | 1.06        |
|    value_loss            | 3.13        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.2         |
| reward                   | -0.93706274 |
| rollout/                 |             |
|    ep_len_mean           | 935         |
|    ep_rew_mean           | -680        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 32          |
|    time_elapsed          | 910         |
|    total_timesteps       | 466944      |
| train/                   |             |
|    approx_kl             | 0.007302575 |
|    clip_fraction         | 0.0942      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.4         |
|    cost_value_loss       | 2.71        |
|    cost_values           | 1.82        |
|    entropy               | -2.96       |
|    entropy_loss          | -2.96       |
|    explained_variance    | 0.601       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.57        |
|    n_updates             | 2270        |
|    policy_gradient_loss  | -0.00795    |
|    std                   | 1.07        |
|    value_loss            | 9.68        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.5289265  |
| rollout/                 |             |
|    ep_len_mean           | 927         |
|    ep_rew_mean           | -670        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 33          |
|    time_elapsed          | 939         |
|    total_timesteps       | 468992      |
| train/                   |             |
|    approx_kl             | 0.004533179 |
|    clip_fraction         | 0.0518      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.94        |
|    cost_value_loss       | 3.25        |
|    cost_values           | 1.49        |
|    entropy               | -2.97       |
|    entropy_loss          | -2.97       |
|    explained_variance    | 0.883       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.87        |
|    n_updates             | 2280        |
|    policy_gradient_loss  | -0.00484    |
|    std                   | 1.07        |
|    value_loss            | 5.3         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.8512399  |
| rollout/                 |             |
|    ep_len_mean           | 932         |
|    ep_rew_mean           | -670        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 34          |
|    time_elapsed          | 968         |
|    total_timesteps       | 471040      |
| train/                   |             |
|    approx_kl             | 0.006464241 |
|    clip_fraction         | 0.039       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.43        |
|    cost_value_loss       | 3.67        |
|    cost_values           | 1.39        |
|    entropy               | -2.97       |
|    entropy_loss          | -2.97       |
|    explained_variance    | 0.721       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 18          |
|    n_updates             | 2290        |
|    policy_gradient_loss  | -0.00397    |
|    std                   | 1.07        |
|    value_loss            | 38.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.5580108   |
| rollout/                 |              |
|    ep_len_mean           | 932          |
|    ep_rew_mean           | -668         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 35           |
|    time_elapsed          | 996          |
|    total_timesteps       | 473088       |
| train/                   |              |
|    approx_kl             | 0.0072498885 |
|    clip_fraction         | 0.067        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.26         |
|    cost_value_loss       | 3.43         |
|    cost_values           | 1.47         |
|    entropy               | -2.96        |
|    entropy_loss          | -2.97        |
|    explained_variance    | 0.246        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 11.3         |
|    n_updates             | 2300         |
|    policy_gradient_loss  | -0.00394     |
|    std                   | 1.06         |
|    value_loss            | 28.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.77         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.77         |
| reward                   | -0.55594724  |
| rollout/                 |              |
|    ep_len_mean           | 932          |
|    ep_rew_mean           | -668         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 36           |
|    time_elapsed          | 1024         |
|    total_timesteps       | 475136       |
| train/                   |              |
|    approx_kl             | 0.0044154446 |
|    clip_fraction         | 0.0444       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.59         |
|    cost_value_loss       | 6.46         |
|    cost_values           | 1.48         |
|    entropy               | -2.96        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.69         |
|    lagrangian_multiplier | 0.000239     |
|    learning_rate         | 0.0003       |
|    loss                  | 4.56         |
|    n_updates             | 2310         |
|    policy_gradient_loss  | -0.00432     |
|    std                   | 1.06         |
|    value_loss            | 4.8          |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.98         |
| reward                   | -0.5945963   |
| rollout/                 |              |
|    ep_len_mean           | 932          |
|    ep_rew_mean           | -667         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 37           |
|    time_elapsed          | 1053         |
|    total_timesteps       | 477184       |
| train/                   |              |
|    approx_kl             | 0.0027394528 |
|    clip_fraction         | 0.0125       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.66         |
|    cost_value_loss       | 1.2          |
|    cost_values           | 1.35         |
|    entropy               | -2.96        |
|    entropy_loss          | -2.96        |
|    explained_variance    | 0.61         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.63         |
|    n_updates             | 2320         |
|    policy_gradient_loss  | -0.00274     |
|    std                   | 1.06         |
|    value_loss            | 9.43         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.6725472  |
| rollout/                 |             |
|    ep_len_mean           | 937         |
|    ep_rew_mean           | -670        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 38          |
|    time_elapsed          | 1081        |
|    total_timesteps       | 479232      |
| train/                   |             |
|    approx_kl             | 0.009579109 |
|    clip_fraction         | 0.117       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.64        |
|    cost_value_loss       | 2.27        |
|    cost_values           | 1.08        |
|    entropy               | -2.95       |
|    entropy_loss          | -2.96       |
|    explained_variance    | 0.787       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.84        |
|    n_updates             | 2330        |
|    policy_gradient_loss  | -0.011      |
|    std                   | 1.06        |
|    value_loss            | 7           |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.80426544 |
| rollout/                 |             |
|    ep_len_mean           | 937         |
|    ep_rew_mean           | -665        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 39          |
|    time_elapsed          | 1110        |
|    total_timesteps       | 481280      |
| train/                   |             |
|    approx_kl             | 0.007196705 |
|    clip_fraction         | 0.0677      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.65        |
|    cost_value_loss       | 2.12        |
|    cost_values           | 1.04        |
|    entropy               | -2.95       |
|    entropy_loss          | -2.95       |
|    explained_variance    | -1.17       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.29        |
|    n_updates             | 2340        |
|    policy_gradient_loss  | -0.00769    |
|    std                   | 1.06        |
|    value_loss            | 4.14        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.46        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.46        |
| reward                   | -0.5162719  |
| rollout/                 |             |
|    ep_len_mean           | 937         |
|    ep_rew_mean           | -663        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 40          |
|    time_elapsed          | 1139        |
|    total_timesteps       | 483328      |
| train/                   |             |
|    approx_kl             | 0.010843463 |
|    clip_fraction         | 0.108       |
|    clip_range            | 0.2         |
|    cost_returns          | 1.11        |
|    cost_value_loss       | 0.667       |
|    cost_values           | 0.977       |
|    entropy               | -2.94       |
|    entropy_loss          | -2.94       |
|    explained_variance    | 0.486       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.26        |
|    n_updates             | 2350        |
|    policy_gradient_loss  | -0.00874    |
|    std                   | 1.05        |
|    value_loss            | 4.32        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.87        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.87        |
| reward                   | -0.74536204 |
| rollout/                 |             |
|    ep_len_mean           | 931         |
|    ep_rew_mean           | -652        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 41          |
|    time_elapsed          | 1167        |
|    total_timesteps       | 485376      |
| train/                   |             |
|    approx_kl             | 0.005590415 |
|    clip_fraction         | 0.071       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.1         |
|    cost_value_loss       | 6.56        |
|    cost_values           | 0.92        |
|    entropy               | -2.94       |
|    entropy_loss          | -2.93       |
|    explained_variance    | 0.883       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.22        |
|    n_updates             | 2360        |
|    policy_gradient_loss  | -0.000982   |
|    std                   | 1.05        |
|    value_loss            | 3.49        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.45         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.45         |
| reward                   | -0.29294398  |
| rollout/                 |              |
|    ep_len_mean           | 931          |
|    ep_rew_mean           | -650         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 42           |
|    time_elapsed          | 1196         |
|    total_timesteps       | 487424       |
| train/                   |              |
|    approx_kl             | 0.0035968178 |
|    clip_fraction         | 0.0309       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.84         |
|    cost_value_loss       | 9.73         |
|    cost_values           | 1.01         |
|    entropy               | -2.94        |
|    entropy_loss          | -2.94        |
|    explained_variance    | 0.421        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.4         |
|    n_updates             | 2370         |
|    policy_gradient_loss  | -0.00337     |
|    std                   | 1.05         |
|    value_loss            | 25.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.28         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.28         |
| reward                   | -0.41730535  |
| rollout/                 |              |
|    ep_len_mean           | 931          |
|    ep_rew_mean           | -646         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 43           |
|    time_elapsed          | 1225         |
|    total_timesteps       | 489472       |
| train/                   |              |
|    approx_kl             | 0.0050196717 |
|    clip_fraction         | 0.048        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.38         |
|    cost_value_loss       | 46.8         |
|    cost_values           | 1.26         |
|    entropy               | -2.93        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.813        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 25.9         |
|    n_updates             | 2380         |
|    policy_gradient_loss  | -0.0054      |
|    std                   | 1.05         |
|    value_loss            | 5.75         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.4         |
| reward                   | -0.42993864 |
| rollout/                 |             |
|    ep_len_mean           | 917         |
|    ep_rew_mean           | -631        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 44          |
|    time_elapsed          | 1254        |
|    total_timesteps       | 491520      |
| train/                   |             |
|    approx_kl             | 0.008764737 |
|    clip_fraction         | 0.0463      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.55        |
|    cost_value_loss       | 4.42        |
|    cost_values           | 1.55        |
|    entropy               | -2.94       |
|    entropy_loss          | -2.94       |
|    explained_variance    | 0.315       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.79        |
|    n_updates             | 2390        |
|    policy_gradient_loss  | -0.0075     |
|    std                   | 1.06        |
|    value_loss            | 4.82        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.51852024 |
| rollout/                 |             |
|    ep_len_mean           | 917         |
|    ep_rew_mean           | -630        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 45          |
|    time_elapsed          | 1283        |
|    total_timesteps       | 493568      |
| train/                   |             |
|    approx_kl             | 0.005741489 |
|    clip_fraction         | 0.0261      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.69        |
|    cost_value_loss       | 4.56        |
|    cost_values           | 1.58        |
|    entropy               | -2.95       |
|    entropy_loss          | -2.95       |
|    explained_variance    | 0.506       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14.1        |
|    n_updates             | 2400        |
|    policy_gradient_loss  | -0.0042     |
|    std                   | 1.06        |
|    value_loss            | 26.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.89        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.89        |
| reward                   | -0.43761253 |
| rollout/                 |             |
|    ep_len_mean           | 917         |
|    ep_rew_mean           | -631        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 46          |
|    time_elapsed          | 1312        |
|    total_timesteps       | 495616      |
| train/                   |             |
|    approx_kl             | 0.004127403 |
|    clip_fraction         | 0.0288      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.19        |
|    cost_value_loss       | 3.81        |
|    cost_values           | 1.38        |
|    entropy               | -2.94       |
|    entropy_loss          | -2.94       |
|    explained_variance    | 0.857       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.92        |
|    n_updates             | 2410        |
|    policy_gradient_loss  | -0.00392    |
|    std                   | 1.06        |
|    value_loss            | 4.63        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.24938262 |
| rollout/                 |             |
|    ep_len_mean           | 917         |
|    ep_rew_mean           | -628        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 47          |
|    time_elapsed          | 1342        |
|    total_timesteps       | 497664      |
| train/                   |             |
|    approx_kl             | 0.003030786 |
|    clip_fraction         | 0.0279      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.14        |
|    cost_value_loss       | 2.96        |
|    cost_values           | 1.35        |
|    entropy               | -2.94       |
|    entropy_loss          | -2.94       |
|    explained_variance    | 0.928       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.27        |
|    n_updates             | 2420        |
|    policy_gradient_loss  | -0.00347    |
|    std                   | 1.05        |
|    value_loss            | 4.82        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -0.223455    |
| rollout/                 |              |
|    ep_len_mean           | 911          |
|    ep_rew_mean           | -619         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 48           |
|    time_elapsed          | 1370         |
|    total_timesteps       | 499712       |
| train/                   |              |
|    approx_kl             | 0.0052182805 |
|    clip_fraction         | 0.0401       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.8          |
|    cost_value_loss       | 6.48         |
|    cost_values           | 1.27         |
|    entropy               | -2.93        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.499        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.55         |
|    n_updates             | 2430         |
|    policy_gradient_loss  | -0.00446     |
|    std                   | 1.05         |
|    value_loss            | 4.46         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.77         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.77         |
| reward                   | -0.50332665  |
| rollout/                 |              |
|    ep_len_mean           | 904          |
|    ep_rew_mean           | -607         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 49           |
|    time_elapsed          | 1399         |
|    total_timesteps       | 501760       |
| train/                   |              |
|    approx_kl             | 0.0061160484 |
|    clip_fraction         | 0.0692       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.92         |
|    cost_value_loss       | 2.04         |
|    cost_values           | 1.45         |
|    entropy               | -2.93        |
|    entropy_loss          | -2.93        |
|    explained_variance    | 0.69         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.6         |
|    n_updates             | 2440         |
|    policy_gradient_loss  | -0.00563     |
|    std                   | 1.05         |
|    value_loss            | 25           |
-------------------------------------------
-----------------------------------
| avg_speed          | 8          |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8          |
| reward             | -0.5493222 |
| rollout/           |            |
|    ep_len_mean     | 904        |
|    ep_rew_mean     | -605       |
| time/              |            |
|    fps             | 76         |
|    iterations      | 1          |
|    time_elapsed    | 26         |
|    total_timesteps | 503808     |
-----------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.9211219  |
| rollout/                 |             |
|    ep_len_mean           | 912         |
|    ep_rew_mean           | -607        |
| time/                    |             |
|    fps                   | 74          |
|    iterations            | 2           |
|    time_elapsed          | 55          |
|    total_timesteps       | 505856      |
| train/                   |             |
|    approx_kl             | 0.013745492 |
|    clip_fraction         | 0.112       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.11        |
|    cost_value_loss       | 4.55        |
|    cost_values           | 1.4         |
|    entropy               | -2.92       |
|    entropy_loss          | -2.93       |
|    explained_variance    | 0.869       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.15        |
|    n_updates             | 2460        |
|    policy_gradient_loss  | -0.0117     |
|    std                   | 1.05        |
|    value_loss            | 6.33        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -0.52678883  |
| rollout/                 |              |
|    ep_len_mean           | 912          |
|    ep_rew_mean           | -607         |
| time/                    |              |
|    fps                   | 73           |
|    iterations            | 3            |
|    time_elapsed          | 83           |
|    total_timesteps       | 507904       |
| train/                   |              |
|    approx_kl             | 0.0072092665 |
|    clip_fraction         | 0.0515       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.34         |
|    cost_value_loss       | 14.3         |
|    cost_values           | 1.41         |
|    entropy               | -2.92        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.529        |
|    lagrangian_multiplier | 0.00358      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.07         |
|    n_updates             | 2470         |
|    policy_gradient_loss  | -0.00628     |
|    std                   | 1.04         |
|    value_loss            | 3.42         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.511644   |
| rollout/                 |             |
|    ep_len_mean           | 910         |
|    ep_rew_mean           | -601        |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 4           |
|    time_elapsed          | 112         |
|    total_timesteps       | 509952      |
| train/                   |             |
|    approx_kl             | 0.005911437 |
|    clip_fraction         | 0.0479      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.55        |
|    cost_value_loss       | 10.4        |
|    cost_values           | 1.59        |
|    entropy               | -2.91       |
|    entropy_loss          | -2.92       |
|    explained_variance    | 0.32        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.27        |
|    n_updates             | 2480        |
|    policy_gradient_loss  | -0.00628    |
|    std                   | 1.04        |
|    value_loss            | 4.13        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.98         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.98         |
| reward                   | -0.72640556  |
| rollout/                 |              |
|    ep_len_mean           | 918          |
|    ep_rew_mean           | -605         |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 5            |
|    time_elapsed          | 140          |
|    total_timesteps       | 512000       |
| train/                   |              |
|    approx_kl             | 0.0049674907 |
|    clip_fraction         | 0.0491       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.27         |
|    cost_value_loss       | 2.76         |
|    cost_values           | 1.61         |
|    entropy               | -2.91        |
|    entropy_loss          | -2.91        |
|    explained_variance    | 0.526        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.63         |
|    n_updates             | 2490         |
|    policy_gradient_loss  | -0.00414     |
|    std                   | 1.04         |
|    value_loss            | 14.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.8210762  |
| rollout/                 |             |
|    ep_len_mean           | 925         |
|    ep_rew_mean           | -608        |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 6           |
|    time_elapsed          | 169         |
|    total_timesteps       | 514048      |
| train/                   |             |
|    approx_kl             | 0.008258204 |
|    clip_fraction         | 0.0834      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.56        |
|    cost_value_loss       | 0.63        |
|    cost_values           | 1.46        |
|    entropy               | -2.9        |
|    entropy_loss          | -2.91       |
|    explained_variance    | 0.715       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 1.65        |
|    n_updates             | 2500        |
|    policy_gradient_loss  | -0.00844    |
|    std                   | 1.04        |
|    value_loss            | 3.39        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.52        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.52        |
| reward                   | -0.47949398 |
| rollout/                 |             |
|    ep_len_mean           | 925         |
|    ep_rew_mean           | -609        |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 7           |
|    time_elapsed          | 197         |
|    total_timesteps       | 516096      |
| train/                   |             |
|    approx_kl             | 0.008313844 |
|    clip_fraction         | 0.0786      |
|    clip_range            | 0.2         |
|    cost_returns          | 1.65        |
|    cost_value_loss       | 2.27        |
|    cost_values           | 1.08        |
|    entropy               | -2.9        |
|    entropy_loss          | -2.9        |
|    explained_variance    | 0.508       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.73        |
|    n_updates             | 2510        |
|    policy_gradient_loss  | -0.00776    |
|    std                   | 1.03        |
|    value_loss            | 4.26        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.7          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.7          |
| reward                   | -0.72170013  |
| rollout/                 |              |
|    ep_len_mean           | 929          |
|    ep_rew_mean           | -607         |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 8            |
|    time_elapsed          | 227          |
|    total_timesteps       | 518144       |
| train/                   |              |
|    approx_kl             | 0.0043375837 |
|    clip_fraction         | 0.0394       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.13         |
|    cost_value_loss       | 3.82         |
|    cost_values           | 1.3          |
|    entropy               | -2.89        |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.819        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.91         |
|    n_updates             | 2520         |
|    policy_gradient_loss  | -0.00641     |
|    std                   | 1.03         |
|    value_loss            | 5.35         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8.01       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8.01       |
| reward                   | -0.6190132 |
| rollout/                 |            |
|    ep_len_mean           | 928        |
|    ep_rew_mean           | -603       |
| time/                    |            |
|    fps                   | 72         |
|    iterations            | 9          |
|    time_elapsed          | 255        |
|    total_timesteps       | 520192     |
| train/                   |            |
|    approx_kl             | 0.00738006 |
|    clip_fraction         | 0.0789     |
|    clip_range            | 0.2        |
|    cost_returns          | 2.82       |
|    cost_value_loss       | 7.15       |
|    cost_values           | 1.15       |
|    entropy               | -2.88      |
|    entropy_loss          | -2.88      |
|    explained_variance    | 0.615      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 8.67       |
|    n_updates             | 2530       |
|    policy_gradient_loss  | -0.00484   |
|    std                   | 1.03       |
|    value_loss            | 12.3       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 7.55         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.55         |
| reward                   | -0.555331    |
| rollout/                 |              |
|    ep_len_mean           | 928          |
|    ep_rew_mean           | -600         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 10           |
|    time_elapsed          | 284          |
|    total_timesteps       | 522240       |
| train/                   |              |
|    approx_kl             | 0.0055309716 |
|    clip_fraction         | 0.0457       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.66         |
|    cost_value_loss       | 5.73         |
|    cost_values           | 1.16         |
|    entropy               | -2.88        |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.284        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 15.6         |
|    n_updates             | 2540         |
|    policy_gradient_loss  | -0.00367     |
|    std                   | 1.03         |
|    value_loss            | 17.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.06         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.06         |
| reward                   | -0.4253751   |
| rollout/                 |              |
|    ep_len_mean           | 928          |
|    ep_rew_mean           | -600         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 11           |
|    time_elapsed          | 313          |
|    total_timesteps       | 524288       |
| train/                   |              |
|    approx_kl             | 0.0066233566 |
|    clip_fraction         | 0.0583       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.05         |
|    cost_value_loss       | 2.93         |
|    cost_values           | 1.23         |
|    entropy               | -2.88        |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.785        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.29         |
|    n_updates             | 2550         |
|    policy_gradient_loss  | -0.00516     |
|    std                   | 1.02         |
|    value_loss            | 3.96         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.8029742   |
| rollout/                 |              |
|    ep_len_mean           | 934          |
|    ep_rew_mean           | -604         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 12           |
|    time_elapsed          | 341          |
|    total_timesteps       | 526336       |
| train/                   |              |
|    approx_kl             | 0.0032018775 |
|    clip_fraction         | 0.0228       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.62         |
|    cost_value_loss       | 1.99         |
|    cost_values           | 1.22         |
|    entropy               | -2.88        |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.857        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.28         |
|    n_updates             | 2560         |
|    policy_gradient_loss  | -0.00306     |
|    std                   | 1.02         |
|    value_loss            | 8.83         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 0.881        |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.881        |
| reward                   | -0.82790935  |
| rollout/                 |              |
|    ep_len_mean           | 934          |
|    ep_rew_mean           | -603         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 13           |
|    time_elapsed          | 370          |
|    total_timesteps       | 528384       |
| train/                   |              |
|    approx_kl             | 0.0066654896 |
|    clip_fraction         | 0.0474       |
|    clip_range            | 0.2          |
|    cost_returns          | 1.68         |
|    cost_value_loss       | 3.46         |
|    cost_values           | 0.982        |
|    entropy               | -2.88        |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.887        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 3.21         |
|    n_updates             | 2570         |
|    policy_gradient_loss  | -0.00541     |
|    std                   | 1.02         |
|    value_loss            | 6.33         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 4.26         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 4.26         |
| reward                   | -0.54039204  |
| rollout/                 |              |
|    ep_len_mean           | 927          |
|    ep_rew_mean           | -593         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 14           |
|    time_elapsed          | 399          |
|    total_timesteps       | 530432       |
| train/                   |              |
|    approx_kl             | 0.0076148678 |
|    clip_fraction         | 0.102        |
|    clip_range            | 0.2          |
|    cost_returns          | 2.95         |
|    cost_value_loss       | 7.5          |
|    cost_values           | 1            |
|    entropy               | -2.87        |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.504        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.82         |
|    n_updates             | 2580         |
|    policy_gradient_loss  | -0.00932     |
|    std                   | 1.02         |
|    value_loss            | 5.12         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 0.2        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.2        |
| reward                   | -0.7430485 |
| rollout/                 |            |
|    ep_len_mean           | 918        |
|    ep_rew_mean           | -583       |
| time/                    |            |
|    fps                   | 71         |
|    iterations            | 15         |
|    time_elapsed          | 428        |
|    total_timesteps       | 532480     |
| train/                   |            |
|    approx_kl             | 0.00417897 |
|    clip_fraction         | 0.0183     |
|    clip_range            | 0.2        |
|    cost_returns          | 3.6        |
|    cost_value_loss       | 19.8       |
|    cost_values           | 1.15       |
|    entropy               | -2.87      |
|    entropy_loss          | -2.87      |
|    explained_variance    | 0.519      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 18.7       |
|    n_updates             | 2590       |
|    policy_gradient_loss  | -0.00286   |
|    std                   | 1.02       |
|    value_loss            | 21.9       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.5353615   |
| rollout/                 |              |
|    ep_len_mean           | 913          |
|    ep_rew_mean           | -578         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 16           |
|    time_elapsed          | 457          |
|    total_timesteps       | 534528       |
| train/                   |              |
|    approx_kl             | 0.0031550198 |
|    clip_fraction         | 0.0254       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.19         |
|    cost_value_loss       | 6.55         |
|    cost_values           | 1.16         |
|    entropy               | -2.87        |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.642        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.01         |
|    n_updates             | 2600         |
|    policy_gradient_loss  | -0.0033      |
|    std                   | 1.02         |
|    value_loss            | 8.63         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.29897478 |
| rollout/                 |             |
|    ep_len_mean           | 913         |
|    ep_rew_mean           | -575        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 17          |
|    time_elapsed          | 486         |
|    total_timesteps       | 536576      |
| train/                   |             |
|    approx_kl             | 0.003457504 |
|    clip_fraction         | 0.043       |
|    clip_range            | 0.2         |
|    cost_returns          | 2.25        |
|    cost_value_loss       | 5.07        |
|    cost_values           | 1.03        |
|    entropy               | -2.86       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.275       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.66        |
|    n_updates             | 2610        |
|    policy_gradient_loss  | -0.00367    |
|    std                   | 1.02        |
|    value_loss            | 15.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.52        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.52        |
| reward                   | -0.62543696 |
| rollout/                 |             |
|    ep_len_mean           | 914         |
|    ep_rew_mean           | -572        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 18          |
|    time_elapsed          | 515         |
|    total_timesteps       | 538624      |
| train/                   |             |
|    approx_kl             | 0.004780247 |
|    clip_fraction         | 0.0363      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.09        |
|    cost_value_loss       | 8.81        |
|    cost_values           | 1.17        |
|    entropy               | -2.85       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.629       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.37        |
|    n_updates             | 2620        |
|    policy_gradient_loss  | -0.00331    |
|    std                   | 1.01        |
|    value_loss            | 3.22        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.7687671   |
| rollout/                 |              |
|    ep_len_mean           | 910          |
|    ep_rew_mean           | -566         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 19           |
|    time_elapsed          | 542          |
|    total_timesteps       | 540672       |
| train/                   |              |
|    approx_kl             | 0.0061471867 |
|    clip_fraction         | 0.0453       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.19         |
|    cost_value_loss       | 6.73         |
|    cost_values           | 1.4          |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.461        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.78         |
|    n_updates             | 2630         |
|    policy_gradient_loss  | -0.00342     |
|    std                   | 1.01         |
|    value_loss            | 13.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 1.33         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.33         |
| reward                   | -0.50280887  |
| rollout/                 |              |
|    ep_len_mean           | 910          |
|    ep_rew_mean           | -567         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 20           |
|    time_elapsed          | 570          |
|    total_timesteps       | 542720       |
| train/                   |              |
|    approx_kl             | 0.0071974103 |
|    clip_fraction         | 0.0788       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.18         |
|    cost_value_loss       | 10.1         |
|    cost_values           | 1.36         |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.825        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.87         |
|    n_updates             | 2640         |
|    policy_gradient_loss  | -0.00554     |
|    std                   | 1.01         |
|    value_loss            | 9.75         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.38288584 |
| rollout/                 |             |
|    ep_len_mean           | 905         |
|    ep_rew_mean           | -560        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 21          |
|    time_elapsed          | 599         |
|    total_timesteps       | 544768      |
| train/                   |             |
|    approx_kl             | 0.004438838 |
|    clip_fraction         | 0.0439      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.02        |
|    cost_value_loss       | 8.36        |
|    cost_values           | 1.48        |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.752       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.32        |
|    n_updates             | 2650        |
|    policy_gradient_loss  | -0.00536    |
|    std                   | 1.01        |
|    value_loss            | 3.56        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.25        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.25        |
| reward                   | -0.693265   |
| rollout/                 |             |
|    ep_len_mean           | 906         |
|    ep_rew_mean           | -553        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 22          |
|    time_elapsed          | 628         |
|    total_timesteps       | 546816      |
| train/                   |             |
|    approx_kl             | 0.008767098 |
|    clip_fraction         | 0.0739      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.39        |
|    cost_value_loss       | 8.1         |
|    cost_values           | 1.53        |
|    entropy               | -2.85       |
|    entropy_loss          | -2.85       |
|    explained_variance    | 0.257       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.88        |
|    n_updates             | 2660        |
|    policy_gradient_loss  | -0.00597    |
|    std                   | 1.01        |
|    value_loss            | 14.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.53035426  |
| rollout/                 |              |
|    ep_len_mean           | 898          |
|    ep_rew_mean           | -545         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 23           |
|    time_elapsed          | 656          |
|    total_timesteps       | 548864       |
| train/                   |              |
|    approx_kl             | 0.0077275597 |
|    clip_fraction         | 0.0958       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.45         |
|    cost_value_loss       | 13.1         |
|    cost_values           | 1.63         |
|    entropy               | -2.85        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.32         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 14.2         |
|    n_updates             | 2670         |
|    policy_gradient_loss  | -0.00423     |
|    std                   | 1.01         |
|    value_loss            | 12.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.65538406  |
| rollout/                 |              |
|    ep_len_mean           | 896          |
|    ep_rew_mean           | -539         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 24           |
|    time_elapsed          | 685          |
|    total_timesteps       | 550912       |
| train/                   |              |
|    approx_kl             | 0.0053620273 |
|    clip_fraction         | 0.06         |
|    clip_range            | 0.2          |
|    cost_returns          | 4.04         |
|    cost_value_loss       | 9.92         |
|    cost_values           | 1.73         |
|    entropy               | -2.84        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.641        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 8.69         |
|    n_updates             | 2680         |
|    policy_gradient_loss  | -0.00481     |
|    std                   | 1.01         |
|    value_loss            | 11           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.6232867  |
| rollout/                 |             |
|    ep_len_mean           | 896         |
|    ep_rew_mean           | -534        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 25          |
|    time_elapsed          | 713         |
|    total_timesteps       | 552960      |
| train/                   |             |
|    approx_kl             | 0.005725303 |
|    clip_fraction         | 0.0593      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.97        |
|    cost_value_loss       | 12.3        |
|    cost_values           | 1.76        |
|    entropy               | -2.85       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.616       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 14          |
|    n_updates             | 2690        |
|    policy_gradient_loss  | -0.00417    |
|    std                   | 1.01        |
|    value_loss            | 21.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 3           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3           |
| reward                   | -0.71032065 |
| rollout/                 |             |
|    ep_len_mean           | 896         |
|    ep_rew_mean           | -531        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 26          |
|    time_elapsed          | 741         |
|    total_timesteps       | 555008      |
| train/                   |             |
|    approx_kl             | 0.005405853 |
|    clip_fraction         | 0.0727      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.14        |
|    cost_value_loss       | 4.75        |
|    cost_values           | 1.85        |
|    entropy               | -2.84       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.736       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.66        |
|    n_updates             | 2700        |
|    policy_gradient_loss  | -0.00715    |
|    std                   | 1.01        |
|    value_loss            | 3.09        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.99        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.99        |
| reward                   | -0.59757054 |
| rollout/                 |             |
|    ep_len_mean           | 890         |
|    ep_rew_mean           | -523        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 27          |
|    time_elapsed          | 771         |
|    total_timesteps       | 557056      |
| train/                   |             |
|    approx_kl             | 0.008969593 |
|    clip_fraction         | 0.0897      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.12        |
|    cost_value_loss       | 1.92        |
|    cost_values           | 1.84        |
|    entropy               | -2.83       |
|    entropy_loss          | -2.84       |
|    explained_variance    | 0.748       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 2.16        |
|    n_updates             | 2710        |
|    policy_gradient_loss  | -0.00453    |
|    std                   | 1           |
|    value_loss            | 2.53        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.63        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.63        |
| reward                   | -0.5800157  |
| rollout/                 |             |
|    ep_len_mean           | 899         |
|    ep_rew_mean           | -528        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 28          |
|    time_elapsed          | 800         |
|    total_timesteps       | 559104      |
| train/                   |             |
|    approx_kl             | 0.011858802 |
|    clip_fraction         | 0.16        |
|    clip_range            | 0.2         |
|    cost_returns          | 2.91        |
|    cost_value_loss       | 5.21        |
|    cost_values           | 1.66        |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.51        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 15.2        |
|    n_updates             | 2720        |
|    policy_gradient_loss  | -0.0022     |
|    std                   | 0.999       |
|    value_loss            | 21.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.77        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.77        |
| reward                   | -0.6200464  |
| rollout/                 |             |
|    ep_len_mean           | 899         |
|    ep_rew_mean           | -526        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 29          |
|    time_elapsed          | 830         |
|    total_timesteps       | 561152      |
| train/                   |             |
|    approx_kl             | 0.007737551 |
|    clip_fraction         | 0.0749      |
|    clip_range            | 0.2         |
|    cost_returns          | 2.2         |
|    cost_value_loss       | 3.75        |
|    cost_values           | 1.45        |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.908       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 3.35        |
|    n_updates             | 2730        |
|    policy_gradient_loss  | -0.00675    |
|    std                   | 1           |
|    value_loss            | 4.49        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.91         |
| reward                   | -0.606332    |
| rollout/                 |              |
|    ep_len_mean           | 889          |
|    ep_rew_mean           | -518         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 30           |
|    time_elapsed          | 859          |
|    total_timesteps       | 563200       |
| train/                   |              |
|    approx_kl             | 0.0045959414 |
|    clip_fraction         | 0.0222       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.87         |
|    cost_value_loss       | 11.2         |
|    cost_values           | 1.49         |
|    entropy               | -2.83        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.908        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 6.56         |
|    n_updates             | 2740         |
|    policy_gradient_loss  | -0.00372     |
|    std                   | 1            |
|    value_loss            | 3.38         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.4338984  |
| rollout/                 |             |
|    ep_len_mean           | 889         |
|    ep_rew_mean           | -513        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 31          |
|    time_elapsed          | 889         |
|    total_timesteps       | 565248      |
| train/                   |             |
|    approx_kl             | 0.005655365 |
|    clip_fraction         | 0.0384      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.39        |
|    cost_value_loss       | 7.49        |
|    cost_values           | 1.57        |
|    entropy               | -2.84       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.485       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.1        |
|    n_updates             | 2750        |
|    policy_gradient_loss  | -0.00154    |
|    std                   | 1           |
|    value_loss            | 17.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.38        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.38        |
| reward                   | -0.72577137 |
| rollout/                 |             |
|    ep_len_mean           | 876         |
|    ep_rew_mean           | -500        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 32          |
|    time_elapsed          | 917         |
|    total_timesteps       | 567296      |
| train/                   |             |
|    approx_kl             | 0.005002362 |
|    clip_fraction         | 0.0542      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.17        |
|    cost_value_loss       | 11.7        |
|    cost_values           | 1.74        |
|    entropy               | -2.83       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.633       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.17        |
|    n_updates             | 2760        |
|    policy_gradient_loss  | -0.00465    |
|    std                   | 1           |
|    value_loss            | 2.05        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.76        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.76        |
| reward                   | -0.652645   |
| rollout/                 |             |
|    ep_len_mean           | 876         |
|    ep_rew_mean           | -499        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 33          |
|    time_elapsed          | 946         |
|    total_timesteps       | 569344      |
| train/                   |             |
|    approx_kl             | 0.009083012 |
|    clip_fraction         | 0.0714      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.33        |
|    cost_value_loss       | 7.48        |
|    cost_values           | 1.94        |
|    entropy               | -2.82       |
|    entropy_loss          | -2.83       |
|    explained_variance    | 0.356       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 11          |
|    n_updates             | 2770        |
|    policy_gradient_loss  | -0.00481    |
|    std                   | 0.999       |
|    value_loss            | 21.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.5905095  |
| rollout/                 |             |
|    ep_len_mean           | 876         |
|    ep_rew_mean           | -498        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 34          |
|    time_elapsed          | 975         |
|    total_timesteps       | 571392      |
| train/                   |             |
|    approx_kl             | 0.006603824 |
|    clip_fraction         | 0.0624      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.11        |
|    cost_value_loss       | 6.59        |
|    cost_values           | 2.02        |
|    entropy               | -2.81       |
|    entropy_loss          | -2.82       |
|    explained_variance    | 0.769       |
|    lagrangian_multiplier | 4.26e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.11        |
|    n_updates             | 2780        |
|    policy_gradient_loss  | -0.00363    |
|    std                   | 0.993       |
|    value_loss            | 2.01        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.5029764  |
| rollout/                 |             |
|    ep_len_mean           | 868         |
|    ep_rew_mean           | -490        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 35          |
|    time_elapsed          | 1004        |
|    total_timesteps       | 573440      |
| train/                   |             |
|    approx_kl             | 0.010151587 |
|    clip_fraction         | 0.0917      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.58        |
|    cost_value_loss       | 9.86        |
|    cost_values           | 1.73        |
|    entropy               | -2.81       |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0.831       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.46        |
|    n_updates             | 2790        |
|    policy_gradient_loss  | -0.00647    |
|    std                   | 0.991       |
|    value_loss            | 4.83        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.06        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.06        |
| reward                   | -0.52647007 |
| rollout/                 |             |
|    ep_len_mean           | 859         |
|    ep_rew_mean           | -485        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 36          |
|    time_elapsed          | 1032        |
|    total_timesteps       | 575488      |
| train/                   |             |
|    approx_kl             | 0.004681702 |
|    clip_fraction         | 0.0564      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.97        |
|    cost_value_loss       | 13.9        |
|    cost_values           | 1.93        |
|    entropy               | -2.81       |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0.332       |
|    lagrangian_multiplier | 0.000187    |
|    learning_rate         | 0.0003      |
|    loss                  | 18.1        |
|    n_updates             | 2800        |
|    policy_gradient_loss  | -0.00443    |
|    std                   | 0.991       |
|    value_loss            | 21.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.4         |
| reward                   | -0.45598853 |
| rollout/                 |             |
|    ep_len_mean           | 865         |
|    ep_rew_mean           | -486        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 37          |
|    time_elapsed          | 1060        |
|    total_timesteps       | 577536      |
| train/                   |             |
|    approx_kl             | 0.009950664 |
|    clip_fraction         | 0.0955      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.84        |
|    cost_value_loss       | 8.3         |
|    cost_values           | 2           |
|    entropy               | -2.8        |
|    entropy_loss          | -2.81       |
|    explained_variance    | 0.247       |
|    lagrangian_multiplier | 0.000111    |
|    learning_rate         | 0.0003      |
|    loss                  | 14.4        |
|    n_updates             | 2810        |
|    policy_gradient_loss  | -0.00684    |
|    std                   | 0.987       |
|    value_loss            | 22.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.61         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.61         |
| reward                   | -0.41079724  |
| rollout/                 |              |
|    ep_len_mean           | 865          |
|    ep_rew_mean           | -483         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 38           |
|    time_elapsed          | 1089         |
|    total_timesteps       | 579584       |
| train/                   |              |
|    approx_kl             | 0.0055342503 |
|    clip_fraction         | 0.0764       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.65         |
|    cost_value_loss       | 13.9         |
|    cost_values           | 1.83         |
|    entropy               | -2.8         |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.371        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13.5         |
|    n_updates             | 2820         |
|    policy_gradient_loss  | -0.00544     |
|    std                   | 0.985        |
|    value_loss            | 20.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -0.48613408 |
| rollout/                 |             |
|    ep_len_mean           | 865         |
|    ep_rew_mean           | -479        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 39          |
|    time_elapsed          | 1118        |
|    total_timesteps       | 581632      |
| train/                   |             |
|    approx_kl             | 0.010510878 |
|    clip_fraction         | 0.098       |
|    clip_range            | 0.2         |
|    cost_returns          | 4           |
|    cost_value_loss       | 9.91        |
|    cost_values           | 1.83        |
|    entropy               | -2.79       |
|    entropy_loss          | -2.79       |
|    explained_variance    | 0.921       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 5.9         |
|    n_updates             | 2830        |
|    policy_gradient_loss  | -0.00847    |
|    std                   | 0.984       |
|    value_loss            | 2.16        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -0.48597267 |
| rollout/                 |             |
|    ep_len_mean           | 854         |
|    ep_rew_mean           | -473        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 40          |
|    time_elapsed          | 1147        |
|    total_timesteps       | 583680      |
| train/                   |             |
|    approx_kl             | 0.005607566 |
|    clip_fraction         | 0.0492      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.1         |
|    cost_value_loss       | 10.5        |
|    cost_values           | 1.89        |
|    entropy               | -2.79       |
|    entropy_loss          | -2.79       |
|    explained_variance    | 0.865       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.82        |
|    n_updates             | 2840        |
|    policy_gradient_loss  | -0.00504    |
|    std                   | 0.981       |
|    value_loss            | 3.78        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.86         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.86         |
| reward                   | -0.40342396  |
| rollout/                 |              |
|    ep_len_mean           | 858          |
|    ep_rew_mean           | -471         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 41           |
|    time_elapsed          | 1175         |
|    total_timesteps       | 585728       |
| train/                   |              |
|    approx_kl             | 0.0063569807 |
|    clip_fraction         | 0.0922       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.82         |
|    cost_value_loss       | 6.43         |
|    cost_values           | 1.72         |
|    entropy               | -2.78        |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.655        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.1         |
|    n_updates             | 2850         |
|    policy_gradient_loss  | -0.00543     |
|    std                   | 0.979        |
|    value_loss            | 18.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.83        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.83        |
| reward                   | -0.6380344  |
| rollout/                 |             |
|    ep_len_mean           | 855         |
|    ep_rew_mean           | -470        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 42          |
|    time_elapsed          | 1204        |
|    total_timesteps       | 587776      |
| train/                   |             |
|    approx_kl             | 0.004060888 |
|    clip_fraction         | 0.0153      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.34        |
|    cost_value_loss       | 11.8        |
|    cost_values           | 1.72        |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.766       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 10.1        |
|    n_updates             | 2860        |
|    policy_gradient_loss  | -0.000967   |
|    std                   | 0.977       |
|    value_loss            | 8.95        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.5127958  |
| rollout/                 |             |
|    ep_len_mean           | 852         |
|    ep_rew_mean           | -465        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 43          |
|    time_elapsed          | 1233        |
|    total_timesteps       | 589824      |
| train/                   |             |
|    approx_kl             | 0.007678948 |
|    clip_fraction         | 0.0902      |
|    clip_range            | 0.2         |
|    cost_returns          | 4           |
|    cost_value_loss       | 11.6        |
|    cost_values           | 1.81        |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.675       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.65        |
|    n_updates             | 2870        |
|    policy_gradient_loss  | -0.00684    |
|    std                   | 0.975       |
|    value_loss            | 8.3         |
------------------------------------------
------------------------------------------
| avg_speed                | 2.09        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.09        |
| reward                   | -0.810569   |
| rollout/                 |             |
|    ep_len_mean           | 852         |
|    ep_rew_mean           | -462        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 44          |
|    time_elapsed          | 1262        |
|    total_timesteps       | 591872      |
| train/                   |             |
|    approx_kl             | 0.004496675 |
|    clip_fraction         | 0.0809      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.5         |
|    cost_value_loss       | 8.7         |
|    cost_values           | 1.67        |
|    entropy               | -2.78       |
|    entropy_loss          | -2.78       |
|    explained_variance    | 0.307       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.63        |
|    n_updates             | 2880        |
|    policy_gradient_loss  | -0.00414    |
|    std                   | 0.975       |
|    value_loss            | 12.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.44230273  |
| rollout/                 |              |
|    ep_len_mean           | 841          |
|    ep_rew_mean           | -455         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 45           |
|    time_elapsed          | 1291         |
|    total_timesteps       | 593920       |
| train/                   |              |
|    approx_kl             | 0.0048233178 |
|    clip_fraction         | 0.0239       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.6          |
|    cost_value_loss       | 22.7         |
|    cost_values           | 1.83         |
|    entropy               | -2.76        |
|    entropy_loss          | -2.77        |
|    explained_variance    | 0.796        |
|    lagrangian_multiplier | 0.00334      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.45         |
|    n_updates             | 2890         |
|    policy_gradient_loss  | -0.00355     |
|    std                   | 0.97         |
|    value_loss            | 2.34         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.03         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.03         |
| reward                   | -0.48248056  |
| rollout/                 |              |
|    ep_len_mean           | 841          |
|    ep_rew_mean           | -452         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 46           |
|    time_elapsed          | 1319         |
|    total_timesteps       | 595968       |
| train/                   |              |
|    approx_kl             | 0.0054629063 |
|    clip_fraction         | 0.0536       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.21         |
|    cost_value_loss       | 11.6         |
|    cost_values           | 1.92         |
|    entropy               | -2.76        |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.465        |
|    lagrangian_multiplier | 0.000587     |
|    learning_rate         | 0.0003       |
|    loss                  | 13.9         |
|    n_updates             | 2900         |
|    policy_gradient_loss  | -0.00334     |
|    std                   | 0.966        |
|    value_loss            | 20.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.61         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.61         |
| reward                   | -0.354349    |
| rollout/                 |              |
|    ep_len_mean           | 841          |
|    ep_rew_mean           | -449         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 47           |
|    time_elapsed          | 1347         |
|    total_timesteps       | 598016       |
| train/                   |              |
|    approx_kl             | 0.0052896217 |
|    clip_fraction         | 0.0635       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.92         |
|    cost_value_loss       | 8.83         |
|    cost_values           | 1.93         |
|    entropy               | -2.75        |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.936        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.96         |
|    n_updates             | 2910         |
|    policy_gradient_loss  | -0.00541     |
|    std                   | 0.963        |
|    value_loss            | 2.38         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.43        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.43        |
| reward                   | -0.37592012 |
| rollout/                 |             |
|    ep_len_mean           | 833         |
|    ep_rew_mean           | -441        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 48          |
|    time_elapsed          | 1375        |
|    total_timesteps       | 600064      |
| train/                   |             |
|    approx_kl             | 0.004393832 |
|    clip_fraction         | 0.0608      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.09        |
|    cost_value_loss       | 8.65        |
|    cost_values           | 2.03        |
|    entropy               | -2.75       |
|    entropy_loss          | -2.75       |
|    explained_variance    | 0.757       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.61        |
|    n_updates             | 2920        |
|    policy_gradient_loss  | -0.00576    |
|    std                   | 0.963       |
|    value_loss            | 1.82        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.92        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.92        |
| reward                   | -0.4031417  |
| rollout/                 |             |
|    ep_len_mean           | 837         |
|    ep_rew_mean           | -443        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 49          |
|    time_elapsed          | 1404        |
|    total_timesteps       | 602112      |
| train/                   |             |
|    approx_kl             | 0.005171959 |
|    clip_fraction         | 0.0379      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.7         |
|    cost_value_loss       | 7.98        |
|    cost_values           | 2.08        |
|    entropy               | -2.75       |
|    entropy_loss          | -2.75       |
|    explained_variance    | 0.707       |
|    lagrangian_multiplier | 0.000212    |
|    learning_rate         | 0.0003      |
|    loss                  | 7.03        |
|    n_updates             | 2930        |
|    policy_gradient_loss  | -0.0034     |
|    std                   | 0.963       |
|    value_loss            | 8.31        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ent-coefficient-ppol/vlorgroe
------------------------------------
| avg_speed          | 8.02        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8.02        |
| reward             | -0.80750483 |
| rollout/           |             |
|    ep_len_mean     | 832         |
|    ep_rew_mean     | -438        |
| time/              |             |
|    fps             | 78          |
|    iterations      | 1           |
|    time_elapsed    | 26          |
|    total_timesteps | 604160      |
------------------------------------
------------------------------------------
| avg_speed                | 7.69        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.69        |
| reward                   | -0.43972644 |
| rollout/                 |             |
|    ep_len_mean           | 824         |
|    ep_rew_mean           | -432        |
| time/                    |             |
|    fps                   | 75          |
|    iterations            | 2           |
|    time_elapsed          | 54          |
|    total_timesteps       | 606208      |
| train/                   |             |
|    approx_kl             | 0.006341025 |
|    clip_fraction         | 0.084       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.23        |
|    cost_value_loss       | 14.5        |
|    cost_values           | 2.29        |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 0.251       |
|    lagrangian_multiplier | 0.000279    |
|    learning_rate         | 0.0003      |
|    loss                  | 11.4        |
|    n_updates             | 2950        |
|    policy_gradient_loss  | -0.0048     |
|    std                   | 0.961       |
|    value_loss            | 19.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.67        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.67        |
| reward                   | -0.37196198 |
| rollout/                 |             |
|    ep_len_mean           | 798         |
|    ep_rew_mean           | -410        |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 3           |
|    time_elapsed          | 83          |
|    total_timesteps       | 608256      |
| train/                   |             |
|    approx_kl             | 0.008023479 |
|    clip_fraction         | 0.0526      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.03        |
|    cost_value_loss       | 5.03        |
|    cost_values           | 2.01        |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 0.746       |
|    lagrangian_multiplier | 0.00288     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.65        |
|    n_updates             | 2960        |
|    policy_gradient_loss  | -0.0037     |
|    std                   | 0.96        |
|    value_loss            | 14.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.75        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.75        |
| reward                   | -0.56995124 |
| rollout/                 |             |
|    ep_len_mean           | 800         |
|    ep_rew_mean           | -411        |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 4           |
|    time_elapsed          | 112         |
|    total_timesteps       | 610304      |
| train/                   |             |
|    approx_kl             | 0.003906672 |
|    clip_fraction         | 0.0417      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.3         |
|    cost_value_loss       | 16.5        |
|    cost_values           | 1.99        |
|    entropy               | -2.74       |
|    entropy_loss          | -2.74       |
|    explained_variance    | 0.355       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 22.5        |
|    n_updates             | 2970        |
|    policy_gradient_loss  | -0.00274    |
|    std                   | 0.959       |
|    value_loss            | 34.9        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8.03       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8.03       |
| reward                   | -0.4203317 |
| rollout/                 |            |
|    ep_len_mean           | 809        |
|    ep_rew_mean           | -416       |
| time/                    |            |
|    fps                   | 72         |
|    iterations            | 5          |
|    time_elapsed          | 140        |
|    total_timesteps       | 612352     |
| train/                   |            |
|    approx_kl             | 0.01409557 |
|    clip_fraction         | 0.133      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.49       |
|    cost_value_loss       | 7.88       |
|    cost_values           | 1.87       |
|    entropy               | -2.74      |
|    entropy_loss          | -2.74      |
|    explained_variance    | 0.783      |
|    lagrangian_multiplier | 0          |
|    learning_rate         | 0.0003     |
|    loss                  | 9.03       |
|    n_updates             | 2980       |
|    policy_gradient_loss  | -0.00955   |
|    std                   | 0.958      |
|    value_loss            | 10.4       |
-----------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.39267898  |
| rollout/                 |              |
|    ep_len_mean           | 792          |
|    ep_rew_mean           | -407         |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 6            |
|    time_elapsed          | 169          |
|    total_timesteps       | 614400       |
| train/                   |              |
|    approx_kl             | 0.0066771745 |
|    clip_fraction         | 0.0785       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.68         |
|    cost_value_loss       | 8.71         |
|    cost_values           | 1.74         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.932        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.37         |
|    n_updates             | 2990         |
|    policy_gradient_loss  | -0.00925     |
|    std                   | 0.957        |
|    value_loss            | 3.23         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.56191945  |
| rollout/                 |              |
|    ep_len_mean           | 786          |
|    ep_rew_mean           | -402         |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 7            |
|    time_elapsed          | 198          |
|    total_timesteps       | 616448       |
| train/                   |              |
|    approx_kl             | 0.0044899913 |
|    clip_fraction         | 0.0454       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.23         |
|    cost_value_loss       | 10.9         |
|    cost_values           | 1.83         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.55         |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 27.5         |
|    n_updates             | 3000         |
|    policy_gradient_loss  | -0.00423     |
|    std                   | 0.956        |
|    value_loss            | 34.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7            |
| reward                   | -0.83312696  |
| rollout/                 |              |
|    ep_len_mean           | 792          |
|    ep_rew_mean           | -406         |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 8            |
|    time_elapsed          | 227          |
|    total_timesteps       | 618496       |
| train/                   |              |
|    approx_kl             | 0.0070081837 |
|    clip_fraction         | 0.0442       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.36         |
|    cost_value_loss       | 11.9         |
|    cost_values           | 1.81         |
|    entropy               | -2.73        |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.423        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 9.94         |
|    n_updates             | 3010         |
|    policy_gradient_loss  | -0.00492     |
|    std                   | 0.955        |
|    value_loss            | 9.87         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.92        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.92        |
| reward                   | -0.49397457 |
| rollout/                 |             |
|    ep_len_mean           | 792         |
|    ep_rew_mean           | -405        |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 9           |
|    time_elapsed          | 255         |
|    total_timesteps       | 620544      |
| train/                   |             |
|    approx_kl             | 0.009783549 |
|    clip_fraction         | 0.103       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.85        |
|    cost_value_loss       | 13.7        |
|    cost_values           | 1.83        |
|    entropy               | -2.73       |
|    entropy_loss          | -2.73       |
|    explained_variance    | 0.461       |
|    lagrangian_multiplier | 0.00265     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.19        |
|    n_updates             | 3020        |
|    policy_gradient_loss  | -0.00712    |
|    std                   | 0.955       |
|    value_loss            | 12.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.37538972 |
| rollout/                 |             |
|    ep_len_mean           | 780         |
|    ep_rew_mean           | -394        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 10          |
|    time_elapsed          | 284         |
|    total_timesteps       | 622592      |
| train/                   |             |
|    approx_kl             | 0.00971468  |
|    clip_fraction         | 0.115       |
|    clip_range            | 0.2         |
|    cost_returns          | 5           |
|    cost_value_loss       | 14          |
|    cost_values           | 1.96        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.73       |
|    explained_variance    | 0.636       |
|    lagrangian_multiplier | 0.000782    |
|    learning_rate         | 0.0003      |
|    loss                  | 6.67        |
|    n_updates             | 3030        |
|    policy_gradient_loss  | -0.0111     |
|    std                   | 0.952       |
|    value_loss            | 3.92        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.46         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.46         |
| reward                   | -0.5154705   |
| rollout/                 |              |
|    ep_len_mean           | 778          |
|    ep_rew_mean           | -391         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 11           |
|    time_elapsed          | 313          |
|    total_timesteps       | 624640       |
| train/                   |              |
|    approx_kl             | 0.0048353504 |
|    clip_fraction         | 0.023        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.66         |
|    cost_value_loss       | 11.6         |
|    cost_values           | 2.05         |
|    entropy               | -2.72        |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.374        |
|    lagrangian_multiplier | 1.14e-05     |
|    learning_rate         | 0.0003       |
|    loss                  | 17.3         |
|    n_updates             | 3040         |
|    policy_gradient_loss  | -0.00396     |
|    std                   | 0.951        |
|    value_loss            | 23.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.86        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.86        |
| reward                   | -0.601735   |
| rollout/                 |             |
|    ep_len_mean           | 782         |
|    ep_rew_mean           | -393        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 12          |
|    time_elapsed          | 341         |
|    total_timesteps       | 626688      |
| train/                   |             |
|    approx_kl             | 0.006235012 |
|    clip_fraction         | 0.0449      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.26        |
|    cost_value_loss       | 9.61        |
|    cost_values           | 2.08        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.675       |
|    lagrangian_multiplier | 0.000198    |
|    learning_rate         | 0.0003      |
|    loss                  | 7.27        |
|    n_updates             | 3050        |
|    policy_gradient_loss  | -0.00295    |
|    std                   | 0.95        |
|    value_loss            | 8.73        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.41        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.41        |
| reward                   | -0.30973542 |
| rollout/                 |             |
|    ep_len_mean           | 783         |
|    ep_rew_mean           | -393        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 13          |
|    time_elapsed          | 370         |
|    total_timesteps       | 628736      |
| train/                   |             |
|    approx_kl             | 0.007864583 |
|    clip_fraction         | 0.0828      |
|    clip_range            | 0.2         |
|    cost_returns          | 4           |
|    cost_value_loss       | 7.83        |
|    cost_values           | 2.14        |
|    entropy               | -2.72       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.612       |
|    lagrangian_multiplier | 0.000254    |
|    learning_rate         | 0.0003      |
|    loss                  | 9.54        |
|    n_updates             | 3060        |
|    policy_gradient_loss  | -0.00417    |
|    std                   | 0.949       |
|    value_loss            | 23.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.68        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.68        |
| reward                   | -0.91163224 |
| rollout/                 |             |
|    ep_len_mean           | 780         |
|    ep_rew_mean           | -393        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 14          |
|    time_elapsed          | 399         |
|    total_timesteps       | 630784      |
| train/                   |             |
|    approx_kl             | 0.010090557 |
|    clip_fraction         | 0.1         |
|    clip_range            | 0.2         |
|    cost_returns          | 4.97        |
|    cost_value_loss       | 13.9        |
|    cost_values           | 2.12        |
|    entropy               | -2.71       |
|    entropy_loss          | -2.72       |
|    explained_variance    | 0.809       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 9.36        |
|    n_updates             | 3070        |
|    policy_gradient_loss  | -0.0111     |
|    std                   | 0.948       |
|    value_loss            | 4.52        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.20401978  |
| rollout/                 |              |
|    ep_len_mean           | 780          |
|    ep_rew_mean           | -392         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 15           |
|    time_elapsed          | 429          |
|    total_timesteps       | 632832       |
| train/                   |              |
|    approx_kl             | 0.0046630134 |
|    clip_fraction         | 0.0349       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.83         |
|    cost_value_loss       | 13.6         |
|    cost_values           | 2            |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.57         |
|    lagrangian_multiplier | 0.00228      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.36         |
|    n_updates             | 3080         |
|    policy_gradient_loss  | -0.00174     |
|    std                   | 0.947        |
|    value_loss            | 11.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.71        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.71        |
| reward                   | -0.45850456 |
| rollout/                 |             |
|    ep_len_mean           | 782         |
|    ep_rew_mean           | -394        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 16          |
|    time_elapsed          | 458         |
|    total_timesteps       | 634880      |
| train/                   |             |
|    approx_kl             | 0.009802227 |
|    clip_fraction         | 0.142       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.46        |
|    cost_value_loss       | 16.7        |
|    cost_values           | 2.19        |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | 0.744       |
|    lagrangian_multiplier | 0.000261    |
|    learning_rate         | 0.0003      |
|    loss                  | 8.68        |
|    n_updates             | 3090        |
|    policy_gradient_loss  | -0.0127     |
|    std                   | 0.946       |
|    value_loss            | 2.97        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.27333698 |
| rollout/                 |             |
|    ep_len_mean           | 773         |
|    ep_rew_mean           | -387        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 17          |
|    time_elapsed          | 487         |
|    total_timesteps       | 636928      |
| train/                   |             |
|    approx_kl             | 0.006894867 |
|    clip_fraction         | 0.071       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.61        |
|    cost_value_loss       | 6.94        |
|    cost_values           | 2.04        |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | 0.417       |
|    lagrangian_multiplier | 0.000438    |
|    learning_rate         | 0.0003      |
|    loss                  | 9.67        |
|    n_updates             | 3100        |
|    policy_gradient_loss  | -0.0057     |
|    std                   | 0.944       |
|    value_loss            | 12.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.53        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.53        |
| reward                   | -0.8616683  |
| rollout/                 |             |
|    ep_len_mean           | 774         |
|    ep_rew_mean           | -385        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 18          |
|    time_elapsed          | 516         |
|    total_timesteps       | 638976      |
| train/                   |             |
|    approx_kl             | 0.007714849 |
|    clip_fraction         | 0.0802      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.76        |
|    cost_value_loss       | 12.3        |
|    cost_values           | 2.05        |
|    entropy               | -2.71       |
|    entropy_loss          | -2.71       |
|    explained_variance    | 0.591       |
|    lagrangian_multiplier | 0.000117    |
|    learning_rate         | 0.0003      |
|    loss                  | 8.78        |
|    n_updates             | 3110        |
|    policy_gradient_loss  | -0.00811    |
|    std                   | 0.945       |
|    value_loss            | 9.08        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.4586604   |
| rollout/                 |              |
|    ep_len_mean           | 783          |
|    ep_rew_mean           | -390         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 19           |
|    time_elapsed          | 544          |
|    total_timesteps       | 641024       |
| train/                   |              |
|    approx_kl             | 0.0052602203 |
|    clip_fraction         | 0.0733       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.21         |
|    cost_value_loss       | 8.23         |
|    cost_values           | 2.1          |
|    entropy               | -2.71        |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.855        |
|    lagrangian_multiplier | 0.000726     |
|    learning_rate         | 0.0003       |
|    loss                  | 5.07         |
|    n_updates             | 3120         |
|    policy_gradient_loss  | -0.00826     |
|    std                   | 0.944        |
|    value_loss            | 3.76         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.379174   |
| rollout/                 |             |
|    ep_len_mean           | 775         |
|    ep_rew_mean           | -384        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 20          |
|    time_elapsed          | 573         |
|    total_timesteps       | 643072      |
| train/                   |             |
|    approx_kl             | 0.008192915 |
|    clip_fraction         | 0.0659      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.3         |
|    cost_value_loss       | 5.79        |
|    cost_values           | 2.07        |
|    entropy               | -2.7        |
|    entropy_loss          | -2.7        |
|    explained_variance    | 0.905       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 4.24        |
|    n_updates             | 3130        |
|    policy_gradient_loss  | -0.00418    |
|    std                   | 0.942       |
|    value_loss            | 3.34        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.51247966  |
| rollout/                 |              |
|    ep_len_mean           | 778          |
|    ep_rew_mean           | -385         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 21           |
|    time_elapsed          | 601          |
|    total_timesteps       | 645120       |
| train/                   |              |
|    approx_kl             | 0.0051697954 |
|    clip_fraction         | 0.0513       |
|    clip_range            | 0.2          |
|    cost_returns          | 2.57         |
|    cost_value_loss       | 2.29         |
|    cost_values           | 2.03         |
|    entropy               | -2.69        |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.394        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 4.26         |
|    n_updates             | 3140         |
|    policy_gradient_loss  | -0.00375     |
|    std                   | 0.94         |
|    value_loss            | 7.93         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -0.47726864 |
| rollout/                 |             |
|    ep_len_mean           | 775         |
|    ep_rew_mean           | -382        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 22          |
|    time_elapsed          | 630         |
|    total_timesteps       | 647168      |
| train/                   |             |
|    approx_kl             | 0.008316395 |
|    clip_fraction         | 0.0996      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.17        |
|    cost_value_loss       | 4.38        |
|    cost_values           | 1.97        |
|    entropy               | -2.69       |
|    entropy_loss          | -2.69       |
|    explained_variance    | 0.418       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 8.76        |
|    n_updates             | 3150        |
|    policy_gradient_loss  | -0.00641    |
|    std                   | 0.937       |
|    value_loss            | 8.35        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.7072364   |
| rollout/                 |              |
|    ep_len_mean           | 772          |
|    ep_rew_mean           | -379         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 23           |
|    time_elapsed          | 658          |
|    total_timesteps       | 649216       |
| train/                   |              |
|    approx_kl             | 0.0046453606 |
|    clip_fraction         | 0.0753       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.29         |
|    cost_value_loss       | 11           |
|    cost_values           | 2.02         |
|    entropy               | -2.68        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0.708        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 10.8         |
|    n_updates             | 3160         |
|    policy_gradient_loss  | -0.00419     |
|    std                   | 0.937        |
|    value_loss            | 9.06         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.18         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.18         |
| reward                   | -0.6591823   |
| rollout/                 |              |
|    ep_len_mean           | 778          |
|    ep_rew_mean           | -382         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 24           |
|    time_elapsed          | 687          |
|    total_timesteps       | 651264       |
| train/                   |              |
|    approx_kl             | 0.0106260255 |
|    clip_fraction         | 0.123        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.42         |
|    cost_value_loss       | 10.4         |
|    cost_values           | 1.99         |
|    entropy               | -2.68        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0.402        |
|    lagrangian_multiplier | 0.000237     |
|    learning_rate         | 0.0003       |
|    loss                  | 12.8         |
|    n_updates             | 3170         |
|    policy_gradient_loss  | -0.00593     |
|    std                   | 0.936        |
|    value_loss            | 16.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.25         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.25         |
| reward                   | -0.3857227   |
| rollout/                 |              |
|    ep_len_mean           | 784          |
|    ep_rew_mean           | -384         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 25           |
|    time_elapsed          | 716          |
|    total_timesteps       | 653312       |
| train/                   |              |
|    approx_kl             | 0.0035822745 |
|    clip_fraction         | 0.0971       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.71         |
|    cost_value_loss       | 8.68         |
|    cost_values           | 1.99         |
|    entropy               | -2.68        |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0.427        |
|    lagrangian_multiplier | 0.00219      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.83         |
|    n_updates             | 3180         |
|    policy_gradient_loss  | -0.00508     |
|    std                   | 0.936        |
|    value_loss            | 10.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.6         |
| reward                   | -0.2544344  |
| rollout/                 |             |
|    ep_len_mean           | 779         |
|    ep_rew_mean           | -382        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 26          |
|    time_elapsed          | 746         |
|    total_timesteps       | 655360      |
| train/                   |             |
|    approx_kl             | 0.008511092 |
|    clip_fraction         | 0.064       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.32        |
|    cost_value_loss       | 11.6        |
|    cost_values           | 2.04        |
|    entropy               | -2.68       |
|    entropy_loss          | -2.68       |
|    explained_variance    | 0.763       |
|    lagrangian_multiplier | 0.0038      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.8         |
|    n_updates             | 3190        |
|    policy_gradient_loss  | -0.00505    |
|    std                   | 0.934       |
|    value_loss            | 3.23        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.4894676  |
| rollout/                 |             |
|    ep_len_mean           | 775         |
|    ep_rew_mean           | -380        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 27          |
|    time_elapsed          | 774         |
|    total_timesteps       | 657408      |
| train/                   |             |
|    approx_kl             | 0.004464903 |
|    clip_fraction         | 0.0851      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.61        |
|    cost_value_loss       | 10.8        |
|    cost_values           | 2.17        |
|    entropy               | -2.67       |
|    entropy_loss          | -2.67       |
|    explained_variance    | 0.499       |
|    lagrangian_multiplier | 0.000489    |
|    learning_rate         | 0.0003      |
|    loss                  | 12.1        |
|    n_updates             | 3200        |
|    policy_gradient_loss  | -0.00335    |
|    std                   | 0.929       |
|    value_loss            | 16.1        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.5107706 |
| rollout/                 |            |
|    ep_len_mean           | 772        |
|    ep_rew_mean           | -378       |
| time/                    |            |
|    fps                   | 71         |
|    iterations            | 28         |
|    time_elapsed          | 804        |
|    total_timesteps       | 659456     |
| train/                   |            |
|    approx_kl             | 0.00520529 |
|    clip_fraction         | 0.107      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.22       |
|    cost_value_loss       | 10.6       |
|    cost_values           | 2.03       |
|    entropy               | -2.66      |
|    entropy_loss          | -2.66      |
|    explained_variance    | 0.619      |
|    lagrangian_multiplier | 0.00355    |
|    learning_rate         | 0.0003     |
|    loss                  | 4.65       |
|    n_updates             | 3210       |
|    policy_gradient_loss  | -0.00438   |
|    std                   | 0.929      |
|    value_loss            | 8.98       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.3459902  |
| rollout/                 |             |
|    ep_len_mean           | 777         |
|    ep_rew_mean           | -381        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 29          |
|    time_elapsed          | 832         |
|    total_timesteps       | 661504      |
| train/                   |             |
|    approx_kl             | 0.008188088 |
|    clip_fraction         | 0.0713      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.58        |
|    cost_value_loss       | 17.2        |
|    cost_values           | 2.04        |
|    entropy               | -2.67       |
|    entropy_loss          | -2.66       |
|    explained_variance    | 0.57        |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 12.4        |
|    n_updates             | 3220        |
|    policy_gradient_loss  | -0.00514    |
|    std                   | 0.93        |
|    value_loss            | 9.9         |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.67         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.67         |
| reward                   | -0.41157007  |
| rollout/                 |              |
|    ep_len_mean           | 777          |
|    ep_rew_mean           | -379         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 30           |
|    time_elapsed          | 861          |
|    total_timesteps       | 663552       |
| train/                   |              |
|    approx_kl             | 0.0069774957 |
|    clip_fraction         | 0.0769       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.36         |
|    cost_value_loss       | 11.1         |
|    cost_values           | 2.07         |
|    entropy               | -2.66        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.35         |
|    lagrangian_multiplier | 0.00041      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.08         |
|    n_updates             | 3230         |
|    policy_gradient_loss  | -0.00616     |
|    std                   | 0.927        |
|    value_loss            | 10.6         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.88         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.88         |
| reward                   | -0.62059903  |
| rollout/                 |              |
|    ep_len_mean           | 768          |
|    ep_rew_mean           | -373         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 31           |
|    time_elapsed          | 891          |
|    total_timesteps       | 665600       |
| train/                   |              |
|    approx_kl             | 0.0051419814 |
|    clip_fraction         | 0.0663       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.96         |
|    cost_value_loss       | 8.57         |
|    cost_values           | 2.06         |
|    entropy               | -2.65        |
|    entropy_loss          | -2.66        |
|    explained_variance    | 0.535        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 5.59         |
|    n_updates             | 3240         |
|    policy_gradient_loss  | -0.00365     |
|    std                   | 0.923        |
|    value_loss            | 7.95         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.64         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.64         |
| reward                   | -0.29245347  |
| rollout/                 |              |
|    ep_len_mean           | 751          |
|    ep_rew_mean           | -363         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 32           |
|    time_elapsed          | 920          |
|    total_timesteps       | 667648       |
| train/                   |              |
|    approx_kl             | 0.0067609395 |
|    clip_fraction         | 0.0463       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.03         |
|    cost_value_loss       | 8.96         |
|    cost_values           | 2.07         |
|    entropy               | -2.64        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.351        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 17.1         |
|    n_updates             | 3250         |
|    policy_gradient_loss  | -0.00252     |
|    std                   | 0.917        |
|    value_loss            | 25.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -0.6570801  |
| rollout/                 |             |
|    ep_len_mean           | 746         |
|    ep_rew_mean           | -358        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 33          |
|    time_elapsed          | 949         |
|    total_timesteps       | 669696      |
| train/                   |             |
|    approx_kl             | 0.008020766 |
|    clip_fraction         | 0.094       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.73        |
|    cost_value_loss       | 12.4        |
|    cost_values           | 2.14        |
|    entropy               | -2.64       |
|    entropy_loss          | -2.64       |
|    explained_variance    | 0.519       |
|    lagrangian_multiplier | 0.000323    |
|    learning_rate         | 0.0003      |
|    loss                  | 11.9        |
|    n_updates             | 3260        |
|    policy_gradient_loss  | -0.00393    |
|    std                   | 0.916       |
|    value_loss            | 19.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1            |
| reward                   | -0.566113    |
| rollout/                 |              |
|    ep_len_mean           | 741          |
|    ep_rew_mean           | -358         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 34           |
|    time_elapsed          | 978          |
|    total_timesteps       | 671744       |
| train/                   |              |
|    approx_kl             | 0.0041825376 |
|    clip_fraction         | 0.0743       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.17         |
|    cost_value_loss       | 9.4          |
|    cost_values           | 2.23         |
|    entropy               | -2.63        |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.527        |
|    lagrangian_multiplier | 0.00126      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.69         |
|    n_updates             | 3270         |
|    policy_gradient_loss  | -0.00377     |
|    std                   | 0.916        |
|    value_loss            | 11.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.7         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.7         |
| reward                   | -0.6248561  |
| rollout/                 |             |
|    ep_len_mean           | 750         |
|    ep_rew_mean           | -361        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 35          |
|    time_elapsed          | 1007        |
|    total_timesteps       | 673792      |
| train/                   |             |
|    approx_kl             | 0.005494781 |
|    clip_fraction         | 0.0832      |
|    clip_range            | 0.2         |
|    cost_returns          | 4           |
|    cost_value_loss       | 7.56        |
|    cost_values           | 2.01        |
|    entropy               | -2.63       |
|    entropy_loss          | -2.63       |
|    explained_variance    | 0.547       |
|    lagrangian_multiplier | 0.000298    |
|    learning_rate         | 0.0003      |
|    loss                  | 7.51        |
|    n_updates             | 3280        |
|    policy_gradient_loss  | -0.00558    |
|    std                   | 0.915       |
|    value_loss            | 12          |
------------------------------------------
------------------------------------------
| avg_speed                | 7.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.84        |
| reward                   | -0.54284877 |
| rollout/                 |             |
|    ep_len_mean           | 736         |
|    ep_rew_mean           | -353        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 36          |
|    time_elapsed          | 1035        |
|    total_timesteps       | 675840      |
| train/                   |             |
|    approx_kl             | 0.009071188 |
|    clip_fraction         | 0.0935      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.37        |
|    cost_value_loss       | 8.82        |
|    cost_values           | 2.16        |
|    entropy               | -2.63       |
|    entropy_loss          | -2.63       |
|    explained_variance    | 0.481       |
|    lagrangian_multiplier | 0.00411     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.37        |
|    n_updates             | 3290        |
|    policy_gradient_loss  | -0.0102     |
|    std                   | 0.913       |
|    value_loss            | 2.56        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.31668693 |
| rollout/                 |             |
|    ep_len_mean           | 738         |
|    ep_rew_mean           | -354        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 37          |
|    time_elapsed          | 1063        |
|    total_timesteps       | 677888      |
| train/                   |             |
|    approx_kl             | 0.008896762 |
|    clip_fraction         | 0.103       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.26        |
|    cost_value_loss       | 8.54        |
|    cost_values           | 2.13        |
|    entropy               | -2.62       |
|    entropy_loss          | -2.63       |
|    explained_variance    | 0.396       |
|    lagrangian_multiplier | 0.000153    |
|    learning_rate         | 0.0003      |
|    loss                  | 8.4         |
|    n_updates             | 3300        |
|    policy_gradient_loss  | -0.00415    |
|    std                   | 0.91        |
|    value_loss            | 11.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.26980716  |
| rollout/                 |              |
|    ep_len_mean           | 733          |
|    ep_rew_mean           | -349         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 38           |
|    time_elapsed          | 1092         |
|    total_timesteps       | 679936       |
| train/                   |              |
|    approx_kl             | 0.0070134974 |
|    clip_fraction         | 0.0978       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.72         |
|    cost_value_loss       | 11.2         |
|    cost_values           | 2.17         |
|    entropy               | -2.62        |
|    entropy_loss          | -2.62        |
|    explained_variance    | 0.522        |
|    lagrangian_multiplier | 0.00124      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.03         |
|    n_updates             | 3310         |
|    policy_gradient_loss  | -0.00564     |
|    std                   | 0.908        |
|    value_loss            | 6.4          |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.39        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.39        |
| reward                   | -0.30488855 |
| rollout/                 |             |
|    ep_len_mean           | 738         |
|    ep_rew_mean           | -352        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 39          |
|    time_elapsed          | 1121        |
|    total_timesteps       | 681984      |
| train/                   |             |
|    approx_kl             | 0.005565471 |
|    clip_fraction         | 0.0969      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.98        |
|    cost_value_loss       | 17.6        |
|    cost_values           | 2.35        |
|    entropy               | -2.62       |
|    entropy_loss          | -2.62       |
|    explained_variance    | 0.479       |
|    lagrangian_multiplier | 0.00218     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.44        |
|    n_updates             | 3320        |
|    policy_gradient_loss  | -0.00558    |
|    std                   | 0.908       |
|    value_loss            | 18.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.59        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.59        |
| reward                   | -0.74042016 |
| rollout/                 |             |
|    ep_len_mean           | 726         |
|    ep_rew_mean           | -343        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 40          |
|    time_elapsed          | 1148        |
|    total_timesteps       | 684032      |
| train/                   |             |
|    approx_kl             | 0.011294959 |
|    clip_fraction         | 0.118       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.78        |
|    cost_value_loss       | 9.67        |
|    cost_values           | 2.35        |
|    entropy               | -2.61       |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.543       |
|    lagrangian_multiplier | 0.00107     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.92        |
|    n_updates             | 3330        |
|    policy_gradient_loss  | -0.00671    |
|    std                   | 0.904       |
|    value_loss            | 8.64        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.83338946  |
| rollout/                 |              |
|    ep_len_mean           | 730          |
|    ep_rew_mean           | -344         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 41           |
|    time_elapsed          | 1177         |
|    total_timesteps       | 686080       |
| train/                   |              |
|    approx_kl             | 0.0058962726 |
|    clip_fraction         | 0.0522       |
|    clip_range            | 0.2          |
|    cost_returns          | 3.39         |
|    cost_value_loss       | 4.06         |
|    cost_values           | 2.27         |
|    entropy               | -2.62        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.441        |
|    lagrangian_multiplier | 0.000405     |
|    learning_rate         | 0.0003       |
|    loss                  | 12.3         |
|    n_updates             | 3340         |
|    policy_gradient_loss  | -0.00411     |
|    std                   | 0.907        |
|    value_loss            | 22.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.6120384   |
| rollout/                 |              |
|    ep_len_mean           | 733          |
|    ep_rew_mean           | -346         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 42           |
|    time_elapsed          | 1206         |
|    total_timesteps       | 688128       |
| train/                   |              |
|    approx_kl             | 0.0082109645 |
|    clip_fraction         | 0.0614       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.71         |
|    cost_value_loss       | 10.5         |
|    cost_values           | 2.25         |
|    entropy               | -2.61        |
|    entropy_loss          | -2.61        |
|    explained_variance    | 0.822        |
|    lagrangian_multiplier | 0.000647     |
|    learning_rate         | 0.0003       |
|    loss                  | 7.43         |
|    n_updates             | 3350         |
|    policy_gradient_loss  | -0.00538     |
|    std                   | 0.904        |
|    value_loss            | 6.59         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.51598144 |
| rollout/                 |             |
|    ep_len_mean           | 734         |
|    ep_rew_mean           | -347        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 43          |
|    time_elapsed          | 1236        |
|    total_timesteps       | 690176      |
| train/                   |             |
|    approx_kl             | 0.008949462 |
|    clip_fraction         | 0.099       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.68        |
|    cost_value_loss       | 11.8        |
|    cost_values           | 2.28        |
|    entropy               | -2.6        |
|    entropy_loss          | -2.61       |
|    explained_variance    | 0.896       |
|    lagrangian_multiplier | 0.00251     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.13        |
|    n_updates             | 3360        |
|    policy_gradient_loss  | -0.00617    |
|    std                   | 0.901       |
|    value_loss            | 5.7         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.37990832 |
| rollout/                 |             |
|    ep_len_mean           | 721         |
|    ep_rew_mean           | -339        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 44          |
|    time_elapsed          | 1264        |
|    total_timesteps       | 692224      |
| train/                   |             |
|    approx_kl             | 0.009275172 |
|    clip_fraction         | 0.096       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.78        |
|    cost_value_loss       | 10.5        |
|    cost_values           | 2.34        |
|    entropy               | -2.59       |
|    entropy_loss          | -2.6        |
|    explained_variance    | 0.455       |
|    lagrangian_multiplier | 0.00116     |
|    learning_rate         | 0.0003      |
|    loss                  | 10.7        |
|    n_updates             | 3370        |
|    policy_gradient_loss  | -0.00344    |
|    std                   | 0.896       |
|    value_loss            | 17          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.2867685   |
| rollout/                 |              |
|    ep_len_mean           | 724          |
|    ep_rew_mean           | -341         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 45           |
|    time_elapsed          | 1293         |
|    total_timesteps       | 694272       |
| train/                   |              |
|    approx_kl             | 0.0054597408 |
|    clip_fraction         | 0.0646       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.06         |
|    cost_value_loss       | 11.8         |
|    cost_values           | 2.22         |
|    entropy               | -2.59        |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.547        |
|    lagrangian_multiplier | 0.00128      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.2          |
|    n_updates             | 3380         |
|    policy_gradient_loss  | -0.00392     |
|    std                   | 0.894        |
|    value_loss            | 16.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.24500859  |
| rollout/                 |              |
|    ep_len_mean           | 717          |
|    ep_rew_mean           | -338         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 46           |
|    time_elapsed          | 1321         |
|    total_timesteps       | 696320       |
| train/                   |              |
|    approx_kl             | 0.0053719254 |
|    clip_fraction         | 0.0499       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.25         |
|    cost_value_loss       | 14.7         |
|    cost_values           | 2.27         |
|    entropy               | -2.58        |
|    entropy_loss          | -2.58        |
|    explained_variance    | 0.538        |
|    lagrangian_multiplier | 0.00255      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.21         |
|    n_updates             | 3390         |
|    policy_gradient_loss  | -0.00374     |
|    std                   | 0.89         |
|    value_loss            | 7.92         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.6         |
| reward                   | -0.34771496 |
| rollout/                 |             |
|    ep_len_mean           | 718         |
|    ep_rew_mean           | -338        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 47          |
|    time_elapsed          | 1350        |
|    total_timesteps       | 698368      |
| train/                   |             |
|    approx_kl             | 0.007942507 |
|    clip_fraction         | 0.135       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.51        |
|    cost_value_loss       | 14          |
|    cost_values           | 2.35        |
|    entropy               | -2.57       |
|    entropy_loss          | -2.57       |
|    explained_variance    | 0.286       |
|    lagrangian_multiplier | 0.00105     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.03        |
|    n_updates             | 3400        |
|    policy_gradient_loss  | -0.00568    |
|    std                   | 0.887       |
|    value_loss            | 9.75        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.9         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.9         |
| reward                   | -0.522313   |
| rollout/                 |             |
|    ep_len_mean           | 714         |
|    ep_rew_mean           | -333        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 48          |
|    time_elapsed          | 1378        |
|    total_timesteps       | 700416      |
| train/                   |             |
|    approx_kl             | 0.008964698 |
|    clip_fraction         | 0.0685      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.37        |
|    cost_value_loss       | 8.95        |
|    cost_values           | 2.24        |
|    entropy               | -2.57       |
|    entropy_loss          | -2.57       |
|    explained_variance    | 0.431       |
|    lagrangian_multiplier | 0.00247     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.96        |
|    n_updates             | 3410        |
|    policy_gradient_loss  | -0.00618    |
|    std                   | 0.885       |
|    value_loss            | 18.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.70030487 |
| rollout/                 |             |
|    ep_len_mean           | 702         |
|    ep_rew_mean           | -325        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 49          |
|    time_elapsed          | 1407        |
|    total_timesteps       | 702464      |
| train/                   |             |
|    approx_kl             | 0.004312776 |
|    clip_fraction         | 0.0859      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.77        |
|    cost_value_loss       | 8.83        |
|    cost_values           | 2.3         |
|    entropy               | -2.56       |
|    entropy_loss          | -2.57       |
|    explained_variance    | 0.535       |
|    lagrangian_multiplier | 0.00247     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.58        |
|    n_updates             | 3420        |
|    policy_gradient_loss  | -0.00344    |
|    std                   | 0.884       |
|    value_loss            | 6.4         |
------------------------------------------
------------------------------------
| avg_speed          | 7.93        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 7.93        |
| reward             | -0.30846965 |
| rollout/           |             |
|    ep_len_mean     | 694         |
|    ep_rew_mean     | -318        |
| time/              |             |
|    fps             | 78          |
|    iterations      | 1           |
|    time_elapsed    | 26          |
|    total_timesteps | 704512      |
------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.5933029  |
| rollout/                 |             |
|    ep_len_mean           | 665         |
|    ep_rew_mean           | -303        |
| time/                    |             |
|    fps                   | 75          |
|    iterations            | 2           |
|    time_elapsed          | 54          |
|    total_timesteps       | 706560      |
| train/                   |             |
|    approx_kl             | 0.008881932 |
|    clip_fraction         | 0.0475      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.46        |
|    cost_value_loss       | 13.1        |
|    cost_values           | 2.38        |
|    entropy               | -2.56       |
|    entropy_loss          | -2.56       |
|    explained_variance    | 0.379       |
|    lagrangian_multiplier | 0.000603    |
|    learning_rate         | 0.0003      |
|    loss                  | 9.8         |
|    n_updates             | 3440        |
|    policy_gradient_loss  | -0.00248    |
|    std                   | 0.884       |
|    value_loss            | 11.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.46229187  |
| rollout/                 |              |
|    ep_len_mean           | 650          |
|    ep_rew_mean           | -296         |
| time/                    |              |
|    fps                   | 73           |
|    iterations            | 3            |
|    time_elapsed          | 83           |
|    total_timesteps       | 708608       |
| train/                   |              |
|    approx_kl             | 0.0067922706 |
|    clip_fraction         | 0.066        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.01         |
|    cost_value_loss       | 11.5         |
|    cost_values           | 2.28         |
|    entropy               | -2.56        |
|    entropy_loss          | -2.56        |
|    explained_variance    | 0.267        |
|    lagrangian_multiplier | 0.00176      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.66         |
|    n_updates             | 3450         |
|    policy_gradient_loss  | -0.00309     |
|    std                   | 0.881        |
|    value_loss            | 29.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3159539  |
| rollout/                 |             |
|    ep_len_mean           | 642         |
|    ep_rew_mean           | -291        |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 4           |
|    time_elapsed          | 111         |
|    total_timesteps       | 710656      |
| train/                   |             |
|    approx_kl             | 0.010061378 |
|    clip_fraction         | 0.0574      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.5         |
|    cost_value_loss       | 8.78        |
|    cost_values           | 2.21        |
|    entropy               | -2.55       |
|    entropy_loss          | -2.56       |
|    explained_variance    | 0.418       |
|    lagrangian_multiplier | 0.000531    |
|    learning_rate         | 0.0003      |
|    loss                  | 10.6        |
|    n_updates             | 3460        |
|    policy_gradient_loss  | -0.00233    |
|    std                   | 0.88        |
|    value_loss            | 16.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.85         |
| reward                   | -0.518944    |
| rollout/                 |              |
|    ep_len_mean           | 642          |
|    ep_rew_mean           | -289         |
| time/                    |              |
|    fps                   | 73           |
|    iterations            | 5            |
|    time_elapsed          | 139          |
|    total_timesteps       | 712704       |
| train/                   |              |
|    approx_kl             | 0.0056380425 |
|    clip_fraction         | 0.0959       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.02         |
|    cost_value_loss       | 10.6         |
|    cost_values           | 2.24         |
|    entropy               | -2.54        |
|    entropy_loss          | -2.55        |
|    explained_variance    | 0.301        |
|    lagrangian_multiplier | 0.00134      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.51         |
|    n_updates             | 3470         |
|    policy_gradient_loss  | -0.0049      |
|    std                   | 0.875        |
|    value_loss            | 14.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.76        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.76        |
| reward                   | -0.5868753  |
| rollout/                 |             |
|    ep_len_mean           | 626         |
|    ep_rew_mean           | -280        |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 6           |
|    time_elapsed          | 167         |
|    total_timesteps       | 714752      |
| train/                   |             |
|    approx_kl             | 0.023457272 |
|    clip_fraction         | 0.0994      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.95        |
|    cost_value_loss       | 9.93        |
|    cost_values           | 2.5         |
|    entropy               | -2.53       |
|    entropy_loss          | -2.54       |
|    explained_variance    | 0.661       |
|    lagrangian_multiplier | 0.00158     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.14        |
|    n_updates             | 3480        |
|    policy_gradient_loss  | -0.00334    |
|    std                   | 0.867       |
|    value_loss            | 1.46        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.3577604  |
| rollout/                 |             |
|    ep_len_mean           | 629         |
|    ep_rew_mean           | -280        |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 7           |
|    time_elapsed          | 195         |
|    total_timesteps       | 716800      |
| train/                   |             |
|    approx_kl             | 0.028683938 |
|    clip_fraction         | 0.411       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.69        |
|    cost_value_loss       | 10.2        |
|    cost_values           | 2.28        |
|    entropy               | -2.53       |
|    entropy_loss          | -2.52       |
|    explained_variance    | 0.32        |
|    lagrangian_multiplier | 0.000294    |
|    learning_rate         | 0.0003      |
|    loss                  | 11.7        |
|    n_updates             | 3490        |
|    policy_gradient_loss  | 0.0402      |
|    std                   | 0.868       |
|    value_loss            | 21.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.27797383 |
| rollout/                 |             |
|    ep_len_mean           | 627         |
|    ep_rew_mean           | -277        |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 8           |
|    time_elapsed          | 224         |
|    total_timesteps       | 718848      |
| train/                   |             |
|    approx_kl             | 0.008180935 |
|    clip_fraction         | 0.132       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.94        |
|    cost_value_loss       | 18.8        |
|    cost_values           | 2.34        |
|    entropy               | -2.53       |
|    entropy_loss          | -2.53       |
|    explained_variance    | 0.61        |
|    lagrangian_multiplier | 0.00378     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.33        |
|    n_updates             | 3500        |
|    policy_gradient_loss  | -0.00758    |
|    std                   | 0.868       |
|    value_loss            | 6.39        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.31         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.31         |
| reward                   | -0.68804646  |
| rollout/                 |              |
|    ep_len_mean           | 608          |
|    ep_rew_mean           | -268         |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 9            |
|    time_elapsed          | 253          |
|    total_timesteps       | 720896       |
| train/                   |              |
|    approx_kl             | 0.0045935647 |
|    clip_fraction         | 0.0541       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.16         |
|    cost_value_loss       | 12.9         |
|    cost_values           | 2.31         |
|    entropy               | -2.53        |
|    entropy_loss          | -2.53        |
|    explained_variance    | 0.392        |
|    lagrangian_multiplier | 0.000271     |
|    learning_rate         | 0.0003       |
|    loss                  | 10.7         |
|    n_updates             | 3510         |
|    policy_gradient_loss  | -0.00465     |
|    std                   | 0.871        |
|    value_loss            | 11.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.69016564 |
| rollout/                 |             |
|    ep_len_mean           | 601         |
|    ep_rew_mean           | -263        |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 10          |
|    time_elapsed          | 282         |
|    total_timesteps       | 722944      |
| train/                   |             |
|    approx_kl             | 0.005897953 |
|    clip_fraction         | 0.0639      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.76        |
|    cost_value_loss       | 11          |
|    cost_values           | 2.28        |
|    entropy               | -2.53       |
|    entropy_loss          | -2.53       |
|    explained_variance    | 0.373       |
|    lagrangian_multiplier | 0.000133    |
|    learning_rate         | 0.0003      |
|    loss                  | 10.4        |
|    n_updates             | 3520        |
|    policy_gradient_loss  | -0.00582    |
|    std                   | 0.871       |
|    value_loss            | 19.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.34946355  |
| rollout/                 |              |
|    ep_len_mean           | 601          |
|    ep_rew_mean           | -263         |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 11           |
|    time_elapsed          | 311          |
|    total_timesteps       | 724992       |
| train/                   |              |
|    approx_kl             | 0.0062765107 |
|    clip_fraction         | 0.106        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.86         |
|    cost_value_loss       | 10.8         |
|    cost_values           | 2.34         |
|    entropy               | -2.53        |
|    entropy_loss          | -2.53        |
|    explained_variance    | 0.316        |
|    lagrangian_multiplier | 0.00366      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.21         |
|    n_updates             | 3530         |
|    policy_gradient_loss  | -0.00477     |
|    std                   | 0.872        |
|    value_loss            | 10.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.25437978 |
| rollout/                 |             |
|    ep_len_mean           | 587         |
|    ep_rew_mean           | -256        |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 12          |
|    time_elapsed          | 340         |
|    total_timesteps       | 727040      |
| train/                   |             |
|    approx_kl             | 0.008829225 |
|    clip_fraction         | 0.0961      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.37        |
|    cost_value_loss       | 13.5        |
|    cost_values           | 2.21        |
|    entropy               | -2.53       |
|    entropy_loss          | -2.53       |
|    explained_variance    | 0.384       |
|    lagrangian_multiplier | 0.00111     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.76        |
|    n_updates             | 3540        |
|    policy_gradient_loss  | -0.0065     |
|    std                   | 0.87        |
|    value_loss            | 11.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.32048094  |
| rollout/                 |              |
|    ep_len_mean           | 590          |
|    ep_rew_mean           | -256         |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 13           |
|    time_elapsed          | 368          |
|    total_timesteps       | 729088       |
| train/                   |              |
|    approx_kl             | 0.0055906135 |
|    clip_fraction         | 0.0963       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.27         |
|    cost_value_loss       | 13.7         |
|    cost_values           | 2.27         |
|    entropy               | -2.53        |
|    entropy_loss          | -2.53        |
|    explained_variance    | 0.383        |
|    lagrangian_multiplier | 0.000917     |
|    learning_rate         | 0.0003       |
|    loss                  | 13           |
|    n_updates             | 3550         |
|    policy_gradient_loss  | -0.00503     |
|    std                   | 0.869        |
|    value_loss            | 25.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.33346915 |
| rollout/                 |             |
|    ep_len_mean           | 592         |
|    ep_rew_mean           | -255        |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 14          |
|    time_elapsed          | 397         |
|    total_timesteps       | 731136      |
| train/                   |             |
|    approx_kl             | 0.008043075 |
|    clip_fraction         | 0.0633      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.47        |
|    cost_value_loss       | 16.6        |
|    cost_values           | 2.29        |
|    entropy               | -2.52       |
|    entropy_loss          | -2.52       |
|    explained_variance    | 0.65        |
|    lagrangian_multiplier | 0.00168     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.79        |
|    n_updates             | 3560        |
|    policy_gradient_loss  | -0.00591    |
|    std                   | 0.866       |
|    value_loss            | 6.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.46854824 |
| rollout/                 |             |
|    ep_len_mean           | 591         |
|    ep_rew_mean           | -253        |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 15          |
|    time_elapsed          | 425         |
|    total_timesteps       | 733184      |
| train/                   |             |
|    approx_kl             | 0.00531679  |
|    clip_fraction         | 0.0555      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.33        |
|    cost_value_loss       | 11.9        |
|    cost_values           | 2.41        |
|    entropy               | -2.51       |
|    entropy_loss          | -2.52       |
|    explained_variance    | 0.418       |
|    lagrangian_multiplier | 0.00119     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.45        |
|    n_updates             | 3570        |
|    policy_gradient_loss  | -0.00403    |
|    std                   | 0.864       |
|    value_loss            | 13.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.30111292 |
| rollout/                 |             |
|    ep_len_mean           | 596         |
|    ep_rew_mean           | -255        |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 16          |
|    time_elapsed          | 452         |
|    total_timesteps       | 735232      |
| train/                   |             |
|    approx_kl             | 0.010582645 |
|    clip_fraction         | 0.127       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.01        |
|    cost_value_loss       | 11.7        |
|    cost_values           | 2.29        |
|    entropy               | -2.51       |
|    entropy_loss          | -2.51       |
|    explained_variance    | 0.28        |
|    lagrangian_multiplier | 0.00141     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.85        |
|    n_updates             | 3580        |
|    policy_gradient_loss  | -0.00978    |
|    std                   | 0.862       |
|    value_loss            | 6.41        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.5342642  |
| rollout/                 |             |
|    ep_len_mean           | 587         |
|    ep_rew_mean           | -252        |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 17          |
|    time_elapsed          | 480         |
|    total_timesteps       | 737280      |
| train/                   |             |
|    approx_kl             | 0.013918652 |
|    clip_fraction         | 0.0983      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.48        |
|    cost_value_loss       | 15.7        |
|    cost_values           | 2.29        |
|    entropy               | -2.5        |
|    entropy_loss          | -2.51       |
|    explained_variance    | 0.506       |
|    lagrangian_multiplier | 0.00332     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.24        |
|    n_updates             | 3590        |
|    policy_gradient_loss  | -0.00556    |
|    std                   | 0.859       |
|    value_loss            | 6.36        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.67         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.67         |
| reward                   | -0.33614945  |
| rollout/                 |              |
|    ep_len_mean           | 593          |
|    ep_rew_mean           | -255         |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 18           |
|    time_elapsed          | 510          |
|    total_timesteps       | 739328       |
| train/                   |              |
|    approx_kl             | 0.0036954586 |
|    clip_fraction         | 0.086        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.1          |
|    cost_value_loss       | 14.9         |
|    cost_values           | 2.38         |
|    entropy               | -2.5         |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0.471        |
|    lagrangian_multiplier | 0.000204     |
|    learning_rate         | 0.0003       |
|    loss                  | 14.1         |
|    n_updates             | 3600         |
|    policy_gradient_loss  | -0.0029      |
|    std                   | 0.86         |
|    value_loss            | 17.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.4459152  |
| rollout/                 |             |
|    ep_len_mean           | 585         |
|    ep_rew_mean           | -250        |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 19          |
|    time_elapsed          | 538         |
|    total_timesteps       | 741376      |
| train/                   |             |
|    approx_kl             | 0.009654829 |
|    clip_fraction         | 0.122       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.73        |
|    cost_value_loss       | 17.5        |
|    cost_values           | 2.44        |
|    entropy               | -2.5        |
|    entropy_loss          | -2.5        |
|    explained_variance    | 0.461       |
|    lagrangian_multiplier | 0.00131     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.45        |
|    n_updates             | 3610        |
|    policy_gradient_loss  | -0.00663    |
|    std                   | 0.857       |
|    value_loss            | 6.61        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.44378063 |
| rollout/                 |             |
|    ep_len_mean           | 598         |
|    ep_rew_mean           | -255        |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 20          |
|    time_elapsed          | 567         |
|    total_timesteps       | 743424      |
| train/                   |             |
|    approx_kl             | 0.008789491 |
|    clip_fraction         | 0.0802      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.97        |
|    cost_value_loss       | 11.1        |
|    cost_values           | 2.54        |
|    entropy               | -2.5        |
|    entropy_loss          | -2.5        |
|    explained_variance    | 0.47        |
|    lagrangian_multiplier | 0.00212     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.87        |
|    n_updates             | 3620        |
|    policy_gradient_loss  | -0.00515    |
|    std                   | 0.857       |
|    value_loss            | 19.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.381353   |
| rollout/                 |             |
|    ep_len_mean           | 592         |
|    ep_rew_mean           | -252        |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 21          |
|    time_elapsed          | 596         |
|    total_timesteps       | 745472      |
| train/                   |             |
|    approx_kl             | 0.025013661 |
|    clip_fraction         | 0.108       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.2         |
|    cost_value_loss       | 18.1        |
|    cost_values           | 2.61        |
|    entropy               | -2.49       |
|    entropy_loss          | -2.49       |
|    explained_variance    | 0.724       |
|    lagrangian_multiplier | 0.00344     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.05        |
|    n_updates             | 3630        |
|    policy_gradient_loss  | -0.00438    |
|    std                   | 0.854       |
|    value_loss            | 1.68        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.39649293 |
| rollout/                 |             |
|    ep_len_mean           | 584         |
|    ep_rew_mean           | -246        |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 22          |
|    time_elapsed          | 625         |
|    total_timesteps       | 747520      |
| train/                   |             |
|    approx_kl             | 0.005798597 |
|    clip_fraction         | 0.143       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.08        |
|    cost_value_loss       | 17.9        |
|    cost_values           | 2.43        |
|    entropy               | -2.48       |
|    entropy_loss          | -2.48       |
|    explained_variance    | 0.313       |
|    lagrangian_multiplier | 0.0036      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.94        |
|    n_updates             | 3640        |
|    policy_gradient_loss  | -0.00389    |
|    std                   | 0.853       |
|    value_loss            | 13          |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.55579203 |
| rollout/                 |             |
|    ep_len_mean           | 561         |
|    ep_rew_mean           | -235        |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 23          |
|    time_elapsed          | 653         |
|    total_timesteps       | 749568      |
| train/                   |             |
|    approx_kl             | 0.009746173 |
|    clip_fraction         | 0.0551      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.09        |
|    cost_value_loss       | 12.6        |
|    cost_values           | 2.37        |
|    entropy               | -2.49       |
|    entropy_loss          | -2.48       |
|    explained_variance    | 0.372       |
|    lagrangian_multiplier | 0.000179    |
|    learning_rate         | 0.0003      |
|    loss                  | 11.8        |
|    n_updates             | 3650        |
|    policy_gradient_loss  | -0.00328    |
|    std                   | 0.853       |
|    value_loss            | 17.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.4341386  |
| rollout/                 |             |
|    ep_len_mean           | 537         |
|    ep_rew_mean           | -226        |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 24          |
|    time_elapsed          | 682         |
|    total_timesteps       | 751616      |
| train/                   |             |
|    approx_kl             | 0.007246328 |
|    clip_fraction         | 0.0804      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.51        |
|    cost_value_loss       | 16.2        |
|    cost_values           | 2.26        |
|    entropy               | -2.49       |
|    entropy_loss          | -2.49       |
|    explained_variance    | 0.263       |
|    lagrangian_multiplier | 0.000922    |
|    learning_rate         | 0.0003      |
|    loss                  | 18.9        |
|    n_updates             | 3660        |
|    policy_gradient_loss  | -0.00507    |
|    std                   | 0.854       |
|    value_loss            | 36.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.45216885 |
| rollout/                 |             |
|    ep_len_mean           | 532         |
|    ep_rew_mean           | -223        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 25          |
|    time_elapsed          | 711         |
|    total_timesteps       | 753664      |
| train/                   |             |
|    approx_kl             | 0.005800477 |
|    clip_fraction         | 0.0592      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.36        |
|    cost_value_loss       | 16.4        |
|    cost_values           | 2.32        |
|    entropy               | -2.48       |
|    entropy_loss          | -2.48       |
|    explained_variance    | 0.205       |
|    lagrangian_multiplier | 0.00104     |
|    learning_rate         | 0.0003      |
|    loss                  | 15.8        |
|    n_updates             | 3670        |
|    policy_gradient_loss  | -0.00367    |
|    std                   | 0.851       |
|    value_loss            | 28.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.3143438  |
| rollout/                 |             |
|    ep_len_mean           | 533         |
|    ep_rew_mean           | -223        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 26          |
|    time_elapsed          | 740         |
|    total_timesteps       | 755712      |
| train/                   |             |
|    approx_kl             | 0.005339699 |
|    clip_fraction         | 0.0522      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.61        |
|    cost_value_loss       | 16.9        |
|    cost_values           | 2.36        |
|    entropy               | -2.48       |
|    entropy_loss          | -2.48       |
|    explained_variance    | 0.468       |
|    lagrangian_multiplier | 0.0013      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.03        |
|    n_updates             | 3680        |
|    policy_gradient_loss  | -0.004      |
|    std                   | 0.85        |
|    value_loss            | 14          |
------------------------------------------
------------------------------------------
| avg_speed                | 7.72        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.72        |
| reward                   | -0.49752462 |
| rollout/                 |             |
|    ep_len_mean           | 531         |
|    ep_rew_mean           | -223        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 27          |
|    time_elapsed          | 769         |
|    total_timesteps       | 757760      |
| train/                   |             |
|    approx_kl             | 0.009359419 |
|    clip_fraction         | 0.0881      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.35        |
|    cost_value_loss       | 19.3        |
|    cost_values           | 2.57        |
|    entropy               | -2.47       |
|    entropy_loss          | -2.48       |
|    explained_variance    | 0.401       |
|    lagrangian_multiplier | 0.00485     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.01        |
|    n_updates             | 3690        |
|    policy_gradient_loss  | -0.00535    |
|    std                   | 0.848       |
|    value_loss            | 9.48        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.91        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.91        |
| reward                   | -0.376128   |
| rollout/                 |             |
|    ep_len_mean           | 537         |
|    ep_rew_mean           | -225        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 28          |
|    time_elapsed          | 798         |
|    total_timesteps       | 759808      |
| train/                   |             |
|    approx_kl             | 0.011107963 |
|    clip_fraction         | 0.1         |
|    clip_range            | 0.2         |
|    cost_returns          | 4.45        |
|    cost_value_loss       | 8.36        |
|    cost_values           | 2.4         |
|    entropy               | -2.46       |
|    entropy_loss          | -2.47       |
|    explained_variance    | 0.291       |
|    lagrangian_multiplier | 0.00225     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.31        |
|    n_updates             | 3700        |
|    policy_gradient_loss  | -0.00582    |
|    std                   | 0.843       |
|    value_loss            | 9.87        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.23262404 |
| rollout/                 |             |
|    ep_len_mean           | 534         |
|    ep_rew_mean           | -224        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 29          |
|    time_elapsed          | 827         |
|    total_timesteps       | 761856      |
| train/                   |             |
|    approx_kl             | 0.005694025 |
|    clip_fraction         | 0.0814      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.6         |
|    cost_value_loss       | 18          |
|    cost_values           | 2.38        |
|    entropy               | -2.45       |
|    entropy_loss          | -2.46       |
|    explained_variance    | 0.391       |
|    lagrangian_multiplier | 0.0022      |
|    learning_rate         | 0.0003      |
|    loss                  | 9.25        |
|    n_updates             | 3710        |
|    policy_gradient_loss  | -0.0046     |
|    std                   | 0.84        |
|    value_loss            | 16.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.9         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.9         |
| reward                   | -0.48141578 |
| rollout/                 |             |
|    ep_len_mean           | 543         |
|    ep_rew_mean           | -228        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 30          |
|    time_elapsed          | 856         |
|    total_timesteps       | 763904      |
| train/                   |             |
|    approx_kl             | 0.010703561 |
|    clip_fraction         | 0.0713      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.45        |
|    cost_value_loss       | 14.3        |
|    cost_values           | 2.42        |
|    entropy               | -2.45       |
|    entropy_loss          | -2.45       |
|    explained_variance    | 0.363       |
|    lagrangian_multiplier | 0.00157     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.82        |
|    n_updates             | 3720        |
|    policy_gradient_loss  | -0.00499    |
|    std                   | 0.839       |
|    value_loss            | 16.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.25246412 |
| rollout/                 |             |
|    ep_len_mean           | 525         |
|    ep_rew_mean           | -221        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 31          |
|    time_elapsed          | 885         |
|    total_timesteps       | 765952      |
| train/                   |             |
|    approx_kl             | 0.006008827 |
|    clip_fraction         | 0.0886      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.33        |
|    cost_value_loss       | 11.7        |
|    cost_values           | 2.5         |
|    entropy               | -2.45       |
|    entropy_loss          | -2.45       |
|    explained_variance    | 0.293       |
|    lagrangian_multiplier | 0.00648     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.37        |
|    n_updates             | 3730        |
|    policy_gradient_loss  | -0.00559    |
|    std                   | 0.84        |
|    value_loss            | 14.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.63        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.63        |
| reward                   | -0.32148534 |
| rollout/                 |             |
|    ep_len_mean           | 527         |
|    ep_rew_mean           | -221        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 32          |
|    time_elapsed          | 914         |
|    total_timesteps       | 768000      |
| train/                   |             |
|    approx_kl             | 0.009073164 |
|    clip_fraction         | 0.108       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.76        |
|    cost_value_loss       | 15.9        |
|    cost_values           | 2.38        |
|    entropy               | -2.45       |
|    entropy_loss          | -2.45       |
|    explained_variance    | 0.333       |
|    lagrangian_multiplier | 0.00241     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.68        |
|    n_updates             | 3740        |
|    policy_gradient_loss  | -0.00345    |
|    std                   | 0.84        |
|    value_loss            | 20.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.38340974  |
| rollout/                 |              |
|    ep_len_mean           | 518          |
|    ep_rew_mean           | -217         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 33           |
|    time_elapsed          | 942          |
|    total_timesteps       | 770048       |
| train/                   |              |
|    approx_kl             | 0.0077404836 |
|    clip_fraction         | 0.102        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.87         |
|    cost_value_loss       | 12.7         |
|    cost_values           | 2.44         |
|    entropy               | -2.45        |
|    entropy_loss          | -2.45        |
|    explained_variance    | 0.341        |
|    lagrangian_multiplier | 0.000911     |
|    learning_rate         | 0.0003       |
|    loss                  | 7.08         |
|    n_updates             | 3750         |
|    policy_gradient_loss  | -0.0048      |
|    std                   | 0.837        |
|    value_loss            | 5.33         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -0.3293655  |
| rollout/                 |             |
|    ep_len_mean           | 508         |
|    ep_rew_mean           | -212        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 34          |
|    time_elapsed          | 971         |
|    total_timesteps       | 772096      |
| train/                   |             |
|    approx_kl             | 0.009680033 |
|    clip_fraction         | 0.0739      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.46        |
|    cost_value_loss       | 14.6        |
|    cost_values           | 2.39        |
|    entropy               | -2.44       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 0.486       |
|    lagrangian_multiplier | 0.00014     |
|    learning_rate         | 0.0003      |
|    loss                  | 17.5        |
|    n_updates             | 3760        |
|    policy_gradient_loss  | -0.00503    |
|    std                   | 0.837       |
|    value_loss            | 20          |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.12676957 |
| rollout/                 |             |
|    ep_len_mean           | 490         |
|    ep_rew_mean           | -205        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 35          |
|    time_elapsed          | 1000        |
|    total_timesteps       | 774144      |
| train/                   |             |
|    approx_kl             | 0.009785831 |
|    clip_fraction         | 0.077       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.84        |
|    cost_value_loss       | 16.5        |
|    cost_values           | 2.46        |
|    entropy               | -2.44       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 0.384       |
|    lagrangian_multiplier | 0.00301     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.62        |
|    n_updates             | 3770        |
|    policy_gradient_loss  | -0.00411    |
|    std                   | 0.837       |
|    value_loss            | 21.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.38199145  |
| rollout/                 |              |
|    ep_len_mean           | 498          |
|    ep_rew_mean           | -207         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 36           |
|    time_elapsed          | 1029         |
|    total_timesteps       | 776192       |
| train/                   |              |
|    approx_kl             | 0.0055428897 |
|    clip_fraction         | 0.0433       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.5          |
|    cost_value_loss       | 14.5         |
|    cost_values           | 2.44         |
|    entropy               | -2.44        |
|    entropy_loss          | -2.44        |
|    explained_variance    | 0.305        |
|    lagrangian_multiplier | 0.00289      |
|    learning_rate         | 0.0003       |
|    loss                  | 9.01         |
|    n_updates             | 3780         |
|    policy_gradient_loss  | -0.00266     |
|    std                   | 0.837        |
|    value_loss            | 24.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.41883737 |
| rollout/                 |             |
|    ep_len_mean           | 488         |
|    ep_rew_mean           | -203        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 37          |
|    time_elapsed          | 1058        |
|    total_timesteps       | 778240      |
| train/                   |             |
|    approx_kl             | 0.01121749  |
|    clip_fraction         | 0.0979      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.31        |
|    cost_value_loss       | 12.7        |
|    cost_values           | 2.56        |
|    entropy               | -2.43       |
|    entropy_loss          | -2.44       |
|    explained_variance    | 0.351       |
|    lagrangian_multiplier | 0.00169     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.86        |
|    n_updates             | 3790        |
|    policy_gradient_loss  | -0.00467    |
|    std                   | 0.832       |
|    value_loss            | 8           |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.55031955 |
| rollout/                 |             |
|    ep_len_mean           | 485         |
|    ep_rew_mean           | -201        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 38          |
|    time_elapsed          | 1086        |
|    total_timesteps       | 780288      |
| train/                   |             |
|    approx_kl             | 0.011170028 |
|    clip_fraction         | 0.0911      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.09        |
|    cost_value_loss       | 18.5        |
|    cost_values           | 2.48        |
|    entropy               | -2.43       |
|    entropy_loss          | -2.43       |
|    explained_variance    | 0.365       |
|    lagrangian_multiplier | 0.00236     |
|    learning_rate         | 0.0003      |
|    loss                  | 10.5        |
|    n_updates             | 3800        |
|    policy_gradient_loss  | -0.00532    |
|    std                   | 0.83        |
|    value_loss            | 20          |
------------------------------------------
------------------------------------------
| avg_speed                | 7.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.01        |
| reward                   | -0.5387019  |
| rollout/                 |             |
|    ep_len_mean           | 475         |
|    ep_rew_mean           | -198        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 39          |
|    time_elapsed          | 1114        |
|    total_timesteps       | 782336      |
| train/                   |             |
|    approx_kl             | 0.008369168 |
|    clip_fraction         | 0.103       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.82        |
|    cost_value_loss       | 16.7        |
|    cost_values           | 2.52        |
|    entropy               | -2.42       |
|    entropy_loss          | -2.42       |
|    explained_variance    | 0.443       |
|    lagrangian_multiplier | 0.00229     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.59        |
|    n_updates             | 3810        |
|    policy_gradient_loss  | -0.0047     |
|    std                   | 0.827       |
|    value_loss            | 11.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.2852103  |
| rollout/                 |             |
|    ep_len_mean           | 473         |
|    ep_rew_mean           | -197        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 40          |
|    time_elapsed          | 1143        |
|    total_timesteps       | 784384      |
| train/                   |             |
|    approx_kl             | 0.007479504 |
|    clip_fraction         | 0.0918      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.69        |
|    cost_value_loss       | 14.6        |
|    cost_values           | 2.52        |
|    entropy               | -2.41       |
|    entropy_loss          | -2.41       |
|    explained_variance    | 0.352       |
|    lagrangian_multiplier | 0.00156     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.47        |
|    n_updates             | 3820        |
|    policy_gradient_loss  | -0.00613    |
|    std                   | 0.824       |
|    value_loss            | 9.89        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -0.21644     |
| rollout/                 |              |
|    ep_len_mean           | 467          |
|    ep_rew_mean           | -192         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 41           |
|    time_elapsed          | 1172         |
|    total_timesteps       | 786432       |
| train/                   |              |
|    approx_kl             | 0.0071854126 |
|    clip_fraction         | 0.071        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.78         |
|    cost_value_loss       | 15.8         |
|    cost_values           | 2.62         |
|    entropy               | -2.4         |
|    entropy_loss          | -2.41        |
|    explained_variance    | 0.552        |
|    lagrangian_multiplier | 0.00271      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.72         |
|    n_updates             | 3830         |
|    policy_gradient_loss  | -0.00386     |
|    std                   | 0.822        |
|    value_loss            | 16.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.59998727 |
| rollout/                 |             |
|    ep_len_mean           | 474         |
|    ep_rew_mean           | -196        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 42          |
|    time_elapsed          | 1202        |
|    total_timesteps       | 788480      |
| train/                   |             |
|    approx_kl             | 0.011734592 |
|    clip_fraction         | 0.118       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.59        |
|    cost_value_loss       | 13.3        |
|    cost_values           | 2.66        |
|    entropy               | -2.4        |
|    entropy_loss          | -2.4        |
|    explained_variance    | 0.384       |
|    lagrangian_multiplier | 0.00373     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.18        |
|    n_updates             | 3840        |
|    policy_gradient_loss  | -0.00369    |
|    std                   | 0.822       |
|    value_loss            | 11.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.43157706 |
| rollout/                 |             |
|    ep_len_mean           | 466         |
|    ep_rew_mean           | -193        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 43          |
|    time_elapsed          | 1230        |
|    total_timesteps       | 790528      |
| train/                   |             |
|    approx_kl             | 0.008028981 |
|    clip_fraction         | 0.119       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.02        |
|    cost_value_loss       | 18          |
|    cost_values           | 2.76        |
|    entropy               | -2.4        |
|    entropy_loss          | -2.4        |
|    explained_variance    | 0.329       |
|    lagrangian_multiplier | 0.0018      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.81        |
|    n_updates             | 3850        |
|    policy_gradient_loss  | 0.00127     |
|    std                   | 0.822       |
|    value_loss            | 5.37        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.40465534 |
| rollout/                 |             |
|    ep_len_mean           | 473         |
|    ep_rew_mean           | -194        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 44          |
|    time_elapsed          | 1258        |
|    total_timesteps       | 792576      |
| train/                   |             |
|    approx_kl             | 0.011563391 |
|    clip_fraction         | 0.128       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.14        |
|    cost_value_loss       | 12.9        |
|    cost_values           | 2.84        |
|    entropy               | -2.41       |
|    entropy_loss          | -2.41       |
|    explained_variance    | 0.314       |
|    lagrangian_multiplier | 0.00216     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.65        |
|    n_updates             | 3860        |
|    policy_gradient_loss  | -0.00424    |
|    std                   | 0.824       |
|    value_loss            | 13.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.43288666 |
| rollout/                 |             |
|    ep_len_mean           | 478         |
|    ep_rew_mean           | -196        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 45          |
|    time_elapsed          | 1287        |
|    total_timesteps       | 794624      |
| train/                   |             |
|    approx_kl             | 0.006358823 |
|    clip_fraction         | 0.0557      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.09        |
|    cost_value_loss       | 13.5        |
|    cost_values           | 2.68        |
|    entropy               | -2.41       |
|    entropy_loss          | -2.41       |
|    explained_variance    | 0.375       |
|    lagrangian_multiplier | 0.0024      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.98        |
|    n_updates             | 3870        |
|    policy_gradient_loss  | -0.00489    |
|    std                   | 0.825       |
|    value_loss            | 1.98        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.3972349  |
| rollout/                 |             |
|    ep_len_mean           | 487         |
|    ep_rew_mean           | -199        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 46          |
|    time_elapsed          | 1317        |
|    total_timesteps       | 796672      |
| train/                   |             |
|    approx_kl             | 0.008808676 |
|    clip_fraction         | 0.125       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.52        |
|    cost_value_loss       | 9.77        |
|    cost_values           | 2.5         |
|    entropy               | -2.41       |
|    entropy_loss          | -2.41       |
|    explained_variance    | 0.415       |
|    lagrangian_multiplier | 0.00504     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.39        |
|    n_updates             | 3880        |
|    policy_gradient_loss  | -0.00865    |
|    std                   | 0.825       |
|    value_loss            | 1.8         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.42664838 |
| rollout/                 |             |
|    ep_len_mean           | 490         |
|    ep_rew_mean           | -199        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 47          |
|    time_elapsed          | 1346        |
|    total_timesteps       | 798720      |
| train/                   |             |
|    approx_kl             | 0.009463043 |
|    clip_fraction         | 0.116       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.79        |
|    cost_value_loss       | 16.4        |
|    cost_values           | 2.5         |
|    entropy               | -2.41       |
|    entropy_loss          | -2.41       |
|    explained_variance    | 0.494       |
|    lagrangian_multiplier | 0.00251     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.49        |
|    n_updates             | 3890        |
|    policy_gradient_loss  | -0.00489    |
|    std                   | 0.825       |
|    value_loss            | 9.76        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.85        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.85        |
| reward                   | -0.26845258 |
| rollout/                 |             |
|    ep_len_mean           | 505         |
|    ep_rew_mean           | -204        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 48          |
|    time_elapsed          | 1375        |
|    total_timesteps       | 800768      |
| train/                   |             |
|    approx_kl             | 0.01907472  |
|    clip_fraction         | 0.15        |
|    clip_range            | 0.2         |
|    cost_returns          | 5.67        |
|    cost_value_loss       | 14.8        |
|    cost_values           | 2.5         |
|    entropy               | -2.4        |
|    entropy_loss          | -2.41       |
|    explained_variance    | 0.328       |
|    lagrangian_multiplier | 0.00518     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.3         |
|    n_updates             | 3900        |
|    policy_gradient_loss  | -0.0071     |
|    std                   | 0.823       |
|    value_loss            | 13.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.5778454  |
| rollout/                 |             |
|    ep_len_mean           | 494         |
|    ep_rew_mean           | -198        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 49          |
|    time_elapsed          | 1404        |
|    total_timesteps       | 802816      |
| train/                   |             |
|    approx_kl             | 0.011960241 |
|    clip_fraction         | 0.136       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.57        |
|    cost_value_loss       | 15.1        |
|    cost_values           | 2.45        |
|    entropy               | -2.39       |
|    entropy_loss          | -2.4        |
|    explained_variance    | 0.315       |
|    lagrangian_multiplier | 0.00526     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.99        |
|    n_updates             | 3910        |
|    policy_gradient_loss  | -0.00634    |
|    std                   | 0.819       |
|    value_loss            | 15.8        |
------------------------------------------
------------------------------------
| avg_speed          | 8.04        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8.04        |
| reward             | -0.28186798 |
| rollout/           |             |
|    ep_len_mean     | 484         |
|    ep_rew_mean     | -193        |
| time/              |             |
|    fps             | 76          |
|    iterations      | 1           |
|    time_elapsed    | 26          |
|    total_timesteps | 804864      |
------------------------------------
-------------------------------------------
| avg_speed                | 2.6          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.6          |
| reward                   | -0.95306164  |
| rollout/                 |              |
|    ep_len_mean           | 472          |
|    ep_rew_mean           | -187         |
| time/                    |              |
|    fps                   | 74           |
|    iterations            | 2            |
|    time_elapsed          | 55           |
|    total_timesteps       | 806912       |
| train/                   |              |
|    approx_kl             | 0.0061663305 |
|    clip_fraction         | 0.0813       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.12         |
|    cost_value_loss       | 10.6         |
|    cost_values           | 2.49         |
|    entropy               | -2.38        |
|    entropy_loss          | -2.38        |
|    explained_variance    | 0.295        |
|    lagrangian_multiplier | 0.00315      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.7          |
|    n_updates             | 3930         |
|    policy_gradient_loss  | -0.00651     |
|    std                   | 0.814        |
|    value_loss            | 15.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.35269415  |
| rollout/                 |              |
|    ep_len_mean           | 483          |
|    ep_rew_mean           | -191         |
| time/                    |              |
|    fps                   | 73           |
|    iterations            | 3            |
|    time_elapsed          | 83           |
|    total_timesteps       | 808960       |
| train/                   |              |
|    approx_kl             | 0.0072060875 |
|    clip_fraction         | 0.0917       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.21         |
|    cost_value_loss       | 11.5         |
|    cost_values           | 2.47         |
|    entropy               | -2.37        |
|    entropy_loss          | -2.37        |
|    explained_variance    | 0.326        |
|    lagrangian_multiplier | 0.0013       |
|    learning_rate         | 0.0003       |
|    loss                  | 10.2         |
|    n_updates             | 3940         |
|    policy_gradient_loss  | -0.00517     |
|    std                   | 0.809        |
|    value_loss            | 16.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.38        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.38        |
| reward                   | -0.73934895 |
| rollout/                 |             |
|    ep_len_mean           | 486         |
|    ep_rew_mean           | -192        |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 4           |
|    time_elapsed          | 112         |
|    total_timesteps       | 811008      |
| train/                   |             |
|    approx_kl             | 0.005628937 |
|    clip_fraction         | 0.0417      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.85        |
|    cost_value_loss       | 27.2        |
|    cost_values           | 2.58        |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.764       |
|    lagrangian_multiplier | 0.0028      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.03        |
|    n_updates             | 3950        |
|    policy_gradient_loss  | -0.00295    |
|    std                   | 0.807       |
|    value_loss            | 2.35        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.40382025 |
| rollout/                 |             |
|    ep_len_mean           | 486         |
|    ep_rew_mean           | -191        |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 5           |
|    time_elapsed          | 141         |
|    total_timesteps       | 813056      |
| train/                   |             |
|    approx_kl             | 0.009552175 |
|    clip_fraction         | 0.0508      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.07        |
|    cost_value_loss       | 18.6        |
|    cost_values           | 2.44        |
|    entropy               | -2.36       |
|    entropy_loss          | -2.36       |
|    explained_variance    | 0.599       |
|    lagrangian_multiplier | 0.00133     |
|    learning_rate         | 0.0003      |
|    loss                  | 10.4        |
|    n_updates             | 3960        |
|    policy_gradient_loss  | -0.00262    |
|    std                   | 0.806       |
|    value_loss            | 13.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.5449118   |
| rollout/                 |              |
|    ep_len_mean           | 496          |
|    ep_rew_mean           | -195         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 6            |
|    time_elapsed          | 171          |
|    total_timesteps       | 815104       |
| train/                   |              |
|    approx_kl             | 0.0051565543 |
|    clip_fraction         | 0.0827       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.43         |
|    cost_value_loss       | 19.9         |
|    cost_values           | 2.49         |
|    entropy               | -2.35        |
|    entropy_loss          | -2.36        |
|    explained_variance    | 0.449        |
|    lagrangian_multiplier | 0.00222      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.92         |
|    n_updates             | 3970         |
|    policy_gradient_loss  | -0.00448     |
|    std                   | 0.803        |
|    value_loss            | 4.47         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.23676509 |
| rollout/                 |             |
|    ep_len_mean           | 510         |
|    ep_rew_mean           | -200        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 7           |
|    time_elapsed          | 199         |
|    total_timesteps       | 817152      |
| train/                   |             |
|    approx_kl             | 0.008979219 |
|    clip_fraction         | 0.0895      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.56        |
|    cost_value_loss       | 20.4        |
|    cost_values           | 2.61        |
|    entropy               | -2.35       |
|    entropy_loss          | -2.35       |
|    explained_variance    | 0.22        |
|    lagrangian_multiplier | 0.00697     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.32        |
|    n_updates             | 3980        |
|    policy_gradient_loss  | -0.00433    |
|    std                   | 0.8         |
|    value_loss            | 10.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.1         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.1         |
| reward                   | -0.7759918  |
| rollout/                 |             |
|    ep_len_mean           | 503         |
|    ep_rew_mean           | -196        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 8           |
|    time_elapsed          | 228         |
|    total_timesteps       | 819200      |
| train/                   |             |
|    approx_kl             | 0.016188577 |
|    clip_fraction         | 0.114       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.54        |
|    cost_value_loss       | 13.5        |
|    cost_values           | 2.53        |
|    entropy               | -2.33       |
|    entropy_loss          | -2.34       |
|    explained_variance    | 0.551       |
|    lagrangian_multiplier | 0.00267     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.29        |
|    n_updates             | 3990        |
|    policy_gradient_loss  | -0.00591    |
|    std                   | 0.795       |
|    value_loss            | 5.21        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.87        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.87        |
| reward                   | -0.37145162 |
| rollout/                 |             |
|    ep_len_mean           | 496         |
|    ep_rew_mean           | -193        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 9           |
|    time_elapsed          | 257         |
|    total_timesteps       | 821248      |
| train/                   |             |
|    approx_kl             | 0.010608878 |
|    clip_fraction         | 0.132       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.25        |
|    cost_value_loss       | 12.2        |
|    cost_values           | 2.58        |
|    entropy               | -2.33       |
|    entropy_loss          | -2.33       |
|    explained_variance    | 0.172       |
|    lagrangian_multiplier | 0.00343     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.08        |
|    n_updates             | 4000        |
|    policy_gradient_loss  | -0.00406    |
|    std                   | 0.792       |
|    value_loss            | 16          |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.422307   |
| rollout/                 |             |
|    ep_len_mean           | 497         |
|    ep_rew_mean           | -195        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 10          |
|    time_elapsed          | 286         |
|    total_timesteps       | 823296      |
| train/                   |             |
|    approx_kl             | 0.007487108 |
|    clip_fraction         | 0.0838      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.39        |
|    cost_value_loss       | 20.4        |
|    cost_values           | 2.6         |
|    entropy               | -2.31       |
|    entropy_loss          | -2.32       |
|    explained_variance    | 0.229       |
|    lagrangian_multiplier | 0.00184     |
|    learning_rate         | 0.0003      |
|    loss                  | 10.2        |
|    n_updates             | 4010        |
|    policy_gradient_loss  | -0.00218    |
|    std                   | 0.788       |
|    value_loss            | 15.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.63015795 |
| rollout/                 |             |
|    ep_len_mean           | 499         |
|    ep_rew_mean           | -197        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 11          |
|    time_elapsed          | 315         |
|    total_timesteps       | 825344      |
| train/                   |             |
|    approx_kl             | 0.007079633 |
|    clip_fraction         | 0.106       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.72        |
|    cost_value_loss       | 23.2        |
|    cost_values           | 2.58        |
|    entropy               | -2.31       |
|    entropy_loss          | -2.31       |
|    explained_variance    | 0.462       |
|    lagrangian_multiplier | 0.00314     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.17        |
|    n_updates             | 4020        |
|    policy_gradient_loss  | -0.00301    |
|    std                   | 0.788       |
|    value_loss            | 12.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.25167754 |
| rollout/                 |             |
|    ep_len_mean           | 498         |
|    ep_rew_mean           | -197        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 12          |
|    time_elapsed          | 343         |
|    total_timesteps       | 827392      |
| train/                   |             |
|    approx_kl             | 0.009246511 |
|    clip_fraction         | 0.1         |
|    clip_range            | 0.2         |
|    cost_returns          | 6.09        |
|    cost_value_loss       | 20          |
|    cost_values           | 2.69        |
|    entropy               | -2.3        |
|    entropy_loss          | -2.31       |
|    explained_variance    | 0.527       |
|    lagrangian_multiplier | 0.00504     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.07        |
|    n_updates             | 4030        |
|    policy_gradient_loss  | -0.00427    |
|    std                   | 0.783       |
|    value_loss            | 8.29        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.95        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.95        |
| reward                   | -0.45060465 |
| rollout/                 |             |
|    ep_len_mean           | 508         |
|    ep_rew_mean           | -200        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 13          |
|    time_elapsed          | 372         |
|    total_timesteps       | 829440      |
| train/                   |             |
|    approx_kl             | 0.010703744 |
|    clip_fraction         | 0.0866      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.72        |
|    cost_value_loss       | 9.96        |
|    cost_values           | 2.52        |
|    entropy               | -2.29       |
|    entropy_loss          | -2.29       |
|    explained_variance    | 0.785       |
|    lagrangian_multiplier | 0.000944    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.61        |
|    n_updates             | 4040        |
|    policy_gradient_loss  | -0.00366    |
|    std                   | 0.779       |
|    value_loss            | 4.63        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.46517354 |
| rollout/                 |             |
|    ep_len_mean           | 491         |
|    ep_rew_mean           | -193        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 14          |
|    time_elapsed          | 402         |
|    total_timesteps       | 831488      |
| train/                   |             |
|    approx_kl             | 0.013865339 |
|    clip_fraction         | 0.129       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.83        |
|    cost_value_loss       | 7.96        |
|    cost_values           | 2.36        |
|    entropy               | -2.28       |
|    entropy_loss          | -2.29       |
|    explained_variance    | 0.543       |
|    lagrangian_multiplier | 0.00146     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.28        |
|    n_updates             | 4050        |
|    policy_gradient_loss  | -0.0028     |
|    std                   | 0.777       |
|    value_loss            | 12.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.37591133  |
| rollout/                 |              |
|    ep_len_mean           | 495          |
|    ep_rew_mean           | -196         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 15           |
|    time_elapsed          | 431          |
|    total_timesteps       | 833536       |
| train/                   |              |
|    approx_kl             | 0.0053071817 |
|    clip_fraction         | 0.0564       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.19         |
|    cost_value_loss       | 12.8         |
|    cost_values           | 2.36         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 0.495        |
|    lagrangian_multiplier | 0.000687     |
|    learning_rate         | 0.0003       |
|    loss                  | 11           |
|    n_updates             | 4060         |
|    policy_gradient_loss  | -0.00164     |
|    std                   | 0.776        |
|    value_loss            | 21.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.21        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.21        |
| reward                   | -0.3697173  |
| rollout/                 |             |
|    ep_len_mean           | 487         |
|    ep_rew_mean           | -193        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 16          |
|    time_elapsed          | 460         |
|    total_timesteps       | 835584      |
| train/                   |             |
|    approx_kl             | 0.008805589 |
|    clip_fraction         | 0.0968      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.97        |
|    cost_value_loss       | 17.1        |
|    cost_values           | 2.39        |
|    entropy               | -2.28       |
|    entropy_loss          | -2.28       |
|    explained_variance    | 0.229       |
|    lagrangian_multiplier | 0.00361     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.57        |
|    n_updates             | 4070        |
|    policy_gradient_loss  | -0.0064     |
|    std                   | 0.777       |
|    value_loss            | 9.96        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.2174538   |
| rollout/                 |              |
|    ep_len_mean           | 483          |
|    ep_rew_mean           | -190         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 17           |
|    time_elapsed          | 489          |
|    total_timesteps       | 837632       |
| train/                   |              |
|    approx_kl             | 0.0051944153 |
|    clip_fraction         | 0.0606       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.98         |
|    cost_value_loss       | 11.7         |
|    cost_values           | 2.39         |
|    entropy               | -2.28        |
|    entropy_loss          | -2.28        |
|    explained_variance    | 0.262        |
|    lagrangian_multiplier | 0.000515     |
|    learning_rate         | 0.0003       |
|    loss                  | 12.3         |
|    n_updates             | 4080         |
|    policy_gradient_loss  | -0.0024      |
|    std                   | 0.775        |
|    value_loss            | 15.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.9         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.9         |
| reward                   | -0.43599328 |
| rollout/                 |             |
|    ep_len_mean           | 436         |
|    ep_rew_mean           | -172        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 18          |
|    time_elapsed          | 518         |
|    total_timesteps       | 839680      |
| train/                   |             |
|    approx_kl             | 0.009042003 |
|    clip_fraction         | 0.0944      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.38        |
|    cost_value_loss       | 14.3        |
|    cost_values           | 2.42        |
|    entropy               | -2.27       |
|    entropy_loss          | -2.28       |
|    explained_variance    | 0.418       |
|    lagrangian_multiplier | 0.00203     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.73        |
|    n_updates             | 4090        |
|    policy_gradient_loss  | -0.0051     |
|    std                   | 0.774       |
|    value_loss            | 10.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.44804955  |
| rollout/                 |              |
|    ep_len_mean           | 425          |
|    ep_rew_mean           | -167         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 19           |
|    time_elapsed          | 547          |
|    total_timesteps       | 841728       |
| train/                   |              |
|    approx_kl             | 0.0052811545 |
|    clip_fraction         | 0.114        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.33         |
|    cost_value_loss       | 14.1         |
|    cost_values           | 2.47         |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0.147        |
|    lagrangian_multiplier | 0.00225      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.1         |
|    n_updates             | 4100         |
|    policy_gradient_loss  | -0.00301     |
|    std                   | 0.774        |
|    value_loss            | 22.8         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.22966516  |
| rollout/                 |              |
|    ep_len_mean           | 421          |
|    ep_rew_mean           | -167         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 20           |
|    time_elapsed          | 576          |
|    total_timesteps       | 843776       |
| train/                   |              |
|    approx_kl             | 0.0051560304 |
|    clip_fraction         | 0.0703       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.59         |
|    cost_value_loss       | 15.9         |
|    cost_values           | 2.44         |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0.31         |
|    lagrangian_multiplier | 0.000846     |
|    learning_rate         | 0.0003       |
|    loss                  | 13.7         |
|    n_updates             | 4110         |
|    policy_gradient_loss  | -0.0035      |
|    std                   | 0.774        |
|    value_loss            | 21.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -0.48503622  |
| rollout/                 |              |
|    ep_len_mean           | 434          |
|    ep_rew_mean           | -172         |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 21           |
|    time_elapsed          | 605          |
|    total_timesteps       | 845824       |
| train/                   |              |
|    approx_kl             | 0.0061175535 |
|    clip_fraction         | 0.0817       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.61         |
|    cost_value_loss       | 10.1         |
|    cost_values           | 2.42         |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0.323        |
|    lagrangian_multiplier | 0.00163      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.97         |
|    n_updates             | 4120         |
|    policy_gradient_loss  | -0.00423     |
|    std                   | 0.772        |
|    value_loss            | 14.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.45720232 |
| rollout/                 |             |
|    ep_len_mean           | 438         |
|    ep_rew_mean           | -174        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 22          |
|    time_elapsed          | 634         |
|    total_timesteps       | 847872      |
| train/                   |             |
|    approx_kl             | 0.008041555 |
|    clip_fraction         | 0.0459      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.17        |
|    cost_value_loss       | 19.6        |
|    cost_values           | 2.51        |
|    entropy               | -2.27       |
|    entropy_loss          | -2.27       |
|    explained_variance    | 0.437       |
|    lagrangian_multiplier | 0.00268     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.68        |
|    n_updates             | 4130        |
|    policy_gradient_loss  | -0.00222    |
|    std                   | 0.772       |
|    value_loss            | 9.64        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.3145659   |
| rollout/                 |              |
|    ep_len_mean           | 429          |
|    ep_rew_mean           | -171         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 23           |
|    time_elapsed          | 663          |
|    total_timesteps       | 849920       |
| train/                   |              |
|    approx_kl             | 0.0054161204 |
|    clip_fraction         | 0.0792       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.08         |
|    cost_value_loss       | 11.7         |
|    cost_values           | 2.57         |
|    entropy               | -2.27        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0.228        |
|    lagrangian_multiplier | 0.000585     |
|    learning_rate         | 0.0003       |
|    loss                  | 11           |
|    n_updates             | 4140         |
|    policy_gradient_loss  | -0.004       |
|    std                   | 0.773        |
|    value_loss            | 18.7         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.27811617  |
| rollout/                 |              |
|    ep_len_mean           | 423          |
|    ep_rew_mean           | -168         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 24           |
|    time_elapsed          | 692          |
|    total_timesteps       | 851968       |
| train/                   |              |
|    approx_kl             | 0.0053385966 |
|    clip_fraction         | 0.124        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.88         |
|    cost_value_loss       | 10.6         |
|    cost_values           | 2.55         |
|    entropy               | -2.26        |
|    entropy_loss          | -2.27        |
|    explained_variance    | 0.318        |
|    lagrangian_multiplier | 0.00194      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.1          |
|    n_updates             | 4150         |
|    policy_gradient_loss  | -0.000534    |
|    std                   | 0.772        |
|    value_loss            | 15.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.40016198 |
| rollout/                 |             |
|    ep_len_mean           | 420         |
|    ep_rew_mean           | -167        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 25          |
|    time_elapsed          | 721         |
|    total_timesteps       | 854016      |
| train/                   |             |
|    approx_kl             | 0.008361006 |
|    clip_fraction         | 0.112       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.95        |
|    cost_value_loss       | 9.02        |
|    cost_values           | 2.59        |
|    entropy               | -2.27       |
|    entropy_loss          | -2.26       |
|    explained_variance    | 0.385       |
|    lagrangian_multiplier | 0.00238     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.21        |
|    n_updates             | 4160        |
|    policy_gradient_loss  | -0.00441    |
|    std                   | 0.774       |
|    value_loss            | 12.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.39330262 |
| rollout/                 |             |
|    ep_len_mean           | 417         |
|    ep_rew_mean           | -166        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 26          |
|    time_elapsed          | 750         |
|    total_timesteps       | 856064      |
| train/                   |             |
|    approx_kl             | 0.014516156 |
|    clip_fraction         | 0.133       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.05        |
|    cost_value_loss       | 13.4        |
|    cost_values           | 2.48        |
|    entropy               | -2.26       |
|    entropy_loss          | -2.27       |
|    explained_variance    | 0.27        |
|    lagrangian_multiplier | 0.00251     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.57        |
|    n_updates             | 4170        |
|    policy_gradient_loss  | -0.00389    |
|    std                   | 0.773       |
|    value_loss            | 12.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.1296526  |
| rollout/                 |             |
|    ep_len_mean           | 402         |
|    ep_rew_mean           | -160        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 27          |
|    time_elapsed          | 779         |
|    total_timesteps       | 858112      |
| train/                   |             |
|    approx_kl             | 0.009747041 |
|    clip_fraction         | 0.0995      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.88        |
|    cost_value_loss       | 17.7        |
|    cost_values           | 2.49        |
|    entropy               | -2.26       |
|    entropy_loss          | -2.26       |
|    explained_variance    | 0.545       |
|    lagrangian_multiplier | 0.00151     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.45        |
|    n_updates             | 4180        |
|    policy_gradient_loss  | -0.00257    |
|    std                   | 0.773       |
|    value_loss            | 8.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.36920464 |
| rollout/                 |             |
|    ep_len_mean           | 402         |
|    ep_rew_mean           | -161        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 28          |
|    time_elapsed          | 808         |
|    total_timesteps       | 860160      |
| train/                   |             |
|    approx_kl             | 0.01211499  |
|    clip_fraction         | 0.0809      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.78        |
|    cost_value_loss       | 14.8        |
|    cost_values           | 2.56        |
|    entropy               | -2.26       |
|    entropy_loss          | -2.26       |
|    explained_variance    | 0.328       |
|    lagrangian_multiplier | 0.00309     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.24        |
|    n_updates             | 4190        |
|    policy_gradient_loss  | -0.00394    |
|    std                   | 0.77        |
|    value_loss            | 21.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.43744677 |
| rollout/                 |             |
|    ep_len_mean           | 395         |
|    ep_rew_mean           | -156        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 29          |
|    time_elapsed          | 837         |
|    total_timesteps       | 862208      |
| train/                   |             |
|    approx_kl             | 0.008413732 |
|    clip_fraction         | 0.0651      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.27        |
|    cost_value_loss       | 19.1        |
|    cost_values           | 2.54        |
|    entropy               | -2.25       |
|    entropy_loss          | -2.25       |
|    explained_variance    | 0.402       |
|    lagrangian_multiplier | 0.00338     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.29        |
|    n_updates             | 4200        |
|    policy_gradient_loss  | -0.00559    |
|    std                   | 0.766       |
|    value_loss            | 13.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.33091307 |
| rollout/                 |             |
|    ep_len_mean           | 399         |
|    ep_rew_mean           | -158        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 30          |
|    time_elapsed          | 865         |
|    total_timesteps       | 864256      |
| train/                   |             |
|    approx_kl             | 0.009187816 |
|    clip_fraction         | 0.119       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.82        |
|    cost_value_loss       | 16          |
|    cost_values           | 2.61        |
|    entropy               | -2.24       |
|    entropy_loss          | -2.25       |
|    explained_variance    | 0.5         |
|    lagrangian_multiplier | 0.00213     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.92        |
|    n_updates             | 4210        |
|    policy_gradient_loss  | -0.00515    |
|    std                   | 0.764       |
|    value_loss            | 15.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.96        |
| reward                   | -0.15960778 |
| rollout/                 |             |
|    ep_len_mean           | 400         |
|    ep_rew_mean           | -157        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 31          |
|    time_elapsed          | 894         |
|    total_timesteps       | 866304      |
| train/                   |             |
|    approx_kl             | 0.015209084 |
|    clip_fraction         | 0.121       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.54        |
|    cost_value_loss       | 13.8        |
|    cost_values           | 2.6         |
|    entropy               | -2.25       |
|    entropy_loss          | -2.24       |
|    explained_variance    | 0.615       |
|    lagrangian_multiplier | 0.00234     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.46        |
|    n_updates             | 4220        |
|    policy_gradient_loss  | -0.00599    |
|    std                   | 0.765       |
|    value_loss            | 10.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.44018933  |
| rollout/                 |              |
|    ep_len_mean           | 378          |
|    ep_rew_mean           | -148         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 32           |
|    time_elapsed          | 923          |
|    total_timesteps       | 868352       |
| train/                   |              |
|    approx_kl             | 0.0064420607 |
|    clip_fraction         | 0.122        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.25         |
|    cost_value_loss       | 18.9         |
|    cost_values           | 2.67         |
|    entropy               | -2.23        |
|    entropy_loss          | -2.24        |
|    explained_variance    | 0.47         |
|    lagrangian_multiplier | 0.00571      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.37         |
|    n_updates             | 4230         |
|    policy_gradient_loss  | -0.00393     |
|    std                   | 0.76         |
|    value_loss            | 10           |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.24834387  |
| rollout/                 |              |
|    ep_len_mean           | 383          |
|    ep_rew_mean           | -150         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 33           |
|    time_elapsed          | 952          |
|    total_timesteps       | 870400       |
| train/                   |              |
|    approx_kl             | 0.0064025167 |
|    clip_fraction         | 0.0936       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.08         |
|    cost_value_loss       | 17.7         |
|    cost_values           | 2.64         |
|    entropy               | -2.22        |
|    entropy_loss          | -2.23        |
|    explained_variance    | 0.417        |
|    lagrangian_multiplier | 0.00375      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.2          |
|    n_updates             | 4240         |
|    policy_gradient_loss  | -0.00456     |
|    std                   | 0.756        |
|    value_loss            | 18.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.24334176 |
| rollout/                 |             |
|    ep_len_mean           | 357         |
|    ep_rew_mean           | -139        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 34          |
|    time_elapsed          | 981         |
|    total_timesteps       | 872448      |
| train/                   |             |
|    approx_kl             | 0.005896268 |
|    clip_fraction         | 0.0687      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.18        |
|    cost_value_loss       | 19.1        |
|    cost_values           | 2.62        |
|    entropy               | -2.22       |
|    entropy_loss          | -2.22       |
|    explained_variance    | 0.427       |
|    lagrangian_multiplier | 0.00436     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.47        |
|    n_updates             | 4250        |
|    policy_gradient_loss  | -0.0056     |
|    std                   | 0.756       |
|    value_loss            | 12.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.06         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.06         |
| reward                   | -0.4354098   |
| rollout/                 |              |
|    ep_len_mean           | 363          |
|    ep_rew_mean           | -141         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 35           |
|    time_elapsed          | 1010         |
|    total_timesteps       | 874496       |
| train/                   |              |
|    approx_kl             | 0.0077861687 |
|    clip_fraction         | 0.0914       |
|    clip_range            | 0.2          |
|    cost_returns          | 5            |
|    cost_value_loss       | 10           |
|    cost_values           | 2.59         |
|    entropy               | -2.22        |
|    entropy_loss          | -2.22        |
|    explained_variance    | 0.372        |
|    lagrangian_multiplier | 0.00125      |
|    learning_rate         | 0.0003       |
|    loss                  | 11.4         |
|    n_updates             | 4260         |
|    policy_gradient_loss  | -0.00348     |
|    std                   | 0.756        |
|    value_loss            | 27.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.26836142 |
| rollout/                 |             |
|    ep_len_mean           | 362         |
|    ep_rew_mean           | -140        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 36          |
|    time_elapsed          | 1039        |
|    total_timesteps       | 876544      |
| train/                   |             |
|    approx_kl             | 0.011915309 |
|    clip_fraction         | 0.115       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.26        |
|    cost_value_loss       | 18.8        |
|    cost_values           | 2.65        |
|    entropy               | -2.22       |
|    entropy_loss          | -2.22       |
|    explained_variance    | 0.502       |
|    lagrangian_multiplier | 0.000768    |
|    learning_rate         | 0.0003      |
|    loss                  | 10.4        |
|    n_updates             | 4270        |
|    policy_gradient_loss  | -0.0071     |
|    std                   | 0.756       |
|    value_loss            | 10.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.14021452  |
| rollout/                 |              |
|    ep_len_mean           | 376          |
|    ep_rew_mean           | -145         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 37           |
|    time_elapsed          | 1069         |
|    total_timesteps       | 878592       |
| train/                   |              |
|    approx_kl             | 0.0088913115 |
|    clip_fraction         | 0.101        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.96         |
|    cost_value_loss       | 16.1         |
|    cost_values           | 2.64         |
|    entropy               | -2.22        |
|    entropy_loss          | -2.22        |
|    explained_variance    | 0.408        |
|    lagrangian_multiplier | 0.00263      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.68         |
|    n_updates             | 4280         |
|    policy_gradient_loss  | -0.00403     |
|    std                   | 0.754        |
|    value_loss            | 15.9         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.29339522  |
| rollout/                 |              |
|    ep_len_mean           | 378          |
|    ep_rew_mean           | -144         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 38           |
|    time_elapsed          | 1098         |
|    total_timesteps       | 880640       |
| train/                   |              |
|    approx_kl             | 0.0064411173 |
|    clip_fraction         | 0.123        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.24         |
|    cost_value_loss       | 11.7         |
|    cost_values           | 2.65         |
|    entropy               | -2.21        |
|    entropy_loss          | -2.21        |
|    explained_variance    | 0.695        |
|    lagrangian_multiplier | 0.0024       |
|    learning_rate         | 0.0003       |
|    loss                  | 6.23         |
|    n_updates             | 4290         |
|    policy_gradient_loss  | -0.00352     |
|    std                   | 0.752        |
|    value_loss            | 6.88         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.41622773 |
| rollout/                 |             |
|    ep_len_mean           | 358         |
|    ep_rew_mean           | -136        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 39          |
|    time_elapsed          | 1127        |
|    total_timesteps       | 882688      |
| train/                   |             |
|    approx_kl             | 0.009206972 |
|    clip_fraction         | 0.108       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.41        |
|    cost_value_loss       | 11.4        |
|    cost_values           | 2.71        |
|    entropy               | -2.2        |
|    entropy_loss          | -2.21       |
|    explained_variance    | 0.544       |
|    lagrangian_multiplier | 0.00186     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.35        |
|    n_updates             | 4300        |
|    policy_gradient_loss  | -0.00426    |
|    std                   | 0.749       |
|    value_loss            | 10.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.5704336  |
| rollout/                 |             |
|    ep_len_mean           | 351         |
|    ep_rew_mean           | -134        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 40          |
|    time_elapsed          | 1156        |
|    total_timesteps       | 884736      |
| train/                   |             |
|    approx_kl             | 0.008741631 |
|    clip_fraction         | 0.0627      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.75        |
|    cost_value_loss       | 13.8        |
|    cost_values           | 2.68        |
|    entropy               | -2.19       |
|    entropy_loss          | -2.2        |
|    explained_variance    | 0.351       |
|    lagrangian_multiplier | 0.00381     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.52        |
|    n_updates             | 4310        |
|    policy_gradient_loss  | -0.00266    |
|    std                   | 0.745       |
|    value_loss            | 22.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.26285103 |
| rollout/                 |             |
|    ep_len_mean           | 342         |
|    ep_rew_mean           | -131        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 41          |
|    time_elapsed          | 1185        |
|    total_timesteps       | 886784      |
| train/                   |             |
|    approx_kl             | 0.006501545 |
|    clip_fraction         | 0.0556      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.16        |
|    cost_value_loss       | 10.2        |
|    cost_values           | 2.67        |
|    entropy               | -2.18       |
|    entropy_loss          | -2.19       |
|    explained_variance    | 0.332       |
|    lagrangian_multiplier | 0.00159     |
|    learning_rate         | 0.0003      |
|    loss                  | 12          |
|    n_updates             | 4320        |
|    policy_gradient_loss  | -0.00187    |
|    std                   | 0.742       |
|    value_loss            | 28.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.89        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.89        |
| reward                   | -0.3196926  |
| rollout/                 |             |
|    ep_len_mean           | 346         |
|    ep_rew_mean           | -133        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 42          |
|    time_elapsed          | 1214        |
|    total_timesteps       | 888832      |
| train/                   |             |
|    approx_kl             | 0.009572933 |
|    clip_fraction         | 0.113       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.29        |
|    cost_value_loss       | 11.9        |
|    cost_values           | 2.62        |
|    entropy               | -2.17       |
|    entropy_loss          | -2.18       |
|    explained_variance    | 0.364       |
|    lagrangian_multiplier | 0.00207     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.44        |
|    n_updates             | 4330        |
|    policy_gradient_loss  | -0.0019     |
|    std                   | 0.741       |
|    value_loss            | 14.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.05         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.05         |
| reward                   | -0.24902251  |
| rollout/                 |              |
|    ep_len_mean           | 345          |
|    ep_rew_mean           | -132         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 43           |
|    time_elapsed          | 1243         |
|    total_timesteps       | 890880       |
| train/                   |              |
|    approx_kl             | 0.0052257376 |
|    clip_fraction         | 0.0807       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.48         |
|    cost_value_loss       | 22           |
|    cost_values           | 2.73         |
|    entropy               | -2.17        |
|    entropy_loss          | -2.17        |
|    explained_variance    | 0.549        |
|    lagrangian_multiplier | 0.00324      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.87         |
|    n_updates             | 4340         |
|    policy_gradient_loss  | -0.00511     |
|    std                   | 0.74         |
|    value_loss            | 7.34         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.18991518 |
| rollout/                 |             |
|    ep_len_mean           | 346         |
|    ep_rew_mean           | -131        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 44          |
|    time_elapsed          | 1272        |
|    total_timesteps       | 892928      |
| train/                   |             |
|    approx_kl             | 0.011002563 |
|    clip_fraction         | 0.123       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.6         |
|    cost_value_loss       | 13          |
|    cost_values           | 2.74        |
|    entropy               | -2.16       |
|    entropy_loss          | -2.17       |
|    explained_variance    | 0.313       |
|    lagrangian_multiplier | 0.00228     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.08        |
|    n_updates             | 4350        |
|    policy_gradient_loss  | -0.00482    |
|    std                   | 0.737       |
|    value_loss            | 11.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3120351  |
| rollout/                 |             |
|    ep_len_mean           | 346         |
|    ep_rew_mean           | -131        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 45          |
|    time_elapsed          | 1302        |
|    total_timesteps       | 894976      |
| train/                   |             |
|    approx_kl             | 0.013075794 |
|    clip_fraction         | 0.121       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.74        |
|    cost_value_loss       | 15.9        |
|    cost_values           | 2.7         |
|    entropy               | -2.15       |
|    entropy_loss          | -2.16       |
|    explained_variance    | 0.288       |
|    lagrangian_multiplier | 0.00291     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.86        |
|    n_updates             | 4360        |
|    policy_gradient_loss  | -0.00415    |
|    std                   | 0.734       |
|    value_loss            | 11.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.27422446 |
| rollout/                 |             |
|    ep_len_mean           | 341         |
|    ep_rew_mean           | -129        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 46          |
|    time_elapsed          | 1331        |
|    total_timesteps       | 897024      |
| train/                   |             |
|    approx_kl             | 0.011406467 |
|    clip_fraction         | 0.108       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.75        |
|    cost_value_loss       | 15.7        |
|    cost_values           | 2.71        |
|    entropy               | -2.15       |
|    entropy_loss          | -2.15       |
|    explained_variance    | 0.421       |
|    lagrangian_multiplier | 0.002       |
|    learning_rate         | 0.0003      |
|    loss                  | 10.1        |
|    n_updates             | 4370        |
|    policy_gradient_loss  | -0.00575    |
|    std                   | 0.735       |
|    value_loss            | 19          |
------------------------------------------
-----------------------------------------
| avg_speed                | 7.91       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.91       |
| reward                   | -0.4696023 |
| rollout/                 |            |
|    ep_len_mean           | 321        |
|    ep_rew_mean           | -121       |
| time/                    |            |
|    fps                   | 70         |
|    iterations            | 47         |
|    time_elapsed          | 1360       |
|    total_timesteps       | 899072     |
| train/                   |            |
|    approx_kl             | 0.0062374  |
|    clip_fraction         | 0.0971     |
|    clip_range            | 0.2        |
|    cost_returns          | 5.89       |
|    cost_value_loss       | 14.1       |
|    cost_values           | 2.7        |
|    entropy               | -2.15      |
|    entropy_loss          | -2.15      |
|    explained_variance    | 0.384      |
|    lagrangian_multiplier | 0.0019     |
|    learning_rate         | 0.0003     |
|    loss                  | 7.86       |
|    n_updates             | 4380       |
|    policy_gradient_loss  | -0.00597   |
|    std                   | 0.734      |
|    value_loss            | 13.8       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.25361884 |
| rollout/                 |             |
|    ep_len_mean           | 319         |
|    ep_rew_mean           | -119        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 48          |
|    time_elapsed          | 1389        |
|    total_timesteps       | 901120      |
| train/                   |             |
|    approx_kl             | 0.008673202 |
|    clip_fraction         | 0.0735      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.92        |
|    cost_value_loss       | 14.2        |
|    cost_values           | 2.72        |
|    entropy               | -2.14       |
|    entropy_loss          | -2.15       |
|    explained_variance    | 0.341       |
|    lagrangian_multiplier | 0.00174     |
|    learning_rate         | 0.0003      |
|    loss                  | 10.3        |
|    n_updates             | 4390        |
|    policy_gradient_loss  | -0.00337    |
|    std                   | 0.731       |
|    value_loss            | 22.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.03         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.03         |
| reward                   | -0.18202116  |
| rollout/                 |              |
|    ep_len_mean           | 328          |
|    ep_rew_mean           | -122         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 49           |
|    time_elapsed          | 1417         |
|    total_timesteps       | 903168       |
| train/                   |              |
|    approx_kl             | 0.0061192196 |
|    clip_fraction         | 0.081        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.47         |
|    cost_value_loss       | 14.5         |
|    cost_values           | 2.73         |
|    entropy               | -2.14        |
|    entropy_loss          | -2.14        |
|    explained_variance    | 0.485        |
|    lagrangian_multiplier | 0.000665     |
|    learning_rate         | 0.0003       |
|    loss                  | 11.5         |
|    n_updates             | 4400         |
|    policy_gradient_loss  | -0.0063      |
|    std                   | 0.73         |
|    value_loss            | 17.8         |
-------------------------------------------
----------------------------------
| avg_speed          | 8         |
| cost               | 0         |
| is_success         | 0         |
| max_speed          | 8         |
| reward             | -0.338348 |
| rollout/           |           |
|    ep_len_mean     | 335       |
|    ep_rew_mean     | -124      |
| time/              |           |
|    fps             | 75        |
|    iterations      | 1         |
|    time_elapsed    | 27        |
|    total_timesteps | 905216    |
----------------------------------
-------------------------------------------
| avg_speed                | 3.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.8          |
| reward                   | -0.638591    |
| rollout/                 |              |
|    ep_len_mean           | 319          |
|    ep_rew_mean           | -117         |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 2            |
|    time_elapsed          | 56           |
|    total_timesteps       | 907264       |
| train/                   |              |
|    approx_kl             | 0.0048981323 |
|    clip_fraction         | 0.0914       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.64         |
|    cost_value_loss       | 12.1         |
|    cost_values           | 2.78         |
|    entropy               | -2.13        |
|    entropy_loss          | -2.13        |
|    explained_variance    | 0.367        |
|    lagrangian_multiplier | 0.00287      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.02         |
|    n_updates             | 4420         |
|    policy_gradient_loss  | -0.000524    |
|    std                   | 0.726        |
|    value_loss            | 11.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.29847097 |
| rollout/                 |             |
|    ep_len_mean           | 310         |
|    ep_rew_mean           | -114        |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 3           |
|    time_elapsed          | 85          |
|    total_timesteps       | 909312      |
| train/                   |             |
|    approx_kl             | 0.00715236  |
|    clip_fraction         | 0.128       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.01        |
|    cost_value_loss       | 8.9         |
|    cost_values           | 2.72        |
|    entropy               | -2.13       |
|    entropy_loss          | -2.13       |
|    explained_variance    | 0.474       |
|    lagrangian_multiplier | 0.0019      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.66        |
|    n_updates             | 4430        |
|    policy_gradient_loss  | -0.00602    |
|    std                   | 0.726       |
|    value_loss            | 19.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3697537  |
| rollout/                 |             |
|    ep_len_mean           | 300         |
|    ep_rew_mean           | -110        |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 4           |
|    time_elapsed          | 113         |
|    total_timesteps       | 911360      |
| train/                   |             |
|    approx_kl             | 0.011606708 |
|    clip_fraction         | 0.0913      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.82        |
|    cost_value_loss       | 10.2        |
|    cost_values           | 2.71        |
|    entropy               | -2.13       |
|    entropy_loss          | -2.13       |
|    explained_variance    | 0.52        |
|    lagrangian_multiplier | 0.00142     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.71        |
|    n_updates             | 4440        |
|    policy_gradient_loss  | -0.00297    |
|    std                   | 0.726       |
|    value_loss            | 11.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.22113323 |
| rollout/                 |             |
|    ep_len_mean           | 307         |
|    ep_rew_mean           | -113        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 5           |
|    time_elapsed          | 142         |
|    total_timesteps       | 913408      |
| train/                   |             |
|    approx_kl             | 0.007561745 |
|    clip_fraction         | 0.095       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.73        |
|    cost_value_loss       | 13.4        |
|    cost_values           | 2.72        |
|    entropy               | -2.13       |
|    entropy_loss          | -2.13       |
|    explained_variance    | 0.43        |
|    lagrangian_multiplier | 0.00202     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.8         |
|    n_updates             | 4450        |
|    policy_gradient_loss  | -0.00192    |
|    std                   | 0.728       |
|    value_loss            | 11.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.81        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.81        |
| reward                   | -0.40438893 |
| rollout/                 |             |
|    ep_len_mean           | 316         |
|    ep_rew_mean           | -116        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 6           |
|    time_elapsed          | 171         |
|    total_timesteps       | 915456      |
| train/                   |             |
|    approx_kl             | 0.019285254 |
|    clip_fraction         | 0.122       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.81        |
|    cost_value_loss       | 12.2        |
|    cost_values           | 2.77        |
|    entropy               | -2.12       |
|    entropy_loss          | -2.13       |
|    explained_variance    | 0.391       |
|    lagrangian_multiplier | 0.0046      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.45        |
|    n_updates             | 4460        |
|    policy_gradient_loss  | -0.00424    |
|    std                   | 0.726       |
|    value_loss            | 11.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3948259  |
| rollout/                 |             |
|    ep_len_mean           | 312         |
|    ep_rew_mean           | -113        |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 7           |
|    time_elapsed          | 201         |
|    total_timesteps       | 917504      |
| train/                   |             |
|    approx_kl             | 0.012449479 |
|    clip_fraction         | 0.142       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.34        |
|    cost_value_loss       | 20.3        |
|    cost_values           | 2.65        |
|    entropy               | -2.12       |
|    entropy_loss          | -2.12       |
|    explained_variance    | 0.329       |
|    lagrangian_multiplier | 0.00225     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.76        |
|    n_updates             | 4470        |
|    policy_gradient_loss  | -0.00296    |
|    std                   | 0.726       |
|    value_loss            | 11.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.19599172 |
| rollout/                 |             |
|    ep_len_mean           | 291         |
|    ep_rew_mean           | -106        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 8           |
|    time_elapsed          | 230         |
|    total_timesteps       | 919552      |
| train/                   |             |
|    approx_kl             | 0.01226596  |
|    clip_fraction         | 0.0916      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.94        |
|    cost_value_loss       | 16.3        |
|    cost_values           | 2.67        |
|    entropy               | -2.13       |
|    entropy_loss          | -2.13       |
|    explained_variance    | 0.407       |
|    lagrangian_multiplier | 0.000969    |
|    learning_rate         | 0.0003      |
|    loss                  | 12.4        |
|    n_updates             | 4480        |
|    policy_gradient_loss  | -0.00354    |
|    std                   | 0.729       |
|    value_loss            | 17.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2250042  |
| rollout/                 |             |
|    ep_len_mean           | 298         |
|    ep_rew_mean           | -107        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 9           |
|    time_elapsed          | 259         |
|    total_timesteps       | 921600      |
| train/                   |             |
|    approx_kl             | 0.019831084 |
|    clip_fraction         | 0.132       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.13        |
|    cost_value_loss       | 10.7        |
|    cost_values           | 2.72        |
|    entropy               | -2.12       |
|    entropy_loss          | -2.13       |
|    explained_variance    | 0.532       |
|    lagrangian_multiplier | 0.00285     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.51        |
|    n_updates             | 4490        |
|    policy_gradient_loss  | -0.00107    |
|    std                   | 0.725       |
|    value_loss            | 13.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.35        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.35        |
| reward                   | -0.74638665 |
| rollout/                 |             |
|    ep_len_mean           | 290         |
|    ep_rew_mean           | -104        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 10          |
|    time_elapsed          | 289         |
|    total_timesteps       | 923648      |
| train/                   |             |
|    approx_kl             | 0.010137968 |
|    clip_fraction         | 0.0979      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.03        |
|    cost_value_loss       | 15.4        |
|    cost_values           | 2.78        |
|    entropy               | -2.1        |
|    entropy_loss          | -2.11       |
|    explained_variance    | 0.454       |
|    lagrangian_multiplier | 0.00105     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.51        |
|    n_updates             | 4500        |
|    policy_gradient_loss  | -0.00295    |
|    std                   | 0.719       |
|    value_loss            | 5.93        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.92         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.92         |
| reward                   | -0.24000518  |
| rollout/                 |              |
|    ep_len_mean           | 285          |
|    ep_rew_mean           | -103         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 11           |
|    time_elapsed          | 318          |
|    total_timesteps       | 925696       |
| train/                   |              |
|    approx_kl             | 0.0076151006 |
|    clip_fraction         | 0.0825       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.91         |
|    cost_value_loss       | 14.7         |
|    cost_values           | 2.75         |
|    entropy               | -2.1         |
|    entropy_loss          | -2.1         |
|    explained_variance    | 0.44         |
|    lagrangian_multiplier | 0.00236      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.91         |
|    n_updates             | 4510         |
|    policy_gradient_loss  | -0.004       |
|    std                   | 0.719        |
|    value_loss            | 16.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.27115843 |
| rollout/                 |             |
|    ep_len_mean           | 292         |
|    ep_rew_mean           | -104        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 12          |
|    time_elapsed          | 347         |
|    total_timesteps       | 927744      |
| train/                   |             |
|    approx_kl             | 0.010500405 |
|    clip_fraction         | 0.0946      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.02        |
|    cost_value_loss       | 9.83        |
|    cost_values           | 2.74        |
|    entropy               | -2.1        |
|    entropy_loss          | -2.1        |
|    explained_variance    | 0.269       |
|    lagrangian_multiplier | 0.00155     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.98        |
|    n_updates             | 4520        |
|    policy_gradient_loss  | -0.00407    |
|    std                   | 0.718       |
|    value_loss            | 13.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.8          |
| reward                   | -0.8122926   |
| rollout/                 |              |
|    ep_len_mean           | 306          |
|    ep_rew_mean           | -109         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 13           |
|    time_elapsed          | 377          |
|    total_timesteps       | 929792       |
| train/                   |              |
|    approx_kl             | 0.0046229176 |
|    clip_fraction         | 0.119        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.56         |
|    cost_value_loss       | 18.9         |
|    cost_values           | 2.81         |
|    entropy               | -2.08        |
|    entropy_loss          | -2.09        |
|    explained_variance    | 0.653        |
|    lagrangian_multiplier | 0.00418      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.29         |
|    n_updates             | 4530         |
|    policy_gradient_loss  | -0.00454     |
|    std                   | 0.714        |
|    value_loss            | 4.66         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.42114723 |
| rollout/                 |             |
|    ep_len_mean           | 308         |
|    ep_rew_mean           | -109        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 14          |
|    time_elapsed          | 405         |
|    total_timesteps       | 931840      |
| train/                   |             |
|    approx_kl             | 0.008750474 |
|    clip_fraction         | 0.0743      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.33        |
|    cost_value_loss       | 15.4        |
|    cost_values           | 2.92        |
|    entropy               | -2.08       |
|    entropy_loss          | -2.08       |
|    explained_variance    | 0.558       |
|    lagrangian_multiplier | 0.00477     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.72        |
|    n_updates             | 4540        |
|    policy_gradient_loss  | -0.00134    |
|    std                   | 0.712       |
|    value_loss            | 11.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.54        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.54        |
| reward                   | -0.8076566  |
| rollout/                 |             |
|    ep_len_mean           | 303         |
|    ep_rew_mean           | -107        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 15          |
|    time_elapsed          | 434         |
|    total_timesteps       | 933888      |
| train/                   |             |
|    approx_kl             | 0.009149613 |
|    clip_fraction         | 0.116       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.46        |
|    cost_value_loss       | 7.35        |
|    cost_values           | 2.8         |
|    entropy               | -2.08       |
|    entropy_loss          | -2.08       |
|    explained_variance    | 0.484       |
|    lagrangian_multiplier | 0.000421    |
|    learning_rate         | 0.0003      |
|    loss                  | 8.04        |
|    n_updates             | 4550        |
|    policy_gradient_loss  | -0.00447    |
|    std                   | 0.712       |
|    value_loss            | 9.82        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.33180988 |
| rollout/                 |             |
|    ep_len_mean           | 319         |
|    ep_rew_mean           | -112        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 16          |
|    time_elapsed          | 462         |
|    total_timesteps       | 935936      |
| train/                   |             |
|    approx_kl             | 0.011143839 |
|    clip_fraction         | 0.107       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.65        |
|    cost_value_loss       | 8.7         |
|    cost_values           | 2.74        |
|    entropy               | -2.07       |
|    entropy_loss          | -2.07       |
|    explained_variance    | 0.603       |
|    lagrangian_multiplier | 0.000539    |
|    learning_rate         | 0.0003      |
|    loss                  | 7.61        |
|    n_updates             | 4560        |
|    policy_gradient_loss  | -0.00661    |
|    std                   | 0.71        |
|    value_loss            | 10.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.31405735 |
| rollout/                 |             |
|    ep_len_mean           | 312         |
|    ep_rew_mean           | -110        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 17          |
|    time_elapsed          | 490         |
|    total_timesteps       | 937984      |
| train/                   |             |
|    approx_kl             | 0.015864518 |
|    clip_fraction         | 0.196       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.03        |
|    cost_value_loss       | 5.9         |
|    cost_values           | 2.75        |
|    entropy               | -2.05       |
|    entropy_loss          | -2.06       |
|    explained_variance    | 0.926       |
|    lagrangian_multiplier | 0.00208     |
|    learning_rate         | 0.0003      |
|    loss                  | 2.95        |
|    n_updates             | 4570        |
|    policy_gradient_loss  | -0.00368    |
|    std                   | 0.705       |
|    value_loss            | 0.766       |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.163482   |
| rollout/                 |             |
|    ep_len_mean           | 326         |
|    ep_rew_mean           | -114        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 18          |
|    time_elapsed          | 519         |
|    total_timesteps       | 940032      |
| train/                   |             |
|    approx_kl             | 0.008898305 |
|    clip_fraction         | 0.189       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.76        |
|    cost_value_loss       | 12.6        |
|    cost_values           | 2.73        |
|    entropy               | -2.05       |
|    entropy_loss          | -2.05       |
|    explained_variance    | 0.403       |
|    lagrangian_multiplier | 0.00163     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.82        |
|    n_updates             | 4580        |
|    policy_gradient_loss  | 0.00714     |
|    std                   | 0.703       |
|    value_loss            | 13.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.40506956 |
| rollout/                 |             |
|    ep_len_mean           | 327         |
|    ep_rew_mean           | -115        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 19          |
|    time_elapsed          | 548         |
|    total_timesteps       | 942080      |
| train/                   |             |
|    approx_kl             | 0.009744664 |
|    clip_fraction         | 0.0869      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.55        |
|    cost_value_loss       | 12.3        |
|    cost_values           | 2.72        |
|    entropy               | -2.04       |
|    entropy_loss          | -2.04       |
|    explained_variance    | 0.428       |
|    lagrangian_multiplier | 0.00134     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.78        |
|    n_updates             | 4590        |
|    policy_gradient_loss  | -0.00295    |
|    std                   | 0.701       |
|    value_loss            | 14.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.35507417  |
| rollout/                 |              |
|    ep_len_mean           | 327          |
|    ep_rew_mean           | -115         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 20           |
|    time_elapsed          | 578          |
|    total_timesteps       | 944128       |
| train/                   |              |
|    approx_kl             | 0.0062523354 |
|    clip_fraction         | 0.0974       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.28         |
|    cost_value_loss       | 7.93         |
|    cost_values           | 2.7          |
|    entropy               | -2.03        |
|    entropy_loss          | -2.03        |
|    explained_variance    | 0.777        |
|    lagrangian_multiplier | 0.000898     |
|    learning_rate         | 0.0003       |
|    loss                  | 6.47         |
|    n_updates             | 4600         |
|    policy_gradient_loss  | -0.00377     |
|    std                   | 0.699        |
|    value_loss            | 9.84         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.30116087 |
| rollout/                 |             |
|    ep_len_mean           | 341         |
|    ep_rew_mean           | -119        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 21          |
|    time_elapsed          | 606         |
|    total_timesteps       | 946176      |
| train/                   |             |
|    approx_kl             | 0.009415647 |
|    clip_fraction         | 0.112       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.11        |
|    cost_value_loss       | 7.4         |
|    cost_values           | 2.63        |
|    entropy               | -2.03       |
|    entropy_loss          | -2.03       |
|    explained_variance    | 0.5         |
|    lagrangian_multiplier | 0.00129     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.29        |
|    n_updates             | 4610        |
|    policy_gradient_loss  | -0.00346    |
|    std                   | 0.698       |
|    value_loss            | 6.91        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.51048875  |
| rollout/                 |              |
|    ep_len_mean           | 336          |
|    ep_rew_mean           | -117         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 22           |
|    time_elapsed          | 635          |
|    total_timesteps       | 948224       |
| train/                   |              |
|    approx_kl             | 0.0065071965 |
|    clip_fraction         | 0.0945       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.71         |
|    cost_value_loss       | 8.55         |
|    cost_values           | 2.59         |
|    entropy               | -2.02        |
|    entropy_loss          | -2.03        |
|    explained_variance    | 0.53         |
|    lagrangian_multiplier | 0.00217      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.79         |
|    n_updates             | 4620         |
|    policy_gradient_loss  | -0.00529     |
|    std                   | 0.698        |
|    value_loss            | 10.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.39774817 |
| rollout/                 |             |
|    ep_len_mean           | 333         |
|    ep_rew_mean           | -116        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 23          |
|    time_elapsed          | 664         |
|    total_timesteps       | 950272      |
| train/                   |             |
|    approx_kl             | 0.008229092 |
|    clip_fraction         | 0.0734      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.65        |
|    cost_value_loss       | 7.14        |
|    cost_values           | 2.57        |
|    entropy               | -2.01       |
|    entropy_loss          | -2.02       |
|    explained_variance    | 0.235       |
|    lagrangian_multiplier | 0.000695    |
|    learning_rate         | 0.0003      |
|    loss                  | 7.19        |
|    n_updates             | 4630        |
|    policy_gradient_loss  | -0.00434    |
|    std                   | 0.695       |
|    value_loss            | 11.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.85        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.85        |
| reward                   | -0.19463281 |
| rollout/                 |             |
|    ep_len_mean           | 337         |
|    ep_rew_mean           | -118        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 24          |
|    time_elapsed          | 693         |
|    total_timesteps       | 952320      |
| train/                   |             |
|    approx_kl             | 0.010470202 |
|    clip_fraction         | 0.0655      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.64        |
|    cost_value_loss       | 8.98        |
|    cost_values           | 2.59        |
|    entropy               | -2.01       |
|    entropy_loss          | -2.01       |
|    explained_variance    | 0.581       |
|    lagrangian_multiplier | 0.000937    |
|    learning_rate         | 0.0003      |
|    loss                  | 10.4        |
|    n_updates             | 4640        |
|    policy_gradient_loss  | -0.00367    |
|    std                   | 0.692       |
|    value_loss            | 16.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.37892586 |
| rollout/                 |             |
|    ep_len_mean           | 327         |
|    ep_rew_mean           | -115        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 25          |
|    time_elapsed          | 722         |
|    total_timesteps       | 954368      |
| train/                   |             |
|    approx_kl             | 0.005646974 |
|    clip_fraction         | 0.0498      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.65        |
|    cost_value_loss       | 9.97        |
|    cost_values           | 2.54        |
|    entropy               | -2          |
|    entropy_loss          | -2          |
|    explained_variance    | 0.51        |
|    lagrangian_multiplier | 0.000183    |
|    learning_rate         | 0.0003      |
|    loss                  | 9.35        |
|    n_updates             | 4650        |
|    policy_gradient_loss  | -0.0044     |
|    std                   | 0.69        |
|    value_loss            | 13.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.18565862 |
| rollout/                 |             |
|    ep_len_mean           | 316         |
|    ep_rew_mean           | -112        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 26          |
|    time_elapsed          | 751         |
|    total_timesteps       | 956416      |
| train/                   |             |
|    approx_kl             | 0.010807255 |
|    clip_fraction         | 0.127       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.64        |
|    cost_value_loss       | 9.41        |
|    cost_values           | 2.54        |
|    entropy               | -1.99       |
|    entropy_loss          | -1.99       |
|    explained_variance    | 0.423       |
|    lagrangian_multiplier | 0.00241     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.7         |
|    n_updates             | 4660        |
|    policy_gradient_loss  | -0.00236    |
|    std                   | 0.686       |
|    value_loss            | 12.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.8          |
| reward                   | -0.22973713  |
| rollout/                 |              |
|    ep_len_mean           | 300          |
|    ep_rew_mean           | -107         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 27           |
|    time_elapsed          | 780          |
|    total_timesteps       | 958464       |
| train/                   |              |
|    approx_kl             | 0.0083852885 |
|    clip_fraction         | 0.0788       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.68         |
|    cost_value_loss       | 10           |
|    cost_values           | 2.56         |
|    entropy               | -1.98        |
|    entropy_loss          | -1.99        |
|    explained_variance    | 0.443        |
|    lagrangian_multiplier | 0.000704     |
|    learning_rate         | 0.0003       |
|    loss                  | 11.8         |
|    n_updates             | 4670         |
|    policy_gradient_loss  | -0.0039      |
|    std                   | 0.684        |
|    value_loss            | 21.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4300952   |
| rollout/                 |              |
|    ep_len_mean           | 291          |
|    ep_rew_mean           | -105         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 28           |
|    time_elapsed          | 811          |
|    total_timesteps       | 960512       |
| train/                   |              |
|    approx_kl             | 0.0066019716 |
|    clip_fraction         | 0.103        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.46         |
|    cost_value_loss       | 9            |
|    cost_values           | 2.58         |
|    entropy               | -1.98        |
|    entropy_loss          | -1.98        |
|    explained_variance    | 0.497        |
|    lagrangian_multiplier | 0.000972     |
|    learning_rate         | 0.0003       |
|    loss                  | 8.09         |
|    n_updates             | 4680         |
|    policy_gradient_loss  | -0.00211     |
|    std                   | 0.686        |
|    value_loss            | 13.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.27020568 |
| rollout/                 |             |
|    ep_len_mean           | 274         |
|    ep_rew_mean           | -99.8       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 29          |
|    time_elapsed          | 840         |
|    total_timesteps       | 962560      |
| train/                   |             |
|    approx_kl             | 0.006662487 |
|    clip_fraction         | 0.0704      |
|    clip_range            | 0.2         |
|    cost_returns          | 5           |
|    cost_value_loss       | 9.33        |
|    cost_values           | 2.63        |
|    entropy               | -1.98       |
|    entropy_loss          | -1.98       |
|    explained_variance    | 0.37        |
|    lagrangian_multiplier | 0.000425    |
|    learning_rate         | 0.0003      |
|    loss                  | 9.95        |
|    n_updates             | 4690        |
|    policy_gradient_loss  | -0.0014     |
|    std                   | 0.686       |
|    value_loss            | 13.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.27934736 |
| rollout/                 |             |
|    ep_len_mean           | 276         |
|    ep_rew_mean           | -102        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 30          |
|    time_elapsed          | 869         |
|    total_timesteps       | 964608      |
| train/                   |             |
|    approx_kl             | 0.008386783 |
|    clip_fraction         | 0.0855      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.45        |
|    cost_value_loss       | 8.48        |
|    cost_values           | 2.53        |
|    entropy               | -1.98       |
|    entropy_loss          | -1.98       |
|    explained_variance    | 0.526       |
|    lagrangian_multiplier | 0.00287     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.15        |
|    n_updates             | 4700        |
|    policy_gradient_loss  | -0.005      |
|    std                   | 0.685       |
|    value_loss            | 16.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.33633038 |
| rollout/                 |             |
|    ep_len_mean           | 272         |
|    ep_rew_mean           | -100        |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 31          |
|    time_elapsed          | 898         |
|    total_timesteps       | 966656      |
| train/                   |             |
|    approx_kl             | 0.005185634 |
|    clip_fraction         | 0.102       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.21        |
|    cost_value_loss       | 6.89        |
|    cost_values           | 2.43        |
|    entropy               | -1.98       |
|    entropy_loss          | -1.98       |
|    explained_variance    | 0.378       |
|    lagrangian_multiplier | 0.000367    |
|    learning_rate         | 0.0003      |
|    loss                  | 7.57        |
|    n_updates             | 4710        |
|    policy_gradient_loss  | -0.00481    |
|    std                   | 0.682       |
|    value_loss            | 11.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.91         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.91         |
| reward                   | -0.474474    |
| rollout/                 |              |
|    ep_len_mean           | 274          |
|    ep_rew_mean           | -101         |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 32           |
|    time_elapsed          | 927          |
|    total_timesteps       | 968704       |
| train/                   |              |
|    approx_kl             | 0.0095716845 |
|    clip_fraction         | 0.098        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.67         |
|    cost_value_loss       | 14.1         |
|    cost_values           | 2.56         |
|    entropy               | -1.97        |
|    entropy_loss          | -1.97        |
|    explained_variance    | 0.371        |
|    lagrangian_multiplier | 0            |
|    learning_rate         | 0.0003       |
|    loss                  | 13           |
|    n_updates             | 4720         |
|    policy_gradient_loss  | -0.00266     |
|    std                   | 0.681        |
|    value_loss            | 12.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.4688619  |
| rollout/                 |             |
|    ep_len_mean           | 268         |
|    ep_rew_mean           | -98.6       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 33          |
|    time_elapsed          | 956         |
|    total_timesteps       | 970752      |
| train/                   |             |
|    approx_kl             | 0.007426089 |
|    clip_fraction         | 0.0604      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.05        |
|    cost_value_loss       | 10.8        |
|    cost_values           | 2.66        |
|    entropy               | -1.96       |
|    entropy_loss          | -1.97       |
|    explained_variance    | 0.542       |
|    lagrangian_multiplier | 0.000906    |
|    learning_rate         | 0.0003      |
|    loss                  | 10.3        |
|    n_updates             | 4730        |
|    policy_gradient_loss  | -0.00365    |
|    std                   | 0.678       |
|    value_loss            | 15.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.22235413 |
| rollout/                 |             |
|    ep_len_mean           | 263         |
|    ep_rew_mean           | -97         |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 34          |
|    time_elapsed          | 984         |
|    total_timesteps       | 972800      |
| train/                   |             |
|    approx_kl             | 0.012228334 |
|    clip_fraction         | 0.158       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.56        |
|    cost_value_loss       | 7.55        |
|    cost_values           | 2.63        |
|    entropy               | -1.95       |
|    entropy_loss          | -1.96       |
|    explained_variance    | 0.399       |
|    lagrangian_multiplier | 0.00121     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.12        |
|    n_updates             | 4740        |
|    policy_gradient_loss  | -0.0049     |
|    std                   | 0.675       |
|    value_loss            | 10.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.24546161 |
| rollout/                 |             |
|    ep_len_mean           | 261         |
|    ep_rew_mean           | -96.2       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 35          |
|    time_elapsed          | 1013        |
|    total_timesteps       | 974848      |
| train/                   |             |
|    approx_kl             | 0.00980988  |
|    clip_fraction         | 0.0918      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.17        |
|    cost_value_loss       | 13.2        |
|    cost_values           | 2.64        |
|    entropy               | -1.95       |
|    entropy_loss          | -1.95       |
|    explained_variance    | 0.498       |
|    lagrangian_multiplier | 0.00224     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.23        |
|    n_updates             | 4750        |
|    policy_gradient_loss  | -0.00342    |
|    std                   | 0.675       |
|    value_loss            | 9.51        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.26563683 |
| rollout/                 |             |
|    ep_len_mean           | 254         |
|    ep_rew_mean           | -93.4       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 36          |
|    time_elapsed          | 1043        |
|    total_timesteps       | 976896      |
| train/                   |             |
|    approx_kl             | 0.019853136 |
|    clip_fraction         | 0.0864      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.5         |
|    cost_value_loss       | 12.4        |
|    cost_values           | 2.7         |
|    entropy               | -1.95       |
|    entropy_loss          | -1.95       |
|    explained_variance    | 0.372       |
|    lagrangian_multiplier | 0.002       |
|    learning_rate         | 0.0003      |
|    loss                  | 7.96        |
|    n_updates             | 4760        |
|    policy_gradient_loss  | -0.0038     |
|    std                   | 0.675       |
|    value_loss            | 16.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.87         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.87         |
| reward                   | -0.20942827  |
| rollout/                 |              |
|    ep_len_mean           | 251          |
|    ep_rew_mean           | -92.2        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 37           |
|    time_elapsed          | 1072         |
|    total_timesteps       | 978944       |
| train/                   |              |
|    approx_kl             | 0.0070867306 |
|    clip_fraction         | 0.0839       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.27         |
|    cost_value_loss       | 10.7         |
|    cost_values           | 2.7          |
|    entropy               | -1.94        |
|    entropy_loss          | -1.94        |
|    explained_variance    | 0.388        |
|    lagrangian_multiplier | 0.00122      |
|    learning_rate         | 0.0003       |
|    loss                  | 10.7         |
|    n_updates             | 4770         |
|    policy_gradient_loss  | -0.00294     |
|    std                   | 0.672        |
|    value_loss            | 20.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.91        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.91        |
| reward                   | -0.3669517  |
| rollout/                 |             |
|    ep_len_mean           | 255         |
|    ep_rew_mean           | -93.2       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 38          |
|    time_elapsed          | 1101        |
|    total_timesteps       | 980992      |
| train/                   |             |
|    approx_kl             | 0.006223256 |
|    clip_fraction         | 0.0993      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.86        |
|    cost_value_loss       | 14          |
|    cost_values           | 2.75        |
|    entropy               | -1.93       |
|    entropy_loss          | -1.93       |
|    explained_variance    | 0.63        |
|    lagrangian_multiplier | 0.00394     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.54        |
|    n_updates             | 4780        |
|    policy_gradient_loss  | -0.0018     |
|    std                   | 0.671       |
|    value_loss            | 8.86        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.15430298 |
| rollout/                 |             |
|    ep_len_mean           | 252         |
|    ep_rew_mean           | -92.3       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 39          |
|    time_elapsed          | 1131        |
|    total_timesteps       | 983040      |
| train/                   |             |
|    approx_kl             | 0.008782807 |
|    clip_fraction         | 0.0825      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.77        |
|    cost_value_loss       | 16.5        |
|    cost_values           | 2.77        |
|    entropy               | -1.93       |
|    entropy_loss          | -1.93       |
|    explained_variance    | 0.575       |
|    lagrangian_multiplier | 0.00236     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.44        |
|    n_updates             | 4790        |
|    policy_gradient_loss  | -0.00506    |
|    std                   | 0.669       |
|    value_loss            | 15.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.13462944 |
| rollout/                 |             |
|    ep_len_mean           | 240         |
|    ep_rew_mean           | -87.9       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 40          |
|    time_elapsed          | 1160        |
|    total_timesteps       | 985088      |
| train/                   |             |
|    approx_kl             | 0.008806111 |
|    clip_fraction         | 0.0986      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.55        |
|    cost_value_loss       | 12.3        |
|    cost_values           | 2.7         |
|    entropy               | -1.91       |
|    entropy_loss          | -1.92       |
|    explained_variance    | 0.506       |
|    lagrangian_multiplier | 0.00213     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.99        |
|    n_updates             | 4800        |
|    policy_gradient_loss  | -0.00724    |
|    std                   | 0.666       |
|    value_loss            | 18.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.38324812 |
| rollout/                 |             |
|    ep_len_mean           | 242         |
|    ep_rew_mean           | -88.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 41          |
|    time_elapsed          | 1190        |
|    total_timesteps       | 987136      |
| train/                   |             |
|    approx_kl             | 0.009896807 |
|    clip_fraction         | 0.0955      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.63        |
|    cost_value_loss       | 15.5        |
|    cost_values           | 2.65        |
|    entropy               | -1.9        |
|    entropy_loss          | -1.91       |
|    explained_variance    | 0.538       |
|    lagrangian_multiplier | 0.00293     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.98        |
|    n_updates             | 4810        |
|    policy_gradient_loss  | -0.00463    |
|    std                   | 0.662       |
|    value_loss            | 18.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.2587509   |
| rollout/                 |              |
|    ep_len_mean           | 241          |
|    ep_rew_mean           | -86.7        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 42           |
|    time_elapsed          | 1220         |
|    total_timesteps       | 989184       |
| train/                   |              |
|    approx_kl             | 0.0071614785 |
|    clip_fraction         | 0.0809       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.56         |
|    cost_value_loss       | 12.6         |
|    cost_values           | 2.67         |
|    entropy               | -1.89        |
|    entropy_loss          | -1.89        |
|    explained_variance    | 0.337        |
|    lagrangian_multiplier | 0.00217      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.05         |
|    n_updates             | 4820         |
|    policy_gradient_loss  | -0.00326     |
|    std                   | 0.658        |
|    value_loss            | 13.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.3732202   |
| rollout/                 |              |
|    ep_len_mean           | 233          |
|    ep_rew_mean           | -83.5        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 43           |
|    time_elapsed          | 1250         |
|    total_timesteps       | 991232       |
| train/                   |              |
|    approx_kl             | 0.0113153085 |
|    clip_fraction         | 0.14         |
|    clip_range            | 0.2          |
|    cost_returns          | 5.05         |
|    cost_value_loss       | 10.9         |
|    cost_values           | 2.65         |
|    entropy               | -1.89        |
|    entropy_loss          | -1.89        |
|    explained_variance    | 0.449        |
|    lagrangian_multiplier | 0.00412      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.49         |
|    n_updates             | 4830         |
|    policy_gradient_loss  | -0.00624     |
|    std                   | 0.659        |
|    value_loss            | 11.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.3343927  |
| rollout/                 |             |
|    ep_len_mean           | 241         |
|    ep_rew_mean           | -85.4       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 44          |
|    time_elapsed          | 1279        |
|    total_timesteps       | 993280      |
| train/                   |             |
|    approx_kl             | 0.007263155 |
|    clip_fraction         | 0.112       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.18        |
|    cost_value_loss       | 9.81        |
|    cost_values           | 2.65        |
|    entropy               | -1.88       |
|    entropy_loss          | -1.89       |
|    explained_variance    | 0.414       |
|    lagrangian_multiplier | 0.00388     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.5         |
|    n_updates             | 4840        |
|    policy_gradient_loss  | -0.00245    |
|    std                   | 0.656       |
|    value_loss            | 11.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3828463  |
| rollout/                 |             |
|    ep_len_mean           | 243         |
|    ep_rew_mean           | -86.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 45          |
|    time_elapsed          | 1309        |
|    total_timesteps       | 995328      |
| train/                   |             |
|    approx_kl             | 0.007852304 |
|    clip_fraction         | 0.109       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.57        |
|    cost_value_loss       | 11.9        |
|    cost_values           | 2.7         |
|    entropy               | -1.87       |
|    entropy_loss          | -1.87       |
|    explained_variance    | 0.447       |
|    lagrangian_multiplier | 0.00328     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.19        |
|    n_updates             | 4850        |
|    policy_gradient_loss  | -6.23e-05   |
|    std                   | 0.652       |
|    value_loss            | 11.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.27684698 |
| rollout/                 |             |
|    ep_len_mean           | 244         |
|    ep_rew_mean           | -86.2       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 46          |
|    time_elapsed          | 1338        |
|    total_timesteps       | 997376      |
| train/                   |             |
|    approx_kl             | 0.021731619 |
|    clip_fraction         | 0.141       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.4         |
|    cost_value_loss       | 17.9        |
|    cost_values           | 2.79        |
|    entropy               | -1.86       |
|    entropy_loss          | -1.86       |
|    explained_variance    | 0.494       |
|    lagrangian_multiplier | 0.00547     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.06        |
|    n_updates             | 4860        |
|    policy_gradient_loss  | -0.00506    |
|    std                   | 0.648       |
|    value_loss            | 6.06        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.25342104 |
| rollout/                 |             |
|    ep_len_mean           | 240         |
|    ep_rew_mean           | -84.7       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 47          |
|    time_elapsed          | 1367        |
|    total_timesteps       | 999424      |
| train/                   |             |
|    approx_kl             | 0.009279316 |
|    clip_fraction         | 0.115       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.68        |
|    cost_value_loss       | 18.8        |
|    cost_values           | 2.83        |
|    entropy               | -1.85       |
|    entropy_loss          | -1.85       |
|    explained_variance    | 0.592       |
|    lagrangian_multiplier | 0.00466     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.61        |
|    n_updates             | 4870        |
|    policy_gradient_loss  | -0.00594    |
|    std                   | 0.646       |
|    value_loss            | 10.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.15894245 |
| rollout/                 |             |
|    ep_len_mean           | 243         |
|    ep_rew_mean           | -85.7       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 48          |
|    time_elapsed          | 1397        |
|    total_timesteps       | 1001472     |
| train/                   |             |
|    approx_kl             | 0.012540422 |
|    clip_fraction         | 0.111       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.79        |
|    cost_value_loss       | 14.3        |
|    cost_values           | 2.78        |
|    entropy               | -1.84       |
|    entropy_loss          | -1.85       |
|    explained_variance    | 0.631       |
|    lagrangian_multiplier | 0.00329     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.54        |
|    n_updates             | 4880        |
|    policy_gradient_loss  | -0.00296    |
|    std                   | 0.643       |
|    value_loss            | 16          |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.45969406 |
| rollout/                 |             |
|    ep_len_mean           | 240         |
|    ep_rew_mean           | -84.3       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 49          |
|    time_elapsed          | 1425        |
|    total_timesteps       | 1003520     |
| train/                   |             |
|    approx_kl             | 0.006787505 |
|    clip_fraction         | 0.0861      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.16        |
|    cost_value_loss       | 9.88        |
|    cost_values           | 2.76        |
|    entropy               | -1.84       |
|    entropy_loss          | -1.84       |
|    explained_variance    | 0.584       |
|    lagrangian_multiplier | 0.00177     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.26        |
|    n_updates             | 4890        |
|    policy_gradient_loss  | -0.00391    |
|    std                   | 0.642       |
|    value_loss            | 14.5        |
------------------------------------------
------------------------------------
| avg_speed          | 7.95        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 7.95        |
| reward             | -0.16223563 |
| rollout/           |             |
|    ep_len_mean     | 230         |
|    ep_rew_mean     | -80.9       |
| time/              |             |
|    fps             | 75          |
|    iterations      | 1           |
|    time_elapsed    | 27          |
|    total_timesteps | 1005568     |
------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.33001703  |
| rollout/                 |              |
|    ep_len_mean           | 232          |
|    ep_rew_mean           | -81.1        |
| time/                    |              |
|    fps                   | 72           |
|    iterations            | 2            |
|    time_elapsed          | 56           |
|    total_timesteps       | 1007616      |
| train/                   |              |
|    approx_kl             | 0.0046488317 |
|    clip_fraction         | 0.0608       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.72         |
|    cost_value_loss       | 13.1         |
|    cost_values           | 2.79         |
|    entropy               | -1.84        |
|    entropy_loss          | -1.84        |
|    explained_variance    | 0.529        |
|    lagrangian_multiplier | 0.00182      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.51         |
|    n_updates             | 4910         |
|    policy_gradient_loss  | -0.00388     |
|    std                   | 0.641        |
|    value_loss            | 16.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.30983037 |
| rollout/                 |             |
|    ep_len_mean           | 245         |
|    ep_rew_mean           | -85.3       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 3           |
|    time_elapsed          | 85          |
|    total_timesteps       | 1009664     |
| train/                   |             |
|    approx_kl             | 0.005045845 |
|    clip_fraction         | 0.0798      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.44        |
|    cost_value_loss       | 10.2        |
|    cost_values           | 2.78        |
|    entropy               | -1.83       |
|    entropy_loss          | -1.84       |
|    explained_variance    | 0.482       |
|    lagrangian_multiplier | 0.00228     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.17        |
|    n_updates             | 4920        |
|    policy_gradient_loss  | -0.00247    |
|    std                   | 0.64        |
|    value_loss            | 12.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.40669233 |
| rollout/                 |             |
|    ep_len_mean           | 258         |
|    ep_rew_mean           | -89.1       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 4           |
|    time_elapsed          | 114         |
|    total_timesteps       | 1011712     |
| train/                   |             |
|    approx_kl             | 0.011964995 |
|    clip_fraction         | 0.122       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.01        |
|    cost_value_loss       | 13          |
|    cost_values           | 2.82        |
|    entropy               | -1.83       |
|    entropy_loss          | -1.83       |
|    explained_variance    | 0.534       |
|    lagrangian_multiplier | 0.00373     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.69        |
|    n_updates             | 4930        |
|    policy_gradient_loss  | -0.00086    |
|    std                   | 0.64        |
|    value_loss            | 5.41        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.28365138 |
| rollout/                 |             |
|    ep_len_mean           | 258         |
|    ep_rew_mean           | -89         |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 5           |
|    time_elapsed          | 143         |
|    total_timesteps       | 1013760     |
| train/                   |             |
|    approx_kl             | 0.005352129 |
|    clip_fraction         | 0.114       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.91        |
|    cost_value_loss       | 14.8        |
|    cost_values           | 2.75        |
|    entropy               | -1.83       |
|    entropy_loss          | -1.83       |
|    explained_variance    | 0.483       |
|    lagrangian_multiplier | 0.00197     |
|    learning_rate         | 0.0003      |
|    loss                  | 10          |
|    n_updates             | 4940        |
|    policy_gradient_loss  | -0.000848   |
|    std                   | 0.638       |
|    value_loss            | 16.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.24470624 |
| rollout/                 |             |
|    ep_len_mean           | 249         |
|    ep_rew_mean           | -86.5       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 6           |
|    time_elapsed          | 172         |
|    total_timesteps       | 1015808     |
| train/                   |             |
|    approx_kl             | 0.017933058 |
|    clip_fraction         | 0.0966      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.86        |
|    cost_value_loss       | 13.3        |
|    cost_values           | 2.78        |
|    entropy               | -1.82       |
|    entropy_loss          | -1.83       |
|    explained_variance    | 0.552       |
|    lagrangian_multiplier | 0.00153     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.04        |
|    n_updates             | 4950        |
|    policy_gradient_loss  | -0.00256    |
|    std                   | 0.637       |
|    value_loss            | 12.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.77        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.77        |
| reward                   | -0.2723245  |
| rollout/                 |             |
|    ep_len_mean           | 244         |
|    ep_rew_mean           | -85.3       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 7           |
|    time_elapsed          | 200         |
|    total_timesteps       | 1017856     |
| train/                   |             |
|    approx_kl             | 0.007197229 |
|    clip_fraction         | 0.093       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.6         |
|    cost_value_loss       | 11.7        |
|    cost_values           | 2.82        |
|    entropy               | -1.84       |
|    entropy_loss          | -1.83       |
|    explained_variance    | 0.612       |
|    lagrangian_multiplier | 0.002       |
|    learning_rate         | 0.0003      |
|    loss                  | 7.6         |
|    n_updates             | 4960        |
|    policy_gradient_loss  | -0.0049     |
|    std                   | 0.643       |
|    value_loss            | 13.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.4408874  |
| rollout/                 |             |
|    ep_len_mean           | 235         |
|    ep_rew_mean           | -82.1       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 8           |
|    time_elapsed          | 228         |
|    total_timesteps       | 1019904     |
| train/                   |             |
|    approx_kl             | 0.018029366 |
|    clip_fraction         | 0.134       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.75        |
|    cost_value_loss       | 12.1        |
|    cost_values           | 2.82        |
|    entropy               | -1.83       |
|    entropy_loss          | -1.84       |
|    explained_variance    | 0.497       |
|    lagrangian_multiplier | 0.00333     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.79        |
|    n_updates             | 4970        |
|    policy_gradient_loss  | -0.00185    |
|    std                   | 0.642       |
|    value_loss            | 12.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.06         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.06         |
| reward                   | -0.32359305  |
| rollout/                 |              |
|    ep_len_mean           | 233          |
|    ep_rew_mean           | -81          |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 9            |
|    time_elapsed          | 257          |
|    total_timesteps       | 1021952      |
| train/                   |              |
|    approx_kl             | 0.0073402356 |
|    clip_fraction         | 0.128        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.78         |
|    cost_value_loss       | 13           |
|    cost_values           | 2.86         |
|    entropy               | -1.83        |
|    entropy_loss          | -1.83        |
|    explained_variance    | 0.53         |
|    lagrangian_multiplier | 0.00351      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.02         |
|    n_updates             | 4980         |
|    policy_gradient_loss  | 0.00136      |
|    std                   | 0.641        |
|    value_loss            | 12.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2057073  |
| rollout/                 |             |
|    ep_len_mean           | 226         |
|    ep_rew_mean           | -79.1       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 10          |
|    time_elapsed          | 286         |
|    total_timesteps       | 1024000     |
| train/                   |             |
|    approx_kl             | 0.010998622 |
|    clip_fraction         | 0.11        |
|    clip_range            | 0.2         |
|    cost_returns          | 5.89        |
|    cost_value_loss       | 14.4        |
|    cost_values           | 2.83        |
|    entropy               | -1.84       |
|    entropy_loss          | -1.83       |
|    explained_variance    | 0.609       |
|    lagrangian_multiplier | 0.00346     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.28        |
|    n_updates             | 4990        |
|    policy_gradient_loss  | -0.00126    |
|    std                   | 0.644       |
|    value_loss            | 12.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.91         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.91         |
| reward                   | -0.26171097  |
| rollout/                 |              |
|    ep_len_mean           | 223          |
|    ep_rew_mean           | -78          |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 11           |
|    time_elapsed          | 315          |
|    total_timesteps       | 1026048      |
| train/                   |              |
|    approx_kl             | 0.0064995447 |
|    clip_fraction         | 0.128        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.01         |
|    cost_value_loss       | 9.56         |
|    cost_values           | 2.76         |
|    entropy               | -1.83        |
|    entropy_loss          | -1.84        |
|    explained_variance    | 0.426        |
|    lagrangian_multiplier | 0.00209      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.63         |
|    n_updates             | 5000         |
|    policy_gradient_loss  | -0.000676    |
|    std                   | 0.642        |
|    value_loss            | 15.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.3104663  |
| rollout/                 |             |
|    ep_len_mean           | 229         |
|    ep_rew_mean           | -80         |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 12          |
|    time_elapsed          | 345         |
|    total_timesteps       | 1028096     |
| train/                   |             |
|    approx_kl             | 0.009429942 |
|    clip_fraction         | 0.0909      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.23        |
|    cost_value_loss       | 10.5        |
|    cost_values           | 2.72        |
|    entropy               | -1.83       |
|    entropy_loss          | -1.83       |
|    explained_variance    | 0.5         |
|    lagrangian_multiplier | 0.00431     |
|    learning_rate         | 0.0003      |
|    loss                  | 5           |
|    n_updates             | 5010        |
|    policy_gradient_loss  | -0.00377    |
|    std                   | 0.641       |
|    value_loss            | 10.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.3201918   |
| rollout/                 |              |
|    ep_len_mean           | 221          |
|    ep_rew_mean           | -78          |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 13           |
|    time_elapsed          | 374          |
|    total_timesteps       | 1030144      |
| train/                   |              |
|    approx_kl             | 0.0065707183 |
|    clip_fraction         | 0.0796       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.4          |
|    cost_value_loss       | 12.5         |
|    cost_values           | 2.68         |
|    entropy               | -1.82        |
|    entropy_loss          | -1.82        |
|    explained_variance    | 0.522        |
|    lagrangian_multiplier | 0.00204      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.86         |
|    n_updates             | 5020         |
|    policy_gradient_loss  | -0.0039      |
|    std                   | 0.639        |
|    value_loss            | 14           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.31283274 |
| rollout/                 |             |
|    ep_len_mean           | 203         |
|    ep_rew_mean           | -72.9       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 14          |
|    time_elapsed          | 404         |
|    total_timesteps       | 1032192     |
| train/                   |             |
|    approx_kl             | 0.010580494 |
|    clip_fraction         | 0.0959      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.89        |
|    cost_value_loss       | 8.25        |
|    cost_values           | 2.69        |
|    entropy               | -1.81       |
|    entropy_loss          | -1.81       |
|    explained_variance    | 0.551       |
|    lagrangian_multiplier | 0.000951    |
|    learning_rate         | 0.0003      |
|    loss                  | 9.32        |
|    n_updates             | 5030        |
|    policy_gradient_loss  | -0.00498    |
|    std                   | 0.637       |
|    value_loss            | 17          |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.28047755 |
| rollout/                 |             |
|    ep_len_mean           | 201         |
|    ep_rew_mean           | -72.4       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 15          |
|    time_elapsed          | 433         |
|    total_timesteps       | 1034240     |
| train/                   |             |
|    approx_kl             | 0.010439404 |
|    clip_fraction         | 0.109       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.52        |
|    cost_value_loss       | 13          |
|    cost_values           | 2.75        |
|    entropy               | -1.8        |
|    entropy_loss          | -1.81       |
|    explained_variance    | 0.643       |
|    lagrangian_multiplier | 0.00492     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.23        |
|    n_updates             | 5040        |
|    policy_gradient_loss  | -0.00413    |
|    std                   | 0.635       |
|    value_loss            | 13.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.20385447 |
| rollout/                 |             |
|    ep_len_mean           | 207         |
|    ep_rew_mean           | -73.9       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 16          |
|    time_elapsed          | 462         |
|    total_timesteps       | 1036288     |
| train/                   |             |
|    approx_kl             | 0.015076426 |
|    clip_fraction         | 0.151       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.13        |
|    cost_value_loss       | 10          |
|    cost_values           | 2.75        |
|    entropy               | -1.8        |
|    entropy_loss          | -1.8        |
|    explained_variance    | 0.648       |
|    lagrangian_multiplier | 0.0023      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.85        |
|    n_updates             | 5050        |
|    policy_gradient_loss  | 0.00216     |
|    std                   | 0.633       |
|    value_loss            | 10.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.3685945  |
| rollout/                 |             |
|    ep_len_mean           | 195         |
|    ep_rew_mean           | -70.8       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 17          |
|    time_elapsed          | 491         |
|    total_timesteps       | 1038336     |
| train/                   |             |
|    approx_kl             | 0.013301529 |
|    clip_fraction         | 0.132       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.77        |
|    cost_value_loss       | 12.6        |
|    cost_values           | 2.77        |
|    entropy               | -1.8        |
|    entropy_loss          | -1.8        |
|    explained_variance    | 0.445       |
|    lagrangian_multiplier | 0.0015      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.41        |
|    n_updates             | 5060        |
|    policy_gradient_loss  | -0.00425    |
|    std                   | 0.633       |
|    value_loss            | 10.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.32082072 |
| rollout/                 |             |
|    ep_len_mean           | 200         |
|    ep_rew_mean           | -72.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 18          |
|    time_elapsed          | 519         |
|    total_timesteps       | 1040384     |
| train/                   |             |
|    approx_kl             | 0.012349338 |
|    clip_fraction         | 0.121       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.45        |
|    cost_value_loss       | 13.2        |
|    cost_values           | 2.71        |
|    entropy               | -1.79       |
|    entropy_loss          | -1.8        |
|    explained_variance    | 0.46        |
|    lagrangian_multiplier | 0.00295     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.27        |
|    n_updates             | 5070        |
|    policy_gradient_loss  | -0.00523    |
|    std                   | 0.63        |
|    value_loss            | 16.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.32813832 |
| rollout/                 |             |
|    ep_len_mean           | 191         |
|    ep_rew_mean           | -69.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 19          |
|    time_elapsed          | 548         |
|    total_timesteps       | 1042432     |
| train/                   |             |
|    approx_kl             | 0.011299595 |
|    clip_fraction         | 0.0875      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.97        |
|    cost_value_loss       | 15.1        |
|    cost_values           | 2.73        |
|    entropy               | -1.78       |
|    entropy_loss          | -1.79       |
|    explained_variance    | 0.561       |
|    lagrangian_multiplier | 0.00185     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.43        |
|    n_updates             | 5080        |
|    policy_gradient_loss  | -0.0025     |
|    std                   | 0.626       |
|    value_loss            | 13.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.18230419  |
| rollout/                 |              |
|    ep_len_mean           | 205          |
|    ep_rew_mean           | -73.8        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 20           |
|    time_elapsed          | 577          |
|    total_timesteps       | 1044480      |
| train/                   |              |
|    approx_kl             | 0.0075905835 |
|    clip_fraction         | 0.0703       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.66         |
|    cost_value_loss       | 12.5         |
|    cost_values           | 2.77         |
|    entropy               | -1.77        |
|    entropy_loss          | -1.78        |
|    explained_variance    | 0.494        |
|    lagrangian_multiplier | 0.00465      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.86         |
|    n_updates             | 5090         |
|    policy_gradient_loss  | -0.00314     |
|    std                   | 0.624        |
|    value_loss            | 14.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.4084587  |
| rollout/                 |             |
|    ep_len_mean           | 195         |
|    ep_rew_mean           | -71.2       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 21          |
|    time_elapsed          | 605         |
|    total_timesteps       | 1046528     |
| train/                   |             |
|    approx_kl             | 0.006750963 |
|    clip_fraction         | 0.0724      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.44        |
|    cost_value_loss       | 10.6        |
|    cost_values           | 2.78        |
|    entropy               | -1.77       |
|    entropy_loss          | -1.77       |
|    explained_variance    | 0.53        |
|    lagrangian_multiplier | 0.00417     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.35        |
|    n_updates             | 5100        |
|    policy_gradient_loss  | -0.00354    |
|    std                   | 0.623       |
|    value_loss            | 6.66        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.3031851   |
| rollout/                 |              |
|    ep_len_mean           | 197          |
|    ep_rew_mean           | -71.6        |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 22           |
|    time_elapsed          | 634          |
|    total_timesteps       | 1048576      |
| train/                   |              |
|    approx_kl             | 0.0093769245 |
|    clip_fraction         | 0.133        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.79         |
|    cost_value_loss       | 13.6         |
|    cost_values           | 2.82         |
|    entropy               | -1.76        |
|    entropy_loss          | -1.77        |
|    explained_variance    | 0.584        |
|    lagrangian_multiplier | 0.00366      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.58         |
|    n_updates             | 5110         |
|    policy_gradient_loss  | -0.00277     |
|    std                   | 0.623        |
|    value_loss            | 14.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.23761085 |
| rollout/                 |             |
|    ep_len_mean           | 205         |
|    ep_rew_mean           | -73.5       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 23          |
|    time_elapsed          | 663         |
|    total_timesteps       | 1050624     |
| train/                   |             |
|    approx_kl             | 0.007999431 |
|    clip_fraction         | 0.126       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.77        |
|    cost_value_loss       | 13.8        |
|    cost_values           | 2.81        |
|    entropy               | -1.76       |
|    entropy_loss          | -1.76       |
|    explained_variance    | 0.624       |
|    lagrangian_multiplier | 0.00227     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.02        |
|    n_updates             | 5120        |
|    policy_gradient_loss  | -0.00405    |
|    std                   | 0.62        |
|    value_loss            | 12          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.3446953   |
| rollout/                 |              |
|    ep_len_mean           | 209          |
|    ep_rew_mean           | -74.4        |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 24           |
|    time_elapsed          | 691          |
|    total_timesteps       | 1052672      |
| train/                   |              |
|    approx_kl             | 0.0056141363 |
|    clip_fraction         | 0.108        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.79         |
|    cost_value_loss       | 12.4         |
|    cost_values           | 2.79         |
|    entropy               | -1.75        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0.421        |
|    lagrangian_multiplier | 0.00441      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.11         |
|    n_updates             | 5130         |
|    policy_gradient_loss  | -0.00289     |
|    std                   | 0.62         |
|    value_loss            | 8.15         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 6.85         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.85         |
| reward                   | -0.3349665   |
| rollout/                 |              |
|    ep_len_mean           | 200          |
|    ep_rew_mean           | -71.6        |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 25           |
|    time_elapsed          | 720          |
|    total_timesteps       | 1054720      |
| train/                   |              |
|    approx_kl             | 0.0056880433 |
|    clip_fraction         | 0.077        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.53         |
|    cost_value_loss       | 11.8         |
|    cost_values           | 2.8          |
|    entropy               | -1.74        |
|    entropy_loss          | -1.75        |
|    explained_variance    | 0.552        |
|    lagrangian_multiplier | 0.00306      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.12         |
|    n_updates             | 5140         |
|    policy_gradient_loss  | -0.00473     |
|    std                   | 0.618        |
|    value_loss            | 12.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3447167  |
| rollout/                 |             |
|    ep_len_mean           | 208         |
|    ep_rew_mean           | -73.8       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 26          |
|    time_elapsed          | 749         |
|    total_timesteps       | 1056768     |
| train/                   |             |
|    approx_kl             | 0.006698083 |
|    clip_fraction         | 0.102       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.46        |
|    cost_value_loss       | 11.2        |
|    cost_values           | 2.81        |
|    entropy               | -1.74       |
|    entropy_loss          | -1.74       |
|    explained_variance    | 0.619       |
|    lagrangian_multiplier | 0.00365     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.68        |
|    n_updates             | 5150        |
|    policy_gradient_loss  | -0.00226    |
|    std                   | 0.618       |
|    value_loss            | 12          |
------------------------------------------
------------------------------------------
| avg_speed                | 6.48        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.48        |
| reward                   | -0.2940796  |
| rollout/                 |             |
|    ep_len_mean           | 211         |
|    ep_rew_mean           | -74.3       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 27          |
|    time_elapsed          | 778         |
|    total_timesteps       | 1058816     |
| train/                   |             |
|    approx_kl             | 0.009189344 |
|    clip_fraction         | 0.135       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.58        |
|    cost_value_loss       | 10.9        |
|    cost_values           | 2.84        |
|    entropy               | -1.73       |
|    entropy_loss          | -1.74       |
|    explained_variance    | 0.49        |
|    lagrangian_multiplier | 0.00343     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.52        |
|    n_updates             | 5160        |
|    policy_gradient_loss  | -0.00518    |
|    std                   | 0.616       |
|    value_loss            | 5.87        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.84        |
| reward                   | -0.32877615 |
| rollout/                 |             |
|    ep_len_mean           | 209         |
|    ep_rew_mean           | -73.6       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 28          |
|    time_elapsed          | 808         |
|    total_timesteps       | 1060864     |
| train/                   |             |
|    approx_kl             | 0.009927243 |
|    clip_fraction         | 0.125       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.02        |
|    cost_value_loss       | 8.27        |
|    cost_values           | 2.8         |
|    entropy               | -1.72       |
|    entropy_loss          | -1.73       |
|    explained_variance    | 0.517       |
|    lagrangian_multiplier | 0.00309     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.66        |
|    n_updates             | 5170        |
|    policy_gradient_loss  | -0.00303    |
|    std                   | 0.612       |
|    value_loss            | 13.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.31106472  |
| rollout/                 |              |
|    ep_len_mean           | 219          |
|    ep_rew_mean           | -76.6        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 29           |
|    time_elapsed          | 838          |
|    total_timesteps       | 1062912      |
| train/                   |              |
|    approx_kl             | 0.0086996285 |
|    clip_fraction         | 0.128        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.4          |
|    cost_value_loss       | 18           |
|    cost_values           | 2.8          |
|    entropy               | -1.71        |
|    entropy_loss          | -1.71        |
|    explained_variance    | 0.537        |
|    lagrangian_multiplier | 0.00337      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.24         |
|    n_updates             | 5180         |
|    policy_gradient_loss  | -0.0075      |
|    std                   | 0.61         |
|    value_loss            | 13           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.13862385 |
| rollout/                 |             |
|    ep_len_mean           | 221         |
|    ep_rew_mean           | -77         |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 30          |
|    time_elapsed          | 867         |
|    total_timesteps       | 1064960     |
| train/                   |             |
|    approx_kl             | 0.006845058 |
|    clip_fraction         | 0.0914      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.46        |
|    cost_value_loss       | 11.2        |
|    cost_values           | 2.77        |
|    entropy               | -1.7        |
|    entropy_loss          | -1.71       |
|    explained_variance    | 0.561       |
|    lagrangian_multiplier | 0.00575     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.63        |
|    n_updates             | 5190        |
|    policy_gradient_loss  | -0.00491    |
|    std                   | 0.607       |
|    value_loss            | 9.57        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.6627539  |
| rollout/                 |             |
|    ep_len_mean           | 215         |
|    ep_rew_mean           | -74.8       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 31          |
|    time_elapsed          | 896         |
|    total_timesteps       | 1067008     |
| train/                   |             |
|    approx_kl             | 0.010499764 |
|    clip_fraction         | 0.126       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.17        |
|    cost_value_loss       | 9.64        |
|    cost_values           | 2.74        |
|    entropy               | -1.7        |
|    entropy_loss          | -1.7        |
|    explained_variance    | 0.514       |
|    lagrangian_multiplier | 0.00129     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.5         |
|    n_updates             | 5200        |
|    policy_gradient_loss  | -0.00124    |
|    std                   | 0.606       |
|    value_loss            | 13.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.97         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.97         |
| reward                   | -0.38867715  |
| rollout/                 |              |
|    ep_len_mean           | 218          |
|    ep_rew_mean           | -75.8        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 32           |
|    time_elapsed          | 925          |
|    total_timesteps       | 1069056      |
| train/                   |              |
|    approx_kl             | 0.0094852615 |
|    clip_fraction         | 0.114        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.42         |
|    cost_value_loss       | 10.2         |
|    cost_values           | 2.77         |
|    entropy               | -1.69        |
|    entropy_loss          | -1.69        |
|    explained_variance    | 0.463        |
|    lagrangian_multiplier | 0.00322      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.88         |
|    n_updates             | 5210         |
|    policy_gradient_loss  | 8.24e-05     |
|    std                   | 0.605        |
|    value_loss            | 12.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.27657437 |
| rollout/                 |             |
|    ep_len_mean           | 220         |
|    ep_rew_mean           | -76.2       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 33          |
|    time_elapsed          | 953         |
|    total_timesteps       | 1071104     |
| train/                   |             |
|    approx_kl             | 0.009383197 |
|    clip_fraction         | 0.0748      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.21        |
|    cost_value_loss       | 16.6        |
|    cost_values           | 2.76        |
|    entropy               | -1.69       |
|    entropy_loss          | -1.69       |
|    explained_variance    | 0.536       |
|    lagrangian_multiplier | 0.00507     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.03        |
|    n_updates             | 5220        |
|    policy_gradient_loss  | -0.00456    |
|    std                   | 0.604       |
|    value_loss            | 14          |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.68         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.68         |
| reward                   | -0.1957851   |
| rollout/                 |              |
|    ep_len_mean           | 214          |
|    ep_rew_mean           | -74.7        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 34           |
|    time_elapsed          | 982          |
|    total_timesteps       | 1073152      |
| train/                   |              |
|    approx_kl             | 0.0071998704 |
|    clip_fraction         | 0.0563       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.93         |
|    cost_value_loss       | 13.2         |
|    cost_values           | 2.77         |
|    entropy               | -1.68        |
|    entropy_loss          | -1.68        |
|    explained_variance    | 0.404        |
|    lagrangian_multiplier | 0.00236      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.22         |
|    n_updates             | 5230         |
|    policy_gradient_loss  | -0.00277     |
|    std                   | 0.602        |
|    value_loss            | 8.94         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.27205575  |
| rollout/                 |              |
|    ep_len_mean           | 219          |
|    ep_rew_mean           | -76.3        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 35           |
|    time_elapsed          | 1011         |
|    total_timesteps       | 1075200      |
| train/                   |              |
|    approx_kl             | 0.0071445294 |
|    clip_fraction         | 0.0729       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.74         |
|    cost_value_loss       | 13.4         |
|    cost_values           | 2.8          |
|    entropy               | -1.67        |
|    entropy_loss          | -1.67        |
|    explained_variance    | 0.597        |
|    lagrangian_multiplier | 0.00503      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.17         |
|    n_updates             | 5240         |
|    policy_gradient_loss  | -0.00544     |
|    std                   | 0.601        |
|    value_loss            | 16.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.27639586 |
| rollout/                 |             |
|    ep_len_mean           | 197         |
|    ep_rew_mean           | -70.2       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 36          |
|    time_elapsed          | 1039        |
|    total_timesteps       | 1077248     |
| train/                   |             |
|    approx_kl             | 0.008570962 |
|    clip_fraction         | 0.13        |
|    clip_range            | 0.2         |
|    cost_returns          | 5.37        |
|    cost_value_loss       | 10.9        |
|    cost_values           | 2.7         |
|    entropy               | -1.67       |
|    entropy_loss          | -1.67       |
|    explained_variance    | 0.518       |
|    lagrangian_multiplier | 0.00259     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.51        |
|    n_updates             | 5250        |
|    policy_gradient_loss  | -0.00061    |
|    std                   | 0.599       |
|    value_loss            | 13          |
------------------------------------------
------------------------------------------
| avg_speed                | 7.72        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.72        |
| reward                   | -0.33907792 |
| rollout/                 |             |
|    ep_len_mean           | 194         |
|    ep_rew_mean           | -69.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 37          |
|    time_elapsed          | 1068        |
|    total_timesteps       | 1079296     |
| train/                   |             |
|    approx_kl             | 0.005029204 |
|    clip_fraction         | 0.104       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.87        |
|    cost_value_loss       | 9.08        |
|    cost_values           | 2.66        |
|    entropy               | -1.66       |
|    entropy_loss          | -1.66       |
|    explained_variance    | 0.527       |
|    lagrangian_multiplier | 0.00257     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.27        |
|    n_updates             | 5260        |
|    policy_gradient_loss  | -0.00157    |
|    std                   | 0.599       |
|    value_loss            | 16.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.12787294  |
| rollout/                 |              |
|    ep_len_mean           | 187          |
|    ep_rew_mean           | -67.1        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 38           |
|    time_elapsed          | 1097         |
|    total_timesteps       | 1081344      |
| train/                   |              |
|    approx_kl             | 0.0074342955 |
|    clip_fraction         | 0.116        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.51         |
|    cost_value_loss       | 12.2         |
|    cost_values           | 2.71         |
|    entropy               | -1.66        |
|    entropy_loss          | -1.66        |
|    explained_variance    | 0.618        |
|    lagrangian_multiplier | 0.00518      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.62         |
|    n_updates             | 5270         |
|    policy_gradient_loss  | -0.000778    |
|    std                   | 0.601        |
|    value_loss            | 12.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.72        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.72        |
| reward                   | -0.26089066 |
| rollout/                 |             |
|    ep_len_mean           | 183         |
|    ep_rew_mean           | -66.4       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 39          |
|    time_elapsed          | 1125        |
|    total_timesteps       | 1083392     |
| train/                   |             |
|    approx_kl             | 0.01008773  |
|    clip_fraction         | 0.113       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.81        |
|    cost_value_loss       | 14.1        |
|    cost_values           | 2.76        |
|    entropy               | -1.66       |
|    entropy_loss          | -1.66       |
|    explained_variance    | 0.562       |
|    lagrangian_multiplier | 0.00425     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.96        |
|    n_updates             | 5280        |
|    policy_gradient_loss  | -0.00501    |
|    std                   | 0.601       |
|    value_loss            | 12.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 1.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 1.8          |
| reward                   | -0.75045556  |
| rollout/                 |              |
|    ep_len_mean           | 188          |
|    ep_rew_mean           | -67.8        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 40           |
|    time_elapsed          | 1154         |
|    total_timesteps       | 1085440      |
| train/                   |              |
|    approx_kl             | 0.0059673106 |
|    clip_fraction         | 0.0813       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.93         |
|    cost_value_loss       | 15           |
|    cost_values           | 2.8          |
|    entropy               | -1.66        |
|    entropy_loss          | -1.66        |
|    explained_variance    | 0.621        |
|    lagrangian_multiplier | 0.00395      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.7          |
|    n_updates             | 5290         |
|    policy_gradient_loss  | -0.00303     |
|    std                   | 0.6          |
|    value_loss            | 13.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3125499  |
| rollout/                 |             |
|    ep_len_mean           | 194         |
|    ep_rew_mean           | -69.5       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 41          |
|    time_elapsed          | 1182        |
|    total_timesteps       | 1087488     |
| train/                   |             |
|    approx_kl             | 0.007287907 |
|    clip_fraction         | 0.0634      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.23        |
|    cost_value_loss       | 9.75        |
|    cost_values           | 2.72        |
|    entropy               | -1.65       |
|    entropy_loss          | -1.65       |
|    explained_variance    | 0.479       |
|    lagrangian_multiplier | 0.00341     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.52        |
|    n_updates             | 5300        |
|    policy_gradient_loss  | -0.00398    |
|    std                   | 0.599       |
|    value_loss            | 11.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.26894668 |
| rollout/                 |             |
|    ep_len_mean           | 176         |
|    ep_rew_mean           | -64.6       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 42          |
|    time_elapsed          | 1211        |
|    total_timesteps       | 1089536     |
| train/                   |             |
|    approx_kl             | 0.012361039 |
|    clip_fraction         | 0.0875      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.03        |
|    cost_value_loss       | 15.7        |
|    cost_values           | 2.7         |
|    entropy               | -1.65       |
|    entropy_loss          | -1.65       |
|    explained_variance    | 0.538       |
|    lagrangian_multiplier | 0.00346     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.9         |
|    n_updates             | 5310        |
|    policy_gradient_loss  | -0.000609   |
|    std                   | 0.597       |
|    value_loss            | 8.89        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.36799777 |
| rollout/                 |             |
|    ep_len_mean           | 177         |
|    ep_rew_mean           | -64.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 43          |
|    time_elapsed          | 1241        |
|    total_timesteps       | 1091584     |
| train/                   |             |
|    approx_kl             | 0.005027516 |
|    clip_fraction         | 0.0747      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.85        |
|    cost_value_loss       | 15.1        |
|    cost_values           | 2.79        |
|    entropy               | -1.64       |
|    entropy_loss          | -1.64       |
|    explained_variance    | 0.631       |
|    lagrangian_multiplier | 0.00387     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.1         |
|    n_updates             | 5320        |
|    policy_gradient_loss  | -0.00421    |
|    std                   | 0.595       |
|    value_loss            | 15.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3005113  |
| rollout/                 |             |
|    ep_len_mean           | 178         |
|    ep_rew_mean           | -64.2       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 44          |
|    time_elapsed          | 1270        |
|    total_timesteps       | 1093632     |
| train/                   |             |
|    approx_kl             | 0.008355979 |
|    clip_fraction         | 0.113       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.45        |
|    cost_value_loss       | 12.6        |
|    cost_values           | 2.74        |
|    entropy               | -1.63       |
|    entropy_loss          | -1.63       |
|    explained_variance    | 0.591       |
|    lagrangian_multiplier | 0.00243     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.25        |
|    n_updates             | 5330        |
|    policy_gradient_loss  | -0.00142    |
|    std                   | 0.592       |
|    value_loss            | 11.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.82         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 7.82         |
| reward                   | -0.24918476  |
| rollout/                 |              |
|    ep_len_mean           | 189          |
|    ep_rew_mean           | -67.3        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 45           |
|    time_elapsed          | 1299         |
|    total_timesteps       | 1095680      |
| train/                   |              |
|    approx_kl             | 0.0077804714 |
|    clip_fraction         | 0.104        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.8          |
|    cost_value_loss       | 13.1         |
|    cost_values           | 2.74         |
|    entropy               | -1.61        |
|    entropy_loss          | -1.62        |
|    explained_variance    | 0.483        |
|    lagrangian_multiplier | 0.00309      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.64         |
|    n_updates             | 5340         |
|    policy_gradient_loss  | -0.00496     |
|    std                   | 0.587        |
|    value_loss            | 11.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.28917965 |
| rollout/                 |             |
|    ep_len_mean           | 190         |
|    ep_rew_mean           | -67.2       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 46          |
|    time_elapsed          | 1328        |
|    total_timesteps       | 1097728     |
| train/                   |             |
|    approx_kl             | 0.006717696 |
|    clip_fraction         | 0.103       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.18        |
|    cost_value_loss       | 11          |
|    cost_values           | 2.65        |
|    entropy               | -1.6        |
|    entropy_loss          | -1.6        |
|    explained_variance    | 0.381       |
|    lagrangian_multiplier | 0.00327     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.66        |
|    n_updates             | 5350        |
|    policy_gradient_loss  | -0.00282    |
|    std                   | 0.584       |
|    value_loss            | 11.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.32544824 |
| rollout/                 |             |
|    ep_len_mean           | 182         |
|    ep_rew_mean           | -64.7       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 47          |
|    time_elapsed          | 1356        |
|    total_timesteps       | 1099776     |
| train/                   |             |
|    approx_kl             | 0.023318015 |
|    clip_fraction         | 0.137       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.27        |
|    cost_value_loss       | 9.55        |
|    cost_values           | 2.66        |
|    entropy               | -1.59       |
|    entropy_loss          | -1.59       |
|    explained_variance    | 0.446       |
|    lagrangian_multiplier | 0.00259     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.3         |
|    n_updates             | 5360        |
|    policy_gradient_loss  | -4.05e-05   |
|    std                   | 0.582       |
|    value_loss            | 13.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.63        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.63        |
| reward                   | -0.3469567  |
| rollout/                 |             |
|    ep_len_mean           | 186         |
|    ep_rew_mean           | -65.7       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 48          |
|    time_elapsed          | 1385        |
|    total_timesteps       | 1101824     |
| train/                   |             |
|    approx_kl             | 0.006250719 |
|    clip_fraction         | 0.12        |
|    clip_range            | 0.2         |
|    cost_returns          | 5.37        |
|    cost_value_loss       | 12.4        |
|    cost_values           | 2.68        |
|    entropy               | -1.59       |
|    entropy_loss          | -1.59       |
|    explained_variance    | 0.622       |
|    lagrangian_multiplier | 0.00241     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.37        |
|    n_updates             | 5370        |
|    policy_gradient_loss  | -0.00283    |
|    std                   | 0.582       |
|    value_loss            | 16.5        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.06         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.06         |
| reward                   | -0.2711933   |
| rollout/                 |              |
|    ep_len_mean           | 204          |
|    ep_rew_mean           | -71.4        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 49           |
|    time_elapsed          | 1414         |
|    total_timesteps       | 1103872      |
| train/                   |              |
|    approx_kl             | 0.0081231445 |
|    clip_fraction         | 0.0868       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.79         |
|    cost_value_loss       | 12.8         |
|    cost_values           | 2.75         |
|    entropy               | -1.6         |
|    entropy_loss          | -1.6         |
|    explained_variance    | 0.567        |
|    lagrangian_multiplier | 0.00376      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.17         |
|    n_updates             | 5380         |
|    policy_gradient_loss  | -0.00205     |
|    std                   | 0.583        |
|    value_loss            | 6.68         |
-------------------------------------------
Directory already exists: tests/PPOL_New/models/ent-coefficient-ppol/vlorgroe
-----------------------------------
| avg_speed          | 7.81       |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 7.81       |
| reward             | -0.4076633 |
| rollout/           |            |
|    ep_len_mean     | 192        |
|    ep_rew_mean     | -68.4      |
| time/              |            |
|    fps             | 76         |
|    iterations      | 1          |
|    time_elapsed    | 26         |
|    total_timesteps | 1105920    |
-----------------------------------
------------------------------------------
| avg_speed                | 7           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7           |
| reward                   | -0.518073   |
| rollout/                 |             |
|    ep_len_mean           | 191         |
|    ep_rew_mean           | -67.8       |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 2           |
|    time_elapsed          | 56          |
|    total_timesteps       | 1107968     |
| train/                   |             |
|    approx_kl             | 0.007422815 |
|    clip_fraction         | 0.146       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.92        |
|    cost_value_loss       | 9.45        |
|    cost_values           | 2.61        |
|    entropy               | -1.59       |
|    entropy_loss          | -1.59       |
|    explained_variance    | 0.532       |
|    lagrangian_multiplier | 0.00152     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.44        |
|    n_updates             | 5400        |
|    policy_gradient_loss  | 0.00174     |
|    std                   | 0.58        |
|    value_loss            | 14.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.40709406 |
| rollout/                 |             |
|    ep_len_mean           | 195         |
|    ep_rew_mean           | -69.1       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 3           |
|    time_elapsed          | 85          |
|    total_timesteps       | 1110016     |
| train/                   |             |
|    approx_kl             | 0.02130397  |
|    clip_fraction         | 0.105       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.11        |
|    cost_value_loss       | 10.8        |
|    cost_values           | 2.61        |
|    entropy               | -1.59       |
|    entropy_loss          | -1.59       |
|    explained_variance    | 0.596       |
|    lagrangian_multiplier | 0.00328     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.79        |
|    n_updates             | 5410        |
|    policy_gradient_loss  | -2.12e-05   |
|    std                   | 0.582       |
|    value_loss            | 16.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.16377728  |
| rollout/                 |              |
|    ep_len_mean           | 196          |
|    ep_rew_mean           | -69.8        |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 4            |
|    time_elapsed          | 114          |
|    total_timesteps       | 1112064      |
| train/                   |              |
|    approx_kl             | 0.0069818133 |
|    clip_fraction         | 0.111        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.78         |
|    cost_value_loss       | 13.9         |
|    cost_values           | 2.67         |
|    entropy               | -1.59        |
|    entropy_loss          | -1.59        |
|    explained_variance    | 0.518        |
|    lagrangian_multiplier | 0.0038       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.36         |
|    n_updates             | 5420         |
|    policy_gradient_loss  | -0.00161     |
|    std                   | 0.581        |
|    value_loss            | 9.15         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.391977   |
| rollout/                 |             |
|    ep_len_mean           | 192         |
|    ep_rew_mean           | -68.8       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 5           |
|    time_elapsed          | 144         |
|    total_timesteps       | 1114112     |
| train/                   |             |
|    approx_kl             | 0.009646228 |
|    clip_fraction         | 0.122       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.36        |
|    cost_value_loss       | 11          |
|    cost_values           | 2.67        |
|    entropy               | -1.59       |
|    entropy_loss          | -1.59       |
|    explained_variance    | 0.475       |
|    lagrangian_multiplier | 0.00158     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.4         |
|    n_updates             | 5430        |
|    policy_gradient_loss  | -0.00267    |
|    std                   | 0.583       |
|    value_loss            | 15          |
------------------------------------------
------------------------------------------
| avg_speed                | 7.9         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.9         |
| reward                   | -0.41030777 |
| rollout/                 |             |
|    ep_len_mean           | 192         |
|    ep_rew_mean           | -68.8       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 6           |
|    time_elapsed          | 172         |
|    total_timesteps       | 1116160     |
| train/                   |             |
|    approx_kl             | 0.008729387 |
|    clip_fraction         | 0.114       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.93        |
|    cost_value_loss       | 10.2        |
|    cost_values           | 2.64        |
|    entropy               | -1.58       |
|    entropy_loss          | -1.58       |
|    explained_variance    | 0.529       |
|    lagrangian_multiplier | 0.00142     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.32        |
|    n_updates             | 5440        |
|    policy_gradient_loss  | -0.000731   |
|    std                   | 0.579       |
|    value_loss            | 14.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.4511862  |
| rollout/                 |             |
|    ep_len_mean           | 197         |
|    ep_rew_mean           | -70.4       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 7           |
|    time_elapsed          | 200         |
|    total_timesteps       | 1118208     |
| train/                   |             |
|    approx_kl             | 0.017120063 |
|    clip_fraction         | 0.141       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.6         |
|    cost_value_loss       | 11.8        |
|    cost_values           | 2.67        |
|    entropy               | -1.57       |
|    entropy_loss          | -1.57       |
|    explained_variance    | 0.383       |
|    lagrangian_multiplier | 0.00207     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.46        |
|    n_updates             | 5450        |
|    policy_gradient_loss  | -0.00023    |
|    std                   | 0.576       |
|    value_loss            | 12.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.39890054  |
| rollout/                 |              |
|    ep_len_mean           | 206          |
|    ep_rew_mean           | -73.7        |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 8            |
|    time_elapsed          | 229          |
|    total_timesteps       | 1120256      |
| train/                   |              |
|    approx_kl             | 0.0065302122 |
|    clip_fraction         | 0.077        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.72         |
|    cost_value_loss       | 13.3         |
|    cost_values           | 2.69         |
|    entropy               | -1.56        |
|    entropy_loss          | -1.56        |
|    explained_variance    | 0.591        |
|    lagrangian_multiplier | 0.00413      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.26         |
|    n_updates             | 5460         |
|    policy_gradient_loss  | -0.00311     |
|    std                   | 0.573        |
|    value_loss            | 14.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.7722232  |
| rollout/                 |             |
|    ep_len_mean           | 187         |
|    ep_rew_mean           | -67.7       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 9           |
|    time_elapsed          | 258         |
|    total_timesteps       | 1122304     |
| train/                   |             |
|    approx_kl             | 0.006654325 |
|    clip_fraction         | 0.103       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.69        |
|    cost_value_loss       | 13.1        |
|    cost_values           | 2.67        |
|    entropy               | -1.54       |
|    entropy_loss          | -1.55       |
|    explained_variance    | 0.671       |
|    lagrangian_multiplier | 0.00159     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.85        |
|    n_updates             | 5470        |
|    policy_gradient_loss  | -0.00364    |
|    std                   | 0.57        |
|    value_loss            | 12.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.23469496 |
| rollout/                 |             |
|    ep_len_mean           | 185         |
|    ep_rew_mean           | -66.8       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 10          |
|    time_elapsed          | 287         |
|    total_timesteps       | 1124352     |
| train/                   |             |
|    approx_kl             | 0.007828083 |
|    clip_fraction         | 0.0676      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.63        |
|    cost_value_loss       | 12.6        |
|    cost_values           | 2.69        |
|    entropy               | -1.53       |
|    entropy_loss          | -1.54       |
|    explained_variance    | 0.457       |
|    lagrangian_multiplier | 0.0026      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.1         |
|    n_updates             | 5480        |
|    policy_gradient_loss  | -0.00251    |
|    std                   | 0.566       |
|    value_loss            | 15.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.32834616 |
| rollout/                 |             |
|    ep_len_mean           | 184         |
|    ep_rew_mean           | -66.2       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 11          |
|    time_elapsed          | 316         |
|    total_timesteps       | 1126400     |
| train/                   |             |
|    approx_kl             | 0.009007644 |
|    clip_fraction         | 0.14        |
|    clip_range            | 0.2         |
|    cost_returns          | 5.74        |
|    cost_value_loss       | 14.3        |
|    cost_values           | 2.72        |
|    entropy               | -1.53       |
|    entropy_loss          | -1.53       |
|    explained_variance    | 0.609       |
|    lagrangian_multiplier | 0.00317     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.18        |
|    n_updates             | 5490        |
|    policy_gradient_loss  | 0.000133    |
|    std                   | 0.567       |
|    value_loss            | 14.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.4399689   |
| rollout/                 |              |
|    ep_len_mean           | 181          |
|    ep_rew_mean           | -65.4        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 12           |
|    time_elapsed          | 346          |
|    total_timesteps       | 1128448      |
| train/                   |              |
|    approx_kl             | 0.0061402796 |
|    clip_fraction         | 0.0825       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.79         |
|    cost_value_loss       | 13.3         |
|    cost_values           | 2.78         |
|    entropy               | -1.52        |
|    entropy_loss          | -1.52        |
|    explained_variance    | 0.552        |
|    lagrangian_multiplier | 0.00413      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.1          |
|    n_updates             | 5500         |
|    policy_gradient_loss  | -0.00211     |
|    std                   | 0.564        |
|    value_loss            | 15.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.3324488  |
| rollout/                 |             |
|    ep_len_mean           | 179         |
|    ep_rew_mean           | -65         |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 13          |
|    time_elapsed          | 375         |
|    total_timesteps       | 1130496     |
| train/                   |             |
|    approx_kl             | 0.016005335 |
|    clip_fraction         | 0.113       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.14        |
|    cost_value_loss       | 16.7        |
|    cost_values           | 2.75        |
|    entropy               | -1.51       |
|    entropy_loss          | -1.51       |
|    explained_variance    | 0.625       |
|    lagrangian_multiplier | 0.00317     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.94        |
|    n_updates             | 5510        |
|    policy_gradient_loss  | -0.00375    |
|    std                   | 0.563       |
|    value_loss            | 11.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.2886464  |
| rollout/                 |             |
|    ep_len_mean           | 170         |
|    ep_rew_mean           | -62.6       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 14          |
|    time_elapsed          | 404         |
|    total_timesteps       | 1132544     |
| train/                   |             |
|    approx_kl             | 0.009798817 |
|    clip_fraction         | 0.111       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.94        |
|    cost_value_loss       | 8.99        |
|    cost_values           | 2.75        |
|    entropy               | -1.5        |
|    entropy_loss          | -1.51       |
|    explained_variance    | 0.685       |
|    lagrangian_multiplier | 0.000725    |
|    learning_rate         | 0.0003      |
|    loss                  | 7.99        |
|    n_updates             | 5520        |
|    policy_gradient_loss  | -0.00215    |
|    std                   | 0.562       |
|    value_loss            | 12.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.58         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.58         |
| reward                   | -0.36948514  |
| rollout/                 |              |
|    ep_len_mean           | 177          |
|    ep_rew_mean           | -65.5        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 15           |
|    time_elapsed          | 433          |
|    total_timesteps       | 1134592      |
| train/                   |              |
|    approx_kl             | 0.0058915946 |
|    clip_fraction         | 0.0978       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.43         |
|    cost_value_loss       | 12.3         |
|    cost_values           | 2.72         |
|    entropy               | -1.5         |
|    entropy_loss          | -1.5         |
|    explained_variance    | 0.678        |
|    lagrangian_multiplier | 0.000313     |
|    learning_rate         | 0.0003       |
|    loss                  | 12.4         |
|    n_updates             | 5530         |
|    policy_gradient_loss  | -0.00421     |
|    std                   | 0.561        |
|    value_loss            | 15.8         |
-------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.59693265 |
| rollout/                 |             |
|    ep_len_mean           | 177         |
|    ep_rew_mean           | -66.2       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 16          |
|    time_elapsed          | 462         |
|    total_timesteps       | 1136640     |
| train/                   |             |
|    approx_kl             | 0.009078473 |
|    clip_fraction         | 0.069       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.12        |
|    cost_value_loss       | 16.8        |
|    cost_values           | 2.74        |
|    entropy               | -1.5        |
|    entropy_loss          | -1.5        |
|    explained_variance    | 0.483       |
|    lagrangian_multiplier | 0.00346     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.98        |
|    n_updates             | 5540        |
|    policy_gradient_loss  | -0.00416    |
|    std                   | 0.561       |
|    value_loss            | 7.94        |
------------------------------------------
-----------------------------------------
| avg_speed                | 5.4        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 5.4        |
| reward                   | -0.6880391 |
| rollout/                 |            |
|    ep_len_mean           | 183        |
|    ep_rew_mean           | -67.6      |
| time/                    |            |
|    fps                   | 70         |
|    iterations            | 17         |
|    time_elapsed          | 491        |
|    total_timesteps       | 1138688    |
| train/                   |            |
|    approx_kl             | 0.01529894 |
|    clip_fraction         | 0.155      |
|    clip_range            | 0.2        |
|    cost_returns          | 6.05       |
|    cost_value_loss       | 15         |
|    cost_values           | 2.72       |
|    entropy               | -1.5       |
|    entropy_loss          | -1.5       |
|    explained_variance    | 0.533      |
|    lagrangian_multiplier | 0.00293    |
|    learning_rate         | 0.0003     |
|    loss                  | 6.64       |
|    n_updates             | 5550       |
|    policy_gradient_loss  | -0.00212   |
|    std                   | 0.56       |
|    value_loss            | 10.9       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.34185457 |
| rollout/                 |             |
|    ep_len_mean           | 184         |
|    ep_rew_mean           | -68.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 18          |
|    time_elapsed          | 520         |
|    total_timesteps       | 1140736     |
| train/                   |             |
|    approx_kl             | 0.005068301 |
|    clip_fraction         | 0.119       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.86        |
|    cost_value_loss       | 9.33        |
|    cost_values           | 2.68        |
|    entropy               | -1.49       |
|    entropy_loss          | -1.49       |
|    explained_variance    | 0.546       |
|    lagrangian_multiplier | 0.00118     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.98        |
|    n_updates             | 5560        |
|    policy_gradient_loss  | -0.00431    |
|    std                   | 0.559       |
|    value_loss            | 13.5        |
------------------------------------------
-----------------------------------------
| avg_speed                | 3          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 3          |
| reward                   | -0.9448056 |
| rollout/                 |            |
|    ep_len_mean           | 186        |
|    ep_rew_mean           | -68.6      |
| time/                    |            |
|    fps                   | 70         |
|    iterations            | 19         |
|    time_elapsed          | 549        |
|    total_timesteps       | 1142784    |
| train/                   |            |
|    approx_kl             | 0.01300867 |
|    clip_fraction         | 0.137      |
|    clip_range            | 0.2        |
|    cost_returns          | 5.48       |
|    cost_value_loss       | 11.4       |
|    cost_values           | 2.69       |
|    entropy               | -1.48      |
|    entropy_loss          | -1.49      |
|    explained_variance    | 0.587      |
|    lagrangian_multiplier | 0.0025     |
|    learning_rate         | 0.0003     |
|    loss                  | 6.18       |
|    n_updates             | 5570       |
|    policy_gradient_loss  | -0.00138   |
|    std                   | 0.557      |
|    value_loss            | 11.2       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.25231332 |
| rollout/                 |             |
|    ep_len_mean           | 187         |
|    ep_rew_mean           | -69.3       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 20          |
|    time_elapsed          | 579         |
|    total_timesteps       | 1144832     |
| train/                   |             |
|    approx_kl             | 0.011651842 |
|    clip_fraction         | 0.0836      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.01        |
|    cost_value_loss       | 15.6        |
|    cost_values           | 2.71        |
|    entropy               | -1.48       |
|    entropy_loss          | -1.48       |
|    explained_variance    | 0.538       |
|    lagrangian_multiplier | 0.00406     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.76        |
|    n_updates             | 5580        |
|    policy_gradient_loss  | -0.00285    |
|    std                   | 0.556       |
|    value_loss            | 17.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.2784868  |
| rollout/                 |             |
|    ep_len_mean           | 190         |
|    ep_rew_mean           | -70         |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 21          |
|    time_elapsed          | 607         |
|    total_timesteps       | 1146880     |
| train/                   |             |
|    approx_kl             | 0.005817828 |
|    clip_fraction         | 0.11        |
|    clip_range            | 0.2         |
|    cost_returns          | 5.44        |
|    cost_value_loss       | 12.3        |
|    cost_values           | 2.69        |
|    entropy               | -1.48       |
|    entropy_loss          | -1.48       |
|    explained_variance    | 0.583       |
|    lagrangian_multiplier | 0.00158     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.84        |
|    n_updates             | 5590        |
|    policy_gradient_loss  | 0.000456    |
|    std                   | 0.559       |
|    value_loss            | 13.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 3.17         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.17         |
| reward                   | -0.87659085  |
| rollout/                 |              |
|    ep_len_mean           | 190          |
|    ep_rew_mean           | -69.5        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 22           |
|    time_elapsed          | 637          |
|    total_timesteps       | 1148928      |
| train/                   |              |
|    approx_kl             | 0.0061131716 |
|    clip_fraction         | 0.0957       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.81         |
|    cost_value_loss       | 13.1         |
|    cost_values           | 2.73         |
|    entropy               | -1.48        |
|    entropy_loss          | -1.48        |
|    explained_variance    | 0.654        |
|    lagrangian_multiplier | 0.00085      |
|    learning_rate         | 0.0003       |
|    loss                  | 8.29         |
|    n_updates             | 5600         |
|    policy_gradient_loss  | -0.00461     |
|    std                   | 0.559        |
|    value_loss            | 10.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.28925455 |
| rollout/                 |             |
|    ep_len_mean           | 185         |
|    ep_rew_mean           | -67.8       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 23          |
|    time_elapsed          | 666         |
|    total_timesteps       | 1150976     |
| train/                   |             |
|    approx_kl             | 0.015371174 |
|    clip_fraction         | 0.13        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.91        |
|    cost_value_loss       | 9           |
|    cost_values           | 2.74        |
|    entropy               | -1.48       |
|    entropy_loss          | -1.48       |
|    explained_variance    | 0.581       |
|    lagrangian_multiplier | 0.001       |
|    learning_rate         | 0.0003      |
|    loss                  | 8.07        |
|    n_updates             | 5610        |
|    policy_gradient_loss  | -0.00183    |
|    std                   | 0.558       |
|    value_loss            | 15          |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.01         |
| reward                   | -0.4486194   |
| rollout/                 |              |
|    ep_len_mean           | 176          |
|    ep_rew_mean           | -64.1        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 24           |
|    time_elapsed          | 695          |
|    total_timesteps       | 1153024      |
| train/                   |              |
|    approx_kl             | 0.0061270846 |
|    clip_fraction         | 0.0808       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.87         |
|    cost_value_loss       | 16.4         |
|    cost_values           | 2.71         |
|    entropy               | -1.47        |
|    entropy_loss          | -1.48        |
|    explained_variance    | 0.61         |
|    lagrangian_multiplier | 0.00328      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.71         |
|    n_updates             | 5620         |
|    policy_gradient_loss  | -0.00221     |
|    std                   | 0.556        |
|    value_loss            | 16.5         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.24985518  |
| rollout/                 |              |
|    ep_len_mean           | 166          |
|    ep_rew_mean           | -60.1        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 25           |
|    time_elapsed          | 723          |
|    total_timesteps       | 1155072      |
| train/                   |              |
|    approx_kl             | 0.0076667843 |
|    clip_fraction         | 0.0673       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.91         |
|    cost_value_loss       | 15.4         |
|    cost_values           | 2.74         |
|    entropy               | -1.47        |
|    entropy_loss          | -1.47        |
|    explained_variance    | 0.613        |
|    lagrangian_multiplier | 0.00272      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.89         |
|    n_updates             | 5630         |
|    policy_gradient_loss  | -0.00317     |
|    std                   | 0.555        |
|    value_loss            | 11.2         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.25341567  |
| rollout/                 |              |
|    ep_len_mean           | 169          |
|    ep_rew_mean           | -60.9        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 26           |
|    time_elapsed          | 752          |
|    total_timesteps       | 1157120      |
| train/                   |              |
|    approx_kl             | 0.0066044717 |
|    clip_fraction         | 0.118        |
|    clip_range            | 0.2          |
|    cost_returns          | 6.3          |
|    cost_value_loss       | 16.5         |
|    cost_values           | 2.81         |
|    entropy               | -1.46        |
|    entropy_loss          | -1.47        |
|    explained_variance    | 0.636        |
|    lagrangian_multiplier | 0.00713      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.13         |
|    n_updates             | 5640         |
|    policy_gradient_loss  | -0.0013      |
|    std                   | 0.553        |
|    value_loss            | 10           |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.730125   |
| rollout/                 |             |
|    ep_len_mean           | 167         |
|    ep_rew_mean           | -59.9       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 27          |
|    time_elapsed          | 782         |
|    total_timesteps       | 1159168     |
| train/                   |             |
|    approx_kl             | 0.014954923 |
|    clip_fraction         | 0.125       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.47        |
|    cost_value_loss       | 11.5        |
|    cost_values           | 2.8         |
|    entropy               | -1.46       |
|    entropy_loss          | -1.46       |
|    explained_variance    | 0.611       |
|    lagrangian_multiplier | 0.000934    |
|    learning_rate         | 0.0003      |
|    loss                  | 7.53        |
|    n_updates             | 5650        |
|    policy_gradient_loss  | -0.00282    |
|    std                   | 0.551       |
|    value_loss            | 9.55        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.34032142 |
| rollout/                 |             |
|    ep_len_mean           | 173         |
|    ep_rew_mean           | -61.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 28          |
|    time_elapsed          | 812         |
|    total_timesteps       | 1161216     |
| train/                   |             |
|    approx_kl             | 0.006653677 |
|    clip_fraction         | 0.0888      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.92        |
|    cost_value_loss       | 14.3        |
|    cost_values           | 2.78        |
|    entropy               | -1.45       |
|    entropy_loss          | -1.46       |
|    explained_variance    | 0.694       |
|    lagrangian_multiplier | 0.00472     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.56        |
|    n_updates             | 5660        |
|    policy_gradient_loss  | -0.00266    |
|    std                   | 0.551       |
|    value_loss            | 11.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.29698995 |
| rollout/                 |             |
|    ep_len_mean           | 176         |
|    ep_rew_mean           | -62.6       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 29          |
|    time_elapsed          | 842         |
|    total_timesteps       | 1163264     |
| train/                   |             |
|    approx_kl             | 0.05068626  |
|    clip_fraction         | 0.213       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.01        |
|    cost_value_loss       | 14.4        |
|    cost_values           | 2.85        |
|    entropy               | -1.44       |
|    entropy_loss          | -1.45       |
|    explained_variance    | 0.697       |
|    lagrangian_multiplier | 0.00263     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.63        |
|    n_updates             | 5670        |
|    policy_gradient_loss  | 0.00722     |
|    std                   | 0.548       |
|    value_loss            | 9.21        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.99         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.99         |
| reward                   | -0.35816053  |
| rollout/                 |              |
|    ep_len_mean           | 172          |
|    ep_rew_mean           | -61.2        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 30           |
|    time_elapsed          | 871          |
|    total_timesteps       | 1165312      |
| train/                   |              |
|    approx_kl             | 0.0068036006 |
|    clip_fraction         | 0.17         |
|    clip_range            | 0.2          |
|    cost_returns          | 6.23         |
|    cost_value_loss       | 15.6         |
|    cost_values           | 2.86         |
|    entropy               | -1.44        |
|    entropy_loss          | -1.44        |
|    explained_variance    | 0.657        |
|    lagrangian_multiplier | 0.00306      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.98         |
|    n_updates             | 5680         |
|    policy_gradient_loss  | 0.00559      |
|    std                   | 0.547        |
|    value_loss            | 8.65         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 3.05       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 3.05       |
| reward                   | -0.6098505 |
| rollout/                 |            |
|    ep_len_mean           | 176        |
|    ep_rew_mean           | -61.6      |
| time/                    |            |
|    fps                   | 70         |
|    iterations            | 31         |
|    time_elapsed          | 900        |
|    total_timesteps       | 1167360    |
| train/                   |            |
|    approx_kl             | 0.01296192 |
|    clip_fraction         | 0.145      |
|    clip_range            | 0.2        |
|    cost_returns          | 5.86       |
|    cost_value_loss       | 13.5       |
|    cost_values           | 2.86       |
|    entropy               | -1.44      |
|    entropy_loss          | -1.44      |
|    explained_variance    | 0.608      |
|    lagrangian_multiplier | 0.00565    |
|    learning_rate         | 0.0003     |
|    loss                  | 5.11       |
|    n_updates             | 5690       |
|    policy_gradient_loss  | 0.000159   |
|    std                   | 0.548      |
|    value_loss            | 11.3       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.33199057 |
| rollout/                 |             |
|    ep_len_mean           | 179         |
|    ep_rew_mean           | -62.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 32          |
|    time_elapsed          | 929         |
|    total_timesteps       | 1169408     |
| train/                   |             |
|    approx_kl             | 0.008314492 |
|    clip_fraction         | 0.113       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.36        |
|    cost_value_loss       | 11.6        |
|    cost_values           | 2.79        |
|    entropy               | -1.43       |
|    entropy_loss          | -1.44       |
|    explained_variance    | 0.528       |
|    lagrangian_multiplier | 0.00289     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.51        |
|    n_updates             | 5700        |
|    policy_gradient_loss  | -0.000274   |
|    std                   | 0.545       |
|    value_loss            | 15.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.42875767 |
| rollout/                 |             |
|    ep_len_mean           | 180         |
|    ep_rew_mean           | -62.6       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 33          |
|    time_elapsed          | 958         |
|    total_timesteps       | 1171456     |
| train/                   |             |
|    approx_kl             | 0.012769677 |
|    clip_fraction         | 0.115       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.4         |
|    cost_value_loss       | 11.3        |
|    cost_values           | 2.76        |
|    entropy               | -1.43       |
|    entropy_loss          | -1.43       |
|    explained_variance    | 0.576       |
|    lagrangian_multiplier | 0.00395     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.6         |
|    n_updates             | 5710        |
|    policy_gradient_loss  | -0.00179    |
|    std                   | 0.545       |
|    value_loss            | 12          |
------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.28767443 |
| rollout/                 |             |
|    ep_len_mean           | 184         |
|    ep_rew_mean           | -64.2       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 34          |
|    time_elapsed          | 987         |
|    total_timesteps       | 1173504     |
| train/                   |             |
|    approx_kl             | 0.005348192 |
|    clip_fraction         | 0.0928      |
|    clip_range            | 0.2         |
|    cost_returns          | 6           |
|    cost_value_loss       | 13.8        |
|    cost_values           | 2.79        |
|    entropy               | -1.42       |
|    entropy_loss          | -1.42       |
|    explained_variance    | 0.656       |
|    lagrangian_multiplier | 0.00265     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.3         |
|    n_updates             | 5720        |
|    policy_gradient_loss  | -0.00231    |
|    std                   | 0.544       |
|    value_loss            | 8.63        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.43287465  |
| rollout/                 |              |
|    ep_len_mean           | 187          |
|    ep_rew_mean           | -65          |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 35           |
|    time_elapsed          | 1017         |
|    total_timesteps       | 1175552      |
| train/                   |              |
|    approx_kl             | 0.0057695177 |
|    clip_fraction         | 0.105        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.4          |
|    cost_value_loss       | 10.9         |
|    cost_values           | 2.84         |
|    entropy               | -1.42        |
|    entropy_loss          | -1.42        |
|    explained_variance    | 0.72         |
|    lagrangian_multiplier | 0.00164      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.6          |
|    n_updates             | 5730         |
|    policy_gradient_loss  | -0.000297    |
|    std                   | 0.545        |
|    value_loss            | 9.26         |
-------------------------------------------
------------------------------------------
| avg_speed                | 3.25        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.25        |
| reward                   | -0.86342305 |
| rollout/                 |             |
|    ep_len_mean           | 189         |
|    ep_rew_mean           | -66         |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 36          |
|    time_elapsed          | 1046        |
|    total_timesteps       | 1177600     |
| train/                   |             |
|    approx_kl             | 0.028984997 |
|    clip_fraction         | 0.12        |
|    clip_range            | 0.2         |
|    cost_returns          | 5.35        |
|    cost_value_loss       | 11.5        |
|    cost_values           | 2.8         |
|    entropy               | -1.42       |
|    entropy_loss          | -1.42       |
|    explained_variance    | 0.751       |
|    lagrangian_multiplier | 0.00179     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.18        |
|    n_updates             | 5740        |
|    policy_gradient_loss  | -0.0011     |
|    std                   | 0.545       |
|    value_loss            | 11.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.43        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.43        |
| reward                   | -0.38206634 |
| rollout/                 |             |
|    ep_len_mean           | 186         |
|    ep_rew_mean           | -64.9       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 37          |
|    time_elapsed          | 1075        |
|    total_timesteps       | 1179648     |
| train/                   |             |
|    approx_kl             | 0.009174202 |
|    clip_fraction         | 0.114       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.27        |
|    cost_value_loss       | 15.9        |
|    cost_values           | 2.81        |
|    entropy               | -1.42       |
|    entropy_loss          | -1.42       |
|    explained_variance    | 0.604       |
|    lagrangian_multiplier | 0.00483     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.81        |
|    n_updates             | 5750        |
|    policy_gradient_loss  | -0.0016     |
|    std                   | 0.544       |
|    value_loss            | 11.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.30240634 |
| rollout/                 |             |
|    ep_len_mean           | 178         |
|    ep_rew_mean           | -62.9       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 38          |
|    time_elapsed          | 1104        |
|    total_timesteps       | 1181696     |
| train/                   |             |
|    approx_kl             | 0.006456944 |
|    clip_fraction         | 0.104       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.42        |
|    cost_value_loss       | 12.3        |
|    cost_values           | 2.75        |
|    entropy               | -1.41       |
|    entropy_loss          | -1.41       |
|    explained_variance    | 0.565       |
|    lagrangian_multiplier | 0.00131     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.45        |
|    n_updates             | 5760        |
|    policy_gradient_loss  | 0.000733    |
|    std                   | 0.542       |
|    value_loss            | 12.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.18794294 |
| rollout/                 |             |
|    ep_len_mean           | 179         |
|    ep_rew_mean           | -63.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 39          |
|    time_elapsed          | 1133        |
|    total_timesteps       | 1183744     |
| train/                   |             |
|    approx_kl             | 0.017325282 |
|    clip_fraction         | 0.0899      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.26        |
|    cost_value_loss       | 10.6        |
|    cost_values           | 2.71        |
|    entropy               | -1.4        |
|    entropy_loss          | -1.4        |
|    explained_variance    | 0.555       |
|    lagrangian_multiplier | 0.00297     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.3         |
|    n_updates             | 5770        |
|    policy_gradient_loss  | -0.0018     |
|    std                   | 0.542       |
|    value_loss            | 13.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2638068  |
| rollout/                 |             |
|    ep_len_mean           | 183         |
|    ep_rew_mean           | -64.4       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 40          |
|    time_elapsed          | 1162        |
|    total_timesteps       | 1185792     |
| train/                   |             |
|    approx_kl             | 0.008166445 |
|    clip_fraction         | 0.0889      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.75        |
|    cost_value_loss       | 13.7        |
|    cost_values           | 2.73        |
|    entropy               | -1.41       |
|    entropy_loss          | -1.4        |
|    explained_variance    | 0.564       |
|    lagrangian_multiplier | 0.00264     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.62        |
|    n_updates             | 5780        |
|    policy_gradient_loss  | -0.00377    |
|    std                   | 0.543       |
|    value_loss            | 10.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.73        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.73        |
| reward                   | -0.25306076 |
| rollout/                 |             |
|    ep_len_mean           | 187         |
|    ep_rew_mean           | -65.6       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 41          |
|    time_elapsed          | 1191        |
|    total_timesteps       | 1187840     |
| train/                   |             |
|    approx_kl             | 0.020043885 |
|    clip_fraction         | 0.118       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.73        |
|    cost_value_loss       | 13.8        |
|    cost_values           | 2.73        |
|    entropy               | -1.4        |
|    entropy_loss          | -1.4        |
|    explained_variance    | 0.535       |
|    lagrangian_multiplier | 0.00274     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.79        |
|    n_updates             | 5790        |
|    policy_gradient_loss  | -0.00182    |
|    std                   | 0.542       |
|    value_loss            | 12.4        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8.03       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8.03       |
| reward                   | -0.269049  |
| rollout/                 |            |
|    ep_len_mean           | 191        |
|    ep_rew_mean           | -66.8      |
| time/                    |            |
|    fps                   | 70         |
|    iterations            | 42         |
|    time_elapsed          | 1220       |
|    total_timesteps       | 1189888    |
| train/                   |            |
|    approx_kl             | 0.02017774 |
|    clip_fraction         | 0.131      |
|    clip_range            | 0.2        |
|    cost_returns          | 5.55       |
|    cost_value_loss       | 11.1       |
|    cost_values           | 2.76       |
|    entropy               | -1.4       |
|    entropy_loss          | -1.4       |
|    explained_variance    | 0.423      |
|    lagrangian_multiplier | 0.00166    |
|    learning_rate         | 0.0003     |
|    loss                  | 7.17       |
|    n_updates             | 5800       |
|    policy_gradient_loss  | 0.00172    |
|    std                   | 0.541      |
|    value_loss            | 10.5       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.25960478 |
| rollout/                 |             |
|    ep_len_mean           | 189         |
|    ep_rew_mean           | -66.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 43          |
|    time_elapsed          | 1250        |
|    total_timesteps       | 1191936     |
| train/                   |             |
|    approx_kl             | 0.017214188 |
|    clip_fraction         | 0.15        |
|    clip_range            | 0.2         |
|    cost_returns          | 6.37        |
|    cost_value_loss       | 17.5        |
|    cost_values           | 2.78        |
|    entropy               | -1.39       |
|    entropy_loss          | -1.39       |
|    explained_variance    | 0.552       |
|    lagrangian_multiplier | 0.00325     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.87        |
|    n_updates             | 5810        |
|    policy_gradient_loss  | -0.00142    |
|    std                   | 0.539       |
|    value_loss            | 9.77        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.16        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.16        |
| reward                   | -0.35743958 |
| rollout/                 |             |
|    ep_len_mean           | 193         |
|    ep_rew_mean           | -66.9       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 44          |
|    time_elapsed          | 1280        |
|    total_timesteps       | 1193984     |
| train/                   |             |
|    approx_kl             | 0.00843136  |
|    clip_fraction         | 0.136       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.02        |
|    cost_value_loss       | 14          |
|    cost_values           | 2.79        |
|    entropy               | -1.39       |
|    entropy_loss          | -1.39       |
|    explained_variance    | 0.397       |
|    lagrangian_multiplier | 0.00288     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.65        |
|    n_updates             | 5820        |
|    policy_gradient_loss  | 0.00136     |
|    std                   | 0.538       |
|    value_loss            | 12          |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.68726164 |
| rollout/                 |             |
|    ep_len_mean           | 193         |
|    ep_rew_mean           | -66.3       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 45          |
|    time_elapsed          | 1309        |
|    total_timesteps       | 1196032     |
| train/                   |             |
|    approx_kl             | 0.030512838 |
|    clip_fraction         | 0.159       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.89        |
|    cost_value_loss       | 12.5        |
|    cost_values           | 2.82        |
|    entropy               | -1.37       |
|    entropy_loss          | -1.38       |
|    explained_variance    | 0.497       |
|    lagrangian_multiplier | 0.0041      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.03        |
|    n_updates             | 5830        |
|    policy_gradient_loss  | -0.00137    |
|    std                   | 0.535       |
|    value_loss            | 10.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.31        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.31        |
| reward                   | -0.2778745  |
| rollout/                 |             |
|    ep_len_mean           | 194         |
|    ep_rew_mean           | -66.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 46          |
|    time_elapsed          | 1339        |
|    total_timesteps       | 1198080     |
| train/                   |             |
|    approx_kl             | 0.013785249 |
|    clip_fraction         | 0.132       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.75        |
|    cost_value_loss       | 12          |
|    cost_values           | 2.83        |
|    entropy               | -1.36       |
|    entropy_loss          | -1.36       |
|    explained_variance    | 0.56        |
|    lagrangian_multiplier | 0.00346     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.28        |
|    n_updates             | 5840        |
|    policy_gradient_loss  | -0.00158    |
|    std                   | 0.53        |
|    value_loss            | 11.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3173846  |
| rollout/                 |             |
|    ep_len_mean           | 193         |
|    ep_rew_mean           | -65.6       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 47          |
|    time_elapsed          | 1368        |
|    total_timesteps       | 1200128     |
| train/                   |             |
|    approx_kl             | 0.010783742 |
|    clip_fraction         | 0.121       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.35        |
|    cost_value_loss       | 16.6        |
|    cost_values           | 2.82        |
|    entropy               | -1.35       |
|    entropy_loss          | -1.35       |
|    explained_variance    | 0.491       |
|    lagrangian_multiplier | 0.00374     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.99        |
|    n_updates             | 5850        |
|    policy_gradient_loss  | -0.0042     |
|    std                   | 0.53        |
|    value_loss            | 11.6        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8.01       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8.01       |
| reward                   | -0.3251234 |
| rollout/                 |            |
|    ep_len_mean           | 194        |
|    ep_rew_mean           | -66.1      |
| time/                    |            |
|    fps                   | 70         |
|    iterations            | 48         |
|    time_elapsed          | 1397       |
|    total_timesteps       | 1202176    |
| train/                   |            |
|    approx_kl             | 0.00891416 |
|    clip_fraction         | 0.118      |
|    clip_range            | 0.2        |
|    cost_returns          | 5.97       |
|    cost_value_loss       | 13.4       |
|    cost_values           | 2.8        |
|    entropy               | -1.35      |
|    entropy_loss          | -1.35      |
|    explained_variance    | 0.516      |
|    lagrangian_multiplier | 0.00309    |
|    learning_rate         | 0.0003     |
|    loss                  | 6.27       |
|    n_updates             | 5860       |
|    policy_gradient_loss  | -0.00399   |
|    std                   | 0.53       |
|    value_loss            | 11.5       |
-----------------------------------------
------------------------------------------
| avg_speed                | 1.17        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.17        |
| reward                   | -0.4926807  |
| rollout/                 |             |
|    ep_len_mean           | 199         |
|    ep_rew_mean           | -67.6       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 49          |
|    time_elapsed          | 1425        |
|    total_timesteps       | 1204224     |
| train/                   |             |
|    approx_kl             | 0.007208324 |
|    clip_fraction         | 0.0635      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.76        |
|    cost_value_loss       | 13.6        |
|    cost_values           | 2.79        |
|    entropy               | -1.35       |
|    entropy_loss          | -1.35       |
|    explained_variance    | 0.562       |
|    lagrangian_multiplier | 0.00309     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.71        |
|    n_updates             | 5870        |
|    policy_gradient_loss  | -0.00345    |
|    std                   | 0.53        |
|    value_loss            | 11.9        |
------------------------------------------
------------------------------------
| avg_speed          | 8           |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 8           |
| reward             | -0.28641894 |
| rollout/           |             |
|    ep_len_mean     | 185         |
|    ep_rew_mean     | -63.7       |
| time/              |             |
|    fps             | 76          |
|    iterations      | 1           |
|    time_elapsed    | 26          |
|    total_timesteps | 1206272     |
------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.24745592 |
| rollout/                 |             |
|    ep_len_mean           | 190         |
|    ep_rew_mean           | -65.1       |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 2           |
|    time_elapsed          | 55          |
|    total_timesteps       | 1208320     |
| train/                   |             |
|    approx_kl             | 0.015881808 |
|    clip_fraction         | 0.116       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.7         |
|    cost_value_loss       | 12.3        |
|    cost_values           | 2.76        |
|    entropy               | -1.33       |
|    entropy_loss          | -1.33       |
|    explained_variance    | 0.555       |
|    lagrangian_multiplier | 0.0027      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.75        |
|    n_updates             | 5890        |
|    policy_gradient_loss  | -0.0026     |
|    std                   | 0.525       |
|    value_loss            | 13.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.25653765 |
| rollout/                 |             |
|    ep_len_mean           | 188         |
|    ep_rew_mean           | -64.2       |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 3           |
|    time_elapsed          | 84          |
|    total_timesteps       | 1210368     |
| train/                   |             |
|    approx_kl             | 0.010325298 |
|    clip_fraction         | 0.103       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.11        |
|    cost_value_loss       | 14.4        |
|    cost_values           | 2.81        |
|    entropy               | -1.32       |
|    entropy_loss          | -1.32       |
|    explained_variance    | 0.654       |
|    lagrangian_multiplier | 0.00382     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.68        |
|    n_updates             | 5900        |
|    policy_gradient_loss  | -0.00248    |
|    std                   | 0.523       |
|    value_loss            | 8.09        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.23426512 |
| rollout/                 |             |
|    ep_len_mean           | 200         |
|    ep_rew_mean           | -67.4       |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 4           |
|    time_elapsed          | 113         |
|    total_timesteps       | 1212416     |
| train/                   |             |
|    approx_kl             | 0.017242605 |
|    clip_fraction         | 0.169       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.76        |
|    cost_value_loss       | 12.6        |
|    cost_values           | 2.82        |
|    entropy               | -1.32       |
|    entropy_loss          | -1.32       |
|    explained_variance    | 0.435       |
|    lagrangian_multiplier | 0.00268     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.03        |
|    n_updates             | 5910        |
|    policy_gradient_loss  | -0.00432    |
|    std                   | 0.523       |
|    value_loss            | 8.6         |
------------------------------------------
------------------------------------------
| avg_speed                | 4.37        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.37        |
| reward                   | -0.7728493  |
| rollout/                 |             |
|    ep_len_mean           | 197         |
|    ep_rew_mean           | -66.5       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 5           |
|    time_elapsed          | 142         |
|    total_timesteps       | 1214464     |
| train/                   |             |
|    approx_kl             | 0.005531433 |
|    clip_fraction         | 0.096       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.01        |
|    cost_value_loss       | 14.4        |
|    cost_values           | 2.77        |
|    entropy               | -1.32       |
|    entropy_loss          | -1.32       |
|    explained_variance    | 0.528       |
|    lagrangian_multiplier | 0.00364     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.06        |
|    n_updates             | 5920        |
|    policy_gradient_loss  | 0.000763    |
|    std                   | 0.522       |
|    value_loss            | 10.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.2858969   |
| rollout/                 |              |
|    ep_len_mean           | 186          |
|    ep_rew_mean           | -63.9        |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 6            |
|    time_elapsed          | 171          |
|    total_timesteps       | 1216512      |
| train/                   |              |
|    approx_kl             | 0.0074129337 |
|    clip_fraction         | 0.0959       |
|    clip_range            | 0.2          |
|    cost_returns          | 6.11         |
|    cost_value_loss       | 15.1         |
|    cost_values           | 2.81         |
|    entropy               | -1.33        |
|    entropy_loss          | -1.32        |
|    explained_variance    | 0.605        |
|    lagrangian_multiplier | 0.00342      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.8          |
|    n_updates             | 5930         |
|    policy_gradient_loss  | -0.00254     |
|    std                   | 0.524        |
|    value_loss            | 12           |
-------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.7723511  |
| rollout/                 |             |
|    ep_len_mean           | 194         |
|    ep_rew_mean           | -66.2       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 7           |
|    time_elapsed          | 200         |
|    total_timesteps       | 1218560     |
| train/                   |             |
|    approx_kl             | 0.008345226 |
|    clip_fraction         | 0.0929      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.63        |
|    cost_value_loss       | 13          |
|    cost_values           | 2.81        |
|    entropy               | -1.32       |
|    entropy_loss          | -1.33       |
|    explained_variance    | 0.602       |
|    lagrangian_multiplier | 0.00186     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.34        |
|    n_updates             | 5940        |
|    policy_gradient_loss  | -0.000484   |
|    std                   | 0.522       |
|    value_loss            | 11.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.84         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.84         |
| reward                   | -0.27722293  |
| rollout/                 |              |
|    ep_len_mean           | 193          |
|    ep_rew_mean           | -65.9        |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 8            |
|    time_elapsed          | 229          |
|    total_timesteps       | 1220608      |
| train/                   |              |
|    approx_kl             | 0.0057185134 |
|    clip_fraction         | 0.0821       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.87         |
|    cost_value_loss       | 12.7         |
|    cost_values           | 2.82         |
|    entropy               | -1.31        |
|    entropy_loss          | -1.32        |
|    explained_variance    | 0.511        |
|    lagrangian_multiplier | 0.00249      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.37         |
|    n_updates             | 5950         |
|    policy_gradient_loss  | -0.00386     |
|    std                   | 0.519        |
|    value_loss            | 8.77         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.19801119 |
| rollout/                 |             |
|    ep_len_mean           | 201         |
|    ep_rew_mean           | -67.7       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 9           |
|    time_elapsed          | 258         |
|    total_timesteps       | 1222656     |
| train/                   |             |
|    approx_kl             | 0.008572739 |
|    clip_fraction         | 0.117       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.61        |
|    cost_value_loss       | 17.9        |
|    cost_values           | 2.87        |
|    entropy               | -1.31       |
|    entropy_loss          | -1.31       |
|    explained_variance    | 0.521       |
|    lagrangian_multiplier | 0.00411     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.28        |
|    n_updates             | 5960        |
|    policy_gradient_loss  | -0.00404    |
|    std                   | 0.518       |
|    value_loss            | 9.4         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.68        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.68        |
| reward                   | -0.3719469  |
| rollout/                 |             |
|    ep_len_mean           | 205         |
|    ep_rew_mean           | -68.9       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 10          |
|    time_elapsed          | 287         |
|    total_timesteps       | 1224704     |
| train/                   |             |
|    approx_kl             | 0.008578351 |
|    clip_fraction         | 0.11        |
|    clip_range            | 0.2         |
|    cost_returns          | 6.14        |
|    cost_value_loss       | 15.4        |
|    cost_values           | 2.83        |
|    entropy               | -1.3        |
|    entropy_loss          | -1.3        |
|    explained_variance    | 0.476       |
|    lagrangian_multiplier | 0.00368     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.49        |
|    n_updates             | 5970        |
|    policy_gradient_loss  | -0.00345    |
|    std                   | 0.516       |
|    value_loss            | 11.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.24998187 |
| rollout/                 |             |
|    ep_len_mean           | 210         |
|    ep_rew_mean           | -70.2       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 11          |
|    time_elapsed          | 315         |
|    total_timesteps       | 1226752     |
| train/                   |             |
|    approx_kl             | 0.02320956  |
|    clip_fraction         | 0.112       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.37        |
|    cost_value_loss       | 16.3        |
|    cost_values           | 2.79        |
|    entropy               | -1.29       |
|    entropy_loss          | -1.29       |
|    explained_variance    | 0.547       |
|    lagrangian_multiplier | 0.00636     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.97        |
|    n_updates             | 5980        |
|    policy_gradient_loss  | -0.00167    |
|    std                   | 0.515       |
|    value_loss            | 9.2         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.27350286 |
| rollout/                 |             |
|    ep_len_mean           | 209         |
|    ep_rew_mean           | -69.9       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 12          |
|    time_elapsed          | 344         |
|    total_timesteps       | 1228800     |
| train/                   |             |
|    approx_kl             | 0.015775874 |
|    clip_fraction         | 0.194       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.85        |
|    cost_value_loss       | 14.3        |
|    cost_values           | 2.76        |
|    entropy               | -1.28       |
|    entropy_loss          | -1.28       |
|    explained_variance    | 0.503       |
|    lagrangian_multiplier | 0.00457     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.5         |
|    n_updates             | 5990        |
|    policy_gradient_loss  | 4.08e-05    |
|    std                   | 0.512       |
|    value_loss            | 11.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.24628368 |
| rollout/                 |             |
|    ep_len_mean           | 197         |
|    ep_rew_mean           | -66.9       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 13          |
|    time_elapsed          | 373         |
|    total_timesteps       | 1230848     |
| train/                   |             |
|    approx_kl             | 0.006900576 |
|    clip_fraction         | 0.107       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.5         |
|    cost_value_loss       | 12.9        |
|    cost_values           | 2.68        |
|    entropy               | -1.27       |
|    entropy_loss          | -1.28       |
|    explained_variance    | 0.551       |
|    lagrangian_multiplier | 0.00239     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.66        |
|    n_updates             | 6000        |
|    policy_gradient_loss  | -0.00322    |
|    std                   | 0.51        |
|    value_loss            | 12.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.32883886 |
| rollout/                 |             |
|    ep_len_mean           | 198         |
|    ep_rew_mean           | -66.8       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 14          |
|    time_elapsed          | 402         |
|    total_timesteps       | 1232896     |
| train/                   |             |
|    approx_kl             | 0.008609764 |
|    clip_fraction         | 0.121       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.96        |
|    cost_value_loss       | 13.3        |
|    cost_values           | 2.73        |
|    entropy               | -1.28       |
|    entropy_loss          | -1.28       |
|    explained_variance    | 0.595       |
|    lagrangian_multiplier | 0.00437     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.95        |
|    n_updates             | 6010        |
|    policy_gradient_loss  | -0.00146    |
|    std                   | 0.512       |
|    value_loss            | 8           |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.29196766 |
| rollout/                 |             |
|    ep_len_mean           | 191         |
|    ep_rew_mean           | -64.7       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 15          |
|    time_elapsed          | 430         |
|    total_timesteps       | 1234944     |
| train/                   |             |
|    approx_kl             | 0.007490311 |
|    clip_fraction         | 0.112       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.38        |
|    cost_value_loss       | 10.6        |
|    cost_values           | 2.77        |
|    entropy               | -1.28       |
|    entropy_loss          | -1.28       |
|    explained_variance    | 0.617       |
|    lagrangian_multiplier | 0.00261     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.34        |
|    n_updates             | 6020        |
|    policy_gradient_loss  | -0.00355    |
|    std                   | 0.513       |
|    value_loss            | 12.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.6637215  |
| rollout/                 |             |
|    ep_len_mean           | 181         |
|    ep_rew_mean           | -61.9       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 16          |
|    time_elapsed          | 459         |
|    total_timesteps       | 1236992     |
| train/                   |             |
|    approx_kl             | 0.008089813 |
|    clip_fraction         | 0.111       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.58        |
|    cost_value_loss       | 11.2        |
|    cost_values           | 2.75        |
|    entropy               | -1.27       |
|    entropy_loss          | -1.27       |
|    explained_variance    | 0.515       |
|    lagrangian_multiplier | 0.00219     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.98        |
|    n_updates             | 6030        |
|    policy_gradient_loss  | -0.00326    |
|    std                   | 0.513       |
|    value_loss            | 9.36        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.30479148 |
| rollout/                 |             |
|    ep_len_mean           | 172         |
|    ep_rew_mean           | -59.4       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 17          |
|    time_elapsed          | 488         |
|    total_timesteps       | 1239040     |
| train/                   |             |
|    approx_kl             | 0.01523484  |
|    clip_fraction         | 0.134       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.13        |
|    cost_value_loss       | 16.4        |
|    cost_values           | 2.79        |
|    entropy               | -1.28       |
|    entropy_loss          | -1.27       |
|    explained_variance    | 0.621       |
|    lagrangian_multiplier | 0.00647     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.26        |
|    n_updates             | 6040        |
|    policy_gradient_loss  | -0.00615    |
|    std                   | 0.514       |
|    value_loss            | 11.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.27162686 |
| rollout/                 |             |
|    ep_len_mean           | 168         |
|    ep_rew_mean           | -58.5       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 18          |
|    time_elapsed          | 517         |
|    total_timesteps       | 1241088     |
| train/                   |             |
|    approx_kl             | 0.011782747 |
|    clip_fraction         | 0.0996      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.08        |
|    cost_value_loss       | 15.7        |
|    cost_values           | 2.77        |
|    entropy               | -1.27       |
|    entropy_loss          | -1.28       |
|    explained_variance    | 0.598       |
|    lagrangian_multiplier | 0.00533     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.29        |
|    n_updates             | 6050        |
|    policy_gradient_loss  | -0.00386    |
|    std                   | 0.514       |
|    value_loss            | 9.64        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.27231666 |
| rollout/                 |             |
|    ep_len_mean           | 159         |
|    ep_rew_mean           | -55.7       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 19          |
|    time_elapsed          | 546         |
|    total_timesteps       | 1243136     |
| train/                   |             |
|    approx_kl             | 0.02648194  |
|    clip_fraction         | 0.126       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.54        |
|    cost_value_loss       | 11.7        |
|    cost_values           | 2.74        |
|    entropy               | -1.27       |
|    entropy_loss          | -1.27       |
|    explained_variance    | 0.584       |
|    lagrangian_multiplier | 0.00326     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.11        |
|    n_updates             | 6060        |
|    policy_gradient_loss  | 0.000679    |
|    std                   | 0.515       |
|    value_loss            | 10.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.25351614 |
| rollout/                 |             |
|    ep_len_mean           | 156         |
|    ep_rew_mean           | -55         |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 20          |
|    time_elapsed          | 575         |
|    total_timesteps       | 1245184     |
| train/                   |             |
|    approx_kl             | 0.009961152 |
|    clip_fraction         | 0.098       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.91        |
|    cost_value_loss       | 9.25        |
|    cost_values           | 2.72        |
|    entropy               | -1.27       |
|    entropy_loss          | -1.27       |
|    explained_variance    | 0.535       |
|    lagrangian_multiplier | 0.0024      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.37        |
|    n_updates             | 6070        |
|    policy_gradient_loss  | -0.0022     |
|    std                   | 0.515       |
|    value_loss            | 12.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.366648   |
| rollout/                 |             |
|    ep_len_mean           | 157         |
|    ep_rew_mean           | -55.7       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 21          |
|    time_elapsed          | 603         |
|    total_timesteps       | 1247232     |
| train/                   |             |
|    approx_kl             | 0.007307427 |
|    clip_fraction         | 0.0747      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.75        |
|    cost_value_loss       | 16          |
|    cost_values           | 2.72        |
|    entropy               | -1.27       |
|    entropy_loss          | -1.27       |
|    explained_variance    | 0.713       |
|    lagrangian_multiplier | 0.00299     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.16        |
|    n_updates             | 6080        |
|    policy_gradient_loss  | -0.0021     |
|    std                   | 0.514       |
|    value_loss            | 10.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.997       |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.997       |
| reward                   | -0.65698063 |
| rollout/                 |             |
|    ep_len_mean           | 160         |
|    ep_rew_mean           | -56.3       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 22          |
|    time_elapsed          | 632         |
|    total_timesteps       | 1249280     |
| train/                   |             |
|    approx_kl             | 0.015555512 |
|    clip_fraction         | 0.155       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.51        |
|    cost_value_loss       | 12.4        |
|    cost_values           | 2.76        |
|    entropy               | -1.27       |
|    entropy_loss          | -1.27       |
|    explained_variance    | 0.565       |
|    lagrangian_multiplier | 0.00561     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.57        |
|    n_updates             | 6090        |
|    policy_gradient_loss  | -0.00223    |
|    std                   | 0.513       |
|    value_loss            | 7.04        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.19        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.19        |
| reward                   | -0.48981783 |
| rollout/                 |             |
|    ep_len_mean           | 169         |
|    ep_rew_mean           | -62.6       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 23          |
|    time_elapsed          | 661         |
|    total_timesteps       | 1251328     |
| train/                   |             |
|    approx_kl             | 0.005509652 |
|    clip_fraction         | 0.198       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.51        |
|    cost_value_loss       | 9.23        |
|    cost_values           | 2.39        |
|    entropy               | -1.27       |
|    entropy_loss          | -1.27       |
|    explained_variance    | 0.696       |
|    lagrangian_multiplier | 0.018       |
|    learning_rate         | 0.0003      |
|    loss                  | 3.09        |
|    n_updates             | 6100        |
|    policy_gradient_loss  | 0.0104      |
|    std                   | 0.513       |
|    value_loss            | 23          |
------------------------------------------
------------------------------------------
| avg_speed                | 5.09        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.09        |
| reward                   | -0.315994   |
| rollout/                 |             |
|    ep_len_mean           | 164         |
|    ep_rew_mean           | -60.9       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 24          |
|    time_elapsed          | 689         |
|    total_timesteps       | 1253376     |
| train/                   |             |
|    approx_kl             | 0.010565704 |
|    clip_fraction         | 0.0866      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.43        |
|    cost_value_loss       | 11.4        |
|    cost_values           | 1.94        |
|    entropy               | -1.26       |
|    entropy_loss          | -1.27       |
|    explained_variance    | 0.731       |
|    lagrangian_multiplier | 0.00211     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.11        |
|    n_updates             | 6110        |
|    policy_gradient_loss  | -0.00553    |
|    std                   | 0.511       |
|    value_loss            | 14.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.52        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.52        |
| reward                   | -0.6996642  |
| rollout/                 |             |
|    ep_len_mean           | 160         |
|    ep_rew_mean           | -60.4       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 25          |
|    time_elapsed          | 719         |
|    total_timesteps       | 1255424     |
| train/                   |             |
|    approx_kl             | 0.016176892 |
|    clip_fraction         | 0.081       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.17        |
|    cost_value_loss       | 10.1        |
|    cost_values           | 1.9         |
|    entropy               | -1.27       |
|    entropy_loss          | -1.26       |
|    explained_variance    | 0.544       |
|    lagrangian_multiplier | 0.000327    |
|    learning_rate         | 0.0003      |
|    loss                  | 10.5        |
|    n_updates             | 6120        |
|    policy_gradient_loss  | -0.000721   |
|    std                   | 0.513       |
|    value_loss            | 14.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.32070234 |
| rollout/                 |             |
|    ep_len_mean           | 162         |
|    ep_rew_mean           | -60.7       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 26          |
|    time_elapsed          | 748         |
|    total_timesteps       | 1257472     |
| train/                   |             |
|    approx_kl             | 0.010421402 |
|    clip_fraction         | 0.103       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.71        |
|    cost_value_loss       | 13.3        |
|    cost_values           | 1.96        |
|    entropy               | -1.27       |
|    entropy_loss          | -1.27       |
|    explained_variance    | 0.633       |
|    lagrangian_multiplier | 0.000534    |
|    learning_rate         | 0.0003      |
|    loss                  | 10.7        |
|    n_updates             | 6130        |
|    policy_gradient_loss  | -0.00544    |
|    std                   | 0.514       |
|    value_loss            | 12.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.65        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.65        |
| reward                   | -0.34096342 |
| rollout/                 |             |
|    ep_len_mean           | 165         |
|    ep_rew_mean           | -61.8       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 27          |
|    time_elapsed          | 777         |
|    total_timesteps       | 1259520     |
| train/                   |             |
|    approx_kl             | 0.005526727 |
|    clip_fraction         | 0.0687      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.19        |
|    cost_value_loss       | 12.8        |
|    cost_values           | 2.18        |
|    entropy               | -1.26       |
|    entropy_loss          | -1.26       |
|    explained_variance    | 0.584       |
|    lagrangian_multiplier | 3.5e-05     |
|    learning_rate         | 0.0003      |
|    loss                  | 9.52        |
|    n_updates             | 6140        |
|    policy_gradient_loss  | -0.00326    |
|    std                   | 0.513       |
|    value_loss            | 9.55        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.27520734 |
| rollout/                 |             |
|    ep_len_mean           | 170         |
|    ep_rew_mean           | -63.1       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 28          |
|    time_elapsed          | 807         |
|    total_timesteps       | 1261568     |
| train/                   |             |
|    approx_kl             | 0.011629596 |
|    clip_fraction         | 0.121       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.88        |
|    cost_value_loss       | 10.6        |
|    cost_values           | 2.34        |
|    entropy               | -1.26       |
|    entropy_loss          | -1.26       |
|    explained_variance    | 0.635       |
|    lagrangian_multiplier | 0.00116     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.44        |
|    n_updates             | 6150        |
|    policy_gradient_loss  | -0.00132    |
|    std                   | 0.512       |
|    value_loss            | 10.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3545364  |
| rollout/                 |             |
|    ep_len_mean           | 158         |
|    ep_rew_mean           | -59.7       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 29          |
|    time_elapsed          | 837         |
|    total_timesteps       | 1263616     |
| train/                   |             |
|    approx_kl             | 0.009792752 |
|    clip_fraction         | 0.0961      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.99        |
|    cost_value_loss       | 10.6        |
|    cost_values           | 2.43        |
|    entropy               | -1.25       |
|    entropy_loss          | -1.26       |
|    explained_variance    | 0.603       |
|    lagrangian_multiplier | 0.00102     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.13        |
|    n_updates             | 6160        |
|    policy_gradient_loss  | -0.00455    |
|    std                   | 0.511       |
|    value_loss            | 8.96        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.55        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.55        |
| reward                   | -0.76413506 |
| rollout/                 |             |
|    ep_len_mean           | 153         |
|    ep_rew_mean           | -54.9       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 30          |
|    time_elapsed          | 866         |
|    total_timesteps       | 1265664     |
| train/                   |             |
|    approx_kl             | 0.011730012 |
|    clip_fraction         | 0.142       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.63        |
|    cost_value_loss       | 15.2        |
|    cost_values           | 2.5         |
|    entropy               | -1.25       |
|    entropy_loss          | -1.25       |
|    explained_variance    | 0.654       |
|    lagrangian_multiplier | 0.0019      |
|    learning_rate         | 0.0003      |
|    loss                  | 8.02        |
|    n_updates             | 6170        |
|    policy_gradient_loss  | -0.00213    |
|    std                   | 0.51        |
|    value_loss            | 12.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.29529762  |
| rollout/                 |              |
|    ep_len_mean           | 159          |
|    ep_rew_mean           | -56.4        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 31           |
|    time_elapsed          | 894          |
|    total_timesteps       | 1267712      |
| train/                   |              |
|    approx_kl             | 0.0058272523 |
|    clip_fraction         | 0.121        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.66         |
|    cost_value_loss       | 13.9         |
|    cost_values           | 2.58         |
|    entropy               | -1.23        |
|    entropy_loss          | -1.24        |
|    explained_variance    | 0.645        |
|    lagrangian_multiplier | 0.00189      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.37         |
|    n_updates             | 6180         |
|    policy_gradient_loss  | -0.00308     |
|    std                   | 0.506        |
|    value_loss            | 9.63         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 3.4          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.4          |
| reward                   | -0.67916685  |
| rollout/                 |              |
|    ep_len_mean           | 163          |
|    ep_rew_mean           | -57.8        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 32           |
|    time_elapsed          | 923          |
|    total_timesteps       | 1269760      |
| train/                   |              |
|    approx_kl             | 0.0084541375 |
|    clip_fraction         | 0.0704       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.71         |
|    cost_value_loss       | 8.79         |
|    cost_values           | 2.6          |
|    entropy               | -1.22        |
|    entropy_loss          | -1.23        |
|    explained_variance    | 0.614        |
|    lagrangian_multiplier | 0.00156      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.35         |
|    n_updates             | 6190         |
|    policy_gradient_loss  | -0.00274     |
|    std                   | 0.503        |
|    value_loss            | 8.28         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.2472942 |
| rollout/                 |            |
|    ep_len_mean           | 161        |
|    ep_rew_mean           | -56.7      |
| time/                    |            |
|    fps                   | 70         |
|    iterations            | 33         |
|    time_elapsed          | 952        |
|    total_timesteps       | 1271808    |
| train/                   |            |
|    approx_kl             | 0.01615764 |
|    clip_fraction         | 0.096      |
|    clip_range            | 0.2        |
|    cost_returns          | 5.93       |
|    cost_value_loss       | 15.5       |
|    cost_values           | 2.61       |
|    entropy               | -1.2       |
|    entropy_loss          | -1.21      |
|    explained_variance    | 0.615      |
|    lagrangian_multiplier | 0.00472    |
|    learning_rate         | 0.0003     |
|    loss                  | 6          |
|    n_updates             | 6200       |
|    policy_gradient_loss  | -0.00308   |
|    std                   | 0.499      |
|    value_loss            | 10.8       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.20054081 |
| rollout/                 |             |
|    ep_len_mean           | 164         |
|    ep_rew_mean           | -57.3       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 34          |
|    time_elapsed          | 981         |
|    total_timesteps       | 1273856     |
| train/                   |             |
|    approx_kl             | 0.004403312 |
|    clip_fraction         | 0.105       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.29        |
|    cost_value_loss       | 11.9        |
|    cost_values           | 2.61        |
|    entropy               | -1.2        |
|    entropy_loss          | -1.2        |
|    explained_variance    | 0.682       |
|    lagrangian_multiplier | 0.00172     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.26        |
|    n_updates             | 6210        |
|    policy_gradient_loss  | -0.00131    |
|    std                   | 0.496       |
|    value_loss            | 11.3        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.17199971  |
| rollout/                 |              |
|    ep_len_mean           | 163          |
|    ep_rew_mean           | -57.3        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 35           |
|    time_elapsed          | 1010         |
|    total_timesteps       | 1275904      |
| train/                   |              |
|    approx_kl             | 0.0089986995 |
|    clip_fraction         | 0.134        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.7          |
|    cost_value_loss       | 12.6         |
|    cost_values           | 2.59         |
|    entropy               | -1.19        |
|    entropy_loss          | -1.19        |
|    explained_variance    | 0.449        |
|    lagrangian_multiplier | 0.00688      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.19         |
|    n_updates             | 6220         |
|    policy_gradient_loss  | -0.00489     |
|    std                   | 0.495        |
|    value_loss            | 7.47         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.6982998  |
| rollout/                 |             |
|    ep_len_mean           | 158         |
|    ep_rew_mean           | -55.8       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 36          |
|    time_elapsed          | 1039        |
|    total_timesteps       | 1277952     |
| train/                   |             |
|    approx_kl             | 0.011183715 |
|    clip_fraction         | 0.169       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.09        |
|    cost_value_loss       | 11.5        |
|    cost_values           | 2.58        |
|    entropy               | -1.18       |
|    entropy_loss          | -1.18       |
|    explained_variance    | 0.729       |
|    lagrangian_multiplier | 0.00164     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.61        |
|    n_updates             | 6230        |
|    policy_gradient_loss  | 0.000503    |
|    std                   | 0.493       |
|    value_loss            | 8.75        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.30661812 |
| rollout/                 |             |
|    ep_len_mean           | 150         |
|    ep_rew_mean           | -53.6       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 37          |
|    time_elapsed          | 1068        |
|    total_timesteps       | 1280000     |
| train/                   |             |
|    approx_kl             | 0.011671225 |
|    clip_fraction         | 0.138       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.06        |
|    cost_value_loss       | 11.8        |
|    cost_values           | 2.61        |
|    entropy               | -1.17       |
|    entropy_loss          | -1.18       |
|    explained_variance    | 0.687       |
|    lagrangian_multiplier | 0.00258     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.06        |
|    n_updates             | 6240        |
|    policy_gradient_loss  | -0.00171    |
|    std                   | 0.492       |
|    value_loss            | 10.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.26611438 |
| rollout/                 |             |
|    ep_len_mean           | 150         |
|    ep_rew_mean           | -53.7       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 38          |
|    time_elapsed          | 1096        |
|    total_timesteps       | 1282048     |
| train/                   |             |
|    approx_kl             | 0.009232013 |
|    clip_fraction         | 0.126       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.26        |
|    cost_value_loss       | 12.5        |
|    cost_values           | 2.64        |
|    entropy               | -1.17       |
|    entropy_loss          | -1.17       |
|    explained_variance    | 0.717       |
|    lagrangian_multiplier | 0.00212     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.41        |
|    n_updates             | 6250        |
|    policy_gradient_loss  | -0.00325    |
|    std                   | 0.491       |
|    value_loss            | 9.84        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.270613   |
| rollout/                 |             |
|    ep_len_mean           | 149         |
|    ep_rew_mean           | -53.3       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 39          |
|    time_elapsed          | 1125        |
|    total_timesteps       | 1284096     |
| train/                   |             |
|    approx_kl             | 0.009838971 |
|    clip_fraction         | 0.0991      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.18        |
|    cost_value_loss       | 11.7        |
|    cost_values           | 2.63        |
|    entropy               | -1.17       |
|    entropy_loss          | -1.17       |
|    explained_variance    | 0.668       |
|    lagrangian_multiplier | 0.0017      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.99        |
|    n_updates             | 6260        |
|    policy_gradient_loss  | -0.00468    |
|    std                   | 0.493       |
|    value_loss            | 9.03        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.28871983  |
| rollout/                 |              |
|    ep_len_mean           | 147          |
|    ep_rew_mean           | -52.9        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 40           |
|    time_elapsed          | 1153         |
|    total_timesteps       | 1286144      |
| train/                   |              |
|    approx_kl             | 0.0047445763 |
|    clip_fraction         | 0.0828       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.29         |
|    cost_value_loss       | 10.7         |
|    cost_values           | 2.65         |
|    entropy               | -1.17        |
|    entropy_loss          | -1.17        |
|    explained_variance    | 0.648        |
|    lagrangian_multiplier | 0.00117      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.3          |
|    n_updates             | 6270         |
|    policy_gradient_loss  | -0.00346     |
|    std                   | 0.493        |
|    value_loss            | 10.2         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.23971033 |
| rollout/                 |             |
|    ep_len_mean           | 145         |
|    ep_rew_mean           | -52.6       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 41          |
|    time_elapsed          | 1182        |
|    total_timesteps       | 1288192     |
| train/                   |             |
|    approx_kl             | 0.01745516  |
|    clip_fraction         | 0.161       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.56        |
|    cost_value_loss       | 13.5        |
|    cost_values           | 2.64        |
|    entropy               | -1.16       |
|    entropy_loss          | -1.16       |
|    explained_variance    | 0.557       |
|    lagrangian_multiplier | 0.00418     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.44        |
|    n_updates             | 6280        |
|    policy_gradient_loss  | -0.00162    |
|    std                   | 0.49        |
|    value_loss            | 11.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.30521575 |
| rollout/                 |             |
|    ep_len_mean           | 149         |
|    ep_rew_mean           | -53.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 42          |
|    time_elapsed          | 1211        |
|    total_timesteps       | 1290240     |
| train/                   |             |
|    approx_kl             | 0.012156074 |
|    clip_fraction         | 0.197       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.19        |
|    cost_value_loss       | 11          |
|    cost_values           | 2.65        |
|    entropy               | -1.16       |
|    entropy_loss          | -1.16       |
|    explained_variance    | 0.557       |
|    lagrangian_multiplier | 0.00262     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.05        |
|    n_updates             | 6290        |
|    policy_gradient_loss  | 0.00326     |
|    std                   | 0.488       |
|    value_loss            | 8.32        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.39597973 |
| rollout/                 |             |
|    ep_len_mean           | 150         |
|    ep_rew_mean           | -53.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 43          |
|    time_elapsed          | 1240        |
|    total_timesteps       | 1292288     |
| train/                   |             |
|    approx_kl             | 0.019571524 |
|    clip_fraction         | 0.145       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.45        |
|    cost_value_loss       | 11.8        |
|    cost_values           | 2.7         |
|    entropy               | -1.16       |
|    entropy_loss          | -1.16       |
|    explained_variance    | 0.624       |
|    lagrangian_multiplier | 0.00201     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.4         |
|    n_updates             | 6300        |
|    policy_gradient_loss  | -0.00221    |
|    std                   | 0.489       |
|    value_loss            | 7.67        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.23782784 |
| rollout/                 |             |
|    ep_len_mean           | 152         |
|    ep_rew_mean           | -54         |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 44          |
|    time_elapsed          | 1269        |
|    total_timesteps       | 1294336     |
| train/                   |             |
|    approx_kl             | 0.022863748 |
|    clip_fraction         | 0.172       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.29        |
|    cost_value_loss       | 11.2        |
|    cost_values           | 2.66        |
|    entropy               | -1.17       |
|    entropy_loss          | -1.16       |
|    explained_variance    | 0.641       |
|    lagrangian_multiplier | 0.00406     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.43        |
|    n_updates             | 6310        |
|    policy_gradient_loss  | 0.00653     |
|    std                   | 0.491       |
|    value_loss            | 11.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.26409566 |
| rollout/                 |             |
|    ep_len_mean           | 157         |
|    ep_rew_mean           | -55.2       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 45          |
|    time_elapsed          | 1299        |
|    total_timesteps       | 1296384     |
| train/                   |             |
|    approx_kl             | 0.016806655 |
|    clip_fraction         | 0.225       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.13        |
|    cost_value_loss       | 10.4        |
|    cost_values           | 2.68        |
|    entropy               | -1.16       |
|    entropy_loss          | -1.17       |
|    explained_variance    | 0.739       |
|    lagrangian_multiplier | 0.00303     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.16        |
|    n_updates             | 6320        |
|    policy_gradient_loss  | 0.00596     |
|    std                   | 0.491       |
|    value_loss            | 8.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2453546  |
| rollout/                 |             |
|    ep_len_mean           | 163         |
|    ep_rew_mean           | -56.9       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 46          |
|    time_elapsed          | 1328        |
|    total_timesteps       | 1298432     |
| train/                   |             |
|    approx_kl             | 0.011492672 |
|    clip_fraction         | 0.103       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.86        |
|    cost_value_loss       | 14.3        |
|    cost_values           | 2.74        |
|    entropy               | -1.16       |
|    entropy_loss          | -1.16       |
|    explained_variance    | 0.68        |
|    lagrangian_multiplier | 0.00313     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.27        |
|    n_updates             | 6330        |
|    policy_gradient_loss  | -0.00132    |
|    std                   | 0.49        |
|    value_loss            | 10.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.94         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.94         |
| reward                   | -0.38591543  |
| rollout/                 |              |
|    ep_len_mean           | 161          |
|    ep_rew_mean           | -56.6        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 47           |
|    time_elapsed          | 1358         |
|    total_timesteps       | 1300480      |
| train/                   |              |
|    approx_kl             | 0.0056363344 |
|    clip_fraction         | 0.106        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.69         |
|    cost_value_loss       | 11.9         |
|    cost_values           | 2.75         |
|    entropy               | -1.16        |
|    entropy_loss          | -1.16        |
|    explained_variance    | 0.653        |
|    lagrangian_multiplier | 0.0021       |
|    learning_rate         | 0.0003       |
|    loss                  | 5.92         |
|    n_updates             | 6340         |
|    policy_gradient_loss  | -0.000221    |
|    std                   | 0.488        |
|    value_loss            | 6.71         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.21763289 |
| rollout/                 |             |
|    ep_len_mean           | 168         |
|    ep_rew_mean           | -58.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 48          |
|    time_elapsed          | 1387        |
|    total_timesteps       | 1302528     |
| train/                   |             |
|    approx_kl             | 0.024157166 |
|    clip_fraction         | 0.125       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.98        |
|    cost_value_loss       | 14.1        |
|    cost_values           | 2.8         |
|    entropy               | -1.14       |
|    entropy_loss          | -1.15       |
|    explained_variance    | 0.668       |
|    lagrangian_multiplier | 0.00491     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.3         |
|    n_updates             | 6350        |
|    policy_gradient_loss  | 0.0013      |
|    std                   | 0.484       |
|    value_loss            | 9.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.22596225 |
| rollout/                 |             |
|    ep_len_mean           | 165         |
|    ep_rew_mean           | -57.7       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 49          |
|    time_elapsed          | 1416        |
|    total_timesteps       | 1304576     |
| train/                   |             |
|    approx_kl             | 0.012823278 |
|    clip_fraction         | 0.128       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.57        |
|    cost_value_loss       | 11.7        |
|    cost_values           | 2.8         |
|    entropy               | -1.13       |
|    entropy_loss          | -1.14       |
|    explained_variance    | 0.565       |
|    lagrangian_multiplier | 0.00294     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.97        |
|    n_updates             | 6360        |
|    policy_gradient_loss  | -0.00352    |
|    std                   | 0.482       |
|    value_loss            | 11.2        |
------------------------------------------
-----------------------------------
| avg_speed          | 0.4        |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 0.4        |
| reward             | -0.7698526 |
| rollout/           |            |
|    ep_len_mean     | 154        |
|    ep_rew_mean     | -54.5      |
| time/              |            |
|    fps             | 74         |
|    iterations      | 1          |
|    time_elapsed    | 27         |
|    total_timesteps | 1306624    |
-----------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.20450017 |
| rollout/                 |             |
|    ep_len_mean           | 154         |
|    ep_rew_mean           | -54.9       |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 2           |
|    time_elapsed          | 56          |
|    total_timesteps       | 1308672     |
| train/                   |             |
|    approx_kl             | 0.011477727 |
|    clip_fraction         | 0.124       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.45        |
|    cost_value_loss       | 12.5        |
|    cost_values           | 2.77        |
|    entropy               | -1.12       |
|    entropy_loss          | -1.13       |
|    explained_variance    | 0.603       |
|    lagrangian_multiplier | 0.00367     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.11        |
|    n_updates             | 6380        |
|    policy_gradient_loss  | 0.00388     |
|    std                   | 0.479       |
|    value_loss            | 12.6        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.95         |
| reward                   | -0.259852    |
| rollout/                 |              |
|    ep_len_mean           | 149          |
|    ep_rew_mean           | -53.8        |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 3            |
|    time_elapsed          | 85           |
|    total_timesteps       | 1310720      |
| train/                   |              |
|    approx_kl             | 0.0076735183 |
|    clip_fraction         | 0.0537       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.39         |
|    cost_value_loss       | 11.3         |
|    cost_values           | 2.73         |
|    entropy               | -1.12        |
|    entropy_loss          | -1.12        |
|    explained_variance    | 0.651        |
|    lagrangian_multiplier | 0.00262      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.24         |
|    n_updates             | 6390         |
|    policy_gradient_loss  | -0.00394     |
|    std                   | 0.477        |
|    value_loss            | 11.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.35467425 |
| rollout/                 |             |
|    ep_len_mean           | 147         |
|    ep_rew_mean           | -52.9       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 4           |
|    time_elapsed          | 114         |
|    total_timesteps       | 1312768     |
| train/                   |             |
|    approx_kl             | 0.011928406 |
|    clip_fraction         | 0.131       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.07        |
|    cost_value_loss       | 9.64        |
|    cost_values           | 2.76        |
|    entropy               | -1.1        |
|    entropy_loss          | -1.11       |
|    explained_variance    | 0.692       |
|    lagrangian_multiplier | 0.00192     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.21        |
|    n_updates             | 6400        |
|    policy_gradient_loss  | -0.00264    |
|    std                   | 0.474       |
|    value_loss            | 9.46        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.29565504 |
| rollout/                 |             |
|    ep_len_mean           | 149         |
|    ep_rew_mean           | -53.3       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 5           |
|    time_elapsed          | 142         |
|    total_timesteps       | 1314816     |
| train/                   |             |
|    approx_kl             | 0.008733577 |
|    clip_fraction         | 0.0962      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.99        |
|    cost_value_loss       | 9.3         |
|    cost_values           | 2.73        |
|    entropy               | -1.09       |
|    entropy_loss          | -1.1        |
|    explained_variance    | 0.697       |
|    lagrangian_multiplier | 0.00173     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.93        |
|    n_updates             | 6410        |
|    policy_gradient_loss  | -0.0011     |
|    std                   | 0.47        |
|    value_loss            | 8.24        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.21740152  |
| rollout/                 |              |
|    ep_len_mean           | 149          |
|    ep_rew_mean           | -53.6        |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 6            |
|    time_elapsed          | 171          |
|    total_timesteps       | 1316864      |
| train/                   |              |
|    approx_kl             | 0.0061888574 |
|    clip_fraction         | 0.11         |
|    clip_range            | 0.2          |
|    cost_returns          | 4.68         |
|    cost_value_loss       | 7.78         |
|    cost_values           | 2.67         |
|    entropy               | -1.09        |
|    entropy_loss          | -1.09        |
|    explained_variance    | 0.585        |
|    lagrangian_multiplier | 0.00113      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.88         |
|    n_updates             | 6420         |
|    policy_gradient_loss  | -0.00409     |
|    std                   | 0.47         |
|    value_loss            | 10.7         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 2          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 2          |
| reward                   | -0.791272  |
| rollout/                 |            |
|    ep_len_mean           | 144        |
|    ep_rew_mean           | -52.2      |
| time/                    |            |
|    fps                   | 71         |
|    iterations            | 7          |
|    time_elapsed          | 200        |
|    total_timesteps       | 1318912    |
| train/                   |            |
|    approx_kl             | 0.00858319 |
|    clip_fraction         | 0.105      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.98       |
|    cost_value_loss       | 8.39       |
|    cost_values           | 2.69       |
|    entropy               | -1.08      |
|    entropy_loss          | -1.09      |
|    explained_variance    | 0.6        |
|    lagrangian_multiplier | 0.00271    |
|    learning_rate         | 0.0003     |
|    loss                  | 5.04       |
|    n_updates             | 6430       |
|    policy_gradient_loss  | -0.00385   |
|    std                   | 0.471      |
|    value_loss            | 9.05       |
-----------------------------------------
-----------------------------------------
| avg_speed                | 6.39       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 6.39       |
| reward                   | -0.2979528 |
| rollout/                 |            |
|    ep_len_mean           | 146        |
|    ep_rew_mean           | -52.7      |
| time/                    |            |
|    fps                   | 71         |
|    iterations            | 8          |
|    time_elapsed          | 229        |
|    total_timesteps       | 1320960    |
| train/                   |            |
|    approx_kl             | 0.01223786 |
|    clip_fraction         | 0.127      |
|    clip_range            | 0.2        |
|    cost_returns          | 5.68       |
|    cost_value_loss       | 13.2       |
|    cost_values           | 2.77       |
|    entropy               | -1.08      |
|    entropy_loss          | -1.08      |
|    explained_variance    | 0.696      |
|    lagrangian_multiplier | 0.00363    |
|    learning_rate         | 0.0003     |
|    loss                  | 5.82       |
|    n_updates             | 6440       |
|    policy_gradient_loss  | 0.000828   |
|    std                   | 0.47       |
|    value_loss            | 10         |
-----------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.30751896 |
| rollout/                 |             |
|    ep_len_mean           | 146         |
|    ep_rew_mean           | -52.6       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 9           |
|    time_elapsed          | 258         |
|    total_timesteps       | 1323008     |
| train/                   |             |
|    approx_kl             | 0.00890754  |
|    clip_fraction         | 0.112       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.88        |
|    cost_value_loss       | 9.34        |
|    cost_values           | 2.69        |
|    entropy               | -1.08       |
|    entropy_loss          | -1.08       |
|    explained_variance    | 0.654       |
|    lagrangian_multiplier | 0.00238     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.97        |
|    n_updates             | 6450        |
|    policy_gradient_loss  | -0.000663   |
|    std                   | 0.471       |
|    value_loss            | 12.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.4443321  |
| rollout/                 |             |
|    ep_len_mean           | 151         |
|    ep_rew_mean           | -54.1       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 10          |
|    time_elapsed          | 287         |
|    total_timesteps       | 1325056     |
| train/                   |             |
|    approx_kl             | 0.023564681 |
|    clip_fraction         | 0.127       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.21        |
|    cost_value_loss       | 10.4        |
|    cost_values           | 2.67        |
|    entropy               | -1.07       |
|    entropy_loss          | -1.07       |
|    explained_variance    | 0.647       |
|    lagrangian_multiplier | 0.00318     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.83        |
|    n_updates             | 6460        |
|    policy_gradient_loss  | -0.00318    |
|    std                   | 0.471       |
|    value_loss            | 10.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.15        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.15        |
| reward                   | -0.27459168 |
| rollout/                 |             |
|    ep_len_mean           | 152         |
|    ep_rew_mean           | -54.1       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 11          |
|    time_elapsed          | 316         |
|    total_timesteps       | 1327104     |
| train/                   |             |
|    approx_kl             | 0.008568231 |
|    clip_fraction         | 0.147       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.48        |
|    cost_value_loss       | 12.3        |
|    cost_values           | 2.7         |
|    entropy               | -1.07       |
|    entropy_loss          | -1.07       |
|    explained_variance    | 0.693       |
|    lagrangian_multiplier | 0.00366     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.66        |
|    n_updates             | 6470        |
|    policy_gradient_loss  | 0.00493     |
|    std                   | 0.471       |
|    value_loss            | 9.19        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.26375914  |
| rollout/                 |              |
|    ep_len_mean           | 154          |
|    ep_rew_mean           | -55.2        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 12           |
|    time_elapsed          | 346          |
|    total_timesteps       | 1329152      |
| train/                   |              |
|    approx_kl             | 0.0106547875 |
|    clip_fraction         | 0.156        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.24         |
|    cost_value_loss       | 10.2         |
|    cost_values           | 2.69         |
|    entropy               | -1.06        |
|    entropy_loss          | -1.06        |
|    explained_variance    | 0.634        |
|    lagrangian_multiplier | 0.00285      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.92         |
|    n_updates             | 6480         |
|    policy_gradient_loss  | 0.0018       |
|    std                   | 0.471        |
|    value_loss            | 10.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.5882842  |
| rollout/                 |             |
|    ep_len_mean           | 146         |
|    ep_rew_mean           | -53.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 13          |
|    time_elapsed          | 375         |
|    total_timesteps       | 1331200     |
| train/                   |             |
|    approx_kl             | 0.008641059 |
|    clip_fraction         | 0.165       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.46        |
|    cost_value_loss       | 8.88        |
|    cost_values           | 2.58        |
|    entropy               | -1.06       |
|    entropy_loss          | -1.06       |
|    explained_variance    | 0.645       |
|    lagrangian_multiplier | 0.00202     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.95        |
|    n_updates             | 6490        |
|    policy_gradient_loss  | 0.00313     |
|    std                   | 0.471       |
|    value_loss            | 10.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.8923724  |
| rollout/                 |             |
|    ep_len_mean           | 151         |
|    ep_rew_mean           | -54.6       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 14          |
|    time_elapsed          | 405         |
|    total_timesteps       | 1333248     |
| train/                   |             |
|    approx_kl             | 0.010083972 |
|    clip_fraction         | 0.14        |
|    clip_range            | 0.2         |
|    cost_returns          | 5.07        |
|    cost_value_loss       | 10.5        |
|    cost_values           | 2.58        |
|    entropy               | -1.06       |
|    entropy_loss          | -1.06       |
|    explained_variance    | 0.629       |
|    lagrangian_multiplier | 0.00155     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.52        |
|    n_updates             | 6500        |
|    policy_gradient_loss  | -0.00104    |
|    std                   | 0.47        |
|    value_loss            | 12.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.2068504  |
| rollout/                 |             |
|    ep_len_mean           | 158         |
|    ep_rew_mean           | -57.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 15          |
|    time_elapsed          | 434         |
|    total_timesteps       | 1335296     |
| train/                   |             |
|    approx_kl             | 0.010437768 |
|    clip_fraction         | 0.118       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.62        |
|    cost_value_loss       | 12.2        |
|    cost_values           | 2.65        |
|    entropy               | -1.05       |
|    entropy_loss          | -1.06       |
|    explained_variance    | 0.609       |
|    lagrangian_multiplier | 0.00287     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.35        |
|    n_updates             | 6510        |
|    policy_gradient_loss  | -0.00152    |
|    std                   | 0.469       |
|    value_loss            | 10.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.21529102 |
| rollout/                 |             |
|    ep_len_mean           | 155         |
|    ep_rew_mean           | -56.6       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 16          |
|    time_elapsed          | 463         |
|    total_timesteps       | 1337344     |
| train/                   |             |
|    approx_kl             | 0.010068094 |
|    clip_fraction         | 0.0706      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.96        |
|    cost_value_loss       | 15.4        |
|    cost_values           | 2.72        |
|    entropy               | -1.05       |
|    entropy_loss          | -1.05       |
|    explained_variance    | 0.567       |
|    lagrangian_multiplier | 0.00408     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.97        |
|    n_updates             | 6520        |
|    policy_gradient_loss  | -0.00172    |
|    std                   | 0.469       |
|    value_loss            | 9.89        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.24673887 |
| rollout/                 |             |
|    ep_len_mean           | 145         |
|    ep_rew_mean           | -53.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 17          |
|    time_elapsed          | 493         |
|    total_timesteps       | 1339392     |
| train/                   |             |
|    approx_kl             | 0.007455431 |
|    clip_fraction         | 0.0704      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.76        |
|    cost_value_loss       | 9.21        |
|    cost_values           | 2.61        |
|    entropy               | -1.05       |
|    entropy_loss          | -1.05       |
|    explained_variance    | 0.591       |
|    lagrangian_multiplier | 0.00105     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.66        |
|    n_updates             | 6530        |
|    policy_gradient_loss  | -0.00421    |
|    std                   | 0.471       |
|    value_loss            | 14.1        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.37190557  |
| rollout/                 |              |
|    ep_len_mean           | 144          |
|    ep_rew_mean           | -53.6        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 18           |
|    time_elapsed          | 522          |
|    total_timesteps       | 1341440      |
| train/                   |              |
|    approx_kl             | 0.0066138953 |
|    clip_fraction         | 0.0933       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.04         |
|    cost_value_loss       | 9.46         |
|    cost_values           | 2.55         |
|    entropy               | -1.06        |
|    entropy_loss          | -1.06        |
|    explained_variance    | 0.561        |
|    lagrangian_multiplier | 0.00121      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.29         |
|    n_updates             | 6540         |
|    policy_gradient_loss  | -0.00112     |
|    std                   | 0.473        |
|    value_loss            | 11.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.8         |
| reward                   | -0.71346503 |
| rollout/                 |             |
|    ep_len_mean           | 144         |
|    ep_rew_mean           | -52.9       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 19          |
|    time_elapsed          | 551         |
|    total_timesteps       | 1343488     |
| train/                   |             |
|    approx_kl             | 0.024945859 |
|    clip_fraction         | 0.131       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.24        |
|    cost_value_loss       | 11.6        |
|    cost_values           | 2.59        |
|    entropy               | -1.05       |
|    entropy_loss          | -1.06       |
|    explained_variance    | 0.579       |
|    lagrangian_multiplier | 0.00255     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.21        |
|    n_updates             | 6550        |
|    policy_gradient_loss  | -0.00386    |
|    std                   | 0.472       |
|    value_loss            | 10.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.27822223 |
| rollout/                 |             |
|    ep_len_mean           | 145         |
|    ep_rew_mean           | -52.9       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 20          |
|    time_elapsed          | 580         |
|    total_timesteps       | 1345536     |
| train/                   |             |
|    approx_kl             | 0.012700286 |
|    clip_fraction         | 0.153       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.71        |
|    cost_value_loss       | 13.4        |
|    cost_values           | 2.65        |
|    entropy               | -1.05       |
|    entropy_loss          | -1.05       |
|    explained_variance    | 0.553       |
|    lagrangian_multiplier | 0.00334     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.2         |
|    n_updates             | 6560        |
|    policy_gradient_loss  | 0.00173     |
|    std                   | 0.471       |
|    value_loss            | 11.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.26373172 |
| rollout/                 |             |
|    ep_len_mean           | 148         |
|    ep_rew_mean           | -54.3       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 21          |
|    time_elapsed          | 608         |
|    total_timesteps       | 1347584     |
| train/                   |             |
|    approx_kl             | 0.011630922 |
|    clip_fraction         | 0.122       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.89        |
|    cost_value_loss       | 9.86        |
|    cost_values           | 2.62        |
|    entropy               | -1.03       |
|    entropy_loss          | -1.04       |
|    explained_variance    | 0.642       |
|    lagrangian_multiplier | 0.00215     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.86        |
|    n_updates             | 6570        |
|    policy_gradient_loss  | -0.00258    |
|    std                   | 0.469       |
|    value_loss            | 9.87        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.15        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.15        |
| reward                   | -0.641177   |
| rollout/                 |             |
|    ep_len_mean           | 145         |
|    ep_rew_mean           | -53.6       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 22          |
|    time_elapsed          | 637         |
|    total_timesteps       | 1349632     |
| train/                   |             |
|    approx_kl             | 0.006948308 |
|    clip_fraction         | 0.0982      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.29        |
|    cost_value_loss       | 7.74        |
|    cost_values           | 2.54        |
|    entropy               | -1.03       |
|    entropy_loss          | -1.03       |
|    explained_variance    | 0.646       |
|    lagrangian_multiplier | 0.00084     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.45        |
|    n_updates             | 6580        |
|    policy_gradient_loss  | -0.00157    |
|    std                   | 0.47        |
|    value_loss            | 10.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2516634  |
| rollout/                 |             |
|    ep_len_mean           | 144         |
|    ep_rew_mean           | -52.7       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 23          |
|    time_elapsed          | 666         |
|    total_timesteps       | 1351680     |
| train/                   |             |
|    approx_kl             | 0.016165841 |
|    clip_fraction         | 0.0965      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.11        |
|    cost_value_loss       | 11.9        |
|    cost_values           | 2.54        |
|    entropy               | -1.03       |
|    entropy_loss          | -1.03       |
|    explained_variance    | 0.591       |
|    lagrangian_multiplier | 0.00181     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.72        |
|    n_updates             | 6590        |
|    policy_gradient_loss  | -0.00361    |
|    std                   | 0.472       |
|    value_loss            | 11.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.24467665 |
| rollout/                 |             |
|    ep_len_mean           | 151         |
|    ep_rew_mean           | -54.8       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 24          |
|    time_elapsed          | 695         |
|    total_timesteps       | 1353728     |
| train/                   |             |
|    approx_kl             | 0.012608403 |
|    clip_fraction         | 0.134       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.13        |
|    cost_value_loss       | 10.2        |
|    cost_values           | 2.57        |
|    entropy               | -1.03       |
|    entropy_loss          | -1.03       |
|    explained_variance    | 0.58        |
|    lagrangian_multiplier | 0.00186     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.37        |
|    n_updates             | 6600        |
|    policy_gradient_loss  | 0.000106    |
|    std                   | 0.47        |
|    value_loss            | 10          |
------------------------------------------
------------------------------------------
| avg_speed                | 7.82        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.82        |
| reward                   | -0.32934025 |
| rollout/                 |             |
|    ep_len_mean           | 148         |
|    ep_rew_mean           | -53.8       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 25          |
|    time_elapsed          | 724         |
|    total_timesteps       | 1355776     |
| train/                   |             |
|    approx_kl             | 0.008941504 |
|    clip_fraction         | 0.186       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.6         |
|    cost_value_loss       | 13.8        |
|    cost_values           | 2.63        |
|    entropy               | -1.03       |
|    entropy_loss          | -1.03       |
|    explained_variance    | 0.703       |
|    lagrangian_multiplier | 0.00244     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.44        |
|    n_updates             | 6610        |
|    policy_gradient_loss  | 0.00368     |
|    std                   | 0.471       |
|    value_loss            | 9.26        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.14        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.14        |
| reward                   | -0.777702   |
| rollout/                 |             |
|    ep_len_mean           | 144         |
|    ep_rew_mean           | -52.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 26          |
|    time_elapsed          | 754         |
|    total_timesteps       | 1357824     |
| train/                   |             |
|    approx_kl             | 0.011679049 |
|    clip_fraction         | 0.131       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.35        |
|    cost_value_loss       | 12.5        |
|    cost_values           | 2.67        |
|    entropy               | -1.03       |
|    entropy_loss          | -1.03       |
|    explained_variance    | 0.737       |
|    lagrangian_multiplier | 0.00161     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.94        |
|    n_updates             | 6620        |
|    policy_gradient_loss  | -0.000469   |
|    std                   | 0.471       |
|    value_loss            | 9.64        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.34507915 |
| rollout/                 |             |
|    ep_len_mean           | 140         |
|    ep_rew_mean           | -51.3       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 27          |
|    time_elapsed          | 784         |
|    total_timesteps       | 1359872     |
| train/                   |             |
|    approx_kl             | 0.00931715  |
|    clip_fraction         | 0.121       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.34        |
|    cost_value_loss       | 13.7        |
|    cost_values           | 2.62        |
|    entropy               | -1.02       |
|    entropy_loss          | -1.02       |
|    explained_variance    | 0.735       |
|    lagrangian_multiplier | 0.00198     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.1         |
|    n_updates             | 6630        |
|    policy_gradient_loss  | -0.00516    |
|    std                   | 0.468       |
|    value_loss            | 10.7        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.5          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.5          |
| reward                   | -0.7095345   |
| rollout/                 |              |
|    ep_len_mean           | 139          |
|    ep_rew_mean           | -49.6        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 28           |
|    time_elapsed          | 814          |
|    total_timesteps       | 1361920      |
| train/                   |              |
|    approx_kl             | 0.0080211945 |
|    clip_fraction         | 0.136        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.39         |
|    cost_value_loss       | 12.1         |
|    cost_values           | 2.65         |
|    entropy               | -1.02        |
|    entropy_loss          | -1.02        |
|    explained_variance    | 0.697        |
|    lagrangian_multiplier | 0.00162      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.69         |
|    n_updates             | 6640         |
|    policy_gradient_loss  | -0.000412    |
|    std                   | 0.468        |
|    value_loss            | 9.75         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.27520755 |
| rollout/                 |             |
|    ep_len_mean           | 140         |
|    ep_rew_mean           | -49.8       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 29          |
|    time_elapsed          | 843         |
|    total_timesteps       | 1363968     |
| train/                   |             |
|    approx_kl             | 0.010018386 |
|    clip_fraction         | 0.102       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.82        |
|    cost_value_loss       | 14          |
|    cost_values           | 2.69        |
|    entropy               | -1.01       |
|    entropy_loss          | -1.01       |
|    explained_variance    | 0.614       |
|    lagrangian_multiplier | 0.00209     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.47        |
|    n_updates             | 6650        |
|    policy_gradient_loss  | -0.00147    |
|    std                   | 0.466       |
|    value_loss            | 8.77        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2105029  |
| rollout/                 |             |
|    ep_len_mean           | 140         |
|    ep_rew_mean           | -50.3       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 30          |
|    time_elapsed          | 872         |
|    total_timesteps       | 1366016     |
| train/                   |             |
|    approx_kl             | 0.010188636 |
|    clip_fraction         | 0.0951      |
|    clip_range            | 0.2         |
|    cost_returns          | 6.25        |
|    cost_value_loss       | 16.6        |
|    cost_values           | 2.76        |
|    entropy               | -1          |
|    entropy_loss          | -1.01       |
|    explained_variance    | 0.616       |
|    lagrangian_multiplier | 0.0031      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.58        |
|    n_updates             | 6660        |
|    policy_gradient_loss  | -0.00299    |
|    std                   | 0.466       |
|    value_loss            | 9.3         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.85        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.85        |
| reward                   | -0.31864113 |
| rollout/                 |             |
|    ep_len_mean           | 138         |
|    ep_rew_mean           | -49.7       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 31          |
|    time_elapsed          | 900         |
|    total_timesteps       | 1368064     |
| train/                   |             |
|    approx_kl             | 0.009825568 |
|    clip_fraction         | 0.103       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.56        |
|    cost_value_loss       | 13.9        |
|    cost_values           | 2.73        |
|    entropy               | -1          |
|    entropy_loss          | -1          |
|    explained_variance    | 0.67        |
|    lagrangian_multiplier | 0.00321     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.62        |
|    n_updates             | 6670        |
|    policy_gradient_loss  | -0.00283    |
|    std                   | 0.466       |
|    value_loss            | 12.2        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.2827835   |
| rollout/                 |              |
|    ep_len_mean           | 134          |
|    ep_rew_mean           | -48.5        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 32           |
|    time_elapsed          | 930          |
|    total_timesteps       | 1370112      |
| train/                   |              |
|    approx_kl             | 0.0097660115 |
|    clip_fraction         | 0.15         |
|    clip_range            | 0.2          |
|    cost_returns          | 5.37         |
|    cost_value_loss       | 11.8         |
|    cost_values           | 2.71         |
|    entropy               | -0.999       |
|    entropy_loss          | -1           |
|    explained_variance    | 0.66         |
|    lagrangian_multiplier | 0.00327      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.06         |
|    n_updates             | 6680         |
|    policy_gradient_loss  | 0.00105      |
|    std                   | 0.465        |
|    value_loss            | 11           |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.20237994 |
| rollout/                 |             |
|    ep_len_mean           | 140         |
|    ep_rew_mean           | -49.4       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 33          |
|    time_elapsed          | 959         |
|    total_timesteps       | 1372160     |
| train/                   |             |
|    approx_kl             | 0.0095402   |
|    clip_fraction         | 0.137       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.53        |
|    cost_value_loss       | 12.9        |
|    cost_values           | 2.66        |
|    entropy               | -1.01       |
|    entropy_loss          | -1          |
|    explained_variance    | 0.6         |
|    lagrangian_multiplier | 0.00177     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.52        |
|    n_updates             | 6690        |
|    policy_gradient_loss  | 0.00238     |
|    std                   | 0.467       |
|    value_loss            | 11.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.28489867 |
| rollout/                 |             |
|    ep_len_mean           | 141         |
|    ep_rew_mean           | -50         |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 34          |
|    time_elapsed          | 988         |
|    total_timesteps       | 1374208     |
| train/                   |             |
|    approx_kl             | 0.011059852 |
|    clip_fraction         | 0.114       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.02        |
|    cost_value_loss       | 15.8        |
|    cost_values           | 2.71        |
|    entropy               | -1          |
|    entropy_loss          | -1.01       |
|    explained_variance    | 0.574       |
|    lagrangian_multiplier | 0.00396     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.97        |
|    n_updates             | 6700        |
|    policy_gradient_loss  | -0.000324   |
|    std                   | 0.467       |
|    value_loss            | 8.75        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.33408257 |
| rollout/                 |             |
|    ep_len_mean           | 137         |
|    ep_rew_mean           | -49.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 35          |
|    time_elapsed          | 1017        |
|    total_timesteps       | 1376256     |
| train/                   |             |
|    approx_kl             | 0.010386994 |
|    clip_fraction         | 0.109       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.58        |
|    cost_value_loss       | 13.2        |
|    cost_values           | 2.69        |
|    entropy               | -0.995      |
|    entropy_loss          | -1          |
|    explained_variance    | 0.649       |
|    lagrangian_multiplier | 0.00619     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.97        |
|    n_updates             | 6710        |
|    policy_gradient_loss  | -0.00334    |
|    std                   | 0.465       |
|    value_loss            | 10.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.16313685 |
| rollout/                 |             |
|    ep_len_mean           | 133         |
|    ep_rew_mean           | -48.2       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 36          |
|    time_elapsed          | 1046        |
|    total_timesteps       | 1378304     |
| train/                   |             |
|    approx_kl             | 0.010108292 |
|    clip_fraction         | 0.159       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.8         |
|    cost_value_loss       | 14.8        |
|    cost_values           | 2.64        |
|    entropy               | -0.984      |
|    entropy_loss          | -0.989      |
|    explained_variance    | 0.67        |
|    lagrangian_multiplier | 0.00206     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.23        |
|    n_updates             | 6720        |
|    policy_gradient_loss  | 0.000786    |
|    std                   | 0.464       |
|    value_loss            | 9.8         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.22701994 |
| rollout/                 |             |
|    ep_len_mean           | 139         |
|    ep_rew_mean           | -49.6       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 37          |
|    time_elapsed          | 1076        |
|    total_timesteps       | 1380352     |
| train/                   |             |
|    approx_kl             | 0.02002817  |
|    clip_fraction         | 0.144       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.58        |
|    cost_value_loss       | 13.9        |
|    cost_values           | 2.61        |
|    entropy               | -0.982      |
|    entropy_loss          | -0.982      |
|    explained_variance    | 0.657       |
|    lagrangian_multiplier | 0.00334     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.16        |
|    n_updates             | 6730        |
|    policy_gradient_loss  | -0.00441    |
|    std                   | 0.463       |
|    value_loss            | 11.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2520492  |
| rollout/                 |             |
|    ep_len_mean           | 137         |
|    ep_rew_mean           | -49         |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 38          |
|    time_elapsed          | 1105        |
|    total_timesteps       | 1382400     |
| train/                   |             |
|    approx_kl             | 0.012859098 |
|    clip_fraction         | 0.125       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.68        |
|    cost_value_loss       | 13.8        |
|    cost_values           | 2.61        |
|    entropy               | -0.985      |
|    entropy_loss          | -0.984      |
|    explained_variance    | 0.646       |
|    lagrangian_multiplier | 0.0031      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.71        |
|    n_updates             | 6740        |
|    policy_gradient_loss  | -0.00322    |
|    std                   | 0.463       |
|    value_loss            | 9.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.2         |
| reward                   | -0.49882331 |
| rollout/                 |             |
|    ep_len_mean           | 135         |
|    ep_rew_mean           | -48.6       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 39          |
|    time_elapsed          | 1134        |
|    total_timesteps       | 1384448     |
| train/                   |             |
|    approx_kl             | 0.013094324 |
|    clip_fraction         | 0.224       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.46        |
|    cost_value_loss       | 12.8        |
|    cost_values           | 2.64        |
|    entropy               | -0.984      |
|    entropy_loss          | -0.984      |
|    explained_variance    | 0.637       |
|    lagrangian_multiplier | 0.00294     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.87        |
|    n_updates             | 6750        |
|    policy_gradient_loss  | 0.00599     |
|    std                   | 0.463       |
|    value_loss            | 9.39        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.21190606  |
| rollout/                 |              |
|    ep_len_mean           | 143          |
|    ep_rew_mean           | -51.5        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 40           |
|    time_elapsed          | 1163         |
|    total_timesteps       | 1386496      |
| train/                   |              |
|    approx_kl             | 0.0102664335 |
|    clip_fraction         | 0.128        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.11         |
|    cost_value_loss       | 10.3         |
|    cost_values           | 2.62         |
|    entropy               | -0.98        |
|    entropy_loss          | -0.982       |
|    explained_variance    | 0.644        |
|    lagrangian_multiplier | 0.00122      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.18         |
|    n_updates             | 6760         |
|    policy_gradient_loss  | 0.00137      |
|    std                   | 0.463        |
|    value_loss            | 10.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.19281486 |
| rollout/                 |             |
|    ep_len_mean           | 140         |
|    ep_rew_mean           | -50.6       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 41          |
|    time_elapsed          | 1192        |
|    total_timesteps       | 1388544     |
| train/                   |             |
|    approx_kl             | 0.010695226 |
|    clip_fraction         | 0.154       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.24        |
|    cost_value_loss       | 11.4        |
|    cost_values           | 2.62        |
|    entropy               | -0.979      |
|    entropy_loss          | -0.98       |
|    explained_variance    | 0.588       |
|    lagrangian_multiplier | 0.0036      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.07        |
|    n_updates             | 6770        |
|    policy_gradient_loss  | -0.00123    |
|    std                   | 0.462       |
|    value_loss            | 8.52        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.3447515   |
| rollout/                 |              |
|    ep_len_mean           | 142          |
|    ep_rew_mean           | -50.8        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 42           |
|    time_elapsed          | 1221         |
|    total_timesteps       | 1390592      |
| train/                   |              |
|    approx_kl             | 0.0087680705 |
|    clip_fraction         | 0.0925       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.64         |
|    cost_value_loss       | 13.6         |
|    cost_values           | 2.64         |
|    entropy               | -0.979       |
|    entropy_loss          | -0.979       |
|    explained_variance    | 0.63         |
|    lagrangian_multiplier | 0.00435      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.93         |
|    n_updates             | 6780         |
|    policy_gradient_loss  | -0.00481     |
|    std                   | 0.463        |
|    value_loss            | 10.9         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.7323582  |
| rollout/                 |             |
|    ep_len_mean           | 135         |
|    ep_rew_mean           | -49.2       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 43          |
|    time_elapsed          | 1250        |
|    total_timesteps       | 1392640     |
| train/                   |             |
|    approx_kl             | 0.016806314 |
|    clip_fraction         | 0.143       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.64        |
|    cost_value_loss       | 12.6        |
|    cost_values           | 2.64        |
|    entropy               | -0.982      |
|    entropy_loss          | -0.981      |
|    explained_variance    | 0.616       |
|    lagrangian_multiplier | 0.00379     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.29        |
|    n_updates             | 6790        |
|    policy_gradient_loss  | 0.0018      |
|    std                   | 0.466       |
|    value_loss            | 9.15        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.22470748 |
| rollout/                 |             |
|    ep_len_mean           | 139         |
|    ep_rew_mean           | -50.3       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 44          |
|    time_elapsed          | 1279        |
|    total_timesteps       | 1394688     |
| train/                   |             |
|    approx_kl             | 0.029465858 |
|    clip_fraction         | 0.162       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.53        |
|    cost_value_loss       | 8.69        |
|    cost_values           | 2.56        |
|    entropy               | -0.981      |
|    entropy_loss          | -0.982      |
|    explained_variance    | 0.681       |
|    lagrangian_multiplier | 0.00184     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.36        |
|    n_updates             | 6800        |
|    policy_gradient_loss  | 0.00426     |
|    std                   | 0.467       |
|    value_loss            | 12.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.33104396 |
| rollout/                 |             |
|    ep_len_mean           | 128         |
|    ep_rew_mean           | -47.6       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 45          |
|    time_elapsed          | 1308        |
|    total_timesteps       | 1396736     |
| train/                   |             |
|    approx_kl             | 0.016561111 |
|    clip_fraction         | 0.137       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.22        |
|    cost_value_loss       | 11.5        |
|    cost_values           | 2.54        |
|    entropy               | -0.976      |
|    entropy_loss          | -0.979      |
|    explained_variance    | 0.634       |
|    lagrangian_multiplier | 0.00179     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.29        |
|    n_updates             | 6810        |
|    policy_gradient_loss  | -0.00301    |
|    std                   | 0.466       |
|    value_loss            | 8.09        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.25639123 |
| rollout/                 |             |
|    ep_len_mean           | 126         |
|    ep_rew_mean           | -46.3       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 46          |
|    time_elapsed          | 1337        |
|    total_timesteps       | 1398784     |
| train/                   |             |
|    approx_kl             | 0.012558284 |
|    clip_fraction         | 0.142       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.2         |
|    cost_value_loss       | 10.9        |
|    cost_values           | 2.6         |
|    entropy               | -0.972      |
|    entropy_loss          | -0.974      |
|    explained_variance    | 0.654       |
|    lagrangian_multiplier | 0.00329     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.6         |
|    n_updates             | 6820        |
|    policy_gradient_loss  | 0.00316     |
|    std                   | 0.466       |
|    value_loss            | 11.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.24959032 |
| rollout/                 |             |
|    ep_len_mean           | 129         |
|    ep_rew_mean           | -47.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 47          |
|    time_elapsed          | 1366        |
|    total_timesteps       | 1400832     |
| train/                   |             |
|    approx_kl             | 0.005498417 |
|    clip_fraction         | 0.0974      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.68        |
|    cost_value_loss       | 13.8        |
|    cost_values           | 2.63        |
|    entropy               | -0.968      |
|    entropy_loss          | -0.97       |
|    explained_variance    | 0.652       |
|    lagrangian_multiplier | 0.00225     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.67        |
|    n_updates             | 6830        |
|    policy_gradient_loss  | 0.00231     |
|    std                   | 0.466       |
|    value_loss            | 9.07        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.226893   |
| rollout/                 |             |
|    ep_len_mean           | 128         |
|    ep_rew_mean           | -46.7       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 48          |
|    time_elapsed          | 1394        |
|    total_timesteps       | 1402880     |
| train/                   |             |
|    approx_kl             | 0.007881796 |
|    clip_fraction         | 0.1         |
|    clip_range            | 0.2         |
|    cost_returns          | 5.59        |
|    cost_value_loss       | 13.2        |
|    cost_values           | 2.67        |
|    entropy               | -0.965      |
|    entropy_loss          | -0.966      |
|    explained_variance    | 0.68        |
|    lagrangian_multiplier | 0.00332     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.92        |
|    n_updates             | 6840        |
|    policy_gradient_loss  | -0.00349    |
|    std                   | 0.466       |
|    value_loss            | 9.38        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.32407638 |
| rollout/                 |             |
|    ep_len_mean           | 136         |
|    ep_rew_mean           | -48.7       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 49          |
|    time_elapsed          | 1424        |
|    total_timesteps       | 1404928     |
| train/                   |             |
|    approx_kl             | 0.015191197 |
|    clip_fraction         | 0.204       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.6         |
|    cost_value_loss       | 12.6        |
|    cost_values           | 2.69        |
|    entropy               | -0.957      |
|    entropy_loss          | -0.961      |
|    explained_variance    | 0.612       |
|    lagrangian_multiplier | 0.00458     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.17        |
|    n_updates             | 6850        |
|    policy_gradient_loss  | -0.000232   |
|    std                   | 0.464       |
|    value_loss            | 8.6         |
------------------------------------------
------------------------------------
| avg_speed          | 8           |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8           |
| reward             | -0.22710665 |
| rollout/           |             |
|    ep_len_mean     | 139         |
|    ep_rew_mean     | -49.6       |
| time/              |             |
|    fps             | 76          |
|    iterations      | 1           |
|    time_elapsed    | 26          |
|    total_timesteps | 1406976     |
------------------------------------
------------------------------------------
| avg_speed                | 7.79        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.79        |
| reward                   | -0.40707672 |
| rollout/                 |             |
|    ep_len_mean           | 137         |
|    ep_rew_mean           | -49         |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 2           |
|    time_elapsed          | 56          |
|    total_timesteps       | 1409024     |
| train/                   |             |
|    approx_kl             | 0.009594098 |
|    clip_fraction         | 0.126       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.38        |
|    cost_value_loss       | 12.4        |
|    cost_values           | 2.63        |
|    entropy               | -0.954      |
|    entropy_loss          | -0.955      |
|    explained_variance    | 0.596       |
|    lagrangian_multiplier | 0.00464     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.49        |
|    n_updates             | 6870        |
|    policy_gradient_loss  | -0.00133    |
|    std                   | 0.465       |
|    value_loss            | 11.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.06        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.06        |
| reward                   | -0.24839775 |
| rollout/                 |             |
|    ep_len_mean           | 140         |
|    ep_rew_mean           | -50.1       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 3           |
|    time_elapsed          | 85          |
|    total_timesteps       | 1411072     |
| train/                   |             |
|    approx_kl             | 0.010178393 |
|    clip_fraction         | 0.122       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.9         |
|    cost_value_loss       | 9.93        |
|    cost_values           | 2.54        |
|    entropy               | -0.953      |
|    entropy_loss          | -0.954      |
|    explained_variance    | 0.654       |
|    lagrangian_multiplier | 0.00209     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.11        |
|    n_updates             | 6880        |
|    policy_gradient_loss  | -0.00131    |
|    std                   | 0.465       |
|    value_loss            | 11.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.32844517 |
| rollout/                 |             |
|    ep_len_mean           | 140         |
|    ep_rew_mean           | -50.3       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 4           |
|    time_elapsed          | 114         |
|    total_timesteps       | 1413120     |
| train/                   |             |
|    approx_kl             | 0.011644004 |
|    clip_fraction         | 0.0947      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.2         |
|    cost_value_loss       | 11.9        |
|    cost_values           | 2.5         |
|    entropy               | -0.946      |
|    entropy_loss          | -0.95       |
|    explained_variance    | 0.649       |
|    lagrangian_multiplier | 0.00136     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.83        |
|    n_updates             | 6890        |
|    policy_gradient_loss  | -0.00432    |
|    std                   | 0.463       |
|    value_loss            | 10.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.9         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.9         |
| reward                   | -0.2956182  |
| rollout/                 |             |
|    ep_len_mean           | 143         |
|    ep_rew_mean           | -51.4       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 5           |
|    time_elapsed          | 143         |
|    total_timesteps       | 1415168     |
| train/                   |             |
|    approx_kl             | 0.009993509 |
|    clip_fraction         | 0.0866      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.47        |
|    cost_value_loss       | 12.9        |
|    cost_values           | 2.57        |
|    entropy               | -0.94       |
|    entropy_loss          | -0.943      |
|    explained_variance    | 0.617       |
|    lagrangian_multiplier | 0.00282     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.84        |
|    n_updates             | 6900        |
|    policy_gradient_loss  | -0.00116    |
|    std                   | 0.462       |
|    value_loss            | 10.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.6          |
| cost                     | 0            |
| is_success               | 1            |
| max_speed                | 6.6          |
| reward                   | -0.093899325 |
| rollout/                 |              |
|    ep_len_mean           | 141          |
|    ep_rew_mean           | -50.7        |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 6            |
|    time_elapsed          | 172          |
|    total_timesteps       | 1417216      |
| train/                   |              |
|    approx_kl             | 0.0072279344 |
|    clip_fraction         | 0.0994       |
|    clip_range            | 0.2          |
|    cost_returns          | 5.03         |
|    cost_value_loss       | 10.2         |
|    cost_values           | 2.61         |
|    entropy               | -0.943       |
|    entropy_loss          | -0.941       |
|    explained_variance    | 0.595        |
|    lagrangian_multiplier | 0.00199      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.93         |
|    n_updates             | 6910         |
|    policy_gradient_loss  | -0.00133     |
|    std                   | 0.463        |
|    value_loss            | 10           |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.96        |
| reward                   | -0.28989017 |
| rollout/                 |             |
|    ep_len_mean           | 132         |
|    ep_rew_mean           | -48.4       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 7           |
|    time_elapsed          | 200         |
|    total_timesteps       | 1419264     |
| train/                   |             |
|    approx_kl             | 0.010524581 |
|    clip_fraction         | 0.139       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.6         |
|    cost_value_loss       | 12.7        |
|    cost_values           | 2.65        |
|    entropy               | -0.937      |
|    entropy_loss          | -0.942      |
|    explained_variance    | 0.59        |
|    lagrangian_multiplier | 0.00302     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.23        |
|    n_updates             | 6920        |
|    policy_gradient_loss  | -0.0021     |
|    std                   | 0.461       |
|    value_loss            | 11.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.8         |
| reward                   | -0.30193174 |
| rollout/                 |             |
|    ep_len_mean           | 134         |
|    ep_rew_mean           | -49.1       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 8           |
|    time_elapsed          | 230         |
|    total_timesteps       | 1421312     |
| train/                   |             |
|    approx_kl             | 0.009317165 |
|    clip_fraction         | 0.113       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.04        |
|    cost_value_loss       | 9.78        |
|    cost_values           | 2.65        |
|    entropy               | -0.934      |
|    entropy_loss          | -0.934      |
|    explained_variance    | 0.705       |
|    lagrangian_multiplier | 0.0023      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.12        |
|    n_updates             | 6930        |
|    policy_gradient_loss  | -0.00493    |
|    std                   | 0.461       |
|    value_loss            | 11.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.32669505 |
| rollout/                 |             |
|    ep_len_mean           | 137         |
|    ep_rew_mean           | -49.6       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 9           |
|    time_elapsed          | 258         |
|    total_timesteps       | 1423360     |
| train/                   |             |
|    approx_kl             | 0.0341839   |
|    clip_fraction         | 0.157       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.71        |
|    cost_value_loss       | 14          |
|    cost_values           | 2.63        |
|    entropy               | -0.929      |
|    entropy_loss          | -0.932      |
|    explained_variance    | 0.617       |
|    lagrangian_multiplier | 0.00371     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.16        |
|    n_updates             | 6940        |
|    policy_gradient_loss  | -0.000692   |
|    std                   | 0.46        |
|    value_loss            | 11.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.8         |
| reward                   | -0.62044585 |
| rollout/                 |             |
|    ep_len_mean           | 131         |
|    ep_rew_mean           | -47.7       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 10          |
|    time_elapsed          | 287         |
|    total_timesteps       | 1425408     |
| train/                   |             |
|    approx_kl             | 0.013183175 |
|    clip_fraction         | 0.177       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.59        |
|    cost_value_loss       | 8.16        |
|    cost_values           | 2.62        |
|    entropy               | -0.925      |
|    entropy_loss          | -0.928      |
|    explained_variance    | 0.669       |
|    lagrangian_multiplier | 0.00152     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.92        |
|    n_updates             | 6950        |
|    policy_gradient_loss  | 0.00287     |
|    std                   | 0.459       |
|    value_loss            | 10.2        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.2965576 |
| rollout/                 |            |
|    ep_len_mean           | 140        |
|    ep_rew_mean           | -49.9      |
| time/                    |            |
|    fps                   | 71         |
|    iterations            | 11         |
|    time_elapsed          | 316        |
|    total_timesteps       | 1427456    |
| train/                   |            |
|    approx_kl             | 0.00628769 |
|    clip_fraction         | 0.101      |
|    clip_range            | 0.2        |
|    cost_returns          | 5.43       |
|    cost_value_loss       | 12.7       |
|    cost_values           | 2.6        |
|    entropy               | -0.921     |
|    entropy_loss          | -0.923     |
|    explained_variance    | 0.668      |
|    lagrangian_multiplier | 0.00251    |
|    learning_rate         | 0.0003     |
|    loss                  | 6.1        |
|    n_updates             | 6960       |
|    policy_gradient_loss  | -0.000894  |
|    std                   | 0.46       |
|    value_loss            | 9.71       |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.18        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.18        |
| reward                   | -0.31926394 |
| rollout/                 |             |
|    ep_len_mean           | 131         |
|    ep_rew_mean           | -47.7       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 12          |
|    time_elapsed          | 345         |
|    total_timesteps       | 1429504     |
| train/                   |             |
|    approx_kl             | 0.008677371 |
|    clip_fraction         | 0.106       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.22        |
|    cost_value_loss       | 11.5        |
|    cost_values           | 2.64        |
|    entropy               | -0.917      |
|    entropy_loss          | -0.919      |
|    explained_variance    | 0.686       |
|    lagrangian_multiplier | 0.00122     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.09        |
|    n_updates             | 6970        |
|    policy_gradient_loss  | -0.00434    |
|    std                   | 0.46        |
|    value_loss            | 7.34        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.29481462 |
| rollout/                 |             |
|    ep_len_mean           | 129         |
|    ep_rew_mean           | -47.5       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 13          |
|    time_elapsed          | 374         |
|    total_timesteps       | 1431552     |
| train/                   |             |
|    approx_kl             | 0.011224544 |
|    clip_fraction         | 0.108       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.66        |
|    cost_value_loss       | 13.5        |
|    cost_values           | 2.69        |
|    entropy               | -0.911      |
|    entropy_loss          | -0.914      |
|    explained_variance    | 0.695       |
|    lagrangian_multiplier | 0.00288     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.74        |
|    n_updates             | 6980        |
|    policy_gradient_loss  | -0.00231    |
|    std                   | 0.459       |
|    value_loss            | 11.6        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8.03       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8.03       |
| reward                   | -0.3227427 |
| rollout/                 |            |
|    ep_len_mean           | 130        |
|    ep_rew_mean           | -47.4      |
| time/                    |            |
|    fps                   | 70         |
|    iterations            | 14         |
|    time_elapsed          | 404        |
|    total_timesteps       | 1433600    |
| train/                   |            |
|    approx_kl             | 0.01223201 |
|    clip_fraction         | 0.166      |
|    clip_range            | 0.2        |
|    cost_returns          | 5.32       |
|    cost_value_loss       | 11.7       |
|    cost_values           | 2.67       |
|    entropy               | -0.902     |
|    entropy_loss          | -0.907     |
|    explained_variance    | 0.68       |
|    lagrangian_multiplier | 0.00212    |
|    learning_rate         | 0.0003     |
|    loss                  | 7.15       |
|    n_updates             | 6990       |
|    policy_gradient_loss  | 0.00388    |
|    std                   | 0.457      |
|    value_loss            | 11.4       |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.03        |
| reward                   | -0.21780826 |
| rollout/                 |             |
|    ep_len_mean           | 127         |
|    ep_rew_mean           | -46.8       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 15          |
|    time_elapsed          | 433         |
|    total_timesteps       | 1435648     |
| train/                   |             |
|    approx_kl             | 0.0096505   |
|    clip_fraction         | 0.0917      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.41        |
|    cost_value_loss       | 11.6        |
|    cost_values           | 2.65        |
|    entropy               | -0.907      |
|    entropy_loss          | -0.903      |
|    explained_variance    | 0.678       |
|    lagrangian_multiplier | 0.00286     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.09        |
|    n_updates             | 7000        |
|    policy_gradient_loss  | -0.00228    |
|    std                   | 0.46        |
|    value_loss            | 10.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.78874034 |
| rollout/                 |             |
|    ep_len_mean           | 125         |
|    ep_rew_mean           | -46.6       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 16          |
|    time_elapsed          | 462         |
|    total_timesteps       | 1437696     |
| train/                   |             |
|    approx_kl             | 0.021166902 |
|    clip_fraction         | 0.135       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.72        |
|    cost_value_loss       | 8.42        |
|    cost_values           | 2.61        |
|    entropy               | -0.902      |
|    entropy_loss          | -0.906      |
|    explained_variance    | 0.666       |
|    lagrangian_multiplier | 0.00154     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.83        |
|    n_updates             | 7010        |
|    policy_gradient_loss  | 0.000916    |
|    std                   | 0.46        |
|    value_loss            | 10.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.6202377  |
| rollout/                 |             |
|    ep_len_mean           | 116         |
|    ep_rew_mean           | -44.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 17          |
|    time_elapsed          | 491         |
|    total_timesteps       | 1439744     |
| train/                   |             |
|    approx_kl             | 0.011171408 |
|    clip_fraction         | 0.181       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.37        |
|    cost_value_loss       | 12.1        |
|    cost_values           | 2.6         |
|    entropy               | -0.893      |
|    entropy_loss          | -0.897      |
|    explained_variance    | 0.609       |
|    lagrangian_multiplier | 0.00271     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.94        |
|    n_updates             | 7020        |
|    policy_gradient_loss  | -0.000407   |
|    std                   | 0.459       |
|    value_loss            | 10.4        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.97         |
| cost                     | 0            |
| is_success               | 1            |
| max_speed                | 6.97         |
| reward                   | -0.11137939  |
| rollout/                 |              |
|    ep_len_mean           | 119          |
|    ep_rew_mean           | -45.2        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 18           |
|    time_elapsed          | 520          |
|    total_timesteps       | 1441792      |
| train/                   |              |
|    approx_kl             | 0.0112987505 |
|    clip_fraction         | 0.115        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.81         |
|    cost_value_loss       | 9.5          |
|    cost_values           | 2.59         |
|    entropy               | -0.889       |
|    entropy_loss          | -0.891       |
|    explained_variance    | 0.693        |
|    lagrangian_multiplier | 0.00275      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.34         |
|    n_updates             | 7030         |
|    policy_gradient_loss  | -0.00431     |
|    std                   | 0.458        |
|    value_loss            | 10.1         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.81060624 |
| rollout/                 |             |
|    ep_len_mean           | 117         |
|    ep_rew_mean           | -44.8       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 19          |
|    time_elapsed          | 549         |
|    total_timesteps       | 1443840     |
| train/                   |             |
|    approx_kl             | 0.008334364 |
|    clip_fraction         | 0.104       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.75        |
|    cost_value_loss       | 8.8         |
|    cost_values           | 2.54        |
|    entropy               | -0.886      |
|    entropy_loss          | -0.888      |
|    explained_variance    | 0.609       |
|    lagrangian_multiplier | 0.00151     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.64        |
|    n_updates             | 7040        |
|    policy_gradient_loss  | -0.00174    |
|    std                   | 0.456       |
|    value_loss            | 11          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.17647514  |
| rollout/                 |              |
|    ep_len_mean           | 115          |
|    ep_rew_mean           | -44.3        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 20           |
|    time_elapsed          | 578          |
|    total_timesteps       | 1445888      |
| train/                   |              |
|    approx_kl             | 0.0073805796 |
|    clip_fraction         | 0.085        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.75         |
|    cost_value_loss       | 8.74         |
|    cost_values           | 2.55         |
|    entropy               | -0.885       |
|    entropy_loss          | -0.885       |
|    explained_variance    | 0.716        |
|    lagrangian_multiplier | 0.000394     |
|    learning_rate         | 0.0003       |
|    loss                  | 8.26         |
|    n_updates             | 7050         |
|    policy_gradient_loss  | -0.00287     |
|    std                   | 0.457        |
|    value_loss            | 9.81         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.82        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.82        |
| reward                   | -0.31917495 |
| rollout/                 |             |
|    ep_len_mean           | 115         |
|    ep_rew_mean           | -44.4       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 21          |
|    time_elapsed          | 607         |
|    total_timesteps       | 1447936     |
| train/                   |             |
|    approx_kl             | 0.02013004  |
|    clip_fraction         | 0.106       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.56        |
|    cost_value_loss       | 13.1        |
|    cost_values           | 2.63        |
|    entropy               | -0.88       |
|    entropy_loss          | -0.882      |
|    explained_variance    | 0.74        |
|    lagrangian_multiplier | 0.00473     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.98        |
|    n_updates             | 7060        |
|    policy_gradient_loss  | 0.000782    |
|    std                   | 0.456       |
|    value_loss            | 8.57        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.41        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.41        |
| reward                   | -0.2984053  |
| rollout/                 |             |
|    ep_len_mean           | 115         |
|    ep_rew_mean           | -44.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 22          |
|    time_elapsed          | 636         |
|    total_timesteps       | 1449984     |
| train/                   |             |
|    approx_kl             | 0.015408037 |
|    clip_fraction         | 0.207       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.21        |
|    cost_value_loss       | 11.8        |
|    cost_values           | 2.6         |
|    entropy               | -0.88       |
|    entropy_loss          | -0.879      |
|    explained_variance    | 0.712       |
|    lagrangian_multiplier | 0.00279     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.94        |
|    n_updates             | 7070        |
|    policy_gradient_loss  | 0.00905     |
|    std                   | 0.457       |
|    value_loss            | 9.44        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.67        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.67        |
| reward                   | -0.17701572 |
| rollout/                 |             |
|    ep_len_mean           | 121         |
|    ep_rew_mean           | -45.3       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 23          |
|    time_elapsed          | 665         |
|    total_timesteps       | 1452032     |
| train/                   |             |
|    approx_kl             | 0.01739795  |
|    clip_fraction         | 0.171       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.12        |
|    cost_value_loss       | 10.2        |
|    cost_values           | 2.59        |
|    entropy               | -0.879      |
|    entropy_loss          | -0.879      |
|    explained_variance    | 0.656       |
|    lagrangian_multiplier | 0.00238     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.09        |
|    n_updates             | 7080        |
|    policy_gradient_loss  | 0.00298     |
|    std                   | 0.457       |
|    value_loss            | 9.86        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.230271   |
| rollout/                 |             |
|    ep_len_mean           | 119         |
|    ep_rew_mean           | -44.8       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 24          |
|    time_elapsed          | 694         |
|    total_timesteps       | 1454080     |
| train/                   |             |
|    approx_kl             | 0.028539011 |
|    clip_fraction         | 0.163       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.23        |
|    cost_value_loss       | 11          |
|    cost_values           | 2.61        |
|    entropy               | -0.863      |
|    entropy_loss          | -0.872      |
|    explained_variance    | 0.708       |
|    lagrangian_multiplier | 0.00266     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.5         |
|    n_updates             | 7090        |
|    policy_gradient_loss  | 0.000483    |
|    std                   | 0.453       |
|    value_loss            | 8.1         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.28435436 |
| rollout/                 |             |
|    ep_len_mean           | 123         |
|    ep_rew_mean           | -45.8       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 25          |
|    time_elapsed          | 723         |
|    total_timesteps       | 1456128     |
| train/                   |             |
|    approx_kl             | 0.007665511 |
|    clip_fraction         | 0.107       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.26        |
|    cost_value_loss       | 10.8        |
|    cost_values           | 2.62        |
|    entropy               | -0.86       |
|    entropy_loss          | -0.861      |
|    explained_variance    | 0.697       |
|    lagrangian_multiplier | 0.00236     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.81        |
|    n_updates             | 7100        |
|    policy_gradient_loss  | 0.000147    |
|    std                   | 0.452       |
|    value_loss            | 9.41        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.2585242  |
| rollout/                 |             |
|    ep_len_mean           | 125         |
|    ep_rew_mean           | -46         |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 26          |
|    time_elapsed          | 752         |
|    total_timesteps       | 1458176     |
| train/                   |             |
|    approx_kl             | 0.014936496 |
|    clip_fraction         | 0.124       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.1         |
|    cost_value_loss       | 10.2        |
|    cost_values           | 2.62        |
|    entropy               | -0.846      |
|    entropy_loss          | -0.854      |
|    explained_variance    | 0.642       |
|    lagrangian_multiplier | 0.00267     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.34        |
|    n_updates             | 7110        |
|    policy_gradient_loss  | -0.00249    |
|    std                   | 0.449       |
|    value_loss            | 8.1         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.7698526  |
| rollout/                 |             |
|    ep_len_mean           | 129         |
|    ep_rew_mean           | -47.2       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 27          |
|    time_elapsed          | 781         |
|    total_timesteps       | 1460224     |
| train/                   |             |
|    approx_kl             | 0.016837731 |
|    clip_fraction         | 0.162       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.54        |
|    cost_value_loss       | 13.1        |
|    cost_values           | 2.62        |
|    entropy               | -0.838      |
|    entropy_loss          | -0.841      |
|    explained_variance    | 0.605       |
|    lagrangian_multiplier | 0.00333     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.19        |
|    n_updates             | 7120        |
|    policy_gradient_loss  | 0.00282     |
|    std                   | 0.448       |
|    value_loss            | 10.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.28218108 |
| rollout/                 |             |
|    ep_len_mean           | 134         |
|    ep_rew_mean           | -48.6       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 28          |
|    time_elapsed          | 810         |
|    total_timesteps       | 1462272     |
| train/                   |             |
|    approx_kl             | 0.010465525 |
|    clip_fraction         | 0.11        |
|    clip_range            | 0.2         |
|    cost_returns          | 5.77        |
|    cost_value_loss       | 14.1        |
|    cost_values           | 2.68        |
|    entropy               | -0.839      |
|    entropy_loss          | -0.838      |
|    explained_variance    | 0.626       |
|    lagrangian_multiplier | 0.00302     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.2         |
|    n_updates             | 7130        |
|    policy_gradient_loss  | -0.00221    |
|    std                   | 0.448       |
|    value_loss            | 8.94        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.3635412  |
| rollout/                 |             |
|    ep_len_mean           | 140         |
|    ep_rew_mean           | -50.4       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 29          |
|    time_elapsed          | 839         |
|    total_timesteps       | 1464320     |
| train/                   |             |
|    approx_kl             | 0.011982961 |
|    clip_fraction         | 0.161       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.65        |
|    cost_value_loss       | 13          |
|    cost_values           | 2.69        |
|    entropy               | -0.832      |
|    entropy_loss          | -0.837      |
|    explained_variance    | 0.666       |
|    lagrangian_multiplier | 0.0041      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.25        |
|    n_updates             | 7140        |
|    policy_gradient_loss  | -0.000947   |
|    std                   | 0.447       |
|    value_loss            | 8.42        |
------------------------------------------
-----------------------------------------
| avg_speed                | 6.6        |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 6.6        |
| reward                   | -0.3815396 |
| rollout/                 |            |
|    ep_len_mean           | 143        |
|    ep_rew_mean           | -51.4      |
| time/                    |            |
|    fps                   | 70         |
|    iterations            | 30         |
|    time_elapsed          | 869        |
|    total_timesteps       | 1466368    |
| train/                   |            |
|    approx_kl             | 0.02011283 |
|    clip_fraction         | 0.167      |
|    clip_range            | 0.2        |
|    cost_returns          | 5.75       |
|    cost_value_loss       | 12.7       |
|    cost_values           | 2.68       |
|    entropy               | -0.831     |
|    entropy_loss          | -0.83      |
|    explained_variance    | 0.577      |
|    lagrangian_multiplier | 0.00249    |
|    learning_rate         | 0.0003     |
|    loss                  | 6.15       |
|    n_updates             | 7150       |
|    policy_gradient_loss  | -0.000243  |
|    std                   | 0.447      |
|    value_loss            | 9.81       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.24478944 |
| rollout/                 |             |
|    ep_len_mean           | 147         |
|    ep_rew_mean           | -52.4       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 31          |
|    time_elapsed          | 898         |
|    total_timesteps       | 1468416     |
| train/                   |             |
|    approx_kl             | 0.009513786 |
|    clip_fraction         | 0.108       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.7         |
|    cost_value_loss       | 13.2        |
|    cost_values           | 2.66        |
|    entropy               | -0.829      |
|    entropy_loss          | -0.831      |
|    explained_variance    | 0.591       |
|    lagrangian_multiplier | 0.00325     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.25        |
|    n_updates             | 7160        |
|    policy_gradient_loss  | 0.00187     |
|    std                   | 0.447       |
|    value_loss            | 11.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.22128761 |
| rollout/                 |             |
|    ep_len_mean           | 153         |
|    ep_rew_mean           | -53.6       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 32          |
|    time_elapsed          | 927         |
|    total_timesteps       | 1470464     |
| train/                   |             |
|    approx_kl             | 0.020953937 |
|    clip_fraction         | 0.117       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.21        |
|    cost_value_loss       | 10.4        |
|    cost_values           | 2.59        |
|    entropy               | -0.823      |
|    entropy_loss          | -0.827      |
|    explained_variance    | 0.61        |
|    lagrangian_multiplier | 0.00206     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.31        |
|    n_updates             | 7170        |
|    policy_gradient_loss  | -0.00412    |
|    std                   | 0.446       |
|    value_loss            | 11.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.40208372 |
| rollout/                 |             |
|    ep_len_mean           | 156         |
|    ep_rew_mean           | -54.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 33          |
|    time_elapsed          | 956         |
|    total_timesteps       | 1472512     |
| train/                   |             |
|    approx_kl             | 0.005724993 |
|    clip_fraction         | 0.124       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.91        |
|    cost_value_loss       | 15.1        |
|    cost_values           | 2.61        |
|    entropy               | -0.821      |
|    entropy_loss          | -0.822      |
|    explained_variance    | 0.57        |
|    lagrangian_multiplier | 0.00319     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.88        |
|    n_updates             | 7180        |
|    policy_gradient_loss  | -0.00171    |
|    std                   | 0.446       |
|    value_loss            | 8.54        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.93         |
| reward                   | -0.32975236  |
| rollout/                 |              |
|    ep_len_mean           | 159          |
|    ep_rew_mean           | -55.1        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 34           |
|    time_elapsed          | 985          |
|    total_timesteps       | 1474560      |
| train/                   |              |
|    approx_kl             | 0.0068819923 |
|    clip_fraction         | 0.144        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.65         |
|    cost_value_loss       | 14.1         |
|    cost_values           | 2.61         |
|    entropy               | -0.809       |
|    entropy_loss          | -0.815       |
|    explained_variance    | 0.614        |
|    lagrangian_multiplier | 0.00183      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.12         |
|    n_updates             | 7190         |
|    policy_gradient_loss  | -0.00472     |
|    std                   | 0.442        |
|    value_loss            | 9.52         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.26570404 |
| rollout/                 |             |
|    ep_len_mean           | 153         |
|    ep_rew_mean           | -53.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 35          |
|    time_elapsed          | 1015        |
|    total_timesteps       | 1476608     |
| train/                   |             |
|    approx_kl             | 0.015425934 |
|    clip_fraction         | 0.15        |
|    clip_range            | 0.2         |
|    cost_returns          | 5.66        |
|    cost_value_loss       | 13.3        |
|    cost_values           | 2.63        |
|    entropy               | -0.805      |
|    entropy_loss          | -0.806      |
|    explained_variance    | 0.626       |
|    lagrangian_multiplier | 0.00311     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.75        |
|    n_updates             | 7200        |
|    policy_gradient_loss  | -0.000852   |
|    std                   | 0.441       |
|    value_loss            | 9.5         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.33830947 |
| rollout/                 |             |
|    ep_len_mean           | 150         |
|    ep_rew_mean           | -52.4       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 36          |
|    time_elapsed          | 1044        |
|    total_timesteps       | 1478656     |
| train/                   |             |
|    approx_kl             | 0.009797294 |
|    clip_fraction         | 0.141       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.43        |
|    cost_value_loss       | 11.4        |
|    cost_values           | 2.66        |
|    entropy               | -0.802      |
|    entropy_loss          | -0.804      |
|    explained_variance    | 0.633       |
|    lagrangian_multiplier | 0.00304     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.11        |
|    n_updates             | 7210        |
|    policy_gradient_loss  | -0.000539   |
|    std                   | 0.44        |
|    value_loss            | 12.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.79619116 |
| rollout/                 |             |
|    ep_len_mean           | 159         |
|    ep_rew_mean           | -54.8       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 37          |
|    time_elapsed          | 1073        |
|    total_timesteps       | 1480704     |
| train/                   |             |
|    approx_kl             | 0.014485865 |
|    clip_fraction         | 0.17        |
|    clip_range            | 0.2         |
|    cost_returns          | 5.39        |
|    cost_value_loss       | 11          |
|    cost_values           | 2.67        |
|    entropy               | -0.811      |
|    entropy_loss          | -0.805      |
|    explained_variance    | 0.633       |
|    lagrangian_multiplier | 0.00259     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.89        |
|    n_updates             | 7220        |
|    policy_gradient_loss  | 0.00202     |
|    std                   | 0.442       |
|    value_loss            | 8.51        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.74        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.74        |
| reward                   | -0.16660818 |
| rollout/                 |             |
|    ep_len_mean           | 153         |
|    ep_rew_mean           | -52.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 38          |
|    time_elapsed          | 1101        |
|    total_timesteps       | 1482752     |
| train/                   |             |
|    approx_kl             | 0.01878744  |
|    clip_fraction         | 0.132       |
|    clip_range            | 0.2         |
|    cost_returns          | 6.25        |
|    cost_value_loss       | 15.8        |
|    cost_values           | 2.73        |
|    entropy               | -0.809      |
|    entropy_loss          | -0.811      |
|    explained_variance    | 0.587       |
|    lagrangian_multiplier | 0.0051      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.99        |
|    n_updates             | 7230        |
|    policy_gradient_loss  | -0.00384    |
|    std                   | 0.442       |
|    value_loss            | 7.43        |
------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.77493626 |
| rollout/                 |             |
|    ep_len_mean           | 144         |
|    ep_rew_mean           | -50.4       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 39          |
|    time_elapsed          | 1130        |
|    total_timesteps       | 1484800     |
| train/                   |             |
|    approx_kl             | 0.014282992 |
|    clip_fraction         | 0.117       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.46        |
|    cost_value_loss       | 12.7        |
|    cost_values           | 2.72        |
|    entropy               | -0.806      |
|    entropy_loss          | -0.808      |
|    explained_variance    | 0.624       |
|    lagrangian_multiplier | 0.0051      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.52        |
|    n_updates             | 7240        |
|    policy_gradient_loss  | -0.000669   |
|    std                   | 0.442       |
|    value_loss            | 12.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.20059882  |
| rollout/                 |              |
|    ep_len_mean           | 142          |
|    ep_rew_mean           | -50.1        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 40           |
|    time_elapsed          | 1159         |
|    total_timesteps       | 1486848      |
| train/                   |              |
|    approx_kl             | 0.0047734864 |
|    clip_fraction         | 0.137        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.35         |
|    cost_value_loss       | 11.4         |
|    cost_values           | 2.62         |
|    entropy               | -0.807       |
|    entropy_loss          | -0.806       |
|    explained_variance    | 0.602        |
|    lagrangian_multiplier | 0.00234      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.65         |
|    n_updates             | 7250         |
|    policy_gradient_loss  | 0.00156      |
|    std                   | 0.443        |
|    value_loss            | 10.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.21789941 |
| rollout/                 |             |
|    ep_len_mean           | 136         |
|    ep_rew_mean           | -48.6       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 41          |
|    time_elapsed          | 1188        |
|    total_timesteps       | 1488896     |
| train/                   |             |
|    approx_kl             | 0.017393373 |
|    clip_fraction         | 0.161       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.92        |
|    cost_value_loss       | 9.31        |
|    cost_values           | 2.58        |
|    entropy               | -0.803      |
|    entropy_loss          | -0.805      |
|    explained_variance    | 0.665       |
|    lagrangian_multiplier | 0.00242     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.34        |
|    n_updates             | 7260        |
|    policy_gradient_loss  | -0.00036    |
|    std                   | 0.443       |
|    value_loss            | 9.51        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.35244507 |
| rollout/                 |             |
|    ep_len_mean           | 141         |
|    ep_rew_mean           | -50.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 42          |
|    time_elapsed          | 1217        |
|    total_timesteps       | 1490944     |
| train/                   |             |
|    approx_kl             | 0.009248201 |
|    clip_fraction         | 0.143       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.46        |
|    cost_value_loss       | 12.8        |
|    cost_values           | 2.61        |
|    entropy               | -0.799      |
|    entropy_loss          | -0.801      |
|    explained_variance    | 0.661       |
|    lagrangian_multiplier | 0.00228     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.67        |
|    n_updates             | 7270        |
|    policy_gradient_loss  | 0.000528    |
|    std                   | 0.442       |
|    value_loss            | 11.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.23397814 |
| rollout/                 |             |
|    ep_len_mean           | 140         |
|    ep_rew_mean           | -50         |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 43          |
|    time_elapsed          | 1246        |
|    total_timesteps       | 1492992     |
| train/                   |             |
|    approx_kl             | 0.02042869  |
|    clip_fraction         | 0.14        |
|    clip_range            | 0.2         |
|    cost_returns          | 5.46        |
|    cost_value_loss       | 11.5        |
|    cost_values           | 2.67        |
|    entropy               | -0.801      |
|    entropy_loss          | -0.798      |
|    explained_variance    | 0.678       |
|    lagrangian_multiplier | 0.00391     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.9         |
|    n_updates             | 7280        |
|    policy_gradient_loss  | -0.00172    |
|    std                   | 0.443       |
|    value_loss            | 8.6         |
------------------------------------------
------------------------------------------
| avg_speed                | 3.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.8         |
| reward                   | -0.64942455 |
| rollout/                 |             |
|    ep_len_mean           | 142         |
|    ep_rew_mean           | -50.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 44          |
|    time_elapsed          | 1276        |
|    total_timesteps       | 1495040     |
| train/                   |             |
|    approx_kl             | 0.011427382 |
|    clip_fraction         | 0.159       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.32        |
|    cost_value_loss       | 10.5        |
|    cost_values           | 2.68        |
|    entropy               | -0.796      |
|    entropy_loss          | -0.8        |
|    explained_variance    | 0.599       |
|    lagrangian_multiplier | 0.00413     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.01        |
|    n_updates             | 7290        |
|    policy_gradient_loss  | 0.00273     |
|    std                   | 0.442       |
|    value_loss            | 10.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.38519    |
| rollout/                 |             |
|    ep_len_mean           | 144         |
|    ep_rew_mean           | -51.2       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 45          |
|    time_elapsed          | 1305        |
|    total_timesteps       | 1497088     |
| train/                   |             |
|    approx_kl             | 0.010057511 |
|    clip_fraction         | 0.125       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.68        |
|    cost_value_loss       | 12.8        |
|    cost_values           | 2.72        |
|    entropy               | -0.786      |
|    entropy_loss          | -0.79       |
|    explained_variance    | 0.631       |
|    lagrangian_multiplier | 0.00245     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.71        |
|    n_updates             | 7300        |
|    policy_gradient_loss  | -0.00149    |
|    std                   | 0.439       |
|    value_loss            | 6.74        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.25512728 |
| rollout/                 |             |
|    ep_len_mean           | 140         |
|    ep_rew_mean           | -50.3       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 46          |
|    time_elapsed          | 1335        |
|    total_timesteps       | 1499136     |
| train/                   |             |
|    approx_kl             | 0.010726608 |
|    clip_fraction         | 0.141       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.61        |
|    cost_value_loss       | 12.5        |
|    cost_values           | 2.74        |
|    entropy               | -0.79       |
|    entropy_loss          | -0.787      |
|    explained_variance    | 0.657       |
|    lagrangian_multiplier | 0.0047      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.29        |
|    n_updates             | 7310        |
|    policy_gradient_loss  | -0.00407    |
|    std                   | 0.439       |
|    value_loss            | 10.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3009795  |
| rollout/                 |             |
|    ep_len_mean           | 133         |
|    ep_rew_mean           | -48.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 47          |
|    time_elapsed          | 1364        |
|    total_timesteps       | 1501184     |
| train/                   |             |
|    approx_kl             | 0.015047237 |
|    clip_fraction         | 0.151       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.09        |
|    cost_value_loss       | 10.4        |
|    cost_values           | 2.63        |
|    entropy               | -0.791      |
|    entropy_loss          | -0.79       |
|    explained_variance    | 0.703       |
|    lagrangian_multiplier | 0.00232     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.77        |
|    n_updates             | 7320        |
|    policy_gradient_loss  | -0.00207    |
|    std                   | 0.438       |
|    value_loss            | 10.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.29472798 |
| rollout/                 |             |
|    ep_len_mean           | 130         |
|    ep_rew_mean           | -47.2       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 48          |
|    time_elapsed          | 1393        |
|    total_timesteps       | 1503232     |
| train/                   |             |
|    approx_kl             | 0.032496065 |
|    clip_fraction         | 0.121       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.84        |
|    cost_value_loss       | 9.82        |
|    cost_values           | 2.62        |
|    entropy               | -0.783      |
|    entropy_loss          | -0.788      |
|    explained_variance    | 0.695       |
|    lagrangian_multiplier | 0.00248     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.21        |
|    n_updates             | 7330        |
|    policy_gradient_loss  | -0.000938   |
|    std                   | 0.437       |
|    value_loss            | 12.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.20593177 |
| rollout/                 |             |
|    ep_len_mean           | 124         |
|    ep_rew_mean           | -45.9       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 49          |
|    time_elapsed          | 1422        |
|    total_timesteps       | 1505280     |
| train/                   |             |
|    approx_kl             | 0.029896662 |
|    clip_fraction         | 0.19        |
|    clip_range            | 0.2         |
|    cost_returns          | 5.1         |
|    cost_value_loss       | 10          |
|    cost_values           | 2.65        |
|    entropy               | -0.779      |
|    entropy_loss          | -0.781      |
|    explained_variance    | 0.681       |
|    lagrangian_multiplier | 0.0017      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.51        |
|    n_updates             | 7340        |
|    policy_gradient_loss  | 0.00886     |
|    std                   | 0.437       |
|    value_loss            | 9.04        |
------------------------------------------
------------------------------------
| avg_speed          | 8.02        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 8.02        |
| reward             | -0.36411658 |
| rollout/           |             |
|    ep_len_mean     | 117         |
|    ep_rew_mean     | -44.1       |
| time/              |             |
|    fps             | 74          |
|    iterations      | 1           |
|    time_elapsed    | 27          |
|    total_timesteps | 1507328     |
------------------------------------
-----------------------------------------
| avg_speed                | 8.01       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8.01       |
| reward                   | -0.3831783 |
| rollout/                 |            |
|    ep_len_mean           | 118        |
|    ep_rew_mean           | -44.2      |
| time/                    |            |
|    fps                   | 71         |
|    iterations            | 2          |
|    time_elapsed          | 57         |
|    total_timesteps       | 1509376    |
| train/                   |            |
|    approx_kl             | 0.0166593  |
|    clip_fraction         | 0.169      |
|    clip_range            | 0.2        |
|    cost_returns          | 5.34       |
|    cost_value_loss       | 11.2       |
|    cost_values           | 2.67       |
|    entropy               | -0.778     |
|    entropy_loss          | -0.778     |
|    explained_variance    | 0.675      |
|    lagrangian_multiplier | 0.00371    |
|    learning_rate         | 0.0003     |
|    loss                  | 5.24       |
|    n_updates             | 7360       |
|    policy_gradient_loss  | 0.00179    |
|    std                   | 0.438      |
|    value_loss            | 8.25       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.20825076 |
| rollout/                 |             |
|    ep_len_mean           | 118         |
|    ep_rew_mean           | -44.4       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 3           |
|    time_elapsed          | 86          |
|    total_timesteps       | 1511424     |
| train/                   |             |
|    approx_kl             | 0.008854626 |
|    clip_fraction         | 0.11        |
|    clip_range            | 0.2         |
|    cost_returns          | 5.13        |
|    cost_value_loss       | 9.25        |
|    cost_values           | 2.66        |
|    entropy               | -0.77       |
|    entropy_loss          | -0.775      |
|    explained_variance    | 0.643       |
|    lagrangian_multiplier | 0.00327     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.04        |
|    n_updates             | 7370        |
|    policy_gradient_loss  | 0.000539    |
|    std                   | 0.437       |
|    value_loss            | 8.43        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.24508964 |
| rollout/                 |             |
|    ep_len_mean           | 125         |
|    ep_rew_mean           | -46.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 4           |
|    time_elapsed          | 115         |
|    total_timesteps       | 1513472     |
| train/                   |             |
|    approx_kl             | 0.008144043 |
|    clip_fraction         | 0.139       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.79        |
|    cost_value_loss       | 8.4         |
|    cost_values           | 2.59        |
|    entropy               | -0.765      |
|    entropy_loss          | -0.767      |
|    explained_variance    | 0.635       |
|    lagrangian_multiplier | 0.00272     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.76        |
|    n_updates             | 7380        |
|    policy_gradient_loss  | -0.000519   |
|    std                   | 0.435       |
|    value_loss            | 11.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3656687  |
| rollout/                 |             |
|    ep_len_mean           | 122         |
|    ep_rew_mean           | -44.9       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 5           |
|    time_elapsed          | 145         |
|    total_timesteps       | 1515520     |
| train/                   |             |
|    approx_kl             | 0.014098816 |
|    clip_fraction         | 0.135       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.85        |
|    cost_value_loss       | 9.56        |
|    cost_values           | 2.58        |
|    entropy               | -0.76       |
|    entropy_loss          | -0.761      |
|    explained_variance    | 0.586       |
|    lagrangian_multiplier | 0.00228     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.62        |
|    n_updates             | 7390        |
|    policy_gradient_loss  | -0.0012     |
|    std                   | 0.434       |
|    value_loss            | 9.31        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.6926644  |
| rollout/                 |             |
|    ep_len_mean           | 119         |
|    ep_rew_mean           | -43.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 6           |
|    time_elapsed          | 174         |
|    total_timesteps       | 1517568     |
| train/                   |             |
|    approx_kl             | 0.015310252 |
|    clip_fraction         | 0.172       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.75        |
|    cost_value_loss       | 8.64        |
|    cost_values           | 2.58        |
|    entropy               | -0.757      |
|    entropy_loss          | -0.759      |
|    explained_variance    | 0.631       |
|    lagrangian_multiplier | 0.00232     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.79        |
|    n_updates             | 7400        |
|    policy_gradient_loss  | 0.00488     |
|    std                   | 0.432       |
|    value_loss            | 11.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.59001786 |
| rollout/                 |             |
|    ep_len_mean           | 105         |
|    ep_rew_mean           | -39.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 7           |
|    time_elapsed          | 203         |
|    total_timesteps       | 1519616     |
| train/                   |             |
|    approx_kl             | 0.009943797 |
|    clip_fraction         | 0.139       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.31        |
|    cost_value_loss       | 6.91        |
|    cost_values           | 2.53        |
|    entropy               | -0.756      |
|    entropy_loss          | -0.757      |
|    explained_variance    | 0.675       |
|    lagrangian_multiplier | 0.000681    |
|    learning_rate         | 0.0003      |
|    loss                  | 7.37        |
|    n_updates             | 7410        |
|    policy_gradient_loss  | -0.00118    |
|    std                   | 0.432       |
|    value_loss            | 11.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.33948645 |
| rollout/                 |             |
|    ep_len_mean           | 103         |
|    ep_rew_mean           | -38.7       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 8           |
|    time_elapsed          | 232         |
|    total_timesteps       | 1521664     |
| train/                   |             |
|    approx_kl             | 0.006148003 |
|    clip_fraction         | 0.113       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.14        |
|    cost_value_loss       | 5.46        |
|    cost_values           | 2.51        |
|    entropy               | -0.754      |
|    entropy_loss          | -0.755      |
|    explained_variance    | 0.639       |
|    lagrangian_multiplier | 0.000804    |
|    learning_rate         | 0.0003      |
|    loss                  | 6.56        |
|    n_updates             | 7420        |
|    policy_gradient_loss  | 0.00103     |
|    std                   | 0.431       |
|    value_loss            | 10.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 1           |
| max_speed                | 8           |
| reward                   | -0.0967915  |
| rollout/                 |             |
|    ep_len_mean           | 111         |
|    ep_rew_mean           | -40.9       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 9           |
|    time_elapsed          | 261         |
|    total_timesteps       | 1523712     |
| train/                   |             |
|    approx_kl             | 0.014579112 |
|    clip_fraction         | 0.134       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.47        |
|    cost_value_loss       | 7.6         |
|    cost_values           | 2.52        |
|    entropy               | -0.75       |
|    entropy_loss          | -0.751      |
|    explained_variance    | 0.692       |
|    lagrangian_multiplier | 0.00192     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.57        |
|    n_updates             | 7430        |
|    policy_gradient_loss  | -0.00173    |
|    std                   | 0.432       |
|    value_loss            | 8.95        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.25085676 |
| rollout/                 |             |
|    ep_len_mean           | 109         |
|    ep_rew_mean           | -40.9       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 10          |
|    time_elapsed          | 290         |
|    total_timesteps       | 1525760     |
| train/                   |             |
|    approx_kl             | 0.018411092 |
|    clip_fraction         | 0.136       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.61        |
|    cost_value_loss       | 8.17        |
|    cost_values           | 2.54        |
|    entropy               | -0.745      |
|    entropy_loss          | -0.748      |
|    explained_variance    | 0.589       |
|    lagrangian_multiplier | 0.00188     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.14        |
|    n_updates             | 7440        |
|    policy_gradient_loss  | -0.00316    |
|    std                   | 0.431       |
|    value_loss            | 8.47        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.01        |
| reward                   | -0.32457742 |
| rollout/                 |             |
|    ep_len_mean           | 111         |
|    ep_rew_mean           | -42.4       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 11          |
|    time_elapsed          | 319         |
|    total_timesteps       | 1527808     |
| train/                   |             |
|    approx_kl             | 0.007428188 |
|    clip_fraction         | 0.101       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.44        |
|    cost_value_loss       | 8.62        |
|    cost_values           | 2.58        |
|    entropy               | -0.739      |
|    entropy_loss          | -0.743      |
|    explained_variance    | 0.678       |
|    lagrangian_multiplier | 0.00186     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.88        |
|    n_updates             | 7450        |
|    policy_gradient_loss  | -0.00378    |
|    std                   | 0.43        |
|    value_loss            | 10.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.6573592  |
| rollout/                 |             |
|    ep_len_mean           | 117         |
|    ep_rew_mean           | -44.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 12          |
|    time_elapsed          | 348         |
|    total_timesteps       | 1529856     |
| train/                   |             |
|    approx_kl             | 0.016893385 |
|    clip_fraction         | 0.132       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.53        |
|    cost_value_loss       | 7.03        |
|    cost_values           | 2.56        |
|    entropy               | -0.736      |
|    entropy_loss          | -0.737      |
|    explained_variance    | 0.648       |
|    lagrangian_multiplier | 0.00245     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.62        |
|    n_updates             | 7460        |
|    policy_gradient_loss  | -0.00158    |
|    std                   | 0.43        |
|    value_loss            | 11.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.8         |
| reward                   | -0.5756466  |
| rollout/                 |             |
|    ep_len_mean           | 117         |
|    ep_rew_mean           | -44.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 13          |
|    time_elapsed          | 377         |
|    total_timesteps       | 1531904     |
| train/                   |             |
|    approx_kl             | 0.008347689 |
|    clip_fraction         | 0.134       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.37        |
|    cost_value_loss       | 6.46        |
|    cost_values           | 2.54        |
|    entropy               | -0.727      |
|    entropy_loss          | -0.732      |
|    explained_variance    | 0.541       |
|    lagrangian_multiplier | 0.00093     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.53        |
|    n_updates             | 7470        |
|    policy_gradient_loss  | 0.00212     |
|    std                   | 0.428       |
|    value_loss            | 11.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.3292143  |
| rollout/                 |             |
|    ep_len_mean           | 114         |
|    ep_rew_mean           | -44.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 14          |
|    time_elapsed          | 406         |
|    total_timesteps       | 1533952     |
| train/                   |             |
|    approx_kl             | 0.020388538 |
|    clip_fraction         | 0.167       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.76        |
|    cost_value_loss       | 8.94        |
|    cost_values           | 2.54        |
|    entropy               | -0.716      |
|    entropy_loss          | -0.721      |
|    explained_variance    | 0.61        |
|    lagrangian_multiplier | 0.00282     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.87        |
|    n_updates             | 7480        |
|    policy_gradient_loss  | 0.00214     |
|    std                   | 0.427       |
|    value_loss            | 12.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.83        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.83        |
| reward                   | -0.23574468 |
| rollout/                 |             |
|    ep_len_mean           | 106         |
|    ep_rew_mean           | -41.7       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 15          |
|    time_elapsed          | 435         |
|    total_timesteps       | 1536000     |
| train/                   |             |
|    approx_kl             | 0.010210638 |
|    clip_fraction         | 0.119       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.11        |
|    cost_value_loss       | 6.23        |
|    cost_values           | 2.49        |
|    entropy               | -0.712      |
|    entropy_loss          | -0.714      |
|    explained_variance    | 0.608       |
|    lagrangian_multiplier | 0.00113     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.57        |
|    n_updates             | 7490        |
|    policy_gradient_loss  | 0.000737    |
|    std                   | 0.426       |
|    value_loss            | 11.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.23641098 |
| rollout/                 |             |
|    ep_len_mean           | 110         |
|    ep_rew_mean           | -42.8       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 16          |
|    time_elapsed          | 464         |
|    total_timesteps       | 1538048     |
| train/                   |             |
|    approx_kl             | 0.010857323 |
|    clip_fraction         | 0.0851      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.59        |
|    cost_value_loss       | 8.13        |
|    cost_values           | 2.45        |
|    entropy               | -0.701      |
|    entropy_loss          | -0.707      |
|    explained_variance    | 0.611       |
|    lagrangian_multiplier | 0.00142     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.55        |
|    n_updates             | 7500        |
|    policy_gradient_loss  | -0.00126    |
|    std                   | 0.424       |
|    value_loss            | 11.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.3293431  |
| rollout/                 |             |
|    ep_len_mean           | 113         |
|    ep_rew_mean           | -43.8       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 17          |
|    time_elapsed          | 493         |
|    total_timesteps       | 1540096     |
| train/                   |             |
|    approx_kl             | 0.011070939 |
|    clip_fraction         | 0.117       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.26        |
|    cost_value_loss       | 6.4         |
|    cost_values           | 2.45        |
|    entropy               | -0.694      |
|    entropy_loss          | -0.697      |
|    explained_variance    | 0.663       |
|    lagrangian_multiplier | 0.0013      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.08        |
|    n_updates             | 7510        |
|    policy_gradient_loss  | -0.00482    |
|    std                   | 0.422       |
|    value_loss            | 10.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.2         |
| reward                   | -0.28942728 |
| rollout/                 |             |
|    ep_len_mean           | 110         |
|    ep_rew_mean           | -42.9       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 18          |
|    time_elapsed          | 522         |
|    total_timesteps       | 1542144     |
| train/                   |             |
|    approx_kl             | 0.020377193 |
|    clip_fraction         | 0.147       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.61        |
|    cost_value_loss       | 5.05        |
|    cost_values           | 2.38        |
|    entropy               | -0.69       |
|    entropy_loss          | -0.692      |
|    explained_variance    | 0.61        |
|    lagrangian_multiplier | 0.00101     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.33        |
|    n_updates             | 7520        |
|    policy_gradient_loss  | -0.00285    |
|    std                   | 0.422       |
|    value_loss            | 9.1         |
------------------------------------------
------------------------------------------
| avg_speed                | 3           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3           |
| reward                   | -0.81765896 |
| rollout/                 |             |
|    ep_len_mean           | 114         |
|    ep_rew_mean           | -44.2       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 19          |
|    time_elapsed          | 551         |
|    total_timesteps       | 1544192     |
| train/                   |             |
|    approx_kl             | 0.008800334 |
|    clip_fraction         | 0.106       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.23        |
|    cost_value_loss       | 7.55        |
|    cost_values           | 2.38        |
|    entropy               | -0.685      |
|    entropy_loss          | -0.687      |
|    explained_variance    | 0.613       |
|    lagrangian_multiplier | 0.000843    |
|    learning_rate         | 0.0003      |
|    loss                  | 8.04        |
|    n_updates             | 7530        |
|    policy_gradient_loss  | -0.00133    |
|    std                   | 0.421       |
|    value_loss            | 14          |
------------------------------------------
------------------------------------------
| avg_speed                | 8.06        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.06        |
| reward                   | -0.25858542 |
| rollout/                 |             |
|    ep_len_mean           | 112         |
|    ep_rew_mean           | -43.7       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 20          |
|    time_elapsed          | 580         |
|    total_timesteps       | 1546240     |
| train/                   |             |
|    approx_kl             | 0.016846303 |
|    clip_fraction         | 0.0868      |
|    clip_range            | 0.2         |
|    cost_returns          | 3.99        |
|    cost_value_loss       | 5.92        |
|    cost_values           | 2.37        |
|    entropy               | -0.681      |
|    entropy_loss          | -0.684      |
|    explained_variance    | 0.613       |
|    lagrangian_multiplier | 0.000881    |
|    learning_rate         | 0.0003      |
|    loss                  | 6.55        |
|    n_updates             | 7540        |
|    policy_gradient_loss  | -0.00456    |
|    std                   | 0.42        |
|    value_loss            | 10.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.68        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.68        |
| reward                   | -0.22535987 |
| rollout/                 |             |
|    ep_len_mean           | 117         |
|    ep_rew_mean           | -45.6       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 21          |
|    time_elapsed          | 610         |
|    total_timesteps       | 1548288     |
| train/                   |             |
|    approx_kl             | 0.037478544 |
|    clip_fraction         | 0.165       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.23        |
|    cost_value_loss       | 7.06        |
|    cost_values           | 2.42        |
|    entropy               | -0.679      |
|    entropy_loss          | -0.679      |
|    explained_variance    | 0.615       |
|    lagrangian_multiplier | 0.00131     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.16        |
|    n_updates             | 7550        |
|    policy_gradient_loss  | 0.00378     |
|    std                   | 0.42        |
|    value_loss            | 13.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.22970097 |
| rollout/                 |             |
|    ep_len_mean           | 118         |
|    ep_rew_mean           | -46         |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 22          |
|    time_elapsed          | 639         |
|    total_timesteps       | 1550336     |
| train/                   |             |
|    approx_kl             | 0.069097295 |
|    clip_fraction         | 0.19        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.8         |
|    cost_value_loss       | 5.87        |
|    cost_values           | 2.38        |
|    entropy               | -0.678      |
|    entropy_loss          | -0.679      |
|    explained_variance    | 0.613       |
|    lagrangian_multiplier | 0.000467    |
|    learning_rate         | 0.0003      |
|    loss                  | 7.89        |
|    n_updates             | 7560        |
|    policy_gradient_loss  | 0.0101      |
|    std                   | 0.42        |
|    value_loss            | 11.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.7362821  |
| rollout/                 |             |
|    ep_len_mean           | 123         |
|    ep_rew_mean           | -47.2       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 23          |
|    time_elapsed          | 668         |
|    total_timesteps       | 1552384     |
| train/                   |             |
|    approx_kl             | 0.010203174 |
|    clip_fraction         | 0.152       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.77        |
|    cost_value_loss       | 5.23        |
|    cost_values           | 2.29        |
|    entropy               | -0.68       |
|    entropy_loss          | -0.678      |
|    explained_variance    | 0.678       |
|    lagrangian_multiplier | 0.000482    |
|    learning_rate         | 0.0003      |
|    loss                  | 6.01        |
|    n_updates             | 7570        |
|    policy_gradient_loss  | 0.00123     |
|    std                   | 0.421       |
|    value_loss            | 8.36        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.18636623 |
| rollout/                 |             |
|    ep_len_mean           | 130         |
|    ep_rew_mean           | -49.4       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 24          |
|    time_elapsed          | 697         |
|    total_timesteps       | 1554432     |
| train/                   |             |
|    approx_kl             | 0.006777182 |
|    clip_fraction         | 0.0865      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.28        |
|    cost_value_loss       | 7.66        |
|    cost_values           | 2.32        |
|    entropy               | -0.68       |
|    entropy_loss          | -0.68       |
|    explained_variance    | 0.406       |
|    lagrangian_multiplier | 0.00224     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.17        |
|    n_updates             | 7580        |
|    policy_gradient_loss  | -0.00237    |
|    std                   | 0.422       |
|    value_loss            | 14          |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.22537738  |
| rollout/                 |              |
|    ep_len_mean           | 141          |
|    ep_rew_mean           | -52.6        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 25           |
|    time_elapsed          | 726          |
|    total_timesteps       | 1556480      |
| train/                   |              |
|    approx_kl             | 0.0136682885 |
|    clip_fraction         | 0.172        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.99         |
|    cost_value_loss       | 4.99         |
|    cost_values           | 2.34         |
|    entropy               | -0.674       |
|    entropy_loss          | -0.678       |
|    explained_variance    | 0.57         |
|    lagrangian_multiplier | 0.000336     |
|    learning_rate         | 0.0003       |
|    loss                  | 7.56         |
|    n_updates             | 7590         |
|    policy_gradient_loss  | 0.00186      |
|    std                   | 0.421        |
|    value_loss            | 11.6         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.96        |
| reward                   | -0.715718   |
| rollout/                 |             |
|    ep_len_mean           | 143         |
|    ep_rew_mean           | -53.3       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 26          |
|    time_elapsed          | 755         |
|    total_timesteps       | 1558528     |
| train/                   |             |
|    approx_kl             | 0.016469352 |
|    clip_fraction         | 0.156       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.17        |
|    cost_value_loss       | 6.7         |
|    cost_values           | 2.37        |
|    entropy               | -0.671      |
|    entropy_loss          | -0.671      |
|    explained_variance    | 0.464       |
|    lagrangian_multiplier | 0.000838    |
|    learning_rate         | 0.0003      |
|    loss                  | 6.5         |
|    n_updates             | 7600        |
|    policy_gradient_loss  | -0.000349   |
|    std                   | 0.42        |
|    value_loss            | 11.4        |
------------------------------------------
-----------------------------------------
| avg_speed                | 5.4        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 5.4        |
| reward                   | -0.3455032 |
| rollout/                 |            |
|    ep_len_mean           | 140        |
|    ep_rew_mean           | -52.1      |
| time/                    |            |
|    fps                   | 70         |
|    iterations            | 27         |
|    time_elapsed          | 785        |
|    total_timesteps       | 1560576    |
| train/                   |            |
|    approx_kl             | 0.00856768 |
|    clip_fraction         | 0.128      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.33       |
|    cost_value_loss       | 7.11       |
|    cost_values           | 2.41       |
|    entropy               | -0.67      |
|    entropy_loss          | -0.671     |
|    explained_variance    | 0.553      |
|    lagrangian_multiplier | 0.000661   |
|    learning_rate         | 0.0003     |
|    loss                  | 8.84       |
|    n_updates             | 7610       |
|    policy_gradient_loss  | 3.25e-05   |
|    std                   | 0.42       |
|    value_loss            | 15.2       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.27702758 |
| rollout/                 |             |
|    ep_len_mean           | 133         |
|    ep_rew_mean           | -49.7       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 28          |
|    time_elapsed          | 814         |
|    total_timesteps       | 1562624     |
| train/                   |             |
|    approx_kl             | 0.009924729 |
|    clip_fraction         | 0.114       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.42        |
|    cost_value_loss       | 7.59        |
|    cost_values           | 2.44        |
|    entropy               | -0.673      |
|    entropy_loss          | -0.671      |
|    explained_variance    | 0.601       |
|    lagrangian_multiplier | 0.0015      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.8         |
|    n_updates             | 7620        |
|    policy_gradient_loss  | 0.00272     |
|    std                   | 0.421       |
|    value_loss            | 13.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.28770158 |
| rollout/                 |             |
|    ep_len_mean           | 128         |
|    ep_rew_mean           | -47.8       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 29          |
|    time_elapsed          | 844         |
|    total_timesteps       | 1564672     |
| train/                   |             |
|    approx_kl             | 0.0514713   |
|    clip_fraction         | 0.176       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.33        |
|    cost_value_loss       | 6.26        |
|    cost_values           | 2.46        |
|    entropy               | -0.67       |
|    entropy_loss          | -0.673      |
|    explained_variance    | 0.655       |
|    lagrangian_multiplier | 0.00203     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.51        |
|    n_updates             | 7630        |
|    policy_gradient_loss  | 0.00387     |
|    std                   | 0.421       |
|    value_loss            | 10.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.93        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.93        |
| reward                   | -0.25586572 |
| rollout/                 |             |
|    ep_len_mean           | 115         |
|    ep_rew_mean           | -44.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 30          |
|    time_elapsed          | 873         |
|    total_timesteps       | 1566720     |
| train/                   |             |
|    approx_kl             | 0.012472059 |
|    clip_fraction         | 0.133       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.53        |
|    cost_value_loss       | 7.96        |
|    cost_values           | 2.48        |
|    entropy               | -0.672      |
|    entropy_loss          | -0.671      |
|    explained_variance    | 0.642       |
|    lagrangian_multiplier | 0.000937    |
|    learning_rate         | 0.0003      |
|    loss                  | 7.22        |
|    n_updates             | 7640        |
|    policy_gradient_loss  | -0.000443   |
|    std                   | 0.421       |
|    value_loss            | 11.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.36017472 |
| rollout/                 |             |
|    ep_len_mean           | 104         |
|    ep_rew_mean           | -40.9       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 31          |
|    time_elapsed          | 903         |
|    total_timesteps       | 1568768     |
| train/                   |             |
|    approx_kl             | 0.025362702 |
|    clip_fraction         | 0.129       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.56        |
|    cost_value_loss       | 7.01        |
|    cost_values           | 2.53        |
|    entropy               | -0.669      |
|    entropy_loss          | -0.67       |
|    explained_variance    | 0.608       |
|    lagrangian_multiplier | 0.0027      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.5         |
|    n_updates             | 7650        |
|    policy_gradient_loss  | 0.000394    |
|    std                   | 0.421       |
|    value_loss            | 11.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.16        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.16        |
| reward                   | -0.5186827  |
| rollout/                 |             |
|    ep_len_mean           | 108         |
|    ep_rew_mean           | -41.9       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 32          |
|    time_elapsed          | 932         |
|    total_timesteps       | 1570816     |
| train/                   |             |
|    approx_kl             | 0.016083928 |
|    clip_fraction         | 0.187       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.7         |
|    cost_value_loss       | 9.04        |
|    cost_values           | 2.54        |
|    entropy               | -0.667      |
|    entropy_loss          | -0.668      |
|    explained_variance    | 0.653       |
|    lagrangian_multiplier | 0.00155     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.72        |
|    n_updates             | 7660        |
|    policy_gradient_loss  | 0.00519     |
|    std                   | 0.421       |
|    value_loss            | 11.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.8         |
| reward                   | -0.62671566 |
| rollout/                 |             |
|    ep_len_mean           | 109         |
|    ep_rew_mean           | -42.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 33          |
|    time_elapsed          | 961         |
|    total_timesteps       | 1572864     |
| train/                   |             |
|    approx_kl             | 0.00929745  |
|    clip_fraction         | 0.102       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.87        |
|    cost_value_loss       | 8.73        |
|    cost_values           | 2.57        |
|    entropy               | -0.659      |
|    entropy_loss          | -0.664      |
|    explained_variance    | 0.577       |
|    lagrangian_multiplier | 0.00164     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.35        |
|    n_updates             | 7670        |
|    policy_gradient_loss  | -0.00145    |
|    std                   | 0.418       |
|    value_loss            | 10.9        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.34343466  |
| rollout/                 |              |
|    ep_len_mean           | 107          |
|    ep_rew_mean           | -42.1        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 34           |
|    time_elapsed          | 989          |
|    total_timesteps       | 1574912      |
| train/                   |              |
|    approx_kl             | 0.0119734965 |
|    clip_fraction         | 0.146        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.97         |
|    cost_value_loss       | 10.1         |
|    cost_values           | 2.61         |
|    entropy               | -0.647       |
|    entropy_loss          | -0.653       |
|    explained_variance    | 0.693        |
|    lagrangian_multiplier | 0.00229      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.24         |
|    n_updates             | 7680         |
|    policy_gradient_loss  | 0.00506      |
|    std                   | 0.416        |
|    value_loss            | 11           |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.96        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.96        |
| reward                   | -0.30233532 |
| rollout/                 |             |
|    ep_len_mean           | 112         |
|    ep_rew_mean           | -43.7       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 35          |
|    time_elapsed          | 1018        |
|    total_timesteps       | 1576960     |
| train/                   |             |
|    approx_kl             | 0.014458686 |
|    clip_fraction         | 0.132       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.12        |
|    cost_value_loss       | 10.6        |
|    cost_values           | 2.58        |
|    entropy               | -0.638      |
|    entropy_loss          | -0.642      |
|    explained_variance    | 0.653       |
|    lagrangian_multiplier | 0.00245     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.88        |
|    n_updates             | 7690        |
|    policy_gradient_loss  | 0.00118     |
|    std                   | 0.414       |
|    value_loss            | 10.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.29333308 |
| rollout/                 |             |
|    ep_len_mean           | 102         |
|    ep_rew_mean           | -40.8       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 36          |
|    time_elapsed          | 1047        |
|    total_timesteps       | 1579008     |
| train/                   |             |
|    approx_kl             | 0.01617243  |
|    clip_fraction         | 0.129       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.89        |
|    cost_value_loss       | 9.3         |
|    cost_values           | 2.6         |
|    entropy               | -0.626      |
|    entropy_loss          | -0.632      |
|    explained_variance    | 0.69        |
|    lagrangian_multiplier | 0.00275     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.38        |
|    n_updates             | 7700        |
|    policy_gradient_loss  | 0.000741    |
|    std                   | 0.412       |
|    value_loss            | 9.89        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 6            |
| reward                   | -0.30279735  |
| rollout/                 |              |
|    ep_len_mean           | 102          |
|    ep_rew_mean           | -40.6        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 37           |
|    time_elapsed          | 1077         |
|    total_timesteps       | 1581056      |
| train/                   |              |
|    approx_kl             | 0.0053343466 |
|    clip_fraction         | 0.0859       |
|    clip_range            | 0.2          |
|    cost_returns          | 4.64         |
|    cost_value_loss       | 7.97         |
|    cost_values           | 2.61         |
|    entropy               | -0.621       |
|    entropy_loss          | -0.623       |
|    explained_variance    | 0.656        |
|    lagrangian_multiplier | 0.00148      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.15         |
|    n_updates             | 7710         |
|    policy_gradient_loss  | -0.00203     |
|    std                   | 0.411        |
|    value_loss            | 12.5         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.8         |
| reward                   | -0.35519007 |
| rollout/                 |             |
|    ep_len_mean           | 105         |
|    ep_rew_mean           | -41.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 38          |
|    time_elapsed          | 1106        |
|    total_timesteps       | 1583104     |
| train/                   |             |
|    approx_kl             | 0.011684555 |
|    clip_fraction         | 0.106       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.52        |
|    cost_value_loss       | 7.29        |
|    cost_values           | 2.56        |
|    entropy               | -0.624      |
|    entropy_loss          | -0.622      |
|    explained_variance    | 0.661       |
|    lagrangian_multiplier | 0.0017      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.83        |
|    n_updates             | 7720        |
|    policy_gradient_loss  | 0.000813    |
|    std                   | 0.412       |
|    value_loss            | 10.6        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.30361578 |
| rollout/                 |             |
|    ep_len_mean           | 107         |
|    ep_rew_mean           | -41.7       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 39          |
|    time_elapsed          | 1135        |
|    total_timesteps       | 1585152     |
| train/                   |             |
|    approx_kl             | 0.014322953 |
|    clip_fraction         | 0.143       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.14        |
|    cost_value_loss       | 10.5        |
|    cost_values           | 2.59        |
|    entropy               | -0.634      |
|    entropy_loss          | -0.629      |
|    explained_variance    | 0.703       |
|    lagrangian_multiplier | 0.00351     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.17        |
|    n_updates             | 7730        |
|    policy_gradient_loss  | 0.000977    |
|    std                   | 0.415       |
|    value_loss            | 9.19        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.30108613 |
| rollout/                 |             |
|    ep_len_mean           | 102         |
|    ep_rew_mean           | -40.2       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 40          |
|    time_elapsed          | 1164        |
|    total_timesteps       | 1587200     |
| train/                   |             |
|    approx_kl             | 0.039268967 |
|    clip_fraction         | 0.177       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.05        |
|    cost_value_loss       | 10.1        |
|    cost_values           | 2.54        |
|    entropy               | -0.632      |
|    entropy_loss          | -0.634      |
|    explained_variance    | 0.604       |
|    lagrangian_multiplier | 0.00215     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.99        |
|    n_updates             | 7740        |
|    policy_gradient_loss  | 0.00553     |
|    std                   | 0.415       |
|    value_loss            | 9.7         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.36477977 |
| rollout/                 |             |
|    ep_len_mean           | 107         |
|    ep_rew_mean           | -41.9       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 41          |
|    time_elapsed          | 1193        |
|    total_timesteps       | 1589248     |
| train/                   |             |
|    approx_kl             | 0.009314172 |
|    clip_fraction         | 0.159       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.05        |
|    cost_value_loss       | 10.6        |
|    cost_values           | 2.53        |
|    entropy               | -0.625      |
|    entropy_loss          | -0.628      |
|    explained_variance    | 0.636       |
|    lagrangian_multiplier | 0.00247     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.99        |
|    n_updates             | 7750        |
|    policy_gradient_loss  | 0.00398     |
|    std                   | 0.413       |
|    value_loss            | 10.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.93         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.93         |
| reward                   | -0.22890374  |
| rollout/                 |              |
|    ep_len_mean           | 104          |
|    ep_rew_mean           | -41.4        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 42           |
|    time_elapsed          | 1222         |
|    total_timesteps       | 1591296      |
| train/                   |              |
|    approx_kl             | 0.0080854455 |
|    clip_fraction         | 0.15         |
|    clip_range            | 0.2          |
|    cost_returns          | 5.14         |
|    cost_value_loss       | 10.6         |
|    cost_values           | 2.52         |
|    entropy               | -0.62        |
|    entropy_loss          | -0.622       |
|    explained_variance    | 0.64         |
|    lagrangian_multiplier | 0.00149      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.94         |
|    n_updates             | 7760         |
|    policy_gradient_loss  | 0.00382      |
|    std                   | 0.411        |
|    value_loss            | 11.3         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.22862586  |
| rollout/                 |              |
|    ep_len_mean           | 103          |
|    ep_rew_mean           | -41.5        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 43           |
|    time_elapsed          | 1251         |
|    total_timesteps       | 1593344      |
| train/                   |              |
|    approx_kl             | 0.0056631994 |
|    clip_fraction         | 0.119        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.28         |
|    cost_value_loss       | 6.64         |
|    cost_values           | 2.46         |
|    entropy               | -0.62        |
|    entropy_loss          | -0.619       |
|    explained_variance    | 0.664        |
|    lagrangian_multiplier | 0.00155      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.36         |
|    n_updates             | 7770         |
|    policy_gradient_loss  | 0.00121      |
|    std                   | 0.412        |
|    value_loss            | 12.4         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.16692124 |
| rollout/                 |             |
|    ep_len_mean           | 111         |
|    ep_rew_mean           | -44         |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 44          |
|    time_elapsed          | 1281        |
|    total_timesteps       | 1595392     |
| train/                   |             |
|    approx_kl             | 0.013216622 |
|    clip_fraction         | 0.164       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.46        |
|    cost_value_loss       | 6.84        |
|    cost_values           | 2.42        |
|    entropy               | -0.617      |
|    entropy_loss          | -0.619      |
|    explained_variance    | 0.646       |
|    lagrangian_multiplier | 0.00183     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.19        |
|    n_updates             | 7780        |
|    policy_gradient_loss  | -0.00072    |
|    std                   | 0.412       |
|    value_loss            | 10.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.88        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.88        |
| reward                   | -0.4628673  |
| rollout/                 |             |
|    ep_len_mean           | 108         |
|    ep_rew_mean           | -43.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 45          |
|    time_elapsed          | 1310        |
|    total_timesteps       | 1597440     |
| train/                   |             |
|    approx_kl             | 0.010474421 |
|    clip_fraction         | 0.122       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.42        |
|    cost_value_loss       | 6.98        |
|    cost_values           | 2.32        |
|    entropy               | -0.618      |
|    entropy_loss          | -0.617      |
|    explained_variance    | 0.631       |
|    lagrangian_multiplier | 0.00135     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.83        |
|    n_updates             | 7790        |
|    policy_gradient_loss  | 0.000553    |
|    std                   | 0.412       |
|    value_loss            | 8.64        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.4430259  |
| rollout/                 |             |
|    ep_len_mean           | 122         |
|    ep_rew_mean           | -48.4       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 46          |
|    time_elapsed          | 1339        |
|    total_timesteps       | 1599488     |
| train/                   |             |
|    approx_kl             | 0.006313408 |
|    clip_fraction         | 0.1         |
|    clip_range            | 0.2         |
|    cost_returns          | 5.08        |
|    cost_value_loss       | 12          |
|    cost_values           | 2.31        |
|    entropy               | -0.618      |
|    entropy_loss          | -0.618      |
|    explained_variance    | 0.52        |
|    lagrangian_multiplier | 0.0029      |
|    learning_rate         | 0.0003      |
|    loss                  | 7.27        |
|    n_updates             | 7800        |
|    policy_gradient_loss  | 3.64e-05    |
|    std                   | 0.413       |
|    value_loss            | 15.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.81060624 |
| rollout/                 |             |
|    ep_len_mean           | 126         |
|    ep_rew_mean           | -50         |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 47          |
|    time_elapsed          | 1368        |
|    total_timesteps       | 1601536     |
| train/                   |             |
|    approx_kl             | 0.020479267 |
|    clip_fraction         | 0.134       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.13        |
|    cost_value_loss       | 6.77        |
|    cost_values           | 2.21        |
|    entropy               | -0.616      |
|    entropy_loss          | -0.617      |
|    explained_variance    | 0.586       |
|    lagrangian_multiplier | 0.000621    |
|    learning_rate         | 0.0003      |
|    loss                  | 7.21        |
|    n_updates             | 7810        |
|    policy_gradient_loss  | -0.00315    |
|    std                   | 0.414       |
|    value_loss            | 10.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.37725747 |
| rollout/                 |             |
|    ep_len_mean           | 131         |
|    ep_rew_mean           | -51.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 48          |
|    time_elapsed          | 1398        |
|    total_timesteps       | 1603584     |
| train/                   |             |
|    approx_kl             | 0.012716271 |
|    clip_fraction         | 0.0653      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.09        |
|    cost_value_loss       | 13          |
|    cost_values           | 2.28        |
|    entropy               | -0.613      |
|    entropy_loss          | -0.615      |
|    explained_variance    | 0.532       |
|    lagrangian_multiplier | 0.00227     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.89        |
|    n_updates             | 7820        |
|    policy_gradient_loss  | -0.0018     |
|    std                   | 0.413       |
|    value_loss            | 19          |
------------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.6627249  |
| rollout/                 |             |
|    ep_len_mean           | 134         |
|    ep_rew_mean           | -52.7       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 49          |
|    time_elapsed          | 1426        |
|    total_timesteps       | 1605632     |
| train/                   |             |
|    approx_kl             | 0.014597804 |
|    clip_fraction         | 0.132       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.65        |
|    cost_value_loss       | 9.53        |
|    cost_values           | 2.27        |
|    entropy               | -0.613      |
|    entropy_loss          | -0.613      |
|    explained_variance    | 0.515       |
|    lagrangian_multiplier | 0.000427    |
|    learning_rate         | 0.0003      |
|    loss                  | 11.1        |
|    n_updates             | 7830        |
|    policy_gradient_loss  | -0.00619    |
|    std                   | 0.413       |
|    value_loss            | 15.1        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ent-coefficient-ppol/vlorgroe
-----------------------------------
| avg_speed          | 1.2        |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 1.2        |
| reward             | -0.8984576 |
| rollout/           |            |
|    ep_len_mean     | 136        |
|    ep_rew_mean     | -53.9      |
| time/              |            |
|    fps             | 76         |
|    iterations      | 1          |
|    time_elapsed    | 26         |
|    total_timesteps | 1607680    |
-----------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.35386005 |
| rollout/                 |             |
|    ep_len_mean           | 126         |
|    ep_rew_mean           | -50.7       |
| time/                    |             |
|    fps                   | 73          |
|    iterations            | 2           |
|    time_elapsed          | 55          |
|    total_timesteps       | 1609728     |
| train/                   |             |
|    approx_kl             | 0.005695097 |
|    clip_fraction         | 0.0981      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.97        |
|    cost_value_loss       | 11.5        |
|    cost_values           | 2.27        |
|    entropy               | -0.6        |
|    entropy_loss          | -0.604      |
|    explained_variance    | 0.615       |
|    lagrangian_multiplier | 0.00147     |
|    learning_rate         | 0.0003      |
|    loss                  | 8.47        |
|    n_updates             | 7850        |
|    policy_gradient_loss  | -7.45e-05   |
|    std                   | 0.412       |
|    value_loss            | 14.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.32226667 |
| rollout/                 |             |
|    ep_len_mean           | 120         |
|    ep_rew_mean           | -48.2       |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 3           |
|    time_elapsed          | 84          |
|    total_timesteps       | 1611776     |
| train/                   |             |
|    approx_kl             | 0.015794583 |
|    clip_fraction         | 0.0914      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.54        |
|    cost_value_loss       | 15          |
|    cost_values           | 2.33        |
|    entropy               | -0.596      |
|    entropy_loss          | -0.598      |
|    explained_variance    | 0.576       |
|    lagrangian_multiplier | 0.00292     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.91        |
|    n_updates             | 7860        |
|    policy_gradient_loss  | -0.00308    |
|    std                   | 0.411       |
|    value_loss            | 14          |
------------------------------------------
------------------------------------------
| avg_speed                | 7.18        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.18        |
| reward                   | -0.42669743 |
| rollout/                 |             |
|    ep_len_mean           | 120         |
|    ep_rew_mean           | -47.8       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 4           |
|    time_elapsed          | 113         |
|    total_timesteps       | 1613824     |
| train/                   |             |
|    approx_kl             | 0.009927923 |
|    clip_fraction         | 0.103       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.89        |
|    cost_value_loss       | 6.69        |
|    cost_values           | 2.26        |
|    entropy               | -0.595      |
|    entropy_loss          | -0.596      |
|    explained_variance    | 0.609       |
|    lagrangian_multiplier | 0.000545    |
|    learning_rate         | 0.0003      |
|    loss                  | 7.71        |
|    n_updates             | 7870        |
|    policy_gradient_loss  | -0.00298    |
|    std                   | 0.411       |
|    value_loss            | 14.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.25375533 |
| rollout/                 |             |
|    ep_len_mean           | 116         |
|    ep_rew_mean           | -46.7       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 5           |
|    time_elapsed          | 142         |
|    total_timesteps       | 1615872     |
| train/                   |             |
|    approx_kl             | 0.010261361 |
|    clip_fraction         | 0.108       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.27        |
|    cost_value_loss       | 14.1        |
|    cost_values           | 2.29        |
|    entropy               | -0.593      |
|    entropy_loss          | -0.594      |
|    explained_variance    | 0.6         |
|    lagrangian_multiplier | 0.000927    |
|    learning_rate         | 0.0003      |
|    loss                  | 11.3        |
|    n_updates             | 7880        |
|    policy_gradient_loss  | -0.0033     |
|    std                   | 0.411       |
|    value_loss            | 16.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.33767876 |
| rollout/                 |             |
|    ep_len_mean           | 119         |
|    ep_rew_mean           | -47         |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 6           |
|    time_elapsed          | 172         |
|    total_timesteps       | 1617920     |
| train/                   |             |
|    approx_kl             | 0.012104753 |
|    clip_fraction         | 0.128       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.78        |
|    cost_value_loss       | 9.99        |
|    cost_values           | 2.34        |
|    entropy               | -0.592      |
|    entropy_loss          | -0.593      |
|    explained_variance    | 0.621       |
|    lagrangian_multiplier | 0.000536    |
|    learning_rate         | 0.0003      |
|    loss                  | 9.84        |
|    n_updates             | 7890        |
|    policy_gradient_loss  | -0.000757   |
|    std                   | 0.411       |
|    value_loss            | 13.9        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.87        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.87        |
| reward                   | -0.13053411 |
| rollout/                 |             |
|    ep_len_mean           | 115         |
|    ep_rew_mean           | -45.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 7           |
|    time_elapsed          | 202         |
|    total_timesteps       | 1619968     |
| train/                   |             |
|    approx_kl             | 0.01718534  |
|    clip_fraction         | 0.0973      |
|    clip_range            | 0.2         |
|    cost_returns          | 5.37        |
|    cost_value_loss       | 14.3        |
|    cost_values           | 2.42        |
|    entropy               | -0.586      |
|    entropy_loss          | -0.589      |
|    explained_variance    | 0.661       |
|    lagrangian_multiplier | 0.000498    |
|    learning_rate         | 0.0003      |
|    loss                  | 10.6        |
|    n_updates             | 7900        |
|    policy_gradient_loss  | -0.000735   |
|    std                   | 0.41        |
|    value_loss            | 11.4        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.250145   |
| rollout/                 |             |
|    ep_len_mean           | 98.9        |
|    ep_rew_mean           | -39.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 8           |
|    time_elapsed          | 231         |
|    total_timesteps       | 1622016     |
| train/                   |             |
|    approx_kl             | 0.025494186 |
|    clip_fraction         | 0.13        |
|    clip_range            | 0.2         |
|    cost_returns          | 5.53        |
|    cost_value_loss       | 13.2        |
|    cost_values           | 2.51        |
|    entropy               | -0.578      |
|    entropy_loss          | -0.582      |
|    explained_variance    | 0.641       |
|    lagrangian_multiplier | 0.00364     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.56        |
|    n_updates             | 7910        |
|    policy_gradient_loss  | -0.000931   |
|    std                   | 0.41        |
|    value_loss            | 11.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.26281565 |
| rollout/                 |             |
|    ep_len_mean           | 94.5        |
|    ep_rew_mean           | -37.8       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 9           |
|    time_elapsed          | 261         |
|    total_timesteps       | 1624064     |
| train/                   |             |
|    approx_kl             | 0.057601888 |
|    clip_fraction         | 0.19        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.69        |
|    cost_value_loss       | 9.27        |
|    cost_values           | 2.51        |
|    entropy               | -0.569      |
|    entropy_loss          | -0.574      |
|    explained_variance    | 0.776       |
|    lagrangian_multiplier | 0.00363     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.96        |
|    n_updates             | 7920        |
|    policy_gradient_loss  | 0.00411     |
|    std                   | 0.408       |
|    value_loss            | 9.71        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.28605145 |
| rollout/                 |             |
|    ep_len_mean           | 95.6        |
|    ep_rew_mean           | -38.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 10          |
|    time_elapsed          | 291         |
|    total_timesteps       | 1626112     |
| train/                   |             |
|    approx_kl             | 0.02056015  |
|    clip_fraction         | 0.161       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.79        |
|    cost_value_loss       | 9.86        |
|    cost_values           | 2.46        |
|    entropy               | -0.561      |
|    entropy_loss          | -0.565      |
|    explained_variance    | 0.748       |
|    lagrangian_multiplier | 0.00135     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.38        |
|    n_updates             | 7930        |
|    policy_gradient_loss  | 0.00444     |
|    std                   | 0.407       |
|    value_loss            | 8.44        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.31040245 |
| rollout/                 |             |
|    ep_len_mean           | 91.3        |
|    ep_rew_mean           | -37.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 11          |
|    time_elapsed          | 321         |
|    total_timesteps       | 1628160     |
| train/                   |             |
|    approx_kl             | 0.023227427 |
|    clip_fraction         | 0.165       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.79        |
|    cost_value_loss       | 9.86        |
|    cost_values           | 2.5         |
|    entropy               | -0.56       |
|    entropy_loss          | -0.559      |
|    explained_variance    | 0.754       |
|    lagrangian_multiplier | 0.00178     |
|    learning_rate         | 0.0003      |
|    loss                  | 6           |
|    n_updates             | 7940        |
|    policy_gradient_loss  | 0.00448     |
|    std                   | 0.407       |
|    value_loss            | 8.31        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.33121443 |
| rollout/                 |             |
|    ep_len_mean           | 92.4        |
|    ep_rew_mean           | -37.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 12          |
|    time_elapsed          | 350         |
|    total_timesteps       | 1630208     |
| train/                   |             |
|    approx_kl             | 0.010944681 |
|    clip_fraction         | 0.14        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.67        |
|    cost_value_loss       | 8.41        |
|    cost_values           | 2.51        |
|    entropy               | -0.561      |
|    entropy_loss          | -0.56       |
|    explained_variance    | 0.792       |
|    lagrangian_multiplier | 0.00139     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.87        |
|    n_updates             | 7950        |
|    policy_gradient_loss  | 0.00233     |
|    std                   | 0.407       |
|    value_loss            | 8.53        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.2358797  |
| rollout/                 |             |
|    ep_len_mean           | 96.8        |
|    ep_rew_mean           | -38.3       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 13          |
|    time_elapsed          | 380         |
|    total_timesteps       | 1632256     |
| train/                   |             |
|    approx_kl             | 0.040570453 |
|    clip_fraction         | 0.148       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.92        |
|    cost_value_loss       | 10          |
|    cost_values           | 2.56        |
|    entropy               | -0.562      |
|    entropy_loss          | -0.562      |
|    explained_variance    | 0.801       |
|    lagrangian_multiplier | 0.00188     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.62        |
|    n_updates             | 7960        |
|    policy_gradient_loss  | 0.00435     |
|    std                   | 0.407       |
|    value_loss            | 8.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.14        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.14        |
| reward                   | -0.4292598  |
| rollout/                 |             |
|    ep_len_mean           | 95          |
|    ep_rew_mean           | -38         |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 14          |
|    time_elapsed          | 408         |
|    total_timesteps       | 1634304     |
| train/                   |             |
|    approx_kl             | 0.029819844 |
|    clip_fraction         | 0.228       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.03        |
|    cost_value_loss       | 9.5         |
|    cost_values           | 2.59        |
|    entropy               | -0.565      |
|    entropy_loss          | -0.562      |
|    explained_variance    | 0.771       |
|    lagrangian_multiplier | 0.00106     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.89        |
|    n_updates             | 7970        |
|    policy_gradient_loss  | 0.01        |
|    std                   | 0.408       |
|    value_loss            | 7.16        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.1959587  |
| rollout/                 |             |
|    ep_len_mean           | 95.1        |
|    ep_rew_mean           | -37.9       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 15          |
|    time_elapsed          | 437         |
|    total_timesteps       | 1636352     |
| train/                   |             |
|    approx_kl             | 0.022595301 |
|    clip_fraction         | 0.15        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.65        |
|    cost_value_loss       | 8.17        |
|    cost_values           | 2.59        |
|    entropy               | -0.571      |
|    entropy_loss          | -0.569      |
|    explained_variance    | 0.725       |
|    lagrangian_multiplier | 0.00123     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.42        |
|    n_updates             | 7980        |
|    policy_gradient_loss  | 0.00288     |
|    std                   | 0.41        |
|    value_loss            | 9.07        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.25883713 |
| rollout/                 |             |
|    ep_len_mean           | 106         |
|    ep_rew_mean           | -41.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 16          |
|    time_elapsed          | 466         |
|    total_timesteps       | 1638400     |
| train/                   |             |
|    approx_kl             | 0.011989079 |
|    clip_fraction         | 0.216       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.58        |
|    cost_value_loss       | 7.69        |
|    cost_values           | 2.53        |
|    entropy               | -0.576      |
|    entropy_loss          | -0.574      |
|    explained_variance    | 0.613       |
|    lagrangian_multiplier | 0.00165     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.33        |
|    n_updates             | 7990        |
|    policy_gradient_loss  | 0.0124      |
|    std                   | 0.412       |
|    value_loss            | 8.74        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.3584766  |
| rollout/                 |             |
|    ep_len_mean           | 103         |
|    ep_rew_mean           | -40.4       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 17          |
|    time_elapsed          | 495         |
|    total_timesteps       | 1640448     |
| train/                   |             |
|    approx_kl             | 0.015849596 |
|    clip_fraction         | 0.153       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.78        |
|    cost_value_loss       | 8.24        |
|    cost_values           | 2.46        |
|    entropy               | -0.578      |
|    entropy_loss          | -0.577      |
|    explained_variance    | 0.648       |
|    lagrangian_multiplier | 0.00104     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.83        |
|    n_updates             | 8000        |
|    policy_gradient_loss  | 0.000284    |
|    std                   | 0.412       |
|    value_loss            | 8.41        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.30232373 |
| rollout/                 |             |
|    ep_len_mean           | 107         |
|    ep_rew_mean           | -41.9       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 18          |
|    time_elapsed          | 525         |
|    total_timesteps       | 1642496     |
| train/                   |             |
|    approx_kl             | 0.022797452 |
|    clip_fraction         | 0.123       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.76        |
|    cost_value_loss       | 9.54        |
|    cost_values           | 2.5         |
|    entropy               | -0.579      |
|    entropy_loss          | -0.578      |
|    explained_variance    | 0.688       |
|    lagrangian_multiplier | 0.00164     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.87        |
|    n_updates             | 8010        |
|    policy_gradient_loss  | 0.0011      |
|    std                   | 0.412       |
|    value_loss            | 9.84        |
------------------------------------------
-----------------------------------------
| avg_speed                | 3.8        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 3.8        |
| reward                   | -0.5870075 |
| rollout/                 |            |
|    ep_len_mean           | 108        |
|    ep_rew_mean           | -41.9      |
| time/                    |            |
|    fps                   | 70         |
|    iterations            | 19         |
|    time_elapsed          | 553        |
|    total_timesteps       | 1644544    |
| train/                   |            |
|    approx_kl             | 0.03193214 |
|    clip_fraction         | 0.231      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.87       |
|    cost_value_loss       | 8.7        |
|    cost_values           | 2.48       |
|    entropy               | -0.577     |
|    entropy_loss          | -0.578     |
|    explained_variance    | 0.628      |
|    lagrangian_multiplier | 0.00202    |
|    learning_rate         | 0.0003     |
|    loss                  | 5.32       |
|    n_updates             | 8020       |
|    policy_gradient_loss  | 0.00963    |
|    std                   | 0.413      |
|    value_loss            | 8.79       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.26452345 |
| rollout/                 |             |
|    ep_len_mean           | 111         |
|    ep_rew_mean           | -43.3       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 20          |
|    time_elapsed          | 582         |
|    total_timesteps       | 1646592     |
| train/                   |             |
|    approx_kl             | 0.011251311 |
|    clip_fraction         | 0.108       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.91        |
|    cost_value_loss       | 10.2        |
|    cost_values           | 2.47        |
|    entropy               | -0.573      |
|    entropy_loss          | -0.575      |
|    explained_variance    | 0.653       |
|    lagrangian_multiplier | 0.00113     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.46        |
|    n_updates             | 8030        |
|    policy_gradient_loss  | -0.00262    |
|    std                   | 0.412       |
|    value_loss            | 10.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.33068252 |
| rollout/                 |             |
|    ep_len_mean           | 98.4        |
|    ep_rew_mean           | -39.4       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 21          |
|    time_elapsed          | 611         |
|    total_timesteps       | 1648640     |
| train/                   |             |
|    approx_kl             | 0.009164037 |
|    clip_fraction         | 0.183       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.04        |
|    cost_value_loss       | 11.2        |
|    cost_values           | 2.49        |
|    entropy               | -0.573      |
|    entropy_loss          | -0.572      |
|    explained_variance    | 0.736       |
|    lagrangian_multiplier | 0.00229     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.41        |
|    n_updates             | 8040        |
|    policy_gradient_loss  | 0.00518     |
|    std                   | 0.412       |
|    value_loss            | 10.2        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3427371  |
| rollout/                 |             |
|    ep_len_mean           | 102         |
|    ep_rew_mean           | -40.7       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 22          |
|    time_elapsed          | 640         |
|    total_timesteps       | 1650688     |
| train/                   |             |
|    approx_kl             | 0.016129661 |
|    clip_fraction         | 0.132       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.08        |
|    cost_value_loss       | 10.6        |
|    cost_values           | 2.54        |
|    entropy               | -0.561      |
|    entropy_loss          | -0.568      |
|    explained_variance    | 0.699       |
|    lagrangian_multiplier | 0.00261     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.96        |
|    n_updates             | 8050        |
|    policy_gradient_loss  | -0.00359    |
|    std                   | 0.41        |
|    value_loss            | 10.8        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.8         |
| reward                   | -0.91403323 |
| rollout/                 |             |
|    ep_len_mean           | 89.2        |
|    ep_rew_mean           | -36.8       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 23          |
|    time_elapsed          | 669         |
|    total_timesteps       | 1652736     |
| train/                   |             |
|    approx_kl             | 0.020807527 |
|    clip_fraction         | 0.166       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.58        |
|    cost_value_loss       | 9.06        |
|    cost_values           | 2.52        |
|    entropy               | -0.55       |
|    entropy_loss          | -0.555      |
|    explained_variance    | 0.698       |
|    lagrangian_multiplier | 0.00111     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.34        |
|    n_updates             | 8060        |
|    policy_gradient_loss  | 0.00286     |
|    std                   | 0.407       |
|    value_loss            | 10.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.12587254 |
| rollout/                 |             |
|    ep_len_mean           | 94.8        |
|    ep_rew_mean           | -38.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 24          |
|    time_elapsed          | 698         |
|    total_timesteps       | 1654784     |
| train/                   |             |
|    approx_kl             | 0.011391726 |
|    clip_fraction         | 0.149       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.8         |
|    cost_value_loss       | 9.2         |
|    cost_values           | 2.49        |
|    entropy               | -0.547      |
|    entropy_loss          | -0.548      |
|    explained_variance    | 0.662       |
|    lagrangian_multiplier | 0.00243     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.69        |
|    n_updates             | 8070        |
|    policy_gradient_loss  | 0.00341     |
|    std                   | 0.406       |
|    value_loss            | 10.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.32877892 |
| rollout/                 |             |
|    ep_len_mean           | 91          |
|    ep_rew_mean           | -36.8       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 25          |
|    time_elapsed          | 727         |
|    total_timesteps       | 1656832     |
| train/                   |             |
|    approx_kl             | 0.030843304 |
|    clip_fraction         | 0.135       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.09        |
|    cost_value_loss       | 9.73        |
|    cost_values           | 2.51        |
|    entropy               | -0.543      |
|    entropy_loss          | -0.546      |
|    explained_variance    | 0.658       |
|    lagrangian_multiplier | 0.0019      |
|    learning_rate         | 0.0003      |
|    loss                  | 6           |
|    n_updates             | 8080        |
|    policy_gradient_loss  | 0.000218    |
|    std                   | 0.406       |
|    value_loss            | 9.3         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.31185246 |
| rollout/                 |             |
|    ep_len_mean           | 95.3        |
|    ep_rew_mean           | -38         |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 26          |
|    time_elapsed          | 756         |
|    total_timesteps       | 1658880     |
| train/                   |             |
|    approx_kl             | 0.011687642 |
|    clip_fraction         | 0.21        |
|    clip_range            | 0.2         |
|    cost_returns          | 5.18        |
|    cost_value_loss       | 12.1        |
|    cost_values           | 2.54        |
|    entropy               | -0.541      |
|    entropy_loss          | -0.542      |
|    explained_variance    | 0.731       |
|    lagrangian_multiplier | 0.000868    |
|    learning_rate         | 0.0003      |
|    loss                  | 7.97        |
|    n_updates             | 8090        |
|    policy_gradient_loss  | 0.012       |
|    std                   | 0.406       |
|    value_loss            | 8.84        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.4         |
| reward                   | -0.13342948 |
| rollout/                 |             |
|    ep_len_mean           | 99.1        |
|    ep_rew_mean           | -39         |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 27          |
|    time_elapsed          | 785         |
|    total_timesteps       | 1660928     |
| train/                   |             |
|    approx_kl             | 0.010457637 |
|    clip_fraction         | 0.104       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.05        |
|    cost_value_loss       | 9.76        |
|    cost_values           | 2.53        |
|    entropy               | -0.532      |
|    entropy_loss          | -0.537      |
|    explained_variance    | 0.743       |
|    lagrangian_multiplier | 0.00115     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.4         |
|    n_updates             | 8100        |
|    policy_gradient_loss  | -0.00326    |
|    std                   | 0.404       |
|    value_loss            | 7.61        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.97        |
| reward                   | -0.39063752 |
| rollout/                 |             |
|    ep_len_mean           | 109         |
|    ep_rew_mean           | -42.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 28          |
|    time_elapsed          | 814         |
|    total_timesteps       | 1662976     |
| train/                   |             |
|    approx_kl             | 0.02037869  |
|    clip_fraction         | 0.161       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.92        |
|    cost_value_loss       | 8.46        |
|    cost_values           | 2.54        |
|    entropy               | -0.53       |
|    entropy_loss          | -0.53       |
|    explained_variance    | 0.686       |
|    lagrangian_multiplier | 0.00428     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.44        |
|    n_updates             | 8110        |
|    policy_gradient_loss  | 0.00344     |
|    std                   | 0.404       |
|    value_loss            | 8.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.7434198  |
| rollout/                 |             |
|    ep_len_mean           | 111         |
|    ep_rew_mean           | -42.8       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 29          |
|    time_elapsed          | 843         |
|    total_timesteps       | 1665024     |
| train/                   |             |
|    approx_kl             | 0.023400068 |
|    clip_fraction         | 0.245       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.35        |
|    cost_value_loss       | 3.69        |
|    cost_values           | 2.45        |
|    entropy               | -0.531      |
|    entropy_loss          | -0.532      |
|    explained_variance    | 0.595       |
|    lagrangian_multiplier | 0.000856    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.13        |
|    n_updates             | 8120        |
|    policy_gradient_loss  | 0.00784     |
|    std                   | 0.404       |
|    value_loss            | 7.49        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.19853124 |
| rollout/                 |             |
|    ep_len_mean           | 113         |
|    ep_rew_mean           | -43.3       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 30          |
|    time_elapsed          | 873         |
|    total_timesteps       | 1667072     |
| train/                   |             |
|    approx_kl             | 0.027763305 |
|    clip_fraction         | 0.174       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.87        |
|    cost_value_loss       | 9.27        |
|    cost_values           | 2.45        |
|    entropy               | -0.527      |
|    entropy_loss          | -0.529      |
|    explained_variance    | 0.63        |
|    lagrangian_multiplier | 0.000354    |
|    learning_rate         | 0.0003      |
|    loss                  | 9.09        |
|    n_updates             | 8130        |
|    policy_gradient_loss  | -0.00413    |
|    std                   | 0.405       |
|    value_loss            | 12          |
------------------------------------------
------------------------------------------
| avg_speed                | 7.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.84        |
| reward                   | -0.23534189 |
| rollout/                 |             |
|    ep_len_mean           | 116         |
|    ep_rew_mean           | -44.6       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 31          |
|    time_elapsed          | 902         |
|    total_timesteps       | 1669120     |
| train/                   |             |
|    approx_kl             | 0.023030158 |
|    clip_fraction         | 0.154       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.76        |
|    cost_value_loss       | 8.56        |
|    cost_values           | 2.48        |
|    entropy               | -0.521      |
|    entropy_loss          | -0.524      |
|    explained_variance    | 0.618       |
|    lagrangian_multiplier | 0.00176     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.64        |
|    n_updates             | 8140        |
|    policy_gradient_loss  | 0.00181     |
|    std                   | 0.403       |
|    value_loss            | 10.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.66575223 |
| rollout/                 |             |
|    ep_len_mean           | 113         |
|    ep_rew_mean           | -43.7       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 32          |
|    time_elapsed          | 931         |
|    total_timesteps       | 1671168     |
| train/                   |             |
|    approx_kl             | 0.03738306  |
|    clip_fraction         | 0.13        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.55        |
|    cost_value_loss       | 7.64        |
|    cost_values           | 2.44        |
|    entropy               | -0.517      |
|    entropy_loss          | -0.519      |
|    explained_variance    | 0.595       |
|    lagrangian_multiplier | 0.00246     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.32        |
|    n_updates             | 8150        |
|    policy_gradient_loss  | -0.00273    |
|    std                   | 0.403       |
|    value_loss            | 12.1        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.2         |
| reward                   | -0.7370402  |
| rollout/                 |             |
|    ep_len_mean           | 102         |
|    ep_rew_mean           | -40.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 33          |
|    time_elapsed          | 960         |
|    total_timesteps       | 1673216     |
| train/                   |             |
|    approx_kl             | 0.020286622 |
|    clip_fraction         | 0.155       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.98        |
|    cost_value_loss       | 11          |
|    cost_values           | 2.41        |
|    entropy               | -0.517      |
|    entropy_loss          | -0.517      |
|    explained_variance    | 0.622       |
|    lagrangian_multiplier | 0.000903    |
|    learning_rate         | 0.0003      |
|    loss                  | 8.83        |
|    n_updates             | 8160        |
|    policy_gradient_loss  | 0.00551     |
|    std                   | 0.404       |
|    value_loss            | 12.8        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.14         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 7.14         |
| reward                   | -0.38887417  |
| rollout/                 |              |
|    ep_len_mean           | 102          |
|    ep_rew_mean           | -40.4        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 34           |
|    time_elapsed          | 989          |
|    total_timesteps       | 1675264      |
| train/                   |              |
|    approx_kl             | 0.0134192575 |
|    clip_fraction         | 0.208        |
|    clip_range            | 0.2          |
|    cost_returns          | 5.2          |
|    cost_value_loss       | 12.1         |
|    cost_values           | 2.44         |
|    entropy               | -0.521       |
|    entropy_loss          | -0.519       |
|    explained_variance    | 0.638        |
|    lagrangian_multiplier | 0.00408      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.52         |
|    n_updates             | 8170         |
|    policy_gradient_loss  | 0.00799      |
|    std                   | 0.405        |
|    value_loss            | 12.1         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 5.4          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.4          |
| reward                   | -0.6138454   |
| rollout/                 |              |
|    ep_len_mean           | 97.1         |
|    ep_rew_mean           | -39.4        |
| time/                    |              |
|    fps                   | 70           |
|    iterations            | 35           |
|    time_elapsed          | 1019         |
|    total_timesteps       | 1677312      |
| train/                   |              |
|    approx_kl             | 0.0148098115 |
|    clip_fraction         | 0.127        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.6          |
|    cost_value_loss       | 8.98         |
|    cost_values           | 2.42         |
|    entropy               | -0.519       |
|    entropy_loss          | -0.52        |
|    explained_variance    | 0.621        |
|    lagrangian_multiplier | 0.00105      |
|    learning_rate         | 0.0003       |
|    loss                  | 7.48         |
|    n_updates             | 8180         |
|    policy_gradient_loss  | 0.000986     |
|    std                   | 0.406        |
|    value_loss            | 12.3         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.21268158 |
| rollout/                 |             |
|    ep_len_mean           | 97.5        |
|    ep_rew_mean           | -40         |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 36          |
|    time_elapsed          | 1048        |
|    total_timesteps       | 1679360     |
| train/                   |             |
|    approx_kl             | 0.010856439 |
|    clip_fraction         | 0.0953      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.91        |
|    cost_value_loss       | 11.8        |
|    cost_values           | 2.43        |
|    entropy               | -0.526      |
|    entropy_loss          | -0.522      |
|    explained_variance    | 0.733       |
|    lagrangian_multiplier | 0.00313     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.21        |
|    n_updates             | 8190        |
|    policy_gradient_loss  | -0.00383    |
|    std                   | 0.407       |
|    value_loss            | 11.3        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.23115486 |
| rollout/                 |             |
|    ep_len_mean           | 99.6        |
|    ep_rew_mean           | -40.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 37          |
|    time_elapsed          | 1078        |
|    total_timesteps       | 1681408     |
| train/                   |             |
|    approx_kl             | 0.04122073  |
|    clip_fraction         | 0.197       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.79        |
|    cost_value_loss       | 10.9        |
|    cost_values           | 2.41        |
|    entropy               | -0.52       |
|    entropy_loss          | -0.524      |
|    explained_variance    | 0.688       |
|    lagrangian_multiplier | 0.000911    |
|    learning_rate         | 0.0003      |
|    loss                  | 8.13        |
|    n_updates             | 8200        |
|    policy_gradient_loss  | 0.00459     |
|    std                   | 0.406       |
|    value_loss            | 10.5        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.35        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.35        |
| reward                   | -0.21353203 |
| rollout/                 |             |
|    ep_len_mean           | 98          |
|    ep_rew_mean           | -39.2       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 38          |
|    time_elapsed          | 1107        |
|    total_timesteps       | 1683456     |
| train/                   |             |
|    approx_kl             | 0.009176435 |
|    clip_fraction         | 0.108       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.16        |
|    cost_value_loss       | 11.4        |
|    cost_values           | 2.48        |
|    entropy               | -0.511      |
|    entropy_loss          | -0.515      |
|    explained_variance    | 0.682       |
|    lagrangian_multiplier | 0.0015      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.52        |
|    n_updates             | 8210        |
|    policy_gradient_loss  | 0.000649    |
|    std                   | 0.405       |
|    value_loss            | 8.87        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.4         |
| reward                   | -0.61488223 |
| rollout/                 |             |
|    ep_len_mean           | 94.4        |
|    ep_rew_mean           | -38         |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 39          |
|    time_elapsed          | 1136        |
|    total_timesteps       | 1685504     |
| train/                   |             |
|    approx_kl             | 0.02074599  |
|    clip_fraction         | 0.14        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.93        |
|    cost_value_loss       | 10          |
|    cost_values           | 2.53        |
|    entropy               | -0.507      |
|    entropy_loss          | -0.508      |
|    explained_variance    | 0.707       |
|    lagrangian_multiplier | 0.00177     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.33        |
|    n_updates             | 8220        |
|    policy_gradient_loss  | 0.000434    |
|    std                   | 0.405       |
|    value_loss            | 9.44        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.24936046 |
| rollout/                 |             |
|    ep_len_mean           | 96.8        |
|    ep_rew_mean           | -38.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 40          |
|    time_elapsed          | 1165        |
|    total_timesteps       | 1687552     |
| train/                   |             |
|    approx_kl             | 0.016074426 |
|    clip_fraction         | 0.18        |
|    clip_range            | 0.2         |
|    cost_returns          | 5.26        |
|    cost_value_loss       | 12.9        |
|    cost_values           | 2.55        |
|    entropy               | -0.5        |
|    entropy_loss          | -0.504      |
|    explained_variance    | 0.827       |
|    lagrangian_multiplier | 0.00421     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.97        |
|    n_updates             | 8230        |
|    policy_gradient_loss  | 0.00836     |
|    std                   | 0.403       |
|    value_loss            | 7.18        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.34337172 |
| rollout/                 |             |
|    ep_len_mean           | 90.2        |
|    ep_rew_mean           | -35.9       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 41          |
|    time_elapsed          | 1194        |
|    total_timesteps       | 1689600     |
| train/                   |             |
|    approx_kl             | 0.034623444 |
|    clip_fraction         | 0.179       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.01        |
|    cost_value_loss       | 10.6        |
|    cost_values           | 2.54        |
|    entropy               | -0.509      |
|    entropy_loss          | -0.504      |
|    explained_variance    | 0.741       |
|    lagrangian_multiplier | 0.00302     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.12        |
|    n_updates             | 8240        |
|    policy_gradient_loss  | 0.00636     |
|    std                   | 0.406       |
|    value_loss            | 7.31        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3921467  |
| rollout/                 |             |
|    ep_len_mean           | 83.5        |
|    ep_rew_mean           | -34.4       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 42          |
|    time_elapsed          | 1224        |
|    total_timesteps       | 1691648     |
| train/                   |             |
|    approx_kl             | 0.020950656 |
|    clip_fraction         | 0.221       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.08        |
|    cost_value_loss       | 12.3        |
|    cost_values           | 2.54        |
|    entropy               | -0.514      |
|    entropy_loss          | -0.512      |
|    explained_variance    | 0.795       |
|    lagrangian_multiplier | 0.00102     |
|    learning_rate         | 0.0003      |
|    loss                  | 7.44        |
|    n_updates             | 8250        |
|    policy_gradient_loss  | 0.00674     |
|    std                   | 0.407       |
|    value_loss            | 8.11        |
------------------------------------------
-----------------------------------------
| avg_speed                | 5.56       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 5.56       |
| reward                   | -0.2201541 |
| rollout/                 |            |
|    ep_len_mean           | 92.2       |
|    ep_rew_mean           | -36.9      |
| time/                    |            |
|    fps                   | 70         |
|    iterations            | 43         |
|    time_elapsed          | 1253       |
|    total_timesteps       | 1693696    |
| train/                   |            |
|    approx_kl             | 0.04185612 |
|    clip_fraction         | 0.171      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.57       |
|    cost_value_loss       | 8.38       |
|    cost_values           | 2.51       |
|    entropy               | -0.514     |
|    entropy_loss          | -0.514     |
|    explained_variance    | 0.787      |
|    lagrangian_multiplier | 0.00159    |
|    learning_rate         | 0.0003     |
|    loss                  | 5.66       |
|    n_updates             | 8260       |
|    policy_gradient_loss  | 0.00196    |
|    std                   | 0.407      |
|    value_loss            | 7.84       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.23479249 |
| rollout/                 |             |
|    ep_len_mean           | 94.6        |
|    ep_rew_mean           | -37.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 44          |
|    time_elapsed          | 1282        |
|    total_timesteps       | 1695744     |
| train/                   |             |
|    approx_kl             | 0.018477308 |
|    clip_fraction         | 0.191       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.34        |
|    cost_value_loss       | 12.3        |
|    cost_values           | 2.53        |
|    entropy               | -0.514      |
|    entropy_loss          | -0.514      |
|    explained_variance    | 0.718       |
|    lagrangian_multiplier | 0.00256     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.44        |
|    n_updates             | 8270        |
|    policy_gradient_loss  | 0.00448     |
|    std                   | 0.407       |
|    value_loss            | 6.71        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.37339294 |
| rollout/                 |             |
|    ep_len_mean           | 97.1        |
|    ep_rew_mean           | -38.4       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 45          |
|    time_elapsed          | 1311        |
|    total_timesteps       | 1697792     |
| train/                   |             |
|    approx_kl             | 0.012196029 |
|    clip_fraction         | 0.144       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.46        |
|    cost_value_loss       | 12.7        |
|    cost_values           | 2.6         |
|    entropy               | -0.507      |
|    entropy_loss          | -0.511      |
|    explained_variance    | 0.695       |
|    lagrangian_multiplier | 0.00589     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.51        |
|    n_updates             | 8280        |
|    policy_gradient_loss  | 0.00233     |
|    std                   | 0.406       |
|    value_loss            | 8.35        |
------------------------------------------
-----------------------------------------
| avg_speed                | 7.65       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.65       |
| reward                   | -0.1908196 |
| rollout/                 |            |
|    ep_len_mean           | 98.2       |
|    ep_rew_mean           | -38.9      |
| time/                    |            |
|    fps                   | 70         |
|    iterations            | 46         |
|    time_elapsed          | 1341       |
|    total_timesteps       | 1699840    |
| train/                   |            |
|    approx_kl             | 0.04141922 |
|    clip_fraction         | 0.186      |
|    clip_range            | 0.2        |
|    cost_returns          | 5.24       |
|    cost_value_loss       | 12.2       |
|    cost_values           | 2.63       |
|    entropy               | -0.503     |
|    entropy_loss          | -0.505     |
|    explained_variance    | 0.732      |
|    lagrangian_multiplier | 0.00252    |
|    learning_rate         | 0.0003     |
|    loss                  | 5.91       |
|    n_updates             | 8290       |
|    policy_gradient_loss  | 0.00682    |
|    std                   | 0.406      |
|    value_loss            | 7.52       |
-----------------------------------------
------------------------------------------
| avg_speed                | 3.51        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.51        |
| reward                   | -0.55661756 |
| rollout/                 |             |
|    ep_len_mean           | 103         |
|    ep_rew_mean           | -40.2       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 47          |
|    time_elapsed          | 1369        |
|    total_timesteps       | 1701888     |
| train/                   |             |
|    approx_kl             | 0.02931146  |
|    clip_fraction         | 0.194       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.68        |
|    cost_value_loss       | 8.89        |
|    cost_values           | 2.54        |
|    entropy               | -0.503      |
|    entropy_loss          | -0.504      |
|    explained_variance    | 0.694       |
|    lagrangian_multiplier | 0.00203     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.02        |
|    n_updates             | 8300        |
|    policy_gradient_loss  | 0.00626     |
|    std                   | 0.405       |
|    value_loss            | 10.7        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.28198755 |
| rollout/                 |             |
|    ep_len_mean           | 87.9        |
|    ep_rew_mean           | -36         |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 48          |
|    time_elapsed          | 1398        |
|    total_timesteps       | 1703936     |
| train/                   |             |
|    approx_kl             | 0.00751552  |
|    clip_fraction         | 0.116       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.52        |
|    cost_value_loss       | 7.48        |
|    cost_values           | 2.5         |
|    entropy               | -0.499      |
|    entropy_loss          | -0.501      |
|    explained_variance    | 0.693       |
|    lagrangian_multiplier | 0.00126     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.18        |
|    n_updates             | 8310        |
|    policy_gradient_loss  | -0.0019     |
|    std                   | 0.404       |
|    value_loss            | 9.63        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.71        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.71        |
| reward                   | -0.28178492 |
| rollout/                 |             |
|    ep_len_mean           | 92.5        |
|    ep_rew_mean           | -37         |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 49          |
|    time_elapsed          | 1427        |
|    total_timesteps       | 1705984     |
| train/                   |             |
|    approx_kl             | 0.031310394 |
|    clip_fraction         | 0.144       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.66        |
|    cost_value_loss       | 8.08        |
|    cost_values           | 2.52        |
|    entropy               | -0.505      |
|    entropy_loss          | -0.501      |
|    explained_variance    | 0.749       |
|    lagrangian_multiplier | 0.00195     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.38        |
|    n_updates             | 8320        |
|    policy_gradient_loss  | 0.00295     |
|    std                   | 0.404       |
|    value_loss            | 8.93        |
------------------------------------------
------------------------------------
| avg_speed          | 5.92        |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 5.92        |
| reward             | -0.23606943 |
| rollout/           |             |
|    ep_len_mean     | 93.1        |
|    ep_rew_mean     | -37.3       |
| time/              |             |
|    fps             | 77          |
|    iterations      | 1           |
|    time_elapsed    | 26          |
|    total_timesteps | 1708032     |
------------------------------------
------------------------------------------
| avg_speed                | 7.06        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.06        |
| reward                   | -0.31324092 |
| rollout/                 |             |
|    ep_len_mean           | 89.5        |
|    ep_rew_mean           | -35.7       |
| time/                    |             |
|    fps                   | 74          |
|    iterations            | 2           |
|    time_elapsed          | 55          |
|    total_timesteps       | 1710080     |
| train/                   |             |
|    approx_kl             | 0.036886733 |
|    clip_fraction         | 0.116       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.27        |
|    cost_value_loss       | 7.7         |
|    cost_values           | 2.45        |
|    entropy               | -0.497      |
|    entropy_loss          | -0.502      |
|    explained_variance    | 0.676       |
|    lagrangian_multiplier | 0.00174     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.39        |
|    n_updates             | 8340        |
|    policy_gradient_loss  | 0.000243    |
|    std                   | 0.402       |
|    value_loss            | 8.49        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.34        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.34        |
| reward                   | -0.45601082 |
| rollout/                 |             |
|    ep_len_mean           | 95          |
|    ep_rew_mean           | -37.1       |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 3           |
|    time_elapsed          | 84          |
|    total_timesteps       | 1712128     |
| train/                   |             |
|    approx_kl             | 0.012526615 |
|    clip_fraction         | 0.145       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.76        |
|    cost_value_loss       | 9.11        |
|    cost_values           | 2.49        |
|    entropy               | -0.49       |
|    entropy_loss          | -0.494      |
|    explained_variance    | 0.802       |
|    lagrangian_multiplier | 0.0007      |
|    learning_rate         | 0.0003      |
|    loss                  | 6.03        |
|    n_updates             | 8350        |
|    policy_gradient_loss  | 0.00564     |
|    std                   | 0.401       |
|    value_loss            | 6.53        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.22737701 |
| rollout/                 |             |
|    ep_len_mean           | 98.1        |
|    ep_rew_mean           | -38.2       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 4           |
|    time_elapsed          | 113         |
|    total_timesteps       | 1714176     |
| train/                   |             |
|    approx_kl             | 0.05731304  |
|    clip_fraction         | 0.162       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.54        |
|    cost_value_loss       | 7.45        |
|    cost_values           | 2.49        |
|    entropy               | -0.482      |
|    entropy_loss          | -0.485      |
|    explained_variance    | 0.692       |
|    lagrangian_multiplier | 0.00208     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.78        |
|    n_updates             | 8360        |
|    policy_gradient_loss  | 0.00553     |
|    std                   | 0.4         |
|    value_loss            | 7.21        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.22236776 |
| rollout/                 |             |
|    ep_len_mean           | 94.2        |
|    ep_rew_mean           | -37.2       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 5           |
|    time_elapsed          | 143         |
|    total_timesteps       | 1716224     |
| train/                   |             |
|    approx_kl             | 0.01984173  |
|    clip_fraction         | 0.171       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.92        |
|    cost_value_loss       | 11.2        |
|    cost_values           | 2.45        |
|    entropy               | -0.475      |
|    entropy_loss          | -0.479      |
|    explained_variance    | 0.775       |
|    lagrangian_multiplier | 0.00196     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.04        |
|    n_updates             | 8370        |
|    policy_gradient_loss  | 0.0049      |
|    std                   | 0.399       |
|    value_loss            | 7.46        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.27712905 |
| rollout/                 |             |
|    ep_len_mean           | 94.6        |
|    ep_rew_mean           | -37.4       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 6           |
|    time_elapsed          | 172         |
|    total_timesteps       | 1718272     |
| train/                   |             |
|    approx_kl             | 0.019193092 |
|    clip_fraction         | 0.168       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.98        |
|    cost_value_loss       | 10.2        |
|    cost_values           | 2.43        |
|    entropy               | -0.466      |
|    entropy_loss          | -0.47       |
|    explained_variance    | 0.775       |
|    lagrangian_multiplier | 0.00373     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.72        |
|    n_updates             | 8380        |
|    policy_gradient_loss  | 0.00547     |
|    std                   | 0.396       |
|    value_loss            | 7.22        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 1           |
| max_speed                | 8.01        |
| reward                   | -0.09566446 |
| rollout/                 |             |
|    ep_len_mean           | 95.2        |
|    ep_rew_mean           | -37.8       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 7           |
|    time_elapsed          | 201         |
|    total_timesteps       | 1720320     |
| train/                   |             |
|    approx_kl             | 0.023888087 |
|    clip_fraction         | 0.136       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.37        |
|    cost_value_loss       | 13.8        |
|    cost_values           | 2.43        |
|    entropy               | -0.461      |
|    entropy_loss          | -0.462      |
|    explained_variance    | 0.767       |
|    lagrangian_multiplier | 0.00295     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.82        |
|    n_updates             | 8390        |
|    policy_gradient_loss  | 0.00222     |
|    std                   | 0.395       |
|    value_loss            | 8.03        |
------------------------------------------
-----------------------------------------
| avg_speed                | 1.2        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 1.2        |
| reward                   | -0.7531441 |
| rollout/                 |            |
|    ep_len_mean           | 94.8       |
|    ep_rew_mean           | -38.2      |
| time/                    |            |
|    fps                   | 70         |
|    iterations            | 8          |
|    time_elapsed          | 230        |
|    total_timesteps       | 1722368    |
| train/                   |            |
|    approx_kl             | 0.00833502 |
|    clip_fraction         | 0.16       |
|    clip_range            | 0.2        |
|    cost_returns          | 4.58       |
|    cost_value_loss       | 7.87       |
|    cost_values           | 2.46       |
|    entropy               | -0.464     |
|    entropy_loss          | -0.463     |
|    explained_variance    | 0.793      |
|    lagrangian_multiplier | 0.00108    |
|    learning_rate         | 0.0003     |
|    loss                  | 5.34       |
|    n_updates             | 8400       |
|    policy_gradient_loss  | 0.00638    |
|    std                   | 0.397      |
|    value_loss            | 6.61       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.36909103 |
| rollout/                 |             |
|    ep_len_mean           | 95          |
|    ep_rew_mean           | -38.2       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 9           |
|    time_elapsed          | 260         |
|    total_timesteps       | 1724416     |
| train/                   |             |
|    approx_kl             | 0.015203297 |
|    clip_fraction         | 0.162       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.78        |
|    cost_value_loss       | 9.06        |
|    cost_values           | 2.47        |
|    entropy               | -0.465      |
|    entropy_loss          | -0.465      |
|    explained_variance    | 0.713       |
|    lagrangian_multiplier | 0.00188     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.41        |
|    n_updates             | 8410        |
|    policy_gradient_loss  | 0.00323     |
|    std                   | 0.398       |
|    value_loss            | 8.36        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.87        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.87        |
| reward                   | -0.2636794  |
| rollout/                 |             |
|    ep_len_mean           | 88.1        |
|    ep_rew_mean           | -36.4       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 10          |
|    time_elapsed          | 289         |
|    total_timesteps       | 1726464     |
| train/                   |             |
|    approx_kl             | 0.012344844 |
|    clip_fraction         | 0.163       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.69        |
|    cost_value_loss       | 8.75        |
|    cost_values           | 2.44        |
|    entropy               | -0.46       |
|    entropy_loss          | -0.463      |
|    explained_variance    | 0.703       |
|    lagrangian_multiplier | 0.00201     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.54        |
|    n_updates             | 8420        |
|    policy_gradient_loss  | 0.00273     |
|    std                   | 0.396       |
|    value_loss            | 8.64        |
------------------------------------------
------------------------------------------
| avg_speed                | 6           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6           |
| reward                   | -0.37408164 |
| rollout/                 |             |
|    ep_len_mean           | 88.2        |
|    ep_rew_mean           | -36.8       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 11          |
|    time_elapsed          | 319         |
|    total_timesteps       | 1728512     |
| train/                   |             |
|    approx_kl             | 0.010472462 |
|    clip_fraction         | 0.162       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.24        |
|    cost_value_loss       | 7.46        |
|    cost_values           | 2.39        |
|    entropy               | -0.45       |
|    entropy_loss          | -0.454      |
|    explained_variance    | 0.805       |
|    lagrangian_multiplier | 0.000544    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.93        |
|    n_updates             | 8430        |
|    policy_gradient_loss  | 0.00631     |
|    std                   | 0.394       |
|    value_loss            | 7.2         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.42772618 |
| rollout/                 |             |
|    ep_len_mean           | 83.3        |
|    ep_rew_mean           | -35.2       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 12          |
|    time_elapsed          | 348         |
|    total_timesteps       | 1730560     |
| train/                   |             |
|    approx_kl             | 0.016708761 |
|    clip_fraction         | 0.135       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.32        |
|    cost_value_loss       | 7.82        |
|    cost_values           | 2.36        |
|    entropy               | -0.441      |
|    entropy_loss          | -0.445      |
|    explained_variance    | 0.786       |
|    lagrangian_multiplier | 0.000404    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.96        |
|    n_updates             | 8440        |
|    policy_gradient_loss  | 0.00572     |
|    std                   | 0.393       |
|    value_loss            | 6.8         |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.63638    |
| rollout/                 |             |
|    ep_len_mean           | 83.5        |
|    ep_rew_mean           | -35.3       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 13          |
|    time_elapsed          | 378         |
|    total_timesteps       | 1732608     |
| train/                   |             |
|    approx_kl             | 0.020451132 |
|    clip_fraction         | 0.155       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.87        |
|    cost_value_loss       | 10.9        |
|    cost_values           | 2.41        |
|    entropy               | -0.443      |
|    entropy_loss          | -0.442      |
|    explained_variance    | 0.725       |
|    lagrangian_multiplier | 0.00305     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.22        |
|    n_updates             | 8450        |
|    policy_gradient_loss  | 0.000282    |
|    std                   | 0.394       |
|    value_loss            | 8.78        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.2         |
| reward                   | -0.9425638  |
| rollout/                 |             |
|    ep_len_mean           | 87.3        |
|    ep_rew_mean           | -36.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 14          |
|    time_elapsed          | 408         |
|    total_timesteps       | 1734656     |
| train/                   |             |
|    approx_kl             | 0.023366883 |
|    clip_fraction         | 0.176       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.87        |
|    cost_value_loss       | 10.9        |
|    cost_values           | 2.42        |
|    entropy               | -0.44       |
|    entropy_loss          | -0.443      |
|    explained_variance    | 0.811       |
|    lagrangian_multiplier | 0.00274     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.01        |
|    n_updates             | 8460        |
|    policy_gradient_loss  | 0.00472     |
|    std                   | 0.394       |
|    value_loss            | 6.56        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.577133   |
| rollout/                 |             |
|    ep_len_mean           | 83.2        |
|    ep_rew_mean           | -35.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 15          |
|    time_elapsed          | 437         |
|    total_timesteps       | 1736704     |
| train/                   |             |
|    approx_kl             | 0.022516793 |
|    clip_fraction         | 0.153       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.51        |
|    cost_value_loss       | 8.56        |
|    cost_values           | 2.36        |
|    entropy               | -0.434      |
|    entropy_loss          | -0.437      |
|    explained_variance    | 0.728       |
|    lagrangian_multiplier | 0.000374    |
|    learning_rate         | 0.0003      |
|    loss                  | 6.97        |
|    n_updates             | 8470        |
|    policy_gradient_loss  | -0.00172    |
|    std                   | 0.394       |
|    value_loss            | 8.2         |
------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.72147506 |
| rollout/                 |             |
|    ep_len_mean           | 85.7        |
|    ep_rew_mean           | -35.7       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 16          |
|    time_elapsed          | 466         |
|    total_timesteps       | 1738752     |
| train/                   |             |
|    approx_kl             | 0.00867482  |
|    clip_fraction         | 0.102       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.4         |
|    cost_value_loss       | 8.14        |
|    cost_values           | 2.33        |
|    entropy               | -0.429      |
|    entropy_loss          | -0.431      |
|    explained_variance    | 0.796       |
|    lagrangian_multiplier | 0.000917    |
|    learning_rate         | 0.0003      |
|    loss                  | 6.32        |
|    n_updates             | 8480        |
|    policy_gradient_loss  | 6.72e-05    |
|    std                   | 0.393       |
|    value_loss            | 8.06        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.91        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.91        |
| reward                   | -0.38956782 |
| rollout/                 |             |
|    ep_len_mean           | 83.5        |
|    ep_rew_mean           | -34.9       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 17          |
|    time_elapsed          | 495         |
|    total_timesteps       | 1740800     |
| train/                   |             |
|    approx_kl             | 0.014083432 |
|    clip_fraction         | 0.124       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.7         |
|    cost_value_loss       | 9.8         |
|    cost_values           | 2.33        |
|    entropy               | -0.419      |
|    entropy_loss          | -0.424      |
|    explained_variance    | 0.79        |
|    lagrangian_multiplier | 0.00332     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.49        |
|    n_updates             | 8490        |
|    policy_gradient_loss  | 0.00325     |
|    std                   | 0.39        |
|    value_loss            | 6.94        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.6         |
| reward                   | -0.8390885  |
| rollout/                 |             |
|    ep_len_mean           | 87          |
|    ep_rew_mean           | -35.9       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 18          |
|    time_elapsed          | 524         |
|    total_timesteps       | 1742848     |
| train/                   |             |
|    approx_kl             | 0.063388266 |
|    clip_fraction         | 0.19        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.95        |
|    cost_value_loss       | 11.8        |
|    cost_values           | 2.4         |
|    entropy               | -0.409      |
|    entropy_loss          | -0.414      |
|    explained_variance    | 0.859       |
|    lagrangian_multiplier | 0.00171     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.88        |
|    n_updates             | 8500        |
|    policy_gradient_loss  | 0.00368     |
|    std                   | 0.389       |
|    value_loss            | 5.42        |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.9089067  |
| rollout/                 |             |
|    ep_len_mean           | 91          |
|    ep_rew_mean           | -36.7       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 19          |
|    time_elapsed          | 553         |
|    total_timesteps       | 1744896     |
| train/                   |             |
|    approx_kl             | 0.034220606 |
|    clip_fraction         | 0.217       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.96        |
|    cost_value_loss       | 10.1        |
|    cost_values           | 2.44        |
|    entropy               | -0.411      |
|    entropy_loss          | -0.41       |
|    explained_variance    | 0.719       |
|    lagrangian_multiplier | 0.00205     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.45        |
|    n_updates             | 8510        |
|    policy_gradient_loss  | 0.00846     |
|    std                   | 0.39        |
|    value_loss            | 7.31        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8.02       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.02       |
| reward                   | -0.2938265 |
| rollout/                 |            |
|    ep_len_mean           | 91.8       |
|    ep_rew_mean           | -37.1      |
| time/                    |            |
|    fps                   | 70         |
|    iterations            | 20         |
|    time_elapsed          | 583        |
|    total_timesteps       | 1746944    |
| train/                   |            |
|    approx_kl             | 0.01009652 |
|    clip_fraction         | 0.134      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.88       |
|    cost_value_loss       | 10.7       |
|    cost_values           | 2.46       |
|    entropy               | -0.404     |
|    entropy_loss          | -0.408     |
|    explained_variance    | 0.762      |
|    lagrangian_multiplier | 0.00232    |
|    learning_rate         | 0.0003     |
|    loss                  | 5.49       |
|    n_updates             | 8520       |
|    policy_gradient_loss  | 0.00031    |
|    std                   | 0.389      |
|    value_loss            | 7.43       |
-----------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.35364062 |
| rollout/                 |             |
|    ep_len_mean           | 91.8        |
|    ep_rew_mean           | -36.9       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 21          |
|    time_elapsed          | 612         |
|    total_timesteps       | 1748992     |
| train/                   |             |
|    approx_kl             | 0.023128802 |
|    clip_fraction         | 0.192       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.78        |
|    cost_value_loss       | 9.26        |
|    cost_values           | 2.43        |
|    entropy               | -0.404      |
|    entropy_loss          | -0.404      |
|    explained_variance    | 0.788       |
|    lagrangian_multiplier | 0.0018      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.58        |
|    n_updates             | 8530        |
|    policy_gradient_loss  | 0.0104      |
|    std                   | 0.389       |
|    value_loss            | 6.84        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.3035273  |
| rollout/                 |             |
|    ep_len_mean           | 88.2        |
|    ep_rew_mean           | -35.8       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 22          |
|    time_elapsed          | 642         |
|    total_timesteps       | 1751040     |
| train/                   |             |
|    approx_kl             | 0.030449215 |
|    clip_fraction         | 0.182       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.59        |
|    cost_value_loss       | 8.75        |
|    cost_values           | 2.41        |
|    entropy               | -0.405      |
|    entropy_loss          | -0.405      |
|    explained_variance    | 0.809       |
|    lagrangian_multiplier | 0.00222     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.96        |
|    n_updates             | 8540        |
|    policy_gradient_loss  | 0.00542     |
|    std                   | 0.39        |
|    value_loss            | 7.05        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.79619116 |
| rollout/                 |             |
|    ep_len_mean           | 82          |
|    ep_rew_mean           | -34.3       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 23          |
|    time_elapsed          | 671         |
|    total_timesteps       | 1753088     |
| train/                   |             |
|    approx_kl             | 0.02213221  |
|    clip_fraction         | 0.172       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.72        |
|    cost_value_loss       | 9.36        |
|    cost_values           | 2.39        |
|    entropy               | -0.4        |
|    entropy_loss          | -0.402      |
|    explained_variance    | 0.766       |
|    lagrangian_multiplier | 0.00118     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.05        |
|    n_updates             | 8550        |
|    policy_gradient_loss  | 0.00345     |
|    std                   | 0.389       |
|    value_loss            | 7.6         |
------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.51953864 |
| rollout/                 |             |
|    ep_len_mean           | 78.4        |
|    ep_rew_mean           | -33.4       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 24          |
|    time_elapsed          | 701         |
|    total_timesteps       | 1755136     |
| train/                   |             |
|    approx_kl             | 0.011615837 |
|    clip_fraction         | 0.146       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.54        |
|    cost_value_loss       | 9.11        |
|    cost_values           | 2.38        |
|    entropy               | -0.393      |
|    entropy_loss          | -0.397      |
|    explained_variance    | 0.797       |
|    lagrangian_multiplier | 0.0031      |
|    learning_rate         | 0.0003      |
|    loss                  | 5           |
|    n_updates             | 8560        |
|    policy_gradient_loss  | 0.0024      |
|    std                   | 0.389       |
|    value_loss            | 8.13        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.23057158 |
| rollout/                 |             |
|    ep_len_mean           | 81          |
|    ep_rew_mean           | -34.2       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 25          |
|    time_elapsed          | 730         |
|    total_timesteps       | 1757184     |
| train/                   |             |
|    approx_kl             | 0.013394048 |
|    clip_fraction         | 0.117       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.49        |
|    cost_value_loss       | 8.74        |
|    cost_values           | 2.35        |
|    entropy               | -0.38       |
|    entropy_loss          | -0.388      |
|    explained_variance    | 0.78        |
|    lagrangian_multiplier | 0.000887    |
|    learning_rate         | 0.0003      |
|    loss                  | 6.71        |
|    n_updates             | 8570        |
|    policy_gradient_loss  | -0.000489   |
|    std                   | 0.385       |
|    value_loss            | 7.61        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.1517655  |
| rollout/                 |             |
|    ep_len_mean           | 77.7        |
|    ep_rew_mean           | -33.2       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 26          |
|    time_elapsed          | 761         |
|    total_timesteps       | 1759232     |
| train/                   |             |
|    approx_kl             | 0.008580473 |
|    clip_fraction         | 0.128       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.86        |
|    cost_value_loss       | 10          |
|    cost_values           | 2.38        |
|    entropy               | -0.371      |
|    entropy_loss          | -0.374      |
|    explained_variance    | 0.786       |
|    lagrangian_multiplier | 0.00149     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.56        |
|    n_updates             | 8580        |
|    policy_gradient_loss  | -0.00121    |
|    std                   | 0.383       |
|    value_loss            | 6.82        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.4         |
| reward                   | -0.2533422  |
| rollout/                 |             |
|    ep_len_mean           | 81.3        |
|    ep_rew_mean           | -34         |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 27          |
|    time_elapsed          | 790         |
|    total_timesteps       | 1761280     |
| train/                   |             |
|    approx_kl             | 0.021303182 |
|    clip_fraction         | 0.146       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.57        |
|    cost_value_loss       | 8.92        |
|    cost_values           | 2.33        |
|    entropy               | -0.371      |
|    entropy_loss          | -0.37       |
|    explained_variance    | 0.802       |
|    lagrangian_multiplier | 0.00127     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.86        |
|    n_updates             | 8590        |
|    policy_gradient_loss  | 0.00242     |
|    std                   | 0.383       |
|    value_loss            | 7.4         |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.27242795  |
| rollout/                 |              |
|    ep_len_mean           | 78.3         |
|    ep_rew_mean           | -33          |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 28           |
|    time_elapsed          | 819          |
|    total_timesteps       | 1763328      |
| train/                   |              |
|    approx_kl             | 0.0092246495 |
|    clip_fraction         | 0.15         |
|    clip_range            | 0.2          |
|    cost_returns          | 4.74         |
|    cost_value_loss       | 9.91         |
|    cost_values           | 2.36         |
|    entropy               | -0.363       |
|    entropy_loss          | -0.368       |
|    explained_variance    | 0.804        |
|    lagrangian_multiplier | 0.000634     |
|    learning_rate         | 0.0003       |
|    loss                  | 6.62         |
|    n_updates             | 8600         |
|    policy_gradient_loss  | 0.00499      |
|    std                   | 0.381        |
|    value_loss            | 6.67         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.20959462 |
| rollout/                 |             |
|    ep_len_mean           | 77.9        |
|    ep_rew_mean           | -32.9       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 29          |
|    time_elapsed          | 849         |
|    total_timesteps       | 1765376     |
| train/                   |             |
|    approx_kl             | 0.019990334 |
|    clip_fraction         | 0.143       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.45        |
|    cost_value_loss       | 8.14        |
|    cost_values           | 2.38        |
|    entropy               | -0.366      |
|    entropy_loss          | -0.364      |
|    explained_variance    | 0.81        |
|    lagrangian_multiplier | 0.00155     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.88        |
|    n_updates             | 8610        |
|    policy_gradient_loss  | -0.00027    |
|    std                   | 0.383       |
|    value_loss            | 6.47        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.19        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.19        |
| reward                   | -0.6790282  |
| rollout/                 |             |
|    ep_len_mean           | 80.9        |
|    ep_rew_mean           | -33.9       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 30          |
|    time_elapsed          | 878         |
|    total_timesteps       | 1767424     |
| train/                   |             |
|    approx_kl             | 0.022184271 |
|    clip_fraction         | 0.182       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.77        |
|    cost_value_loss       | 10.2        |
|    cost_values           | 2.41        |
|    entropy               | -0.366      |
|    entropy_loss          | -0.367      |
|    explained_variance    | 0.849       |
|    lagrangian_multiplier | 0.00204     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.96        |
|    n_updates             | 8620        |
|    policy_gradient_loss  | 0.00321     |
|    std                   | 0.382       |
|    value_loss            | 5.03        |
------------------------------------------
------------------------------------------
| avg_speed                | 3           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3           |
| reward                   | -0.8671699  |
| rollout/                 |             |
|    ep_len_mean           | 80.7        |
|    ep_rew_mean           | -33.8       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 31          |
|    time_elapsed          | 908         |
|    total_timesteps       | 1769472     |
| train/                   |             |
|    approx_kl             | 0.024332982 |
|    clip_fraction         | 0.182       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.36        |
|    cost_value_loss       | 8.48        |
|    cost_values           | 2.36        |
|    entropy               | -0.36       |
|    entropy_loss          | -0.364      |
|    explained_variance    | 0.818       |
|    lagrangian_multiplier | 0.00243     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.36        |
|    n_updates             | 8630        |
|    policy_gradient_loss  | 0.00635     |
|    std                   | 0.382       |
|    value_loss            | 6.53        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.2752849  |
| rollout/                 |             |
|    ep_len_mean           | 86.8        |
|    ep_rew_mean           | -35.5       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 32          |
|    time_elapsed          | 937         |
|    total_timesteps       | 1771520     |
| train/                   |             |
|    approx_kl             | 0.017376814 |
|    clip_fraction         | 0.163       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.91        |
|    cost_value_loss       | 11.1        |
|    cost_values           | 2.39        |
|    entropy               | -0.359      |
|    entropy_loss          | -0.359      |
|    explained_variance    | 0.841       |
|    lagrangian_multiplier | 0.00237     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.69        |
|    n_updates             | 8640        |
|    policy_gradient_loss  | 0.00324     |
|    std                   | 0.382       |
|    value_loss            | 5.47        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.36860168 |
| rollout/                 |             |
|    ep_len_mean           | 89          |
|    ep_rew_mean           | -36.3       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 33          |
|    time_elapsed          | 966         |
|    total_timesteps       | 1773568     |
| train/                   |             |
|    approx_kl             | 0.024721213 |
|    clip_fraction         | 0.195       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.41        |
|    cost_value_loss       | 12.8        |
|    cost_values           | 2.47        |
|    entropy               | -0.358      |
|    entropy_loss          | -0.358      |
|    explained_variance    | 0.801       |
|    lagrangian_multiplier | 0.00255     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.32        |
|    n_updates             | 8650        |
|    policy_gradient_loss  | 0.00865     |
|    std                   | 0.382       |
|    value_loss            | 5.13        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.43434024 |
| rollout/                 |             |
|    ep_len_mean           | 87.8        |
|    ep_rew_mean           | -35.6       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 34          |
|    time_elapsed          | 995         |
|    total_timesteps       | 1775616     |
| train/                   |             |
|    approx_kl             | 0.030903323 |
|    clip_fraction         | 0.182       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.74        |
|    cost_value_loss       | 10          |
|    cost_values           | 2.45        |
|    entropy               | -0.365      |
|    entropy_loss          | -0.361      |
|    explained_variance    | 0.793       |
|    lagrangian_multiplier | 0.00205     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.05        |
|    n_updates             | 8660        |
|    policy_gradient_loss  | 0.0058      |
|    std                   | 0.384       |
|    value_loss            | 6.61        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.5178041  |
| rollout/                 |             |
|    ep_len_mean           | 90.8        |
|    ep_rew_mean           | -36.2       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 35          |
|    time_elapsed          | 1024        |
|    total_timesteps       | 1777664     |
| train/                   |             |
|    approx_kl             | 0.007972013 |
|    clip_fraction         | 0.156       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.41        |
|    cost_value_loss       | 8.5         |
|    cost_values           | 2.39        |
|    entropy               | -0.366      |
|    entropy_loss          | -0.366      |
|    explained_variance    | 0.842       |
|    lagrangian_multiplier | 0.000812    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.76        |
|    n_updates             | 8670        |
|    policy_gradient_loss  | 0.00391     |
|    std                   | 0.384       |
|    value_loss            | 6.14        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.73        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.73        |
| reward                   | -0.25495344 |
| rollout/                 |             |
|    ep_len_mean           | 88.8        |
|    ep_rew_mean           | -35.7       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 36          |
|    time_elapsed          | 1055        |
|    total_timesteps       | 1779712     |
| train/                   |             |
|    approx_kl             | 0.03590078  |
|    clip_fraction         | 0.2         |
|    clip_range            | 0.2         |
|    cost_returns          | 4.97        |
|    cost_value_loss       | 11.3        |
|    cost_values           | 2.4         |
|    entropy               | -0.36       |
|    entropy_loss          | -0.362      |
|    explained_variance    | 0.785       |
|    lagrangian_multiplier | 0.00297     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.75        |
|    n_updates             | 8680        |
|    policy_gradient_loss  | 0.00724     |
|    std                   | 0.384       |
|    value_loss            | 6.66        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.1637906 |
| rollout/                 |            |
|    ep_len_mean           | 85.3       |
|    ep_rew_mean           | -34.7      |
| time/                    |            |
|    fps                   | 69         |
|    iterations            | 37         |
|    time_elapsed          | 1084       |
|    total_timesteps       | 1781760    |
| train/                   |            |
|    approx_kl             | 0.03358816 |
|    clip_fraction         | 0.194      |
|    clip_range            | 0.2        |
|    cost_returns          | 5.33       |
|    cost_value_loss       | 13.4       |
|    cost_values           | 2.45       |
|    entropy               | -0.353     |
|    entropy_loss          | -0.356     |
|    explained_variance    | 0.832      |
|    lagrangian_multiplier | 0.00178    |
|    learning_rate         | 0.0003     |
|    loss                  | 6.15       |
|    n_updates             | 8690       |
|    policy_gradient_loss  | 0.00957    |
|    std                   | 0.383      |
|    value_loss            | 5.38       |
-----------------------------------------
-----------------------------------------
| avg_speed                | 8.01       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.01       |
| reward                   | -0.3202019 |
| rollout/                 |            |
|    ep_len_mean           | 87.4       |
|    ep_rew_mean           | -35.4      |
| time/                    |            |
|    fps                   | 69         |
|    iterations            | 38         |
|    time_elapsed          | 1113       |
|    total_timesteps       | 1783808    |
| train/                   |            |
|    approx_kl             | 0.03972768 |
|    clip_fraction         | 0.195      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.98       |
|    cost_value_loss       | 11.8       |
|    cost_values           | 2.43       |
|    entropy               | -0.348     |
|    entropy_loss          | -0.35      |
|    explained_variance    | 0.817      |
|    lagrangian_multiplier | 0.00233    |
|    learning_rate         | 0.0003     |
|    loss                  | 5.42       |
|    n_updates             | 8700       |
|    policy_gradient_loss  | 0.00798    |
|    std                   | 0.383      |
|    value_loss            | 5.96       |
-----------------------------------------
------------------------------------------
| avg_speed                | 5.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.6         |
| reward                   | -0.45236275 |
| rollout/                 |             |
|    ep_len_mean           | 90.6        |
|    ep_rew_mean           | -36.5       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 39          |
|    time_elapsed          | 1142        |
|    total_timesteps       | 1785856     |
| train/                   |             |
|    approx_kl             | 0.015338246 |
|    clip_fraction         | 0.161       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.88        |
|    cost_value_loss       | 10.1        |
|    cost_values           | 2.43        |
|    entropy               | -0.34       |
|    entropy_loss          | -0.344      |
|    explained_variance    | 0.825       |
|    lagrangian_multiplier | 0.00202     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.14        |
|    n_updates             | 8710        |
|    policy_gradient_loss  | 0.0045      |
|    std                   | 0.381       |
|    value_loss            | 5.86        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.55670494 |
| rollout/                 |             |
|    ep_len_mean           | 89.5        |
|    ep_rew_mean           | -36.3       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 40          |
|    time_elapsed          | 1172        |
|    total_timesteps       | 1787904     |
| train/                   |             |
|    approx_kl             | 0.012200477 |
|    clip_fraction         | 0.2         |
|    clip_range            | 0.2         |
|    cost_returns          | 5.22        |
|    cost_value_loss       | 12.3        |
|    cost_values           | 2.46        |
|    entropy               | -0.341      |
|    entropy_loss          | -0.339      |
|    explained_variance    | 0.807       |
|    lagrangian_multiplier | 0.00255     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.29        |
|    n_updates             | 8720        |
|    policy_gradient_loss  | 0.00667     |
|    std                   | 0.381       |
|    value_loss            | 6.38        |
------------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.7024032  |
| rollout/                 |             |
|    ep_len_mean           | 83.8        |
|    ep_rew_mean           | -34.3       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 41          |
|    time_elapsed          | 1202        |
|    total_timesteps       | 1789952     |
| train/                   |             |
|    approx_kl             | 0.013497472 |
|    clip_fraction         | 0.186       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.91        |
|    cost_value_loss       | 10.1        |
|    cost_values           | 2.45        |
|    entropy               | -0.346      |
|    entropy_loss          | -0.344      |
|    explained_variance    | 0.758       |
|    lagrangian_multiplier | 0.00352     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.66        |
|    n_updates             | 8730        |
|    policy_gradient_loss  | 0.00308     |
|    std                   | 0.381       |
|    value_loss            | 7.91        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.7245547  |
| rollout/                 |             |
|    ep_len_mean           | 81.8        |
|    ep_rew_mean           | -34         |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 42          |
|    time_elapsed          | 1231        |
|    total_timesteps       | 1792000     |
| train/                   |             |
|    approx_kl             | 0.013918248 |
|    clip_fraction         | 0.211       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.51        |
|    cost_value_loss       | 8.81        |
|    cost_values           | 2.4         |
|    entropy               | -0.346      |
|    entropy_loss          | -0.346      |
|    explained_variance    | 0.85        |
|    lagrangian_multiplier | 0.000748    |
|    learning_rate         | 0.0003      |
|    loss                  | 6.02        |
|    n_updates             | 8740        |
|    policy_gradient_loss  | 0.0032      |
|    std                   | 0.381       |
|    value_loss            | 5.98        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.33065182 |
| rollout/                 |             |
|    ep_len_mean           | 76.6        |
|    ep_rew_mean           | -32.3       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 43          |
|    time_elapsed          | 1261        |
|    total_timesteps       | 1794048     |
| train/                   |             |
|    approx_kl             | 0.03523475  |
|    clip_fraction         | 0.153       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.74        |
|    cost_value_loss       | 10.6        |
|    cost_values           | 2.44        |
|    entropy               | -0.349      |
|    entropy_loss          | -0.347      |
|    explained_variance    | 0.834       |
|    lagrangian_multiplier | 0.00174     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.36        |
|    n_updates             | 8750        |
|    policy_gradient_loss  | 0.00583     |
|    std                   | 0.382       |
|    value_loss            | 5.87        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.3141353  |
| rollout/                 |             |
|    ep_len_mean           | 79.3        |
|    ep_rew_mean           | -33.4       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 44          |
|    time_elapsed          | 1290        |
|    total_timesteps       | 1796096     |
| train/                   |             |
|    approx_kl             | 0.024127943 |
|    clip_fraction         | 0.182       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.86        |
|    cost_value_loss       | 9.96        |
|    cost_values           | 2.46        |
|    entropy               | -0.355      |
|    entropy_loss          | -0.352      |
|    explained_variance    | 0.832       |
|    lagrangian_multiplier | 0.00475     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.01        |
|    n_updates             | 8760        |
|    policy_gradient_loss  | 0.00208     |
|    std                   | 0.383       |
|    value_loss            | 5.75        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.31        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.31        |
| reward                   | -0.4721784  |
| rollout/                 |             |
|    ep_len_mean           | 84.2        |
|    ep_rew_mean           | -34.8       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 45          |
|    time_elapsed          | 1320        |
|    total_timesteps       | 1798144     |
| train/                   |             |
|    approx_kl             | 0.009511694 |
|    clip_fraction         | 0.145       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.21        |
|    cost_value_loss       | 11.6        |
|    cost_values           | 2.44        |
|    entropy               | -0.366      |
|    entropy_loss          | -0.36       |
|    explained_variance    | 0.787       |
|    lagrangian_multiplier | 0.00341     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.65        |
|    n_updates             | 8770        |
|    policy_gradient_loss  | 0.00298     |
|    std                   | 0.385       |
|    value_loss            | 6.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.18517359 |
| rollout/                 |             |
|    ep_len_mean           | 85.8        |
|    ep_rew_mean           | -35.2       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 46          |
|    time_elapsed          | 1349        |
|    total_timesteps       | 1800192     |
| train/                   |             |
|    approx_kl             | 0.010987103 |
|    clip_fraction         | 0.154       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.83        |
|    cost_value_loss       | 9.81        |
|    cost_values           | 2.47        |
|    entropy               | -0.376      |
|    entropy_loss          | -0.372      |
|    explained_variance    | 0.788       |
|    lagrangian_multiplier | 0.00161     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.47        |
|    n_updates             | 8780        |
|    policy_gradient_loss  | 0.00356     |
|    std                   | 0.387       |
|    value_loss            | 6.52        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.34245896 |
| rollout/                 |             |
|    ep_len_mean           | 84.7        |
|    ep_rew_mean           | -34.6       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 47          |
|    time_elapsed          | 1378        |
|    total_timesteps       | 1802240     |
| train/                   |             |
|    approx_kl             | 0.011548083 |
|    clip_fraction         | 0.138       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.14        |
|    cost_value_loss       | 11.1        |
|    cost_values           | 2.45        |
|    entropy               | -0.369      |
|    entropy_loss          | -0.374      |
|    explained_variance    | 0.748       |
|    lagrangian_multiplier | 0.00159     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.98        |
|    n_updates             | 8790        |
|    policy_gradient_loss  | 0.00266     |
|    std                   | 0.386       |
|    value_loss            | 6.91        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.26470008 |
| rollout/                 |             |
|    ep_len_mean           | 87.3        |
|    ep_rew_mean           | -35.4       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 48          |
|    time_elapsed          | 1407        |
|    total_timesteps       | 1804288     |
| train/                   |             |
|    approx_kl             | 0.03203307  |
|    clip_fraction         | 0.185       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.37        |
|    cost_value_loss       | 7.48        |
|    cost_values           | 2.4         |
|    entropy               | -0.358      |
|    entropy_loss          | -0.364      |
|    explained_variance    | 0.786       |
|    lagrangian_multiplier | 0.00274     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.43        |
|    n_updates             | 8800        |
|    policy_gradient_loss  | 0.00662     |
|    std                   | 0.385       |
|    value_loss            | 7.27        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.36460006 |
| rollout/                 |             |
|    ep_len_mean           | 83.5        |
|    ep_rew_mean           | -34.7       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 49          |
|    time_elapsed          | 1436        |
|    total_timesteps       | 1806336     |
| train/                   |             |
|    approx_kl             | 0.019974826 |
|    clip_fraction         | 0.131       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.06        |
|    cost_value_loss       | 11.5        |
|    cost_values           | 2.35        |
|    entropy               | -0.351      |
|    entropy_loss          | -0.354      |
|    explained_variance    | 0.719       |
|    lagrangian_multiplier | 0.000845    |
|    learning_rate         | 0.0003      |
|    loss                  | 7.16        |
|    n_updates             | 8810        |
|    policy_gradient_loss  | 0.00117     |
|    std                   | 0.384       |
|    value_loss            | 7.57        |
------------------------------------------
------------------------------------
| avg_speed          | 5.2         |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 5.2         |
| reward             | -0.39256844 |
| rollout/           |             |
|    ep_len_mean     | 76.1        |
|    ep_rew_mean     | -32.9       |
| time/              |             |
|    fps             | 74          |
|    iterations      | 1           |
|    time_elapsed    | 27          |
|    total_timesteps | 1808384     |
------------------------------------
-------------------------------------------
| avg_speed                | 3.4          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 3.4          |
| reward                   | -0.88091296  |
| rollout/                 |              |
|    ep_len_mean           | 78           |
|    ep_rew_mean           | -33.8        |
| time/                    |              |
|    fps                   | 71           |
|    iterations            | 2            |
|    time_elapsed          | 57           |
|    total_timesteps       | 1810432      |
| train/                   |              |
|    approx_kl             | 0.0101256445 |
|    clip_fraction         | 0.137        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.27         |
|    cost_value_loss       | 8.9          |
|    cost_values           | 2.33         |
|    entropy               | -0.329       |
|    entropy_loss          | -0.332       |
|    explained_variance    | 0.85         |
|    lagrangian_multiplier | 0.000511     |
|    learning_rate         | 0.0003       |
|    loss                  | 6.29         |
|    n_updates             | 8830         |
|    policy_gradient_loss  | -0.00298     |
|    std                   | 0.381        |
|    value_loss            | 6.24         |
-------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.69352686 |
| rollout/                 |             |
|    ep_len_mean           | 75.5        |
|    ep_rew_mean           | -33.2       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 3           |
|    time_elapsed          | 86          |
|    total_timesteps       | 1812480     |
| train/                   |             |
|    approx_kl             | 0.02130283  |
|    clip_fraction         | 0.161       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.67        |
|    cost_value_loss       | 9.85        |
|    cost_values           | 2.39        |
|    entropy               | -0.322      |
|    entropy_loss          | -0.325      |
|    explained_variance    | 0.855       |
|    lagrangian_multiplier | 0.00141     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.55        |
|    n_updates             | 8840        |
|    policy_gradient_loss  | 0.00124     |
|    std                   | 0.381       |
|    value_loss            | 5.65        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.82        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.82        |
| reward                   | -0.17289288 |
| rollout/                 |             |
|    ep_len_mean           | 77.8        |
|    ep_rew_mean           | -33.6       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 4           |
|    time_elapsed          | 115         |
|    total_timesteps       | 1814528     |
| train/                   |             |
|    approx_kl             | 0.025360651 |
|    clip_fraction         | 0.192       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.85        |
|    cost_value_loss       | 10.5        |
|    cost_values           | 2.45        |
|    entropy               | -0.318      |
|    entropy_loss          | -0.32       |
|    explained_variance    | 0.849       |
|    lagrangian_multiplier | 0.00118     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.93        |
|    n_updates             | 8850        |
|    policy_gradient_loss  | 0.00921     |
|    std                   | 0.38        |
|    value_loss            | 5.36        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.79        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.79        |
| reward                   | -0.62740785 |
| rollout/                 |             |
|    ep_len_mean           | 81          |
|    ep_rew_mean           | -34.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 5           |
|    time_elapsed          | 144         |
|    total_timesteps       | 1816576     |
| train/                   |             |
|    approx_kl             | 0.022994962 |
|    clip_fraction         | 0.204       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.45        |
|    cost_value_loss       | 8.53        |
|    cost_values           | 2.39        |
|    entropy               | -0.32       |
|    entropy_loss          | -0.318      |
|    explained_variance    | 0.87        |
|    lagrangian_multiplier | 0.00145     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.62        |
|    n_updates             | 8860        |
|    policy_gradient_loss  | 0.00512     |
|    std                   | 0.381       |
|    value_loss            | 5           |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.20708029 |
| rollout/                 |             |
|    ep_len_mean           | 84.2        |
|    ep_rew_mean           | -35.2       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 6           |
|    time_elapsed          | 173         |
|    total_timesteps       | 1818624     |
| train/                   |             |
|    approx_kl             | 0.030525744 |
|    clip_fraction         | 0.189       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.4         |
|    cost_value_loss       | 8.32        |
|    cost_values           | 2.38        |
|    entropy               | -0.32       |
|    entropy_loss          | -0.32       |
|    explained_variance    | 0.829       |
|    lagrangian_multiplier | 0.00143     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.03        |
|    n_updates             | 8870        |
|    policy_gradient_loss  | 0.00568     |
|    std                   | 0.381       |
|    value_loss            | 6.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.56        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.56        |
| reward                   | -0.44647893 |
| rollout/                 |             |
|    ep_len_mean           | 83.5        |
|    ep_rew_mean           | -34.9       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 7           |
|    time_elapsed          | 203         |
|    total_timesteps       | 1820672     |
| train/                   |             |
|    approx_kl             | 0.006965662 |
|    clip_fraction         | 0.166       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.78        |
|    cost_value_loss       | 9.14        |
|    cost_values           | 2.43        |
|    entropy               | -0.32       |
|    entropy_loss          | -0.321      |
|    explained_variance    | 0.799       |
|    lagrangian_multiplier | 0.00304     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.4         |
|    n_updates             | 8880        |
|    policy_gradient_loss  | 0.00347     |
|    std                   | 0.381       |
|    value_loss            | 5.67        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.2         |
| reward                   | -0.8530777  |
| rollout/                 |             |
|    ep_len_mean           | 84.5        |
|    ep_rew_mean           | -35.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 8           |
|    time_elapsed          | 233         |
|    total_timesteps       | 1822720     |
| train/                   |             |
|    approx_kl             | 0.006983691 |
|    clip_fraction         | 0.132       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.41        |
|    cost_value_loss       | 8.07        |
|    cost_values           | 2.41        |
|    entropy               | -0.329      |
|    entropy_loss          | -0.324      |
|    explained_variance    | 0.85        |
|    lagrangian_multiplier | 0.00206     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.88        |
|    n_updates             | 8890        |
|    policy_gradient_loss  | 0.00336     |
|    std                   | 0.384       |
|    value_loss            | 5.89        |
------------------------------------------
-----------------------------------------
| avg_speed                | 4.4        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 4.4        |
| reward                   | -0.7048368 |
| rollout/                 |            |
|    ep_len_mean           | 83.6       |
|    ep_rew_mean           | -34.8      |
| time/                    |            |
|    fps                   | 70         |
|    iterations            | 9          |
|    time_elapsed          | 262        |
|    total_timesteps       | 1824768    |
| train/                   |            |
|    approx_kl             | 0.0152322  |
|    clip_fraction         | 0.178      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.79       |
|    cost_value_loss       | 11.6       |
|    cost_values           | 2.35       |
|    entropy               | -0.333     |
|    entropy_loss          | -0.333     |
|    explained_variance    | 0.831      |
|    lagrangian_multiplier | 0.00336    |
|    learning_rate         | 0.0003     |
|    loss                  | 4.72       |
|    n_updates             | 8900       |
|    policy_gradient_loss  | 0.00425    |
|    std                   | 0.385      |
|    value_loss            | 5.66       |
-----------------------------------------
------------------------------------------
| avg_speed                | 7.52        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.52        |
| reward                   | -0.32442018 |
| rollout/                 |             |
|    ep_len_mean           | 91.5        |
|    ep_rew_mean           | -37.2       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 10          |
|    time_elapsed          | 292         |
|    total_timesteps       | 1826816     |
| train/                   |             |
|    approx_kl             | 0.02252642  |
|    clip_fraction         | 0.217       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.58        |
|    cost_value_loss       | 9.66        |
|    cost_values           | 2.37        |
|    entropy               | -0.331      |
|    entropy_loss          | -0.331      |
|    explained_variance    | 0.834       |
|    lagrangian_multiplier | 0.0024      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.9         |
|    n_updates             | 8910        |
|    policy_gradient_loss  | 0.00999     |
|    std                   | 0.385       |
|    value_loss            | 6.28        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.1791204  |
| rollout/                 |             |
|    ep_len_mean           | 84.8        |
|    ep_rew_mean           | -35         |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 11          |
|    time_elapsed          | 322         |
|    total_timesteps       | 1828864     |
| train/                   |             |
|    approx_kl             | 0.017702434 |
|    clip_fraction         | 0.129       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.65        |
|    cost_value_loss       | 13.8        |
|    cost_values           | 2.42        |
|    entropy               | -0.326      |
|    entropy_loss          | -0.329      |
|    explained_variance    | 0.682       |
|    lagrangian_multiplier | 0.00333     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.04        |
|    n_updates             | 8920        |
|    policy_gradient_loss  | -0.000528   |
|    std                   | 0.384       |
|    value_loss            | 6.31        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.8         |
| reward                   | -0.7690623  |
| rollout/                 |             |
|    ep_len_mean           | 80          |
|    ep_rew_mean           | -33.7       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 12          |
|    time_elapsed          | 352         |
|    total_timesteps       | 1830912     |
| train/                   |             |
|    approx_kl             | 0.020621017 |
|    clip_fraction         | 0.169       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.43        |
|    cost_value_loss       | 8.3         |
|    cost_values           | 2.36        |
|    entropy               | -0.325      |
|    entropy_loss          | -0.325      |
|    explained_variance    | 0.82        |
|    lagrangian_multiplier | 0.00164     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.31        |
|    n_updates             | 8930        |
|    policy_gradient_loss  | 0.00652     |
|    std                   | 0.383       |
|    value_loss            | 6.71        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.30287546 |
| rollout/                 |             |
|    ep_len_mean           | 78          |
|    ep_rew_mean           | -32.9       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 13          |
|    time_elapsed          | 382         |
|    total_timesteps       | 1832960     |
| train/                   |             |
|    approx_kl             | 0.011790576 |
|    clip_fraction         | 0.17        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.38        |
|    cost_value_loss       | 8.75        |
|    cost_values           | 2.26        |
|    entropy               | -0.336      |
|    entropy_loss          | -0.33       |
|    explained_variance    | 0.853       |
|    lagrangian_multiplier | 0.00165     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.77        |
|    n_updates             | 8940        |
|    policy_gradient_loss  | 0.00301     |
|    std                   | 0.386       |
|    value_loss            | 6.1         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.22807972 |
| rollout/                 |             |
|    ep_len_mean           | 71.9        |
|    ep_rew_mean           | -31.3       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 14          |
|    time_elapsed          | 411         |
|    total_timesteps       | 1835008     |
| train/                   |             |
|    approx_kl             | 0.032507345 |
|    clip_fraction         | 0.181       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.5         |
|    cost_value_loss       | 8.84        |
|    cost_values           | 2.31        |
|    entropy               | -0.344      |
|    entropy_loss          | -0.34       |
|    explained_variance    | 0.824       |
|    lagrangian_multiplier | 0.00297     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.38        |
|    n_updates             | 8950        |
|    policy_gradient_loss  | 0.00834     |
|    std                   | 0.387       |
|    value_loss            | 5.93        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.22751208 |
| rollout/                 |             |
|    ep_len_mean           | 78.3        |
|    ep_rew_mean           | -33.2       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 15          |
|    time_elapsed          | 441         |
|    total_timesteps       | 1837056     |
| train/                   |             |
|    approx_kl             | 0.023180524 |
|    clip_fraction         | 0.156       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.01        |
|    cost_value_loss       | 12.2        |
|    cost_values           | 2.38        |
|    entropy               | -0.341      |
|    entropy_loss          | -0.342      |
|    explained_variance    | 0.834       |
|    lagrangian_multiplier | 0.00274     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.17        |
|    n_updates             | 8960        |
|    policy_gradient_loss  | 0.0026      |
|    std                   | 0.388       |
|    value_loss            | 5.88        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.22757041 |
| rollout/                 |             |
|    ep_len_mean           | 79.1        |
|    ep_rew_mean           | -33.5       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 16          |
|    time_elapsed          | 471         |
|    total_timesteps       | 1839104     |
| train/                   |             |
|    approx_kl             | 0.031270586 |
|    clip_fraction         | 0.193       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.76        |
|    cost_value_loss       | 10.2        |
|    cost_values           | 2.42        |
|    entropy               | -0.341      |
|    entropy_loss          | -0.341      |
|    explained_variance    | 0.824       |
|    lagrangian_multiplier | 0.00101     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.06        |
|    n_updates             | 8970        |
|    policy_gradient_loss  | 0.0056      |
|    std                   | 0.388       |
|    value_loss            | 6.03        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.40816215 |
| rollout/                 |             |
|    ep_len_mean           | 81.5        |
|    ep_rew_mean           | -34.3       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 17          |
|    time_elapsed          | 500         |
|    total_timesteps       | 1841152     |
| train/                   |             |
|    approx_kl             | 0.03382089  |
|    clip_fraction         | 0.165       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.81        |
|    cost_value_loss       | 10.2        |
|    cost_values           | 2.4         |
|    entropy               | -0.328      |
|    entropy_loss          | -0.336      |
|    explained_variance    | 0.836       |
|    lagrangian_multiplier | 0.00198     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.33        |
|    n_updates             | 8980        |
|    policy_gradient_loss  | 0.00454     |
|    std                   | 0.386       |
|    value_loss            | 6.04        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.16        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.16        |
| reward                   | -0.8251456  |
| rollout/                 |             |
|    ep_len_mean           | 82.9        |
|    ep_rew_mean           | -34.5       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 18          |
|    time_elapsed          | 530         |
|    total_timesteps       | 1843200     |
| train/                   |             |
|    approx_kl             | 0.026035104 |
|    clip_fraction         | 0.216       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.42        |
|    cost_value_loss       | 8.74        |
|    cost_values           | 2.34        |
|    entropy               | -0.324      |
|    entropy_loss          | -0.325      |
|    explained_variance    | 0.817       |
|    lagrangian_multiplier | 0.00189     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.6         |
|    n_updates             | 8990        |
|    policy_gradient_loss  | 0.0105      |
|    std                   | 0.385       |
|    value_loss            | 5.51        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.28006306 |
| rollout/                 |             |
|    ep_len_mean           | 81.2        |
|    ep_rew_mean           | -33.7       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 19          |
|    time_elapsed          | 559         |
|    total_timesteps       | 1845248     |
| train/                   |             |
|    approx_kl             | 0.04178262  |
|    clip_fraction         | 0.188       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.89        |
|    cost_value_loss       | 10.7        |
|    cost_values           | 2.38        |
|    entropy               | -0.322      |
|    entropy_loss          | -0.323      |
|    explained_variance    | 0.863       |
|    lagrangian_multiplier | 0.00242     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.68        |
|    n_updates             | 9000        |
|    policy_gradient_loss  | 0.00753     |
|    std                   | 0.384       |
|    value_loss            | 5.05        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.20704821 |
| rollout/                 |             |
|    ep_len_mean           | 85.7        |
|    ep_rew_mean           | -35.3       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 20          |
|    time_elapsed          | 588         |
|    total_timesteps       | 1847296     |
| train/                   |             |
|    approx_kl             | 0.031255774 |
|    clip_fraction         | 0.204       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.62        |
|    cost_value_loss       | 9.89        |
|    cost_values           | 2.4         |
|    entropy               | -0.325      |
|    entropy_loss          | -0.324      |
|    explained_variance    | 0.847       |
|    lagrangian_multiplier | 0.00209     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.93        |
|    n_updates             | 9010        |
|    policy_gradient_loss  | 0.00631     |
|    std                   | 0.385       |
|    value_loss            | 5.63        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.75165117 |
| rollout/                 |             |
|    ep_len_mean           | 83.6        |
|    ep_rew_mean           | -34.6       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 21          |
|    time_elapsed          | 618         |
|    total_timesteps       | 1849344     |
| train/                   |             |
|    approx_kl             | 0.020929622 |
|    clip_fraction         | 0.2         |
|    clip_range            | 0.2         |
|    cost_returns          | 4.82        |
|    cost_value_loss       | 11.2        |
|    cost_values           | 2.39        |
|    entropy               | -0.333      |
|    entropy_loss          | -0.329      |
|    explained_variance    | 0.828       |
|    lagrangian_multiplier | 0.000843    |
|    learning_rate         | 0.0003      |
|    loss                  | 6.64        |
|    n_updates             | 9020        |
|    policy_gradient_loss  | 0.00597     |
|    std                   | 0.388       |
|    value_loss            | 5.9         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.24940039 |
| rollout/                 |             |
|    ep_len_mean           | 83.7        |
|    ep_rew_mean           | -34.9       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 22          |
|    time_elapsed          | 647         |
|    total_timesteps       | 1851392     |
| train/                   |             |
|    approx_kl             | 0.013583523 |
|    clip_fraction         | 0.162       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.69        |
|    cost_value_loss       | 9.81        |
|    cost_values           | 2.41        |
|    entropy               | -0.339      |
|    entropy_loss          | -0.336      |
|    explained_variance    | 0.81        |
|    lagrangian_multiplier | 0.000854    |
|    learning_rate         | 0.0003      |
|    loss                  | 6.49        |
|    n_updates             | 9030        |
|    policy_gradient_loss  | 0.00299     |
|    std                   | 0.39        |
|    value_loss            | 7.03        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.3207364  |
| rollout/                 |             |
|    ep_len_mean           | 86.8        |
|    ep_rew_mean           | -35.9       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 23          |
|    time_elapsed          | 676         |
|    total_timesteps       | 1853440     |
| train/                   |             |
|    approx_kl             | 0.008841583 |
|    clip_fraction         | 0.137       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.12        |
|    cost_value_loss       | 6.87        |
|    cost_values           | 2.37        |
|    entropy               | -0.333      |
|    entropy_loss          | -0.337      |
|    explained_variance    | 0.775       |
|    lagrangian_multiplier | 0.00108     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.37        |
|    n_updates             | 9040        |
|    policy_gradient_loss  | 0.00403     |
|    std                   | 0.388       |
|    value_loss            | 7.66        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.4         |
| reward                   | -0.7794764  |
| rollout/                 |             |
|    ep_len_mean           | 83.2        |
|    ep_rew_mean           | -34.3       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 24          |
|    time_elapsed          | 706         |
|    total_timesteps       | 1855488     |
| train/                   |             |
|    approx_kl             | 0.011601488 |
|    clip_fraction         | 0.145       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.07        |
|    cost_value_loss       | 10.9        |
|    cost_values           | 2.43        |
|    entropy               | -0.32       |
|    entropy_loss          | -0.325      |
|    explained_variance    | 0.816       |
|    lagrangian_multiplier | 0.00094     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.35        |
|    n_updates             | 9050        |
|    policy_gradient_loss  | 0.00131     |
|    std                   | 0.385       |
|    value_loss            | 6.15        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.76        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.76        |
| reward                   | -0.31097257 |
| rollout/                 |             |
|    ep_len_mean           | 82.1        |
|    ep_rew_mean           | -34.1       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 25          |
|    time_elapsed          | 735         |
|    total_timesteps       | 1857536     |
| train/                   |             |
|    approx_kl             | 0.019515121 |
|    clip_fraction         | 0.201       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.54        |
|    cost_value_loss       | 8.53        |
|    cost_values           | 2.45        |
|    entropy               | -0.317      |
|    entropy_loss          | -0.318      |
|    explained_variance    | 0.833       |
|    lagrangian_multiplier | 0.00354     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.14        |
|    n_updates             | 9060        |
|    policy_gradient_loss  | 0.00697     |
|    std                   | 0.384       |
|    value_loss            | 6.28        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.6134725  |
| rollout/                 |             |
|    ep_len_mean           | 78.5        |
|    ep_rew_mean           | -33.1       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 26          |
|    time_elapsed          | 765         |
|    total_timesteps       | 1859584     |
| train/                   |             |
|    approx_kl             | 0.010705927 |
|    clip_fraction         | 0.151       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.69        |
|    cost_value_loss       | 9.57        |
|    cost_values           | 2.37        |
|    entropy               | -0.307      |
|    entropy_loss          | -0.313      |
|    explained_variance    | 0.805       |
|    lagrangian_multiplier | 0.00349     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.5         |
|    n_updates             | 9070        |
|    policy_gradient_loss  | 0.00253     |
|    std                   | 0.381       |
|    value_loss            | 7.1         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.23393323 |
| rollout/                 |             |
|    ep_len_mean           | 77.6        |
|    ep_rew_mean           | -33.1       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 27          |
|    time_elapsed          | 794         |
|    total_timesteps       | 1861632     |
| train/                   |             |
|    approx_kl             | 0.019364953 |
|    clip_fraction         | 0.183       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.73        |
|    cost_value_loss       | 9.93        |
|    cost_values           | 2.36        |
|    entropy               | -0.301      |
|    entropy_loss          | -0.303      |
|    explained_variance    | 0.843       |
|    lagrangian_multiplier | 0.00172     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.09        |
|    n_updates             | 9080        |
|    policy_gradient_loss  | 0.00548     |
|    std                   | 0.379       |
|    value_loss            | 6.14        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.6         |
| reward                   | -0.2699329  |
| rollout/                 |             |
|    ep_len_mean           | 81.9        |
|    ep_rew_mean           | -34.6       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 28          |
|    time_elapsed          | 823         |
|    total_timesteps       | 1863680     |
| train/                   |             |
|    approx_kl             | 0.014115021 |
|    clip_fraction         | 0.183       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.67        |
|    cost_value_loss       | 9.88        |
|    cost_values           | 2.34        |
|    entropy               | -0.301      |
|    entropy_loss          | -0.301      |
|    explained_variance    | 0.803       |
|    lagrangian_multiplier | 0.00202     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.29        |
|    n_updates             | 9090        |
|    policy_gradient_loss  | 0.00717     |
|    std                   | 0.379       |
|    value_loss            | 6.28        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.24092203 |
| rollout/                 |             |
|    ep_len_mean           | 82.3        |
|    ep_rew_mean           | -34.7       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 29          |
|    time_elapsed          | 853         |
|    total_timesteps       | 1865728     |
| train/                   |             |
|    approx_kl             | 0.011117646 |
|    clip_fraction         | 0.141       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.87        |
|    cost_value_loss       | 10.6        |
|    cost_values           | 2.32        |
|    entropy               | -0.299      |
|    entropy_loss          | -0.3        |
|    explained_variance    | 0.735       |
|    lagrangian_multiplier | 0.00121     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.39        |
|    n_updates             | 9100        |
|    policy_gradient_loss  | -0.000821   |
|    std                   | 0.38        |
|    value_loss            | 7.31        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.14982234 |
| rollout/                 |             |
|    ep_len_mean           | 87.9        |
|    ep_rew_mean           | -36.4       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 30          |
|    time_elapsed          | 882         |
|    total_timesteps       | 1867776     |
| train/                   |             |
|    approx_kl             | 0.013333162 |
|    clip_fraction         | 0.18        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.76        |
|    cost_value_loss       | 10.2        |
|    cost_values           | 2.32        |
|    entropy               | -0.291      |
|    entropy_loss          | -0.295      |
|    explained_variance    | 0.763       |
|    lagrangian_multiplier | 0.00148     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.01        |
|    n_updates             | 9110        |
|    policy_gradient_loss  | 0.00256     |
|    std                   | 0.378       |
|    value_loss            | 7.64        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.8984576  |
| rollout/                 |             |
|    ep_len_mean           | 89.7        |
|    ep_rew_mean           | -36.9       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 31          |
|    time_elapsed          | 912         |
|    total_timesteps       | 1869824     |
| train/                   |             |
|    approx_kl             | 0.023953829 |
|    clip_fraction         | 0.161       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.92        |
|    cost_value_loss       | 11.4        |
|    cost_values           | 2.3         |
|    entropy               | -0.29       |
|    entropy_loss          | -0.289      |
|    explained_variance    | 0.811       |
|    lagrangian_multiplier | 0.00283     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.93        |
|    n_updates             | 9120        |
|    policy_gradient_loss  | 0.00393     |
|    std                   | 0.378       |
|    value_loss            | 6.61        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.321122   |
| rollout/                 |             |
|    ep_len_mean           | 81.6        |
|    ep_rew_mean           | -34.3       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 32          |
|    time_elapsed          | 942         |
|    total_timesteps       | 1871872     |
| train/                   |             |
|    approx_kl             | 0.010431111 |
|    clip_fraction         | 0.186       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.77        |
|    cost_value_loss       | 10.3        |
|    cost_values           | 2.29        |
|    entropy               | -0.294      |
|    entropy_loss          | -0.291      |
|    explained_variance    | 0.772       |
|    lagrangian_multiplier | 0.0025      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.11        |
|    n_updates             | 9130        |
|    policy_gradient_loss  | 0.00725     |
|    std                   | 0.379       |
|    value_loss            | 6.73        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.8         |
| reward                   | -0.72607404 |
| rollout/                 |             |
|    ep_len_mean           | 81.6        |
|    ep_rew_mean           | -34.3       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 33          |
|    time_elapsed          | 971         |
|    total_timesteps       | 1873920     |
| train/                   |             |
|    approx_kl             | 0.02127834  |
|    clip_fraction         | 0.15        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.38        |
|    cost_value_loss       | 8.56        |
|    cost_values           | 2.24        |
|    entropy               | -0.298      |
|    entropy_loss          | -0.295      |
|    explained_variance    | 0.879       |
|    lagrangian_multiplier | 0.00104     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.09        |
|    n_updates             | 9140        |
|    policy_gradient_loss  | 0.00607     |
|    std                   | 0.381       |
|    value_loss            | 4.83        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.3919423  |
| rollout/                 |             |
|    ep_len_mean           | 79.4        |
|    ep_rew_mean           | -33         |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 34          |
|    time_elapsed          | 1001        |
|    total_timesteps       | 1875968     |
| train/                   |             |
|    approx_kl             | 0.009903561 |
|    clip_fraction         | 0.134       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.64        |
|    cost_value_loss       | 9.56        |
|    cost_values           | 2.3         |
|    entropy               | -0.298      |
|    entropy_loss          | -0.298      |
|    explained_variance    | 0.858       |
|    lagrangian_multiplier | 0.000979    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.62        |
|    n_updates             | 9150        |
|    policy_gradient_loss  | -0.00169    |
|    std                   | 0.381       |
|    value_loss            | 5.12        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.20544772 |
| rollout/                 |             |
|    ep_len_mean           | 78.1        |
|    ep_rew_mean           | -32.9       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 35          |
|    time_elapsed          | 1030        |
|    total_timesteps       | 1878016     |
| train/                   |             |
|    approx_kl             | 0.034018703 |
|    clip_fraction         | 0.174       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.57        |
|    cost_value_loss       | 8.56        |
|    cost_values           | 2.36        |
|    entropy               | -0.291      |
|    entropy_loss          | -0.295      |
|    explained_variance    | 0.822       |
|    lagrangian_multiplier | 0.00161     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.23        |
|    n_updates             | 9160        |
|    policy_gradient_loss  | 0.00624     |
|    std                   | 0.38        |
|    value_loss            | 5.61        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.8199565  |
| rollout/                 |             |
|    ep_len_mean           | 77.2        |
|    ep_rew_mean           | -32.7       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 36          |
|    time_elapsed          | 1059        |
|    total_timesteps       | 1880064     |
| train/                   |             |
|    approx_kl             | 0.010129676 |
|    clip_fraction         | 0.158       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.39        |
|    cost_value_loss       | 8.56        |
|    cost_values           | 2.31        |
|    entropy               | -0.286      |
|    entropy_loss          | -0.288      |
|    explained_variance    | 0.788       |
|    lagrangian_multiplier | 0.0018      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.95        |
|    n_updates             | 9170        |
|    policy_gradient_loss  | 0.0029      |
|    std                   | 0.379       |
|    value_loss            | 6.74        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.24234453 |
| rollout/                 |             |
|    ep_len_mean           | 80.2        |
|    ep_rew_mean           | -33.7       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 37          |
|    time_elapsed          | 1088        |
|    total_timesteps       | 1882112     |
| train/                   |             |
|    approx_kl             | 0.008132314 |
|    clip_fraction         | 0.156       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.24        |
|    cost_value_loss       | 7.81        |
|    cost_values           | 2.27        |
|    entropy               | -0.281      |
|    entropy_loss          | -0.283      |
|    explained_variance    | 0.823       |
|    lagrangian_multiplier | 0.00124     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.47        |
|    n_updates             | 9180        |
|    policy_gradient_loss  | 0.00393     |
|    std                   | 0.377       |
|    value_loss            | 6.49        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.33019388 |
| rollout/                 |             |
|    ep_len_mean           | 82.3        |
|    ep_rew_mean           | -34.6       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 38          |
|    time_elapsed          | 1118        |
|    total_timesteps       | 1884160     |
| train/                   |             |
|    approx_kl             | 0.008655897 |
|    clip_fraction         | 0.154       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.75        |
|    cost_value_loss       | 10.1        |
|    cost_values           | 2.27        |
|    entropy               | -0.277      |
|    entropy_loss          | -0.279      |
|    explained_variance    | 0.827       |
|    lagrangian_multiplier | 0.00236     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.69        |
|    n_updates             | 9190        |
|    policy_gradient_loss  | 0.00499     |
|    std                   | 0.376       |
|    value_loss            | 5.48        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.90352005 |
| rollout/                 |             |
|    ep_len_mean           | 81.8        |
|    ep_rew_mean           | -34.1       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 39          |
|    time_elapsed          | 1148        |
|    total_timesteps       | 1886208     |
| train/                   |             |
|    approx_kl             | 0.035228804 |
|    clip_fraction         | 0.16        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.46        |
|    cost_value_loss       | 7.98        |
|    cost_values           | 2.27        |
|    entropy               | -0.271      |
|    entropy_loss          | -0.274      |
|    explained_variance    | 0.735       |
|    lagrangian_multiplier | 0.00132     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.76        |
|    n_updates             | 9200        |
|    policy_gradient_loss  | 0.0026      |
|    std                   | 0.375       |
|    value_loss            | 8.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.27353603 |
| rollout/                 |             |
|    ep_len_mean           | 87.7        |
|    ep_rew_mean           | -35.7       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 40          |
|    time_elapsed          | 1177        |
|    total_timesteps       | 1888256     |
| train/                   |             |
|    approx_kl             | 0.0183407   |
|    clip_fraction         | 0.152       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.74        |
|    cost_value_loss       | 10.2        |
|    cost_values           | 2.28        |
|    entropy               | -0.264      |
|    entropy_loss          | -0.267      |
|    explained_variance    | 0.799       |
|    lagrangian_multiplier | 0.000964    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.78        |
|    n_updates             | 9210        |
|    policy_gradient_loss  | 0.00324     |
|    std                   | 0.373       |
|    value_loss            | 6.72        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.24390525 |
| rollout/                 |             |
|    ep_len_mean           | 84.9        |
|    ep_rew_mean           | -34.4       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 41          |
|    time_elapsed          | 1207        |
|    total_timesteps       | 1890304     |
| train/                   |             |
|    approx_kl             | 0.032075558 |
|    clip_fraction         | 0.214       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.92        |
|    cost_value_loss       | 11.4        |
|    cost_values           | 2.27        |
|    entropy               | -0.264      |
|    entropy_loss          | -0.264      |
|    explained_variance    | 0.791       |
|    lagrangian_multiplier | 0.00154     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.79        |
|    n_updates             | 9220        |
|    policy_gradient_loss  | 0.00964     |
|    std                   | 0.373       |
|    value_loss            | 6.19        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.8199565  |
| rollout/                 |             |
|    ep_len_mean           | 80.9        |
|    ep_rew_mean           | -33.3       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 42          |
|    time_elapsed          | 1237        |
|    total_timesteps       | 1892352     |
| train/                   |             |
|    approx_kl             | 0.025070664 |
|    clip_fraction         | 0.155       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.49        |
|    cost_value_loss       | 8.96        |
|    cost_values           | 2.25        |
|    entropy               | -0.263      |
|    entropy_loss          | -0.263      |
|    explained_variance    | 0.791       |
|    lagrangian_multiplier | 0.00164     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.6         |
|    n_updates             | 9230        |
|    policy_gradient_loss  | 0.00408     |
|    std                   | 0.373       |
|    value_loss            | 6.91        |
------------------------------------------
-----------------------------------------
| avg_speed                | 3.2        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 3.2        |
| reward                   | -0.8329027 |
| rollout/                 |            |
|    ep_len_mean           | 80.3       |
|    ep_rew_mean           | -33.2      |
| time/                    |            |
|    fps                   | 69         |
|    iterations            | 43         |
|    time_elapsed          | 1266       |
|    total_timesteps       | 1894400    |
| train/                   |            |
|    approx_kl             | 0.051993   |
|    clip_fraction         | 0.197      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.42       |
|    cost_value_loss       | 9.7        |
|    cost_values           | 2.21       |
|    entropy               | -0.257     |
|    entropy_loss          | -0.261     |
|    explained_variance    | 0.837      |
|    lagrangian_multiplier | 0.000855   |
|    learning_rate         | 0.0003     |
|    loss                  | 6.39       |
|    n_updates             | 9240       |
|    policy_gradient_loss  | 0.00481    |
|    std                   | 0.372      |
|    value_loss            | 6.2        |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.1971769  |
| rollout/                 |             |
|    ep_len_mean           | 73.8        |
|    ep_rew_mean           | -31.7       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 44          |
|    time_elapsed          | 1296        |
|    total_timesteps       | 1896448     |
| train/                   |             |
|    approx_kl             | 0.013841439 |
|    clip_fraction         | 0.147       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.5         |
|    cost_value_loss       | 9.09        |
|    cost_values           | 2.27        |
|    entropy               | -0.261      |
|    entropy_loss          | -0.259      |
|    explained_variance    | 0.848       |
|    lagrangian_multiplier | 0.00102     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.39        |
|    n_updates             | 9250        |
|    policy_gradient_loss  | 0.000989    |
|    std                   | 0.372       |
|    value_loss            | 5.77        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.576659   |
| rollout/                 |             |
|    ep_len_mean           | 78.1        |
|    ep_rew_mean           | -33.2       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 45          |
|    time_elapsed          | 1326        |
|    total_timesteps       | 1898496     |
| train/                   |             |
|    approx_kl             | 0.010274882 |
|    clip_fraction         | 0.138       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.51        |
|    cost_value_loss       | 9.27        |
|    cost_values           | 2.29        |
|    entropy               | -0.257      |
|    entropy_loss          | -0.26       |
|    explained_variance    | 0.838       |
|    lagrangian_multiplier | 0.00487     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.79        |
|    n_updates             | 9260        |
|    policy_gradient_loss  | 0.00284     |
|    std                   | 0.372       |
|    value_loss            | 5.9         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.3502428  |
| rollout/                 |             |
|    ep_len_mean           | 81.3        |
|    ep_rew_mean           | -34.1       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 46          |
|    time_elapsed          | 1356        |
|    total_timesteps       | 1900544     |
| train/                   |             |
|    approx_kl             | 0.013736648 |
|    clip_fraction         | 0.0901      |
|    clip_range            | 0.2         |
|    cost_returns          | 4.97        |
|    cost_value_loss       | 11.2        |
|    cost_values           | 2.32        |
|    entropy               | -0.253      |
|    entropy_loss          | -0.255      |
|    explained_variance    | 0.812       |
|    lagrangian_multiplier | 0.00191     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.41        |
|    n_updates             | 9270        |
|    policy_gradient_loss  | -0.00288    |
|    std                   | 0.371       |
|    value_loss            | 5.77        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.4          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 5.4          |
| reward                   | -0.5175738   |
| rollout/                 |              |
|    ep_len_mean           | 81.8         |
|    ep_rew_mean           | -33.9        |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 47           |
|    time_elapsed          | 1385         |
|    total_timesteps       | 1902592      |
| train/                   |              |
|    approx_kl             | 0.0114045385 |
|    clip_fraction         | 0.142        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.94         |
|    cost_value_loss       | 11.3         |
|    cost_values           | 2.38         |
|    entropy               | -0.255       |
|    entropy_loss          | -0.254       |
|    explained_variance    | 0.818        |
|    lagrangian_multiplier | 0.00116      |
|    learning_rate         | 0.0003       |
|    loss                  | 6.25         |
|    n_updates             | 9280         |
|    policy_gradient_loss  | 0.00174      |
|    std                   | 0.371        |
|    value_loss            | 5.67         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.4         |
| reward                   | -0.3128604  |
| rollout/                 |             |
|    ep_len_mean           | 82.7        |
|    ep_rew_mean           | -33.8       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 48          |
|    time_elapsed          | 1414        |
|    total_timesteps       | 1904640     |
| train/                   |             |
|    approx_kl             | 0.054259814 |
|    clip_fraction         | 0.183       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.78        |
|    cost_value_loss       | 10.8        |
|    cost_values           | 2.37        |
|    entropy               | -0.254      |
|    entropy_loss          | -0.256      |
|    explained_variance    | 0.829       |
|    lagrangian_multiplier | 0.000993    |
|    learning_rate         | 0.0003      |
|    loss                  | 6.18        |
|    n_updates             | 9290        |
|    policy_gradient_loss  | 0.0054      |
|    std                   | 0.371       |
|    value_loss            | 6.04        |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.6        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.6        |
| reward                   | -0.8682859 |
| rollout/                 |            |
|    ep_len_mean           | 81.7       |
|    ep_rew_mean           | -33.8      |
| time/                    |            |
|    fps                   | 69         |
|    iterations            | 49         |
|    time_elapsed          | 1444       |
|    total_timesteps       | 1906688    |
| train/                   |            |
|    approx_kl             | 0.02271298 |
|    clip_fraction         | 0.217      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.55       |
|    cost_value_loss       | 8.23       |
|    cost_values           | 2.33       |
|    entropy               | -0.25      |
|    entropy_loss          | -0.252     |
|    explained_variance    | 0.794      |
|    lagrangian_multiplier | 0.000391   |
|    learning_rate         | 0.0003     |
|    loss                  | 6.07       |
|    n_updates             | 9300       |
|    policy_gradient_loss  | 0.00879    |
|    std                   | 0.371      |
|    value_loss            | 6.11       |
-----------------------------------------
-----------------------------------
| avg_speed          | 8          |
| cost               | 1          |
| is_success         | 0          |
| max_speed          | 8          |
| reward             | -0.2774213 |
| rollout/           |            |
|    ep_len_mean     | 79.6       |
|    ep_rew_mean     | -33.2      |
| time/              |            |
|    fps             | 73         |
|    iterations      | 1          |
|    time_elapsed    | 27         |
|    total_timesteps | 1908736    |
-----------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.22990008 |
| rollout/                 |             |
|    ep_len_mean           | 78.1        |
|    ep_rew_mean           | -32.9       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 2           |
|    time_elapsed          | 57          |
|    total_timesteps       | 1910784     |
| train/                   |             |
|    approx_kl             | 0.016498778 |
|    clip_fraction         | 0.191       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.88        |
|    cost_value_loss       | 9.98        |
|    cost_values           | 2.35        |
|    entropy               | -0.238      |
|    entropy_loss          | -0.241      |
|    explained_variance    | 0.82        |
|    lagrangian_multiplier | 0.00214     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.93        |
|    n_updates             | 9320        |
|    policy_gradient_loss  | 0.00492     |
|    std                   | 0.369       |
|    value_loss            | 5.65        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.7925409  |
| rollout/                 |             |
|    ep_len_mean           | 80.3        |
|    ep_rew_mean           | -34.1       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 3           |
|    time_elapsed          | 87          |
|    total_timesteps       | 1912832     |
| train/                   |             |
|    approx_kl             | 0.010995036 |
|    clip_fraction         | 0.133       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.7         |
|    cost_value_loss       | 9.32        |
|    cost_values           | 2.37        |
|    entropy               | -0.238      |
|    entropy_loss          | -0.237      |
|    explained_variance    | 0.839       |
|    lagrangian_multiplier | 0.00341     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.15        |
|    n_updates             | 9330        |
|    policy_gradient_loss  | 0.000533    |
|    std                   | 0.37        |
|    value_loss            | 5.38        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.6108048  |
| rollout/                 |             |
|    ep_len_mean           | 81          |
|    ep_rew_mean           | -34.1       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 4           |
|    time_elapsed          | 117         |
|    total_timesteps       | 1914880     |
| train/                   |             |
|    approx_kl             | 0.012079579 |
|    clip_fraction         | 0.171       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.87        |
|    cost_value_loss       | 10.9        |
|    cost_values           | 2.41        |
|    entropy               | -0.242      |
|    entropy_loss          | -0.239      |
|    explained_variance    | 0.864       |
|    lagrangian_multiplier | 0.00263     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.85        |
|    n_updates             | 9340        |
|    policy_gradient_loss  | 0.00228     |
|    std                   | 0.371       |
|    value_loss            | 5.48        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.7073532  |
| rollout/                 |             |
|    ep_len_mean           | 81          |
|    ep_rew_mean           | -34         |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 5           |
|    time_elapsed          | 147         |
|    total_timesteps       | 1916928     |
| train/                   |             |
|    approx_kl             | 0.028224617 |
|    clip_fraction         | 0.166       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.69        |
|    cost_value_loss       | 8.39        |
|    cost_values           | 2.42        |
|    entropy               | -0.247      |
|    entropy_loss          | -0.245      |
|    explained_variance    | 0.803       |
|    lagrangian_multiplier | 0.00291     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.41        |
|    n_updates             | 9350        |
|    policy_gradient_loss  | 0.00417     |
|    std                   | 0.371       |
|    value_loss            | 6.3         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.3292381  |
| rollout/                 |             |
|    ep_len_mean           | 82.8        |
|    ep_rew_mean           | -34.4       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 6           |
|    time_elapsed          | 177         |
|    total_timesteps       | 1918976     |
| train/                   |             |
|    approx_kl             | 0.016903317 |
|    clip_fraction         | 0.205       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.94        |
|    cost_value_loss       | 10.8        |
|    cost_values           | 2.33        |
|    entropy               | -0.244      |
|    entropy_loss          | -0.246      |
|    explained_variance    | 0.814       |
|    lagrangian_multiplier | 0.00273     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.8         |
|    n_updates             | 9360        |
|    policy_gradient_loss  | 0.0115      |
|    std                   | 0.371       |
|    value_loss            | 5.94        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.38583344 |
| rollout/                 |             |
|    ep_len_mean           | 83.4        |
|    ep_rew_mean           | -34         |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 7           |
|    time_elapsed          | 208         |
|    total_timesteps       | 1921024     |
| train/                   |             |
|    approx_kl             | 0.00702748  |
|    clip_fraction         | 0.17        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.35        |
|    cost_value_loss       | 7.49        |
|    cost_values           | 2.27        |
|    entropy               | -0.23       |
|    entropy_loss          | -0.238      |
|    explained_variance    | 0.812       |
|    lagrangian_multiplier | 0.000619    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.55        |
|    n_updates             | 9370        |
|    policy_gradient_loss  | 0.00707     |
|    std                   | 0.368       |
|    value_loss            | 5.76        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2678605  |
| rollout/                 |             |
|    ep_len_mean           | 85          |
|    ep_rew_mean           | -34.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 8           |
|    time_elapsed          | 237         |
|    total_timesteps       | 1923072     |
| train/                   |             |
|    approx_kl             | 0.020124696 |
|    clip_fraction         | 0.153       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.78        |
|    cost_value_loss       | 10.5        |
|    cost_values           | 2.32        |
|    entropy               | -0.233      |
|    entropy_loss          | -0.229      |
|    explained_variance    | 0.816       |
|    lagrangian_multiplier | 0.00297     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.35        |
|    n_updates             | 9380        |
|    policy_gradient_loss  | 0.00381     |
|    std                   | 0.37        |
|    value_loss            | 5.43        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.5656928  |
| rollout/                 |             |
|    ep_len_mean           | 81.8        |
|    ep_rew_mean           | -33.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 9           |
|    time_elapsed          | 267         |
|    total_timesteps       | 1925120     |
| train/                   |             |
|    approx_kl             | 0.020965382 |
|    clip_fraction         | 0.173       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.78        |
|    cost_value_loss       | 9.74        |
|    cost_values           | 2.37        |
|    entropy               | -0.227      |
|    entropy_loss          | -0.231      |
|    explained_variance    | 0.852       |
|    lagrangian_multiplier | 0.0027      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.31        |
|    n_updates             | 9390        |
|    policy_gradient_loss  | 0.00599     |
|    std                   | 0.369       |
|    value_loss            | 4.93        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.91        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.91        |
| reward                   | -0.27250412 |
| rollout/                 |             |
|    ep_len_mean           | 81.6        |
|    ep_rew_mean           | -33.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 10          |
|    time_elapsed          | 297         |
|    total_timesteps       | 1927168     |
| train/                   |             |
|    approx_kl             | 0.019893646 |
|    clip_fraction         | 0.218       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.3         |
|    cost_value_loss       | 7.53        |
|    cost_values           | 2.39        |
|    entropy               | -0.222      |
|    entropy_loss          | -0.224      |
|    explained_variance    | 0.884       |
|    lagrangian_multiplier | 0.00199     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.33        |
|    n_updates             | 9400        |
|    policy_gradient_loss  | 0.00901     |
|    std                   | 0.369       |
|    value_loss            | 4.52        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.20797007 |
| rollout/                 |             |
|    ep_len_mean           | 80.7        |
|    ep_rew_mean           | -33.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 11          |
|    time_elapsed          | 327         |
|    total_timesteps       | 1929216     |
| train/                   |             |
|    approx_kl             | 0.024097905 |
|    clip_fraction         | 0.172       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.32        |
|    cost_value_loss       | 7.66        |
|    cost_values           | 2.38        |
|    entropy               | -0.218      |
|    entropy_loss          | -0.22       |
|    explained_variance    | 0.813       |
|    lagrangian_multiplier | 0.00166     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.05        |
|    n_updates             | 9410        |
|    policy_gradient_loss  | 0.00508     |
|    std                   | 0.368       |
|    value_loss            | 6.2         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.21207681 |
| rollout/                 |             |
|    ep_len_mean           | 80.8        |
|    ep_rew_mean           | -33         |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 12          |
|    time_elapsed          | 357         |
|    total_timesteps       | 1931264     |
| train/                   |             |
|    approx_kl             | 0.029762788 |
|    clip_fraction         | 0.18        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.68        |
|    cost_value_loss       | 8.46        |
|    cost_values           | 2.4         |
|    entropy               | -0.222      |
|    entropy_loss          | -0.219      |
|    explained_variance    | 0.831       |
|    lagrangian_multiplier | 0.00241     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.3         |
|    n_updates             | 9420        |
|    policy_gradient_loss  | 0.00402     |
|    std                   | 0.369       |
|    value_loss            | 5.22        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2698303  |
| rollout/                 |             |
|    ep_len_mean           | 83.9        |
|    ep_rew_mean           | -33.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 13          |
|    time_elapsed          | 387         |
|    total_timesteps       | 1933312     |
| train/                   |             |
|    approx_kl             | 0.017550478 |
|    clip_fraction         | 0.179       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.65        |
|    cost_value_loss       | 8.39        |
|    cost_values           | 2.44        |
|    entropy               | -0.222      |
|    entropy_loss          | -0.222      |
|    explained_variance    | 0.807       |
|    lagrangian_multiplier | 0.0016      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.76        |
|    n_updates             | 9430        |
|    policy_gradient_loss  | 0.00554     |
|    std                   | 0.37        |
|    value_loss            | 5.59        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.23556112 |
| rollout/                 |             |
|    ep_len_mean           | 87.3        |
|    ep_rew_mean           | -34.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 14          |
|    time_elapsed          | 416         |
|    total_timesteps       | 1935360     |
| train/                   |             |
|    approx_kl             | 0.02123252  |
|    clip_fraction         | 0.181       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.77        |
|    cost_value_loss       | 8.55        |
|    cost_values           | 2.48        |
|    entropy               | -0.227      |
|    entropy_loss          | -0.224      |
|    explained_variance    | 0.78        |
|    lagrangian_multiplier | 0.00262     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.68        |
|    n_updates             | 9440        |
|    policy_gradient_loss  | 0.0051      |
|    std                   | 0.371       |
|    value_loss            | 6.39        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.6         |
| reward                   | -0.26865155 |
| rollout/                 |             |
|    ep_len_mean           | 87.3        |
|    ep_rew_mean           | -35.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 15          |
|    time_elapsed          | 446         |
|    total_timesteps       | 1937408     |
| train/                   |             |
|    approx_kl             | 0.015263055 |
|    clip_fraction         | 0.163       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.91        |
|    cost_value_loss       | 9.68        |
|    cost_values           | 2.48        |
|    entropy               | -0.232      |
|    entropy_loss          | -0.229      |
|    explained_variance    | 0.8         |
|    lagrangian_multiplier | 0.00404     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.23        |
|    n_updates             | 9450        |
|    policy_gradient_loss  | 0.00225     |
|    std                   | 0.372       |
|    value_loss            | 6.23        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.89        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.89        |
| reward                   | -0.15182713 |
| rollout/                 |             |
|    ep_len_mean           | 86.7        |
|    ep_rew_mean           | -35.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 16          |
|    time_elapsed          | 475         |
|    total_timesteps       | 1939456     |
| train/                   |             |
|    approx_kl             | 0.014386965 |
|    clip_fraction         | 0.195       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.72        |
|    cost_value_loss       | 8.6         |
|    cost_values           | 2.44        |
|    entropy               | -0.225      |
|    entropy_loss          | -0.228      |
|    explained_variance    | 0.795       |
|    lagrangian_multiplier | 0.00168     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.32        |
|    n_updates             | 9460        |
|    policy_gradient_loss  | 0.00383     |
|    std                   | 0.371       |
|    value_loss            | 6.53        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.5494718  |
| rollout/                 |             |
|    ep_len_mean           | 79.9        |
|    ep_rew_mean           | -33.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 17          |
|    time_elapsed          | 505         |
|    total_timesteps       | 1941504     |
| train/                   |             |
|    approx_kl             | 0.009581255 |
|    clip_fraction         | 0.16        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.66        |
|    cost_value_loss       | 9.86        |
|    cost_values           | 2.42        |
|    entropy               | -0.223      |
|    entropy_loss          | -0.223      |
|    explained_variance    | 0.818       |
|    lagrangian_multiplier | 0.00229     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.01        |
|    n_updates             | 9470        |
|    policy_gradient_loss  | 0.00608     |
|    std                   | 0.371       |
|    value_loss            | 6.61        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.30176845 |
| rollout/                 |             |
|    ep_len_mean           | 77.9        |
|    ep_rew_mean           | -32.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 18          |
|    time_elapsed          | 534         |
|    total_timesteps       | 1943552     |
| train/                   |             |
|    approx_kl             | 0.01476593  |
|    clip_fraction         | 0.172       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.6         |
|    cost_value_loss       | 9.22        |
|    cost_values           | 2.39        |
|    entropy               | -0.219      |
|    entropy_loss          | -0.221      |
|    explained_variance    | 0.849       |
|    lagrangian_multiplier | 0.00184     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.88        |
|    n_updates             | 9480        |
|    policy_gradient_loss  | 0.00814     |
|    std                   | 0.369       |
|    value_loss            | 5.67        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.2         |
| reward                   | -0.5390255  |
| rollout/                 |             |
|    ep_len_mean           | 71          |
|    ep_rew_mean           | -30.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 19          |
|    time_elapsed          | 564         |
|    total_timesteps       | 1945600     |
| train/                   |             |
|    approx_kl             | 0.009180504 |
|    clip_fraction         | 0.166       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.29        |
|    cost_value_loss       | 7.27        |
|    cost_values           | 2.37        |
|    entropy               | -0.213      |
|    entropy_loss          | -0.215      |
|    explained_variance    | 0.83        |
|    lagrangian_multiplier | 0.000645    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.22        |
|    n_updates             | 9490        |
|    policy_gradient_loss  | 0.00742     |
|    std                   | 0.367       |
|    value_loss            | 5.36        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.7752287  |
| rollout/                 |             |
|    ep_len_mean           | 71.5        |
|    ep_rew_mean           | -30.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 20          |
|    time_elapsed          | 594         |
|    total_timesteps       | 1947648     |
| train/                   |             |
|    approx_kl             | 0.019756332 |
|    clip_fraction         | 0.168       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.69        |
|    cost_value_loss       | 9.48        |
|    cost_values           | 2.38        |
|    entropy               | -0.214      |
|    entropy_loss          | -0.214      |
|    explained_variance    | 0.846       |
|    lagrangian_multiplier | 0.00219     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.86        |
|    n_updates             | 9500        |
|    policy_gradient_loss  | 0.00371     |
|    std                   | 0.368       |
|    value_loss            | 5.98        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3318908  |
| rollout/                 |             |
|    ep_len_mean           | 72.7        |
|    ep_rew_mean           | -31.5       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 21          |
|    time_elapsed          | 623         |
|    total_timesteps       | 1949696     |
| train/                   |             |
|    approx_kl             | 0.019830057 |
|    clip_fraction         | 0.173       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.19        |
|    cost_value_loss       | 6.53        |
|    cost_values           | 2.4         |
|    entropy               | -0.202      |
|    entropy_loss          | -0.21       |
|    explained_variance    | 0.868       |
|    lagrangian_multiplier | 0.00249     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.96        |
|    n_updates             | 9510        |
|    policy_gradient_loss  | 0.00524     |
|    std                   | 0.365       |
|    value_loss            | 4.76        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.7407246  |
| rollout/                 |             |
|    ep_len_mean           | 73.7        |
|    ep_rew_mean           | -31.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 22          |
|    time_elapsed          | 653         |
|    total_timesteps       | 1951744     |
| train/                   |             |
|    approx_kl             | 0.016862579 |
|    clip_fraction         | 0.193       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.21        |
|    cost_value_loss       | 7.67        |
|    cost_values           | 2.38        |
|    entropy               | -0.193      |
|    entropy_loss          | -0.197      |
|    explained_variance    | 0.842       |
|    lagrangian_multiplier | 0.000776    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.31        |
|    n_updates             | 9520        |
|    policy_gradient_loss  | 0.00457     |
|    std                   | 0.364       |
|    value_loss            | 4.91        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.21574144 |
| rollout/                 |             |
|    ep_len_mean           | 76.6        |
|    ep_rew_mean           | -32.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 23          |
|    time_elapsed          | 682         |
|    total_timesteps       | 1953792     |
| train/                   |             |
|    approx_kl             | 0.018558374 |
|    clip_fraction         | 0.206       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.47        |
|    cost_value_loss       | 7.24        |
|    cost_values           | 2.41        |
|    entropy               | -0.187      |
|    entropy_loss          | -0.189      |
|    explained_variance    | 0.852       |
|    lagrangian_multiplier | 0.00169     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.47        |
|    n_updates             | 9530        |
|    policy_gradient_loss  | 0.0107      |
|    std                   | 0.362       |
|    value_loss            | 4.75        |
------------------------------------------
------------------------------------------
| avg_speed                | 3           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3           |
| reward                   | -0.93186116 |
| rollout/                 |             |
|    ep_len_mean           | 75.4        |
|    ep_rew_mean           | -32         |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 24          |
|    time_elapsed          | 712         |
|    total_timesteps       | 1955840     |
| train/                   |             |
|    approx_kl             | 0.03886342  |
|    clip_fraction         | 0.146       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.8         |
|    cost_value_loss       | 9.32        |
|    cost_values           | 2.45        |
|    entropy               | -0.182      |
|    entropy_loss          | -0.185      |
|    explained_variance    | 0.818       |
|    lagrangian_multiplier | 0.00261     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.48        |
|    n_updates             | 9540        |
|    policy_gradient_loss  | 0.00283     |
|    std                   | 0.361       |
|    value_loss            | 5.69        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.6         |
| reward                   | -0.4185347  |
| rollout/                 |             |
|    ep_len_mean           | 76.9        |
|    ep_rew_mean           | -32.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 25          |
|    time_elapsed          | 743         |
|    total_timesteps       | 1957888     |
| train/                   |             |
|    approx_kl             | 0.009393934 |
|    clip_fraction         | 0.175       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.4         |
|    cost_value_loss       | 7.84        |
|    cost_values           | 2.43        |
|    entropy               | -0.181      |
|    entropy_loss          | -0.18       |
|    explained_variance    | 0.845       |
|    lagrangian_multiplier | 0.000586    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.57        |
|    n_updates             | 9550        |
|    policy_gradient_loss  | 0.00635     |
|    std                   | 0.362       |
|    value_loss            | 6.12        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.18771286 |
| rollout/                 |             |
|    ep_len_mean           | 78.4        |
|    ep_rew_mean           | -32.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 26          |
|    time_elapsed          | 773         |
|    total_timesteps       | 1959936     |
| train/                   |             |
|    approx_kl             | 0.026113493 |
|    clip_fraction         | 0.208       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.37        |
|    cost_value_loss       | 7.58        |
|    cost_values           | 2.41        |
|    entropy               | -0.168      |
|    entropy_loss          | -0.175      |
|    explained_variance    | 0.828       |
|    lagrangian_multiplier | 0.00124     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.09        |
|    n_updates             | 9560        |
|    policy_gradient_loss  | 0.00327     |
|    std                   | 0.359       |
|    value_loss            | 5.45        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.2         |
| reward                   | -0.32071543 |
| rollout/                 |             |
|    ep_len_mean           | 78.3        |
|    ep_rew_mean           | -32.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 27          |
|    time_elapsed          | 804         |
|    total_timesteps       | 1961984     |
| train/                   |             |
|    approx_kl             | 0.040964425 |
|    clip_fraction         | 0.175       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.53        |
|    cost_value_loss       | 7.54        |
|    cost_values           | 2.42        |
|    entropy               | -0.171      |
|    entropy_loss          | -0.167      |
|    explained_variance    | 0.822       |
|    lagrangian_multiplier | 0.00235     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.32        |
|    n_updates             | 9570        |
|    policy_gradient_loss  | 0.00832     |
|    std                   | 0.36        |
|    value_loss            | 5.18        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.20875163 |
| rollout/                 |             |
|    ep_len_mean           | 78.9        |
|    ep_rew_mean           | -32.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 28          |
|    time_elapsed          | 834         |
|    total_timesteps       | 1964032     |
| train/                   |             |
|    approx_kl             | 0.044283677 |
|    clip_fraction         | 0.17        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.54        |
|    cost_value_loss       | 7.44        |
|    cost_values           | 2.42        |
|    entropy               | -0.171      |
|    entropy_loss          | -0.171      |
|    explained_variance    | 0.786       |
|    lagrangian_multiplier | 0.00162     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.66        |
|    n_updates             | 9580        |
|    policy_gradient_loss  | 0.00669     |
|    std                   | 0.361       |
|    value_loss            | 6.19        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.20537281 |
| rollout/                 |             |
|    ep_len_mean           | 78.2        |
|    ep_rew_mean           | -32.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 29          |
|    time_elapsed          | 864         |
|    total_timesteps       | 1966080     |
| train/                   |             |
|    approx_kl             | 0.010065073 |
|    clip_fraction         | 0.159       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.75        |
|    cost_value_loss       | 9.54        |
|    cost_values           | 2.43        |
|    entropy               | -0.172      |
|    entropy_loss          | -0.172      |
|    explained_variance    | 0.835       |
|    lagrangian_multiplier | 0.00259     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.46        |
|    n_updates             | 9590        |
|    policy_gradient_loss  | 0.00727     |
|    std                   | 0.361       |
|    value_loss            | 5.73        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.2          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.2          |
| reward                   | -0.33909124  |
| rollout/                 |              |
|    ep_len_mean           | 74           |
|    ep_rew_mean           | -31.3        |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 30           |
|    time_elapsed          | 893          |
|    total_timesteps       | 1968128      |
| train/                   |              |
|    approx_kl             | 0.0147469435 |
|    clip_fraction         | 0.153        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.11         |
|    cost_value_loss       | 6.99         |
|    cost_values           | 2.39         |
|    entropy               | -0.173       |
|    entropy_loss          | -0.173       |
|    explained_variance    | 0.824        |
|    lagrangian_multiplier | 0.00116      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.83         |
|    n_updates             | 9600         |
|    policy_gradient_loss  | 0.000491     |
|    std                   | 0.361        |
|    value_loss            | 6.07         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.74        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.74        |
| reward                   | -0.22784767 |
| rollout/                 |             |
|    ep_len_mean           | 71.3        |
|    ep_rew_mean           | -30.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 31          |
|    time_elapsed          | 922         |
|    total_timesteps       | 1970176     |
| train/                   |             |
|    approx_kl             | 0.018406436 |
|    clip_fraction         | 0.16        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.36        |
|    cost_value_loss       | 7.7         |
|    cost_values           | 2.38        |
|    entropy               | -0.162      |
|    entropy_loss          | -0.168      |
|    explained_variance    | 0.86        |
|    lagrangian_multiplier | 0.00208     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.27        |
|    n_updates             | 9610        |
|    policy_gradient_loss  | -0.00118    |
|    std                   | 0.36        |
|    value_loss            | 5.02        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.88        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.88        |
| reward                   | -0.21872754 |
| rollout/                 |             |
|    ep_len_mean           | 70.5        |
|    ep_rew_mean           | -30.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 32          |
|    time_elapsed          | 952         |
|    total_timesteps       | 1972224     |
| train/                   |             |
|    approx_kl             | 0.027061185 |
|    clip_fraction         | 0.193       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.6         |
|    cost_value_loss       | 8.54        |
|    cost_values           | 2.45        |
|    entropy               | -0.153      |
|    entropy_loss          | -0.157      |
|    explained_variance    | 0.882       |
|    lagrangian_multiplier | 0.00132     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.71        |
|    n_updates             | 9620        |
|    policy_gradient_loss  | 0.00778     |
|    std                   | 0.358       |
|    value_loss            | 4.06        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.9         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.9         |
| reward                   | -0.27315506 |
| rollout/                 |             |
|    ep_len_mean           | 68          |
|    ep_rew_mean           | -29.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 33          |
|    time_elapsed          | 982         |
|    total_timesteps       | 1974272     |
| train/                   |             |
|    approx_kl             | 0.021255834 |
|    clip_fraction         | 0.181       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.61        |
|    cost_value_loss       | 8.04        |
|    cost_values           | 2.49        |
|    entropy               | -0.154      |
|    entropy_loss          | -0.153      |
|    explained_variance    | 0.867       |
|    lagrangian_multiplier | 0.00107     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.95        |
|    n_updates             | 9630        |
|    policy_gradient_loss  | 0.008       |
|    std                   | 0.358       |
|    value_loss            | 4.64        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.89379865 |
| rollout/                 |             |
|    ep_len_mean           | 70.9        |
|    ep_rew_mean           | -30.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 34          |
|    time_elapsed          | 1012        |
|    total_timesteps       | 1976320     |
| train/                   |             |
|    approx_kl             | 0.017336907 |
|    clip_fraction         | 0.224       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.34        |
|    cost_value_loss       | 7.56        |
|    cost_values           | 2.47        |
|    entropy               | -0.156      |
|    entropy_loss          | -0.155      |
|    explained_variance    | 0.884       |
|    lagrangian_multiplier | 0.0015      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.6         |
|    n_updates             | 9640        |
|    policy_gradient_loss  | 0.0103      |
|    std                   | 0.358       |
|    value_loss            | 4.51        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.7233436  |
| rollout/                 |             |
|    ep_len_mean           | 70.6        |
|    ep_rew_mean           | -30.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 35          |
|    time_elapsed          | 1041        |
|    total_timesteps       | 1978368     |
| train/                   |             |
|    approx_kl             | 0.031009117 |
|    clip_fraction         | 0.222       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.27        |
|    cost_value_loss       | 7.77        |
|    cost_values           | 2.4         |
|    entropy               | -0.15       |
|    entropy_loss          | -0.154      |
|    explained_variance    | 0.838       |
|    lagrangian_multiplier | 0.00115     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.49        |
|    n_updates             | 9650        |
|    policy_gradient_loss  | 0.00819     |
|    std                   | 0.357       |
|    value_loss            | 5.91        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.3033831  |
| rollout/                 |             |
|    ep_len_mean           | 71.2        |
|    ep_rew_mean           | -31.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 36          |
|    time_elapsed          | 1071        |
|    total_timesteps       | 1980416     |
| train/                   |             |
|    approx_kl             | 0.016459085 |
|    clip_fraction         | 0.182       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.46        |
|    cost_value_loss       | 7.77        |
|    cost_values           | 2.39        |
|    entropy               | -0.152      |
|    entropy_loss          | -0.15       |
|    explained_variance    | 0.833       |
|    lagrangian_multiplier | 0.0017      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.69        |
|    n_updates             | 9660        |
|    policy_gradient_loss  | 0.00704     |
|    std                   | 0.358       |
|    value_loss            | 5.05        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.4154657  |
| rollout/                 |             |
|    ep_len_mean           | 68.8        |
|    ep_rew_mean           | -30.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 37          |
|    time_elapsed          | 1101        |
|    total_timesteps       | 1982464     |
| train/                   |             |
|    approx_kl             | 0.009730861 |
|    clip_fraction         | 0.134       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.45        |
|    cost_value_loss       | 7.14        |
|    cost_values           | 2.42        |
|    entropy               | -0.147      |
|    entropy_loss          | -0.15       |
|    explained_variance    | 0.785       |
|    lagrangian_multiplier | 0.00188     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.32        |
|    n_updates             | 9670        |
|    policy_gradient_loss  | 0.00309     |
|    std                   | 0.357       |
|    value_loss            | 5.69        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.26276866 |
| rollout/                 |             |
|    ep_len_mean           | 73.1        |
|    ep_rew_mean           | -31.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 38          |
|    time_elapsed          | 1131        |
|    total_timesteps       | 1984512     |
| train/                   |             |
|    approx_kl             | 0.014090633 |
|    clip_fraction         | 0.154       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.39        |
|    cost_value_loss       | 8.04        |
|    cost_values           | 2.43        |
|    entropy               | -0.143      |
|    entropy_loss          | -0.145      |
|    explained_variance    | 0.844       |
|    lagrangian_multiplier | 0.000835    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.58        |
|    n_updates             | 9680        |
|    policy_gradient_loss  | 0.00494     |
|    std                   | 0.356       |
|    value_loss            | 5.66        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.88131094 |
| rollout/                 |             |
|    ep_len_mean           | 73.2        |
|    ep_rew_mean           | -31.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 39          |
|    time_elapsed          | 1161        |
|    total_timesteps       | 1986560     |
| train/                   |             |
|    approx_kl             | 0.02962274  |
|    clip_fraction         | 0.157       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.39        |
|    cost_value_loss       | 7.42        |
|    cost_values           | 2.38        |
|    entropy               | -0.133      |
|    entropy_loss          | -0.138      |
|    explained_variance    | 0.806       |
|    lagrangian_multiplier | 0.00135     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.96        |
|    n_updates             | 9690        |
|    policy_gradient_loss  | 0.00244     |
|    std                   | 0.354       |
|    value_loss            | 6.19        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.82         |
| cost                     | 0            |
| is_success               | 1            |
| max_speed                | 7.82         |
| reward                   | -0.114307046 |
| rollout/                 |              |
|    ep_len_mean           | 71.9         |
|    ep_rew_mean           | -31.7        |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 40           |
|    time_elapsed          | 1190         |
|    total_timesteps       | 1988608      |
| train/                   |              |
|    approx_kl             | 0.0058522075 |
|    clip_fraction         | 0.118        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.35         |
|    cost_value_loss       | 7.1          |
|    cost_values           | 2.38         |
|    entropy               | -0.131       |
|    entropy_loss          | -0.132       |
|    explained_variance    | 0.771        |
|    lagrangian_multiplier | 0.000271     |
|    learning_rate         | 0.0003       |
|    loss                  | 6.95         |
|    n_updates             | 9700         |
|    policy_gradient_loss  | 0.00109      |
|    std                   | 0.353        |
|    value_loss            | 8.11         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.29        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.29        |
| reward                   | -0.22280402 |
| rollout/                 |             |
|    ep_len_mean           | 74          |
|    ep_rew_mean           | -32.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 41          |
|    time_elapsed          | 1220        |
|    total_timesteps       | 1990656     |
| train/                   |             |
|    approx_kl             | 0.009640938 |
|    clip_fraction         | 0.131       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.47        |
|    cost_value_loss       | 8.27        |
|    cost_values           | 2.39        |
|    entropy               | -0.13       |
|    entropy_loss          | -0.131      |
|    explained_variance    | 0.81        |
|    lagrangian_multiplier | 0.00154     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.18        |
|    n_updates             | 9710        |
|    policy_gradient_loss  | 0.00271     |
|    std                   | 0.353       |
|    value_loss            | 6.59        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.20180674 |
| rollout/                 |             |
|    ep_len_mean           | 70.5        |
|    ep_rew_mean           | -31.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 42          |
|    time_elapsed          | 1250        |
|    total_timesteps       | 1992704     |
| train/                   |             |
|    approx_kl             | 0.020352745 |
|    clip_fraction         | 0.169       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.28        |
|    cost_value_loss       | 6.95        |
|    cost_values           | 2.34        |
|    entropy               | -0.128      |
|    entropy_loss          | -0.13       |
|    explained_variance    | 0.777       |
|    lagrangian_multiplier | 0.000963    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.4         |
|    n_updates             | 9720        |
|    policy_gradient_loss  | -0.000497   |
|    std                   | 0.352       |
|    value_loss            | 6.98        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.95         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 5.95         |
| reward                   | -0.28628764  |
| rollout/                 |              |
|    ep_len_mean           | 70.1         |
|    ep_rew_mean           | -31.5        |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 43           |
|    time_elapsed          | 1281         |
|    total_timesteps       | 1994752      |
| train/                   |              |
|    approx_kl             | 0.0090018045 |
|    clip_fraction         | 0.129        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.59         |
|    cost_value_loss       | 9.26         |
|    cost_values           | 2.33         |
|    entropy               | -0.127       |
|    entropy_loss          | -0.128       |
|    explained_variance    | 0.797        |
|    lagrangian_multiplier | 0.00161      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.23         |
|    n_updates             | 9730         |
|    policy_gradient_loss  | 0.000986     |
|    std                   | 0.353        |
|    value_loss            | 7.18         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.8         |
| reward                   | -0.6039332  |
| rollout/                 |             |
|    ep_len_mean           | 67.9        |
|    ep_rew_mean           | -30.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 44          |
|    time_elapsed          | 1311        |
|    total_timesteps       | 1996800     |
| train/                   |             |
|    approx_kl             | 0.018299773 |
|    clip_fraction         | 0.146       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.01        |
|    cost_value_loss       | 6.16        |
|    cost_values           | 2.35        |
|    entropy               | -0.122      |
|    entropy_loss          | -0.125      |
|    explained_variance    | 0.84        |
|    lagrangian_multiplier | 0.00231     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.93        |
|    n_updates             | 9740        |
|    policy_gradient_loss  | 0.00157     |
|    std                   | 0.353       |
|    value_loss            | 6.14        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 1           |
| max_speed                | 8           |
| reward                   | -0.1105754  |
| rollout/                 |             |
|    ep_len_mean           | 70          |
|    ep_rew_mean           | -30.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 45          |
|    time_elapsed          | 1340        |
|    total_timesteps       | 1998848     |
| train/                   |             |
|    approx_kl             | 0.015757091 |
|    clip_fraction         | 0.206       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.48        |
|    cost_value_loss       | 8.47        |
|    cost_values           | 2.33        |
|    entropy               | -0.12       |
|    entropy_loss          | -0.121      |
|    explained_variance    | 0.824       |
|    lagrangian_multiplier | 0.000462    |
|    learning_rate         | 0.0003      |
|    loss                  | 6.1         |
|    n_updates             | 9750        |
|    policy_gradient_loss  | 0.0055      |
|    std                   | 0.352       |
|    value_loss            | 6.07        |
------------------------------------------
-------------------------------------------
| avg_speed                | 0.2          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 0.2          |
| reward                   | -0.68711066  |
| rollout/                 |              |
|    ep_len_mean           | 69.8         |
|    ep_rew_mean           | -30.4        |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 46           |
|    time_elapsed          | 1370         |
|    total_timesteps       | 2000896      |
| train/                   |              |
|    approx_kl             | 0.0137020815 |
|    clip_fraction         | 0.171        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.71         |
|    cost_value_loss       | 9.35         |
|    cost_values           | 2.42         |
|    entropy               | -0.118       |
|    entropy_loss          | -0.119       |
|    explained_variance    | 0.84         |
|    lagrangian_multiplier | 0.00339      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.26         |
|    n_updates             | 9760         |
|    policy_gradient_loss  | 0.00636      |
|    std                   | 0.351        |
|    value_loss            | 5.47         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.8464787  |
| rollout/                 |             |
|    ep_len_mean           | 74.8        |
|    ep_rew_mean           | -32.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 47          |
|    time_elapsed          | 1399        |
|    total_timesteps       | 2002944     |
| train/                   |             |
|    approx_kl             | 0.025068723 |
|    clip_fraction         | 0.179       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.53        |
|    cost_value_loss       | 7.79        |
|    cost_values           | 2.44        |
|    entropy               | -0.111      |
|    entropy_loss          | -0.115      |
|    explained_variance    | 0.845       |
|    lagrangian_multiplier | 0.00149     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.98        |
|    n_updates             | 9770        |
|    policy_gradient_loss  | 0.00675     |
|    std                   | 0.349       |
|    value_loss            | 5.47        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.71282613 |
| rollout/                 |             |
|    ep_len_mean           | 75.3        |
|    ep_rew_mean           | -32         |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 48          |
|    time_elapsed          | 1429        |
|    total_timesteps       | 2004992     |
| train/                   |             |
|    approx_kl             | 0.011878594 |
|    clip_fraction         | 0.14        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.53        |
|    cost_value_loss       | 8.25        |
|    cost_values           | 2.43        |
|    entropy               | -0.104      |
|    entropy_loss          | -0.107      |
|    explained_variance    | 0.779       |
|    lagrangian_multiplier | 0.00259     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.46        |
|    n_updates             | 9780        |
|    policy_gradient_loss  | -0.000112   |
|    std                   | 0.347       |
|    value_loss            | 6.46        |
------------------------------------------
------------------------------------------
| avg_speed                | 5           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5           |
| reward                   | -0.58819705 |
| rollout/                 |             |
|    ep_len_mean           | 71.1        |
|    ep_rew_mean           | -30.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 49          |
|    time_elapsed          | 1460        |
|    total_timesteps       | 2007040     |
| train/                   |             |
|    approx_kl             | 0.028979514 |
|    clip_fraction         | 0.12        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.8         |
|    cost_value_loss       | 9.64        |
|    cost_values           | 2.43        |
|    entropy               | -0.1        |
|    entropy_loss          | -0.101      |
|    explained_variance    | 0.768       |
|    lagrangian_multiplier | 0.000833    |
|    learning_rate         | 0.0003      |
|    loss                  | 6.38        |
|    n_updates             | 9790        |
|    policy_gradient_loss  | -0.000532   |
|    std                   | 0.347       |
|    value_loss            | 7.34        |
------------------------------------------
------------------------------------
| avg_speed          | 8           |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 8           |
| reward             | -0.25107616 |
| rollout/           |             |
|    ep_len_mean     | 71.5        |
|    ep_rew_mean     | -31         |
| time/              |             |
|    fps             | 73          |
|    iterations      | 1           |
|    time_elapsed    | 27          |
|    total_timesteps | 2009088     |
------------------------------------
------------------------------------------
| avg_speed                | 6.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.2         |
| reward                   | -0.28917152 |
| rollout/                 |             |
|    ep_len_mean           | 68.1        |
|    ep_rew_mean           | -30.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 2           |
|    time_elapsed          | 57          |
|    total_timesteps       | 2011136     |
| train/                   |             |
|    approx_kl             | 0.03319201  |
|    clip_fraction         | 0.225       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.4         |
|    cost_value_loss       | 7.12        |
|    cost_values           | 2.43        |
|    entropy               | -0.0975     |
|    entropy_loss          | -0.0975     |
|    explained_variance    | 0.829       |
|    lagrangian_multiplier | 0.00113     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.78        |
|    n_updates             | 9810        |
|    policy_gradient_loss  | 0.00963     |
|    std                   | 0.347       |
|    value_loss            | 5.4         |
------------------------------------------
----------------------------------------
| avg_speed                | 8         |
| cost                     | 0         |
| is_success               | 0         |
| max_speed                | 8         |
| reward                   | -0.37249  |
| rollout/                 |           |
|    ep_len_mean           | 71.4      |
|    ep_rew_mean           | -31.2     |
| time/                    |           |
|    fps                   | 70        |
|    iterations            | 3         |
|    time_elapsed          | 87        |
|    total_timesteps       | 2013184   |
| train/                   |           |
|    approx_kl             | 0.0434716 |
|    clip_fraction         | 0.153     |
|    clip_range            | 0.2       |
|    cost_returns          | 4.73      |
|    cost_value_loss       | 9.34      |
|    cost_values           | 2.43      |
|    entropy               | -0.0995   |
|    entropy_loss          | -0.0983   |
|    explained_variance    | 0.863     |
|    lagrangian_multiplier | 0.00274   |
|    learning_rate         | 0.0003    |
|    loss                  | 4.3       |
|    n_updates             | 9820      |
|    policy_gradient_loss  | 0.00374   |
|    std                   | 0.347     |
|    value_loss            | 4.9       |
----------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.43365657 |
| rollout/                 |             |
|    ep_len_mean           | 76.5        |
|    ep_rew_mean           | -32.6       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 4           |
|    time_elapsed          | 117         |
|    total_timesteps       | 2015232     |
| train/                   |             |
|    approx_kl             | 0.026209274 |
|    clip_fraction         | 0.16        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.88        |
|    cost_value_loss       | 9.73        |
|    cost_values           | 2.42        |
|    entropy               | -0.102      |
|    entropy_loss          | -0.101      |
|    explained_variance    | 0.824       |
|    lagrangian_multiplier | 0.00284     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.46        |
|    n_updates             | 9830        |
|    policy_gradient_loss  | 0.00544     |
|    std                   | 0.348       |
|    value_loss            | 5.95        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2864784  |
| rollout/                 |             |
|    ep_len_mean           | 77          |
|    ep_rew_mean           | -32.7       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 5           |
|    time_elapsed          | 146         |
|    total_timesteps       | 2017280     |
| train/                   |             |
|    approx_kl             | 0.021062892 |
|    clip_fraction         | 0.198       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.9         |
|    cost_value_loss       | 10.5        |
|    cost_values           | 2.43        |
|    entropy               | -0.0995     |
|    entropy_loss          | -0.101      |
|    explained_variance    | 0.792       |
|    lagrangian_multiplier | 0.00264     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.71        |
|    n_updates             | 9840        |
|    policy_gradient_loss  | 0.00681     |
|    std                   | 0.347       |
|    value_loss            | 6.18        |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.73899347 |
| rollout/                 |             |
|    ep_len_mean           | 78.9        |
|    ep_rew_mean           | -33.1       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 6           |
|    time_elapsed          | 176         |
|    total_timesteps       | 2019328     |
| train/                   |             |
|    approx_kl             | 0.032365203 |
|    clip_fraction         | 0.22        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.59        |
|    cost_value_loss       | 8.61        |
|    cost_values           | 2.42        |
|    entropy               | -0.0928     |
|    entropy_loss          | -0.0957     |
|    explained_variance    | 0.794       |
|    lagrangian_multiplier | 0.000638    |
|    learning_rate         | 0.0003      |
|    loss                  | 6.53        |
|    n_updates             | 9850        |
|    policy_gradient_loss  | 0.0141      |
|    std                   | 0.346       |
|    value_loss            | 6.75        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.6         |
| reward                   | -0.25367418 |
| rollout/                 |             |
|    ep_len_mean           | 72.9        |
|    ep_rew_mean           | -31.8       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 7           |
|    time_elapsed          | 206         |
|    total_timesteps       | 2021376     |
| train/                   |             |
|    approx_kl             | 0.05029772  |
|    clip_fraction         | 0.193       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.73        |
|    cost_value_loss       | 9.14        |
|    cost_values           | 2.43        |
|    entropy               | -0.0964     |
|    entropy_loss          | -0.094      |
|    explained_variance    | 0.863       |
|    lagrangian_multiplier | 0.000483    |
|    learning_rate         | 0.0003      |
|    loss                  | 6.09        |
|    n_updates             | 9860        |
|    policy_gradient_loss  | 0.01        |
|    std                   | 0.347       |
|    value_loss            | 4.8         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.58        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.58        |
| reward                   | -0.3149371  |
| rollout/                 |             |
|    ep_len_mean           | 68.9        |
|    ep_rew_mean           | -30.5       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 8           |
|    time_elapsed          | 236         |
|    total_timesteps       | 2023424     |
| train/                   |             |
|    approx_kl             | 0.025914144 |
|    clip_fraction         | 0.236       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.78        |
|    cost_value_loss       | 10.9        |
|    cost_values           | 2.45        |
|    entropy               | -0.0986     |
|    entropy_loss          | -0.0975     |
|    explained_variance    | 0.91        |
|    lagrangian_multiplier | 0.000952    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.29        |
|    n_updates             | 9870        |
|    policy_gradient_loss  | 0.00943     |
|    std                   | 0.347       |
|    value_loss            | 3.82        |
------------------------------------------
-----------------------------------------
| avg_speed                | 7.61       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.61       |
| reward                   | -0.3841701 |
| rollout/                 |            |
|    ep_len_mean           | 68.1       |
|    ep_rew_mean           | -30.6      |
| time/                    |            |
|    fps                   | 69         |
|    iterations            | 9          |
|    time_elapsed          | 267        |
|    total_timesteps       | 2025472    |
| train/                   |            |
|    approx_kl             | 0.03797948 |
|    clip_fraction         | 0.27       |
|    clip_range            | 0.2        |
|    cost_returns          | 4.69       |
|    cost_value_loss       | 8.83       |
|    cost_values           | 2.45       |
|    entropy               | -0.102     |
|    entropy_loss          | -0.1       |
|    explained_variance    | 0.88       |
|    lagrangian_multiplier | 0.000723   |
|    learning_rate         | 0.0003     |
|    loss                  | 5.63       |
|    n_updates             | 9880       |
|    policy_gradient_loss  | 0.0119     |
|    std                   | 0.348      |
|    value_loss            | 4.59       |
-----------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.76337606 |
| rollout/                 |             |
|    ep_len_mean           | 68.8        |
|    ep_rew_mean           | -30.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 10          |
|    time_elapsed          | 297         |
|    total_timesteps       | 2027520     |
| train/                   |             |
|    approx_kl             | 0.026550006 |
|    clip_fraction         | 0.18        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.48        |
|    cost_value_loss       | 7.86        |
|    cost_values           | 2.43        |
|    entropy               | -0.107      |
|    entropy_loss          | -0.105      |
|    explained_variance    | 0.897       |
|    lagrangian_multiplier | 0.00168     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.38        |
|    n_updates             | 9890        |
|    policy_gradient_loss  | 0.00945     |
|    std                   | 0.349       |
|    value_loss            | 4.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.38536757 |
| rollout/                 |             |
|    ep_len_mean           | 72.3        |
|    ep_rew_mean           | -31.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 11          |
|    time_elapsed          | 327         |
|    total_timesteps       | 2029568     |
| train/                   |             |
|    approx_kl             | 0.0181246   |
|    clip_fraction         | 0.154       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.79        |
|    cost_value_loss       | 9.58        |
|    cost_values           | 2.45        |
|    entropy               | -0.108      |
|    entropy_loss          | -0.108      |
|    explained_variance    | 0.863       |
|    lagrangian_multiplier | 0.00132     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.05        |
|    n_updates             | 9900        |
|    policy_gradient_loss  | 0.00545     |
|    std                   | 0.349       |
|    value_loss            | 4.32        |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.68272346 |
| rollout/                 |             |
|    ep_len_mean           | 71.8        |
|    ep_rew_mean           | -31.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 12          |
|    time_elapsed          | 357         |
|    total_timesteps       | 2031616     |
| train/                   |             |
|    approx_kl             | 0.01134819  |
|    clip_fraction         | 0.185       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.01        |
|    cost_value_loss       | 10.5        |
|    cost_values           | 2.52        |
|    entropy               | -0.113      |
|    entropy_loss          | -0.111      |
|    explained_variance    | 0.868       |
|    lagrangian_multiplier | 0.00144     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.06        |
|    n_updates             | 9910        |
|    policy_gradient_loss  | 0.00198     |
|    std                   | 0.35        |
|    value_loss            | 4.48        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.29183963 |
| rollout/                 |             |
|    ep_len_mean           | 73.5        |
|    ep_rew_mean           | -31.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 13          |
|    time_elapsed          | 387         |
|    total_timesteps       | 2033664     |
| train/                   |             |
|    approx_kl             | 0.012849186 |
|    clip_fraction         | 0.176       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.64        |
|    cost_value_loss       | 8.58        |
|    cost_values           | 2.55        |
|    entropy               | -0.112      |
|    entropy_loss          | -0.113      |
|    explained_variance    | 0.863       |
|    lagrangian_multiplier | 0.00122     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.7         |
|    n_updates             | 9920        |
|    policy_gradient_loss  | 0.00329     |
|    std                   | 0.35        |
|    value_loss            | 4.59        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.88        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.88        |
| reward                   | -0.25159314 |
| rollout/                 |             |
|    ep_len_mean           | 73.4        |
|    ep_rew_mean           | -31.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 14          |
|    time_elapsed          | 416         |
|    total_timesteps       | 2035712     |
| train/                   |             |
|    approx_kl             | 0.019439764 |
|    clip_fraction         | 0.188       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.62        |
|    cost_value_loss       | 8.34        |
|    cost_values           | 2.49        |
|    entropy               | -0.113      |
|    entropy_loss          | -0.112      |
|    explained_variance    | 0.877       |
|    lagrangian_multiplier | 0.00215     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.18        |
|    n_updates             | 9930        |
|    policy_gradient_loss  | 0.00812     |
|    std                   | 0.351       |
|    value_loss            | 4.17        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.8          |
| reward                   | -0.843479    |
| rollout/                 |              |
|    ep_len_mean           | 72.4         |
|    ep_rew_mean           | -31          |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 15           |
|    time_elapsed          | 446          |
|    total_timesteps       | 2037760      |
| train/                   |              |
|    approx_kl             | 0.0119861495 |
|    clip_fraction         | 0.173        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.65         |
|    cost_value_loss       | 8.23         |
|    cost_values           | 2.45         |
|    entropy               | -0.11        |
|    entropy_loss          | -0.112       |
|    explained_variance    | 0.877        |
|    lagrangian_multiplier | 0.00163      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.58         |
|    n_updates             | 9940         |
|    policy_gradient_loss  | 0.00622      |
|    std                   | 0.349        |
|    value_loss            | 4.32         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.53218985 |
| rollout/                 |             |
|    ep_len_mean           | 73.2        |
|    ep_rew_mean           | -31.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 16          |
|    time_elapsed          | 475         |
|    total_timesteps       | 2039808     |
| train/                   |             |
|    approx_kl             | 0.013005756 |
|    clip_fraction         | 0.195       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.4         |
|    cost_value_loss       | 7.85        |
|    cost_values           | 2.45        |
|    entropy               | -0.114      |
|    entropy_loss          | -0.11       |
|    explained_variance    | 0.899       |
|    lagrangian_multiplier | 0.00158     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.4         |
|    n_updates             | 9950        |
|    policy_gradient_loss  | 0.00767     |
|    std                   | 0.351       |
|    value_loss            | 3.86        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.8603311  |
| rollout/                 |             |
|    ep_len_mean           | 72.7        |
|    ep_rew_mean           | -31.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 17          |
|    time_elapsed          | 505         |
|    total_timesteps       | 2041856     |
| train/                   |             |
|    approx_kl             | 0.015600419 |
|    clip_fraction         | 0.145       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.55        |
|    cost_value_loss       | 8.24        |
|    cost_values           | 2.45        |
|    entropy               | -0.114      |
|    entropy_loss          | -0.114      |
|    explained_variance    | 0.882       |
|    lagrangian_multiplier | 0.00164     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.45        |
|    n_updates             | 9960        |
|    policy_gradient_loss  | 0.00708     |
|    std                   | 0.352       |
|    value_loss            | 4.56        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.35558367 |
| rollout/                 |             |
|    ep_len_mean           | 76.4        |
|    ep_rew_mean           | -32.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 18          |
|    time_elapsed          | 534         |
|    total_timesteps       | 2043904     |
| train/                   |             |
|    approx_kl             | 0.020432973 |
|    clip_fraction         | 0.168       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.77        |
|    cost_value_loss       | 9.26        |
|    cost_values           | 2.45        |
|    entropy               | -0.113      |
|    entropy_loss          | -0.114      |
|    explained_variance    | 0.882       |
|    lagrangian_multiplier | 0.00183     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.58        |
|    n_updates             | 9970        |
|    policy_gradient_loss  | -2.35e-05   |
|    std                   | 0.351       |
|    value_loss            | 4.41        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2408136  |
| rollout/                 |             |
|    ep_len_mean           | 79.2        |
|    ep_rew_mean           | -33.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 19          |
|    time_elapsed          | 564         |
|    total_timesteps       | 2045952     |
| train/                   |             |
|    approx_kl             | 0.012233136 |
|    clip_fraction         | 0.17        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.91        |
|    cost_value_loss       | 10.3        |
|    cost_values           | 2.46        |
|    entropy               | -0.117      |
|    entropy_loss          | -0.115      |
|    explained_variance    | 0.813       |
|    lagrangian_multiplier | 0.00162     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.2         |
|    n_updates             | 9980        |
|    policy_gradient_loss  | 0.00328     |
|    std                   | 0.352       |
|    value_loss            | 5.25        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.42608878 |
| rollout/                 |             |
|    ep_len_mean           | 76.9        |
|    ep_rew_mean           | -33         |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 20          |
|    time_elapsed          | 595         |
|    total_timesteps       | 2048000     |
| train/                   |             |
|    approx_kl             | 0.012321975 |
|    clip_fraction         | 0.158       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.87        |
|    cost_value_loss       | 9.77        |
|    cost_values           | 2.49        |
|    entropy               | -0.109      |
|    entropy_loss          | -0.114      |
|    explained_variance    | 0.838       |
|    lagrangian_multiplier | 0.00165     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.37        |
|    n_updates             | 9990        |
|    policy_gradient_loss  | 0.00395     |
|    std                   | 0.35        |
|    value_loss            | 5.96        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.86        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.86        |
| reward                   | -0.39402452 |
| rollout/                 |             |
|    ep_len_mean           | 72.5        |
|    ep_rew_mean           | -31.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 21          |
|    time_elapsed          | 625         |
|    total_timesteps       | 2050048     |
| train/                   |             |
|    approx_kl             | 0.020875964 |
|    clip_fraction         | 0.19        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.62        |
|    cost_value_loss       | 8.63        |
|    cost_values           | 2.45        |
|    entropy               | -0.109      |
|    entropy_loss          | -0.108      |
|    explained_variance    | 0.824       |
|    lagrangian_multiplier | 0.00311     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.46        |
|    n_updates             | 10000       |
|    policy_gradient_loss  | 0.00847     |
|    std                   | 0.35        |
|    value_loss            | 6.41        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.30950177 |
| rollout/                 |             |
|    ep_len_mean           | 72.2        |
|    ep_rew_mean           | -31.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 22          |
|    time_elapsed          | 655         |
|    total_timesteps       | 2052096     |
| train/                   |             |
|    approx_kl             | 0.017831415 |
|    clip_fraction         | 0.178       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.61        |
|    cost_value_loss       | 8.83        |
|    cost_values           | 2.4         |
|    entropy               | -0.106      |
|    entropy_loss          | -0.107      |
|    explained_variance    | 0.871       |
|    lagrangian_multiplier | 0.00183     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.99        |
|    n_updates             | 10010       |
|    policy_gradient_loss  | 0.00171     |
|    std                   | 0.348       |
|    value_loss            | 5.54        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.26702192 |
| rollout/                 |             |
|    ep_len_mean           | 70.9        |
|    ep_rew_mean           | -30.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 23          |
|    time_elapsed          | 685         |
|    total_timesteps       | 2054144     |
| train/                   |             |
|    approx_kl             | 0.02695507  |
|    clip_fraction         | 0.205       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.92        |
|    cost_value_loss       | 10.2        |
|    cost_values           | 2.45        |
|    entropy               | -0.102      |
|    entropy_loss          | -0.104      |
|    explained_variance    | 0.839       |
|    lagrangian_multiplier | 0.000801    |
|    learning_rate         | 0.0003      |
|    loss                  | 6.3         |
|    n_updates             | 10020       |
|    policy_gradient_loss  | 0.0124      |
|    std                   | 0.348       |
|    value_loss            | 5.54        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.6         |
| reward                   | -0.8149046  |
| rollout/                 |             |
|    ep_len_mean           | 74.1        |
|    ep_rew_mean           | -31.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 24          |
|    time_elapsed          | 715         |
|    total_timesteps       | 2056192     |
| train/                   |             |
|    approx_kl             | 0.021122722 |
|    clip_fraction         | 0.19        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.67        |
|    cost_value_loss       | 8.35        |
|    cost_values           | 2.46        |
|    entropy               | -0.0955     |
|    entropy_loss          | -0.0994     |
|    explained_variance    | 0.848       |
|    lagrangian_multiplier | 0.00133     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.06        |
|    n_updates             | 10030       |
|    policy_gradient_loss  | 0.00668     |
|    std                   | 0.347       |
|    value_loss            | 5.11        |
------------------------------------------
-----------------------------------------
| avg_speed                | 3.8        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 3.8        |
| reward                   | -0.6732479 |
| rollout/                 |            |
|    ep_len_mean           | 76.4       |
|    ep_rew_mean           | -32.3      |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 25         |
|    time_elapsed          | 746        |
|    total_timesteps       | 2058240    |
| train/                   |            |
|    approx_kl             | 0.01610756 |
|    clip_fraction         | 0.175      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.69       |
|    cost_value_loss       | 8.97       |
|    cost_values           | 2.46       |
|    entropy               | -0.091     |
|    entropy_loss          | -0.0928    |
|    explained_variance    | 0.83       |
|    lagrangian_multiplier | 0.00119    |
|    learning_rate         | 0.0003     |
|    loss                  | 5.62       |
|    n_updates             | 10040      |
|    policy_gradient_loss  | 0.00235    |
|    std                   | 0.347      |
|    value_loss            | 5.97       |
-----------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.7021983  |
| rollout/                 |             |
|    ep_len_mean           | 74          |
|    ep_rew_mean           | -32.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 26          |
|    time_elapsed          | 776         |
|    total_timesteps       | 2060288     |
| train/                   |             |
|    approx_kl             | 0.009409532 |
|    clip_fraction         | 0.167       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.88        |
|    cost_value_loss       | 10.7        |
|    cost_values           | 2.45        |
|    entropy               | -0.0887     |
|    entropy_loss          | -0.0898     |
|    explained_variance    | 0.822       |
|    lagrangian_multiplier | 0.00394     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.44        |
|    n_updates             | 10050       |
|    policy_gradient_loss  | 0.00556     |
|    std                   | 0.347       |
|    value_loss            | 6.1         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.2889813  |
| rollout/                 |             |
|    ep_len_mean           | 77          |
|    ep_rew_mean           | -33         |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 27          |
|    time_elapsed          | 806         |
|    total_timesteps       | 2062336     |
| train/                   |             |
|    approx_kl             | 0.038774885 |
|    clip_fraction         | 0.185       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.55        |
|    cost_value_loss       | 8.22        |
|    cost_values           | 2.42        |
|    entropy               | -0.0816     |
|    entropy_loss          | -0.0854     |
|    explained_variance    | 0.864       |
|    lagrangian_multiplier | 0.00117     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.12        |
|    n_updates             | 10060       |
|    policy_gradient_loss  | 0.00592     |
|    std                   | 0.347       |
|    value_loss            | 5.39        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.31060973 |
| rollout/                 |             |
|    ep_len_mean           | 77.1        |
|    ep_rew_mean           | -33.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 28          |
|    time_elapsed          | 835         |
|    total_timesteps       | 2064384     |
| train/                   |             |
|    approx_kl             | 0.03912968  |
|    clip_fraction         | 0.206       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.25        |
|    cost_value_loss       | 12.3        |
|    cost_values           | 2.46        |
|    entropy               | -0.075      |
|    entropy_loss          | -0.0781     |
|    explained_variance    | 0.81        |
|    lagrangian_multiplier | 0.00252     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.25        |
|    n_updates             | 10070       |
|    policy_gradient_loss  | 0.00933     |
|    std                   | 0.347       |
|    value_loss            | 5.88        |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.73899347 |
| rollout/                 |             |
|    ep_len_mean           | 75.1        |
|    ep_rew_mean           | -33         |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 29          |
|    time_elapsed          | 865         |
|    total_timesteps       | 2066432     |
| train/                   |             |
|    approx_kl             | 0.018668368 |
|    clip_fraction         | 0.179       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.04        |
|    cost_value_loss       | 11.7        |
|    cost_values           | 2.45        |
|    entropy               | -0.0769     |
|    entropy_loss          | -0.0753     |
|    explained_variance    | 0.836       |
|    lagrangian_multiplier | 0.00259     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.08        |
|    n_updates             | 10080       |
|    policy_gradient_loss  | 0.00608     |
|    std                   | 0.347       |
|    value_loss            | 5.76        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8.03       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.03       |
| reward                   | -0.2699444 |
| rollout/                 |            |
|    ep_len_mean           | 78.6       |
|    ep_rew_mean           | -34.1      |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 30         |
|    time_elapsed          | 895        |
|    total_timesteps       | 2068480    |
| train/                   |            |
|    approx_kl             | 0.01723825 |
|    clip_fraction         | 0.15       |
|    clip_range            | 0.2        |
|    cost_returns          | 4.66       |
|    cost_value_loss       | 9.16       |
|    cost_values           | 2.45       |
|    entropy               | -0.0843    |
|    entropy_loss          | -0.0806    |
|    explained_variance    | 0.812      |
|    lagrangian_multiplier | 0.00136    |
|    learning_rate         | 0.0003     |
|    loss                  | 5.65       |
|    n_updates             | 10090      |
|    policy_gradient_loss  | 0.00481    |
|    std                   | 0.348      |
|    value_loss            | 6.82       |
-----------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.6644805  |
| rollout/                 |             |
|    ep_len_mean           | 76.3        |
|    ep_rew_mean           | -32.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 31          |
|    time_elapsed          | 925         |
|    total_timesteps       | 2070528     |
| train/                   |             |
|    approx_kl             | 0.029262671 |
|    clip_fraction         | 0.151       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.04        |
|    cost_value_loss       | 10.3        |
|    cost_values           | 2.47        |
|    entropy               | -0.0901     |
|    entropy_loss          | -0.0877     |
|    explained_variance    | 0.803       |
|    lagrangian_multiplier | 0.00194     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.37        |
|    n_updates             | 10100       |
|    policy_gradient_loss  | 0.00506     |
|    std                   | 0.349       |
|    value_loss            | 6.43        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.96        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.96        |
| reward                   | -0.2457385  |
| rollout/                 |             |
|    ep_len_mean           | 72.8        |
|    ep_rew_mean           | -31.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 32          |
|    time_elapsed          | 955         |
|    total_timesteps       | 2072576     |
| train/                   |             |
|    approx_kl             | 0.010577282 |
|    clip_fraction         | 0.2         |
|    clip_range            | 0.2         |
|    cost_returns          | 4.64        |
|    cost_value_loss       | 8.27        |
|    cost_values           | 2.46        |
|    entropy               | -0.0981     |
|    entropy_loss          | -0.0939     |
|    explained_variance    | 0.852       |
|    lagrangian_multiplier | 0.00248     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.03        |
|    n_updates             | 10110       |
|    policy_gradient_loss  | 0.00865     |
|    std                   | 0.35        |
|    value_loss            | 4.61        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.71562636 |
| rollout/                 |             |
|    ep_len_mean           | 73.5        |
|    ep_rew_mean           | -31.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 33          |
|    time_elapsed          | 984         |
|    total_timesteps       | 2074624     |
| train/                   |             |
|    approx_kl             | 0.008531474 |
|    clip_fraction         | 0.127       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.71        |
|    cost_value_loss       | 8.57        |
|    cost_values           | 2.44        |
|    entropy               | -0.109      |
|    entropy_loss          | -0.104      |
|    explained_variance    | 0.891       |
|    lagrangian_multiplier | 0.00245     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.04        |
|    n_updates             | 10120       |
|    policy_gradient_loss  | -0.00025    |
|    std                   | 0.352       |
|    value_loss            | 3.87        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.38857836 |
| rollout/                 |             |
|    ep_len_mean           | 74.2        |
|    ep_rew_mean           | -31.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 34          |
|    time_elapsed          | 1014        |
|    total_timesteps       | 2076672     |
| train/                   |             |
|    approx_kl             | 0.08079608  |
|    clip_fraction         | 0.22        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.92        |
|    cost_value_loss       | 10.3        |
|    cost_values           | 2.48        |
|    entropy               | -0.114      |
|    entropy_loss          | -0.112      |
|    explained_variance    | 0.86        |
|    lagrangian_multiplier | 0.00241     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.9         |
|    n_updates             | 10130       |
|    policy_gradient_loss  | 0.0122      |
|    std                   | 0.353       |
|    value_loss            | 4.75        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.84        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.84        |
| reward                   | -0.30014727 |
| rollout/                 |             |
|    ep_len_mean           | 76.3        |
|    ep_rew_mean           | -31.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 35          |
|    time_elapsed          | 1044        |
|    total_timesteps       | 2078720     |
| train/                   |             |
|    approx_kl             | 0.017354395 |
|    clip_fraction         | 0.197       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.09        |
|    cost_value_loss       | 10.9        |
|    cost_values           | 2.5         |
|    entropy               | -0.114      |
|    entropy_loss          | -0.115      |
|    explained_variance    | 0.875       |
|    lagrangian_multiplier | 0.00048     |
|    learning_rate         | 0.0003      |
|    loss                  | 6.5         |
|    n_updates             | 10140       |
|    policy_gradient_loss  | 0.00515     |
|    std                   | 0.352       |
|    value_loss            | 4.25        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.4         |
| reward                   | -0.6362174  |
| rollout/                 |             |
|    ep_len_mean           | 75.1        |
|    ep_rew_mean           | -31.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 36          |
|    time_elapsed          | 1074        |
|    total_timesteps       | 2080768     |
| train/                   |             |
|    approx_kl             | 0.012776801 |
|    clip_fraction         | 0.166       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.68        |
|    cost_value_loss       | 8.63        |
|    cost_values           | 2.52        |
|    entropy               | -0.106      |
|    entropy_loss          | -0.111      |
|    explained_variance    | 0.864       |
|    lagrangian_multiplier | 0.00329     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.1         |
|    n_updates             | 10150       |
|    policy_gradient_loss  | 0.00123     |
|    std                   | 0.351       |
|    value_loss            | 4.67        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.2         |
| reward                   | -0.53452486 |
| rollout/                 |             |
|    ep_len_mean           | 73.7        |
|    ep_rew_mean           | -30.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 37          |
|    time_elapsed          | 1104        |
|    total_timesteps       | 2082816     |
| train/                   |             |
|    approx_kl             | 0.012375705 |
|    clip_fraction         | 0.203       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.62        |
|    cost_value_loss       | 9.34        |
|    cost_values           | 2.47        |
|    entropy               | -0.0968     |
|    entropy_loss          | -0.1        |
|    explained_variance    | 0.884       |
|    lagrangian_multiplier | 0.00271     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.52        |
|    n_updates             | 10160       |
|    policy_gradient_loss  | 0.00686     |
|    std                   | 0.349       |
|    value_loss            | 4.16        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.2         |
| reward                   | -0.43980268 |
| rollout/                 |             |
|    ep_len_mean           | 70.4        |
|    ep_rew_mean           | -30.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 38          |
|    time_elapsed          | 1135        |
|    total_timesteps       | 2084864     |
| train/                   |             |
|    approx_kl             | 0.01227315  |
|    clip_fraction         | 0.147       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.28        |
|    cost_value_loss       | 7.17        |
|    cost_values           | 2.44        |
|    entropy               | -0.0914     |
|    entropy_loss          | -0.0945     |
|    explained_variance    | 0.878       |
|    lagrangian_multiplier | 0.000678    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.95        |
|    n_updates             | 10170       |
|    policy_gradient_loss  | 0.00443     |
|    std                   | 0.348       |
|    value_loss            | 4.6         |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.9407335  |
| rollout/                 |             |
|    ep_len_mean           | 71.3        |
|    ep_rew_mean           | -30.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 39          |
|    time_elapsed          | 1165        |
|    total_timesteps       | 2086912     |
| train/                   |             |
|    approx_kl             | 0.031963237 |
|    clip_fraction         | 0.171       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.56        |
|    cost_value_loss       | 7.89        |
|    cost_values           | 2.43        |
|    entropy               | -0.0956     |
|    entropy_loss          | -0.0927     |
|    explained_variance    | 0.86        |
|    lagrangian_multiplier | 0.00166     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.67        |
|    n_updates             | 10180       |
|    policy_gradient_loss  | 0.00324     |
|    std                   | 0.349       |
|    value_loss            | 4.4         |
------------------------------------------
------------------------------------------
| avg_speed                | 6.69        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.69        |
| reward                   | -0.30705133 |
| rollout/                 |             |
|    ep_len_mean           | 75.5        |
|    ep_rew_mean           | -31.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 40          |
|    time_elapsed          | 1196        |
|    total_timesteps       | 2088960     |
| train/                   |             |
|    approx_kl             | 0.014600576 |
|    clip_fraction         | 0.16        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.46        |
|    cost_value_loss       | 8.27        |
|    cost_values           | 2.47        |
|    entropy               | -0.0946     |
|    entropy_loss          | -0.0959     |
|    explained_variance    | 0.875       |
|    lagrangian_multiplier | 0.00137     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.89        |
|    n_updates             | 10190       |
|    policy_gradient_loss  | 0.00194     |
|    std                   | 0.349       |
|    value_loss            | 4.95        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.30629435 |
| rollout/                 |             |
|    ep_len_mean           | 76.5        |
|    ep_rew_mean           | -32.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 41          |
|    time_elapsed          | 1226        |
|    total_timesteps       | 2091008     |
| train/                   |             |
|    approx_kl             | 0.048428703 |
|    clip_fraction         | 0.19        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.53        |
|    cost_value_loss       | 7.64        |
|    cost_values           | 2.48        |
|    entropy               | -0.0932     |
|    entropy_loss          | -0.0935     |
|    explained_variance    | 0.812       |
|    lagrangian_multiplier | 0.0031      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.99        |
|    n_updates             | 10200       |
|    policy_gradient_loss  | 0.00702     |
|    std                   | 0.349       |
|    value_loss            | 5.13        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.4         |
| reward                   | -0.36797726 |
| rollout/                 |             |
|    ep_len_mean           | 77.9        |
|    ep_rew_mean           | -32.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 42          |
|    time_elapsed          | 1257        |
|    total_timesteps       | 2093056     |
| train/                   |             |
|    approx_kl             | 0.011363066 |
|    clip_fraction         | 0.161       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.69        |
|    cost_value_loss       | 9.04        |
|    cost_values           | 2.45        |
|    entropy               | -0.0957     |
|    entropy_loss          | -0.0943     |
|    explained_variance    | 0.825       |
|    lagrangian_multiplier | 0.00138     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.4         |
|    n_updates             | 10210       |
|    policy_gradient_loss  | 0.00753     |
|    std                   | 0.351       |
|    value_loss            | 5.89        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.16397537 |
| rollout/                 |             |
|    ep_len_mean           | 75          |
|    ep_rew_mean           | -31.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 43          |
|    time_elapsed          | 1287        |
|    total_timesteps       | 2095104     |
| train/                   |             |
|    approx_kl             | 0.030158512 |
|    clip_fraction         | 0.191       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.78        |
|    cost_value_loss       | 9.08        |
|    cost_values           | 2.45        |
|    entropy               | -0.0925     |
|    entropy_loss          | -0.0945     |
|    explained_variance    | 0.84        |
|    lagrangian_multiplier | 0.00264     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.48        |
|    n_updates             | 10220       |
|    policy_gradient_loss  | 0.00635     |
|    std                   | 0.351       |
|    value_loss            | 5.7         |
------------------------------------------
------------------------------------------
| avg_speed                | 6.19        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.19        |
| reward                   | -0.400155   |
| rollout/                 |             |
|    ep_len_mean           | 71.6        |
|    ep_rew_mean           | -31.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 44          |
|    time_elapsed          | 1317        |
|    total_timesteps       | 2097152     |
| train/                   |             |
|    approx_kl             | 0.027910544 |
|    clip_fraction         | 0.218       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.53        |
|    cost_value_loss       | 8.21        |
|    cost_values           | 2.45        |
|    entropy               | -0.0867     |
|    entropy_loss          | -0.0902     |
|    explained_variance    | 0.876       |
|    lagrangian_multiplier | 0.00158     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.72        |
|    n_updates             | 10230       |
|    policy_gradient_loss  | 0.00624     |
|    std                   | 0.349       |
|    value_loss            | 4.75        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.3954337  |
| rollout/                 |             |
|    ep_len_mean           | 69.9        |
|    ep_rew_mean           | -30.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 45          |
|    time_elapsed          | 1347        |
|    total_timesteps       | 2099200     |
| train/                   |             |
|    approx_kl             | 0.014022386 |
|    clip_fraction         | 0.175       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.64        |
|    cost_value_loss       | 8.52        |
|    cost_values           | 2.45        |
|    entropy               | -0.0875     |
|    entropy_loss          | -0.086      |
|    explained_variance    | 0.882       |
|    lagrangian_multiplier | 0.00148     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.84        |
|    n_updates             | 10240       |
|    policy_gradient_loss  | 0.00905     |
|    std                   | 0.349       |
|    value_loss            | 4.96        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.20139648 |
| rollout/                 |             |
|    ep_len_mean           | 71          |
|    ep_rew_mean           | -31.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 46          |
|    time_elapsed          | 1376        |
|    total_timesteps       | 2101248     |
| train/                   |             |
|    approx_kl             | 0.050381117 |
|    clip_fraction         | 0.217       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.12        |
|    cost_value_loss       | 6.53        |
|    cost_values           | 2.44        |
|    entropy               | -0.0858     |
|    entropy_loss          | -0.0874     |
|    explained_variance    | 0.883       |
|    lagrangian_multiplier | 0.000808    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.46        |
|    n_updates             | 10250       |
|    policy_gradient_loss  | 0.00502     |
|    std                   | 0.348       |
|    value_loss            | 4.35        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.67511845 |
| rollout/                 |             |
|    ep_len_mean           | 73.8        |
|    ep_rew_mean           | -32.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 47          |
|    time_elapsed          | 1405        |
|    total_timesteps       | 2103296     |
| train/                   |             |
|    approx_kl             | 0.019780038 |
|    clip_fraction         | 0.171       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.74        |
|    cost_value_loss       | 8.48        |
|    cost_values           | 2.46        |
|    entropy               | -0.0857     |
|    entropy_loss          | -0.0853     |
|    explained_variance    | 0.847       |
|    lagrangian_multiplier | 0.00124     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.03        |
|    n_updates             | 10260       |
|    policy_gradient_loss  | 0.00595     |
|    std                   | 0.347       |
|    value_loss            | 5.53        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.2538339   |
| rollout/                 |              |
|    ep_len_mean           | 81.2         |
|    ep_rew_mean           | -34.3        |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 48           |
|    time_elapsed          | 1435         |
|    total_timesteps       | 2105344      |
| train/                   |              |
|    approx_kl             | 0.0124825835 |
|    clip_fraction         | 0.163        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.98         |
|    cost_value_loss       | 6.6          |
|    cost_values           | 2.45         |
|    entropy               | -0.0856      |
|    entropy_loss          | -0.0854      |
|    explained_variance    | 0.859        |
|    lagrangian_multiplier | 0.000136     |
|    learning_rate         | 0.0003       |
|    loss                  | 6.12         |
|    n_updates             | 10270        |
|    policy_gradient_loss  | 0.00548      |
|    std                   | 0.348        |
|    value_loss            | 5.99         |
-------------------------------------------
------------------------------------------
| avg_speed                | 6.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.8         |
| reward                   | -0.19860247 |
| rollout/                 |             |
|    ep_len_mean           | 83.2        |
|    ep_rew_mean           | -34.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 49          |
|    time_elapsed          | 1464        |
|    total_timesteps       | 2107392     |
| train/                   |             |
|    approx_kl             | 0.026877828 |
|    clip_fraction         | 0.162       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.34        |
|    cost_value_loss       | 7.51        |
|    cost_values           | 2.41        |
|    entropy               | -0.0889     |
|    entropy_loss          | -0.0873     |
|    explained_variance    | 0.844       |
|    lagrangian_multiplier | 0.000661    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.21        |
|    n_updates             | 10280       |
|    policy_gradient_loss  | 0.00441     |
|    std                   | 0.35        |
|    value_loss            | 4.91        |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ent-coefficient-ppol/vlorgroe
------------------------------------
| avg_speed          | 7.83        |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 7.83        |
| reward             | -0.18507457 |
| rollout/           |             |
|    ep_len_mean     | 85.1        |
|    ep_rew_mean     | -35.3       |
| time/              |             |
|    fps             | 74          |
|    iterations      | 1           |
|    time_elapsed    | 27          |
|    total_timesteps | 2109440     |
------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.33022335 |
| rollout/                 |             |
|    ep_len_mean           | 87.3        |
|    ep_rew_mean           | -35.9       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 2           |
|    time_elapsed          | 57          |
|    total_timesteps       | 2111488     |
| train/                   |             |
|    approx_kl             | 0.013598427 |
|    clip_fraction         | 0.153       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.56        |
|    cost_value_loss       | 7.43        |
|    cost_values           | 2.45        |
|    entropy               | -0.0855     |
|    entropy_loss          | -0.0853     |
|    explained_variance    | 0.783       |
|    lagrangian_multiplier | 0.00206     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.78        |
|    n_updates             | 10300       |
|    policy_gradient_loss  | 0.00452     |
|    std                   | 0.351       |
|    value_loss            | 7.48        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.83        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.83        |
| reward                   | -0.2368287  |
| rollout/                 |             |
|    ep_len_mean           | 82.5        |
|    ep_rew_mean           | -34.5       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 3           |
|    time_elapsed          | 87          |
|    total_timesteps       | 2113536     |
| train/                   |             |
|    approx_kl             | 0.007111636 |
|    clip_fraction         | 0.126       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.24        |
|    cost_value_loss       | 6.35        |
|    cost_values           | 2.44        |
|    entropy               | -0.0708     |
|    entropy_loss          | -0.0796     |
|    explained_variance    | 0.847       |
|    lagrangian_multiplier | 0.000495    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.47        |
|    n_updates             | 10310       |
|    policy_gradient_loss  | -0.00059    |
|    std                   | 0.348       |
|    value_loss            | 6.43        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.57805693 |
| rollout/                 |             |
|    ep_len_mean           | 82          |
|    ep_rew_mean           | -34.8       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 4           |
|    time_elapsed          | 118         |
|    total_timesteps       | 2115584     |
| train/                   |             |
|    approx_kl             | 0.020247994 |
|    clip_fraction         | 0.19        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.58        |
|    cost_value_loss       | 7.98        |
|    cost_values           | 2.42        |
|    entropy               | -0.0664     |
|    entropy_loss          | -0.0668     |
|    explained_variance    | 0.818       |
|    lagrangian_multiplier | 0.0011      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.51        |
|    n_updates             | 10320       |
|    policy_gradient_loss  | 0.00538     |
|    std                   | 0.347       |
|    value_loss            | 6.64        |
------------------------------------------
------------------------------------------
| avg_speed                | 3           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3           |
| reward                   | -0.7396582  |
| rollout/                 |             |
|    ep_len_mean           | 77.1        |
|    ep_rew_mean           | -33.5       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 5           |
|    time_elapsed          | 148         |
|    total_timesteps       | 2117632     |
| train/                   |             |
|    approx_kl             | 0.015798928 |
|    clip_fraction         | 0.191       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.01        |
|    cost_value_loss       | 6.49        |
|    cost_values           | 2.4         |
|    entropy               | -0.0556     |
|    entropy_loss          | -0.0613     |
|    explained_variance    | 0.82        |
|    lagrangian_multiplier | 0.00105     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.46        |
|    n_updates             | 10330       |
|    policy_gradient_loss  | 0.00567     |
|    std                   | 0.345       |
|    value_loss            | 7.2         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.19205776 |
| rollout/                 |             |
|    ep_len_mean           | 75.9        |
|    ep_rew_mean           | -32.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 6           |
|    time_elapsed          | 179         |
|    total_timesteps       | 2119680     |
| train/                   |             |
|    approx_kl             | 0.02105224  |
|    clip_fraction         | 0.164       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.61        |
|    cost_value_loss       | 8.76        |
|    cost_values           | 2.38        |
|    entropy               | -0.0452     |
|    entropy_loss          | -0.05       |
|    explained_variance    | 0.791       |
|    lagrangian_multiplier | 0.00239     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.17        |
|    n_updates             | 10340       |
|    policy_gradient_loss  | 0.00433     |
|    std                   | 0.342       |
|    value_loss            | 8.46        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.55886364 |
| rollout/                 |             |
|    ep_len_mean           | 71.6        |
|    ep_rew_mean           | -31.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 7           |
|    time_elapsed          | 209         |
|    total_timesteps       | 2121728     |
| train/                   |             |
|    approx_kl             | 0.020214071 |
|    clip_fraction         | 0.169       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.02        |
|    cost_value_loss       | 5.68        |
|    cost_values           | 2.36        |
|    entropy               | -0.0363     |
|    entropy_loss          | -0.0403     |
|    explained_variance    | 0.799       |
|    lagrangian_multiplier | 0.000623    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.4         |
|    n_updates             | 10350       |
|    policy_gradient_loss  | -0.00071    |
|    std                   | 0.341       |
|    value_loss            | 7.34        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.19958818 |
| rollout/                 |             |
|    ep_len_mean           | 67.4        |
|    ep_rew_mean           | -29.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 8           |
|    time_elapsed          | 240         |
|    total_timesteps       | 2123776     |
| train/                   |             |
|    approx_kl             | 0.015629532 |
|    clip_fraction         | 0.142       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.34        |
|    cost_value_loss       | 7.02        |
|    cost_values           | 2.38        |
|    entropy               | -0.0379     |
|    entropy_loss          | -0.0367     |
|    explained_variance    | 0.835       |
|    lagrangian_multiplier | 0.00113     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.28        |
|    n_updates             | 10360       |
|    policy_gradient_loss  | -0.00592    |
|    std                   | 0.342       |
|    value_loss            | 6.55        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 1           |
| max_speed                | 8           |
| reward                   | -0.11264866 |
| rollout/                 |             |
|    ep_len_mean           | 69.7        |
|    ep_rew_mean           | -30         |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 9           |
|    time_elapsed          | 271         |
|    total_timesteps       | 2125824     |
| train/                   |             |
|    approx_kl             | 0.032461993 |
|    clip_fraction         | 0.199       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.16        |
|    cost_value_loss       | 6.63        |
|    cost_values           | 2.42        |
|    entropy               | -0.0317     |
|    entropy_loss          | -0.0355     |
|    explained_variance    | 0.876       |
|    lagrangian_multiplier | 0.000706    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.6         |
|    n_updates             | 10370       |
|    policy_gradient_loss  | 0.0101      |
|    std                   | 0.341       |
|    value_loss            | 4.64        |
------------------------------------------
------------------------------------------
| avg_speed                | 3           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3           |
| reward                   | -0.76940477 |
| rollout/                 |             |
|    ep_len_mean           | 70.8        |
|    ep_rew_mean           | -30         |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 10          |
|    time_elapsed          | 301         |
|    total_timesteps       | 2127872     |
| train/                   |             |
|    approx_kl             | 0.02446204  |
|    clip_fraction         | 0.178       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.41        |
|    cost_value_loss       | 7.04        |
|    cost_values           | 2.43        |
|    entropy               | -0.0319     |
|    entropy_loss          | -0.0308     |
|    explained_variance    | 0.86        |
|    lagrangian_multiplier | 0.000129    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.21        |
|    n_updates             | 10380       |
|    policy_gradient_loss  | 0.00776     |
|    std                   | 0.342       |
|    value_loss            | 4.34        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.54854625 |
| rollout/                 |             |
|    ep_len_mean           | 72.4        |
|    ep_rew_mean           | -30.8       |
| time/                    |             |
|    fps                   | 67          |
|    iterations            | 11          |
|    time_elapsed          | 331         |
|    total_timesteps       | 2129920     |
| train/                   |             |
|    approx_kl             | 0.016444832 |
|    clip_fraction         | 0.188       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.39        |
|    cost_value_loss       | 7.43        |
|    cost_values           | 2.42        |
|    entropy               | -0.0448     |
|    entropy_loss          | -0.0378     |
|    explained_variance    | 0.866       |
|    lagrangian_multiplier | 0.000331    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.16        |
|    n_updates             | 10390       |
|    policy_gradient_loss  | 0.008       |
|    std                   | 0.344       |
|    value_loss            | 4.82        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.37471363 |
| rollout/                 |             |
|    ep_len_mean           | 71.3        |
|    ep_rew_mean           | -30.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 12          |
|    time_elapsed          | 361         |
|    total_timesteps       | 2131968     |
| train/                   |             |
|    approx_kl             | 0.016963432 |
|    clip_fraction         | 0.19        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.5         |
|    cost_value_loss       | 7.97        |
|    cost_values           | 2.42        |
|    entropy               | -0.0425     |
|    entropy_loss          | -0.0446     |
|    explained_variance    | 0.843       |
|    lagrangian_multiplier | 0.00125     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.81        |
|    n_updates             | 10400       |
|    policy_gradient_loss  | 0.00138     |
|    std                   | 0.344       |
|    value_loss            | 5.63        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.56        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.56        |
| reward                   | -0.32373843 |
| rollout/                 |             |
|    ep_len_mean           | 71.9        |
|    ep_rew_mean           | -31.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 13          |
|    time_elapsed          | 390         |
|    total_timesteps       | 2134016     |
| train/                   |             |
|    approx_kl             | 0.040414453 |
|    clip_fraction         | 0.229       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.46        |
|    cost_value_loss       | 7.42        |
|    cost_values           | 2.44        |
|    entropy               | -0.0389     |
|    entropy_loss          | -0.0403     |
|    explained_variance    | 0.884       |
|    lagrangian_multiplier | 0.00112     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.41        |
|    n_updates             | 10410       |
|    policy_gradient_loss  | 0.00921     |
|    std                   | 0.344       |
|    value_loss            | 4.36        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.85620236 |
| rollout/                 |             |
|    ep_len_mean           | 69.9        |
|    ep_rew_mean           | -31.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 14          |
|    time_elapsed          | 420         |
|    total_timesteps       | 2136064     |
| train/                   |             |
|    approx_kl             | 0.02764484  |
|    clip_fraction         | 0.205       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.3         |
|    cost_value_loss       | 7.34        |
|    cost_values           | 2.42        |
|    entropy               | -0.0313     |
|    entropy_loss          | -0.0352     |
|    explained_variance    | 0.884       |
|    lagrangian_multiplier | 0.00089     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.8         |
|    n_updates             | 10420       |
|    policy_gradient_loss  | 0.0102      |
|    std                   | 0.342       |
|    value_loss            | 4.84        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.89        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.89        |
| reward                   | -0.25233027 |
| rollout/                 |             |
|    ep_len_mean           | 73.1        |
|    ep_rew_mean           | -32         |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 15          |
|    time_elapsed          | 449         |
|    total_timesteps       | 2138112     |
| train/                   |             |
|    approx_kl             | 0.03533441  |
|    clip_fraction         | 0.24        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.5         |
|    cost_value_loss       | 8.31        |
|    cost_values           | 2.43        |
|    entropy               | -0.0278     |
|    entropy_loss          | -0.0292     |
|    explained_variance    | 0.913       |
|    lagrangian_multiplier | 0.00257     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.09        |
|    n_updates             | 10430       |
|    policy_gradient_loss  | 0.0155      |
|    std                   | 0.341       |
|    value_loss            | 3.45        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 1           |
| max_speed                | 8           |
| reward                   | -0.11739596 |
| rollout/                 |             |
|    ep_len_mean           | 73.4        |
|    ep_rew_mean           | -32.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 16          |
|    time_elapsed          | 479         |
|    total_timesteps       | 2140160     |
| train/                   |             |
|    approx_kl             | 0.028338604 |
|    clip_fraction         | 0.198       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.21        |
|    cost_value_loss       | 6.86        |
|    cost_values           | 2.36        |
|    entropy               | -0.0209     |
|    entropy_loss          | -0.025      |
|    explained_variance    | 0.795       |
|    lagrangian_multiplier | 0.000391    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.64        |
|    n_updates             | 10440       |
|    policy_gradient_loss  | 0.00638     |
|    std                   | 0.34        |
|    value_loss            | 5.59        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.17123058 |
| rollout/                 |             |
|    ep_len_mean           | 70.4        |
|    ep_rew_mean           | -31.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 17          |
|    time_elapsed          | 509         |
|    total_timesteps       | 2142208     |
| train/                   |             |
|    approx_kl             | 0.02476504  |
|    clip_fraction         | 0.216       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.22        |
|    cost_value_loss       | 7.58        |
|    cost_values           | 2.36        |
|    entropy               | -0.018      |
|    entropy_loss          | -0.0189     |
|    explained_variance    | 0.886       |
|    lagrangian_multiplier | 0.000837    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.82        |
|    n_updates             | 10450       |
|    policy_gradient_loss  | 0.00883     |
|    std                   | 0.34        |
|    value_loss            | 4.5         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.41420856 |
| rollout/                 |             |
|    ep_len_mean           | 75.3        |
|    ep_rew_mean           | -32.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 18          |
|    time_elapsed          | 538         |
|    total_timesteps       | 2144256     |
| train/                   |             |
|    approx_kl             | 0.03201896  |
|    clip_fraction         | 0.204       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.42        |
|    cost_value_loss       | 7.31        |
|    cost_values           | 2.39        |
|    entropy               | -0.00942    |
|    entropy_loss          | -0.0134     |
|    explained_variance    | 0.914       |
|    lagrangian_multiplier | 0.000847    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.25        |
|    n_updates             | 10460       |
|    policy_gradient_loss  | 0.00354     |
|    std                   | 0.338       |
|    value_loss            | 3.35        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.01         |
| reward                   | -0.3724158   |
| rollout/                 |              |
|    ep_len_mean           | 70.7         |
|    ep_rew_mean           | -31.7        |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 19           |
|    time_elapsed          | 568          |
|    total_timesteps       | 2146304      |
| train/                   |              |
|    approx_kl             | 0.0112980995 |
|    clip_fraction         | 0.211        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.16         |
|    cost_value_loss       | 6.13         |
|    cost_values           | 2.41         |
|    entropy               | -0.00543     |
|    entropy_loss          | -0.00699     |
|    explained_variance    | 0.855        |
|    lagrangian_multiplier | 0.000926     |
|    learning_rate         | 0.0003       |
|    loss                  | 4.55         |
|    n_updates             | 10470        |
|    policy_gradient_loss  | 0.0066       |
|    std                   | 0.336        |
|    value_loss            | 4.95         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.76581323 |
| rollout/                 |             |
|    ep_len_mean           | 74          |
|    ep_rew_mean           | -32.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 20          |
|    time_elapsed          | 598         |
|    total_timesteps       | 2148352     |
| train/                   |             |
|    approx_kl             | 0.024132578 |
|    clip_fraction         | 0.157       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.76        |
|    cost_value_loss       | 9.17        |
|    cost_values           | 2.43        |
|    entropy               | 0.000199    |
|    entropy_loss          | -0.003      |
|    explained_variance    | 0.853       |
|    lagrangian_multiplier | 0.00187     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.04        |
|    n_updates             | 10480       |
|    policy_gradient_loss  | 0.00121     |
|    std                   | 0.335       |
|    value_loss            | 5.41        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.17824546 |
| rollout/                 |             |
|    ep_len_mean           | 70.7        |
|    ep_rew_mean           | -31.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 21          |
|    time_elapsed          | 629         |
|    total_timesteps       | 2150400     |
| train/                   |             |
|    approx_kl             | 0.015924457 |
|    clip_fraction         | 0.178       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.59        |
|    cost_value_loss       | 7.7         |
|    cost_values           | 2.44        |
|    entropy               | 0.0029      |
|    entropy_loss          | 0.00142     |
|    explained_variance    | 0.817       |
|    lagrangian_multiplier | 0.00141     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.17        |
|    n_updates             | 10490       |
|    policy_gradient_loss  | 0.00571     |
|    std                   | 0.335       |
|    value_loss            | 6.01        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.68711066 |
| rollout/                 |             |
|    ep_len_mean           | 74.1        |
|    ep_rew_mean           | -32         |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 22          |
|    time_elapsed          | 660         |
|    total_timesteps       | 2152448     |
| train/                   |             |
|    approx_kl             | 0.01700158  |
|    clip_fraction         | 0.216       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.66        |
|    cost_value_loss       | 8.58        |
|    cost_values           | 2.43        |
|    entropy               | 0.00744     |
|    entropy_loss          | 0.00482     |
|    explained_variance    | 0.839       |
|    lagrangian_multiplier | 0.00137     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.4         |
|    n_updates             | 10500       |
|    policy_gradient_loss  | 0.00823     |
|    std                   | 0.334       |
|    value_loss            | 5.74        |
------------------------------------------
------------------------------------------
| avg_speed                | 5           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5           |
| reward                   | -0.1844428  |
| rollout/                 |             |
|    ep_len_mean           | 72.6        |
|    ep_rew_mean           | -31.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 23          |
|    time_elapsed          | 690         |
|    total_timesteps       | 2154496     |
| train/                   |             |
|    approx_kl             | 0.015065826 |
|    clip_fraction         | 0.165       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.66        |
|    cost_value_loss       | 8.42        |
|    cost_values           | 2.42        |
|    entropy               | 0.00834     |
|    entropy_loss          | 0.008       |
|    explained_variance    | 0.81        |
|    lagrangian_multiplier | 0.00221     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.69        |
|    n_updates             | 10510       |
|    policy_gradient_loss  | -0.000517   |
|    std                   | 0.334       |
|    value_loss            | 6.1         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3285311  |
| rollout/                 |             |
|    ep_len_mean           | 73.3        |
|    ep_rew_mean           | -31.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 24          |
|    time_elapsed          | 720         |
|    total_timesteps       | 2156544     |
| train/                   |             |
|    approx_kl             | 0.015045729 |
|    clip_fraction         | 0.191       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.42        |
|    cost_value_loss       | 7.94        |
|    cost_values           | 2.42        |
|    entropy               | 0.012       |
|    entropy_loss          | 0.00995     |
|    explained_variance    | 0.888       |
|    lagrangian_multiplier | 0.000868    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.92        |
|    n_updates             | 10520       |
|    policy_gradient_loss  | 0.00901     |
|    std                   | 0.334       |
|    value_loss            | 4.48        |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.86145884 |
| rollout/                 |             |
|    ep_len_mean           | 73.9        |
|    ep_rew_mean           | -31.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 25          |
|    time_elapsed          | 751         |
|    total_timesteps       | 2158592     |
| train/                   |             |
|    approx_kl             | 0.012895813 |
|    clip_fraction         | 0.168       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.42        |
|    cost_value_loss       | 7.5         |
|    cost_values           | 2.37        |
|    entropy               | 0.0176      |
|    entropy_loss          | 0.0149      |
|    explained_variance    | 0.814       |
|    lagrangian_multiplier | 0.00156     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.58        |
|    n_updates             | 10530       |
|    policy_gradient_loss  | 0.00264     |
|    std                   | 0.333       |
|    value_loss            | 5.53        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.2         |
| reward                   | -0.31284255 |
| rollout/                 |             |
|    ep_len_mean           | 72.3        |
|    ep_rew_mean           | -31.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 26          |
|    time_elapsed          | 781         |
|    total_timesteps       | 2160640     |
| train/                   |             |
|    approx_kl             | 0.018298227 |
|    clip_fraction         | 0.194       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.51        |
|    cost_value_loss       | 8.17        |
|    cost_values           | 2.41        |
|    entropy               | 0.0119      |
|    entropy_loss          | 0.0152      |
|    explained_variance    | 0.902       |
|    lagrangian_multiplier | 0.000801    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.96        |
|    n_updates             | 10540       |
|    policy_gradient_loss  | 0.00692     |
|    std                   | 0.334       |
|    value_loss            | 3.59        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.26408902 |
| rollout/                 |             |
|    ep_len_mean           | 71.6        |
|    ep_rew_mean           | -31.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 27          |
|    time_elapsed          | 811         |
|    total_timesteps       | 2162688     |
| train/                   |             |
|    approx_kl             | 0.034702636 |
|    clip_fraction         | 0.207       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.43        |
|    cost_value_loss       | 7.74        |
|    cost_values           | 2.41        |
|    entropy               | 0.0107      |
|    entropy_loss          | 0.011       |
|    explained_variance    | 0.899       |
|    lagrangian_multiplier | 0.00169     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.44        |
|    n_updates             | 10550       |
|    policy_gradient_loss  | 0.00476     |
|    std                   | 0.334       |
|    value_loss            | 4.38        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.8581075  |
| rollout/                 |             |
|    ep_len_mean           | 73.4        |
|    ep_rew_mean           | -32.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 28          |
|    time_elapsed          | 840         |
|    total_timesteps       | 2164736     |
| train/                   |             |
|    approx_kl             | 0.025760189 |
|    clip_fraction         | 0.184       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.36        |
|    cost_value_loss       | 6.94        |
|    cost_values           | 2.41        |
|    entropy               | 0.0169      |
|    entropy_loss          | 0.0135      |
|    explained_variance    | 0.839       |
|    lagrangian_multiplier | 0.000831    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.22        |
|    n_updates             | 10560       |
|    policy_gradient_loss  | 0.00623     |
|    std                   | 0.334       |
|    value_loss            | 5.8         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.26096758 |
| rollout/                 |             |
|    ep_len_mean           | 74          |
|    ep_rew_mean           | -32.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 29          |
|    time_elapsed          | 870         |
|    total_timesteps       | 2166784     |
| train/                   |             |
|    approx_kl             | 0.036032192 |
|    clip_fraction         | 0.242       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.6         |
|    cost_value_loss       | 8.57        |
|    cost_values           | 2.37        |
|    entropy               | 0.0169      |
|    entropy_loss          | 0.0177      |
|    explained_variance    | 0.798       |
|    lagrangian_multiplier | 0.00195     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.79        |
|    n_updates             | 10570       |
|    policy_gradient_loss  | 0.0157      |
|    std                   | 0.334       |
|    value_loss            | 5.54        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.2122823   |
| rollout/                 |              |
|    ep_len_mean           | 74.3         |
|    ep_rew_mean           | -32.3        |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 30           |
|    time_elapsed          | 899          |
|    total_timesteps       | 2168832      |
| train/                   |              |
|    approx_kl             | 0.0136992205 |
|    clip_fraction         | 0.175        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.7          |
|    cost_value_loss       | 8.94         |
|    cost_values           | 2.39         |
|    entropy               | 0.0181       |
|    entropy_loss          | 0.0172       |
|    explained_variance    | 0.819        |
|    lagrangian_multiplier | 0.00084      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.95         |
|    n_updates             | 10580        |
|    policy_gradient_loss  | 0.00605      |
|    std                   | 0.334        |
|    value_loss            | 6.16         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 0.8        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.8        |
| reward                   | -0.8696715 |
| rollout/                 |            |
|    ep_len_mean           | 79.9       |
|    ep_rew_mean           | -34.3      |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 31         |
|    time_elapsed          | 928        |
|    total_timesteps       | 2170880    |
| train/                   |            |
|    approx_kl             | 0.03563781 |
|    clip_fraction         | 0.206      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.17       |
|    cost_value_loss       | 6.98       |
|    cost_values           | 2.4        |
|    entropy               | 0.0242     |
|    entropy_loss          | 0.0215     |
|    explained_variance    | 0.875      |
|    lagrangian_multiplier | 0.000224   |
|    learning_rate         | 0.0003     |
|    loss                  | 4.89       |
|    n_updates             | 10590      |
|    policy_gradient_loss  | 0.00685    |
|    std                   | 0.332      |
|    value_loss            | 4.65       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.30757105 |
| rollout/                 |             |
|    ep_len_mean           | 74.3        |
|    ep_rew_mean           | -32.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 32          |
|    time_elapsed          | 958         |
|    total_timesteps       | 2172928     |
| train/                   |             |
|    approx_kl             | 0.014573292 |
|    clip_fraction         | 0.208       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.63        |
|    cost_value_loss       | 8.92        |
|    cost_values           | 2.33        |
|    entropy               | 0.0201      |
|    entropy_loss          | 0.0227      |
|    explained_variance    | 0.756       |
|    lagrangian_multiplier | 0.000299    |
|    learning_rate         | 0.0003      |
|    loss                  | 7.66        |
|    n_updates             | 10600       |
|    policy_gradient_loss  | 0.0101      |
|    std                   | 0.333       |
|    value_loss            | 7.94        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.68        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.68        |
| reward                   | -0.3518675  |
| rollout/                 |             |
|    ep_len_mean           | 74.8        |
|    ep_rew_mean           | -32.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 33          |
|    time_elapsed          | 988         |
|    total_timesteps       | 2174976     |
| train/                   |             |
|    approx_kl             | 0.012591732 |
|    clip_fraction         | 0.18        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.44        |
|    cost_value_loss       | 7.69        |
|    cost_values           | 2.37        |
|    entropy               | 0.0205      |
|    entropy_loss          | 0.0202      |
|    explained_variance    | 0.815       |
|    lagrangian_multiplier | 0.000815    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.86        |
|    n_updates             | 10610       |
|    policy_gradient_loss  | 0.00585     |
|    std                   | 0.333       |
|    value_loss            | 6.98        |
------------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.47377795 |
| rollout/                 |             |
|    ep_len_mean           | 75.8        |
|    ep_rew_mean           | -32.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 34          |
|    time_elapsed          | 1018        |
|    total_timesteps       | 2177024     |
| train/                   |             |
|    approx_kl             | 0.044489384 |
|    clip_fraction         | 0.189       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.61        |
|    cost_value_loss       | 9.04        |
|    cost_values           | 2.41        |
|    entropy               | 0.0211      |
|    entropy_loss          | 0.0213      |
|    explained_variance    | 0.882       |
|    lagrangian_multiplier | 0.000626    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.64        |
|    n_updates             | 10620       |
|    policy_gradient_loss  | 0.00584     |
|    std                   | 0.333       |
|    value_loss            | 4.31        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.22681135 |
| rollout/                 |             |
|    ep_len_mean           | 73          |
|    ep_rew_mean           | -31.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 35          |
|    time_elapsed          | 1048        |
|    total_timesteps       | 2179072     |
| train/                   |             |
|    approx_kl             | 0.019291613 |
|    clip_fraction         | 0.149       |
|    clip_range            | 0.2         |
|    cost_returns          | 5.01        |
|    cost_value_loss       | 11.1        |
|    cost_values           | 2.41        |
|    entropy               | 0.0185      |
|    entropy_loss          | 0.0195      |
|    explained_variance    | 0.817       |
|    lagrangian_multiplier | 0.00247     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.18        |
|    n_updates             | 10630       |
|    policy_gradient_loss  | 0.00194     |
|    std                   | 0.334       |
|    value_loss            | 6.42        |
------------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.6501967  |
| rollout/                 |             |
|    ep_len_mean           | 75.4        |
|    ep_rew_mean           | -33         |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 36          |
|    time_elapsed          | 1079        |
|    total_timesteps       | 2181120     |
| train/                   |             |
|    approx_kl             | 0.025845144 |
|    clip_fraction         | 0.212       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.68        |
|    cost_value_loss       | 8.74        |
|    cost_values           | 2.4         |
|    entropy               | 0.0214      |
|    entropy_loss          | 0.0198      |
|    explained_variance    | 0.81        |
|    lagrangian_multiplier | 0.002       |
|    learning_rate         | 0.0003      |
|    loss                  | 4.73        |
|    n_updates             | 10640       |
|    policy_gradient_loss  | 0.00571     |
|    std                   | 0.333       |
|    value_loss            | 6.2         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.22419596 |
| rollout/                 |             |
|    ep_len_mean           | 74.5        |
|    ep_rew_mean           | -32.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 37          |
|    time_elapsed          | 1109        |
|    total_timesteps       | 2183168     |
| train/                   |             |
|    approx_kl             | 0.017220642 |
|    clip_fraction         | 0.156       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.16        |
|    cost_value_loss       | 7.04        |
|    cost_values           | 2.38        |
|    entropy               | 0.0215      |
|    entropy_loss          | 0.022       |
|    explained_variance    | 0.844       |
|    lagrangian_multiplier | 0.000713    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.51        |
|    n_updates             | 10650       |
|    policy_gradient_loss  | 0.00209     |
|    std                   | 0.333       |
|    value_loss            | 6.76        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.70807505 |
| rollout/                 |             |
|    ep_len_mean           | 70.4        |
|    ep_rew_mean           | -31.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 38          |
|    time_elapsed          | 1139        |
|    total_timesteps       | 2185216     |
| train/                   |             |
|    approx_kl             | 0.029471945 |
|    clip_fraction         | 0.196       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.49        |
|    cost_value_loss       | 7.68        |
|    cost_values           | 2.39        |
|    entropy               | 0.0272      |
|    entropy_loss          | 0.0237      |
|    explained_variance    | 0.862       |
|    lagrangian_multiplier | 0.00126     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.67        |
|    n_updates             | 10660       |
|    policy_gradient_loss  | 0.00758     |
|    std                   | 0.333       |
|    value_loss            | 5.19        |
------------------------------------------
-----------------------------------------
| avg_speed                | 6.84       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 6.84       |
| reward                   | -0.2785642 |
| rollout/                 |            |
|    ep_len_mean           | 66.4       |
|    ep_rew_mean           | -29.8      |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 39         |
|    time_elapsed          | 1170       |
|    total_timesteps       | 2187264    |
| train/                   |            |
|    approx_kl             | 0.01591289 |
|    clip_fraction         | 0.185      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.74       |
|    cost_value_loss       | 9.62       |
|    cost_values           | 2.4        |
|    entropy               | 0.028      |
|    entropy_loss          | 0.0279     |
|    explained_variance    | 0.82       |
|    lagrangian_multiplier | 0.000535   |
|    learning_rate         | 0.0003     |
|    loss                  | 6.64       |
|    n_updates             | 10670      |
|    policy_gradient_loss  | 0.00801    |
|    std                   | 0.333      |
|    value_loss            | 6.2        |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3020399  |
| rollout/                 |             |
|    ep_len_mean           | 71.4        |
|    ep_rew_mean           | -30.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 40          |
|    time_elapsed          | 1200        |
|    total_timesteps       | 2189312     |
| train/                   |             |
|    approx_kl             | 0.046258517 |
|    clip_fraction         | 0.195       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.61        |
|    cost_value_loss       | 8.43        |
|    cost_values           | 2.41        |
|    entropy               | 0.0277      |
|    entropy_loss          | 0.0281      |
|    explained_variance    | 0.853       |
|    lagrangian_multiplier | 0.00132     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.7         |
|    n_updates             | 10680       |
|    policy_gradient_loss  | 0.0135      |
|    std                   | 0.331       |
|    value_loss            | 5.14        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.87        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.87        |
| reward                   | -0.17470917 |
| rollout/                 |             |
|    ep_len_mean           | 69.6        |
|    ep_rew_mean           | -30.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 41          |
|    time_elapsed          | 1231        |
|    total_timesteps       | 2191360     |
| train/                   |             |
|    approx_kl             | 0.019989925 |
|    clip_fraction         | 0.239       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.38        |
|    cost_value_loss       | 6.99        |
|    cost_values           | 2.4         |
|    entropy               | 0.024       |
|    entropy_loss          | 0.0256      |
|    explained_variance    | 0.839       |
|    lagrangian_multiplier | 0.00158     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.32        |
|    n_updates             | 10690       |
|    policy_gradient_loss  | 0.0118      |
|    std                   | 0.331       |
|    value_loss            | 4.98        |
------------------------------------------
----------------------------------------
| avg_speed                | 3.4       |
| cost                     | 0         |
| is_success               | 0         |
| max_speed                | 3.4       |
| reward                   | -0.646125 |
| rollout/                 |           |
|    ep_len_mean           | 72.8      |
|    ep_rew_mean           | -31.6     |
| time/                    |           |
|    fps                   | 68        |
|    iterations            | 42        |
|    time_elapsed          | 1261      |
|    total_timesteps       | 2193408   |
| train/                   |           |
|    approx_kl             | 0.0501007 |
|    clip_fraction         | 0.199     |
|    clip_range            | 0.2       |
|    cost_returns          | 4.55      |
|    cost_value_loss       | 7.99      |
|    cost_values           | 2.4       |
|    entropy               | 0.0197    |
|    entropy_loss          | 0.0214    |
|    explained_variance    | 0.858     |
|    lagrangian_multiplier | 0.0015    |
|    learning_rate         | 0.0003    |
|    loss                  | 4.72      |
|    n_updates             | 10700     |
|    policy_gradient_loss  | 0.00971   |
|    std                   | 0.331     |
|    value_loss            | 5.19      |
----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 1           |
| max_speed                | 8           |
| reward                   | -0.10539736 |
| rollout/                 |             |
|    ep_len_mean           | 71.5        |
|    ep_rew_mean           | -31.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 43          |
|    time_elapsed          | 1291        |
|    total_timesteps       | 2195456     |
| train/                   |             |
|    approx_kl             | 0.014787367 |
|    clip_fraction         | 0.189       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.57        |
|    cost_value_loss       | 9.07        |
|    cost_values           | 2.38        |
|    entropy               | 0.0241      |
|    entropy_loss          | 0.0212      |
|    explained_variance    | 0.833       |
|    lagrangian_multiplier | 0.0014      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.15        |
|    n_updates             | 10710       |
|    policy_gradient_loss  | 0.00669     |
|    std                   | 0.33        |
|    value_loss            | 5.88        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.57203674 |
| rollout/                 |             |
|    ep_len_mean           | 70.7        |
|    ep_rew_mean           | -30.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 44          |
|    time_elapsed          | 1321        |
|    total_timesteps       | 2197504     |
| train/                   |             |
|    approx_kl             | 0.011543146 |
|    clip_fraction         | 0.2         |
|    clip_range            | 0.2         |
|    cost_returns          | 4.53        |
|    cost_value_loss       | 9           |
|    cost_values           | 2.37        |
|    entropy               | 0.0244      |
|    entropy_loss          | 0.0249      |
|    explained_variance    | 0.872       |
|    lagrangian_multiplier | 0.00134     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.14        |
|    n_updates             | 10720       |
|    policy_gradient_loss  | 0.0105      |
|    std                   | 0.33        |
|    value_loss            | 4.67        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.29561126 |
| rollout/                 |             |
|    ep_len_mean           | 72.3        |
|    ep_rew_mean           | -31.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 45          |
|    time_elapsed          | 1350        |
|    total_timesteps       | 2199552     |
| train/                   |             |
|    approx_kl             | 0.028482066 |
|    clip_fraction         | 0.224       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.61        |
|    cost_value_loss       | 9.12        |
|    cost_values           | 2.39        |
|    entropy               | 0.0356      |
|    entropy_loss          | 0.0298      |
|    explained_variance    | 0.89        |
|    lagrangian_multiplier | 0.00158     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.65        |
|    n_updates             | 10730       |
|    policy_gradient_loss  | 0.00978     |
|    std                   | 0.328       |
|    value_loss            | 4.01        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.63322943 |
| rollout/                 |             |
|    ep_len_mean           | 74.9        |
|    ep_rew_mean           | -32.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 46          |
|    time_elapsed          | 1380        |
|    total_timesteps       | 2201600     |
| train/                   |             |
|    approx_kl             | 0.038934395 |
|    clip_fraction         | 0.222       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.71        |
|    cost_value_loss       | 8.65        |
|    cost_values           | 2.41        |
|    entropy               | 0.0404      |
|    entropy_loss          | 0.0387      |
|    explained_variance    | 0.864       |
|    lagrangian_multiplier | 0.00289     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.17        |
|    n_updates             | 10740       |
|    policy_gradient_loss  | 0.0149      |
|    std                   | 0.327       |
|    value_loss            | 4.28        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2036678  |
| rollout/                 |             |
|    ep_len_mean           | 74.5        |
|    ep_rew_mean           | -31.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 47          |
|    time_elapsed          | 1410        |
|    total_timesteps       | 2203648     |
| train/                   |             |
|    approx_kl             | 0.014884649 |
|    clip_fraction         | 0.203       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.63        |
|    cost_value_loss       | 8.92        |
|    cost_values           | 2.4         |
|    entropy               | 0.047       |
|    entropy_loss          | 0.0435      |
|    explained_variance    | 0.832       |
|    lagrangian_multiplier | 0.00202     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.78        |
|    n_updates             | 10750       |
|    policy_gradient_loss  | 0.00962     |
|    std                   | 0.326       |
|    value_loss            | 5.31        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.36542347 |
| rollout/                 |             |
|    ep_len_mean           | 75.9        |
|    ep_rew_mean           | -32.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 48          |
|    time_elapsed          | 1439        |
|    total_timesteps       | 2205696     |
| train/                   |             |
|    approx_kl             | 0.01835696  |
|    clip_fraction         | 0.19        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.46        |
|    cost_value_loss       | 7.64        |
|    cost_values           | 2.43        |
|    entropy               | 0.0529      |
|    entropy_loss          | 0.0504      |
|    explained_variance    | 0.882       |
|    lagrangian_multiplier | 0.00178     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.87        |
|    n_updates             | 10760       |
|    policy_gradient_loss  | 0.0066      |
|    std                   | 0.325       |
|    value_loss            | 3.96        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.16300778 |
| rollout/                 |             |
|    ep_len_mean           | 73.9        |
|    ep_rew_mean           | -32.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 49          |
|    time_elapsed          | 1469        |
|    total_timesteps       | 2207744     |
| train/                   |             |
|    approx_kl             | 0.013950382 |
|    clip_fraction         | 0.184       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.35        |
|    cost_value_loss       | 7.86        |
|    cost_values           | 2.39        |
|    entropy               | 0.0581      |
|    entropy_loss          | 0.0562      |
|    explained_variance    | 0.874       |
|    lagrangian_multiplier | 0.000779    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.44        |
|    n_updates             | 10770       |
|    policy_gradient_loss  | 0.00703     |
|    std                   | 0.324       |
|    value_loss            | 5.01        |
------------------------------------------
-----------------------------------
| avg_speed          | 2.8        |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 2.8        |
| reward             | -0.9342366 |
| rollout/           |            |
|    ep_len_mean     | 75.2       |
|    ep_rew_mean     | -32.5      |
| time/              |            |
|    fps             | 73         |
|    iterations      | 1          |
|    time_elapsed    | 27         |
|    total_timesteps | 2209792    |
-----------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.3776869 |
| rollout/                 |            |
|    ep_len_mean           | 71.6       |
|    ep_rew_mean           | -31.5      |
| time/                    |            |
|    fps                   | 70         |
|    iterations            | 2          |
|    time_elapsed          | 58         |
|    total_timesteps       | 2211840    |
| train/                   |            |
|    approx_kl             | 0.03904253 |
|    clip_fraction         | 0.137      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.58       |
|    cost_value_loss       | 8.69       |
|    cost_values           | 2.35       |
|    entropy               | 0.0704     |
|    entropy_loss          | 0.0691     |
|    explained_variance    | 0.795      |
|    lagrangian_multiplier | 0.00209    |
|    learning_rate         | 0.0003     |
|    loss                  | 5.18       |
|    n_updates             | 10790      |
|    policy_gradient_loss  | 0.00177    |
|    std                   | 0.323      |
|    value_loss            | 6.45       |
-----------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.735084   |
| rollout/                 |             |
|    ep_len_mean           | 75.8        |
|    ep_rew_mean           | -32.6       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 3           |
|    time_elapsed          | 88          |
|    total_timesteps       | 2213888     |
| train/                   |             |
|    approx_kl             | 0.020019948 |
|    clip_fraction         | 0.115       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.49        |
|    cost_value_loss       | 7.92        |
|    cost_values           | 2.4         |
|    entropy               | 0.079       |
|    entropy_loss          | 0.0744      |
|    explained_variance    | 0.879       |
|    lagrangian_multiplier | 0.00235     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.32        |
|    n_updates             | 10800       |
|    policy_gradient_loss  | -0.000909   |
|    std                   | 0.323       |
|    value_loss            | 5.03        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8.01       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.01       |
| reward                   | -0.2541602 |
| rollout/                 |            |
|    ep_len_mean           | 71.7       |
|    ep_rew_mean           | -31.4      |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 4          |
|    time_elapsed          | 118        |
|    total_timesteps       | 2215936    |
| train/                   |            |
|    approx_kl             | 0.06993363 |
|    clip_fraction         | 0.205      |
|    clip_range            | 0.2        |
|    cost_returns          | 5.01       |
|    cost_value_loss       | 11.1       |
|    cost_values           | 2.41       |
|    entropy               | 0.0822     |
|    entropy_loss          | 0.081      |
|    explained_variance    | 0.792      |
|    lagrangian_multiplier | 0.00192    |
|    learning_rate         | 0.0003     |
|    loss                  | 5.82       |
|    n_updates             | 10810      |
|    policy_gradient_loss  | 0.0138     |
|    std                   | 0.323      |
|    value_loss            | 6.83       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.28316724 |
| rollout/                 |             |
|    ep_len_mean           | 71.3        |
|    ep_rew_mean           | -31.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 5           |
|    time_elapsed          | 148         |
|    total_timesteps       | 2217984     |
| train/                   |             |
|    approx_kl             | 0.012552131 |
|    clip_fraction         | 0.197       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.22        |
|    cost_value_loss       | 7.23        |
|    cost_values           | 2.37        |
|    entropy               | 0.0784      |
|    entropy_loss          | 0.0807      |
|    explained_variance    | 0.898       |
|    lagrangian_multiplier | 0.00174     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.27        |
|    n_updates             | 10820       |
|    policy_gradient_loss  | 0.0076      |
|    std                   | 0.326       |
|    value_loss            | 4.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.6         |
| reward                   | -0.20023465 |
| rollout/                 |             |
|    ep_len_mean           | 69.6        |
|    ep_rew_mean           | -30.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 6           |
|    time_elapsed          | 179         |
|    total_timesteps       | 2220032     |
| train/                   |             |
|    approx_kl             | 0.036230184 |
|    clip_fraction         | 0.235       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.51        |
|    cost_value_loss       | 8.37        |
|    cost_values           | 2.38        |
|    entropy               | 0.0759      |
|    entropy_loss          | 0.077       |
|    explained_variance    | 0.892       |
|    lagrangian_multiplier | 0.00184     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.44        |
|    n_updates             | 10830       |
|    policy_gradient_loss  | 0.00861     |
|    std                   | 0.327       |
|    value_loss            | 4.32        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.7977021  |
| rollout/                 |             |
|    ep_len_mean           | 69          |
|    ep_rew_mean           | -30.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 7           |
|    time_elapsed          | 210         |
|    total_timesteps       | 2222080     |
| train/                   |             |
|    approx_kl             | 0.052988153 |
|    clip_fraction         | 0.241       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.28        |
|    cost_value_loss       | 7.03        |
|    cost_values           | 2.41        |
|    entropy               | 0.0741      |
|    entropy_loss          | 0.0749      |
|    explained_variance    | 0.916       |
|    lagrangian_multiplier | 0.00011     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.31        |
|    n_updates             | 10840       |
|    policy_gradient_loss  | 0.0115      |
|    std                   | 0.326       |
|    value_loss            | 3.49        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.33624163 |
| rollout/                 |             |
|    ep_len_mean           | 65          |
|    ep_rew_mean           | -29.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 8           |
|    time_elapsed          | 240         |
|    total_timesteps       | 2224128     |
| train/                   |             |
|    approx_kl             | 0.031633202 |
|    clip_fraction         | 0.2         |
|    clip_range            | 0.2         |
|    cost_returns          | 4.49        |
|    cost_value_loss       | 8.13        |
|    cost_values           | 2.41        |
|    entropy               | 0.0728      |
|    entropy_loss          | 0.0737      |
|    explained_variance    | 0.91        |
|    lagrangian_multiplier | 0.00198     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.1         |
|    n_updates             | 10850       |
|    policy_gradient_loss  | 0.0136      |
|    std                   | 0.326       |
|    value_loss            | 3.48        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.24250901 |
| rollout/                 |             |
|    ep_len_mean           | 66          |
|    ep_rew_mean           | -29.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 9           |
|    time_elapsed          | 270         |
|    total_timesteps       | 2226176     |
| train/                   |             |
|    approx_kl             | 0.020448646 |
|    clip_fraction         | 0.205       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.5         |
|    cost_value_loss       | 7.81        |
|    cost_values           | 2.42        |
|    entropy               | 0.0751      |
|    entropy_loss          | 0.0741      |
|    explained_variance    | 0.913       |
|    lagrangian_multiplier | 0.000975    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.59        |
|    n_updates             | 10860       |
|    policy_gradient_loss  | 0.0105      |
|    std                   | 0.326       |
|    value_loss            | 3.37        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8.02       |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8.02       |
| reward                   | -0.3181711 |
| rollout/                 |            |
|    ep_len_mean           | 67         |
|    ep_rew_mean           | -29.3      |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 10         |
|    time_elapsed          | 299        |
|    total_timesteps       | 2228224    |
| train/                   |            |
|    approx_kl             | 0.04038244 |
|    clip_fraction         | 0.281      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.51       |
|    cost_value_loss       | 8.62       |
|    cost_values           | 2.41       |
|    entropy               | 0.0771     |
|    entropy_loss          | 0.0761     |
|    explained_variance    | 0.901      |
|    lagrangian_multiplier | 0.00165    |
|    learning_rate         | 0.0003     |
|    loss                  | 4.32       |
|    n_updates             | 10870      |
|    policy_gradient_loss  | 0.015      |
|    std                   | 0.325      |
|    value_loss            | 3.37       |
-----------------------------------------
------------------------------------------
| avg_speed                | 3           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3           |
| reward                   | -0.81974614 |
| rollout/                 |             |
|    ep_len_mean           | 68.1        |
|    ep_rew_mean           | -29.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 11          |
|    time_elapsed          | 329         |
|    total_timesteps       | 2230272     |
| train/                   |             |
|    approx_kl             | 0.018022107 |
|    clip_fraction         | 0.207       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.68        |
|    cost_value_loss       | 9.39        |
|    cost_values           | 2.39        |
|    entropy               | 0.0788      |
|    entropy_loss          | 0.0776      |
|    explained_variance    | 0.867       |
|    lagrangian_multiplier | 0.001       |
|    learning_rate         | 0.0003      |
|    loss                  | 5.26        |
|    n_updates             | 10880       |
|    policy_gradient_loss  | 0.0129      |
|    std                   | 0.325       |
|    value_loss            | 4.26        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.21809232 |
| rollout/                 |             |
|    ep_len_mean           | 66.6        |
|    ep_rew_mean           | -29.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 12          |
|    time_elapsed          | 358         |
|    total_timesteps       | 2232320     |
| train/                   |             |
|    approx_kl             | 0.028725028 |
|    clip_fraction         | 0.242       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.97        |
|    cost_value_loss       | 5.92        |
|    cost_values           | 2.35        |
|    entropy               | 0.0831      |
|    entropy_loss          | 0.0812      |
|    explained_variance    | 0.89        |
|    lagrangian_multiplier | 0.00141     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.61        |
|    n_updates             | 10890       |
|    policy_gradient_loss  | 0.0177      |
|    std                   | 0.324       |
|    value_loss            | 3.81        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.33686617 |
| rollout/                 |             |
|    ep_len_mean           | 66.5        |
|    ep_rew_mean           | -29.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 13          |
|    time_elapsed          | 388         |
|    total_timesteps       | 2234368     |
| train/                   |             |
|    approx_kl             | 0.025032755 |
|    clip_fraction         | 0.243       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.43        |
|    cost_value_loss       | 8.33        |
|    cost_values           | 2.35        |
|    entropy               | 0.0816      |
|    entropy_loss          | 0.0822      |
|    explained_variance    | 0.909       |
|    lagrangian_multiplier | 0.00101     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.73        |
|    n_updates             | 10900       |
|    policy_gradient_loss  | 0.00671     |
|    std                   | 0.324       |
|    value_loss            | 3.61        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.19581403 |
| rollout/                 |             |
|    ep_len_mean           | 65.7        |
|    ep_rew_mean           | -29.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 14          |
|    time_elapsed          | 417         |
|    total_timesteps       | 2236416     |
| train/                   |             |
|    approx_kl             | 0.028582774 |
|    clip_fraction         | 0.22        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.28        |
|    cost_value_loss       | 6.87        |
|    cost_values           | 2.36        |
|    entropy               | 0.0835      |
|    entropy_loss          | 0.0827      |
|    explained_variance    | 0.85        |
|    lagrangian_multiplier | 0.0013      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.38        |
|    n_updates             | 10910       |
|    policy_gradient_loss  | 0.0095      |
|    std                   | 0.324       |
|    value_loss            | 4.51        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.81738675 |
| rollout/                 |             |
|    ep_len_mean           | 66.4        |
|    ep_rew_mean           | -29.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 15          |
|    time_elapsed          | 447         |
|    total_timesteps       | 2238464     |
| train/                   |             |
|    approx_kl             | 0.037134767 |
|    clip_fraction         | 0.198       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.11        |
|    cost_value_loss       | 6.42        |
|    cost_values           | 2.35        |
|    entropy               | 0.0926      |
|    entropy_loss          | 0.0877      |
|    explained_variance    | 0.902       |
|    lagrangian_multiplier | 0.00137     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.87        |
|    n_updates             | 10920       |
|    policy_gradient_loss  | 0.00863     |
|    std                   | 0.323       |
|    value_loss            | 3.38        |
------------------------------------------
-----------------------------------------
| avg_speed                | 4.4        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 4.4        |
| reward                   | -0.3713978 |
| rollout/                 |            |
|    ep_len_mean           | 66.2       |
|    ep_rew_mean           | -30.1      |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 16         |
|    time_elapsed          | 477        |
|    total_timesteps       | 2240512    |
| train/                   |            |
|    approx_kl             | 0.047087   |
|    clip_fraction         | 0.24       |
|    clip_range            | 0.2        |
|    cost_returns          | 4.04       |
|    cost_value_loss       | 6.54       |
|    cost_values           | 2.34       |
|    entropy               | 0.0895     |
|    entropy_loss          | 0.092      |
|    explained_variance    | 0.882      |
|    lagrangian_multiplier | 0.000576   |
|    learning_rate         | 0.0003     |
|    loss                  | 5.07       |
|    n_updates             | 10930      |
|    policy_gradient_loss  | 0.0124     |
|    std                   | 0.323      |
|    value_loss            | 4.9        |
-----------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.2597445  |
| rollout/                 |             |
|    ep_len_mean           | 69.4        |
|    ep_rew_mean           | -31.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 17          |
|    time_elapsed          | 507         |
|    total_timesteps       | 2242560     |
| train/                   |             |
|    approx_kl             | 0.033551533 |
|    clip_fraction         | 0.215       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.31        |
|    cost_value_loss       | 7.42        |
|    cost_values           | 2.35        |
|    entropy               | 0.0937      |
|    entropy_loss          | 0.0908      |
|    explained_variance    | 0.892       |
|    lagrangian_multiplier | 0.00127     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.33        |
|    n_updates             | 10940       |
|    policy_gradient_loss  | 0.0113      |
|    std                   | 0.322       |
|    value_loss            | 4.03        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.2         |
| reward                   | -0.5178041  |
| rollout/                 |             |
|    ep_len_mean           | 71.6        |
|    ep_rew_mean           | -32.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 18          |
|    time_elapsed          | 538         |
|    total_timesteps       | 2244608     |
| train/                   |             |
|    approx_kl             | 0.024920696 |
|    clip_fraction         | 0.171       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.24        |
|    cost_value_loss       | 6.86        |
|    cost_values           | 2.35        |
|    entropy               | 0.101       |
|    entropy_loss          | 0.0976      |
|    explained_variance    | 0.837       |
|    lagrangian_multiplier | 0.000413    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.21        |
|    n_updates             | 10950       |
|    policy_gradient_loss  | 0.00547     |
|    std                   | 0.321       |
|    value_loss            | 5.43        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.29351065 |
| rollout/                 |             |
|    ep_len_mean           | 69.1        |
|    ep_rew_mean           | -30.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 19          |
|    time_elapsed          | 568         |
|    total_timesteps       | 2246656     |
| train/                   |             |
|    approx_kl             | 0.03922376  |
|    clip_fraction         | 0.196       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.18        |
|    cost_value_loss       | 6.6         |
|    cost_values           | 2.34        |
|    entropy               | 0.112       |
|    entropy_loss          | 0.106       |
|    explained_variance    | 0.876       |
|    lagrangian_multiplier | 0.000185    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.48        |
|    n_updates             | 10960       |
|    policy_gradient_loss  | 0.0125      |
|    std                   | 0.319       |
|    value_loss            | 4.96        |
------------------------------------------
-----------------------------------------
| avg_speed                | 7.18       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.18       |
| reward                   | -0.3305023 |
| rollout/                 |            |
|    ep_len_mean           | 66.1       |
|    ep_rew_mean           | -29.7      |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 20         |
|    time_elapsed          | 598        |
|    total_timesteps       | 2248704    |
| train/                   |            |
|    approx_kl             | 0.01956409 |
|    clip_fraction         | 0.138      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.42       |
|    cost_value_loss       | 7.6        |
|    cost_values           | 2.34       |
|    entropy               | 0.121      |
|    entropy_loss          | 0.116      |
|    explained_variance    | 0.816      |
|    lagrangian_multiplier | 0.00303    |
|    learning_rate         | 0.0003     |
|    loss                  | 4.15       |
|    n_updates             | 10970      |
|    policy_gradient_loss  | 0.00322    |
|    std                   | 0.318      |
|    value_loss            | 5.66       |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.82092655 |
| rollout/                 |             |
|    ep_len_mean           | 65.4        |
|    ep_rew_mean           | -29.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 21          |
|    time_elapsed          | 629         |
|    total_timesteps       | 2250752     |
| train/                   |             |
|    approx_kl             | 0.018439095 |
|    clip_fraction         | 0.215       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.16        |
|    cost_value_loss       | 6.04        |
|    cost_values           | 2.33        |
|    entropy               | 0.121       |
|    entropy_loss          | 0.121       |
|    explained_variance    | 0.819       |
|    lagrangian_multiplier | 0.000651    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.19        |
|    n_updates             | 10980       |
|    policy_gradient_loss  | 0.00928     |
|    std                   | 0.318       |
|    value_loss            | 5.65        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.33642596  |
| rollout/                 |              |
|    ep_len_mean           | 65           |
|    ep_rew_mean           | -28.6        |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 22           |
|    time_elapsed          | 660          |
|    total_timesteps       | 2252800      |
| train/                   |              |
|    approx_kl             | 0.0105854375 |
|    clip_fraction         | 0.157        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.15         |
|    cost_value_loss       | 6.83         |
|    cost_values           | 2.31         |
|    entropy               | 0.131        |
|    entropy_loss          | 0.125        |
|    explained_variance    | 0.86         |
|    lagrangian_multiplier | 0.000868     |
|    learning_rate         | 0.0003       |
|    loss                  | 4.56         |
|    n_updates             | 10990        |
|    policy_gradient_loss  | 0.00405      |
|    std                   | 0.316        |
|    value_loss            | 4.96         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.7         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.7         |
| reward                   | -0.35143465 |
| rollout/                 |             |
|    ep_len_mean           | 69.8        |
|    ep_rew_mean           | -29.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 23          |
|    time_elapsed          | 691         |
|    total_timesteps       | 2254848     |
| train/                   |             |
|    approx_kl             | 0.024044082 |
|    clip_fraction         | 0.219       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.11        |
|    cost_value_loss       | 5.88        |
|    cost_values           | 2.33        |
|    entropy               | 0.135       |
|    entropy_loss          | 0.135       |
|    explained_variance    | 0.888       |
|    lagrangian_multiplier | 0.000354    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.24        |
|    n_updates             | 11000       |
|    policy_gradient_loss  | 0.0137      |
|    std                   | 0.315       |
|    value_loss            | 3.61        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.6859081  |
| rollout/                 |             |
|    ep_len_mean           | 67.1        |
|    ep_rew_mean           | -29.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 24          |
|    time_elapsed          | 721         |
|    total_timesteps       | 2256896     |
| train/                   |             |
|    approx_kl             | 0.030211654 |
|    clip_fraction         | 0.201       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.39        |
|    cost_value_loss       | 7.61        |
|    cost_values           | 2.36        |
|    entropy               | 0.141       |
|    entropy_loss          | 0.138       |
|    explained_variance    | 0.871       |
|    lagrangian_multiplier | 0.00203     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.17        |
|    n_updates             | 11010       |
|    policy_gradient_loss  | 0.00606     |
|    std                   | 0.314       |
|    value_loss            | 4.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.2         |
| reward                   | -0.37399235 |
| rollout/                 |             |
|    ep_len_mean           | 71.7        |
|    ep_rew_mean           | -30.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 25          |
|    time_elapsed          | 751         |
|    total_timesteps       | 2258944     |
| train/                   |             |
|    approx_kl             | 0.021050863 |
|    clip_fraction         | 0.22        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.31        |
|    cost_value_loss       | 7.3         |
|    cost_values           | 2.36        |
|    entropy               | 0.137       |
|    entropy_loss          | 0.14        |
|    explained_variance    | 0.861       |
|    lagrangian_multiplier | 0.000724    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.31        |
|    n_updates             | 11020       |
|    policy_gradient_loss  | 0.0114      |
|    std                   | 0.315       |
|    value_loss            | 5.28        |
------------------------------------------
------------------------------------------
| avg_speed                | 5           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5           |
| reward                   | -0.33635414 |
| rollout/                 |             |
|    ep_len_mean           | 70.5        |
|    ep_rew_mean           | -30.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 26          |
|    time_elapsed          | 780         |
|    total_timesteps       | 2260992     |
| train/                   |             |
|    approx_kl             | 0.03906281  |
|    clip_fraction         | 0.194       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.21        |
|    cost_value_loss       | 6.53        |
|    cost_values           | 2.34        |
|    entropy               | 0.135       |
|    entropy_loss          | 0.136       |
|    explained_variance    | 0.843       |
|    lagrangian_multiplier | 0.00037     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.27        |
|    n_updates             | 11030       |
|    policy_gradient_loss  | 0.00706     |
|    std                   | 0.314       |
|    value_loss            | 4.84        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.32959518 |
| rollout/                 |             |
|    ep_len_mean           | 71.4        |
|    ep_rew_mean           | -30.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 27          |
|    time_elapsed          | 809         |
|    total_timesteps       | 2263040     |
| train/                   |             |
|    approx_kl             | 0.020945817 |
|    clip_fraction         | 0.197       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.16        |
|    cost_value_loss       | 6.77        |
|    cost_values           | 2.36        |
|    entropy               | 0.13        |
|    entropy_loss          | 0.133       |
|    explained_variance    | 0.88        |
|    lagrangian_multiplier | 0.00127     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.18        |
|    n_updates             | 11040       |
|    policy_gradient_loss  | 0.00421     |
|    std                   | 0.315       |
|    value_loss            | 4.29        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2987527  |
| rollout/                 |             |
|    ep_len_mean           | 74.2        |
|    ep_rew_mean           | -31.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 28          |
|    time_elapsed          | 839         |
|    total_timesteps       | 2265088     |
| train/                   |             |
|    approx_kl             | 0.012776158 |
|    clip_fraction         | 0.159       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.43        |
|    cost_value_loss       | 8.27        |
|    cost_values           | 2.34        |
|    entropy               | 0.124       |
|    entropy_loss          | 0.127       |
|    explained_variance    | 0.873       |
|    lagrangian_multiplier | 0.00033     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.9         |
|    n_updates             | 11050       |
|    policy_gradient_loss  | 0.00356     |
|    std                   | 0.316       |
|    value_loss            | 4.15        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.2854008  |
| rollout/                 |             |
|    ep_len_mean           | 73.5        |
|    ep_rew_mean           | -31.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 29          |
|    time_elapsed          | 869         |
|    total_timesteps       | 2267136     |
| train/                   |             |
|    approx_kl             | 0.026658338 |
|    clip_fraction         | 0.213       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.28        |
|    cost_value_loss       | 6.94        |
|    cost_values           | 2.35        |
|    entropy               | 0.122       |
|    entropy_loss          | 0.123       |
|    explained_variance    | 0.868       |
|    lagrangian_multiplier | 0.000467    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.72        |
|    n_updates             | 11060       |
|    policy_gradient_loss  | 0.00531     |
|    std                   | 0.317       |
|    value_loss            | 4.7         |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.7628938  |
| rollout/                 |             |
|    ep_len_mean           | 74.1        |
|    ep_rew_mean           | -32.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 30          |
|    time_elapsed          | 898         |
|    total_timesteps       | 2269184     |
| train/                   |             |
|    approx_kl             | 0.011825921 |
|    clip_fraction         | 0.175       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.17        |
|    cost_value_loss       | 7.81        |
|    cost_values           | 2.38        |
|    entropy               | 0.119       |
|    entropy_loss          | 0.121       |
|    explained_variance    | 0.879       |
|    lagrangian_multiplier | 0.00104     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.84        |
|    n_updates             | 11070       |
|    policy_gradient_loss  | 0.0072      |
|    std                   | 0.318       |
|    value_loss            | 4.58        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.8         |
| reward                   | -0.53226113 |
| rollout/                 |             |
|    ep_len_mean           | 70          |
|    ep_rew_mean           | -30.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 31          |
|    time_elapsed          | 928         |
|    total_timesteps       | 2271232     |
| train/                   |             |
|    approx_kl             | 0.02036442  |
|    clip_fraction         | 0.197       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.27        |
|    cost_value_loss       | 7.42        |
|    cost_values           | 2.33        |
|    entropy               | 0.116       |
|    entropy_loss          | 0.117       |
|    explained_variance    | 0.866       |
|    lagrangian_multiplier | 0.000874    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.12        |
|    n_updates             | 11080       |
|    policy_gradient_loss  | 0.00943     |
|    std                   | 0.319       |
|    value_loss            | 5.5         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.14833908 |
| rollout/                 |             |
|    ep_len_mean           | 66.8        |
|    ep_rew_mean           | -29.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 32          |
|    time_elapsed          | 958         |
|    total_timesteps       | 2273280     |
| train/                   |             |
|    approx_kl             | 0.026915848 |
|    clip_fraction         | 0.214       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.37        |
|    cost_value_loss       | 8.18        |
|    cost_values           | 2.32        |
|    entropy               | 0.105       |
|    entropy_loss          | 0.111       |
|    explained_variance    | 0.903       |
|    lagrangian_multiplier | 0.000793    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.52        |
|    n_updates             | 11090       |
|    policy_gradient_loss  | 0.00368     |
|    std                   | 0.321       |
|    value_loss            | 3.45        |
------------------------------------------
------------------------------------------
| avg_speed                | 5           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5           |
| reward                   | -0.4831489  |
| rollout/                 |             |
|    ep_len_mean           | 69.2        |
|    ep_rew_mean           | -29.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 33          |
|    time_elapsed          | 988         |
|    total_timesteps       | 2275328     |
| train/                   |             |
|    approx_kl             | 0.013705412 |
|    clip_fraction         | 0.224       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.13        |
|    cost_value_loss       | 6.72        |
|    cost_values           | 2.33        |
|    entropy               | 0.107       |
|    entropy_loss          | 0.105       |
|    explained_variance    | 0.912       |
|    lagrangian_multiplier | 0.00121     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.9         |
|    n_updates             | 11100       |
|    policy_gradient_loss  | 0.00854     |
|    std                   | 0.32        |
|    value_loss            | 3.19        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.97        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.97        |
| reward                   | -0.30480587 |
| rollout/                 |             |
|    ep_len_mean           | 70.9        |
|    ep_rew_mean           | -30.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 34          |
|    time_elapsed          | 1019        |
|    total_timesteps       | 2277376     |
| train/                   |             |
|    approx_kl             | 0.06040298  |
|    clip_fraction         | 0.236       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.26        |
|    cost_value_loss       | 6.26        |
|    cost_values           | 2.36        |
|    entropy               | 0.114       |
|    entropy_loss          | 0.111       |
|    explained_variance    | 0.872       |
|    lagrangian_multiplier | 0.00103     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.98        |
|    n_updates             | 11110       |
|    policy_gradient_loss  | 0.014       |
|    std                   | 0.32        |
|    value_loss            | 3.72        |
------------------------------------------
------------------------------------------
| avg_speed                | 5           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5           |
| reward                   | -0.21188335 |
| rollout/                 |             |
|    ep_len_mean           | 74.3        |
|    ep_rew_mean           | -31.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 35          |
|    time_elapsed          | 1049        |
|    total_timesteps       | 2279424     |
| train/                   |             |
|    approx_kl             | 0.019030042 |
|    clip_fraction         | 0.214       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.5         |
|    cost_value_loss       | 7.95        |
|    cost_values           | 2.38        |
|    entropy               | 0.114       |
|    entropy_loss          | 0.114       |
|    explained_variance    | 0.883       |
|    lagrangian_multiplier | 0.00124     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.21        |
|    n_updates             | 11120       |
|    policy_gradient_loss  | 0.0109      |
|    std                   | 0.32        |
|    value_loss            | 4.18        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3121988  |
| rollout/                 |             |
|    ep_len_mean           | 71.1        |
|    ep_rew_mean           | -30.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 36          |
|    time_elapsed          | 1079        |
|    total_timesteps       | 2281472     |
| train/                   |             |
|    approx_kl             | 0.013471026 |
|    clip_fraction         | 0.181       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.28        |
|    cost_value_loss       | 6.77        |
|    cost_values           | 2.35        |
|    entropy               | 0.115       |
|    entropy_loss          | 0.114       |
|    explained_variance    | 0.832       |
|    lagrangian_multiplier | 0.00131     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.57        |
|    n_updates             | 11130       |
|    policy_gradient_loss  | 0.00723     |
|    std                   | 0.319       |
|    value_loss            | 5.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.17086986 |
| rollout/                 |             |
|    ep_len_mean           | 69.2        |
|    ep_rew_mean           | -30.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 37          |
|    time_elapsed          | 1110        |
|    total_timesteps       | 2283520     |
| train/                   |             |
|    approx_kl             | 0.012120519 |
|    clip_fraction         | 0.18        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.89        |
|    cost_value_loss       | 5.13        |
|    cost_values           | 2.33        |
|    entropy               | 0.116       |
|    entropy_loss          | 0.116       |
|    explained_variance    | 0.893       |
|    lagrangian_multiplier | 0.000262    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.52        |
|    n_updates             | 11140       |
|    policy_gradient_loss  | 0.00958     |
|    std                   | 0.32        |
|    value_loss            | 4.33        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.40135747 |
| rollout/                 |             |
|    ep_len_mean           | 66.8        |
|    ep_rew_mean           | -30         |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 38          |
|    time_elapsed          | 1140        |
|    total_timesteps       | 2285568     |
| train/                   |             |
|    approx_kl             | 0.01828539  |
|    clip_fraction         | 0.179       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.54        |
|    cost_value_loss       | 8.52        |
|    cost_values           | 2.33        |
|    entropy               | 0.119       |
|    entropy_loss          | 0.117       |
|    explained_variance    | 0.839       |
|    lagrangian_multiplier | 0.00115     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.38        |
|    n_updates             | 11150       |
|    policy_gradient_loss  | -0.00047    |
|    std                   | 0.319       |
|    value_loss            | 5.53        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2534263  |
| rollout/                 |             |
|    ep_len_mean           | 69.1        |
|    ep_rew_mean           | -30.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 39          |
|    time_elapsed          | 1170        |
|    total_timesteps       | 2287616     |
| train/                   |             |
|    approx_kl             | 0.011759453 |
|    clip_fraction         | 0.171       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.3         |
|    cost_value_loss       | 7.27        |
|    cost_values           | 2.33        |
|    entropy               | 0.119       |
|    entropy_loss          | 0.119       |
|    explained_variance    | 0.795       |
|    lagrangian_multiplier | 0.00192     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.78        |
|    n_updates             | 11160       |
|    policy_gradient_loss  | 0.00211     |
|    std                   | 0.318       |
|    value_loss            | 6.61        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3230487  |
| rollout/                 |             |
|    ep_len_mean           | 71.4        |
|    ep_rew_mean           | -30.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 40          |
|    time_elapsed          | 1200        |
|    total_timesteps       | 2289664     |
| train/                   |             |
|    approx_kl             | 0.023186885 |
|    clip_fraction         | 0.178       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.99        |
|    cost_value_loss       | 5.86        |
|    cost_values           | 2.3         |
|    entropy               | 0.117       |
|    entropy_loss          | 0.118       |
|    explained_variance    | 0.831       |
|    lagrangian_multiplier | 0.00072     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.78        |
|    n_updates             | 11170       |
|    policy_gradient_loss  | 0.0071      |
|    std                   | 0.318       |
|    value_loss            | 5.62        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.21272448 |
| rollout/                 |             |
|    ep_len_mean           | 69.5        |
|    ep_rew_mean           | -30.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 41          |
|    time_elapsed          | 1229        |
|    total_timesteps       | 2291712     |
| train/                   |             |
|    approx_kl             | 0.010641487 |
|    clip_fraction         | 0.206       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.05        |
|    cost_value_loss       | 6.22        |
|    cost_values           | 2.28        |
|    entropy               | 0.113       |
|    entropy_loss          | 0.116       |
|    explained_variance    | 0.747       |
|    lagrangian_multiplier | 0.0012      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.11        |
|    n_updates             | 11180       |
|    policy_gradient_loss  | 0.00739     |
|    std                   | 0.318       |
|    value_loss            | 7.1         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 1           |
| max_speed                | 8.01        |
| reward                   | -0.1092739  |
| rollout/                 |             |
|    ep_len_mean           | 69.3        |
|    ep_rew_mean           | -30.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 42          |
|    time_elapsed          | 1259        |
|    total_timesteps       | 2293760     |
| train/                   |             |
|    approx_kl             | 0.024022179 |
|    clip_fraction         | 0.159       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.13        |
|    cost_value_loss       | 7.48        |
|    cost_values           | 2.28        |
|    entropy               | 0.114       |
|    entropy_loss          | 0.114       |
|    explained_variance    | 0.888       |
|    lagrangian_multiplier | 0.000191    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.05        |
|    n_updates             | 11190       |
|    policy_gradient_loss  | 0.00447     |
|    std                   | 0.318       |
|    value_loss            | 4.77        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.17739181 |
| rollout/                 |             |
|    ep_len_mean           | 68.6        |
|    ep_rew_mean           | -30.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 43          |
|    time_elapsed          | 1289        |
|    total_timesteps       | 2295808     |
| train/                   |             |
|    approx_kl             | 0.016391942 |
|    clip_fraction         | 0.202       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.23        |
|    cost_value_loss       | 8.18        |
|    cost_values           | 2.3         |
|    entropy               | 0.117       |
|    entropy_loss          | 0.116       |
|    explained_variance    | 0.82        |
|    lagrangian_multiplier | 0.000615    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.83        |
|    n_updates             | 11200       |
|    policy_gradient_loss  | 0.0034      |
|    std                   | 0.318       |
|    value_loss            | 6.04        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.37120578 |
| rollout/                 |             |
|    ep_len_mean           | 69.5        |
|    ep_rew_mean           | -30.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 44          |
|    time_elapsed          | 1319        |
|    total_timesteps       | 2297856     |
| train/                   |             |
|    approx_kl             | 0.033583883 |
|    clip_fraction         | 0.193       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.26        |
|    cost_value_loss       | 6.39        |
|    cost_values           | 2.3         |
|    entropy               | 0.127       |
|    entropy_loss          | 0.123       |
|    explained_variance    | 0.858       |
|    lagrangian_multiplier | 0.00103     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.35        |
|    n_updates             | 11210       |
|    policy_gradient_loss  | 0.00692     |
|    std                   | 0.316       |
|    value_loss            | 4.55        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.29241705 |
| rollout/                 |             |
|    ep_len_mean           | 71.8        |
|    ep_rew_mean           | -31.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 45          |
|    time_elapsed          | 1349        |
|    total_timesteps       | 2299904     |
| train/                   |             |
|    approx_kl             | 0.019497633 |
|    clip_fraction         | 0.164       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.1         |
|    cost_value_loss       | 6.17        |
|    cost_values           | 2.32        |
|    entropy               | 0.128       |
|    entropy_loss          | 0.129       |
|    explained_variance    | 0.884       |
|    lagrangian_multiplier | 0.000609    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.58        |
|    n_updates             | 11220       |
|    policy_gradient_loss  | 0.00426     |
|    std                   | 0.317       |
|    value_loss            | 4.15        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.29        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.29        |
| reward                   | -0.30494127 |
| rollout/                 |             |
|    ep_len_mean           | 74.2        |
|    ep_rew_mean           | -31.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 46          |
|    time_elapsed          | 1378        |
|    total_timesteps       | 2301952     |
| train/                   |             |
|    approx_kl             | 0.02652974  |
|    clip_fraction         | 0.184       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.31        |
|    cost_value_loss       | 6.79        |
|    cost_values           | 2.33        |
|    entropy               | 0.128       |
|    entropy_loss          | 0.127       |
|    explained_variance    | 0.84        |
|    lagrangian_multiplier | 0.00116     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.48        |
|    n_updates             | 11230       |
|    policy_gradient_loss  | 0.00507     |
|    std                   | 0.316       |
|    value_loss            | 5.04        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.8449381  |
| rollout/                 |             |
|    ep_len_mean           | 71.9        |
|    ep_rew_mean           | -31         |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 47          |
|    time_elapsed          | 1407        |
|    total_timesteps       | 2304000     |
| train/                   |             |
|    approx_kl             | 0.014847919 |
|    clip_fraction         | 0.215       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.49        |
|    cost_value_loss       | 8.22        |
|    cost_values           | 2.32        |
|    entropy               | 0.123       |
|    entropy_loss          | 0.126       |
|    explained_variance    | 0.764       |
|    lagrangian_multiplier | 0.000438    |
|    learning_rate         | 0.0003      |
|    loss                  | 6.46        |
|    n_updates             | 11240       |
|    policy_gradient_loss  | 0.00803     |
|    std                   | 0.317       |
|    value_loss            | 6.54        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.4931795  |
| rollout/                 |             |
|    ep_len_mean           | 69.2        |
|    ep_rew_mean           | -30.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 48          |
|    time_elapsed          | 1438        |
|    total_timesteps       | 2306048     |
| train/                   |             |
|    approx_kl             | 0.017334528 |
|    clip_fraction         | 0.21        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.47        |
|    cost_value_loss       | 8.8         |
|    cost_values           | 2.34        |
|    entropy               | 0.116       |
|    entropy_loss          | 0.12        |
|    explained_variance    | 0.897       |
|    lagrangian_multiplier | 0.00206     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.21        |
|    n_updates             | 11250       |
|    policy_gradient_loss  | 0.00735     |
|    std                   | 0.318       |
|    value_loss            | 4.52        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.86        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.86        |
| reward                   | -0.26782417 |
| rollout/                 |             |
|    ep_len_mean           | 68.4        |
|    ep_rew_mean           | -30.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 49          |
|    time_elapsed          | 1468        |
|    total_timesteps       | 2308096     |
| train/                   |             |
|    approx_kl             | 0.016925672 |
|    clip_fraction         | 0.205       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.34        |
|    cost_value_loss       | 7.97        |
|    cost_values           | 2.31        |
|    entropy               | 0.106       |
|    entropy_loss          | 0.11        |
|    explained_variance    | 0.839       |
|    lagrangian_multiplier | 0.00133     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.96        |
|    n_updates             | 11260       |
|    policy_gradient_loss  | 0.00723     |
|    std                   | 0.32        |
|    value_loss            | 5.45        |
------------------------------------------
----------------------------------
| avg_speed          | 1.2       |
| cost               | 0         |
| is_success         | 0         |
| max_speed          | 1.2       |
| reward             | -0.850427 |
| rollout/           |           |
|    ep_len_mean     | 68.3      |
|    ep_rew_mean     | -29.9     |
| time/              |           |
|    fps             | 71        |
|    iterations      | 1         |
|    time_elapsed    | 28        |
|    total_timesteps | 2310144   |
----------------------------------
------------------------------------------
| avg_speed                | 1.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.8         |
| reward                   | -0.66572034 |
| rollout/                 |             |
|    ep_len_mean           | 68.9        |
|    ep_rew_mean           | -29.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 2           |
|    time_elapsed          | 59          |
|    total_timesteps       | 2312192     |
| train/                   |             |
|    approx_kl             | 0.014913833 |
|    clip_fraction         | 0.177       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.47        |
|    cost_value_loss       | 8.57        |
|    cost_values           | 2.29        |
|    entropy               | 0.115       |
|    entropy_loss          | 0.11        |
|    explained_variance    | 0.848       |
|    lagrangian_multiplier | 0.00143     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.74        |
|    n_updates             | 11280       |
|    policy_gradient_loss  | 0.00796     |
|    std                   | 0.319       |
|    value_loss            | 4.74        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.24853909 |
| rollout/                 |             |
|    ep_len_mean           | 70.8        |
|    ep_rew_mean           | -30.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 3           |
|    time_elapsed          | 89          |
|    total_timesteps       | 2314240     |
| train/                   |             |
|    approx_kl             | 0.01697078  |
|    clip_fraction         | 0.179       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.35        |
|    cost_value_loss       | 7.52        |
|    cost_values           | 2.3         |
|    entropy               | 0.113       |
|    entropy_loss          | 0.115       |
|    explained_variance    | 0.864       |
|    lagrangian_multiplier | 0.000779    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.07        |
|    n_updates             | 11290       |
|    policy_gradient_loss  | 0.00621     |
|    std                   | 0.319       |
|    value_loss            | 4.71        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.68841875 |
| rollout/                 |             |
|    ep_len_mean           | 72.2        |
|    ep_rew_mean           | -31.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 4           |
|    time_elapsed          | 119         |
|    total_timesteps       | 2316288     |
| train/                   |             |
|    approx_kl             | 0.02978989  |
|    clip_fraction         | 0.203       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.45        |
|    cost_value_loss       | 8.71        |
|    cost_values           | 2.34        |
|    entropy               | 0.108       |
|    entropy_loss          | 0.111       |
|    explained_variance    | 0.9         |
|    lagrangian_multiplier | 0.00109     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.75        |
|    n_updates             | 11300       |
|    policy_gradient_loss  | 0.0112      |
|    std                   | 0.319       |
|    value_loss            | 3.73        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.14987744 |
| rollout/                 |             |
|    ep_len_mean           | 70.4        |
|    ep_rew_mean           | -31         |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 5           |
|    time_elapsed          | 150         |
|    total_timesteps       | 2318336     |
| train/                   |             |
|    approx_kl             | 0.009034436 |
|    clip_fraction         | 0.146       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.13        |
|    cost_value_loss       | 6.58        |
|    cost_values           | 2.28        |
|    entropy               | 0.11        |
|    entropy_loss          | 0.108       |
|    explained_variance    | 0.808       |
|    lagrangian_multiplier | 0.00121     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.62        |
|    n_updates             | 11310       |
|    policy_gradient_loss  | 0.000786    |
|    std                   | 0.319       |
|    value_loss            | 5.76        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.94        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.94        |
| reward                   | -0.2885333  |
| rollout/                 |             |
|    ep_len_mean           | 71.6        |
|    ep_rew_mean           | -31.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 6           |
|    time_elapsed          | 180         |
|    total_timesteps       | 2320384     |
| train/                   |             |
|    approx_kl             | 0.023878023 |
|    clip_fraction         | 0.166       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.35        |
|    cost_value_loss       | 7.85        |
|    cost_values           | 2.29        |
|    entropy               | 0.116       |
|    entropy_loss          | 0.113       |
|    explained_variance    | 0.863       |
|    lagrangian_multiplier | 0.000549    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.99        |
|    n_updates             | 11320       |
|    policy_gradient_loss  | 0.00467     |
|    std                   | 0.318       |
|    value_loss            | 4.44        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.6         |
| reward                   | -0.7899807  |
| rollout/                 |             |
|    ep_len_mean           | 74.1        |
|    ep_rew_mean           | -31.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 7           |
|    time_elapsed          | 209         |
|    total_timesteps       | 2322432     |
| train/                   |             |
|    approx_kl             | 0.025448868 |
|    clip_fraction         | 0.19        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.17        |
|    cost_value_loss       | 6.84        |
|    cost_values           | 2.26        |
|    entropy               | 0.124       |
|    entropy_loss          | 0.121       |
|    explained_variance    | 0.802       |
|    lagrangian_multiplier | 0.000485    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.35        |
|    n_updates             | 11330       |
|    policy_gradient_loss  | 0.0103      |
|    std                   | 0.317       |
|    value_loss            | 5.96        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 1           |
| max_speed                | 8.02        |
| reward                   | -0.09254493 |
| rollout/                 |             |
|    ep_len_mean           | 69.6        |
|    ep_rew_mean           | -30.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 8           |
|    time_elapsed          | 239         |
|    total_timesteps       | 2324480     |
| train/                   |             |
|    approx_kl             | 0.021213342 |
|    clip_fraction         | 0.198       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.42        |
|    cost_value_loss       | 8.04        |
|    cost_values           | 2.32        |
|    entropy               | 0.128       |
|    entropy_loss          | 0.127       |
|    explained_variance    | 0.886       |
|    lagrangian_multiplier | 0.00183     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.14        |
|    n_updates             | 11340       |
|    policy_gradient_loss  | 0.0115      |
|    std                   | 0.316       |
|    value_loss            | 4.04        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.13086624 |
| rollout/                 |             |
|    ep_len_mean           | 64.8        |
|    ep_rew_mean           | -28.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 9           |
|    time_elapsed          | 269         |
|    total_timesteps       | 2326528     |
| train/                   |             |
|    approx_kl             | 0.026305387 |
|    clip_fraction         | 0.241       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.27        |
|    cost_value_loss       | 8.78        |
|    cost_values           | 2.3         |
|    entropy               | 0.126       |
|    entropy_loss          | 0.128       |
|    explained_variance    | 0.889       |
|    lagrangian_multiplier | 0.0013      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.89        |
|    n_updates             | 11350       |
|    policy_gradient_loss  | 0.0135      |
|    std                   | 0.316       |
|    value_loss            | 3.97        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.2         |
| reward                   | -0.89834803 |
| rollout/                 |             |
|    ep_len_mean           | 69.1        |
|    ep_rew_mean           | -30.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 10          |
|    time_elapsed          | 298         |
|    total_timesteps       | 2328576     |
| train/                   |             |
|    approx_kl             | 0.012974054 |
|    clip_fraction         | 0.214       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.17        |
|    cost_value_loss       | 6.86        |
|    cost_values           | 2.3         |
|    entropy               | 0.125       |
|    entropy_loss          | 0.125       |
|    explained_variance    | 0.918       |
|    lagrangian_multiplier | 0.00216     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.65        |
|    n_updates             | 11360       |
|    policy_gradient_loss  | 0.00866     |
|    std                   | 0.316       |
|    value_loss            | 2.92        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3217819  |
| rollout/                 |             |
|    ep_len_mean           | 66.5        |
|    ep_rew_mean           | -29.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 11          |
|    time_elapsed          | 328         |
|    total_timesteps       | 2330624     |
| train/                   |             |
|    approx_kl             | 0.029364012 |
|    clip_fraction         | 0.187       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.58        |
|    cost_value_loss       | 8.39        |
|    cost_values           | 2.32        |
|    entropy               | 0.124       |
|    entropy_loss          | 0.125       |
|    explained_variance    | 0.836       |
|    lagrangian_multiplier | 0.00436     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.49        |
|    n_updates             | 11370       |
|    policy_gradient_loss  | 0.00537     |
|    std                   | 0.317       |
|    value_loss            | 4.46        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2518376  |
| rollout/                 |             |
|    ep_len_mean           | 72.6        |
|    ep_rew_mean           | -31.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 12          |
|    time_elapsed          | 358         |
|    total_timesteps       | 2332672     |
| train/                   |             |
|    approx_kl             | 0.016841244 |
|    clip_fraction         | 0.212       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.21        |
|    cost_value_loss       | 6.94        |
|    cost_values           | 2.32        |
|    entropy               | 0.122       |
|    entropy_loss          | 0.123       |
|    explained_variance    | 0.855       |
|    lagrangian_multiplier | 0.00145     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.72        |
|    n_updates             | 11380       |
|    policy_gradient_loss  | 0.00482     |
|    std                   | 0.318       |
|    value_loss            | 5.29        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.5028465  |
| rollout/                 |             |
|    ep_len_mean           | 76.7        |
|    ep_rew_mean           | -32.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 13          |
|    time_elapsed          | 387         |
|    total_timesteps       | 2334720     |
| train/                   |             |
|    approx_kl             | 0.027342578 |
|    clip_fraction         | 0.151       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.52        |
|    cost_value_loss       | 8.96        |
|    cost_values           | 2.29        |
|    entropy               | 0.116       |
|    entropy_loss          | 0.12        |
|    explained_variance    | 0.817       |
|    lagrangian_multiplier | 0.00192     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.65        |
|    n_updates             | 11390       |
|    policy_gradient_loss  | 0.000862    |
|    std                   | 0.318       |
|    value_loss            | 5.07        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.8481309  |
| rollout/                 |             |
|    ep_len_mean           | 75.5        |
|    ep_rew_mean           | -32.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 14          |
|    time_elapsed          | 417         |
|    total_timesteps       | 2336768     |
| train/                   |             |
|    approx_kl             | 0.011495129 |
|    clip_fraction         | 0.156       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.38        |
|    cost_value_loss       | 7.65        |
|    cost_values           | 2.26        |
|    entropy               | 0.114       |
|    entropy_loss          | 0.114       |
|    explained_variance    | 0.757       |
|    lagrangian_multiplier | 0.000888    |
|    learning_rate         | 0.0003      |
|    loss                  | 5           |
|    n_updates             | 11400       |
|    policy_gradient_loss  | 0.00745     |
|    std                   | 0.318       |
|    value_loss            | 5.93        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.18193515 |
| rollout/                 |             |
|    ep_len_mean           | 77.2        |
|    ep_rew_mean           | -32.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 15          |
|    time_elapsed          | 447         |
|    total_timesteps       | 2338816     |
| train/                   |             |
|    approx_kl             | 0.039758094 |
|    clip_fraction         | 0.172       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.19        |
|    cost_value_loss       | 7.29        |
|    cost_values           | 2.25        |
|    entropy               | 0.113       |
|    entropy_loss          | 0.113       |
|    explained_variance    | 0.846       |
|    lagrangian_multiplier | 0.000897    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.15        |
|    n_updates             | 11410       |
|    policy_gradient_loss  | 0.00597     |
|    std                   | 0.319       |
|    value_loss            | 5.9         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.394893   |
| rollout/                 |             |
|    ep_len_mean           | 71.5        |
|    ep_rew_mean           | -31.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 16          |
|    time_elapsed          | 477         |
|    total_timesteps       | 2340864     |
| train/                   |             |
|    approx_kl             | 0.021473873 |
|    clip_fraction         | 0.19        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.39        |
|    cost_value_loss       | 8.33        |
|    cost_values           | 2.29        |
|    entropy               | 0.107       |
|    entropy_loss          | 0.11        |
|    explained_variance    | 0.878       |
|    lagrangian_multiplier | 0.000659    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.87        |
|    n_updates             | 11420       |
|    policy_gradient_loss  | 0.00556     |
|    std                   | 0.32        |
|    value_loss            | 5.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 3           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3           |
| reward                   | -0.6893752  |
| rollout/                 |             |
|    ep_len_mean           | 77          |
|    ep_rew_mean           | -32.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 17          |
|    time_elapsed          | 508         |
|    total_timesteps       | 2342912     |
| train/                   |             |
|    approx_kl             | 0.013763214 |
|    clip_fraction         | 0.163       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.18        |
|    cost_value_loss       | 6.66        |
|    cost_values           | 2.25        |
|    entropy               | 0.106       |
|    entropy_loss          | 0.106       |
|    explained_variance    | 0.729       |
|    lagrangian_multiplier | 0.00122     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.83        |
|    n_updates             | 11430       |
|    policy_gradient_loss  | 0.0032      |
|    std                   | 0.32        |
|    value_loss            | 6.73        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.25769514 |
| rollout/                 |             |
|    ep_len_mean           | 76.7        |
|    ep_rew_mean           | -32.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 18          |
|    time_elapsed          | 538         |
|    total_timesteps       | 2344960     |
| train/                   |             |
|    approx_kl             | 0.019381715 |
|    clip_fraction         | 0.188       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.26        |
|    cost_value_loss       | 7.67        |
|    cost_values           | 2.21        |
|    entropy               | 0.115       |
|    entropy_loss          | 0.11        |
|    explained_variance    | 0.807       |
|    lagrangian_multiplier | 0.000488    |
|    learning_rate         | 0.0003      |
|    loss                  | 6.31        |
|    n_updates             | 11440       |
|    policy_gradient_loss  | 0.0064      |
|    std                   | 0.319       |
|    value_loss            | 6.67        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.19699885 |
| rollout/                 |             |
|    ep_len_mean           | 75.7        |
|    ep_rew_mean           | -31.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 19          |
|    time_elapsed          | 570         |
|    total_timesteps       | 2347008     |
| train/                   |             |
|    approx_kl             | 0.01882333  |
|    clip_fraction         | 0.197       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.56        |
|    cost_value_loss       | 9.19        |
|    cost_values           | 2.25        |
|    entropy               | 0.119       |
|    entropy_loss          | 0.118       |
|    explained_variance    | 0.849       |
|    lagrangian_multiplier | 0.00127     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.15        |
|    n_updates             | 11450       |
|    policy_gradient_loss  | 0.00527     |
|    std                   | 0.318       |
|    value_loss            | 5.23        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.4         |
| reward                   | -0.24744081 |
| rollout/                 |             |
|    ep_len_mean           | 66.4        |
|    ep_rew_mean           | -29.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 20          |
|    time_elapsed          | 601         |
|    total_timesteps       | 2349056     |
| train/                   |             |
|    approx_kl             | 0.017017037 |
|    clip_fraction         | 0.169       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.51        |
|    cost_value_loss       | 8.47        |
|    cost_values           | 2.32        |
|    entropy               | 0.127       |
|    entropy_loss          | 0.122       |
|    explained_variance    | 0.878       |
|    lagrangian_multiplier | 0.00295     |
|    learning_rate         | 0.0003      |
|    loss                  | 4           |
|    n_updates             | 11460       |
|    policy_gradient_loss  | -0.000984   |
|    std                   | 0.317       |
|    value_loss            | 4.61        |
------------------------------------------
-----------------------------------------
| avg_speed                | 5          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 5          |
| reward                   | -0.260564  |
| rollout/                 |            |
|    ep_len_mean           | 66.7       |
|    ep_rew_mean           | -29.5      |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 21         |
|    time_elapsed          | 631        |
|    total_timesteps       | 2351104    |
| train/                   |            |
|    approx_kl             | 0.01910412 |
|    clip_fraction         | 0.219      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.17       |
|    cost_value_loss       | 7.15       |
|    cost_values           | 2.3        |
|    entropy               | 0.128      |
|    entropy_loss          | 0.128      |
|    explained_variance    | 0.882      |
|    lagrangian_multiplier | 0.00209    |
|    learning_rate         | 0.0003     |
|    loss                  | 4.11       |
|    n_updates             | 11470      |
|    policy_gradient_loss  | 0.0131     |
|    std                   | 0.316      |
|    value_loss            | 4.95       |
-----------------------------------------
------------------------------------------
| avg_speed                | 6.7         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.7         |
| reward                   | -0.3730555  |
| rollout/                 |             |
|    ep_len_mean           | 72.7        |
|    ep_rew_mean           | -31.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 22          |
|    time_elapsed          | 661         |
|    total_timesteps       | 2353152     |
| train/                   |             |
|    approx_kl             | 0.045872353 |
|    clip_fraction         | 0.204       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.48        |
|    cost_value_loss       | 7.89        |
|    cost_values           | 2.27        |
|    entropy               | 0.132       |
|    entropy_loss          | 0.129       |
|    explained_variance    | 0.852       |
|    lagrangian_multiplier | 0.000772    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.35        |
|    n_updates             | 11480       |
|    policy_gradient_loss  | 0.01        |
|    std                   | 0.316       |
|    value_loss            | 4.81        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.18593018 |
| rollout/                 |             |
|    ep_len_mean           | 78.7        |
|    ep_rew_mean           | -32.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 23          |
|    time_elapsed          | 691         |
|    total_timesteps       | 2355200     |
| train/                   |             |
|    approx_kl             | 0.019320551 |
|    clip_fraction         | 0.153       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.38        |
|    cost_value_loss       | 7.03        |
|    cost_values           | 2.23        |
|    entropy               | 0.135       |
|    entropy_loss          | 0.133       |
|    explained_variance    | 0.671       |
|    lagrangian_multiplier | 0.000689    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.95        |
|    n_updates             | 11490       |
|    policy_gradient_loss  | 0.00667     |
|    std                   | 0.315       |
|    value_loss            | 7.23        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.34716773 |
| rollout/                 |             |
|    ep_len_mean           | 81.2        |
|    ep_rew_mean           | -33.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 24          |
|    time_elapsed          | 720         |
|    total_timesteps       | 2357248     |
| train/                   |             |
|    approx_kl             | 0.011177365 |
|    clip_fraction         | 0.134       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.12        |
|    cost_value_loss       | 6.75        |
|    cost_values           | 2.19        |
|    entropy               | 0.133       |
|    entropy_loss          | 0.134       |
|    explained_variance    | 0.761       |
|    lagrangian_multiplier | 7.71e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 6           |
|    n_updates             | 11500       |
|    policy_gradient_loss  | 0.000266    |
|    std                   | 0.316       |
|    value_loss            | 7.37        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.27809083 |
| rollout/                 |             |
|    ep_len_mean           | 79.4        |
|    ep_rew_mean           | -33.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 25          |
|    time_elapsed          | 750         |
|    total_timesteps       | 2359296     |
| train/                   |             |
|    approx_kl             | 0.032087922 |
|    clip_fraction         | 0.232       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.36        |
|    cost_value_loss       | 8.03        |
|    cost_values           | 2.21        |
|    entropy               | 0.137       |
|    entropy_loss          | 0.135       |
|    explained_variance    | 0.843       |
|    lagrangian_multiplier | 0.000637    |
|    learning_rate         | 0.0003      |
|    loss                  | 6.02        |
|    n_updates             | 11510       |
|    policy_gradient_loss  | 0.00968     |
|    std                   | 0.316       |
|    value_loss            | 6.26        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.25493786 |
| rollout/                 |             |
|    ep_len_mean           | 71.3        |
|    ep_rew_mean           | -31.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 26          |
|    time_elapsed          | 779         |
|    total_timesteps       | 2361344     |
| train/                   |             |
|    approx_kl             | 0.02744262  |
|    clip_fraction         | 0.206       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.26        |
|    cost_value_loss       | 7.39        |
|    cost_values           | 2.25        |
|    entropy               | 0.14        |
|    entropy_loss          | 0.139       |
|    explained_variance    | 0.857       |
|    lagrangian_multiplier | 0.000532    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.15        |
|    n_updates             | 11520       |
|    policy_gradient_loss  | 0.00979     |
|    std                   | 0.315       |
|    value_loss            | 5.5         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.38244182 |
| rollout/                 |             |
|    ep_len_mean           | 69.8        |
|    ep_rew_mean           | -30.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 27          |
|    time_elapsed          | 809         |
|    total_timesteps       | 2363392     |
| train/                   |             |
|    approx_kl             | 0.031904865 |
|    clip_fraction         | 0.177       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.19        |
|    cost_value_loss       | 6.99        |
|    cost_values           | 2.27        |
|    entropy               | 0.143       |
|    entropy_loss          | 0.141       |
|    explained_variance    | 0.898       |
|    lagrangian_multiplier | 0.000833    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.65        |
|    n_updates             | 11530       |
|    policy_gradient_loss  | 0.011       |
|    std                   | 0.314       |
|    value_loss            | 4.19        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 1           |
| max_speed                | 8           |
| reward                   | -0.11538227 |
| rollout/                 |             |
|    ep_len_mean           | 73          |
|    ep_rew_mean           | -31.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 28          |
|    time_elapsed          | 839         |
|    total_timesteps       | 2365440     |
| train/                   |             |
|    approx_kl             | 0.058831505 |
|    clip_fraction         | 0.238       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.55        |
|    cost_value_loss       | 9.03        |
|    cost_values           | 2.26        |
|    entropy               | 0.144       |
|    entropy_loss          | 0.144       |
|    explained_variance    | 0.856       |
|    lagrangian_multiplier | 0.00142     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.04        |
|    n_updates             | 11540       |
|    policy_gradient_loss  | 0.0118      |
|    std                   | 0.314       |
|    value_loss            | 4.93        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.32652354 |
| rollout/                 |             |
|    ep_len_mean           | 71          |
|    ep_rew_mean           | -31.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 29          |
|    time_elapsed          | 869         |
|    total_timesteps       | 2367488     |
| train/                   |             |
|    approx_kl             | 0.024481956 |
|    clip_fraction         | 0.219       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.68        |
|    cost_value_loss       | 9.66        |
|    cost_values           | 2.29        |
|    entropy               | 0.14        |
|    entropy_loss          | 0.142       |
|    explained_variance    | 0.868       |
|    lagrangian_multiplier | 0.00181     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.83        |
|    n_updates             | 11550       |
|    policy_gradient_loss  | 0.011       |
|    std                   | 0.315       |
|    value_loss            | 4.78        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.4         |
| reward                   | -0.26139858 |
| rollout/                 |             |
|    ep_len_mean           | 68.6        |
|    ep_rew_mean           | -30.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 30          |
|    time_elapsed          | 899         |
|    total_timesteps       | 2369536     |
| train/                   |             |
|    approx_kl             | 0.047634654 |
|    clip_fraction         | 0.216       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.3         |
|    cost_value_loss       | 7.69        |
|    cost_values           | 2.28        |
|    entropy               | 0.14        |
|    entropy_loss          | 0.139       |
|    explained_variance    | 0.906       |
|    lagrangian_multiplier | 0.00113     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.51        |
|    n_updates             | 11560       |
|    policy_gradient_loss  | 0.00936     |
|    std                   | 0.315       |
|    value_loss            | 3.71        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.6         |
| reward                   | -0.25069275 |
| rollout/                 |             |
|    ep_len_mean           | 69          |
|    ep_rew_mean           | -30.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 31          |
|    time_elapsed          | 929         |
|    total_timesteps       | 2371584     |
| train/                   |             |
|    approx_kl             | 0.029479876 |
|    clip_fraction         | 0.223       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.09        |
|    cost_value_loss       | 6.54        |
|    cost_values           | 2.27        |
|    entropy               | 0.148       |
|    entropy_loss          | 0.143       |
|    explained_variance    | 0.915       |
|    lagrangian_multiplier | 0.00142     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.86        |
|    n_updates             | 11570       |
|    policy_gradient_loss  | 0.00966     |
|    std                   | 0.314       |
|    value_loss            | 3.65        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.16714975 |
| rollout/                 |             |
|    ep_len_mean           | 71.6        |
|    ep_rew_mean           | -31.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 32          |
|    time_elapsed          | 959         |
|    total_timesteps       | 2373632     |
| train/                   |             |
|    approx_kl             | 0.017867053 |
|    clip_fraction         | 0.196       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.34        |
|    cost_value_loss       | 7.18        |
|    cost_values           | 2.21        |
|    entropy               | 0.145       |
|    entropy_loss          | 0.148       |
|    explained_variance    | 0.782       |
|    lagrangian_multiplier | 0.000609    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.07        |
|    n_updates             | 11580       |
|    policy_gradient_loss  | 0.00808     |
|    std                   | 0.315       |
|    value_loss            | 5.74        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.24008566 |
| rollout/                 |             |
|    ep_len_mean           | 72.8        |
|    ep_rew_mean           | -31.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 33          |
|    time_elapsed          | 989         |
|    total_timesteps       | 2375680     |
| train/                   |             |
|    approx_kl             | 0.010647528 |
|    clip_fraction         | 0.186       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.21        |
|    cost_value_loss       | 6.93        |
|    cost_values           | 2.23        |
|    entropy               | 0.142       |
|    entropy_loss          | 0.143       |
|    explained_variance    | 0.78        |
|    lagrangian_multiplier | 0.00119     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.89        |
|    n_updates             | 11590       |
|    policy_gradient_loss  | 0.00902     |
|    std                   | 0.315       |
|    value_loss            | 6.02        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.31563994 |
| rollout/                 |             |
|    ep_len_mean           | 74.1        |
|    ep_rew_mean           | -31.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 34          |
|    time_elapsed          | 1020        |
|    total_timesteps       | 2377728     |
| train/                   |             |
|    approx_kl             | 0.044108443 |
|    clip_fraction         | 0.181       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.11        |
|    cost_value_loss       | 6.47        |
|    cost_values           | 2.21        |
|    entropy               | 0.138       |
|    entropy_loss          | 0.14        |
|    explained_variance    | 0.821       |
|    lagrangian_multiplier | 0.00128     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.79        |
|    n_updates             | 11600       |
|    policy_gradient_loss  | 0.00712     |
|    std                   | 0.316       |
|    value_loss            | 5.95        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.27527678 |
| rollout/                 |             |
|    ep_len_mean           | 68.9        |
|    ep_rew_mean           | -30.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 35          |
|    time_elapsed          | 1050        |
|    total_timesteps       | 2379776     |
| train/                   |             |
|    approx_kl             | 0.023853093 |
|    clip_fraction         | 0.174       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.13        |
|    cost_value_loss       | 7.09        |
|    cost_values           | 2.18        |
|    entropy               | 0.14        |
|    entropy_loss          | 0.138       |
|    explained_variance    | 0.845       |
|    lagrangian_multiplier | 0.00106     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.02        |
|    n_updates             | 11610       |
|    policy_gradient_loss  | 0.00719     |
|    std                   | 0.316       |
|    value_loss            | 5.83        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.6942746  |
| rollout/                 |             |
|    ep_len_mean           | 72.3        |
|    ep_rew_mean           | -31         |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 36          |
|    time_elapsed          | 1081        |
|    total_timesteps       | 2381824     |
| train/                   |             |
|    approx_kl             | 0.039476126 |
|    clip_fraction         | 0.237       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.13        |
|    cost_value_loss       | 6.72        |
|    cost_values           | 2.2         |
|    entropy               | 0.139       |
|    entropy_loss          | 0.141       |
|    explained_variance    | 0.883       |
|    lagrangian_multiplier | 0.000436    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.64        |
|    n_updates             | 11620       |
|    policy_gradient_loss  | 0.00886     |
|    std                   | 0.316       |
|    value_loss            | 3.97        |
------------------------------------------
------------------------------------------
| avg_speed                | 7           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7           |
| reward                   | -0.31661737 |
| rollout/                 |             |
|    ep_len_mean           | 74.3        |
|    ep_rew_mean           | -31.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 37          |
|    time_elapsed          | 1111        |
|    total_timesteps       | 2383872     |
| train/                   |             |
|    approx_kl             | 0.04754057  |
|    clip_fraction         | 0.205       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.3         |
|    cost_value_loss       | 7.33        |
|    cost_values           | 2.21        |
|    entropy               | 0.135       |
|    entropy_loss          | 0.137       |
|    explained_variance    | 0.805       |
|    lagrangian_multiplier | 0.00115     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.9         |
|    n_updates             | 11630       |
|    policy_gradient_loss  | 0.0135      |
|    std                   | 0.316       |
|    value_loss            | 5.24        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.75965947 |
| rollout/                 |             |
|    ep_len_mean           | 71.4        |
|    ep_rew_mean           | -30.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 38          |
|    time_elapsed          | 1141        |
|    total_timesteps       | 2385920     |
| train/                   |             |
|    approx_kl             | 0.03343291  |
|    clip_fraction         | 0.216       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.45        |
|    cost_value_loss       | 8.42        |
|    cost_values           | 2.22        |
|    entropy               | 0.14        |
|    entropy_loss          | 0.138       |
|    explained_variance    | 0.837       |
|    lagrangian_multiplier | 0.00161     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.96        |
|    n_updates             | 11640       |
|    policy_gradient_loss  | 0.0135      |
|    std                   | 0.315       |
|    value_loss            | 5.32        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.33483648 |
| rollout/                 |             |
|    ep_len_mean           | 71.4        |
|    ep_rew_mean           | -30.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 39          |
|    time_elapsed          | 1171        |
|    total_timesteps       | 2387968     |
| train/                   |             |
|    approx_kl             | 0.05640904  |
|    clip_fraction         | 0.211       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.81        |
|    cost_value_loss       | 5.67        |
|    cost_values           | 2.2         |
|    entropy               | 0.141       |
|    entropy_loss          | 0.14        |
|    explained_variance    | 0.879       |
|    lagrangian_multiplier | 0.00129     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.98        |
|    n_updates             | 11650       |
|    policy_gradient_loss  | 0.00719     |
|    std                   | 0.315       |
|    value_loss            | 5           |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.7792471  |
| rollout/                 |             |
|    ep_len_mean           | 68          |
|    ep_rew_mean           | -29.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 40          |
|    time_elapsed          | 1200        |
|    total_timesteps       | 2390016     |
| train/                   |             |
|    approx_kl             | 0.019057237 |
|    clip_fraction         | 0.177       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.32        |
|    cost_value_loss       | 7.86        |
|    cost_values           | 2.22        |
|    entropy               | 0.145       |
|    entropy_loss          | 0.143       |
|    explained_variance    | 0.894       |
|    lagrangian_multiplier | 0.00102     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.47        |
|    n_updates             | 11660       |
|    policy_gradient_loss  | 0.00394     |
|    std                   | 0.314       |
|    value_loss            | 3.71        |
------------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.82702214 |
| rollout/                 |             |
|    ep_len_mean           | 70.6        |
|    ep_rew_mean           | -30.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 41          |
|    time_elapsed          | 1230        |
|    total_timesteps       | 2392064     |
| train/                   |             |
|    approx_kl             | 0.017840602 |
|    clip_fraction         | 0.199       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.97        |
|    cost_value_loss       | 7.54        |
|    cost_values           | 2.18        |
|    entropy               | 0.15        |
|    entropy_loss          | 0.147       |
|    explained_variance    | 0.866       |
|    lagrangian_multiplier | 0.00057     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.14        |
|    n_updates             | 11670       |
|    policy_gradient_loss  | 0.0131      |
|    std                   | 0.313       |
|    value_loss            | 4.03        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.26301453 |
| rollout/                 |             |
|    ep_len_mean           | 70          |
|    ep_rew_mean           | -31         |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 42          |
|    time_elapsed          | 1259        |
|    total_timesteps       | 2394112     |
| train/                   |             |
|    approx_kl             | 0.01568617  |
|    clip_fraction         | 0.2         |
|    clip_range            | 0.2         |
|    cost_returns          | 4.03        |
|    cost_value_loss       | 6.77        |
|    cost_values           | 2.18        |
|    entropy               | 0.155       |
|    entropy_loss          | 0.153       |
|    explained_variance    | 0.873       |
|    lagrangian_multiplier | 0.00129     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.28        |
|    n_updates             | 11680       |
|    policy_gradient_loss  | 0.00526     |
|    std                   | 0.312       |
|    value_loss            | 4.82        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.6248759  |
| rollout/                 |             |
|    ep_len_mean           | 66.4        |
|    ep_rew_mean           | -30.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 43          |
|    time_elapsed          | 1289        |
|    total_timesteps       | 2396160     |
| train/                   |             |
|    approx_kl             | 0.018253844 |
|    clip_fraction         | 0.176       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.08        |
|    cost_value_loss       | 7.27        |
|    cost_values           | 2.19        |
|    entropy               | 0.164       |
|    entropy_loss          | 0.161       |
|    explained_variance    | 0.866       |
|    lagrangian_multiplier | 0.00141     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.67        |
|    n_updates             | 11690       |
|    policy_gradient_loss  | 0.00382     |
|    std                   | 0.311       |
|    value_loss            | 5.11        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.3047228 |
| rollout/                 |            |
|    ep_len_mean           | 64.8       |
|    ep_rew_mean           | -29.2      |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 44         |
|    time_elapsed          | 1318       |
|    total_timesteps       | 2398208    |
| train/                   |            |
|    approx_kl             | 0.01810488 |
|    clip_fraction         | 0.188      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.38       |
|    cost_value_loss       | 8.68       |
|    cost_values           | 2.18       |
|    entropy               | 0.17       |
|    entropy_loss          | 0.167      |
|    explained_variance    | 0.859      |
|    lagrangian_multiplier | 0.0016     |
|    learning_rate         | 0.0003     |
|    loss                  | 4.9        |
|    n_updates             | 11700      |
|    policy_gradient_loss  | 0.00555    |
|    std                   | 0.31       |
|    value_loss            | 5.3        |
-----------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.81060624 |
| rollout/                 |             |
|    ep_len_mean           | 66.9        |
|    ep_rew_mean           | -29.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 45          |
|    time_elapsed          | 1348        |
|    total_timesteps       | 2400256     |
| train/                   |             |
|    approx_kl             | 0.02810374  |
|    clip_fraction         | 0.225       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.38        |
|    cost_value_loss       | 8.65        |
|    cost_values           | 2.23        |
|    entropy               | 0.177       |
|    entropy_loss          | 0.175       |
|    explained_variance    | 0.902       |
|    lagrangian_multiplier | 0.00166     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.32        |
|    n_updates             | 11710       |
|    policy_gradient_loss  | 0.0127      |
|    std                   | 0.308       |
|    value_loss            | 3.59        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.834475   |
| rollout/                 |             |
|    ep_len_mean           | 66.3        |
|    ep_rew_mean           | -28.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 46          |
|    time_elapsed          | 1379        |
|    total_timesteps       | 2402304     |
| train/                   |             |
|    approx_kl             | 0.016540922 |
|    clip_fraction         | 0.25        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.41        |
|    cost_value_loss       | 8.77        |
|    cost_values           | 2.22        |
|    entropy               | 0.172       |
|    entropy_loss          | 0.175       |
|    explained_variance    | 0.904       |
|    lagrangian_multiplier | 0.00281     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.88        |
|    n_updates             | 11720       |
|    policy_gradient_loss  | 0.0174      |
|    std                   | 0.309       |
|    value_loss            | 3.18        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.22732519 |
| rollout/                 |             |
|    ep_len_mean           | 65.8        |
|    ep_rew_mean           | -29         |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 47          |
|    time_elapsed          | 1409        |
|    total_timesteps       | 2404352     |
| train/                   |             |
|    approx_kl             | 0.02605926  |
|    clip_fraction         | 0.225       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.35        |
|    cost_value_loss       | 8.09        |
|    cost_values           | 2.23        |
|    entropy               | 0.173       |
|    entropy_loss          | 0.172       |
|    explained_variance    | 0.912       |
|    lagrangian_multiplier | 0.000624    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.99        |
|    n_updates             | 11730       |
|    policy_gradient_loss  | 0.00951     |
|    std                   | 0.309       |
|    value_loss            | 3.36        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.82        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.82        |
| reward                   | -0.3055755  |
| rollout/                 |             |
|    ep_len_mean           | 65.2        |
|    ep_rew_mean           | -28.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 48          |
|    time_elapsed          | 1439        |
|    total_timesteps       | 2406400     |
| train/                   |             |
|    approx_kl             | 0.023691215 |
|    clip_fraction         | 0.186       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.13        |
|    cost_value_loss       | 6.93        |
|    cost_values           | 2.26        |
|    entropy               | 0.176       |
|    entropy_loss          | 0.175       |
|    explained_variance    | 0.919       |
|    lagrangian_multiplier | 0.000693    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.21        |
|    n_updates             | 11740       |
|    policy_gradient_loss  | 0.0054      |
|    std                   | 0.307       |
|    value_loss            | 3.2         |
------------------------------------------
------------------------------------------
| avg_speed                | 6.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.4         |
| reward                   | -0.22500598 |
| rollout/                 |             |
|    ep_len_mean           | 66.6        |
|    ep_rew_mean           | -29.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 49          |
|    time_elapsed          | 1470        |
|    total_timesteps       | 2408448     |
| train/                   |             |
|    approx_kl             | 0.021111935 |
|    clip_fraction         | 0.237       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.36        |
|    cost_value_loss       | 7.9         |
|    cost_values           | 2.28        |
|    entropy               | 0.177       |
|    entropy_loss          | 0.176       |
|    explained_variance    | 0.923       |
|    lagrangian_multiplier | 0.0024      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.71        |
|    n_updates             | 11750       |
|    policy_gradient_loss  | 0.00594     |
|    std                   | 0.306       |
|    value_loss            | 2.59        |
------------------------------------------
----------------------------------
| avg_speed          | 2.4       |
| cost               | 0         |
| is_success         | 0         |
| max_speed          | 2.4       |
| reward             | -0.735084 |
| rollout/           |           |
|    ep_len_mean     | 66.8      |
|    ep_rew_mean     | -29.5     |
| time/              |           |
|    fps             | 72        |
|    iterations      | 1         |
|    time_elapsed    | 28        |
|    total_timesteps | 2410496   |
----------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.25991198 |
| rollout/                 |             |
|    ep_len_mean           | 66.6        |
|    ep_rew_mean           | -29.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 2           |
|    time_elapsed          | 59          |
|    total_timesteps       | 2412544     |
| train/                   |             |
|    approx_kl             | 0.009437386 |
|    clip_fraction         | 0.164       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.3         |
|    cost_value_loss       | 8.43        |
|    cost_values           | 2.22        |
|    entropy               | 0.154       |
|    entropy_loss          | 0.158       |
|    explained_variance    | 0.894       |
|    lagrangian_multiplier | 0.00164     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.14        |
|    n_updates             | 11770       |
|    policy_gradient_loss  | 0.00257     |
|    std                   | 0.309       |
|    value_loss            | 3.8         |
------------------------------------------
-----------------------------------------
| avg_speed                | 1.8        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 1.8        |
| reward                   | -0.850402  |
| rollout/                 |            |
|    ep_len_mean           | 63.5       |
|    ep_rew_mean           | -28.7      |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 3          |
|    time_elapsed          | 90         |
|    total_timesteps       | 2414592    |
| train/                   |            |
|    approx_kl             | 0.03781169 |
|    clip_fraction         | 0.205      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.52       |
|    cost_value_loss       | 9.07       |
|    cost_values           | 2.28       |
|    entropy               | 0.149      |
|    entropy_loss          | 0.151      |
|    explained_variance    | 0.903      |
|    lagrangian_multiplier | 0.000867   |
|    learning_rate         | 0.0003     |
|    loss                  | 4.83       |
|    n_updates             | 11780      |
|    policy_gradient_loss  | 0.00657    |
|    std                   | 0.309      |
|    value_loss            | 3.57       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2475073  |
| rollout/                 |             |
|    ep_len_mean           | 63.4        |
|    ep_rew_mean           | -28.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 4           |
|    time_elapsed          | 119         |
|    total_timesteps       | 2416640     |
| train/                   |             |
|    approx_kl             | 0.015309326 |
|    clip_fraction         | 0.212       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.84        |
|    cost_value_loss       | 5.56        |
|    cost_values           | 2.27        |
|    entropy               | 0.141       |
|    entropy_loss          | 0.145       |
|    explained_variance    | 0.923       |
|    lagrangian_multiplier | 0.00168     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.47        |
|    n_updates             | 11790       |
|    policy_gradient_loss  | 0.00742     |
|    std                   | 0.311       |
|    value_loss            | 2.85        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.1847716  |
| rollout/                 |             |
|    ep_len_mean           | 65.2        |
|    ep_rew_mean           | -28.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 5           |
|    time_elapsed          | 150         |
|    total_timesteps       | 2418688     |
| train/                   |             |
|    approx_kl             | 0.023878073 |
|    clip_fraction         | 0.22        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.13        |
|    cost_value_loss       | 7.57        |
|    cost_values           | 2.21        |
|    entropy               | 0.143       |
|    entropy_loss          | 0.141       |
|    explained_variance    | 0.893       |
|    lagrangian_multiplier | 0.00171     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.08        |
|    n_updates             | 11800       |
|    policy_gradient_loss  | 0.0124      |
|    std                   | 0.31        |
|    value_loss            | 3.51        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.2         |
| reward                   | -0.3132282  |
| rollout/                 |             |
|    ep_len_mean           | 64.1        |
|    ep_rew_mean           | -28.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 6           |
|    time_elapsed          | 179         |
|    total_timesteps       | 2420736     |
| train/                   |             |
|    approx_kl             | 0.017715115 |
|    clip_fraction         | 0.187       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.21        |
|    cost_value_loss       | 7.16        |
|    cost_values           | 2.2         |
|    entropy               | 0.149       |
|    entropy_loss          | 0.146       |
|    explained_variance    | 0.869       |
|    lagrangian_multiplier | 0.00196     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.8         |
|    n_updates             | 11810       |
|    policy_gradient_loss  | 0.00527     |
|    std                   | 0.309       |
|    value_loss            | 3.92        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.2         |
| reward                   | -0.47189957 |
| rollout/                 |             |
|    ep_len_mean           | 65.5        |
|    ep_rew_mean           | -28.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 7           |
|    time_elapsed          | 209         |
|    total_timesteps       | 2422784     |
| train/                   |             |
|    approx_kl             | 0.0269872   |
|    clip_fraction         | 0.214       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.14        |
|    cost_value_loss       | 7.35        |
|    cost_values           | 2.23        |
|    entropy               | 0.145       |
|    entropy_loss          | 0.148       |
|    explained_variance    | 0.908       |
|    lagrangian_multiplier | 0.000614    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.59        |
|    n_updates             | 11820       |
|    policy_gradient_loss  | 0.00512     |
|    std                   | 0.309       |
|    value_loss            | 3.48        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2215465  |
| rollout/                 |             |
|    ep_len_mean           | 62.8        |
|    ep_rew_mean           | -28.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 8           |
|    time_elapsed          | 239         |
|    total_timesteps       | 2424832     |
| train/                   |             |
|    approx_kl             | 0.031964943 |
|    clip_fraction         | 0.199       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.38        |
|    cost_value_loss       | 8.27        |
|    cost_values           | 2.23        |
|    entropy               | 0.135       |
|    entropy_loss          | 0.14        |
|    explained_variance    | 0.892       |
|    lagrangian_multiplier | 0.0017      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.07        |
|    n_updates             | 11830       |
|    policy_gradient_loss  | 0.00982     |
|    std                   | 0.311       |
|    value_loss            | 3.59        |
------------------------------------------
------------------------------------------
| avg_speed                | 3           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3           |
| reward                   | -0.9121314  |
| rollout/                 |             |
|    ep_len_mean           | 64.6        |
|    ep_rew_mean           | -29         |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 9           |
|    time_elapsed          | 269         |
|    total_timesteps       | 2426880     |
| train/                   |             |
|    approx_kl             | 0.020280303 |
|    clip_fraction         | 0.181       |
|    clip_range            | 0.2         |
|    cost_returns          | 4           |
|    cost_value_loss       | 6.88        |
|    cost_values           | 2.26        |
|    entropy               | 0.138       |
|    entropy_loss          | 0.135       |
|    explained_variance    | 0.913       |
|    lagrangian_multiplier | 0.00119     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.47        |
|    n_updates             | 11840       |
|    policy_gradient_loss  | 0.00709     |
|    std                   | 0.31        |
|    value_loss            | 3.1         |
------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.3058008 |
| rollout/                 |            |
|    ep_len_mean           | 61.2       |
|    ep_rew_mean           | -27.9      |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 10         |
|    time_elapsed          | 299        |
|    total_timesteps       | 2428928    |
| train/                   |            |
|    approx_kl             | 0.06175778 |
|    clip_fraction         | 0.221      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.99       |
|    cost_value_loss       | 6.17       |
|    cost_values           | 2.27       |
|    entropy               | 0.136      |
|    entropy_loss          | 0.138      |
|    explained_variance    | 0.935      |
|    lagrangian_multiplier | 0.0011     |
|    learning_rate         | 0.0003     |
|    loss                  | 3.57       |
|    n_updates             | 11850      |
|    policy_gradient_loss  | 0.0101     |
|    std                   | 0.31       |
|    value_loss            | 2.61       |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.47950014 |
| rollout/                 |             |
|    ep_len_mean           | 68.9        |
|    ep_rew_mean           | -30.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 11          |
|    time_elapsed          | 329         |
|    total_timesteps       | 2430976     |
| train/                   |             |
|    approx_kl             | 0.02024276  |
|    clip_fraction         | 0.213       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.94        |
|    cost_value_loss       | 6.5         |
|    cost_values           | 2.27        |
|    entropy               | 0.131       |
|    entropy_loss          | 0.133       |
|    explained_variance    | 0.924       |
|    lagrangian_multiplier | 0.00238     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.53        |
|    n_updates             | 11860       |
|    policy_gradient_loss  | 0.00822     |
|    std                   | 0.31        |
|    value_loss            | 3.1         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.24577788 |
| rollout/                 |             |
|    ep_len_mean           | 69.8        |
|    ep_rew_mean           | -30.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 12          |
|    time_elapsed          | 359         |
|    total_timesteps       | 2433024     |
| train/                   |             |
|    approx_kl             | 0.034291428 |
|    clip_fraction         | 0.197       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.63        |
|    cost_value_loss       | 9.03        |
|    cost_values           | 2.24        |
|    entropy               | 0.131       |
|    entropy_loss          | 0.131       |
|    explained_variance    | 0.825       |
|    lagrangian_multiplier | 0.00147     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.8         |
|    n_updates             | 11870       |
|    policy_gradient_loss  | 0.00937     |
|    std                   | 0.31        |
|    value_loss            | 4.97        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.85620236 |
| rollout/                 |             |
|    ep_len_mean           | 70.7        |
|    ep_rew_mean           | -30.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 13          |
|    time_elapsed          | 389         |
|    total_timesteps       | 2435072     |
| train/                   |             |
|    approx_kl             | 0.023450539 |
|    clip_fraction         | 0.16        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.34        |
|    cost_value_loss       | 7.95        |
|    cost_values           | 2.26        |
|    entropy               | 0.136       |
|    entropy_loss          | 0.132       |
|    explained_variance    | 0.859       |
|    lagrangian_multiplier | 0.00102     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.7         |
|    n_updates             | 11880       |
|    policy_gradient_loss  | 0.00108     |
|    std                   | 0.309       |
|    value_loss            | 4.92        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.26408643 |
| rollout/                 |             |
|    ep_len_mean           | 64.7        |
|    ep_rew_mean           | -29.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 14          |
|    time_elapsed          | 419         |
|    total_timesteps       | 2437120     |
| train/                   |             |
|    approx_kl             | 0.023385052 |
|    clip_fraction         | 0.187       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.35        |
|    cost_value_loss       | 7.69        |
|    cost_values           | 2.3         |
|    entropy               | 0.144       |
|    entropy_loss          | 0.14        |
|    explained_variance    | 0.859       |
|    lagrangian_multiplier | 0.00205     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.62        |
|    n_updates             | 11890       |
|    policy_gradient_loss  | 0.00197     |
|    std                   | 0.308       |
|    value_loss            | 5.09        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.6         |
| reward                   | -0.79263544 |
| rollout/                 |             |
|    ep_len_mean           | 62.5        |
|    ep_rew_mean           | -28.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 15          |
|    time_elapsed          | 450         |
|    total_timesteps       | 2439168     |
| train/                   |             |
|    approx_kl             | 0.060222447 |
|    clip_fraction         | 0.197       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.17        |
|    cost_value_loss       | 7.15        |
|    cost_values           | 2.31        |
|    entropy               | 0.15        |
|    entropy_loss          | 0.146       |
|    explained_variance    | 0.904       |
|    lagrangian_multiplier | 0.0015      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.04        |
|    n_updates             | 11900       |
|    policy_gradient_loss  | 0.00359     |
|    std                   | 0.307       |
|    value_loss            | 3.67        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.39705375 |
| rollout/                 |             |
|    ep_len_mean           | 64.3        |
|    ep_rew_mean           | -29.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 16          |
|    time_elapsed          | 480         |
|    total_timesteps       | 2441216     |
| train/                   |             |
|    approx_kl             | 0.024517108 |
|    clip_fraction         | 0.187       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.23        |
|    cost_value_loss       | 7.01        |
|    cost_values           | 2.27        |
|    entropy               | 0.151       |
|    entropy_loss          | 0.15        |
|    explained_variance    | 0.899       |
|    lagrangian_multiplier | 0.000872    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.33        |
|    n_updates             | 11910       |
|    policy_gradient_loss  | 0.0122      |
|    std                   | 0.306       |
|    value_loss            | 3.8         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.20869164 |
| rollout/                 |             |
|    ep_len_mean           | 67.4        |
|    ep_rew_mean           | -30.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 17          |
|    time_elapsed          | 510         |
|    total_timesteps       | 2443264     |
| train/                   |             |
|    approx_kl             | 0.014405857 |
|    clip_fraction         | 0.156       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.17        |
|    cost_value_loss       | 6.69        |
|    cost_values           | 2.27        |
|    entropy               | 0.15        |
|    entropy_loss          | 0.151       |
|    explained_variance    | 0.862       |
|    lagrangian_multiplier | 0.00105     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.33        |
|    n_updates             | 11920       |
|    policy_gradient_loss  | 0.00311     |
|    std                   | 0.306       |
|    value_loss            | 4.42        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.8612248  |
| rollout/                 |             |
|    ep_len_mean           | 68.5        |
|    ep_rew_mean           | -30.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 18          |
|    time_elapsed          | 540         |
|    total_timesteps       | 2445312     |
| train/                   |             |
|    approx_kl             | 0.026487127 |
|    clip_fraction         | 0.216       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.22        |
|    cost_value_loss       | 7.34        |
|    cost_values           | 2.26        |
|    entropy               | 0.156       |
|    entropy_loss          | 0.153       |
|    explained_variance    | 0.881       |
|    lagrangian_multiplier | 0.000607    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.08        |
|    n_updates             | 11930       |
|    policy_gradient_loss  | 0.00348     |
|    std                   | 0.306       |
|    value_loss            | 4.18        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.32908183 |
| rollout/                 |             |
|    ep_len_mean           | 70.5        |
|    ep_rew_mean           | -30.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 19          |
|    time_elapsed          | 570         |
|    total_timesteps       | 2447360     |
| train/                   |             |
|    approx_kl             | 0.026216801 |
|    clip_fraction         | 0.178       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.11        |
|    cost_value_loss       | 6.67        |
|    cost_values           | 2.24        |
|    entropy               | 0.152       |
|    entropy_loss          | 0.155       |
|    explained_variance    | 0.869       |
|    lagrangian_multiplier | 0.000299    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.07        |
|    n_updates             | 11940       |
|    policy_gradient_loss  | 0.00635     |
|    std                   | 0.306       |
|    value_loss            | 4.82        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.19559394 |
| rollout/                 |             |
|    ep_len_mean           | 71.6        |
|    ep_rew_mean           | -31         |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 20          |
|    time_elapsed          | 600         |
|    total_timesteps       | 2449408     |
| train/                   |             |
|    approx_kl             | 0.019701168 |
|    clip_fraction         | 0.186       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.45        |
|    cost_value_loss       | 8.09        |
|    cost_values           | 2.29        |
|    entropy               | 0.146       |
|    entropy_loss          | 0.149       |
|    explained_variance    | 0.865       |
|    lagrangian_multiplier | 0.000471    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.98        |
|    n_updates             | 11950       |
|    policy_gradient_loss  | 0.00435     |
|    std                   | 0.307       |
|    value_loss            | 4.16        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.8514573  |
| rollout/                 |             |
|    ep_len_mean           | 70.3        |
|    ep_rew_mean           | -30.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 21          |
|    time_elapsed          | 630         |
|    total_timesteps       | 2451456     |
| train/                   |             |
|    approx_kl             | 0.017077537 |
|    clip_fraction         | 0.199       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.1         |
|    cost_value_loss       | 6.19        |
|    cost_values           | 2.3         |
|    entropy               | 0.154       |
|    entropy_loss          | 0.149       |
|    explained_variance    | 0.888       |
|    lagrangian_multiplier | 0.00192     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.75        |
|    n_updates             | 11960       |
|    policy_gradient_loss  | 0.00937     |
|    std                   | 0.305       |
|    value_loss            | 4           |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2039089  |
| rollout/                 |             |
|    ep_len_mean           | 71.8        |
|    ep_rew_mean           | -30.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 22          |
|    time_elapsed          | 659         |
|    total_timesteps       | 2453504     |
| train/                   |             |
|    approx_kl             | 0.019689979 |
|    clip_fraction         | 0.211       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.05        |
|    cost_value_loss       | 6.34        |
|    cost_values           | 2.25        |
|    entropy               | 0.157       |
|    entropy_loss          | 0.157       |
|    explained_variance    | 0.904       |
|    lagrangian_multiplier | 0.00203     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.6         |
|    n_updates             | 11970       |
|    policy_gradient_loss  | 0.0113      |
|    std                   | 0.304       |
|    value_loss            | 3.59        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.28878888 |
| rollout/                 |             |
|    ep_len_mean           | 73.2        |
|    ep_rew_mean           | -31.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 23          |
|    time_elapsed          | 689         |
|    total_timesteps       | 2455552     |
| train/                   |             |
|    approx_kl             | 0.016181907 |
|    clip_fraction         | 0.17        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.94        |
|    cost_value_loss       | 6.5         |
|    cost_values           | 2.2         |
|    entropy               | 0.156       |
|    entropy_loss          | 0.157       |
|    explained_variance    | 0.868       |
|    lagrangian_multiplier | 0.000777    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.33        |
|    n_updates             | 11980       |
|    policy_gradient_loss  | 0.00832     |
|    std                   | 0.304       |
|    value_loss            | 3.92        |
------------------------------------------
-----------------------------------------
| avg_speed                | 4          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 4          |
| reward                   | -0.7083134 |
| rollout/                 |            |
|    ep_len_mean           | 73.5       |
|    ep_rew_mean           | -31.6      |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 24         |
|    time_elapsed          | 719        |
|    total_timesteps       | 2457600    |
| train/                   |            |
|    approx_kl             | 0.04600213 |
|    clip_fraction         | 0.178      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.25       |
|    cost_value_loss       | 7.18       |
|    cost_values           | 2.2        |
|    entropy               | 0.16       |
|    entropy_loss          | 0.158      |
|    explained_variance    | 0.792      |
|    lagrangian_multiplier | 0.000499   |
|    learning_rate         | 0.0003     |
|    loss                  | 6.02       |
|    n_updates             | 11990      |
|    policy_gradient_loss  | 0.00474    |
|    std                   | 0.304      |
|    value_loss            | 5.81       |
-----------------------------------------
------------------------------------------
| avg_speed                | 5           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5           |
| reward                   | -0.52858806 |
| rollout/                 |             |
|    ep_len_mean           | 71.5        |
|    ep_rew_mean           | -30.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 25          |
|    time_elapsed          | 748         |
|    total_timesteps       | 2459648     |
| train/                   |             |
|    approx_kl             | 0.008585501 |
|    clip_fraction         | 0.143       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.13        |
|    cost_value_loss       | 6.47        |
|    cost_values           | 2.23        |
|    entropy               | 0.161       |
|    entropy_loss          | 0.16        |
|    explained_variance    | 0.802       |
|    lagrangian_multiplier | 0.000457    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.8         |
|    n_updates             | 12000       |
|    policy_gradient_loss  | 0.00508     |
|    std                   | 0.304       |
|    value_loss            | 7.03        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.4         |
| reward                   | -0.2563135  |
| rollout/                 |             |
|    ep_len_mean           | 64.7        |
|    ep_rew_mean           | -28.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 26          |
|    time_elapsed          | 779         |
|    total_timesteps       | 2461696     |
| train/                   |             |
|    approx_kl             | 0.029647348 |
|    clip_fraction         | 0.175       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.9         |
|    cost_value_loss       | 5.67        |
|    cost_values           | 2.22        |
|    entropy               | 0.163       |
|    entropy_loss          | 0.161       |
|    explained_variance    | 0.845       |
|    lagrangian_multiplier | 0.000528    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.48        |
|    n_updates             | 12010       |
|    policy_gradient_loss  | 0.00486     |
|    std                   | 0.304       |
|    value_loss            | 4.79        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.6         |
| reward                   | -0.29396918 |
| rollout/                 |             |
|    ep_len_mean           | 63.4        |
|    ep_rew_mean           | -27.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 27          |
|    time_elapsed          | 808         |
|    total_timesteps       | 2463744     |
| train/                   |             |
|    approx_kl             | 0.035545282 |
|    clip_fraction         | 0.21        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.76        |
|    cost_value_loss       | 5.5         |
|    cost_values           | 2.16        |
|    entropy               | 0.168       |
|    entropy_loss          | 0.165       |
|    explained_variance    | 0.868       |
|    lagrangian_multiplier | 0.00066     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.96        |
|    n_updates             | 12020       |
|    policy_gradient_loss  | 0.000463    |
|    std                   | 0.302       |
|    value_loss            | 4.44        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.37259007 |
| rollout/                 |             |
|    ep_len_mean           | 63.1        |
|    ep_rew_mean           | -28.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 28          |
|    time_elapsed          | 838         |
|    total_timesteps       | 2465792     |
| train/                   |             |
|    approx_kl             | 0.030096937 |
|    clip_fraction         | 0.173       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.05        |
|    cost_value_loss       | 7.01        |
|    cost_values           | 2.18        |
|    entropy               | 0.169       |
|    entropy_loss          | 0.169       |
|    explained_variance    | 0.915       |
|    lagrangian_multiplier | 0.00158     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.75        |
|    n_updates             | 12030       |
|    policy_gradient_loss  | 0.00394     |
|    std                   | 0.302       |
|    value_loss            | 3.31        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.30392328 |
| rollout/                 |             |
|    ep_len_mean           | 63          |
|    ep_rew_mean           | -28.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 29          |
|    time_elapsed          | 868         |
|    total_timesteps       | 2467840     |
| train/                   |             |
|    approx_kl             | 0.051936064 |
|    clip_fraction         | 0.174       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.13        |
|    cost_value_loss       | 6.81        |
|    cost_values           | 2.23        |
|    entropy               | 0.176       |
|    entropy_loss          | 0.172       |
|    explained_variance    | 0.881       |
|    lagrangian_multiplier | 0.000565    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.82        |
|    n_updates             | 12040       |
|    policy_gradient_loss  | 0.00948     |
|    std                   | 0.302       |
|    value_loss            | 4.15        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.13136113 |
| rollout/                 |             |
|    ep_len_mean           | 61.6        |
|    ep_rew_mean           | -28.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 30          |
|    time_elapsed          | 899         |
|    total_timesteps       | 2469888     |
| train/                   |             |
|    approx_kl             | 0.02778674  |
|    clip_fraction         | 0.208       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.8         |
|    cost_value_loss       | 5.97        |
|    cost_values           | 2.24        |
|    entropy               | 0.176       |
|    entropy_loss          | 0.176       |
|    explained_variance    | 0.921       |
|    lagrangian_multiplier | 0.000968    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.1         |
|    n_updates             | 12050       |
|    policy_gradient_loss  | 0.00331     |
|    std                   | 0.302       |
|    value_loss            | 3.32        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.59        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.59        |
| reward                   | -0.36228174 |
| rollout/                 |             |
|    ep_len_mean           | 63.9        |
|    ep_rew_mean           | -29.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 31          |
|    time_elapsed          | 929         |
|    total_timesteps       | 2471936     |
| train/                   |             |
|    approx_kl             | 0.019303523 |
|    clip_fraction         | 0.185       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.73        |
|    cost_value_loss       | 5.16        |
|    cost_values           | 2.19        |
|    entropy               | 0.176       |
|    entropy_loss          | 0.175       |
|    explained_variance    | 0.938       |
|    lagrangian_multiplier | 0.000497    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.38        |
|    n_updates             | 12060       |
|    policy_gradient_loss  | 0.00734     |
|    std                   | 0.303       |
|    value_loss            | 2.38        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8            |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8            |
| reward                   | -0.33024782  |
| rollout/                 |              |
|    ep_len_mean           | 67.5         |
|    ep_rew_mean           | -30.1        |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 32           |
|    time_elapsed          | 959          |
|    total_timesteps       | 2473984      |
| train/                   |              |
|    approx_kl             | 0.0065330863 |
|    clip_fraction         | 0.163        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.1          |
|    cost_value_loss       | 6.81         |
|    cost_values           | 2.12         |
|    entropy               | 0.175        |
|    entropy_loss          | 0.176        |
|    explained_variance    | 0.701        |
|    lagrangian_multiplier | 0.000694     |
|    learning_rate         | 0.0003       |
|    loss                  | 5.53         |
|    n_updates             | 12070        |
|    policy_gradient_loss  | 0.00912      |
|    std                   | 0.304        |
|    value_loss            | 6.48         |
-------------------------------------------
------------------------------------------
| avg_speed                | 4.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.4         |
| reward                   | -0.733391   |
| rollout/                 |             |
|    ep_len_mean           | 68.2        |
|    ep_rew_mean           | -30.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 33          |
|    time_elapsed          | 991         |
|    total_timesteps       | 2476032     |
| train/                   |             |
|    approx_kl             | 0.014508741 |
|    clip_fraction         | 0.172       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.96        |
|    cost_value_loss       | 5.88        |
|    cost_values           | 2.15        |
|    entropy               | 0.177       |
|    entropy_loss          | 0.177       |
|    explained_variance    | 0.822       |
|    lagrangian_multiplier | 0.00122     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.42        |
|    n_updates             | 12080       |
|    policy_gradient_loss  | 0.00433     |
|    std                   | 0.304       |
|    value_loss            | 5.65        |
------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.66070133 |
| rollout/                 |             |
|    ep_len_mean           | 64.2        |
|    ep_rew_mean           | -29         |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 34          |
|    time_elapsed          | 1021        |
|    total_timesteps       | 2478080     |
| train/                   |             |
|    approx_kl             | 0.014527242 |
|    clip_fraction         | 0.175       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.91        |
|    cost_value_loss       | 5.93        |
|    cost_values           | 2.17        |
|    entropy               | 0.186       |
|    entropy_loss          | 0.181       |
|    explained_variance    | 0.859       |
|    lagrangian_multiplier | 0.00151     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.11        |
|    n_updates             | 12090       |
|    policy_gradient_loss  | 0.00387     |
|    std                   | 0.302       |
|    value_loss            | 5.38        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.23170318 |
| rollout/                 |             |
|    ep_len_mean           | 62          |
|    ep_rew_mean           | -28.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 35          |
|    time_elapsed          | 1052        |
|    total_timesteps       | 2480128     |
| train/                   |             |
|    approx_kl             | 0.017896252 |
|    clip_fraction         | 0.167       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.96        |
|    cost_value_loss       | 6.4         |
|    cost_values           | 2.14        |
|    entropy               | 0.186       |
|    entropy_loss          | 0.187       |
|    explained_variance    | 0.861       |
|    lagrangian_multiplier | 0.000503    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.77        |
|    n_updates             | 12100       |
|    policy_gradient_loss  | 0.00139     |
|    std                   | 0.302       |
|    value_loss            | 4.79        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.69801575 |
| rollout/                 |             |
|    ep_len_mean           | 63.8        |
|    ep_rew_mean           | -28.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 36          |
|    time_elapsed          | 1082        |
|    total_timesteps       | 2482176     |
| train/                   |             |
|    approx_kl             | 0.038268648 |
|    clip_fraction         | 0.197       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.09        |
|    cost_value_loss       | 6.87        |
|    cost_values           | 2.15        |
|    entropy               | 0.183       |
|    entropy_loss          | 0.185       |
|    explained_variance    | 0.815       |
|    lagrangian_multiplier | 0.00123     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.03        |
|    n_updates             | 12110       |
|    policy_gradient_loss  | 0.00709     |
|    std                   | 0.303       |
|    value_loss            | 6.18        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.22875936 |
| rollout/                 |             |
|    ep_len_mean           | 64.4        |
|    ep_rew_mean           | -28.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 37          |
|    time_elapsed          | 1111        |
|    total_timesteps       | 2484224     |
| train/                   |             |
|    approx_kl             | 0.014811626 |
|    clip_fraction         | 0.143       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.89        |
|    cost_value_loss       | 5.97        |
|    cost_values           | 2.13        |
|    entropy               | 0.182       |
|    entropy_loss          | 0.182       |
|    explained_variance    | 0.838       |
|    lagrangian_multiplier | 0.00133     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.25        |
|    n_updates             | 12120       |
|    policy_gradient_loss  | 0.00329     |
|    std                   | 0.303       |
|    value_loss            | 5.29        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.739236   |
| rollout/                 |             |
|    ep_len_mean           | 70          |
|    ep_rew_mean           | -30.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 38          |
|    time_elapsed          | 1141        |
|    total_timesteps       | 2486272     |
| train/                   |             |
|    approx_kl             | 0.012125589 |
|    clip_fraction         | 0.135       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.14        |
|    cost_value_loss       | 7.23        |
|    cost_values           | 2.13        |
|    entropy               | 0.18        |
|    entropy_loss          | 0.181       |
|    explained_variance    | 0.769       |
|    lagrangian_multiplier | 0.000626    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.94        |
|    n_updates             | 12130       |
|    policy_gradient_loss  | -0.00267    |
|    std                   | 0.304       |
|    value_loss            | 7.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.05        |
| reward                   | -0.38221404 |
| rollout/                 |             |
|    ep_len_mean           | 68.3        |
|    ep_rew_mean           | -30         |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 39          |
|    time_elapsed          | 1171        |
|    total_timesteps       | 2488320     |
| train/                   |             |
|    approx_kl             | 0.030719949 |
|    clip_fraction         | 0.183       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.16        |
|    cost_value_loss       | 7.17        |
|    cost_values           | 2.13        |
|    entropy               | 0.173       |
|    entropy_loss          | 0.177       |
|    explained_variance    | 0.84        |
|    lagrangian_multiplier | 0.000289    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.87        |
|    n_updates             | 12140       |
|    policy_gradient_loss  | 0.0018      |
|    std                   | 0.305       |
|    value_loss            | 5.75        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.93        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.93        |
| reward                   | -0.27218464 |
| rollout/                 |             |
|    ep_len_mean           | 67.7        |
|    ep_rew_mean           | -29.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 40          |
|    time_elapsed          | 1201        |
|    total_timesteps       | 2490368     |
| train/                   |             |
|    approx_kl             | 0.011231668 |
|    clip_fraction         | 0.178       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.88        |
|    cost_value_loss       | 5.91        |
|    cost_values           | 2.11        |
|    entropy               | 0.174       |
|    entropy_loss          | 0.173       |
|    explained_variance    | 0.815       |
|    lagrangian_multiplier | 0.00132     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.24        |
|    n_updates             | 12150       |
|    policy_gradient_loss  | 0.00575     |
|    std                   | 0.305       |
|    value_loss            | 5.94        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.35884947 |
| rollout/                 |             |
|    ep_len_mean           | 63.6        |
|    ep_rew_mean           | -28.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 41          |
|    time_elapsed          | 1231        |
|    total_timesteps       | 2492416     |
| train/                   |             |
|    approx_kl             | 0.030505314 |
|    clip_fraction         | 0.205       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.04        |
|    cost_value_loss       | 6.72        |
|    cost_values           | 2.12        |
|    entropy               | 0.172       |
|    entropy_loss          | 0.174       |
|    explained_variance    | 0.889       |
|    lagrangian_multiplier | 0.00217     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.68        |
|    n_updates             | 12160       |
|    policy_gradient_loss  | 0.00883     |
|    std                   | 0.305       |
|    value_loss            | 3.73        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.23848234 |
| rollout/                 |             |
|    ep_len_mean           | 62.3        |
|    ep_rew_mean           | -28.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 42          |
|    time_elapsed          | 1261        |
|    total_timesteps       | 2494464     |
| train/                   |             |
|    approx_kl             | 0.034562185 |
|    clip_fraction         | 0.178       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.02        |
|    cost_value_loss       | 6.77        |
|    cost_values           | 2.16        |
|    entropy               | 0.163       |
|    entropy_loss          | 0.168       |
|    explained_variance    | 0.925       |
|    lagrangian_multiplier | 0.00175     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.62        |
|    n_updates             | 12170       |
|    policy_gradient_loss  | 0.00586     |
|    std                   | 0.307       |
|    value_loss            | 3.09        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.24228194 |
| rollout/                 |             |
|    ep_len_mean           | 61.5        |
|    ep_rew_mean           | -28.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 43          |
|    time_elapsed          | 1291        |
|    total_timesteps       | 2496512     |
| train/                   |             |
|    approx_kl             | 0.02737416  |
|    clip_fraction         | 0.219       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.91        |
|    cost_value_loss       | 6.03        |
|    cost_values           | 2.17        |
|    entropy               | 0.16        |
|    entropy_loss          | 0.161       |
|    explained_variance    | 0.848       |
|    lagrangian_multiplier | 0.00151     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.07        |
|    n_updates             | 12180       |
|    policy_gradient_loss  | 0.00361     |
|    std                   | 0.308       |
|    value_loss            | 5.35        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.31864992 |
| rollout/                 |             |
|    ep_len_mean           | 65.4        |
|    ep_rew_mean           | -29         |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 44          |
|    time_elapsed          | 1321        |
|    total_timesteps       | 2498560     |
| train/                   |             |
|    approx_kl             | 0.04208746  |
|    clip_fraction         | 0.192       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.94        |
|    cost_value_loss       | 6.27        |
|    cost_values           | 2.15        |
|    entropy               | 0.162       |
|    entropy_loss          | 0.161       |
|    explained_variance    | 0.886       |
|    lagrangian_multiplier | 0.00112     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.95        |
|    n_updates             | 12190       |
|    policy_gradient_loss  | 0.00565     |
|    std                   | 0.308       |
|    value_loss            | 3.72        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.70995224 |
| rollout/                 |             |
|    ep_len_mean           | 65.7        |
|    ep_rew_mean           | -28.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 45          |
|    time_elapsed          | 1351        |
|    total_timesteps       | 2500608     |
| train/                   |             |
|    approx_kl             | 0.021898823 |
|    clip_fraction         | 0.18        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.33        |
|    cost_value_loss       | 7.67        |
|    cost_values           | 2.16        |
|    entropy               | 0.158       |
|    entropy_loss          | 0.16        |
|    explained_variance    | 0.822       |
|    lagrangian_multiplier | 0.00144     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.53        |
|    n_updates             | 12200       |
|    policy_gradient_loss  | 0.00588     |
|    std                   | 0.309       |
|    value_loss            | 4.88        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.5         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.5         |
| reward                   | -0.26295462 |
| rollout/                 |             |
|    ep_len_mean           | 67.1        |
|    ep_rew_mean           | -29.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 46          |
|    time_elapsed          | 1382        |
|    total_timesteps       | 2502656     |
| train/                   |             |
|    approx_kl             | 0.015208906 |
|    clip_fraction         | 0.203       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.04        |
|    cost_value_loss       | 6.23        |
|    cost_values           | 2.17        |
|    entropy               | 0.156       |
|    entropy_loss          | 0.157       |
|    explained_variance    | 0.855       |
|    lagrangian_multiplier | 0.0018      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.78        |
|    n_updates             | 12210       |
|    policy_gradient_loss  | 0.0067      |
|    std                   | 0.309       |
|    value_loss            | 4.47        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.78        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.78        |
| reward                   | -0.16515547 |
| rollout/                 |             |
|    ep_len_mean           | 63.1        |
|    ep_rew_mean           | -28.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 47          |
|    time_elapsed          | 1411        |
|    total_timesteps       | 2504704     |
| train/                   |             |
|    approx_kl             | 0.023756567 |
|    clip_fraction         | 0.23        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.08        |
|    cost_value_loss       | 7.17        |
|    cost_values           | 2.17        |
|    entropy               | 0.157       |
|    entropy_loss          | 0.157       |
|    explained_variance    | 0.883       |
|    lagrangian_multiplier | 0.000998    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.49        |
|    n_updates             | 12220       |
|    policy_gradient_loss  | 0.011       |
|    std                   | 0.308       |
|    value_loss            | 4.19        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.8581075  |
| rollout/                 |             |
|    ep_len_mean           | 62.6        |
|    ep_rew_mean           | -28.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 48          |
|    time_elapsed          | 1442        |
|    total_timesteps       | 2506752     |
| train/                   |             |
|    approx_kl             | 0.016906034 |
|    clip_fraction         | 0.19        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.99        |
|    cost_value_loss       | 6.64        |
|    cost_values           | 2.14        |
|    entropy               | 0.158       |
|    entropy_loss          | 0.158       |
|    explained_variance    | 0.86        |
|    lagrangian_multiplier | 0.000689    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.78        |
|    n_updates             | 12230       |
|    policy_gradient_loss  | 0.00859     |
|    std                   | 0.308       |
|    value_loss            | 4.83        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.8         |
| reward                   | -0.2135768  |
| rollout/                 |             |
|    ep_len_mean           | 63.8        |
|    ep_rew_mean           | -29.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 49          |
|    time_elapsed          | 1473        |
|    total_timesteps       | 2508800     |
| train/                   |             |
|    approx_kl             | 0.046801016 |
|    clip_fraction         | 0.202       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.99        |
|    cost_value_loss       | 6.55        |
|    cost_values           | 2.14        |
|    entropy               | 0.163       |
|    entropy_loss          | 0.161       |
|    explained_variance    | 0.851       |
|    lagrangian_multiplier | 0.000821    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.78        |
|    n_updates             | 12240       |
|    policy_gradient_loss  | 0.00574     |
|    std                   | 0.307       |
|    value_loss            | 5.37        |
------------------------------------------
-----------------------------------
| avg_speed          | 8          |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8          |
| reward             | -0.3783554 |
| rollout/           |            |
|    ep_len_mean     | 66.1       |
|    ep_rew_mean     | -29.8      |
| time/              |            |
|    fps             | 72         |
|    iterations      | 1          |
|    time_elapsed    | 28         |
|    total_timesteps | 2510848    |
-----------------------------------
------------------------------------------
| avg_speed                | 3.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.2         |
| reward                   | -0.83305484 |
| rollout/                 |             |
|    ep_len_mean           | 70.3        |
|    ep_rew_mean           | -30.1       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 2           |
|    time_elapsed          | 58          |
|    total_timesteps       | 2512896     |
| train/                   |             |
|    approx_kl             | 0.026637023 |
|    clip_fraction         | 0.21        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.65        |
|    cost_value_loss       | 9.54        |
|    cost_values           | 2.24        |
|    entropy               | 0.17        |
|    entropy_loss          | 0.169       |
|    explained_variance    | 0.847       |
|    lagrangian_multiplier | 0.00166     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.74        |
|    n_updates             | 12260       |
|    policy_gradient_loss  | 0.00511     |
|    std                   | 0.305       |
|    value_loss            | 4.55        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.73        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.73        |
| reward                   | -0.25254497 |
| rollout/                 |             |
|    ep_len_mean           | 70.2        |
|    ep_rew_mean           | -30         |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 3           |
|    time_elapsed          | 87          |
|    total_timesteps       | 2514944     |
| train/                   |             |
|    approx_kl             | 0.02930491  |
|    clip_fraction         | 0.194       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.18        |
|    cost_value_loss       | 6.75        |
|    cost_values           | 2.22        |
|    entropy               | 0.171       |
|    entropy_loss          | 0.171       |
|    explained_variance    | 0.832       |
|    lagrangian_multiplier | 0.000569    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.75        |
|    n_updates             | 12270       |
|    policy_gradient_loss  | 0.011       |
|    std                   | 0.305       |
|    value_loss            | 4.55        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.44        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.44        |
| reward                   | -0.32106742 |
| rollout/                 |             |
|    ep_len_mean           | 68.9        |
|    ep_rew_mean           | -29.2       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 4           |
|    time_elapsed          | 117         |
|    total_timesteps       | 2516992     |
| train/                   |             |
|    approx_kl             | 0.04689206  |
|    clip_fraction         | 0.195       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.28        |
|    cost_value_loss       | 7.61        |
|    cost_values           | 2.23        |
|    entropy               | 0.175       |
|    entropy_loss          | 0.173       |
|    explained_variance    | 0.877       |
|    lagrangian_multiplier | 0.000758    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.05        |
|    n_updates             | 12280       |
|    policy_gradient_loss  | 0.00812     |
|    std                   | 0.304       |
|    value_loss            | 4.49        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.92        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.92        |
| reward                   | -0.13810009 |
| rollout/                 |             |
|    ep_len_mean           | 63.7        |
|    ep_rew_mean           | -28.2       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 5           |
|    time_elapsed          | 147         |
|    total_timesteps       | 2519040     |
| train/                   |             |
|    approx_kl             | 0.019950874 |
|    clip_fraction         | 0.244       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.36        |
|    cost_value_loss       | 7.66        |
|    cost_values           | 2.25        |
|    entropy               | 0.179       |
|    entropy_loss          | 0.177       |
|    explained_variance    | 0.911       |
|    lagrangian_multiplier | 0.000284    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.27        |
|    n_updates             | 12290       |
|    policy_gradient_loss  | 0.00946     |
|    std                   | 0.304       |
|    value_loss            | 3.14        |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.6797877  |
| rollout/                 |             |
|    ep_len_mean           | 64          |
|    ep_rew_mean           | -28.8       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 6           |
|    time_elapsed          | 176         |
|    total_timesteps       | 2521088     |
| train/                   |             |
|    approx_kl             | 0.017894763 |
|    clip_fraction         | 0.166       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.97        |
|    cost_value_loss       | 5.91        |
|    cost_values           | 2.23        |
|    entropy               | 0.192       |
|    entropy_loss          | 0.185       |
|    explained_variance    | 0.911       |
|    lagrangian_multiplier | 0.00294     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.35        |
|    n_updates             | 12300       |
|    policy_gradient_loss  | 0.00552     |
|    std                   | 0.301       |
|    value_loss            | 3.72        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.7217891  |
| rollout/                 |             |
|    ep_len_mean           | 64.8        |
|    ep_rew_mean           | -29.4       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 7           |
|    time_elapsed          | 206         |
|    total_timesteps       | 2523136     |
| train/                   |             |
|    approx_kl             | 0.021463787 |
|    clip_fraction         | 0.182       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.35        |
|    cost_value_loss       | 8.31        |
|    cost_values           | 2.19        |
|    entropy               | 0.198       |
|    entropy_loss          | 0.197       |
|    explained_variance    | 0.873       |
|    lagrangian_multiplier | 0.00121     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.92        |
|    n_updates             | 12310       |
|    policy_gradient_loss  | 0.00458     |
|    std                   | 0.301       |
|    value_loss            | 4.65        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.1418373  |
| rollout/                 |             |
|    ep_len_mean           | 67          |
|    ep_rew_mean           | -29.6       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 8           |
|    time_elapsed          | 235         |
|    total_timesteps       | 2525184     |
| train/                   |             |
|    approx_kl             | 0.021472074 |
|    clip_fraction         | 0.143       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.11        |
|    cost_value_loss       | 6.95        |
|    cost_values           | 2.18        |
|    entropy               | 0.199       |
|    entropy_loss          | 0.199       |
|    explained_variance    | 0.863       |
|    lagrangian_multiplier | 0.00124     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.17        |
|    n_updates             | 12320       |
|    policy_gradient_loss  | -0.00441    |
|    std                   | 0.301       |
|    value_loss            | 4.69        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.39071354 |
| rollout/                 |             |
|    ep_len_mean           | 66.9        |
|    ep_rew_mean           | -29.5       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 9           |
|    time_elapsed          | 265         |
|    total_timesteps       | 2527232     |
| train/                   |             |
|    approx_kl             | 0.017995019 |
|    clip_fraction         | 0.184       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.18        |
|    cost_value_loss       | 6.73        |
|    cost_values           | 2.15        |
|    entropy               | 0.212       |
|    entropy_loss          | 0.204       |
|    explained_variance    | 0.866       |
|    lagrangian_multiplier | 0.000855    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.34        |
|    n_updates             | 12330       |
|    policy_gradient_loss  | 0.00359     |
|    std                   | 0.3         |
|    value_loss            | 4.18        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.18        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.18        |
| reward                   | -0.26594096 |
| rollout/                 |             |
|    ep_len_mean           | 69.6        |
|    ep_rew_mean           | -30.2       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 10          |
|    time_elapsed          | 295         |
|    total_timesteps       | 2529280     |
| train/                   |             |
|    approx_kl             | 0.044517674 |
|    clip_fraction         | 0.163       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.27        |
|    cost_value_loss       | 7.73        |
|    cost_values           | 2.15        |
|    entropy               | 0.222       |
|    entropy_loss          | 0.217       |
|    explained_variance    | 0.851       |
|    lagrangian_multiplier | 0.00152     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.48        |
|    n_updates             | 12340       |
|    policy_gradient_loss  | 0.00869     |
|    std                   | 0.299       |
|    value_loss            | 5           |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.25958654 |
| rollout/                 |             |
|    ep_len_mean           | 66.8        |
|    ep_rew_mean           | -29.6       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 11          |
|    time_elapsed          | 325         |
|    total_timesteps       | 2531328     |
| train/                   |             |
|    approx_kl             | 0.039492577 |
|    clip_fraction         | 0.184       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.89        |
|    cost_value_loss       | 6.43        |
|    cost_values           | 2.13        |
|    entropy               | 0.223       |
|    entropy_loss          | 0.223       |
|    explained_variance    | 0.907       |
|    lagrangian_multiplier | 0.00136     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.77        |
|    n_updates             | 12350       |
|    policy_gradient_loss  | 0.00798     |
|    std                   | 0.299       |
|    value_loss            | 3.39        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.2140626  |
| rollout/                 |             |
|    ep_len_mean           | 65          |
|    ep_rew_mean           | -29.2       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 12          |
|    time_elapsed          | 355         |
|    total_timesteps       | 2533376     |
| train/                   |             |
|    approx_kl             | 0.024506614 |
|    clip_fraction         | 0.161       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.09        |
|    cost_value_loss       | 6.81        |
|    cost_values           | 2.12        |
|    entropy               | 0.223       |
|    entropy_loss          | 0.222       |
|    explained_variance    | 0.838       |
|    lagrangian_multiplier | 0.00176     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.43        |
|    n_updates             | 12360       |
|    policy_gradient_loss  | 0.00475     |
|    std                   | 0.299       |
|    value_loss            | 5.75        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.6760788  |
| rollout/                 |             |
|    ep_len_mean           | 66.5        |
|    ep_rew_mean           | -29.5       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 13          |
|    time_elapsed          | 385         |
|    total_timesteps       | 2535424     |
| train/                   |             |
|    approx_kl             | 0.013323623 |
|    clip_fraction         | 0.161       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.13        |
|    cost_value_loss       | 7.01        |
|    cost_values           | 2.15        |
|    entropy               | 0.222       |
|    entropy_loss          | 0.222       |
|    explained_variance    | 0.904       |
|    lagrangian_multiplier | 0.00237     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.63        |
|    n_updates             | 12370       |
|    policy_gradient_loss  | 0.00805     |
|    std                   | 0.3         |
|    value_loss            | 3.42        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.7940213  |
| rollout/                 |             |
|    ep_len_mean           | 66.2        |
|    ep_rew_mean           | -29.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 14          |
|    time_elapsed          | 415         |
|    total_timesteps       | 2537472     |
| train/                   |             |
|    approx_kl             | 0.019940782 |
|    clip_fraction         | 0.215       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.07        |
|    cost_value_loss       | 6.95        |
|    cost_values           | 2.15        |
|    entropy               | 0.225       |
|    entropy_loss          | 0.224       |
|    explained_variance    | 0.849       |
|    lagrangian_multiplier | 0.0013      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.42        |
|    n_updates             | 12380       |
|    policy_gradient_loss  | 0.0102      |
|    std                   | 0.3         |
|    value_loss            | 5.01        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.79        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.79        |
| reward                   | -0.35904542 |
| rollout/                 |             |
|    ep_len_mean           | 68.2        |
|    ep_rew_mean           | -29.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 15          |
|    time_elapsed          | 445         |
|    total_timesteps       | 2539520     |
| train/                   |             |
|    approx_kl             | 0.020993678 |
|    clip_fraction         | 0.216       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.66        |
|    cost_value_loss       | 5.39        |
|    cost_values           | 2.13        |
|    entropy               | 0.227       |
|    entropy_loss          | 0.226       |
|    explained_variance    | 0.865       |
|    lagrangian_multiplier | 0.00101     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.11        |
|    n_updates             | 12390       |
|    policy_gradient_loss  | 0.0105      |
|    std                   | 0.3         |
|    value_loss            | 4.92        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.2712293 |
| rollout/                 |            |
|    ep_len_mean           | 69.5       |
|    ep_rew_mean           | -30.1      |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 16         |
|    time_elapsed          | 475        |
|    total_timesteps       | 2541568    |
| train/                   |            |
|    approx_kl             | 0.04494369 |
|    clip_fraction         | 0.213      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.39       |
|    cost_value_loss       | 8.53       |
|    cost_values           | 2.14       |
|    entropy               | 0.231      |
|    entropy_loss          | 0.229      |
|    explained_variance    | 0.867      |
|    lagrangian_multiplier | 0.00124    |
|    learning_rate         | 0.0003     |
|    loss                  | 4.72       |
|    n_updates             | 12400      |
|    policy_gradient_loss  | 0.00602    |
|    std                   | 0.299      |
|    value_loss            | 4.19       |
-----------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.7969351  |
| rollout/                 |             |
|    ep_len_mean           | 66          |
|    ep_rew_mean           | -28.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 17          |
|    time_elapsed          | 506         |
|    total_timesteps       | 2543616     |
| train/                   |             |
|    approx_kl             | 0.017117899 |
|    clip_fraction         | 0.188       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.18        |
|    cost_value_loss       | 7.37        |
|    cost_values           | 2.17        |
|    entropy               | 0.23        |
|    entropy_loss          | 0.231       |
|    explained_variance    | 0.872       |
|    lagrangian_multiplier | 0.00232     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.83        |
|    n_updates             | 12410       |
|    policy_gradient_loss  | 0.00941     |
|    std                   | 0.299       |
|    value_loss            | 4.27        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.40378228 |
| rollout/                 |             |
|    ep_len_mean           | 67.5        |
|    ep_rew_mean           | -29.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 18          |
|    time_elapsed          | 536         |
|    total_timesteps       | 2545664     |
| train/                   |             |
|    approx_kl             | 0.051781572 |
|    clip_fraction         | 0.205       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.83        |
|    cost_value_loss       | 5.74        |
|    cost_values           | 2.14        |
|    entropy               | 0.228       |
|    entropy_loss          | 0.229       |
|    explained_variance    | 0.893       |
|    lagrangian_multiplier | 0.000759    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.19        |
|    n_updates             | 12420       |
|    policy_gradient_loss  | 0.00517     |
|    std                   | 0.298       |
|    value_loss            | 3.97        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.8883014  |
| rollout/                 |             |
|    ep_len_mean           | 66.4        |
|    ep_rew_mean           | -29.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 19          |
|    time_elapsed          | 565         |
|    total_timesteps       | 2547712     |
| train/                   |             |
|    approx_kl             | 0.025967846 |
|    clip_fraction         | 0.188       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.11        |
|    cost_value_loss       | 7.33        |
|    cost_values           | 2.12        |
|    entropy               | 0.225       |
|    entropy_loss          | 0.226       |
|    explained_variance    | 0.896       |
|    lagrangian_multiplier | 0.000752    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.54        |
|    n_updates             | 12430       |
|    policy_gradient_loss  | 0.00547     |
|    std                   | 0.298       |
|    value_loss            | 3.64        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.40775836 |
| rollout/                 |             |
|    ep_len_mean           | 68.7        |
|    ep_rew_mean           | -30.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 20          |
|    time_elapsed          | 595         |
|    total_timesteps       | 2549760     |
| train/                   |             |
|    approx_kl             | 0.028112425 |
|    clip_fraction         | 0.199       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.24        |
|    cost_value_loss       | 8.02        |
|    cost_values           | 2.17        |
|    entropy               | 0.225       |
|    entropy_loss          | 0.224       |
|    explained_variance    | 0.87        |
|    lagrangian_multiplier | 0.00172     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.3         |
|    n_updates             | 12440       |
|    policy_gradient_loss  | 0.00661     |
|    std                   | 0.297       |
|    value_loss            | 4.74        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.47819766 |
| rollout/                 |             |
|    ep_len_mean           | 69.8        |
|    ep_rew_mean           | -30.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 21          |
|    time_elapsed          | 624         |
|    total_timesteps       | 2551808     |
| train/                   |             |
|    approx_kl             | 0.024687756 |
|    clip_fraction         | 0.187       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.99        |
|    cost_value_loss       | 6.44        |
|    cost_values           | 2.15        |
|    entropy               | 0.227       |
|    entropy_loss          | 0.227       |
|    explained_variance    | 0.822       |
|    lagrangian_multiplier | 0.0013      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.27        |
|    n_updates             | 12450       |
|    policy_gradient_loss  | 0.00991     |
|    std                   | 0.296       |
|    value_loss            | 5.23        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.01         |
| cost                     | 0            |
| is_success               | 1            |
| max_speed                | 8.01         |
| reward                   | -0.118853286 |
| rollout/                 |              |
|    ep_len_mean           | 72.5         |
|    ep_rew_mean           | -30.8        |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 22           |
|    time_elapsed          | 654          |
|    total_timesteps       | 2553856      |
| train/                   |              |
|    approx_kl             | 0.024771504  |
|    clip_fraction         | 0.223        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.31         |
|    cost_value_loss       | 7.78         |
|    cost_values           | 2.14         |
|    entropy               | 0.228        |
|    entropy_loss          | 0.228        |
|    explained_variance    | 0.887        |
|    lagrangian_multiplier | 0.00118      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.52         |
|    n_updates             | 12460        |
|    policy_gradient_loss  | 0.00984      |
|    std                   | 0.297        |
|    value_loss            | 4.16         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.29567048 |
| rollout/                 |             |
|    ep_len_mean           | 71.6        |
|    ep_rew_mean           | -30.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 23          |
|    time_elapsed          | 683         |
|    total_timesteps       | 2555904     |
| train/                   |             |
|    approx_kl             | 0.025627654 |
|    clip_fraction         | 0.232       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.35        |
|    cost_value_loss       | 8.26        |
|    cost_values           | 2.15        |
|    entropy               | 0.222       |
|    entropy_loss          | 0.225       |
|    explained_variance    | 0.862       |
|    lagrangian_multiplier | 0.00138     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.6         |
|    n_updates             | 12470       |
|    policy_gradient_loss  | 0.0128      |
|    std                   | 0.298       |
|    value_loss            | 4.31        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.34543982 |
| rollout/                 |             |
|    ep_len_mean           | 67.6        |
|    ep_rew_mean           | -29.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 24          |
|    time_elapsed          | 713         |
|    total_timesteps       | 2557952     |
| train/                   |             |
|    approx_kl             | 0.020301726 |
|    clip_fraction         | 0.182       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.53        |
|    cost_value_loss       | 9.33        |
|    cost_values           | 2.19        |
|    entropy               | 0.224       |
|    entropy_loss          | 0.221       |
|    explained_variance    | 0.882       |
|    lagrangian_multiplier | 0.00103     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.89        |
|    n_updates             | 12480       |
|    policy_gradient_loss  | 0.00608     |
|    std                   | 0.297       |
|    value_loss            | 4.25        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.8         |
| reward                   | -0.66068506 |
| rollout/                 |             |
|    ep_len_mean           | 63          |
|    ep_rew_mean           | -28.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 25          |
|    time_elapsed          | 743         |
|    total_timesteps       | 2560000     |
| train/                   |             |
|    approx_kl             | 0.024118582 |
|    clip_fraction         | 0.206       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.43        |
|    cost_value_loss       | 8.75        |
|    cost_values           | 2.19        |
|    entropy               | 0.229       |
|    entropy_loss          | 0.226       |
|    explained_variance    | 0.914       |
|    lagrangian_multiplier | 0.00179     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.4         |
|    n_updates             | 12490       |
|    policy_gradient_loss  | 0.00961     |
|    std                   | 0.297       |
|    value_loss            | 3.41        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.33993664 |
| rollout/                 |             |
|    ep_len_mean           | 61.7        |
|    ep_rew_mean           | -28.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 26          |
|    time_elapsed          | 774         |
|    total_timesteps       | 2562048     |
| train/                   |             |
|    approx_kl             | 0.028098552 |
|    clip_fraction         | 0.221       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.1         |
|    cost_value_loss       | 6.81        |
|    cost_values           | 2.18        |
|    entropy               | 0.225       |
|    entropy_loss          | 0.229       |
|    explained_variance    | 0.924       |
|    lagrangian_multiplier | 0.00191     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.72        |
|    n_updates             | 12500       |
|    policy_gradient_loss  | 0.00522     |
|    std                   | 0.298       |
|    value_loss            | 3.28        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.6964047  |
| rollout/                 |             |
|    ep_len_mean           | 63.5        |
|    ep_rew_mean           | -28.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 27          |
|    time_elapsed          | 804         |
|    total_timesteps       | 2564096     |
| train/                   |             |
|    approx_kl             | 0.026021853 |
|    clip_fraction         | 0.223       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.39        |
|    cost_value_loss       | 8.44        |
|    cost_values           | 2.17        |
|    entropy               | 0.22        |
|    entropy_loss          | 0.222       |
|    explained_variance    | 0.872       |
|    lagrangian_multiplier | 0.0024      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.03        |
|    n_updates             | 12510       |
|    policy_gradient_loss  | 0.0091      |
|    std                   | 0.299       |
|    value_loss            | 4.23        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.2648272  |
| rollout/                 |             |
|    ep_len_mean           | 67.6        |
|    ep_rew_mean           | -29.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 28          |
|    time_elapsed          | 834         |
|    total_timesteps       | 2566144     |
| train/                   |             |
|    approx_kl             | 0.024180861 |
|    clip_fraction         | 0.214       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.41        |
|    cost_value_loss       | 8.64        |
|    cost_values           | 2.15        |
|    entropy               | 0.22        |
|    entropy_loss          | 0.22        |
|    explained_variance    | 0.868       |
|    lagrangian_multiplier | 0.00191     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.18        |
|    n_updates             | 12520       |
|    policy_gradient_loss  | 0.0094      |
|    std                   | 0.299       |
|    value_loss            | 4.1         |
------------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.7940213  |
| rollout/                 |             |
|    ep_len_mean           | 70.1        |
|    ep_rew_mean           | -30.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 29          |
|    time_elapsed          | 865         |
|    total_timesteps       | 2568192     |
| train/                   |             |
|    approx_kl             | 0.011715952 |
|    clip_fraction         | 0.161       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.5         |
|    cost_value_loss       | 8.91        |
|    cost_values           | 2.19        |
|    entropy               | 0.219       |
|    entropy_loss          | 0.219       |
|    explained_variance    | 0.885       |
|    lagrangian_multiplier | 0.00143     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.67        |
|    n_updates             | 12530       |
|    policy_gradient_loss  | 0.00563     |
|    std                   | 0.299       |
|    value_loss            | 4.1         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.05        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.05        |
| reward                   | -0.17437613 |
| rollout/                 |             |
|    ep_len_mean           | 69.8        |
|    ep_rew_mean           | -30.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 30          |
|    time_elapsed          | 895         |
|    total_timesteps       | 2570240     |
| train/                   |             |
|    approx_kl             | 0.02074907  |
|    clip_fraction         | 0.216       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.4         |
|    cost_value_loss       | 8.24        |
|    cost_values           | 2.23        |
|    entropy               | 0.217       |
|    entropy_loss          | 0.219       |
|    explained_variance    | 0.875       |
|    lagrangian_multiplier | 0.000787    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.06        |
|    n_updates             | 12540       |
|    policy_gradient_loss  | 0.00717     |
|    std                   | 0.3         |
|    value_loss            | 3.97        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.93        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.93        |
| reward                   | -0.28264606 |
| rollout/                 |             |
|    ep_len_mean           | 71.1        |
|    ep_rew_mean           | -30.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 31          |
|    time_elapsed          | 926         |
|    total_timesteps       | 2572288     |
| train/                   |             |
|    approx_kl             | 0.010480477 |
|    clip_fraction         | 0.164       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.34        |
|    cost_value_loss       | 8.06        |
|    cost_values           | 2.17        |
|    entropy               | 0.223       |
|    entropy_loss          | 0.22        |
|    explained_variance    | 0.852       |
|    lagrangian_multiplier | 0.00148     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.67        |
|    n_updates             | 12550       |
|    policy_gradient_loss  | 0.00614     |
|    std                   | 0.299       |
|    value_loss            | 4.64        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.6462943  |
| rollout/                 |             |
|    ep_len_mean           | 67.8        |
|    ep_rew_mean           | -29.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 32          |
|    time_elapsed          | 956         |
|    total_timesteps       | 2574336     |
| train/                   |             |
|    approx_kl             | 0.044118837 |
|    clip_fraction         | 0.228       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.33        |
|    cost_value_loss       | 8.4         |
|    cost_values           | 2.16        |
|    entropy               | 0.22        |
|    entropy_loss          | 0.222       |
|    explained_variance    | 0.893       |
|    lagrangian_multiplier | 0.00217     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.98        |
|    n_updates             | 12560       |
|    policy_gradient_loss  | 0.0123      |
|    std                   | 0.299       |
|    value_loss            | 3.64        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8.02       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.02       |
| reward                   | -0.3745641 |
| rollout/                 |            |
|    ep_len_mean           | 66.1       |
|    ep_rew_mean           | -29        |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 33         |
|    time_elapsed          | 986        |
|    total_timesteps       | 2576384    |
| train/                   |            |
|    approx_kl             | 0.0352501  |
|    clip_fraction         | 0.2        |
|    clip_range            | 0.2        |
|    cost_returns          | 4.17       |
|    cost_value_loss       | 7.78       |
|    cost_values           | 2.16       |
|    entropy               | 0.211      |
|    entropy_loss          | 0.215      |
|    explained_variance    | 0.905      |
|    lagrangian_multiplier | 0.00175    |
|    learning_rate         | 0.0003     |
|    loss                  | 3.78       |
|    n_updates             | 12570      |
|    policy_gradient_loss  | 0.00739    |
|    std                   | 0.299      |
|    value_loss            | 3.42       |
-----------------------------------------
------------------------------------------
| avg_speed                | 5.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.6         |
| reward                   | -0.49638668 |
| rollout/                 |             |
|    ep_len_mean           | 66.9        |
|    ep_rew_mean           | -29.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 34          |
|    time_elapsed          | 1016        |
|    total_timesteps       | 2578432     |
| train/                   |             |
|    approx_kl             | 0.014261886 |
|    clip_fraction         | 0.197       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.11        |
|    cost_value_loss       | 7.44        |
|    cost_values           | 2.17        |
|    entropy               | 0.208       |
|    entropy_loss          | 0.209       |
|    explained_variance    | 0.909       |
|    lagrangian_multiplier | 0.00213     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.92        |
|    n_updates             | 12580       |
|    policy_gradient_loss  | 0.00816     |
|    std                   | 0.3         |
|    value_loss            | 3.53        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.3381803 |
| rollout/                 |            |
|    ep_len_mean           | 67         |
|    ep_rew_mean           | -29.6      |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 35         |
|    time_elapsed          | 1046       |
|    total_timesteps       | 2580480    |
| train/                   |            |
|    approx_kl             | 0.04448811 |
|    clip_fraction         | 0.2        |
|    clip_range            | 0.2        |
|    cost_returns          | 4.12       |
|    cost_value_loss       | 7.57       |
|    cost_values           | 2.17       |
|    entropy               | 0.206      |
|    entropy_loss          | 0.207      |
|    explained_variance    | 0.903      |
|    lagrangian_multiplier | 0.00122    |
|    learning_rate         | 0.0003     |
|    loss                  | 4.22       |
|    n_updates             | 12590      |
|    policy_gradient_loss  | 0.00791    |
|    std                   | 0.301      |
|    value_loss            | 3.63       |
-----------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.75640273 |
| rollout/                 |             |
|    ep_len_mean           | 68.1        |
|    ep_rew_mean           | -29.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 36          |
|    time_elapsed          | 1076        |
|    total_timesteps       | 2582528     |
| train/                   |             |
|    approx_kl             | 0.026921844 |
|    clip_fraction         | 0.223       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.2         |
|    cost_value_loss       | 7.53        |
|    cost_values           | 2.15        |
|    entropy               | 0.204       |
|    entropy_loss          | 0.205       |
|    explained_variance    | 0.913       |
|    lagrangian_multiplier | 0.000655    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.58        |
|    n_updates             | 12600       |
|    policy_gradient_loss  | 0.0116      |
|    std                   | 0.302       |
|    value_loss            | 3.18        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.80450356 |
| rollout/                 |             |
|    ep_len_mean           | 67.2        |
|    ep_rew_mean           | -29.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 37          |
|    time_elapsed          | 1105        |
|    total_timesteps       | 2584576     |
| train/                   |             |
|    approx_kl             | 0.022322876 |
|    clip_fraction         | 0.177       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.47        |
|    cost_value_loss       | 8.58        |
|    cost_values           | 2.18        |
|    entropy               | 0.198       |
|    entropy_loss          | 0.201       |
|    explained_variance    | 0.889       |
|    lagrangian_multiplier | 0.00131     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.54        |
|    n_updates             | 12610       |
|    policy_gradient_loss  | 0.0065      |
|    std                   | 0.302       |
|    value_loss            | 4.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.45881137 |
| rollout/                 |             |
|    ep_len_mean           | 65.8        |
|    ep_rew_mean           | -29.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 38          |
|    time_elapsed          | 1134        |
|    total_timesteps       | 2586624     |
| train/                   |             |
|    approx_kl             | 0.012140114 |
|    clip_fraction         | 0.187       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.07        |
|    cost_value_loss       | 6.63        |
|    cost_values           | 2.2         |
|    entropy               | 0.192       |
|    entropy_loss          | 0.195       |
|    explained_variance    | 0.926       |
|    lagrangian_multiplier | 0.00228     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.39        |
|    n_updates             | 12620       |
|    policy_gradient_loss  | 0.00663     |
|    std                   | 0.303       |
|    value_loss            | 2.89        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.15743478 |
| rollout/                 |             |
|    ep_len_mean           | 64          |
|    ep_rew_mean           | -28.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 39          |
|    time_elapsed          | 1164        |
|    total_timesteps       | 2588672     |
| train/                   |             |
|    approx_kl             | 0.036283728 |
|    clip_fraction         | 0.22        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.91        |
|    cost_value_loss       | 5.98        |
|    cost_values           | 2.19        |
|    entropy               | 0.191       |
|    entropy_loss          | 0.191       |
|    explained_variance    | 0.92        |
|    lagrangian_multiplier | 0.0014      |
|    learning_rate         | 0.0003      |
|    loss                  | 3.67        |
|    n_updates             | 12630       |
|    policy_gradient_loss  | 0.0114      |
|    std                   | 0.303       |
|    value_loss            | 3.29        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.2         |
| reward                   | -0.5303846  |
| rollout/                 |             |
|    ep_len_mean           | 65.3        |
|    ep_rew_mean           | -29.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 40          |
|    time_elapsed          | 1193        |
|    total_timesteps       | 2590720     |
| train/                   |             |
|    approx_kl             | 0.026862664 |
|    clip_fraction         | 0.214       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.34        |
|    cost_value_loss       | 8.24        |
|    cost_values           | 2.21        |
|    entropy               | 0.189       |
|    entropy_loss          | 0.19        |
|    explained_variance    | 0.887       |
|    lagrangian_multiplier | 0.00106     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.55        |
|    n_updates             | 12640       |
|    policy_gradient_loss  | 0.00952     |
|    std                   | 0.304       |
|    value_loss            | 3.8         |
------------------------------------------
------------------------------------------
| avg_speed                | 1.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.8         |
| reward                   | -0.75045556 |
| rollout/                 |             |
|    ep_len_mean           | 67.7        |
|    ep_rew_mean           | -30         |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 41          |
|    time_elapsed          | 1223        |
|    total_timesteps       | 2592768     |
| train/                   |             |
|    approx_kl             | 0.028595015 |
|    clip_fraction         | 0.219       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.19        |
|    cost_value_loss       | 7.5         |
|    cost_values           | 2.19        |
|    entropy               | 0.19        |
|    entropy_loss          | 0.189       |
|    explained_variance    | 0.85        |
|    lagrangian_multiplier | 0.00164     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.55        |
|    n_updates             | 12650       |
|    policy_gradient_loss  | 0.00763     |
|    std                   | 0.303       |
|    value_loss            | 5.07        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.8         |
| reward                   | -0.7531159  |
| rollout/                 |             |
|    ep_len_mean           | 71.7        |
|    ep_rew_mean           | -31.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 42          |
|    time_elapsed          | 1253        |
|    total_timesteps       | 2594816     |
| train/                   |             |
|    approx_kl             | 0.029299866 |
|    clip_fraction         | 0.184       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.27        |
|    cost_value_loss       | 7.6         |
|    cost_values           | 2.14        |
|    entropy               | 0.194       |
|    entropy_loss          | 0.192       |
|    explained_variance    | 0.742       |
|    lagrangian_multiplier | 0.00101     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.99        |
|    n_updates             | 12660       |
|    policy_gradient_loss  | 0.000795    |
|    std                   | 0.303       |
|    value_loss            | 6.7         |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.7083866  |
| rollout/                 |             |
|    ep_len_mean           | 73.1        |
|    ep_rew_mean           | -31.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 43          |
|    time_elapsed          | 1282        |
|    total_timesteps       | 2596864     |
| train/                   |             |
|    approx_kl             | 0.016008072 |
|    clip_fraction         | 0.148       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.4         |
|    cost_value_loss       | 8.28        |
|    cost_values           | 2.11        |
|    entropy               | 0.193       |
|    entropy_loss          | 0.194       |
|    explained_variance    | 0.772       |
|    lagrangian_multiplier | 0.00125     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.56        |
|    n_updates             | 12670       |
|    policy_gradient_loss  | 0.00145     |
|    std                   | 0.303       |
|    value_loss            | 6.86        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.33461934 |
| rollout/                 |             |
|    ep_len_mean           | 73          |
|    ep_rew_mean           | -31.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 44          |
|    time_elapsed          | 1313        |
|    total_timesteps       | 2598912     |
| train/                   |             |
|    approx_kl             | 0.04030276  |
|    clip_fraction         | 0.163       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.45        |
|    cost_value_loss       | 9.32        |
|    cost_values           | 2.15        |
|    entropy               | 0.195       |
|    entropy_loss          | 0.193       |
|    explained_variance    | 0.821       |
|    lagrangian_multiplier | 0.00191     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.86        |
|    n_updates             | 12680       |
|    policy_gradient_loss  | -0.00105    |
|    std                   | 0.302       |
|    value_loss            | 5.83        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.6         |
| reward                   | -0.23453362 |
| rollout/                 |             |
|    ep_len_mean           | 66.3        |
|    ep_rew_mean           | -29.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 45          |
|    time_elapsed          | 1343        |
|    total_timesteps       | 2600960     |
| train/                   |             |
|    approx_kl             | 0.010883897 |
|    clip_fraction         | 0.14        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.25        |
|    cost_value_loss       | 7.48        |
|    cost_values           | 2.14        |
|    entropy               | 0.195       |
|    entropy_loss          | 0.195       |
|    explained_variance    | 0.833       |
|    lagrangian_multiplier | 0.0023      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.2         |
|    n_updates             | 12690       |
|    policy_gradient_loss  | 0.00189     |
|    std                   | 0.302       |
|    value_loss            | 5.67        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.8         |
| reward                   | -0.26528126 |
| rollout/                 |             |
|    ep_len_mean           | 68.2        |
|    ep_rew_mean           | -29.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 46          |
|    time_elapsed          | 1374        |
|    total_timesteps       | 2603008     |
| train/                   |             |
|    approx_kl             | 0.027934954 |
|    clip_fraction         | 0.187       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.92        |
|    cost_value_loss       | 6.14        |
|    cost_values           | 2.11        |
|    entropy               | 0.2         |
|    entropy_loss          | 0.198       |
|    explained_variance    | 0.898       |
|    lagrangian_multiplier | 0.000324    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.45        |
|    n_updates             | 12700       |
|    policy_gradient_loss  | 0.00181     |
|    std                   | 0.302       |
|    value_loss            | 3.62        |
------------------------------------------
------------------------------------------
| avg_speed                | 3           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3           |
| reward                   | -0.74295604 |
| rollout/                 |             |
|    ep_len_mean           | 66.3        |
|    ep_rew_mean           | -29.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 47          |
|    time_elapsed          | 1404        |
|    total_timesteps       | 2605056     |
| train/                   |             |
|    approx_kl             | 0.022936871 |
|    clip_fraction         | 0.154       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.28        |
|    cost_value_loss       | 7.8         |
|    cost_values           | 2.14        |
|    entropy               | 0.195       |
|    entropy_loss          | 0.199       |
|    explained_variance    | 0.89        |
|    lagrangian_multiplier | 0.00143     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.35        |
|    n_updates             | 12710       |
|    policy_gradient_loss  | 0.00368     |
|    std                   | 0.303       |
|    value_loss            | 3.99        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.6         |
| reward                   | -0.310288   |
| rollout/                 |             |
|    ep_len_mean           | 66.8        |
|    ep_rew_mean           | -29.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 48          |
|    time_elapsed          | 1435        |
|    total_timesteps       | 2607104     |
| train/                   |             |
|    approx_kl             | 0.027574396 |
|    clip_fraction         | 0.171       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.04        |
|    cost_value_loss       | 7.39        |
|    cost_values           | 2.13        |
|    entropy               | 0.197       |
|    entropy_loss          | 0.195       |
|    explained_variance    | 0.866       |
|    lagrangian_multiplier | 0.00166     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.55        |
|    n_updates             | 12720       |
|    policy_gradient_loss  | 0.00806     |
|    std                   | 0.303       |
|    value_loss            | 4.8         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.16886804 |
| rollout/                 |             |
|    ep_len_mean           | 64.9        |
|    ep_rew_mean           | -29.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 49          |
|    time_elapsed          | 1465        |
|    total_timesteps       | 2609152     |
| train/                   |             |
|    approx_kl             | 0.015095751 |
|    clip_fraction         | 0.192       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.3         |
|    cost_value_loss       | 8.28        |
|    cost_values           | 2.11        |
|    entropy               | 0.196       |
|    entropy_loss          | 0.197       |
|    explained_variance    | 0.855       |
|    lagrangian_multiplier | 0.00114     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.96        |
|    n_updates             | 12730       |
|    policy_gradient_loss  | 0.00688     |
|    std                   | 0.303       |
|    value_loss            | 5           |
------------------------------------------
Directory already exists: tests/PPOL_New/models/ent-coefficient-ppol/vlorgroe
------------------------------------
| avg_speed          | 3.8         |
| cost               | 0           |
| is_success         | 0           |
| max_speed          | 3.8         |
| reward             | -0.65068716 |
| rollout/           |             |
|    ep_len_mean     | 65.2        |
|    ep_rew_mean     | -29.1       |
| time/              |             |
|    fps             | 72          |
|    iterations      | 1           |
|    time_elapsed    | 28          |
|    total_timesteps | 2611200     |
------------------------------------
-----------------------------------------
| avg_speed                | 6          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 6          |
| reward                   | -0.2701506 |
| rollout/                 |            |
|    ep_len_mean           | 69.2       |
|    ep_rew_mean           | -30.1      |
| time/                    |            |
|    fps                   | 70         |
|    iterations            | 2          |
|    time_elapsed          | 58         |
|    total_timesteps       | 2613248    |
| train/                   |            |
|    approx_kl             | 0.01639233 |
|    clip_fraction         | 0.197      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.16       |
|    cost_value_loss       | 7.46       |
|    cost_values           | 2.15       |
|    entropy               | 0.186      |
|    entropy_loss          | 0.188      |
|    explained_variance    | 0.865      |
|    lagrangian_multiplier | 0.00087    |
|    learning_rate         | 0.0003     |
|    loss                  | 4.69       |
|    n_updates             | 12750      |
|    policy_gradient_loss  | 0.003      |
|    std                   | 0.304      |
|    value_loss            | 4.51       |
-----------------------------------------
------------------------------------------
| avg_speed                | 7           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7           |
| reward                   | -0.18933661 |
| rollout/                 |             |
|    ep_len_mean           | 68.4        |
|    ep_rew_mean           | -29.6       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 3           |
|    time_elapsed          | 87          |
|    total_timesteps       | 2615296     |
| train/                   |             |
|    approx_kl             | 0.01899923  |
|    clip_fraction         | 0.161       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.34        |
|    cost_value_loss       | 8.18        |
|    cost_values           | 2.15        |
|    entropy               | 0.188       |
|    entropy_loss          | 0.186       |
|    explained_variance    | 0.83        |
|    lagrangian_multiplier | 0.00288     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.08        |
|    n_updates             | 12760       |
|    policy_gradient_loss  | 0.00313     |
|    std                   | 0.304       |
|    value_loss            | 5.28        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.82899094 |
| rollout/                 |             |
|    ep_len_mean           | 65.8        |
|    ep_rew_mean           | -28.9       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 4           |
|    time_elapsed          | 117         |
|    total_timesteps       | 2617344     |
| train/                   |             |
|    approx_kl             | 0.014665701 |
|    clip_fraction         | 0.193       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.53        |
|    cost_value_loss       | 9.19        |
|    cost_values           | 2.14        |
|    entropy               | 0.181       |
|    entropy_loss          | 0.185       |
|    explained_variance    | 0.868       |
|    lagrangian_multiplier | 0.00188     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.29        |
|    n_updates             | 12770       |
|    policy_gradient_loss  | 0.00511     |
|    std                   | 0.306       |
|    value_loss            | 4.15        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.8         |
| reward                   | -0.17386086 |
| rollout/                 |             |
|    ep_len_mean           | 65.6        |
|    ep_rew_mean           | -28.8       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 5           |
|    time_elapsed          | 147         |
|    total_timesteps       | 2619392     |
| train/                   |             |
|    approx_kl             | 0.028567454 |
|    clip_fraction         | 0.196       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.05        |
|    cost_value_loss       | 7.02        |
|    cost_values           | 2.16        |
|    entropy               | 0.177       |
|    entropy_loss          | 0.179       |
|    explained_variance    | 0.916       |
|    lagrangian_multiplier | 0.000186    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.87        |
|    n_updates             | 12780       |
|    policy_gradient_loss  | 0.00529     |
|    std                   | 0.305       |
|    value_loss            | 3.35        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.3810706  |
| rollout/                 |             |
|    ep_len_mean           | 64.3        |
|    ep_rew_mean           | -28.9       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 6           |
|    time_elapsed          | 176         |
|    total_timesteps       | 2621440     |
| train/                   |             |
|    approx_kl             | 0.017431842 |
|    clip_fraction         | 0.17        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.53        |
|    cost_value_loss       | 9           |
|    cost_values           | 2.19        |
|    entropy               | 0.174       |
|    entropy_loss          | 0.176       |
|    explained_variance    | 0.888       |
|    lagrangian_multiplier | 0.00141     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.43        |
|    n_updates             | 12790       |
|    policy_gradient_loss  | 0.00615     |
|    std                   | 0.305       |
|    value_loss            | 3.61        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.59357274 |
| rollout/                 |             |
|    ep_len_mean           | 66.1        |
|    ep_rew_mean           | -29.5       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 7           |
|    time_elapsed          | 206         |
|    total_timesteps       | 2623488     |
| train/                   |             |
|    approx_kl             | 0.019627301 |
|    clip_fraction         | 0.171       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.13        |
|    cost_value_loss       | 7.65        |
|    cost_values           | 2.19        |
|    entropy               | 0.173       |
|    entropy_loss          | 0.173       |
|    explained_variance    | 0.895       |
|    lagrangian_multiplier | 0.000275    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.56        |
|    n_updates             | 12800       |
|    policy_gradient_loss  | 0.00592     |
|    std                   | 0.304       |
|    value_loss            | 4.04        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.79257303 |
| rollout/                 |             |
|    ep_len_mean           | 65          |
|    ep_rew_mean           | -29.3       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 8           |
|    time_elapsed          | 236         |
|    total_timesteps       | 2625536     |
| train/                   |             |
|    approx_kl             | 0.016620085 |
|    clip_fraction         | 0.143       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.45        |
|    cost_value_loss       | 8.75        |
|    cost_values           | 2.16        |
|    entropy               | 0.182       |
|    entropy_loss          | 0.176       |
|    explained_variance    | 0.841       |
|    lagrangian_multiplier | 0.0027      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.13        |
|    n_updates             | 12810       |
|    policy_gradient_loss  | 0.00378     |
|    std                   | 0.303       |
|    value_loss            | 5.39        |
------------------------------------------
-------------------------------------------
| avg_speed                | 6.32         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 6.32         |
| reward                   | -0.22640134  |
| rollout/                 |              |
|    ep_len_mean           | 64           |
|    ep_rew_mean           | -28.7        |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 9            |
|    time_elapsed          | 266          |
|    total_timesteps       | 2627584      |
| train/                   |              |
|    approx_kl             | 0.0146667715 |
|    clip_fraction         | 0.21         |
|    clip_range            | 0.2          |
|    cost_returns          | 4.17         |
|    cost_value_loss       | 7.57         |
|    cost_values           | 2.15         |
|    entropy               | 0.185        |
|    entropy_loss          | 0.185        |
|    explained_variance    | 0.893        |
|    lagrangian_multiplier | 0.00304      |
|    learning_rate         | 0.0003       |
|    loss                  | 3.66         |
|    n_updates             | 12820        |
|    policy_gradient_loss  | 0.00937      |
|    std                   | 0.303        |
|    value_loss            | 3.98         |
-------------------------------------------
------------------------------------------
| avg_speed                | 7.2         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.2         |
| reward                   | -0.34945607 |
| rollout/                 |             |
|    ep_len_mean           | 64.8        |
|    ep_rew_mean           | -28.8       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 10          |
|    time_elapsed          | 295         |
|    total_timesteps       | 2629632     |
| train/                   |             |
|    approx_kl             | 0.03025823  |
|    clip_fraction         | 0.152       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.49        |
|    cost_value_loss       | 9.72        |
|    cost_values           | 2.17        |
|    entropy               | 0.176       |
|    entropy_loss          | 0.181       |
|    explained_variance    | 0.865       |
|    lagrangian_multiplier | 0.0016      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.77        |
|    n_updates             | 12830       |
|    policy_gradient_loss  | 0.00151     |
|    std                   | 0.304       |
|    value_loss            | 4.67        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.27696562 |
| rollout/                 |             |
|    ep_len_mean           | 65.2        |
|    ep_rew_mean           | -29.1       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 11          |
|    time_elapsed          | 325         |
|    total_timesteps       | 2631680     |
| train/                   |             |
|    approx_kl             | 0.02045545  |
|    clip_fraction         | 0.18        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.43        |
|    cost_value_loss       | 8.76        |
|    cost_values           | 2.21        |
|    entropy               | 0.177       |
|    entropy_loss          | 0.175       |
|    explained_variance    | 0.897       |
|    lagrangian_multiplier | 0.00178     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.31        |
|    n_updates             | 12840       |
|    policy_gradient_loss  | 0.00442     |
|    std                   | 0.304       |
|    value_loss            | 3.67        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.19903599 |
| rollout/                 |             |
|    ep_len_mean           | 65.9        |
|    ep_rew_mean           | -29.6       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 12          |
|    time_elapsed          | 355         |
|    total_timesteps       | 2633728     |
| train/                   |             |
|    approx_kl             | 0.061275333 |
|    clip_fraction         | 0.176       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.55        |
|    cost_value_loss       | 9.12        |
|    cost_values           | 2.17        |
|    entropy               | 0.182       |
|    entropy_loss          | 0.18        |
|    explained_variance    | 0.844       |
|    lagrangian_multiplier | 0.00245     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.41        |
|    n_updates             | 12850       |
|    policy_gradient_loss  | 0.00294     |
|    std                   | 0.304       |
|    value_loss            | 5.28        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.6         |
| reward                   | -0.6847641  |
| rollout/                 |             |
|    ep_len_mean           | 64.5        |
|    ep_rew_mean           | -29.6       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 13          |
|    time_elapsed          | 385         |
|    total_timesteps       | 2635776     |
| train/                   |             |
|    approx_kl             | 0.009307312 |
|    clip_fraction         | 0.159       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.17        |
|    cost_value_loss       | 7.71        |
|    cost_values           | 2.13        |
|    entropy               | 0.183       |
|    entropy_loss          | 0.182       |
|    explained_variance    | 0.835       |
|    lagrangian_multiplier | 0.00347     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.9         |
|    n_updates             | 12860       |
|    policy_gradient_loss  | 0.00241     |
|    std                   | 0.304       |
|    value_loss            | 5.95        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.31994566 |
| rollout/                 |             |
|    ep_len_mean           | 62.1        |
|    ep_rew_mean           | -28.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 14          |
|    time_elapsed          | 416         |
|    total_timesteps       | 2637824     |
| train/                   |             |
|    approx_kl             | 0.017723257 |
|    clip_fraction         | 0.194       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.04        |
|    cost_value_loss       | 7.27        |
|    cost_values           | 2.15        |
|    entropy               | 0.182       |
|    entropy_loss          | 0.183       |
|    explained_variance    | 0.883       |
|    lagrangian_multiplier | 3.98e-05    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.86        |
|    n_updates             | 12870       |
|    policy_gradient_loss  | 0.006       |
|    std                   | 0.304       |
|    value_loss            | 4.46        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.2         |
| reward                   | -0.8783692  |
| rollout/                 |             |
|    ep_len_mean           | 62.2        |
|    ep_rew_mean           | -28.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 15          |
|    time_elapsed          | 447         |
|    total_timesteps       | 2639872     |
| train/                   |             |
|    approx_kl             | 0.018354181 |
|    clip_fraction         | 0.209       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.2         |
|    cost_value_loss       | 7.39        |
|    cost_values           | 2.16        |
|    entropy               | 0.184       |
|    entropy_loss          | 0.183       |
|    explained_variance    | 0.885       |
|    lagrangian_multiplier | 0.00111     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.37        |
|    n_updates             | 12880       |
|    policy_gradient_loss  | 0.0102      |
|    std                   | 0.304       |
|    value_loss            | 3.98        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3351631  |
| rollout/                 |             |
|    ep_len_mean           | 63.9        |
|    ep_rew_mean           | -28.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 16          |
|    time_elapsed          | 476         |
|    total_timesteps       | 2641920     |
| train/                   |             |
|    approx_kl             | 0.023657735 |
|    clip_fraction         | 0.223       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.29        |
|    cost_value_loss       | 7.82        |
|    cost_values           | 2.17        |
|    entropy               | 0.186       |
|    entropy_loss          | 0.185       |
|    explained_variance    | 0.882       |
|    lagrangian_multiplier | 0.000529    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.19        |
|    n_updates             | 12890       |
|    policy_gradient_loss  | 0.00465     |
|    std                   | 0.304       |
|    value_loss            | 4.32        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.36784524 |
| rollout/                 |             |
|    ep_len_mean           | 66.1        |
|    ep_rew_mean           | -29.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 17          |
|    time_elapsed          | 506         |
|    total_timesteps       | 2643968     |
| train/                   |             |
|    approx_kl             | 0.02145352  |
|    clip_fraction         | 0.175       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.24        |
|    cost_value_loss       | 7.76        |
|    cost_values           | 2.18        |
|    entropy               | 0.188       |
|    entropy_loss          | 0.187       |
|    explained_variance    | 0.863       |
|    lagrangian_multiplier | 0.00111     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.82        |
|    n_updates             | 12900       |
|    policy_gradient_loss  | 0.00718     |
|    std                   | 0.303       |
|    value_loss            | 4.49        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.02        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.02        |
| reward                   | -0.21332605 |
| rollout/                 |             |
|    ep_len_mean           | 67.5        |
|    ep_rew_mean           | -30.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 18          |
|    time_elapsed          | 535         |
|    total_timesteps       | 2646016     |
| train/                   |             |
|    approx_kl             | 0.02069389  |
|    clip_fraction         | 0.162       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.5         |
|    cost_value_loss       | 9.47        |
|    cost_values           | 2.19        |
|    entropy               | 0.191       |
|    entropy_loss          | 0.189       |
|    explained_variance    | 0.874       |
|    lagrangian_multiplier | 0.000755    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.31        |
|    n_updates             | 12910       |
|    policy_gradient_loss  | 0.00759     |
|    std                   | 0.303       |
|    value_loss            | 4.33        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.35195443 |
| rollout/                 |             |
|    ep_len_mean           | 66          |
|    ep_rew_mean           | -29.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 19          |
|    time_elapsed          | 565         |
|    total_timesteps       | 2648064     |
| train/                   |             |
|    approx_kl             | 0.044735778 |
|    clip_fraction         | 0.15        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.18        |
|    cost_value_loss       | 7.62        |
|    cost_values           | 2.18        |
|    entropy               | 0.193       |
|    entropy_loss          | 0.193       |
|    explained_variance    | 0.794       |
|    lagrangian_multiplier | 0.00211     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.59        |
|    n_updates             | 12920       |
|    policy_gradient_loss  | 0.0032      |
|    std                   | 0.302       |
|    value_loss            | 6.53        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.23967084 |
| rollout/                 |             |
|    ep_len_mean           | 67.2        |
|    ep_rew_mean           | -30.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 20          |
|    time_elapsed          | 594         |
|    total_timesteps       | 2650112     |
| train/                   |             |
|    approx_kl             | 0.013452573 |
|    clip_fraction         | 0.2         |
|    clip_range            | 0.2         |
|    cost_returns          | 4.14        |
|    cost_value_loss       | 8.13        |
|    cost_values           | 2.17        |
|    entropy               | 0.201       |
|    entropy_loss          | 0.196       |
|    explained_variance    | 0.836       |
|    lagrangian_multiplier | 0.000653    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.75        |
|    n_updates             | 12930       |
|    policy_gradient_loss  | 0.00331     |
|    std                   | 0.301       |
|    value_loss            | 6.06        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.92        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.92        |
| reward                   | -0.38507897 |
| rollout/                 |             |
|    ep_len_mean           | 67.7        |
|    ep_rew_mean           | -30.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 21          |
|    time_elapsed          | 624         |
|    total_timesteps       | 2652160     |
| train/                   |             |
|    approx_kl             | 0.012892295 |
|    clip_fraction         | 0.2         |
|    clip_range            | 0.2         |
|    cost_returns          | 4.14        |
|    cost_value_loss       | 7.76        |
|    cost_values           | 2.15        |
|    entropy               | 0.206       |
|    entropy_loss          | 0.204       |
|    explained_variance    | 0.807       |
|    lagrangian_multiplier | 0.00108     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.74        |
|    n_updates             | 12940       |
|    policy_gradient_loss  | 0.00593     |
|    std                   | 0.301       |
|    value_loss            | 6.87        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.23602796 |
| rollout/                 |             |
|    ep_len_mean           | 67.3        |
|    ep_rew_mean           | -29.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 22          |
|    time_elapsed          | 654         |
|    total_timesteps       | 2654208     |
| train/                   |             |
|    approx_kl             | 0.017237304 |
|    clip_fraction         | 0.203       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.33        |
|    cost_value_loss       | 8.57        |
|    cost_values           | 2.14        |
|    entropy               | 0.208       |
|    entropy_loss          | 0.207       |
|    explained_variance    | 0.862       |
|    lagrangian_multiplier | 0.000686    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.59        |
|    n_updates             | 12950       |
|    policy_gradient_loss  | 0.00909     |
|    std                   | 0.301       |
|    value_loss            | 5.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.8177243  |
| rollout/                 |             |
|    ep_len_mean           | 65.5        |
|    ep_rew_mean           | -28.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 23          |
|    time_elapsed          | 684         |
|    total_timesteps       | 2656256     |
| train/                   |             |
|    approx_kl             | 0.009061798 |
|    clip_fraction         | 0.146       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.23        |
|    cost_value_loss       | 7.89        |
|    cost_values           | 2.11        |
|    entropy               | 0.209       |
|    entropy_loss          | 0.208       |
|    explained_variance    | 0.844       |
|    lagrangian_multiplier | 0.00151     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.55        |
|    n_updates             | 12960       |
|    policy_gradient_loss  | 0.00137     |
|    std                   | 0.301       |
|    value_loss            | 5.23        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.8         |
| reward                   | -0.18115115 |
| rollout/                 |             |
|    ep_len_mean           | 68.4        |
|    ep_rew_mean           | -29.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 24          |
|    time_elapsed          | 713         |
|    total_timesteps       | 2658304     |
| train/                   |             |
|    approx_kl             | 0.031332508 |
|    clip_fraction         | 0.158       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.43        |
|    cost_value_loss       | 9.13        |
|    cost_values           | 2.15        |
|    entropy               | 0.216       |
|    entropy_loss          | 0.212       |
|    explained_variance    | 0.866       |
|    lagrangian_multiplier | 0.000955    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.95        |
|    n_updates             | 12970       |
|    policy_gradient_loss  | 0.00586     |
|    std                   | 0.301       |
|    value_loss            | 3.89        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.17365468 |
| rollout/                 |             |
|    ep_len_mean           | 70          |
|    ep_rew_mean           | -30         |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 25          |
|    time_elapsed          | 743         |
|    total_timesteps       | 2660352     |
| train/                   |             |
|    approx_kl             | 0.03129698  |
|    clip_fraction         | 0.215       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.49        |
|    cost_value_loss       | 9.11        |
|    cost_values           | 2.19        |
|    entropy               | 0.204       |
|    entropy_loss          | 0.211       |
|    explained_variance    | 0.891       |
|    lagrangian_multiplier | 0.00166     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.49        |
|    n_updates             | 12980       |
|    policy_gradient_loss  | 0.012       |
|    std                   | 0.303       |
|    value_loss            | 3.86        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.27803484 |
| rollout/                 |             |
|    ep_len_mean           | 71.8        |
|    ep_rew_mean           | -30.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 26          |
|    time_elapsed          | 772         |
|    total_timesteps       | 2662400     |
| train/                   |             |
|    approx_kl             | 0.016134437 |
|    clip_fraction         | 0.177       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.45        |
|    cost_value_loss       | 8.72        |
|    cost_values           | 2.21        |
|    entropy               | 0.198       |
|    entropy_loss          | 0.2         |
|    explained_variance    | 0.894       |
|    lagrangian_multiplier | 0.00221     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.09        |
|    n_updates             | 12990       |
|    policy_gradient_loss  | 0.00456     |
|    std                   | 0.304       |
|    value_loss            | 3.61        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.23009212 |
| rollout/                 |             |
|    ep_len_mean           | 68.7        |
|    ep_rew_mean           | -29.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 27          |
|    time_elapsed          | 802         |
|    total_timesteps       | 2664448     |
| train/                   |             |
|    approx_kl             | 0.018703893 |
|    clip_fraction         | 0.157       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.68        |
|    cost_value_loss       | 9.1         |
|    cost_values           | 2.24        |
|    entropy               | 0.197       |
|    entropy_loss          | 0.197       |
|    explained_variance    | 0.842       |
|    lagrangian_multiplier | 0.00466     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.68        |
|    n_updates             | 13000       |
|    policy_gradient_loss  | 0.00633     |
|    std                   | 0.303       |
|    value_loss            | 5.03        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.325781   |
| rollout/                 |             |
|    ep_len_mean           | 65.7        |
|    ep_rew_mean           | -29.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 28          |
|    time_elapsed          | 833         |
|    total_timesteps       | 2666496     |
| train/                   |             |
|    approx_kl             | 0.021135656 |
|    clip_fraction         | 0.215       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.28        |
|    cost_value_loss       | 7.98        |
|    cost_values           | 2.17        |
|    entropy               | 0.195       |
|    entropy_loss          | 0.196       |
|    explained_variance    | 0.876       |
|    lagrangian_multiplier | 0.00136     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.75        |
|    n_updates             | 13010       |
|    policy_gradient_loss  | 0.00886     |
|    std                   | 0.303       |
|    value_loss            | 4.88        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.4         |
| reward                   | -0.8325158  |
| rollout/                 |             |
|    ep_len_mean           | 66.2        |
|    ep_rew_mean           | -29.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 29          |
|    time_elapsed          | 863         |
|    total_timesteps       | 2668544     |
| train/                   |             |
|    approx_kl             | 0.009427582 |
|    clip_fraction         | 0.19        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.15        |
|    cost_value_loss       | 7.39        |
|    cost_values           | 2.14        |
|    entropy               | 0.192       |
|    entropy_loss          | 0.194       |
|    explained_variance    | 0.901       |
|    lagrangian_multiplier | 0.000472    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.8         |
|    n_updates             | 13020       |
|    policy_gradient_loss  | 0.00582     |
|    std                   | 0.304       |
|    value_loss            | 3.75        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.90352005 |
| rollout/                 |             |
|    ep_len_mean           | 65.4        |
|    ep_rew_mean           | -29.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 30          |
|    time_elapsed          | 894         |
|    total_timesteps       | 2670592     |
| train/                   |             |
|    approx_kl             | 0.015308231 |
|    clip_fraction         | 0.196       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.17        |
|    cost_value_loss       | 7.59        |
|    cost_values           | 2.18        |
|    entropy               | 0.184       |
|    entropy_loss          | 0.189       |
|    explained_variance    | 0.835       |
|    lagrangian_multiplier | 0.000525    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.14        |
|    n_updates             | 13030       |
|    policy_gradient_loss  | 0.00558     |
|    std                   | 0.306       |
|    value_loss            | 5.02        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8.02       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.02       |
| reward                   | -0.3589626 |
| rollout/                 |            |
|    ep_len_mean           | 66.1       |
|    ep_rew_mean           | -29.4      |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 31         |
|    time_elapsed          | 924        |
|    total_timesteps       | 2672640    |
| train/                   |            |
|    approx_kl             | 0.02797113 |
|    clip_fraction         | 0.188      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.32       |
|    cost_value_loss       | 7.73       |
|    cost_values           | 2.2        |
|    entropy               | 0.187      |
|    entropy_loss          | 0.184      |
|    explained_variance    | 0.872      |
|    lagrangian_multiplier | 0.00259    |
|    learning_rate         | 0.0003     |
|    loss                  | 3.9        |
|    n_updates             | 13040      |
|    policy_gradient_loss  | 0.00883    |
|    std                   | 0.306      |
|    value_loss            | 4.55       |
-----------------------------------------
------------------------------------------
| avg_speed                | 7           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7           |
| reward                   | -0.34293196 |
| rollout/                 |             |
|    ep_len_mean           | 62.7        |
|    ep_rew_mean           | -28.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 32          |
|    time_elapsed          | 953         |
|    total_timesteps       | 2674688     |
| train/                   |             |
|    approx_kl             | 0.017735187 |
|    clip_fraction         | 0.142       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.34        |
|    cost_value_loss       | 8.57        |
|    cost_values           | 2.22        |
|    entropy               | 0.187       |
|    entropy_loss          | 0.187       |
|    explained_variance    | 0.894       |
|    lagrangian_multiplier | 0.00072     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.72        |
|    n_updates             | 13050       |
|    policy_gradient_loss  | -0.000263   |
|    std                   | 0.306       |
|    value_loss            | 3.7         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.25604835 |
| rollout/                 |             |
|    ep_len_mean           | 62          |
|    ep_rew_mean           | -28.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 33          |
|    time_elapsed          | 982         |
|    total_timesteps       | 2676736     |
| train/                   |             |
|    approx_kl             | 0.040013976 |
|    clip_fraction         | 0.224       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.11        |
|    cost_value_loss       | 7.3         |
|    cost_values           | 2.23        |
|    entropy               | 0.18        |
|    entropy_loss          | 0.184       |
|    explained_variance    | 0.915       |
|    lagrangian_multiplier | 0.00111     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.05        |
|    n_updates             | 13060       |
|    policy_gradient_loss  | 0.00213     |
|    std                   | 0.306       |
|    value_loss            | 3.07        |
------------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.69274575 |
| rollout/                 |             |
|    ep_len_mean           | 64.4        |
|    ep_rew_mean           | -28.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 34          |
|    time_elapsed          | 1012        |
|    total_timesteps       | 2678784     |
| train/                   |             |
|    approx_kl             | 0.023696048 |
|    clip_fraction         | 0.158       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.13        |
|    cost_value_loss       | 6.47        |
|    cost_values           | 2.24        |
|    entropy               | 0.186       |
|    entropy_loss          | 0.181       |
|    explained_variance    | 0.91        |
|    lagrangian_multiplier | 0.00144     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.76        |
|    n_updates             | 13070       |
|    policy_gradient_loss  | 0.00469     |
|    std                   | 0.305       |
|    value_loss            | 3.47        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.71        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.71        |
| reward                   | -0.25401282 |
| rollout/                 |             |
|    ep_len_mean           | 65.9        |
|    ep_rew_mean           | -29.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 35          |
|    time_elapsed          | 1040        |
|    total_timesteps       | 2680832     |
| train/                   |             |
|    approx_kl             | 0.034106914 |
|    clip_fraction         | 0.218       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.47        |
|    cost_value_loss       | 8.55        |
|    cost_values           | 2.24        |
|    entropy               | 0.19        |
|    entropy_loss          | 0.189       |
|    explained_variance    | 0.894       |
|    lagrangian_multiplier | 0.00136     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.56        |
|    n_updates             | 13080       |
|    policy_gradient_loss  | 0.00894     |
|    std                   | 0.304       |
|    value_loss            | 3.69        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.37563616 |
| rollout/                 |             |
|    ep_len_mean           | 67.7        |
|    ep_rew_mean           | -29.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 36          |
|    time_elapsed          | 1069        |
|    total_timesteps       | 2682880     |
| train/                   |             |
|    approx_kl             | 0.044798538 |
|    clip_fraction         | 0.196       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.41        |
|    cost_value_loss       | 8.19        |
|    cost_values           | 2.25        |
|    entropy               | 0.191       |
|    entropy_loss          | 0.191       |
|    explained_variance    | 0.812       |
|    lagrangian_multiplier | 0.00175     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.77        |
|    n_updates             | 13090       |
|    policy_gradient_loss  | 0.00502     |
|    std                   | 0.302       |
|    value_loss            | 5.04        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.4299609  |
| rollout/                 |             |
|    ep_len_mean           | 66.7        |
|    ep_rew_mean           | -29.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 37          |
|    time_elapsed          | 1098        |
|    total_timesteps       | 2684928     |
| train/                   |             |
|    approx_kl             | 0.023986004 |
|    clip_fraction         | 0.178       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.55        |
|    cost_value_loss       | 9.27        |
|    cost_values           | 2.24        |
|    entropy               | 0.187       |
|    entropy_loss          | 0.19        |
|    explained_variance    | 0.842       |
|    lagrangian_multiplier | 0.00174     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.94        |
|    n_updates             | 13100       |
|    policy_gradient_loss  | 0.00222     |
|    std                   | 0.303       |
|    value_loss            | 5.29        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.40213212 |
| rollout/                 |             |
|    ep_len_mean           | 65.5        |
|    ep_rew_mean           | -29         |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 38          |
|    time_elapsed          | 1128        |
|    total_timesteps       | 2686976     |
| train/                   |             |
|    approx_kl             | 0.018674336 |
|    clip_fraction         | 0.214       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.08        |
|    cost_value_loss       | 6.62        |
|    cost_values           | 2.18        |
|    entropy               | 0.184       |
|    entropy_loss          | 0.185       |
|    explained_variance    | 0.832       |
|    lagrangian_multiplier | 0.00201     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.05        |
|    n_updates             | 13110       |
|    policy_gradient_loss  | 0.00914     |
|    std                   | 0.303       |
|    value_loss            | 5.59        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.37037307 |
| rollout/                 |             |
|    ep_len_mean           | 65.8        |
|    ep_rew_mean           | -29.3       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 39          |
|    time_elapsed          | 1157        |
|    total_timesteps       | 2689024     |
| train/                   |             |
|    approx_kl             | 0.01806791  |
|    clip_fraction         | 0.179       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.45        |
|    cost_value_loss       | 9.03        |
|    cost_values           | 2.14        |
|    entropy               | 0.185       |
|    entropy_loss          | 0.184       |
|    explained_variance    | 0.842       |
|    lagrangian_multiplier | 0.000488    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.88        |
|    n_updates             | 13120       |
|    policy_gradient_loss  | 0.000449    |
|    std                   | 0.302       |
|    value_loss            | 5.31        |
------------------------------------------
-----------------------------------------
| avg_speed                | 4          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 4          |
| reward                   | -0.6523294 |
| rollout/                 |            |
|    ep_len_mean           | 69.2       |
|    ep_rew_mean           | -30.2      |
| time/                    |            |
|    fps                   | 69         |
|    iterations            | 40         |
|    time_elapsed          | 1186       |
|    total_timesteps       | 2691072    |
| train/                   |            |
|    approx_kl             | 0.03720986 |
|    clip_fraction         | 0.175      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.15       |
|    cost_value_loss       | 6.98       |
|    cost_values           | 2.19       |
|    entropy               | 0.188      |
|    entropy_loss          | 0.187      |
|    explained_variance    | 0.913      |
|    lagrangian_multiplier | 0.00125    |
|    learning_rate         | 0.0003     |
|    loss                  | 4.07       |
|    n_updates             | 13130      |
|    policy_gradient_loss  | 0.00552    |
|    std                   | 0.302      |
|    value_loss            | 3.29       |
-----------------------------------------
-----------------------------------------
| avg_speed                | 1          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 1          |
| reward                   | -0.5296473 |
| rollout/                 |            |
|    ep_len_mean           | 70.8       |
|    ep_rew_mean           | -30.9      |
| time/                    |            |
|    fps                   | 69         |
|    iterations            | 41         |
|    time_elapsed          | 1216       |
|    total_timesteps       | 2693120    |
| train/                   |            |
|    approx_kl             | 0.02422192 |
|    clip_fraction         | 0.204      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.35       |
|    cost_value_loss       | 8.2        |
|    cost_values           | 2.2        |
|    entropy               | 0.187      |
|    entropy_loss          | 0.188      |
|    explained_variance    | 0.87       |
|    lagrangian_multiplier | 0.00183    |
|    learning_rate         | 0.0003     |
|    loss                  | 4.47       |
|    n_updates             | 13140      |
|    policy_gradient_loss  | 0.0126     |
|    std                   | 0.302      |
|    value_loss            | 4.66       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.42181605 |
| rollout/                 |             |
|    ep_len_mean           | 69.9        |
|    ep_rew_mean           | -30.2       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 42          |
|    time_elapsed          | 1245        |
|    total_timesteps       | 2695168     |
| train/                   |             |
|    approx_kl             | 0.019298742 |
|    clip_fraction         | 0.162       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.48        |
|    cost_value_loss       | 9.12        |
|    cost_values           | 2.22        |
|    entropy               | 0.192       |
|    entropy_loss          | 0.188       |
|    explained_variance    | 0.885       |
|    lagrangian_multiplier | 0.00206     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.45        |
|    n_updates             | 13150       |
|    policy_gradient_loss  | 0.00845     |
|    std                   | 0.302       |
|    value_loss            | 4.19        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.514529   |
| rollout/                 |             |
|    ep_len_mean           | 69.9        |
|    ep_rew_mean           | -30.5       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 43          |
|    time_elapsed          | 1275        |
|    total_timesteps       | 2697216     |
| train/                   |             |
|    approx_kl             | 0.021492139 |
|    clip_fraction         | 0.248       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.52        |
|    cost_value_loss       | 8.73        |
|    cost_values           | 2.24        |
|    entropy               | 0.189       |
|    entropy_loss          | 0.191       |
|    explained_variance    | 0.905       |
|    lagrangian_multiplier | 0.00311     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.84        |
|    n_updates             | 13160       |
|    policy_gradient_loss  | 0.00538     |
|    std                   | 0.302       |
|    value_loss            | 3.4         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.20016031 |
| rollout/                 |             |
|    ep_len_mean           | 71.5        |
|    ep_rew_mean           | -31.2       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 44          |
|    time_elapsed          | 1305        |
|    total_timesteps       | 2699264     |
| train/                   |             |
|    approx_kl             | 0.027650066 |
|    clip_fraction         | 0.191       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.31        |
|    cost_value_loss       | 7.93        |
|    cost_values           | 2.23        |
|    entropy               | 0.189       |
|    entropy_loss          | 0.189       |
|    explained_variance    | 0.879       |
|    lagrangian_multiplier | 0.00201     |
|    learning_rate         | 0.0003      |
|    loss                  | 4           |
|    n_updates             | 13170       |
|    policy_gradient_loss  | 0.00927     |
|    std                   | 0.302       |
|    value_loss            | 4.04        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.19033666 |
| rollout/                 |             |
|    ep_len_mean           | 72.5        |
|    ep_rew_mean           | -31.1       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 45          |
|    time_elapsed          | 1334        |
|    total_timesteps       | 2701312     |
| train/                   |             |
|    approx_kl             | 0.018870672 |
|    clip_fraction         | 0.153       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.39        |
|    cost_value_loss       | 8.18        |
|    cost_values           | 2.24        |
|    entropy               | 0.19        |
|    entropy_loss          | 0.19        |
|    explained_variance    | 0.857       |
|    lagrangian_multiplier | 0.00181     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.4         |
|    n_updates             | 13180       |
|    policy_gradient_loss  | 0.000172    |
|    std                   | 0.301       |
|    value_loss            | 4.99        |
------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.8720816  |
| rollout/                 |             |
|    ep_len_mean           | 70.9        |
|    ep_rew_mean           | -30.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 46          |
|    time_elapsed          | 1365        |
|    total_timesteps       | 2703360     |
| train/                   |             |
|    approx_kl             | 0.041644085 |
|    clip_fraction         | 0.218       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.42        |
|    cost_value_loss       | 8.62        |
|    cost_values           | 2.25        |
|    entropy               | 0.19        |
|    entropy_loss          | 0.19        |
|    explained_variance    | 0.866       |
|    lagrangian_multiplier | 0.000919    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.34        |
|    n_updates             | 13190       |
|    policy_gradient_loss  | 0.00597     |
|    std                   | 0.3         |
|    value_loss            | 4.31        |
------------------------------------------
-----------------------------------------
| avg_speed                | 2          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 2          |
| reward                   | -0.7629622 |
| rollout/                 |            |
|    ep_len_mean           | 70.1       |
|    ep_rew_mean           | -30.8      |
| time/                    |            |
|    fps                   | 69         |
|    iterations            | 47         |
|    time_elapsed          | 1394       |
|    total_timesteps       | 2705408    |
| train/                   |            |
|    approx_kl             | 0.05870889 |
|    clip_fraction         | 0.199      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.78       |
|    cost_value_loss       | 6.42       |
|    cost_values           | 2.2        |
|    entropy               | 0.184      |
|    entropy_loss          | 0.188      |
|    explained_variance    | 0.909      |
|    lagrangian_multiplier | 0.000634   |
|    learning_rate         | 0.0003     |
|    loss                  | 4.26       |
|    n_updates             | 13200      |
|    policy_gradient_loss  | 0.00966    |
|    std                   | 0.301      |
|    value_loss            | 3.24       |
-----------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.60268235 |
| rollout/                 |             |
|    ep_len_mean           | 66.9        |
|    ep_rew_mean           | -29.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 48          |
|    time_elapsed          | 1424        |
|    total_timesteps       | 2707456     |
| train/                   |             |
|    approx_kl             | 0.03433499  |
|    clip_fraction         | 0.159       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.44        |
|    cost_value_loss       | 8.53        |
|    cost_values           | 2.23        |
|    entropy               | 0.18        |
|    entropy_loss          | 0.181       |
|    explained_variance    | 0.863       |
|    lagrangian_multiplier | 0.00135     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.94        |
|    n_updates             | 13210       |
|    policy_gradient_loss  | 0.0042      |
|    std                   | 0.301       |
|    value_loss            | 5.02        |
------------------------------------------
------------------------------------------
| avg_speed                | 5           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5           |
| reward                   | -0.6284881  |
| rollout/                 |             |
|    ep_len_mean           | 70.4        |
|    ep_rew_mean           | -30.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 49          |
|    time_elapsed          | 1454        |
|    total_timesteps       | 2709504     |
| train/                   |             |
|    approx_kl             | 0.015407103 |
|    clip_fraction         | 0.175       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.28        |
|    cost_value_loss       | 7.22        |
|    cost_values           | 2.25        |
|    entropy               | 0.182       |
|    entropy_loss          | 0.18        |
|    explained_variance    | 0.878       |
|    lagrangian_multiplier | 0.00104     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.4         |
|    n_updates             | 13220       |
|    policy_gradient_loss  | 0.0113      |
|    std                   | 0.301       |
|    value_loss            | 3.87        |
------------------------------------------
-----------------------------------
| avg_speed          | 8          |
| cost               | 0          |
| is_success         | 0          |
| max_speed          | 8          |
| reward             | -0.3083666 |
| rollout/           |            |
|    ep_len_mean     | 68.7       |
|    ep_rew_mean     | -30        |
| time/              |            |
|    fps             | 74         |
|    iterations      | 1          |
|    time_elapsed    | 27         |
|    total_timesteps | 2711552    |
-----------------------------------
------------------------------------------
| avg_speed                | 5           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5           |
| reward                   | -0.49993762 |
| rollout/                 |             |
|    ep_len_mean           | 68.4        |
|    ep_rew_mean           | -29.9       |
| time/                    |             |
|    fps                   | 72          |
|    iterations            | 2           |
|    time_elapsed          | 56          |
|    total_timesteps       | 2713600     |
| train/                   |             |
|    approx_kl             | 0.02675315  |
|    clip_fraction         | 0.179       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.47        |
|    cost_value_loss       | 8.46        |
|    cost_values           | 2.27        |
|    entropy               | 0.176       |
|    entropy_loss          | 0.177       |
|    explained_variance    | 0.874       |
|    lagrangian_multiplier | 0.000654    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.63        |
|    n_updates             | 13240       |
|    policy_gradient_loss  | 0.00602     |
|    std                   | 0.301       |
|    value_loss            | 4.76        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.79519093 |
| rollout/                 |             |
|    ep_len_mean           | 64.5        |
|    ep_rew_mean           | -29.2       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 3           |
|    time_elapsed          | 86          |
|    total_timesteps       | 2715648     |
| train/                   |             |
|    approx_kl             | 0.02085679  |
|    clip_fraction         | 0.194       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.19        |
|    cost_value_loss       | 7.15        |
|    cost_values           | 2.26        |
|    entropy               | 0.177       |
|    entropy_loss          | 0.176       |
|    explained_variance    | 0.907       |
|    lagrangian_multiplier | 0.00234     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.57        |
|    n_updates             | 13250       |
|    policy_gradient_loss  | 0.01        |
|    std                   | 0.301       |
|    value_loss            | 3.64        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.17411049 |
| rollout/                 |             |
|    ep_len_mean           | 63.9        |
|    ep_rew_mean           | -28.7       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 4           |
|    time_elapsed          | 115         |
|    total_timesteps       | 2717696     |
| train/                   |             |
|    approx_kl             | 0.008315114 |
|    clip_fraction         | 0.126       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.21        |
|    cost_value_loss       | 7.36        |
|    cost_values           | 2.24        |
|    entropy               | 0.172       |
|    entropy_loss          | 0.175       |
|    explained_variance    | 0.86        |
|    lagrangian_multiplier | 0.00199     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.04        |
|    n_updates             | 13260       |
|    policy_gradient_loss  | -0.00128    |
|    std                   | 0.302       |
|    value_loss            | 5.05        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.31363362 |
| rollout/                 |             |
|    ep_len_mean           | 67.6        |
|    ep_rew_mean           | -29.9       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 5           |
|    time_elapsed          | 144         |
|    total_timesteps       | 2719744     |
| train/                   |             |
|    approx_kl             | 0.017415352 |
|    clip_fraction         | 0.212       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.56        |
|    cost_value_loss       | 9.52        |
|    cost_values           | 2.26        |
|    entropy               | 0.166       |
|    entropy_loss          | 0.169       |
|    explained_variance    | 0.878       |
|    lagrangian_multiplier | 0.00215     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.62        |
|    n_updates             | 13270       |
|    policy_gradient_loss  | 0.00585     |
|    std                   | 0.302       |
|    value_loss            | 4.05        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.23705716 |
| rollout/                 |             |
|    ep_len_mean           | 68.9        |
|    ep_rew_mean           | -30.4       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 6           |
|    time_elapsed          | 174         |
|    total_timesteps       | 2721792     |
| train/                   |             |
|    approx_kl             | 0.015925705 |
|    clip_fraction         | 0.15        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.7         |
|    cost_value_loss       | 9.25        |
|    cost_values           | 2.25        |
|    entropy               | 0.163       |
|    entropy_loss          | 0.164       |
|    explained_variance    | 0.857       |
|    lagrangian_multiplier | 0.00256     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.25        |
|    n_updates             | 13280       |
|    policy_gradient_loss  | 0.00407     |
|    std                   | 0.303       |
|    value_loss            | 4.41        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.31994087 |
| rollout/                 |             |
|    ep_len_mean           | 71.7        |
|    ep_rew_mean           | -31.2       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 7           |
|    time_elapsed          | 203         |
|    total_timesteps       | 2723840     |
| train/                   |             |
|    approx_kl             | 0.016076377 |
|    clip_fraction         | 0.138       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.34        |
|    cost_value_loss       | 8.06        |
|    cost_values           | 2.24        |
|    entropy               | 0.158       |
|    entropy_loss          | 0.16        |
|    explained_variance    | 0.868       |
|    lagrangian_multiplier | 0.00155     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.4         |
|    n_updates             | 13290       |
|    policy_gradient_loss  | -0.00114    |
|    std                   | 0.303       |
|    value_loss            | 4.69        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.6         |
| reward                   | -0.71325815 |
| rollout/                 |             |
|    ep_len_mean           | 69.8        |
|    ep_rew_mean           | -30.6       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 8           |
|    time_elapsed          | 234         |
|    total_timesteps       | 2725888     |
| train/                   |             |
|    approx_kl             | 0.01378358  |
|    clip_fraction         | 0.179       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.58        |
|    cost_value_loss       | 9.66        |
|    cost_values           | 2.24        |
|    entropy               | 0.16        |
|    entropy_loss          | 0.159       |
|    explained_variance    | 0.871       |
|    lagrangian_multiplier | 0.00178     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.9         |
|    n_updates             | 13300       |
|    policy_gradient_loss  | 0.00164     |
|    std                   | 0.303       |
|    value_loss            | 4.43        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.80095595 |
| rollout/                 |             |
|    ep_len_mean           | 68.6        |
|    ep_rew_mean           | -30.2       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 9           |
|    time_elapsed          | 264         |
|    total_timesteps       | 2727936     |
| train/                   |             |
|    approx_kl             | 0.02214877  |
|    clip_fraction         | 0.15        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.62        |
|    cost_value_loss       | 9.15        |
|    cost_values           | 2.21        |
|    entropy               | 0.165       |
|    entropy_loss          | 0.163       |
|    explained_variance    | 0.836       |
|    lagrangian_multiplier | 0.000844    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.31        |
|    n_updates             | 13310       |
|    policy_gradient_loss  | 0.00322     |
|    std                   | 0.303       |
|    value_loss            | 5.41        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.21838985 |
| rollout/                 |             |
|    ep_len_mean           | 69.8        |
|    ep_rew_mean           | -30.1       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 10          |
|    time_elapsed          | 294         |
|    total_timesteps       | 2729984     |
| train/                   |             |
|    approx_kl             | 0.01451445  |
|    clip_fraction         | 0.161       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.49        |
|    cost_value_loss       | 9.15        |
|    cost_values           | 2.22        |
|    entropy               | 0.166       |
|    entropy_loss          | 0.166       |
|    explained_variance    | 0.896       |
|    lagrangian_multiplier | 0.00239     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.08        |
|    n_updates             | 13320       |
|    policy_gradient_loss  | 0.00432     |
|    std                   | 0.303       |
|    value_loss            | 4.01        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.34423319 |
| rollout/                 |             |
|    ep_len_mean           | 67.2        |
|    ep_rew_mean           | -29.6       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 11          |
|    time_elapsed          | 324         |
|    total_timesteps       | 2732032     |
| train/                   |             |
|    approx_kl             | 0.025975622 |
|    clip_fraction         | 0.185       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.48        |
|    cost_value_loss       | 8.51        |
|    cost_values           | 2.25        |
|    entropy               | 0.17        |
|    entropy_loss          | 0.168       |
|    explained_variance    | 0.864       |
|    lagrangian_multiplier | 0.00104     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.01        |
|    n_updates             | 13330       |
|    policy_gradient_loss  | -0.000372   |
|    std                   | 0.302       |
|    value_loss            | 4.47        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.17210965 |
| rollout/                 |             |
|    ep_len_mean           | 67.6        |
|    ep_rew_mean           | -29.8       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 12          |
|    time_elapsed          | 355         |
|    total_timesteps       | 2734080     |
| train/                   |             |
|    approx_kl             | 0.024980873 |
|    clip_fraction         | 0.183       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.31        |
|    cost_value_loss       | 7.96        |
|    cost_values           | 2.25        |
|    entropy               | 0.18        |
|    entropy_loss          | 0.175       |
|    explained_variance    | 0.92        |
|    lagrangian_multiplier | 0.00267     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.78        |
|    n_updates             | 13340       |
|    policy_gradient_loss  | 0.00531     |
|    std                   | 0.3         |
|    value_loss            | 3.15        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.35021645 |
| rollout/                 |             |
|    ep_len_mean           | 67.3        |
|    ep_rew_mean           | -29.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 13          |
|    time_elapsed          | 385         |
|    total_timesteps       | 2736128     |
| train/                   |             |
|    approx_kl             | 0.05524447  |
|    clip_fraction         | 0.186       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.7         |
|    cost_value_loss       | 9.42        |
|    cost_values           | 2.28        |
|    entropy               | 0.171       |
|    entropy_loss          | 0.177       |
|    explained_variance    | 0.911       |
|    lagrangian_multiplier | 0.00321     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.99        |
|    n_updates             | 13350       |
|    policy_gradient_loss  | 0.00421     |
|    std                   | 0.301       |
|    value_loss            | 3.32        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.62885374 |
| rollout/                 |             |
|    ep_len_mean           | 67.7        |
|    ep_rew_mean           | -29.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 14          |
|    time_elapsed          | 416         |
|    total_timesteps       | 2738176     |
| train/                   |             |
|    approx_kl             | 0.03538565  |
|    clip_fraction         | 0.207       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.54        |
|    cost_value_loss       | 8.62        |
|    cost_values           | 2.29        |
|    entropy               | 0.172       |
|    entropy_loss          | 0.17        |
|    explained_variance    | 0.908       |
|    lagrangian_multiplier | 0.00179     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.21        |
|    n_updates             | 13360       |
|    policy_gradient_loss  | 0.00804     |
|    std                   | 0.3         |
|    value_loss            | 3.35        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.46        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.46        |
| reward                   | -0.23828626 |
| rollout/                 |             |
|    ep_len_mean           | 66          |
|    ep_rew_mean           | -29.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 15          |
|    time_elapsed          | 445         |
|    total_timesteps       | 2740224     |
| train/                   |             |
|    approx_kl             | 0.014591642 |
|    clip_fraction         | 0.193       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.17        |
|    cost_value_loss       | 7.73        |
|    cost_values           | 2.27        |
|    entropy               | 0.178       |
|    entropy_loss          | 0.176       |
|    explained_variance    | 0.878       |
|    lagrangian_multiplier | 0.000984    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.63        |
|    n_updates             | 13370       |
|    policy_gradient_loss  | 0.0119      |
|    std                   | 0.3         |
|    value_loss            | 4.1         |
------------------------------------------
------------------------------------------
| avg_speed                | 3.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.8         |
| reward                   | -0.70455587 |
| rollout/                 |             |
|    ep_len_mean           | 67.3        |
|    ep_rew_mean           | -29.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 16          |
|    time_elapsed          | 475         |
|    total_timesteps       | 2742272     |
| train/                   |             |
|    approx_kl             | 0.02289908  |
|    clip_fraction         | 0.169       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.09        |
|    cost_value_loss       | 7.18        |
|    cost_values           | 2.22        |
|    entropy               | 0.175       |
|    entropy_loss          | 0.178       |
|    explained_variance    | 0.894       |
|    lagrangian_multiplier | 0.00173     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.07        |
|    n_updates             | 13380       |
|    policy_gradient_loss  | 0.002       |
|    std                   | 0.301       |
|    value_loss            | 3.88        |
------------------------------------------
------------------------------------------
| avg_speed                | 6           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6           |
| reward                   | -0.15269285 |
| rollout/                 |             |
|    ep_len_mean           | 68.3        |
|    ep_rew_mean           | -30.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 17          |
|    time_elapsed          | 505         |
|    total_timesteps       | 2744320     |
| train/                   |             |
|    approx_kl             | 0.059426975 |
|    clip_fraction         | 0.21        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.47        |
|    cost_value_loss       | 8.56        |
|    cost_values           | 2.24        |
|    entropy               | 0.178       |
|    entropy_loss          | 0.176       |
|    explained_variance    | 0.897       |
|    lagrangian_multiplier | 0.00275     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.92        |
|    n_updates             | 13390       |
|    policy_gradient_loss  | 0.00802     |
|    std                   | 0.301       |
|    value_loss            | 3.71        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.31283718 |
| rollout/                 |             |
|    ep_len_mean           | 68.9        |
|    ep_rew_mean           | -30.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 18          |
|    time_elapsed          | 534         |
|    total_timesteps       | 2746368     |
| train/                   |             |
|    approx_kl             | 0.025813313 |
|    clip_fraction         | 0.201       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.17        |
|    cost_value_loss       | 7.16        |
|    cost_values           | 2.24        |
|    entropy               | 0.177       |
|    entropy_loss          | 0.178       |
|    explained_variance    | 0.893       |
|    lagrangian_multiplier | 0.00326     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.48        |
|    n_updates             | 13400       |
|    policy_gradient_loss  | 0.00629     |
|    std                   | 0.301       |
|    value_loss            | 3.88        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.5915407  |
| rollout/                 |             |
|    ep_len_mean           | 71          |
|    ep_rew_mean           | -30.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 19          |
|    time_elapsed          | 564         |
|    total_timesteps       | 2748416     |
| train/                   |             |
|    approx_kl             | 0.022901254 |
|    clip_fraction         | 0.199       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.49        |
|    cost_value_loss       | 8.75        |
|    cost_values           | 2.22        |
|    entropy               | 0.18        |
|    entropy_loss          | 0.179       |
|    explained_variance    | 0.858       |
|    lagrangian_multiplier | 0.00261     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.18        |
|    n_updates             | 13410       |
|    policy_gradient_loss  | 0.0158      |
|    std                   | 0.302       |
|    value_loss            | 4.79        |
------------------------------------------
-------------------------------------------
| avg_speed                | 2.8          |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 2.8          |
| reward                   | -0.65685374  |
| rollout/                 |              |
|    ep_len_mean           | 73.5         |
|    ep_rew_mean           | -31.1        |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 20           |
|    time_elapsed          | 594          |
|    total_timesteps       | 2750464      |
| train/                   |              |
|    approx_kl             | 0.0104199415 |
|    clip_fraction         | 0.172        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.84         |
|    cost_value_loss       | 10.5         |
|    cost_values           | 2.24         |
|    entropy               | 0.178        |
|    entropy_loss          | 0.179        |
|    explained_variance    | 0.857        |
|    lagrangian_multiplier | 0.00147      |
|    learning_rate         | 0.0003       |
|    loss                  | 5.26         |
|    n_updates             | 13420        |
|    policy_gradient_loss  | 0.000918     |
|    std                   | 0.302        |
|    value_loss            | 4.74         |
-------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.52224565 |
| rollout/                 |             |
|    ep_len_mean           | 75.1        |
|    ep_rew_mean           | -31.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 21          |
|    time_elapsed          | 624         |
|    total_timesteps       | 2752512     |
| train/                   |             |
|    approx_kl             | 0.035072453 |
|    clip_fraction         | 0.19        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.51        |
|    cost_value_loss       | 8.11        |
|    cost_values           | 2.3         |
|    entropy               | 0.181       |
|    entropy_loss          | 0.18        |
|    explained_variance    | 0.853       |
|    lagrangian_multiplier | 0.00172     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.34        |
|    n_updates             | 13430       |
|    policy_gradient_loss  | 0.00888     |
|    std                   | 0.302       |
|    value_loss            | 4.36        |
------------------------------------------
------------------------------------------
| avg_speed                | 4           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4           |
| reward                   | -0.814807   |
| rollout/                 |             |
|    ep_len_mean           | 74.5        |
|    ep_rew_mean           | -31.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 22          |
|    time_elapsed          | 653         |
|    total_timesteps       | 2754560     |
| train/                   |             |
|    approx_kl             | 0.015721768 |
|    clip_fraction         | 0.17        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.54        |
|    cost_value_loss       | 9.06        |
|    cost_values           | 2.27        |
|    entropy               | 0.186       |
|    entropy_loss          | 0.183       |
|    explained_variance    | 0.877       |
|    lagrangian_multiplier | 0.00211     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.63        |
|    n_updates             | 13440       |
|    policy_gradient_loss  | 0.00533     |
|    std                   | 0.301       |
|    value_loss            | 4.43        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.328561  |
| rollout/                 |            |
|    ep_len_mean           | 75.3       |
|    ep_rew_mean           | -32.1      |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 23         |
|    time_elapsed          | 683        |
|    total_timesteps       | 2756608    |
| train/                   |            |
|    approx_kl             | 0.02448392 |
|    clip_fraction         | 0.209      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.59       |
|    cost_value_loss       | 9.24       |
|    cost_values           | 2.3        |
|    entropy               | 0.181      |
|    entropy_loss          | 0.185      |
|    explained_variance    | 0.865      |
|    lagrangian_multiplier | 0.00354    |
|    learning_rate         | 0.0003     |
|    loss                  | 4.14       |
|    n_updates             | 13450      |
|    policy_gradient_loss  | 0.00669    |
|    std                   | 0.301      |
|    value_loss            | 5.45       |
-----------------------------------------
------------------------------------------
| avg_speed                | 6.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.4         |
| reward                   | -0.3160064  |
| rollout/                 |             |
|    ep_len_mean           | 70.2        |
|    ep_rew_mean           | -31         |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 24          |
|    time_elapsed          | 713         |
|    total_timesteps       | 2758656     |
| train/                   |             |
|    approx_kl             | 0.015485278 |
|    clip_fraction         | 0.196       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.67        |
|    cost_value_loss       | 9.4         |
|    cost_values           | 2.34        |
|    entropy               | 0.187       |
|    entropy_loss          | 0.183       |
|    explained_variance    | 0.888       |
|    lagrangian_multiplier | 0.000321    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.8         |
|    n_updates             | 13460       |
|    policy_gradient_loss  | 0.00103     |
|    std                   | 0.301       |
|    value_loss            | 4.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.13982348 |
| rollout/                 |             |
|    ep_len_mean           | 66.1        |
|    ep_rew_mean           | -29.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 25          |
|    time_elapsed          | 743         |
|    total_timesteps       | 2760704     |
| train/                   |             |
|    approx_kl             | 0.033729445 |
|    clip_fraction         | 0.237       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.33        |
|    cost_value_loss       | 7.69        |
|    cost_values           | 2.29        |
|    entropy               | 0.189       |
|    entropy_loss          | 0.189       |
|    explained_variance    | 0.924       |
|    lagrangian_multiplier | 0.000962    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.3         |
|    n_updates             | 13470       |
|    policy_gradient_loss  | 0.00855     |
|    std                   | 0.301       |
|    value_loss            | 3.21        |
------------------------------------------
-------------------------------------------
| avg_speed                | 8.02         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.02         |
| reward                   | -0.12985478  |
| rollout/                 |              |
|    ep_len_mean           | 64           |
|    ep_rew_mean           | -28.6        |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 26           |
|    time_elapsed          | 773          |
|    total_timesteps       | 2762752      |
| train/                   |              |
|    approx_kl             | 0.0069787004 |
|    clip_fraction         | 0.125        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.56         |
|    cost_value_loss       | 8.96         |
|    cost_values           | 2.29         |
|    entropy               | 0.181        |
|    entropy_loss          | 0.185        |
|    explained_variance    | 0.893        |
|    lagrangian_multiplier | 0.000708     |
|    learning_rate         | 0.0003       |
|    loss                  | 5.18         |
|    n_updates             | 13480        |
|    policy_gradient_loss  | 0.0039       |
|    std                   | 0.303        |
|    value_loss            | 3.94         |
-------------------------------------------
------------------------------------------
| avg_speed                | 1.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.8         |
| reward                   | -0.7792198  |
| rollout/                 |             |
|    ep_len_mean           | 66.5        |
|    ep_rew_mean           | -29.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 27          |
|    time_elapsed          | 803         |
|    total_timesteps       | 2764800     |
| train/                   |             |
|    approx_kl             | 0.040915206 |
|    clip_fraction         | 0.196       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.04        |
|    cost_value_loss       | 6.77        |
|    cost_values           | 2.3         |
|    entropy               | 0.187       |
|    entropy_loss          | 0.183       |
|    explained_variance    | 0.845       |
|    lagrangian_multiplier | 0.00144     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.42        |
|    n_updates             | 13490       |
|    policy_gradient_loss  | 0.00549     |
|    std                   | 0.302       |
|    value_loss            | 5           |
------------------------------------------
------------------------------------------
| avg_speed                | 4.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.8         |
| reward                   | -0.64844656 |
| rollout/                 |             |
|    ep_len_mean           | 65          |
|    ep_rew_mean           | -29.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 28          |
|    time_elapsed          | 832         |
|    total_timesteps       | 2766848     |
| train/                   |             |
|    approx_kl             | 0.061880164 |
|    clip_fraction         | 0.194       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.35        |
|    cost_value_loss       | 7.86        |
|    cost_values           | 2.24        |
|    entropy               | 0.191       |
|    entropy_loss          | 0.19        |
|    explained_variance    | 0.881       |
|    lagrangian_multiplier | 0.00149     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.17        |
|    n_updates             | 13500       |
|    policy_gradient_loss  | 0.0123      |
|    std                   | 0.301       |
|    value_loss            | 3.58        |
------------------------------------------
-----------------------------------------
| avg_speed                | 6.6        |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 6.6        |
| reward                   | -0.2562334 |
| rollout/                 |            |
|    ep_len_mean           | 60.3       |
|    ep_rew_mean           | -27.6      |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 29         |
|    time_elapsed          | 863        |
|    total_timesteps       | 2768896    |
| train/                   |            |
|    approx_kl             | 0.02283877 |
|    clip_fraction         | 0.194      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.28       |
|    cost_value_loss       | 7.37       |
|    cost_values           | 2.27       |
|    entropy               | 0.186      |
|    entropy_loss          | 0.189      |
|    explained_variance    | 0.908      |
|    lagrangian_multiplier | 0.0019     |
|    learning_rate         | 0.0003     |
|    loss                  | 3.77       |
|    n_updates             | 13510      |
|    policy_gradient_loss  | 0.00752    |
|    std                   | 0.301      |
|    value_loss            | 3.63       |
-----------------------------------------
------------------------------------------
| avg_speed                | 2.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.8         |
| reward                   | -0.8434923  |
| rollout/                 |             |
|    ep_len_mean           | 64          |
|    ep_rew_mean           | -28.8       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 30          |
|    time_elapsed          | 893         |
|    total_timesteps       | 2770944     |
| train/                   |             |
|    approx_kl             | 0.054200485 |
|    clip_fraction         | 0.206       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.32        |
|    cost_value_loss       | 7.64        |
|    cost_values           | 2.3         |
|    entropy               | 0.184       |
|    entropy_loss          | 0.184       |
|    explained_variance    | 0.902       |
|    lagrangian_multiplier | 0.00143     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.33        |
|    n_updates             | 13520       |
|    policy_gradient_loss  | 0.0117      |
|    std                   | 0.301       |
|    value_loss            | 3.5         |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.38000652 |
| rollout/                 |             |
|    ep_len_mean           | 64.7        |
|    ep_rew_mean           | -29.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 31          |
|    time_elapsed          | 922         |
|    total_timesteps       | 2772992     |
| train/                   |             |
|    approx_kl             | 0.019008217 |
|    clip_fraction         | 0.197       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.5         |
|    cost_value_loss       | 8.95        |
|    cost_values           | 2.29        |
|    entropy               | 0.188       |
|    entropy_loss          | 0.186       |
|    explained_variance    | 0.85        |
|    lagrangian_multiplier | 0.00225     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.41        |
|    n_updates             | 13530       |
|    policy_gradient_loss  | 0.00826     |
|    std                   | 0.3         |
|    value_loss            | 5.07        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.2         |
| reward                   | -0.6686554  |
| rollout/                 |             |
|    ep_len_mean           | 66.3        |
|    ep_rew_mean           | -29.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 32          |
|    time_elapsed          | 952         |
|    total_timesteps       | 2775040     |
| train/                   |             |
|    approx_kl             | 0.009944985 |
|    clip_fraction         | 0.14        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.54        |
|    cost_value_loss       | 8.67        |
|    cost_values           | 2.29        |
|    entropy               | 0.196       |
|    entropy_loss          | 0.192       |
|    explained_variance    | 0.884       |
|    lagrangian_multiplier | 0.00278     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.04        |
|    n_updates             | 13540       |
|    policy_gradient_loss  | 0.000744    |
|    std                   | 0.299       |
|    value_loss            | 4.07        |
------------------------------------------
-------------------------------------------
| avg_speed                | 5.8          |
| cost                     | 1            |
| is_success               | 0            |
| max_speed                | 5.8          |
| reward                   | -0.36606252  |
| rollout/                 |              |
|    ep_len_mean           | 65.8         |
|    ep_rew_mean           | -29.4        |
| time/                    |              |
|    fps                   | 68           |
|    iterations            | 33           |
|    time_elapsed          | 981          |
|    total_timesteps       | 2777088      |
| train/                   |              |
|    approx_kl             | 0.0103519745 |
|    clip_fraction         | 0.197        |
|    clip_range            | 0.2          |
|    cost_returns          | 4.41         |
|    cost_value_loss       | 8.08         |
|    cost_values           | 2.29         |
|    entropy               | 0.204        |
|    entropy_loss          | 0.2          |
|    explained_variance    | 0.893        |
|    lagrangian_multiplier | 0.00164      |
|    learning_rate         | 0.0003       |
|    loss                  | 4.15         |
|    n_updates             | 13550        |
|    policy_gradient_loss  | -0.00249     |
|    std                   | 0.298        |
|    value_loss            | 3.93         |
-------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.33230594 |
| rollout/                 |             |
|    ep_len_mean           | 67.6        |
|    ep_rew_mean           | -29.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 34          |
|    time_elapsed          | 1011        |
|    total_timesteps       | 2779136     |
| train/                   |             |
|    approx_kl             | 0.028855868 |
|    clip_fraction         | 0.191       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.75        |
|    cost_value_loss       | 9.78        |
|    cost_values           | 2.32        |
|    entropy               | 0.214       |
|    entropy_loss          | 0.21        |
|    explained_variance    | 0.904       |
|    lagrangian_multiplier | 0.00151     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.57        |
|    n_updates             | 13560       |
|    policy_gradient_loss  | 0.0106      |
|    std                   | 0.296       |
|    value_loss            | 3.39        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.4         |
| reward                   | -0.33377048 |
| rollout/                 |             |
|    ep_len_mean           | 69.6        |
|    ep_rew_mean           | -30.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 35          |
|    time_elapsed          | 1040        |
|    total_timesteps       | 2781184     |
| train/                   |             |
|    approx_kl             | 0.01750426  |
|    clip_fraction         | 0.236       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.64        |
|    cost_value_loss       | 9.46        |
|    cost_values           | 2.32        |
|    entropy               | 0.215       |
|    entropy_loss          | 0.216       |
|    explained_variance    | 0.908       |
|    lagrangian_multiplier | 0.00122     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.09        |
|    n_updates             | 13570       |
|    policy_gradient_loss  | 0.00768     |
|    std                   | 0.297       |
|    value_loss            | 3.61        |
------------------------------------------
-----------------------------------------
| avg_speed                | 4.8        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 4.8        |
| reward                   | -0.5911443 |
| rollout/                 |            |
|    ep_len_mean           | 72.3       |
|    ep_rew_mean           | -31.4      |
| time/                    |            |
|    fps                   | 68         |
|    iterations            | 36         |
|    time_elapsed          | 1069       |
|    total_timesteps       | 2783232    |
| train/                   |            |
|    approx_kl             | 0.01928162 |
|    clip_fraction         | 0.178      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.84       |
|    cost_value_loss       | 10.5       |
|    cost_values           | 2.31       |
|    entropy               | 0.215      |
|    entropy_loss          | 0.215      |
|    explained_variance    | 0.867      |
|    lagrangian_multiplier | 0.0012     |
|    learning_rate         | 0.0003     |
|    loss                  | 5.62       |
|    n_updates             | 13580      |
|    policy_gradient_loss  | 2.12e-05   |
|    std                   | 0.297      |
|    value_loss            | 4.52       |
-----------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.66406286 |
| rollout/                 |             |
|    ep_len_mean           | 73.3        |
|    ep_rew_mean           | -31.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 37          |
|    time_elapsed          | 1098        |
|    total_timesteps       | 2785280     |
| train/                   |             |
|    approx_kl             | 0.014043921 |
|    clip_fraction         | 0.152       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.65        |
|    cost_value_loss       | 9.49        |
|    cost_values           | 2.34        |
|    entropy               | 0.211       |
|    entropy_loss          | 0.213       |
|    explained_variance    | 0.847       |
|    lagrangian_multiplier | 0.00201     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.86        |
|    n_updates             | 13590       |
|    policy_gradient_loss  | 0.00219     |
|    std                   | 0.297       |
|    value_loss            | 5.37        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.2         |
| reward                   | -0.69352686 |
| rollout/                 |             |
|    ep_len_mean           | 71.1        |
|    ep_rew_mean           | -31.1       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 38          |
|    time_elapsed          | 1128        |
|    total_timesteps       | 2787328     |
| train/                   |             |
|    approx_kl             | 0.022383682 |
|    clip_fraction         | 0.146       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.39        |
|    cost_value_loss       | 8.12        |
|    cost_values           | 2.33        |
|    entropy               | 0.208       |
|    entropy_loss          | 0.208       |
|    explained_variance    | 0.86        |
|    lagrangian_multiplier | 0.000791    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.25        |
|    n_updates             | 13600       |
|    policy_gradient_loss  | 0.000547    |
|    std                   | 0.297       |
|    value_loss            | 5.29        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.26774845 |
| rollout/                 |             |
|    ep_len_mean           | 74          |
|    ep_rew_mean           | -31.8       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 39          |
|    time_elapsed          | 1157        |
|    total_timesteps       | 2789376     |
| train/                   |             |
|    approx_kl             | 0.035031077 |
|    clip_fraction         | 0.209       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.3         |
|    cost_value_loss       | 8.4         |
|    cost_values           | 2.32        |
|    entropy               | 0.206       |
|    entropy_loss          | 0.207       |
|    explained_variance    | 0.864       |
|    lagrangian_multiplier | 0.00258     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.33        |
|    n_updates             | 13610       |
|    policy_gradient_loss  | 0.00504     |
|    std                   | 0.297       |
|    value_loss            | 5.21        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.21935709 |
| rollout/                 |             |
|    ep_len_mean           | 72.2        |
|    ep_rew_mean           | -31.3       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 40          |
|    time_elapsed          | 1186        |
|    total_timesteps       | 2791424     |
| train/                   |             |
|    approx_kl             | 0.018015908 |
|    clip_fraction         | 0.191       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.6         |
|    cost_value_loss       | 9.67        |
|    cost_values           | 2.31        |
|    entropy               | 0.206       |
|    entropy_loss          | 0.206       |
|    explained_variance    | 0.844       |
|    lagrangian_multiplier | 0.0008      |
|    learning_rate         | 0.0003      |
|    loss                  | 6           |
|    n_updates             | 13620       |
|    policy_gradient_loss  | 0.00771     |
|    std                   | 0.296       |
|    value_loss            | 4.82        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.29042917 |
| rollout/                 |             |
|    ep_len_mean           | 72.1        |
|    ep_rew_mean           | -30.8       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 41          |
|    time_elapsed          | 1215        |
|    total_timesteps       | 2793472     |
| train/                   |             |
|    approx_kl             | 0.034373254 |
|    clip_fraction         | 0.208       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.56        |
|    cost_value_loss       | 8.99        |
|    cost_values           | 2.34        |
|    entropy               | 0.204       |
|    entropy_loss          | 0.205       |
|    explained_variance    | 0.878       |
|    lagrangian_multiplier | 0.00277     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.19        |
|    n_updates             | 13630       |
|    policy_gradient_loss  | 0.0089      |
|    std                   | 0.296       |
|    value_loss            | 4.7         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.55        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.55        |
| reward                   | -0.3069945  |
| rollout/                 |             |
|    ep_len_mean           | 70.7        |
|    ep_rew_mean           | -30.4       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 42          |
|    time_elapsed          | 1245        |
|    total_timesteps       | 2795520     |
| train/                   |             |
|    approx_kl             | 0.026933363 |
|    clip_fraction         | 0.222       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.52        |
|    cost_value_loss       | 9.39        |
|    cost_values           | 2.29        |
|    entropy               | 0.21        |
|    entropy_loss          | 0.206       |
|    explained_variance    | 0.88        |
|    lagrangian_multiplier | 0.00208     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.56        |
|    n_updates             | 13640       |
|    policy_gradient_loss  | 0.00858     |
|    std                   | 0.296       |
|    value_loss            | 4.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.2         |
| reward                   | -0.22073525 |
| rollout/                 |             |
|    ep_len_mean           | 65.6        |
|    ep_rew_mean           | -28.7       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 43          |
|    time_elapsed          | 1275        |
|    total_timesteps       | 2797568     |
| train/                   |             |
|    approx_kl             | 0.027620874 |
|    clip_fraction         | 0.208       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.27        |
|    cost_value_loss       | 7.7         |
|    cost_values           | 2.27        |
|    entropy               | 0.207       |
|    entropy_loss          | 0.209       |
|    explained_variance    | 0.89        |
|    lagrangian_multiplier | 0.00162     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.08        |
|    n_updates             | 13650       |
|    policy_gradient_loss  | 0.00631     |
|    std                   | 0.296       |
|    value_loss            | 4.06        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.36626974 |
| rollout/                 |             |
|    ep_len_mean           | 65.4        |
|    ep_rew_mean           | -28.8       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 44          |
|    time_elapsed          | 1305        |
|    total_timesteps       | 2799616     |
| train/                   |             |
|    approx_kl             | 0.04303617  |
|    clip_fraction         | 0.198       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.16        |
|    cost_value_loss       | 6.94        |
|    cost_values           | 2.28        |
|    entropy               | 0.203       |
|    entropy_loss          | 0.205       |
|    explained_variance    | 0.919       |
|    lagrangian_multiplier | 0.00147     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.85        |
|    n_updates             | 13660       |
|    policy_gradient_loss  | 0.0125      |
|    std                   | 0.297       |
|    value_loss            | 3.42        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.38534117 |
| rollout/                 |             |
|    ep_len_mean           | 65.1        |
|    ep_rew_mean           | -28.8       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 45          |
|    time_elapsed          | 1335        |
|    total_timesteps       | 2801664     |
| train/                   |             |
|    approx_kl             | 0.025336467 |
|    clip_fraction         | 0.14        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.39        |
|    cost_value_loss       | 7.97        |
|    cost_values           | 2.27        |
|    entropy               | 0.203       |
|    entropy_loss          | 0.203       |
|    explained_variance    | 0.818       |
|    lagrangian_multiplier | 0.00102     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.17        |
|    n_updates             | 13670       |
|    policy_gradient_loss  | 0.00156     |
|    std                   | 0.296       |
|    value_loss            | 5.56        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.25084516 |
| rollout/                 |             |
|    ep_len_mean           | 66.7        |
|    ep_rew_mean           | -29.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 46          |
|    time_elapsed          | 1365        |
|    total_timesteps       | 2803712     |
| train/                   |             |
|    approx_kl             | 0.014970859 |
|    clip_fraction         | 0.149       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.53        |
|    cost_value_loss       | 8.74        |
|    cost_values           | 2.29        |
|    entropy               | 0.205       |
|    entropy_loss          | 0.204       |
|    explained_variance    | 0.841       |
|    lagrangian_multiplier | 0.00159     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.77        |
|    n_updates             | 13680       |
|    policy_gradient_loss  | 0.00449     |
|    std                   | 0.295       |
|    value_loss            | 5.09        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.15382177 |
| rollout/                 |             |
|    ep_len_mean           | 68          |
|    ep_rew_mean           | -29.5       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 47          |
|    time_elapsed          | 1395        |
|    total_timesteps       | 2805760     |
| train/                   |             |
|    approx_kl             | 0.020060329 |
|    clip_fraction         | 0.155       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.56        |
|    cost_value_loss       | 8.77        |
|    cost_values           | 2.31        |
|    entropy               | 0.204       |
|    entropy_loss          | 0.204       |
|    explained_variance    | 0.875       |
|    lagrangian_multiplier | 0.00166     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.76        |
|    n_updates             | 13690       |
|    policy_gradient_loss  | 0.00293     |
|    std                   | 0.295       |
|    value_loss            | 4.14        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2795486  |
| rollout/                 |             |
|    ep_len_mean           | 65.7        |
|    ep_rew_mean           | -28.9       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 48          |
|    time_elapsed          | 1425        |
|    total_timesteps       | 2807808     |
| train/                   |             |
|    approx_kl             | 0.023192618 |
|    clip_fraction         | 0.176       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.49        |
|    cost_value_loss       | 8.42        |
|    cost_values           | 2.3         |
|    entropy               | 0.211       |
|    entropy_loss          | 0.206       |
|    explained_variance    | 0.883       |
|    lagrangian_multiplier | 0.000754    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.4         |
|    n_updates             | 13700       |
|    policy_gradient_loss  | 0.00375     |
|    std                   | 0.294       |
|    value_loss            | 4.35        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.30456784 |
| rollout/                 |             |
|    ep_len_mean           | 67.1        |
|    ep_rew_mean           | -29.4       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 49          |
|    time_elapsed          | 1454        |
|    total_timesteps       | 2809856     |
| train/                   |             |
|    approx_kl             | 0.015233576 |
|    clip_fraction         | 0.189       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.6         |
|    cost_value_loss       | 8.83        |
|    cost_values           | 2.28        |
|    entropy               | 0.213       |
|    entropy_loss          | 0.213       |
|    explained_variance    | 0.79        |
|    lagrangian_multiplier | 0.00149     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.07        |
|    n_updates             | 13710       |
|    policy_gradient_loss  | 0.00291     |
|    std                   | 0.294       |
|    value_loss            | 5.49        |
------------------------------------------
------------------------------------
| avg_speed          | 8.01        |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 8.01        |
| reward             | -0.35107648 |
| rollout/           |             |
|    ep_len_mean     | 68.2        |
|    ep_rew_mean     | -29.7       |
| time/              |             |
|    fps             | 74          |
|    iterations      | 1           |
|    time_elapsed    | 27          |
|    total_timesteps | 2811904     |
------------------------------------
------------------------------------------
| avg_speed                | 2.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.4         |
| reward                   | -0.7073532  |
| rollout/                 |             |
|    ep_len_mean           | 65.9        |
|    ep_rew_mean           | -28.8       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 2           |
|    time_elapsed          | 57          |
|    total_timesteps       | 2813952     |
| train/                   |             |
|    approx_kl             | 0.041694615 |
|    clip_fraction         | 0.212       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.38        |
|    cost_value_loss       | 8.08        |
|    cost_values           | 2.33        |
|    entropy               | 0.219       |
|    entropy_loss          | 0.214       |
|    explained_variance    | 0.905       |
|    lagrangian_multiplier | 0.00299     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.78        |
|    n_updates             | 13730       |
|    policy_gradient_loss  | 0.00715     |
|    std                   | 0.291       |
|    value_loss            | 3.64        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.31473464 |
| rollout/                 |             |
|    ep_len_mean           | 63.2        |
|    ep_rew_mean           | -28.3       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 3           |
|    time_elapsed          | 86          |
|    total_timesteps       | 2816000     |
| train/                   |             |
|    approx_kl             | 0.03374788  |
|    clip_fraction         | 0.189       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.46        |
|    cost_value_loss       | 8.39        |
|    cost_values           | 2.29        |
|    entropy               | 0.216       |
|    entropy_loss          | 0.219       |
|    explained_variance    | 0.902       |
|    lagrangian_multiplier | 0.00177     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.47        |
|    n_updates             | 13740       |
|    policy_gradient_loss  | 0.0087      |
|    std                   | 0.292       |
|    value_loss            | 3.41        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.44979295 |
| rollout/                 |             |
|    ep_len_mean           | 64.8        |
|    ep_rew_mean           | -29         |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 4           |
|    time_elapsed          | 116         |
|    total_timesteps       | 2818048     |
| train/                   |             |
|    approx_kl             | 0.016370786 |
|    clip_fraction         | 0.171       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.26        |
|    cost_value_loss       | 7.28        |
|    cost_values           | 2.3         |
|    entropy               | 0.22        |
|    entropy_loss          | 0.217       |
|    explained_variance    | 0.921       |
|    lagrangian_multiplier | 0.00302     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.6         |
|    n_updates             | 13750       |
|    policy_gradient_loss  | 0.00739     |
|    std                   | 0.291       |
|    value_loss            | 3.17        |
------------------------------------------
------------------------------------------
| avg_speed                | 2.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.8         |
| reward                   | -0.6872016  |
| rollout/                 |             |
|    ep_len_mean           | 66.2        |
|    ep_rew_mean           | -29.4       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 5           |
|    time_elapsed          | 145         |
|    total_timesteps       | 2820096     |
| train/                   |             |
|    approx_kl             | 0.011677806 |
|    clip_fraction         | 0.194       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.32        |
|    cost_value_loss       | 7.5         |
|    cost_values           | 2.31        |
|    entropy               | 0.224       |
|    entropy_loss          | 0.223       |
|    explained_variance    | 0.909       |
|    lagrangian_multiplier | 0.00173     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.15        |
|    n_updates             | 13760       |
|    policy_gradient_loss  | 0.011       |
|    std                   | 0.291       |
|    value_loss            | 3.45        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.26692015 |
| rollout/                 |             |
|    ep_len_mean           | 66.3        |
|    ep_rew_mean           | -28.9       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 6           |
|    time_elapsed          | 174         |
|    total_timesteps       | 2822144     |
| train/                   |             |
|    approx_kl             | 0.01611894  |
|    clip_fraction         | 0.189       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.42        |
|    cost_value_loss       | 8.17        |
|    cost_values           | 2.31        |
|    entropy               | 0.232       |
|    entropy_loss          | 0.228       |
|    explained_variance    | 0.883       |
|    lagrangian_multiplier | 0.00222     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.8         |
|    n_updates             | 13770       |
|    policy_gradient_loss  | 0.00358     |
|    std                   | 0.29        |
|    value_loss            | 3.84        |
------------------------------------------
-----------------------------------------
| avg_speed                | 0.8        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 0.8        |
| reward                   | -0.8923724 |
| rollout/                 |            |
|    ep_len_mean           | 66.2       |
|    ep_rew_mean           | -28.9      |
| time/                    |            |
|    fps                   | 69         |
|    iterations            | 7          |
|    time_elapsed          | 204        |
|    total_timesteps       | 2824192    |
| train/                   |            |
|    approx_kl             | 0.04542009 |
|    clip_fraction         | 0.231      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.36       |
|    cost_value_loss       | 7.38       |
|    cost_values           | 2.32       |
|    entropy               | 0.227      |
|    entropy_loss          | 0.231      |
|    explained_variance    | 0.875      |
|    lagrangian_multiplier | 0.000493   |
|    learning_rate         | 0.0003     |
|    loss                  | 5.26       |
|    n_updates             | 13780      |
|    policy_gradient_loss  | 0.00837    |
|    std                   | 0.292      |
|    value_loss            | 4.08       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3408138  |
| rollout/                 |             |
|    ep_len_mean           | 63.9        |
|    ep_rew_mean           | -28.7       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 8           |
|    time_elapsed          | 234         |
|    total_timesteps       | 2826240     |
| train/                   |             |
|    approx_kl             | 0.024723401 |
|    clip_fraction         | 0.187       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.23        |
|    cost_value_loss       | 7.34        |
|    cost_values           | 2.3         |
|    entropy               | 0.227       |
|    entropy_loss          | 0.226       |
|    explained_variance    | 0.892       |
|    lagrangian_multiplier | 0.00158     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.11        |
|    n_updates             | 13790       |
|    policy_gradient_loss  | 0.00741     |
|    std                   | 0.293       |
|    value_loss            | 3.85        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.33481923 |
| rollout/                 |             |
|    ep_len_mean           | 65.8        |
|    ep_rew_mean           | -29.8       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 9           |
|    time_elapsed          | 264         |
|    total_timesteps       | 2828288     |
| train/                   |             |
|    approx_kl             | 0.014968179 |
|    clip_fraction         | 0.176       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.43        |
|    cost_value_loss       | 7.99        |
|    cost_values           | 2.34        |
|    entropy               | 0.221       |
|    entropy_loss          | 0.224       |
|    explained_variance    | 0.929       |
|    lagrangian_multiplier | 0.00242     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.78        |
|    n_updates             | 13800       |
|    policy_gradient_loss  | 0.00204     |
|    std                   | 0.294       |
|    value_loss            | 2.82        |
------------------------------------------
------------------------------------------
| avg_speed                | 3           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3           |
| reward                   | -0.88715583 |
| rollout/                 |             |
|    ep_len_mean           | 69          |
|    ep_rew_mean           | -30.7       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 10          |
|    time_elapsed          | 294         |
|    total_timesteps       | 2830336     |
| train/                   |             |
|    approx_kl             | 0.042975213 |
|    clip_fraction         | 0.201       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.4         |
|    cost_value_loss       | 7.59        |
|    cost_values           | 2.34        |
|    entropy               | 0.229       |
|    entropy_loss          | 0.225       |
|    explained_variance    | 0.883       |
|    lagrangian_multiplier | 0.00312     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.74        |
|    n_updates             | 13810       |
|    policy_gradient_loss  | 0.00316     |
|    std                   | 0.294       |
|    value_loss            | 4.23        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.8         |
| reward                   | -0.3435087  |
| rollout/                 |             |
|    ep_len_mean           | 70.7        |
|    ep_rew_mean           | -30.5       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 11          |
|    time_elapsed          | 325         |
|    total_timesteps       | 2832384     |
| train/                   |             |
|    approx_kl             | 0.022407468 |
|    clip_fraction         | 0.181       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.23        |
|    cost_value_loss       | 7.41        |
|    cost_values           | 2.29        |
|    entropy               | 0.225       |
|    entropy_loss          | 0.228       |
|    explained_variance    | 0.818       |
|    lagrangian_multiplier | 0.000976    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.73        |
|    n_updates             | 13820       |
|    policy_gradient_loss  | 0.00697     |
|    std                   | 0.295       |
|    value_loss            | 5.36        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.33165088 |
| rollout/                 |             |
|    ep_len_mean           | 69.3        |
|    ep_rew_mean           | -29.6       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 12          |
|    time_elapsed          | 356         |
|    total_timesteps       | 2834432     |
| train/                   |             |
|    approx_kl             | 0.014501495 |
|    clip_fraction         | 0.161       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.39        |
|    cost_value_loss       | 7.85        |
|    cost_values           | 2.27        |
|    entropy               | 0.229       |
|    entropy_loss          | 0.225       |
|    explained_variance    | 0.816       |
|    lagrangian_multiplier | 0.00248     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.14        |
|    n_updates             | 13830       |
|    policy_gradient_loss  | 0.00518     |
|    std                   | 0.295       |
|    value_loss            | 5.38        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.28896132 |
| rollout/                 |             |
|    ep_len_mean           | 76.2        |
|    ep_rew_mean           | -31.7       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 13          |
|    time_elapsed          | 386         |
|    total_timesteps       | 2836480     |
| train/                   |             |
|    approx_kl             | 0.01715659  |
|    clip_fraction         | 0.185       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.16        |
|    cost_value_loss       | 7.03        |
|    cost_values           | 2.28        |
|    entropy               | 0.234       |
|    entropy_loss          | 0.232       |
|    explained_variance    | 0.85        |
|    lagrangian_multiplier | 0.000761    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.87        |
|    n_updates             | 13840       |
|    policy_gradient_loss  | 0.0035      |
|    std                   | 0.293       |
|    value_loss            | 4.98        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.2         |
| reward                   | -0.20156023 |
| rollout/                 |             |
|    ep_len_mean           | 80.5        |
|    ep_rew_mean           | -33.2       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 14          |
|    time_elapsed          | 416         |
|    total_timesteps       | 2838528     |
| train/                   |             |
|    approx_kl             | 0.022738967 |
|    clip_fraction         | 0.168       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.41        |
|    cost_value_loss       | 7.33        |
|    cost_values           | 2.27        |
|    entropy               | 0.235       |
|    entropy_loss          | 0.234       |
|    explained_variance    | 0.723       |
|    lagrangian_multiplier | 0.000979    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.18        |
|    n_updates             | 13850       |
|    policy_gradient_loss  | 0.00163     |
|    std                   | 0.293       |
|    value_loss            | 6.55        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.4         |
| reward                   | -0.58277416 |
| rollout/                 |             |
|    ep_len_mean           | 84          |
|    ep_rew_mean           | -34.3       |
| time/                    |             |
|    fps                   | 68          |
|    iterations            | 15          |
|    time_elapsed          | 445         |
|    total_timesteps       | 2840576     |
| train/                   |             |
|    approx_kl             | 0.013183879 |
|    clip_fraction         | 0.155       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.25        |
|    cost_value_loss       | 6.89        |
|    cost_values           | 2.25        |
|    entropy               | 0.241       |
|    entropy_loss          | 0.238       |
|    explained_variance    | 0.688       |
|    lagrangian_multiplier | 0.000222    |
|    learning_rate         | 0.0003      |
|    loss                  | 6.55        |
|    n_updates             | 13860       |
|    policy_gradient_loss  | 0.00419     |
|    std                   | 0.292       |
|    value_loss            | 7           |
------------------------------------------
------------------------------------------
| avg_speed                | 2.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.6         |
| reward                   | -0.62372476 |
| rollout/                 |             |
|    ep_len_mean           | 90.6        |
|    ep_rew_mean           | -36.5       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 16          |
|    time_elapsed          | 474         |
|    total_timesteps       | 2842624     |
| train/                   |             |
|    approx_kl             | 0.010824729 |
|    clip_fraction         | 0.16        |
|    clip_range            | 0.2         |
|    cost_returns          | 3.79        |
|    cost_value_loss       | 6.17        |
|    cost_values           | 2.21        |
|    entropy               | 0.24        |
|    entropy_loss          | 0.241       |
|    explained_variance    | 0.684       |
|    lagrangian_multiplier | 0           |
|    learning_rate         | 0.0003      |
|    loss                  | 6.82        |
|    n_updates             | 13870       |
|    policy_gradient_loss  | 0.00582     |
|    std                   | 0.292       |
|    value_loss            | 7.98        |
------------------------------------------
-----------------------------------------
| avg_speed                | 2.6        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 2.6        |
| reward                   | -0.7376107 |
| rollout/                 |            |
|    ep_len_mean           | 81.2       |
|    ep_rew_mean           | -33.5      |
| time/                    |            |
|    fps                   | 69         |
|    iterations            | 17         |
|    time_elapsed          | 503        |
|    total_timesteps       | 2844672    |
| train/                   |            |
|    approx_kl             | 0.01215114 |
|    clip_fraction         | 0.13       |
|    clip_range            | 0.2        |
|    cost_returns          | 3.96       |
|    cost_value_loss       | 6.41       |
|    cost_values           | 2.2        |
|    entropy               | 0.239      |
|    entropy_loss          | 0.24       |
|    explained_variance    | 0.691      |
|    lagrangian_multiplier | 0.000187   |
|    learning_rate         | 0.0003     |
|    loss                  | 7.82       |
|    n_updates             | 13880      |
|    policy_gradient_loss  | 0.00154    |
|    std                   | 0.292      |
|    value_loss            | 8.92       |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.4         |
| reward                   | -0.68751216 |
| rollout/                 |             |
|    ep_len_mean           | 72.1        |
|    ep_rew_mean           | -30.7       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 18          |
|    time_elapsed          | 532         |
|    total_timesteps       | 2846720     |
| train/                   |             |
|    approx_kl             | 0.021068828 |
|    clip_fraction         | 0.213       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.01        |
|    cost_value_loss       | 6.73        |
|    cost_values           | 2.19        |
|    entropy               | 0.242       |
|    entropy_loss          | 0.241       |
|    explained_variance    | 0.809       |
|    lagrangian_multiplier | 0.00147     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.64        |
|    n_updates             | 13890       |
|    policy_gradient_loss  | 0.00183     |
|    std                   | 0.291       |
|    value_loss            | 6.6         |
------------------------------------------
------------------------------------------
| avg_speed                | 7.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7.4         |
| reward                   | -0.292908   |
| rollout/                 |             |
|    ep_len_mean           | 65.2        |
|    ep_rew_mean           | -28.9       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 19          |
|    time_elapsed          | 562         |
|    total_timesteps       | 2848768     |
| train/                   |             |
|    approx_kl             | 0.013198351 |
|    clip_fraction         | 0.185       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.19        |
|    cost_value_loss       | 7.25        |
|    cost_values           | 2.23        |
|    entropy               | 0.244       |
|    entropy_loss          | 0.244       |
|    explained_variance    | 0.822       |
|    lagrangian_multiplier | 0.00159     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.59        |
|    n_updates             | 13900       |
|    policy_gradient_loss  | 0.00422     |
|    std                   | 0.291       |
|    value_loss            | 6.02        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.3         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.3         |
| reward                   | -0.20888147 |
| rollout/                 |             |
|    ep_len_mean           | 66.8        |
|    ep_rew_mean           | -29.7       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 20          |
|    time_elapsed          | 591         |
|    total_timesteps       | 2850816     |
| train/                   |             |
|    approx_kl             | 0.023018455 |
|    clip_fraction         | 0.195       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.02        |
|    cost_value_loss       | 6.53        |
|    cost_values           | 2.22        |
|    entropy               | 0.245       |
|    entropy_loss          | 0.245       |
|    explained_variance    | 0.863       |
|    lagrangian_multiplier | 0.00118     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.35        |
|    n_updates             | 13910       |
|    policy_gradient_loss  | 0.00691     |
|    std                   | 0.29        |
|    value_loss            | 5.21        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.30957934 |
| rollout/                 |             |
|    ep_len_mean           | 65.6        |
|    ep_rew_mean           | -29.7       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 21          |
|    time_elapsed          | 621         |
|    total_timesteps       | 2852864     |
| train/                   |             |
|    approx_kl             | 0.020654267 |
|    clip_fraction         | 0.169       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.14        |
|    cost_value_loss       | 7.35        |
|    cost_values           | 2.24        |
|    entropy               | 0.25        |
|    entropy_loss          | 0.247       |
|    explained_variance    | 0.844       |
|    lagrangian_multiplier | 0.0017      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.63        |
|    n_updates             | 13920       |
|    policy_gradient_loss  | 0.0038      |
|    std                   | 0.29        |
|    value_loss            | 5.51        |
------------------------------------------
------------------------------------------
| avg_speed                | 1.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.2         |
| reward                   | -0.850427   |
| rollout/                 |             |
|    ep_len_mean           | 70.7        |
|    ep_rew_mean           | -31.1       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 22          |
|    time_elapsed          | 650         |
|    total_timesteps       | 2854912     |
| train/                   |             |
|    approx_kl             | 0.011621284 |
|    clip_fraction         | 0.182       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.4         |
|    cost_value_loss       | 7.91        |
|    cost_values           | 2.24        |
|    entropy               | 0.25        |
|    entropy_loss          | 0.251       |
|    explained_variance    | 0.843       |
|    lagrangian_multiplier | 0.00108     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.17        |
|    n_updates             | 13930       |
|    policy_gradient_loss  | 0.00647     |
|    std                   | 0.291       |
|    value_loss            | 5.7         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.28869098 |
| rollout/                 |             |
|    ep_len_mean           | 70.3        |
|    ep_rew_mean           | -31.2       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 23          |
|    time_elapsed          | 680         |
|    total_timesteps       | 2856960     |
| train/                   |             |
|    approx_kl             | 0.034226745 |
|    clip_fraction         | 0.172       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.26        |
|    cost_value_loss       | 7.81        |
|    cost_values           | 2.26        |
|    entropy               | 0.242       |
|    entropy_loss          | 0.247       |
|    explained_variance    | 0.843       |
|    lagrangian_multiplier | 0.002       |
|    learning_rate         | 0.0003      |
|    loss                  | 4.36        |
|    n_updates             | 13940       |
|    policy_gradient_loss  | 0.00852     |
|    std                   | 0.292       |
|    value_loss            | 5.3         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.29227126 |
| rollout/                 |             |
|    ep_len_mean           | 66.8        |
|    ep_rew_mean           | -29.8       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 24          |
|    time_elapsed          | 710         |
|    total_timesteps       | 2859008     |
| train/                   |             |
|    approx_kl             | 0.020543108 |
|    clip_fraction         | 0.195       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.57        |
|    cost_value_loss       | 8.73        |
|    cost_values           | 2.29        |
|    entropy               | 0.246       |
|    entropy_loss          | 0.243       |
|    explained_variance    | 0.911       |
|    lagrangian_multiplier | 0.00139     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.47        |
|    n_updates             | 13950       |
|    policy_gradient_loss  | 0.00754     |
|    std                   | 0.292       |
|    value_loss            | 3.63        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.4         |
| reward                   | -0.70502543 |
| rollout/                 |             |
|    ep_len_mean           | 62.3        |
|    ep_rew_mean           | -28.4       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 25          |
|    time_elapsed          | 740         |
|    total_timesteps       | 2861056     |
| train/                   |             |
|    approx_kl             | 0.020632537 |
|    clip_fraction         | 0.211       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.29        |
|    cost_value_loss       | 7.43        |
|    cost_values           | 2.31        |
|    entropy               | 0.248       |
|    entropy_loss          | 0.248       |
|    explained_variance    | 0.895       |
|    lagrangian_multiplier | 0.00156     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.39        |
|    n_updates             | 13960       |
|    policy_gradient_loss  | 0.0123      |
|    std                   | 0.291       |
|    value_loss            | 4.18        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.26322296 |
| rollout/                 |             |
|    ep_len_mean           | 63.1        |
|    ep_rew_mean           | -28.5       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 26          |
|    time_elapsed          | 770         |
|    total_timesteps       | 2863104     |
| train/                   |             |
|    approx_kl             | 0.017832903 |
|    clip_fraction         | 0.188       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.48        |
|    cost_value_loss       | 8.92        |
|    cost_values           | 2.25        |
|    entropy               | 0.248       |
|    entropy_loss          | 0.248       |
|    explained_variance    | 0.892       |
|    lagrangian_multiplier | 0.00062     |
|    learning_rate         | 0.0003      |
|    loss                  | 5.81        |
|    n_updates             | 13970       |
|    policy_gradient_loss  | 0.00706     |
|    std                   | 0.293       |
|    value_loss            | 3.94        |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.81615645 |
| rollout/                 |             |
|    ep_len_mean           | 61.9        |
|    ep_rew_mean           | -28.6       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 27          |
|    time_elapsed          | 800         |
|    total_timesteps       | 2865152     |
| train/                   |             |
|    approx_kl             | 0.01468376  |
|    clip_fraction         | 0.205       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.49        |
|    cost_value_loss       | 8.66        |
|    cost_values           | 2.25        |
|    entropy               | 0.254       |
|    entropy_loss          | 0.251       |
|    explained_variance    | 0.869       |
|    lagrangian_multiplier | 0.00253     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.19        |
|    n_updates             | 13980       |
|    policy_gradient_loss  | 0.00907     |
|    std                   | 0.292       |
|    value_loss            | 4.57        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.8356197  |
| rollout/                 |             |
|    ep_len_mean           | 62.9        |
|    ep_rew_mean           | -29         |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 28          |
|    time_elapsed          | 830         |
|    total_timesteps       | 2867200     |
| train/                   |             |
|    approx_kl             | 0.032752212 |
|    clip_fraction         | 0.211       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.25        |
|    cost_value_loss       | 7.53        |
|    cost_values           | 2.25        |
|    entropy               | 0.264       |
|    entropy_loss          | 0.26        |
|    explained_variance    | 0.941       |
|    lagrangian_multiplier | 0.00111     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.25        |
|    n_updates             | 13990       |
|    policy_gradient_loss  | 0.00937     |
|    std                   | 0.29        |
|    value_loss            | 2.29        |
------------------------------------------
------------------------------------------
| avg_speed                | 5           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5           |
| reward                   | -0.5814074  |
| rollout/                 |             |
|    ep_len_mean           | 63.3        |
|    ep_rew_mean           | -29.1       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 29          |
|    time_elapsed          | 860         |
|    total_timesteps       | 2869248     |
| train/                   |             |
|    approx_kl             | 0.010941358 |
|    clip_fraction         | 0.173       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.27        |
|    cost_value_loss       | 6.97        |
|    cost_values           | 2.29        |
|    entropy               | 0.263       |
|    entropy_loss          | 0.264       |
|    explained_variance    | 0.878       |
|    lagrangian_multiplier | 0.000963    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.28        |
|    n_updates             | 14000       |
|    policy_gradient_loss  | 0.00503     |
|    std                   | 0.291       |
|    value_loss            | 3.96        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.42        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.42        |
| reward                   | -0.22917248 |
| rollout/                 |             |
|    ep_len_mean           | 66.9        |
|    ep_rew_mean           | -30.3       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 30          |
|    time_elapsed          | 889         |
|    total_timesteps       | 2871296     |
| train/                   |             |
|    approx_kl             | 0.014762103 |
|    clip_fraction         | 0.25        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.01        |
|    cost_value_loss       | 6.23        |
|    cost_values           | 2.24        |
|    entropy               | 0.259       |
|    entropy_loss          | 0.261       |
|    explained_variance    | 0.869       |
|    lagrangian_multiplier | 0.00185     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.79        |
|    n_updates             | 14010       |
|    policy_gradient_loss  | 0.00649     |
|    std                   | 0.291       |
|    value_loss            | 4.39        |
------------------------------------------
------------------------------------------
| avg_speed                | 7           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 7           |
| reward                   | -0.24564703 |
| rollout/                 |             |
|    ep_len_mean           | 65.9        |
|    ep_rew_mean           | -29.6       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 31          |
|    time_elapsed          | 919         |
|    total_timesteps       | 2873344     |
| train/                   |             |
|    approx_kl             | 0.02842711  |
|    clip_fraction         | 0.148       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.53        |
|    cost_value_loss       | 8.81        |
|    cost_values           | 2.24        |
|    entropy               | 0.265       |
|    entropy_loss          | 0.261       |
|    explained_variance    | 0.879       |
|    lagrangian_multiplier | 0.00272     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.01        |
|    n_updates             | 14020       |
|    policy_gradient_loss  | -0.000681   |
|    std                   | 0.29        |
|    value_loss            | 4.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.4         |
| reward                   | -0.521087   |
| rollout/                 |             |
|    ep_len_mean           | 68.8        |
|    ep_rew_mean           | -30.4       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 32          |
|    time_elapsed          | 948         |
|    total_timesteps       | 2875392     |
| train/                   |             |
|    approx_kl             | 0.014006266 |
|    clip_fraction         | 0.177       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.22        |
|    cost_value_loss       | 6.52        |
|    cost_values           | 2.28        |
|    entropy               | 0.261       |
|    entropy_loss          | 0.264       |
|    explained_variance    | 0.878       |
|    lagrangian_multiplier | 0.00154     |
|    learning_rate         | 0.0003      |
|    loss                  | 4           |
|    n_updates             | 14030       |
|    policy_gradient_loss  | 0.00828     |
|    std                   | 0.291       |
|    value_loss            | 3.89        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.03        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.03        |
| reward                   | -0.30498052 |
| rollout/                 |             |
|    ep_len_mean           | 67.5        |
|    ep_rew_mean           | -29.6       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 33          |
|    time_elapsed          | 977         |
|    total_timesteps       | 2877440     |
| train/                   |             |
|    approx_kl             | 0.015023226 |
|    clip_fraction         | 0.174       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.12        |
|    cost_value_loss       | 6.22        |
|    cost_values           | 2.25        |
|    entropy               | 0.263       |
|    entropy_loss          | 0.262       |
|    explained_variance    | 0.857       |
|    lagrangian_multiplier | 0.00125     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.1         |
|    n_updates             | 14040       |
|    policy_gradient_loss  | 0.00622     |
|    std                   | 0.291       |
|    value_loss            | 5.19        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.36869675 |
| rollout/                 |             |
|    ep_len_mean           | 65.3        |
|    ep_rew_mean           | -29.2       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 34          |
|    time_elapsed          | 1007        |
|    total_timesteps       | 2879488     |
| train/                   |             |
|    approx_kl             | 0.031988703 |
|    clip_fraction         | 0.212       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.2         |
|    cost_value_loss       | 6.72        |
|    cost_values           | 2.28        |
|    entropy               | 0.262       |
|    entropy_loss          | 0.263       |
|    explained_variance    | 0.895       |
|    lagrangian_multiplier | 0.00137     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.03        |
|    n_updates             | 14050       |
|    policy_gradient_loss  | 0.00663     |
|    std                   | 0.291       |
|    value_loss            | 3.72        |
------------------------------------------
-----------------------------------------
| avg_speed                | 3.2        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 3.2        |
| reward                   | -0.8988365 |
| rollout/                 |            |
|    ep_len_mean           | 64         |
|    ep_rew_mean           | -28.7      |
| time/                    |            |
|    fps                   | 69         |
|    iterations            | 35         |
|    time_elapsed          | 1036       |
|    total_timesteps       | 2881536    |
| train/                   |            |
|    approx_kl             | 0.02367913 |
|    clip_fraction         | 0.227      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.5        |
|    cost_value_loss       | 8.59       |
|    cost_values           | 2.27       |
|    entropy               | 0.253      |
|    entropy_loss          | 0.258      |
|    explained_variance    | 0.893      |
|    lagrangian_multiplier | 0.00101    |
|    learning_rate         | 0.0003     |
|    loss                  | 4.73       |
|    n_updates             | 14060      |
|    policy_gradient_loss  | 0.0068     |
|    std                   | 0.293      |
|    value_loss            | 3.74       |
-----------------------------------------
-----------------------------------------
| avg_speed                | 7.92       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 7.92       |
| reward                   | -0.2299033 |
| rollout/                 |            |
|    ep_len_mean           | 64.4       |
|    ep_rew_mean           | -28.7      |
| time/                    |            |
|    fps                   | 69         |
|    iterations            | 36         |
|    time_elapsed          | 1066       |
|    total_timesteps       | 2883584    |
| train/                   |            |
|    approx_kl             | 0.03809005 |
|    clip_fraction         | 0.185      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.27       |
|    cost_value_loss       | 7.63       |
|    cost_values           | 2.26       |
|    entropy               | 0.248      |
|    entropy_loss          | 0.25       |
|    explained_variance    | 0.921      |
|    lagrangian_multiplier | 0.000314   |
|    learning_rate         | 0.0003     |
|    loss                  | 4.87       |
|    n_updates             | 14070      |
|    policy_gradient_loss  | 0.00765    |
|    std                   | 0.295      |
|    value_loss            | 2.98       |
-----------------------------------------
-----------------------------------------
| avg_speed                | 3.2        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 3.2        |
| reward                   | -0.9422474 |
| rollout/                 |            |
|    ep_len_mean           | 66.1       |
|    ep_rew_mean           | -29.1      |
| time/                    |            |
|    fps                   | 69         |
|    iterations            | 37         |
|    time_elapsed          | 1096       |
|    total_timesteps       | 2885632    |
| train/                   |            |
|    approx_kl             | 0.03249132 |
|    clip_fraction         | 0.22       |
|    clip_range            | 0.2        |
|    cost_returns          | 4.45       |
|    cost_value_loss       | 8.14       |
|    cost_values           | 2.26       |
|    entropy               | 0.249      |
|    entropy_loss          | 0.248      |
|    explained_variance    | 0.887      |
|    lagrangian_multiplier | 0.00152    |
|    learning_rate         | 0.0003     |
|    loss                  | 4.48       |
|    n_updates             | 14080      |
|    policy_gradient_loss  | 0.0106     |
|    std                   | 0.294      |
|    value_loss            | 3.66       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.31410664 |
| rollout/                 |             |
|    ep_len_mean           | 66.8        |
|    ep_rew_mean           | -29.4       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 38          |
|    time_elapsed          | 1126        |
|    total_timesteps       | 2887680     |
| train/                   |             |
|    approx_kl             | 0.024066105 |
|    clip_fraction         | 0.199       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.37        |
|    cost_value_loss       | 7.8         |
|    cost_values           | 2.27        |
|    entropy               | 0.256       |
|    entropy_loss          | 0.252       |
|    explained_variance    | 0.909       |
|    lagrangian_multiplier | 0.000601    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.02        |
|    n_updates             | 14090       |
|    policy_gradient_loss  | 0.0112      |
|    std                   | 0.292       |
|    value_loss            | 3.62        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.51953864 |
| rollout/                 |             |
|    ep_len_mean           | 67.8        |
|    ep_rew_mean           | -29.8       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 39          |
|    time_elapsed          | 1155        |
|    total_timesteps       | 2889728     |
| train/                   |             |
|    approx_kl             | 0.026282044 |
|    clip_fraction         | 0.178       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.13        |
|    cost_value_loss       | 6.89        |
|    cost_values           | 2.25        |
|    entropy               | 0.257       |
|    entropy_loss          | 0.257       |
|    explained_variance    | 0.901       |
|    lagrangian_multiplier | 0.00117     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.16        |
|    n_updates             | 14100       |
|    policy_gradient_loss  | 0.00599     |
|    std                   | 0.291       |
|    value_loss            | 3.67        |
------------------------------------------
------------------------------------------
| avg_speed                | 5           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5           |
| reward                   | -0.44382048 |
| rollout/                 |             |
|    ep_len_mean           | 68.1        |
|    ep_rew_mean           | -29.7       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 40          |
|    time_elapsed          | 1185        |
|    total_timesteps       | 2891776     |
| train/                   |             |
|    approx_kl             | 0.014562001 |
|    clip_fraction         | 0.19        |
|    clip_range            | 0.2         |
|    cost_returns          | 4.1         |
|    cost_value_loss       | 6.5         |
|    cost_values           | 2.24        |
|    entropy               | 0.256       |
|    entropy_loss          | 0.257       |
|    explained_variance    | 0.855       |
|    lagrangian_multiplier | 0.00116     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.55        |
|    n_updates             | 14110       |
|    policy_gradient_loss  | 0.00676     |
|    std                   | 0.291       |
|    value_loss            | 4.84        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.2         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.2         |
| reward                   | -0.63152736 |
| rollout/                 |             |
|    ep_len_mean           | 70.1        |
|    ep_rew_mean           | -30.1       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 41          |
|    time_elapsed          | 1215        |
|    total_timesteps       | 2893824     |
| train/                   |             |
|    approx_kl             | 0.017142642 |
|    clip_fraction         | 0.181       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.17        |
|    cost_value_loss       | 6.93        |
|    cost_values           | 2.22        |
|    entropy               | 0.261       |
|    entropy_loss          | 0.259       |
|    explained_variance    | 0.858       |
|    lagrangian_multiplier | 0.00284     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.71        |
|    n_updates             | 14120       |
|    policy_gradient_loss  | 0.00563     |
|    std                   | 0.29        |
|    value_loss            | 4.27        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.23265736 |
| rollout/                 |             |
|    ep_len_mean           | 73.8        |
|    ep_rew_mean           | -31.3       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 42          |
|    time_elapsed          | 1245        |
|    total_timesteps       | 2895872     |
| train/                   |             |
|    approx_kl             | 0.017338322 |
|    clip_fraction         | 0.228       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.37        |
|    cost_value_loss       | 7.82        |
|    cost_values           | 2.24        |
|    entropy               | 0.265       |
|    entropy_loss          | 0.264       |
|    explained_variance    | 0.88        |
|    lagrangian_multiplier | 0.000943    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.57        |
|    n_updates             | 14130       |
|    policy_gradient_loss  | 0.0132      |
|    std                   | 0.29        |
|    value_loss            | 4.2         |
------------------------------------------
------------------------------------------
| avg_speed                | 2.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2.6         |
| reward                   | -0.8877328  |
| rollout/                 |             |
|    ep_len_mean           | 74.3        |
|    ep_rew_mean           | -31.6       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 43          |
|    time_elapsed          | 1275        |
|    total_timesteps       | 2897920     |
| train/                   |             |
|    approx_kl             | 0.030761966 |
|    clip_fraction         | 0.197       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.38        |
|    cost_value_loss       | 7.36        |
|    cost_values           | 2.27        |
|    entropy               | 0.269       |
|    entropy_loss          | 0.267       |
|    explained_variance    | 0.829       |
|    lagrangian_multiplier | 0.000745    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.98        |
|    n_updates             | 14140       |
|    policy_gradient_loss  | 0.00796     |
|    std                   | 0.29        |
|    value_loss            | 5.3         |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.2620287  |
| rollout/                 |             |
|    ep_len_mean           | 73          |
|    ep_rew_mean           | -31.3       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 44          |
|    time_elapsed          | 1304        |
|    total_timesteps       | 2899968     |
| train/                   |             |
|    approx_kl             | 0.033935815 |
|    clip_fraction         | 0.227       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.46        |
|    cost_value_loss       | 7.89        |
|    cost_values           | 2.3         |
|    entropy               | 0.265       |
|    entropy_loss          | 0.268       |
|    explained_variance    | 0.827       |
|    lagrangian_multiplier | 0.00166     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.82        |
|    n_updates             | 14150       |
|    policy_gradient_loss  | 0.0128      |
|    std                   | 0.291       |
|    value_loss            | 5.73        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.8         |
| reward                   | -0.40543294 |
| rollout/                 |             |
|    ep_len_mean           | 69.3        |
|    ep_rew_mean           | -30.4       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 45          |
|    time_elapsed          | 1334        |
|    total_timesteps       | 2902016     |
| train/                   |             |
|    approx_kl             | 0.022668447 |
|    clip_fraction         | 0.203       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.14        |
|    cost_value_loss       | 6.52        |
|    cost_values           | 2.27        |
|    entropy               | 0.262       |
|    entropy_loss          | 0.263       |
|    explained_variance    | 0.848       |
|    lagrangian_multiplier | 0.000426    |
|    learning_rate         | 0.0003      |
|    loss                  | 5           |
|    n_updates             | 14160       |
|    policy_gradient_loss  | 0.00461     |
|    std                   | 0.291       |
|    value_loss            | 5.15        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.4         |
| reward                   | -0.19116913 |
| rollout/                 |             |
|    ep_len_mean           | 63.8        |
|    ep_rew_mean           | -28.6       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 46          |
|    time_elapsed          | 1363        |
|    total_timesteps       | 2904064     |
| train/                   |             |
|    approx_kl             | 0.012076486 |
|    clip_fraction         | 0.206       |
|    clip_range            | 0.2         |
|    cost_returns          | 4           |
|    cost_value_loss       | 6.58        |
|    cost_values           | 2.22        |
|    entropy               | 0.259       |
|    entropy_loss          | 0.26        |
|    explained_variance    | 0.871       |
|    lagrangian_multiplier | 0.000407    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.26        |
|    n_updates             | 14170       |
|    policy_gradient_loss  | 0.00837     |
|    std                   | 0.291       |
|    value_loss            | 4.99        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.4154881  |
| rollout/                 |             |
|    ep_len_mean           | 62.7        |
|    ep_rew_mean           | -28.4       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 47          |
|    time_elapsed          | 1393        |
|    total_timesteps       | 2906112     |
| train/                   |             |
|    approx_kl             | 0.017155001 |
|    clip_fraction         | 0.192       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.96        |
|    cost_value_loss       | 6.31        |
|    cost_values           | 2.17        |
|    entropy               | 0.249       |
|    entropy_loss          | 0.256       |
|    explained_variance    | 0.822       |
|    lagrangian_multiplier | 0.000277    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.43        |
|    n_updates             | 14180       |
|    policy_gradient_loss  | 0.00471     |
|    std                   | 0.294       |
|    value_loss            | 5.82        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.4         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 4.4         |
| reward                   | -0.58109415 |
| rollout/                 |             |
|    ep_len_mean           | 63.9        |
|    ep_rew_mean           | -28.7       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 48          |
|    time_elapsed          | 1422        |
|    total_timesteps       | 2908160     |
| train/                   |             |
|    approx_kl             | 0.013979366 |
|    clip_fraction         | 0.143       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.02        |
|    cost_value_loss       | 6.23        |
|    cost_values           | 2.19        |
|    entropy               | 0.251       |
|    entropy_loss          | 0.248       |
|    explained_variance    | 0.841       |
|    lagrangian_multiplier | 0.00106     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.59        |
|    n_updates             | 14190       |
|    policy_gradient_loss  | 0.00264     |
|    std                   | 0.294       |
|    value_loss            | 5.61        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.25313818 |
| rollout/                 |             |
|    ep_len_mean           | 65.3        |
|    ep_rew_mean           | -29.3       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 49          |
|    time_elapsed          | 1451        |
|    total_timesteps       | 2910208     |
| train/                   |             |
|    approx_kl             | 0.012267135 |
|    clip_fraction         | 0.151       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.26        |
|    cost_value_loss       | 7.89        |
|    cost_values           | 2.23        |
|    entropy               | 0.25        |
|    entropy_loss          | 0.251       |
|    explained_variance    | 0.877       |
|    lagrangian_multiplier | 0.00127     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.35        |
|    n_updates             | 14200       |
|    policy_gradient_loss  | 0.00558     |
|    std                   | 0.295       |
|    value_loss            | 4.29        |
------------------------------------------
------------------------------------
| avg_speed          | 5           |
| cost               | 1           |
| is_success         | 0           |
| max_speed          | 5           |
| reward             | -0.39117345 |
| rollout/           |             |
|    ep_len_mean     | 67.1        |
|    ep_rew_mean     | -30         |
| time/              |             |
|    fps             | 75          |
|    iterations      | 1           |
|    time_elapsed    | 27          |
|    total_timesteps | 2912256     |
------------------------------------
------------------------------------------
| avg_speed                | 8.01        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.01        |
| reward                   | -0.19237445 |
| rollout/                 |             |
|    ep_len_mean           | 65.7        |
|    ep_rew_mean           | -29.5       |
| time/                    |             |
|    fps                   | 71          |
|    iterations            | 2           |
|    time_elapsed          | 56          |
|    total_timesteps       | 2914304     |
| train/                   |             |
|    approx_kl             | 0.021813365 |
|    clip_fraction         | 0.198       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.27        |
|    cost_value_loss       | 7.34        |
|    cost_values           | 2.21        |
|    entropy               | 0.255       |
|    entropy_loss          | 0.253       |
|    explained_variance    | 0.796       |
|    lagrangian_multiplier | 0.000966    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.51        |
|    n_updates             | 14220       |
|    policy_gradient_loss  | 0.01        |
|    std                   | 0.294       |
|    value_loss            | 6.31        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8          |
| cost                     | 1          |
| is_success               | 0          |
| max_speed                | 8          |
| reward                   | -0.302724  |
| rollout/                 |            |
|    ep_len_mean           | 65         |
|    ep_rew_mean           | -29.3      |
| time/                    |            |
|    fps                   | 70         |
|    iterations            | 3          |
|    time_elapsed          | 86         |
|    total_timesteps       | 2916352    |
| train/                   |            |
|    approx_kl             | 0.01708968 |
|    clip_fraction         | 0.142      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.26       |
|    cost_value_loss       | 7.52       |
|    cost_values           | 2.23       |
|    entropy               | 0.261      |
|    entropy_loss          | 0.258      |
|    explained_variance    | 0.869      |
|    lagrangian_multiplier | 0.00248    |
|    learning_rate         | 0.0003     |
|    loss                  | 3.86       |
|    n_updates             | 14230      |
|    policy_gradient_loss  | 0.00377    |
|    std                   | 0.294      |
|    value_loss            | 4.66       |
-----------------------------------------
------------------------------------------
| avg_speed                | 1.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.6         |
| reward                   | -0.71166694 |
| rollout/                 |             |
|    ep_len_mean           | 62          |
|    ep_rew_mean           | -28.3       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 4           |
|    time_elapsed          | 116         |
|    total_timesteps       | 2918400     |
| train/                   |             |
|    approx_kl             | 0.03775168  |
|    clip_fraction         | 0.174       |
|    clip_range            | 0.2         |
|    cost_returns          | 4           |
|    cost_value_loss       | 6.52        |
|    cost_values           | 2.22        |
|    entropy               | 0.265       |
|    entropy_loss          | 0.263       |
|    explained_variance    | 0.861       |
|    lagrangian_multiplier | 0.000705    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.34        |
|    n_updates             | 14240       |
|    policy_gradient_loss  | 0.00691     |
|    std                   | 0.294       |
|    value_loss            | 4.43        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.4         |
| reward                   | -0.65387857 |
| rollout/                 |             |
|    ep_len_mean           | 63.6        |
|    ep_rew_mean           | -28.7       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 5           |
|    time_elapsed          | 145         |
|    total_timesteps       | 2920448     |
| train/                   |             |
|    approx_kl             | 0.040436335 |
|    clip_fraction         | 0.184       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.24        |
|    cost_value_loss       | 7.49        |
|    cost_values           | 2.25        |
|    entropy               | 0.274       |
|    entropy_loss          | 0.27        |
|    explained_variance    | 0.906       |
|    lagrangian_multiplier | 0.001       |
|    learning_rate         | 0.0003      |
|    loss                  | 4.54        |
|    n_updates             | 14250       |
|    policy_gradient_loss  | 0.00822     |
|    std                   | 0.293       |
|    value_loss            | 3.23        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.30978513 |
| rollout/                 |             |
|    ep_len_mean           | 62          |
|    ep_rew_mean           | -27.7       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 6           |
|    time_elapsed          | 175         |
|    total_timesteps       | 2922496     |
| train/                   |             |
|    approx_kl             | 0.02768233  |
|    clip_fraction         | 0.242       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.16        |
|    cost_value_loss       | 6.83        |
|    cost_values           | 2.26        |
|    entropy               | 0.275       |
|    entropy_loss          | 0.275       |
|    explained_variance    | 0.915       |
|    lagrangian_multiplier | 0.000993    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.1         |
|    n_updates             | 14260       |
|    policy_gradient_loss  | 0.0102      |
|    std                   | 0.293       |
|    value_loss            | 2.94        |
------------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.56615037 |
| rollout/                 |             |
|    ep_len_mean           | 63.9        |
|    ep_rew_mean           | -28.3       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 7           |
|    time_elapsed          | 204         |
|    total_timesteps       | 2924544     |
| train/                   |             |
|    approx_kl             | 0.05088451  |
|    clip_fraction         | 0.211       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.19        |
|    cost_value_loss       | 6.66        |
|    cost_values           | 2.29        |
|    entropy               | 0.276       |
|    entropy_loss          | 0.274       |
|    explained_variance    | 0.902       |
|    lagrangian_multiplier | 0.00236     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.55        |
|    n_updates             | 14270       |
|    policy_gradient_loss  | 0.0117      |
|    std                   | 0.294       |
|    value_loss            | 3.16        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.22867575 |
| rollout/                 |             |
|    ep_len_mean           | 62.8        |
|    ep_rew_mean           | -27.9       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 8           |
|    time_elapsed          | 233         |
|    total_timesteps       | 2926592     |
| train/                   |             |
|    approx_kl             | 0.017279414 |
|    clip_fraction         | 0.188       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.23        |
|    cost_value_loss       | 7.32        |
|    cost_values           | 2.28        |
|    entropy               | 0.276       |
|    entropy_loss          | 0.277       |
|    explained_variance    | 0.913       |
|    lagrangian_multiplier | 0.00227     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.67        |
|    n_updates             | 14280       |
|    policy_gradient_loss  | 0.00272     |
|    std                   | 0.295       |
|    value_loss            | 3.32        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.8         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.8         |
| reward                   | -0.29185203 |
| rollout/                 |             |
|    ep_len_mean           | 65.9        |
|    ep_rew_mean           | -29.3       |
| time/                    |             |
|    fps                   | 70          |
|    iterations            | 9           |
|    time_elapsed          | 263         |
|    total_timesteps       | 2928640     |
| train/                   |             |
|    approx_kl             | 0.026460748 |
|    clip_fraction         | 0.214       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.02        |
|    cost_value_loss       | 5.73        |
|    cost_values           | 2.27        |
|    entropy               | 0.273       |
|    entropy_loss          | 0.274       |
|    explained_variance    | 0.891       |
|    lagrangian_multiplier | 0.00164     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.39        |
|    n_updates             | 14290       |
|    policy_gradient_loss  | 0.0127      |
|    std                   | 0.295       |
|    value_loss            | 3.5         |
------------------------------------------
------------------------------------------
| avg_speed                | 1.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1.8         |
| reward                   | -0.8984339  |
| rollout/                 |             |
|    ep_len_mean           | 62.9        |
|    ep_rew_mean           | -28.4       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 10          |
|    time_elapsed          | 293         |
|    total_timesteps       | 2930688     |
| train/                   |             |
|    approx_kl             | 0.013328254 |
|    clip_fraction         | 0.181       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.39        |
|    cost_value_loss       | 7.64        |
|    cost_values           | 2.25        |
|    entropy               | 0.268       |
|    entropy_loss          | 0.271       |
|    explained_variance    | 0.877       |
|    lagrangian_multiplier | 0.00171     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.2         |
|    n_updates             | 14300       |
|    policy_gradient_loss  | 0.00405     |
|    std                   | 0.298       |
|    value_loss            | 3.93        |
------------------------------------------
-----------------------------------------
| avg_speed                | 2.6        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 2.6        |
| reward                   | -0.9317025 |
| rollout/                 |            |
|    ep_len_mean           | 63.5       |
|    ep_rew_mean           | -28.6      |
| time/                    |            |
|    fps                   | 69         |
|    iterations            | 11         |
|    time_elapsed          | 323        |
|    total_timesteps       | 2932736    |
| train/                   |            |
|    approx_kl             | 0.07256541 |
|    clip_fraction         | 0.176      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.28       |
|    cost_value_loss       | 7.54       |
|    cost_values           | 2.27       |
|    entropy               | 0.272      |
|    entropy_loss          | 0.268      |
|    explained_variance    | 0.885      |
|    lagrangian_multiplier | 0.00181    |
|    learning_rate         | 0.0003     |
|    loss                  | 4.06       |
|    n_updates             | 14310      |
|    policy_gradient_loss  | 0.0015     |
|    std                   | 0.297      |
|    value_loss            | 3.99       |
-----------------------------------------
------------------------------------------
| avg_speed                | 6           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6           |
| reward                   | -0.34948006 |
| rollout/                 |             |
|    ep_len_mean           | 64.1        |
|    ep_rew_mean           | -28.9       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 12          |
|    time_elapsed          | 352         |
|    total_timesteps       | 2934784     |
| train/                   |             |
|    approx_kl             | 0.014668917 |
|    clip_fraction         | 0.203       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.38        |
|    cost_value_loss       | 7.83        |
|    cost_values           | 2.26        |
|    entropy               | 0.274       |
|    entropy_loss          | 0.274       |
|    explained_variance    | 0.866       |
|    lagrangian_multiplier | 0.000576    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.07        |
|    n_updates             | 14320       |
|    policy_gradient_loss  | 0.00785     |
|    std                   | 0.297       |
|    value_loss            | 4.26        |
------------------------------------------
------------------------------------------
| avg_speed                | 6           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6           |
| reward                   | -0.18076976 |
| rollout/                 |             |
|    ep_len_mean           | 67.5        |
|    ep_rew_mean           | -29.8       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 13          |
|    time_elapsed          | 381         |
|    total_timesteps       | 2936832     |
| train/                   |             |
|    approx_kl             | 0.015183168 |
|    clip_fraction         | 0.203       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.09        |
|    cost_value_loss       | 7.03        |
|    cost_values           | 2.26        |
|    entropy               | 0.275       |
|    entropy_loss          | 0.274       |
|    explained_variance    | 0.881       |
|    lagrangian_multiplier | 0.000563    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.79        |
|    n_updates             | 14330       |
|    policy_gradient_loss  | 0.00893     |
|    std                   | 0.296       |
|    value_loss            | 4.19        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 5.8         |
| reward                   | -0.4969088  |
| rollout/                 |             |
|    ep_len_mean           | 68.8        |
|    ep_rew_mean           | -30.3       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 14          |
|    time_elapsed          | 412         |
|    total_timesteps       | 2938880     |
| train/                   |             |
|    approx_kl             | 0.035390895 |
|    clip_fraction         | 0.203       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.22        |
|    cost_value_loss       | 6.79        |
|    cost_values           | 2.23        |
|    entropy               | 0.286       |
|    entropy_loss          | 0.281       |
|    explained_variance    | 0.809       |
|    lagrangian_multiplier | 0.000777    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.56        |
|    n_updates             | 14340       |
|    policy_gradient_loss  | 0.000773    |
|    std                   | 0.295       |
|    value_loss            | 4.89        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.8         |
| reward                   | -0.71210676 |
| rollout/                 |             |
|    ep_len_mean           | 68.7        |
|    ep_rew_mean           | -30.2       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 15          |
|    time_elapsed          | 441         |
|    total_timesteps       | 2940928     |
| train/                   |             |
|    approx_kl             | 0.035948202 |
|    clip_fraction         | 0.192       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.1         |
|    cost_value_loss       | 6.11        |
|    cost_values           | 2.24        |
|    entropy               | 0.29        |
|    entropy_loss          | 0.288       |
|    explained_variance    | 0.804       |
|    lagrangian_multiplier | 0.00213     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.41        |
|    n_updates             | 14350       |
|    policy_gradient_loss  | 0.00775     |
|    std                   | 0.294       |
|    value_loss            | 6.59        |
------------------------------------------
------------------------------------------
| avg_speed                | 5.6         |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 5.6         |
| reward                   | -0.27483767 |
| rollout/                 |             |
|    ep_len_mean           | 64.1        |
|    ep_rew_mean           | -28.8       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 16          |
|    time_elapsed          | 470         |
|    total_timesteps       | 2942976     |
| train/                   |             |
|    approx_kl             | 0.016008455 |
|    clip_fraction         | 0.138       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.74        |
|    cost_value_loss       | 5.46        |
|    cost_values           | 2.18        |
|    entropy               | 0.285       |
|    entropy_loss          | 0.288       |
|    explained_variance    | 0.855       |
|    lagrangian_multiplier | 0.000671    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.32        |
|    n_updates             | 14360       |
|    policy_gradient_loss  | 0.00324     |
|    std                   | 0.295       |
|    value_loss            | 4.99        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.4         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.4         |
| reward                   | -0.8112738  |
| rollout/                 |             |
|    ep_len_mean           | 65.3        |
|    ep_rew_mean           | -28.9       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 17          |
|    time_elapsed          | 499         |
|    total_timesteps       | 2945024     |
| train/                   |             |
|    approx_kl             | 0.018321738 |
|    clip_fraction         | 0.164       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.13        |
|    cost_value_loss       | 6.99        |
|    cost_values           | 2.2         |
|    entropy               | 0.281       |
|    entropy_loss          | 0.283       |
|    explained_variance    | 0.862       |
|    lagrangian_multiplier | 0.0011      |
|    learning_rate         | 0.0003      |
|    loss                  | 4.32        |
|    n_updates             | 14370       |
|    policy_gradient_loss  | 0.00534     |
|    std                   | 0.295       |
|    value_loss            | 4.48        |
------------------------------------------
------------------------------------------
| avg_speed                | 0.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.8         |
| reward                   | -0.7185601  |
| rollout/                 |             |
|    ep_len_mean           | 67.2        |
|    ep_rew_mean           | -29.3       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 18          |
|    time_elapsed          | 528         |
|    total_timesteps       | 2947072     |
| train/                   |             |
|    approx_kl             | 0.019648535 |
|    clip_fraction         | 0.179       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.17        |
|    cost_value_loss       | 6.69        |
|    cost_values           | 2.17        |
|    entropy               | 0.282       |
|    entropy_loss          | 0.281       |
|    explained_variance    | 0.828       |
|    lagrangian_multiplier | 0.00155     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.62        |
|    n_updates             | 14380       |
|    policy_gradient_loss  | 0.00531     |
|    std                   | 0.296       |
|    value_loss            | 5.25        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.6         |
| reward                   | -0.29782268 |
| rollout/                 |             |
|    ep_len_mean           | 69.1        |
|    ep_rew_mean           | -29.8       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 19          |
|    time_elapsed          | 557         |
|    total_timesteps       | 2949120     |
| train/                   |             |
|    approx_kl             | 0.022439137 |
|    clip_fraction         | 0.203       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.27        |
|    cost_value_loss       | 7.79        |
|    cost_values           | 2.15        |
|    entropy               | 0.283       |
|    entropy_loss          | 0.283       |
|    explained_variance    | 0.743       |
|    lagrangian_multiplier | 0.00158     |
|    learning_rate         | 0.0003      |
|    loss                  | 5           |
|    n_updates             | 14390       |
|    policy_gradient_loss  | 0.0042      |
|    std                   | 0.295       |
|    value_loss            | 7.22        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.67        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 6.67        |
| reward                   | -0.12454258 |
| rollout/                 |             |
|    ep_len_mean           | 71.4        |
|    ep_rew_mean           | -30.7       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 20          |
|    time_elapsed          | 586         |
|    total_timesteps       | 2951168     |
| train/                   |             |
|    approx_kl             | 0.012546897 |
|    clip_fraction         | 0.163       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.11        |
|    cost_value_loss       | 6.4         |
|    cost_values           | 2.17        |
|    entropy               | 0.283       |
|    entropy_loss          | 0.282       |
|    explained_variance    | 0.827       |
|    lagrangian_multiplier | 0.00129     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.23        |
|    n_updates             | 14400       |
|    policy_gradient_loss  | -0.00118    |
|    std                   | 0.296       |
|    value_loss            | 5.44        |
------------------------------------------
------------------------------------------
| avg_speed                | 2           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 2           |
| reward                   | -0.791272   |
| rollout/                 |             |
|    ep_len_mean           | 63.6        |
|    ep_rew_mean           | -28.5       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 21          |
|    time_elapsed          | 616         |
|    total_timesteps       | 2953216     |
| train/                   |             |
|    approx_kl             | 0.010821555 |
|    clip_fraction         | 0.185       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.35        |
|    cost_value_loss       | 8.67        |
|    cost_values           | 2.2         |
|    entropy               | 0.287       |
|    entropy_loss          | 0.285       |
|    explained_variance    | 0.846       |
|    lagrangian_multiplier | 0.00177     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.84        |
|    n_updates             | 14410       |
|    policy_gradient_loss  | 0.0112      |
|    std                   | 0.296       |
|    value_loss            | 5.38        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.35        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.35        |
| reward                   | -0.3156726  |
| rollout/                 |             |
|    ep_len_mean           | 65.2        |
|    ep_rew_mean           | -29.2       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 22          |
|    time_elapsed          | 646         |
|    total_timesteps       | 2955264     |
| train/                   |             |
|    approx_kl             | 0.027307699 |
|    clip_fraction         | 0.221       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.15        |
|    cost_value_loss       | 7.25        |
|    cost_values           | 2.23        |
|    entropy               | 0.288       |
|    entropy_loss          | 0.288       |
|    explained_variance    | 0.879       |
|    lagrangian_multiplier | 0.00156     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.35        |
|    n_updates             | 14420       |
|    policy_gradient_loss  | 0.0105      |
|    std                   | 0.296       |
|    value_loss            | 4.48        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.7         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.7         |
| reward                   | -0.17581746 |
| rollout/                 |             |
|    ep_len_mean           | 62.5        |
|    ep_rew_mean           | -28.3       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 23          |
|    time_elapsed          | 675         |
|    total_timesteps       | 2957312     |
| train/                   |             |
|    approx_kl             | 0.040387552 |
|    clip_fraction         | 0.178       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.02        |
|    cost_value_loss       | 6.91        |
|    cost_values           | 2.18        |
|    entropy               | 0.287       |
|    entropy_loss          | 0.287       |
|    explained_variance    | 0.834       |
|    lagrangian_multiplier | 0.00172     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.45        |
|    n_updates             | 14430       |
|    policy_gradient_loss  | 0.00765     |
|    std                   | 0.297       |
|    value_loss            | 5.48        |
------------------------------------------
-----------------------------------------
| avg_speed                | 1.8        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 1.8        |
| reward                   | -0.850402  |
| rollout/                 |            |
|    ep_len_mean           | 65.8       |
|    ep_rew_mean           | -29.6      |
| time/                    |            |
|    fps                   | 69         |
|    iterations            | 24         |
|    time_elapsed          | 705        |
|    total_timesteps       | 2959360    |
| train/                   |            |
|    approx_kl             | 0.03760367 |
|    clip_fraction         | 0.167      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.07       |
|    cost_value_loss       | 6.94       |
|    cost_values           | 2.18       |
|    entropy               | 0.286      |
|    entropy_loss          | 0.286      |
|    explained_variance    | 0.873      |
|    lagrangian_multiplier | 0.000983   |
|    learning_rate         | 0.0003     |
|    loss                  | 4.56       |
|    n_updates             | 14440      |
|    policy_gradient_loss  | 0.00721    |
|    std                   | 0.297      |
|    value_loss            | 4.48       |
-----------------------------------------
------------------------------------------
| avg_speed                | 4.8         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.8         |
| reward                   | -0.5696101  |
| rollout/                 |             |
|    ep_len_mean           | 62.5        |
|    ep_rew_mean           | -28.7       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 25          |
|    time_elapsed          | 735         |
|    total_timesteps       | 2961408     |
| train/                   |             |
|    approx_kl             | 0.021845207 |
|    clip_fraction         | 0.217       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.01        |
|    cost_value_loss       | 6.63        |
|    cost_values           | 2.17        |
|    entropy               | 0.285       |
|    entropy_loss          | 0.285       |
|    explained_variance    | 0.885       |
|    lagrangian_multiplier | 0.000868    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.45        |
|    n_updates             | 14450       |
|    policy_gradient_loss  | 0.00487     |
|    std                   | 0.298       |
|    value_loss            | 4.27        |
------------------------------------------
-----------------------------------------
| avg_speed                | 1.2        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 1.2        |
| reward                   | -0.8984576 |
| rollout/                 |            |
|    ep_len_mean           | 64         |
|    ep_rew_mean           | -29.4      |
| time/                    |            |
|    fps                   | 69         |
|    iterations            | 26         |
|    time_elapsed          | 765        |
|    total_timesteps       | 2963456    |
| train/                   |            |
|    approx_kl             | 0.04772038 |
|    clip_fraction         | 0.227      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.34       |
|    cost_value_loss       | 8.34       |
|    cost_values           | 2.15       |
|    entropy               | 0.29       |
|    entropy_loss          | 0.288      |
|    explained_variance    | 0.869      |
|    lagrangian_multiplier | 0.000914   |
|    learning_rate         | 0.0003     |
|    loss                  | 4.82       |
|    n_updates             | 14460      |
|    policy_gradient_loss  | 0.00967    |
|    std                   | 0.297      |
|    value_loss            | 4.47       |
-----------------------------------------
------------------------------------------
| avg_speed                | 0.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 0.6         |
| reward                   | -0.65872633 |
| rollout/                 |             |
|    ep_len_mean           | 65.3        |
|    ep_rew_mean           | -29.7       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 27          |
|    time_elapsed          | 795         |
|    total_timesteps       | 2965504     |
| train/                   |             |
|    approx_kl             | 0.023549523 |
|    clip_fraction         | 0.194       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.19        |
|    cost_value_loss       | 7.68        |
|    cost_values           | 2.17        |
|    entropy               | 0.294       |
|    entropy_loss          | 0.292       |
|    explained_variance    | 0.892       |
|    lagrangian_multiplier | 0.00141     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.35        |
|    n_updates             | 14470       |
|    policy_gradient_loss  | 0.00174     |
|    std                   | 0.296       |
|    value_loss            | 4.14        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.28213382 |
| rollout/                 |             |
|    ep_len_mean           | 63.9        |
|    ep_rew_mean           | -29.1       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 28          |
|    time_elapsed          | 825         |
|    total_timesteps       | 2967552     |
| train/                   |             |
|    approx_kl             | 0.033934865 |
|    clip_fraction         | 0.249       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.19        |
|    cost_value_loss       | 7.34        |
|    cost_values           | 2.19        |
|    entropy               | 0.295       |
|    entropy_loss          | 0.294       |
|    explained_variance    | 0.9         |
|    lagrangian_multiplier | 0.00296     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.56        |
|    n_updates             | 14480       |
|    policy_gradient_loss  | 0.0174      |
|    std                   | 0.297       |
|    value_loss            | 3.65        |
------------------------------------------
------------------------------------------
| avg_speed                | 7.98        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 7.98        |
| reward                   | -0.20168859 |
| rollout/                 |             |
|    ep_len_mean           | 61.9        |
|    ep_rew_mean           | -27.9       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 29          |
|    time_elapsed          | 855         |
|    total_timesteps       | 2969600     |
| train/                   |             |
|    approx_kl             | 0.037581056 |
|    clip_fraction         | 0.194       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.18        |
|    cost_value_loss       | 7.06        |
|    cost_values           | 2.19        |
|    entropy               | 0.297       |
|    entropy_loss          | 0.296       |
|    explained_variance    | 0.891       |
|    lagrangian_multiplier | 0.00125     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.38        |
|    n_updates             | 14490       |
|    policy_gradient_loss  | 0.0107      |
|    std                   | 0.296       |
|    value_loss            | 4.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 4.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 4.6         |
| reward                   | -0.5774599  |
| rollout/                 |             |
|    ep_len_mean           | 60.5        |
|    ep_rew_mean           | -27.4       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 30          |
|    time_elapsed          | 885         |
|    total_timesteps       | 2971648     |
| train/                   |             |
|    approx_kl             | 0.018885681 |
|    clip_fraction         | 0.228       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.03        |
|    cost_value_loss       | 6.85        |
|    cost_values           | 2.21        |
|    entropy               | 0.298       |
|    entropy_loss          | 0.297       |
|    explained_variance    | 0.888       |
|    lagrangian_multiplier | 0.00121     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.15        |
|    n_updates             | 14500       |
|    policy_gradient_loss  | 0.0134      |
|    std                   | 0.295       |
|    value_loss            | 3.61        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.30153754 |
| rollout/                 |             |
|    ep_len_mean           | 62          |
|    ep_rew_mean           | -27.9       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 31          |
|    time_elapsed          | 914         |
|    total_timesteps       | 2973696     |
| train/                   |             |
|    approx_kl             | 0.02314862  |
|    clip_fraction         | 0.162       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.31        |
|    cost_value_loss       | 8.23        |
|    cost_values           | 2.21        |
|    entropy               | 0.301       |
|    entropy_loss          | 0.299       |
|    explained_variance    | 0.908       |
|    lagrangian_multiplier | 0.00191     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.95        |
|    n_updates             | 14510       |
|    policy_gradient_loss  | 0.00202     |
|    std                   | 0.296       |
|    value_loss            | 3.34        |
------------------------------------------
-----------------------------------------
| avg_speed                | 4.6        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 4.6        |
| reward                   | -0.5836254 |
| rollout/                 |            |
|    ep_len_mean           | 62.4       |
|    ep_rew_mean           | -28.7      |
| time/                    |            |
|    fps                   | 69         |
|    iterations            | 32         |
|    time_elapsed          | 944        |
|    total_timesteps       | 2975744    |
| train/                   |            |
|    approx_kl             | 0.03365734 |
|    clip_fraction         | 0.224      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.14       |
|    cost_value_loss       | 6.9        |
|    cost_values           | 2.2        |
|    entropy               | 0.305      |
|    entropy_loss          | 0.304      |
|    explained_variance    | 0.89       |
|    lagrangian_multiplier | 0.000784   |
|    learning_rate         | 0.0003     |
|    loss                  | 4.41       |
|    n_updates             | 14520      |
|    policy_gradient_loss  | 0.0124     |
|    std                   | 0.295      |
|    value_loss            | 3.77       |
-----------------------------------------
------------------------------------------
| avg_speed                | 6           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6           |
| reward                   | -0.25480148 |
| rollout/                 |             |
|    ep_len_mean           | 61.4        |
|    ep_rew_mean           | -28.5       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 33          |
|    time_elapsed          | 974         |
|    total_timesteps       | 2977792     |
| train/                   |             |
|    approx_kl             | 0.026077528 |
|    clip_fraction         | 0.234       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.02        |
|    cost_value_loss       | 7.08        |
|    cost_values           | 2.2         |
|    entropy               | 0.306       |
|    entropy_loss          | 0.306       |
|    explained_variance    | 0.948       |
|    lagrangian_multiplier | 0.000792    |
|    learning_rate         | 0.0003      |
|    loss                  | 3.75        |
|    n_updates             | 14530       |
|    policy_gradient_loss  | 0.0104      |
|    std                   | 0.294       |
|    value_loss            | 2.08        |
------------------------------------------
-----------------------------------------
| avg_speed                | 2          |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 2          |
| reward                   | -0.5495937 |
| rollout/                 |            |
|    ep_len_mean           | 60.9       |
|    ep_rew_mean           | -28.2      |
| time/                    |            |
|    fps                   | 69         |
|    iterations            | 34         |
|    time_elapsed          | 1003       |
|    total_timesteps       | 2979840    |
| train/                   |            |
|    approx_kl             | 0.0319269  |
|    clip_fraction         | 0.214      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.99       |
|    cost_value_loss       | 6.2        |
|    cost_values           | 2.17       |
|    entropy               | 0.315      |
|    entropy_loss          | 0.31       |
|    explained_variance    | 0.919      |
|    lagrangian_multiplier | 0.00126    |
|    learning_rate         | 0.0003     |
|    loss                  | 3.6        |
|    n_updates             | 14540      |
|    policy_gradient_loss  | 0.0086     |
|    std                   | 0.292      |
|    value_loss            | 3.01       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.16020988 |
| rollout/                 |             |
|    ep_len_mean           | 60.9        |
|    ep_rew_mean           | -28.1       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 35          |
|    time_elapsed          | 1033        |
|    total_timesteps       | 2981888     |
| train/                   |             |
|    approx_kl             | 0.06904556  |
|    clip_fraction         | 0.222       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.88        |
|    cost_value_loss       | 6.1         |
|    cost_values           | 2.14        |
|    entropy               | 0.31        |
|    entropy_loss          | 0.314       |
|    explained_variance    | 0.874       |
|    lagrangian_multiplier | 0.000818    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.38        |
|    n_updates             | 14550       |
|    policy_gradient_loss  | 0.0109      |
|    std                   | 0.292       |
|    value_loss            | 4.11        |
------------------------------------------
------------------------------------------
| avg_speed                | 6.96        |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 6.96        |
| reward                   | -0.23553073 |
| rollout/                 |             |
|    ep_len_mean           | 65.2        |
|    ep_rew_mean           | -29.3       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 36          |
|    time_elapsed          | 1063        |
|    total_timesteps       | 2983936     |
| train/                   |             |
|    approx_kl             | 0.037137877 |
|    clip_fraction         | 0.233       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.04        |
|    cost_value_loss       | 7.13        |
|    cost_values           | 2.12        |
|    entropy               | 0.307       |
|    entropy_loss          | 0.308       |
|    explained_variance    | 0.895       |
|    lagrangian_multiplier | 0.00147     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.22        |
|    n_updates             | 14560       |
|    policy_gradient_loss  | 0.00538     |
|    std                   | 0.292       |
|    value_loss            | 3.81        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 1           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.33703086 |
| rollout/                 |             |
|    ep_len_mean           | 65.9        |
|    ep_rew_mean           | -29.4       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 37          |
|    time_elapsed          | 1092        |
|    total_timesteps       | 2985984     |
| train/                   |             |
|    approx_kl             | 0.012137886 |
|    clip_fraction         | 0.182       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.99        |
|    cost_value_loss       | 6.53        |
|    cost_values           | 2.12        |
|    entropy               | 0.304       |
|    entropy_loss          | 0.305       |
|    explained_variance    | 0.88        |
|    lagrangian_multiplier | 0.00147     |
|    learning_rate         | 0.0003      |
|    loss                  | 3.71        |
|    n_updates             | 14570       |
|    policy_gradient_loss  | 0.00761     |
|    std                   | 0.292       |
|    value_loss            | 3.39        |
------------------------------------------
------------------------------------------
| avg_speed                | 8.04        |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8.04        |
| reward                   | -0.22116171 |
| rollout/                 |             |
|    ep_len_mean           | 66          |
|    ep_rew_mean           | -29.4       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 38          |
|    time_elapsed          | 1122        |
|    total_timesteps       | 2988032     |
| train/                   |             |
|    approx_kl             | 0.048449207 |
|    clip_fraction         | 0.213       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.19        |
|    cost_value_loss       | 7.39        |
|    cost_values           | 2.13        |
|    entropy               | 0.303       |
|    entropy_loss          | 0.303       |
|    explained_variance    | 0.833       |
|    lagrangian_multiplier | 0.000837    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.08        |
|    n_updates             | 14580       |
|    policy_gradient_loss  | 0.00771     |
|    std                   | 0.292       |
|    value_loss            | 5.08        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.21975762 |
| rollout/                 |             |
|    ep_len_mean           | 64.3        |
|    ep_rew_mean           | -28.6       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 39          |
|    time_elapsed          | 1152        |
|    total_timesteps       | 2990080     |
| train/                   |             |
|    approx_kl             | 0.013165258 |
|    clip_fraction         | 0.161       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.91        |
|    cost_value_loss       | 6.16        |
|    cost_values           | 2.09        |
|    entropy               | 0.309       |
|    entropy_loss          | 0.306       |
|    explained_variance    | 0.863       |
|    lagrangian_multiplier | 0.00092     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.32        |
|    n_updates             | 14590       |
|    policy_gradient_loss  | 0.007       |
|    std                   | 0.291       |
|    value_loss            | 4.63        |
------------------------------------------
-----------------------------------------
| avg_speed                | 8.02       |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 8.02       |
| reward                   | -0.286231  |
| rollout/                 |            |
|    ep_len_mean           | 66.7       |
|    ep_rew_mean           | -29.3      |
| time/                    |            |
|    fps                   | 69         |
|    iterations            | 40         |
|    time_elapsed          | 1181       |
|    total_timesteps       | 2992128    |
| train/                   |            |
|    approx_kl             | 0.02496968 |
|    clip_fraction         | 0.164      |
|    clip_range            | 0.2        |
|    cost_returns          | 4.08       |
|    cost_value_loss       | 6.73       |
|    cost_values           | 2.09       |
|    entropy               | 0.307      |
|    entropy_loss          | 0.308      |
|    explained_variance    | 0.865      |
|    lagrangian_multiplier | 0.00241    |
|    learning_rate         | 0.0003     |
|    loss                  | 3.82       |
|    n_updates             | 14600      |
|    policy_gradient_loss  | 0.00451    |
|    std                   | 0.292      |
|    value_loss            | 4.71       |
-----------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.22651006 |
| rollout/                 |             |
|    ep_len_mean           | 69.8        |
|    ep_rew_mean           | -30         |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 41          |
|    time_elapsed          | 1211        |
|    total_timesteps       | 2994176     |
| train/                   |             |
|    approx_kl             | 0.018011233 |
|    clip_fraction         | 0.192       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.08        |
|    cost_value_loss       | 6.9         |
|    cost_values           | 2.08        |
|    entropy               | 0.31        |
|    entropy_loss          | 0.308       |
|    explained_variance    | 0.806       |
|    lagrangian_multiplier | 0.00111     |
|    learning_rate         | 0.0003      |
|    loss                  | 4.91        |
|    n_updates             | 14610       |
|    policy_gradient_loss  | 0.00185     |
|    std                   | 0.291       |
|    value_loss            | 5.83        |
------------------------------------------
-------------------------------------------
| avg_speed                | 7.81         |
| cost                     | 0            |
| is_success               | 1            |
| max_speed                | 7.81         |
| reward                   | -0.118883364 |
| rollout/                 |              |
|    ep_len_mean           | 71.5         |
|    ep_rew_mean           | -31          |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 42           |
|    time_elapsed          | 1241         |
|    total_timesteps       | 2996224      |
| train/                   |              |
|    approx_kl             | 0.015779596  |
|    clip_fraction         | 0.17         |
|    clip_range            | 0.2          |
|    cost_returns          | 4.18         |
|    cost_value_loss       | 7.1          |
|    cost_values           | 2.08         |
|    entropy               | 0.316        |
|    entropy_loss          | 0.312        |
|    explained_variance    | 0.81         |
|    lagrangian_multiplier | 0.000737     |
|    learning_rate         | 0.0003       |
|    loss                  | 5.11         |
|    n_updates             | 14620        |
|    policy_gradient_loss  | 0.00334      |
|    std                   | 0.29         |
|    value_loss            | 5.71         |
-------------------------------------------
-------------------------------------------
| avg_speed                | 8.04         |
| cost                     | 0            |
| is_success               | 0            |
| max_speed                | 8.04         |
| reward                   | -0.27814853  |
| rollout/                 |              |
|    ep_len_mean           | 66.2         |
|    ep_rew_mean           | -29.8        |
| time/                    |              |
|    fps                   | 69           |
|    iterations            | 43           |
|    time_elapsed          | 1271         |
|    total_timesteps       | 2998272      |
| train/                   |              |
|    approx_kl             | 0.0126254745 |
|    clip_fraction         | 0.163        |
|    clip_range            | 0.2          |
|    cost_returns          | 3.89         |
|    cost_value_loss       | 5.88         |
|    cost_values           | 2.11         |
|    entropy               | 0.321        |
|    entropy_loss          | 0.319        |
|    explained_variance    | 0.866        |
|    lagrangian_multiplier | 0.000917     |
|    learning_rate         | 0.0003       |
|    loss                  | 4.27         |
|    n_updates             | 14630        |
|    policy_gradient_loss  | 0.0086       |
|    std                   | 0.289        |
|    value_loss            | 5.11         |
-------------------------------------------
-----------------------------------------
| avg_speed                | 2.6        |
| cost                     | 0          |
| is_success               | 0          |
| max_speed                | 2.6        |
| reward                   | -0.6847628 |
| rollout/                 |            |
|    ep_len_mean           | 65.1       |
|    ep_rew_mean           | -29.8      |
| time/                    |            |
|    fps                   | 69         |
|    iterations            | 44         |
|    time_elapsed          | 1301       |
|    total_timesteps       | 3000320    |
| train/                   |            |
|    approx_kl             | 0.02090438 |
|    clip_fraction         | 0.186      |
|    clip_range            | 0.2        |
|    cost_returns          | 3.9        |
|    cost_value_loss       | 6.56       |
|    cost_values           | 2.09       |
|    entropy               | 0.319      |
|    entropy_loss          | 0.321      |
|    explained_variance    | 0.899      |
|    lagrangian_multiplier | 0.00178    |
|    learning_rate         | 0.0003     |
|    loss                  | 3.89       |
|    n_updates             | 14640      |
|    policy_gradient_loss  | 0.00633    |
|    std                   | 0.29       |
|    value_loss            | 3.97       |
-----------------------------------------
------------------------------------------
| avg_speed                | 1           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 1           |
| reward                   | -0.80032885 |
| rollout/                 |             |
|    ep_len_mean           | 63.2        |
|    ep_rew_mean           | -28.4       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 45          |
|    time_elapsed          | 1331        |
|    total_timesteps       | 3002368     |
| train/                   |             |
|    approx_kl             | 0.019179454 |
|    clip_fraction         | 0.198       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.69        |
|    cost_value_loss       | 6.07        |
|    cost_values           | 2.04        |
|    entropy               | 0.321       |
|    entropy_loss          | 0.32        |
|    explained_variance    | 0.84        |
|    lagrangian_multiplier | 0.000941    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.35        |
|    n_updates             | 14650       |
|    policy_gradient_loss  | 0.00798     |
|    std                   | 0.29        |
|    value_loss            | 5.03        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.3469878  |
| rollout/                 |             |
|    ep_len_mean           | 66.6        |
|    ep_rew_mean           | -29.3       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 46          |
|    time_elapsed          | 1360        |
|    total_timesteps       | 3004416     |
| train/                   |             |
|    approx_kl             | 0.009112613 |
|    clip_fraction         | 0.177       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.73        |
|    cost_value_loss       | 5.25        |
|    cost_values           | 2.01        |
|    entropy               | 0.321       |
|    entropy_loss          | 0.321       |
|    explained_variance    | 0.852       |
|    lagrangian_multiplier | 0.000651    |
|    learning_rate         | 0.0003      |
|    loss                  | 4.27        |
|    n_updates             | 14660       |
|    policy_gradient_loss  | 0.0066      |
|    std                   | 0.29        |
|    value_loss            | 4.82        |
------------------------------------------
------------------------------------------
| avg_speed                | 3.6         |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 3.6         |
| reward                   | -0.7022497  |
| rollout/                 |             |
|    ep_len_mean           | 68.1        |
|    ep_rew_mean           | -29.6       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 47          |
|    time_elapsed          | 1390        |
|    total_timesteps       | 3006464     |
| train/                   |             |
|    approx_kl             | 0.013083862 |
|    clip_fraction         | 0.162       |
|    clip_range            | 0.2         |
|    cost_returns          | 4.06        |
|    cost_value_loss       | 7.07        |
|    cost_values           | 1.99        |
|    entropy               | 0.327       |
|    entropy_loss          | 0.323       |
|    explained_variance    | 0.814       |
|    lagrangian_multiplier | 0.000653    |
|    learning_rate         | 0.0003      |
|    loss                  | 5.37        |
|    n_updates             | 14670       |
|    policy_gradient_loss  | 0.00215     |
|    std                   | 0.289       |
|    value_loss            | 5.38        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.33313972 |
| rollout/                 |             |
|    ep_len_mean           | 69.4        |
|    ep_rew_mean           | -30.3       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 48          |
|    time_elapsed          | 1419        |
|    total_timesteps       | 3008512     |
| train/                   |             |
|    approx_kl             | 0.020341849 |
|    clip_fraction         | 0.179       |
|    clip_range            | 0.2         |
|    cost_returns          | 3.93        |
|    cost_value_loss       | 6.53        |
|    cost_values           | 2           |
|    entropy               | 0.327       |
|    entropy_loss          | 0.328       |
|    explained_variance    | 0.739       |
|    lagrangian_multiplier | 0.0011      |
|    learning_rate         | 0.0003      |
|    loss                  | 5.21        |
|    n_updates             | 14680       |
|    policy_gradient_loss  | 0.0104      |
|    std                   | 0.29        |
|    value_loss            | 7.39        |
------------------------------------------
------------------------------------------
| avg_speed                | 8           |
| cost                     | 0           |
| is_success               | 0           |
| max_speed                | 8           |
| reward                   | -0.23721153 |
| rollout/                 |             |
|    ep_len_mean           | 67.2        |
|    ep_rew_mean           | -29.7       |
| time/                    |             |
|    fps                   | 69          |
|    iterations            | 49          |
|    time_elapsed          | 1449        |
|    total_timesteps       | 3010560     |
| train/                   |             |
|    approx_kl             | 0.016872603 |
|    clip_fraction         | 0.181       |
|    clip_range            | 0.2         |
|    cost_returns          | 4           |
|    cost_value_loss       | 6.77        |
|    cost_values           | 1.98        |
|    entropy               | 0.333       |
|    entropy_loss          | 0.329       |
|    explained_variance    | 0.793       |
|    lagrangian_multiplier | 0.000299    |
|    learning_rate         | 0.0003      |
|    loss                  | 6.19        |
|    n_updates             | 14690       |
|    policy_gradient_loss  | 0.00124     |
|    std                   | 0.289       |
|    value_loss            | 6.78        |
------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.5550865530967712
Final reward: -0.5555834770202637
Final reward: -0.5567049384117126
Final reward: -0.558863639831543
Final reward: -0.5626066327095032
Final reward: -0.5685297250747681
Final reward: -0.5771329998970032
Final reward: -0.5886169075965881
Final reward: -0.6026471257209778
Final reward: -0.6181515455245972
Final reward: -0.6332294344902039
Final reward: -0.6452507376670837
Final reward: -0.6512061953544617
Final reward: -0.6568537354469299
Final reward: -0.654172956943512
Final reward: -0.6390113830566406
Final reward: -0.6146160364151001
Final reward: -0.5861904621124268
Final reward: -0.5524314641952515
Final reward: -0.5155012011528015
Final reward: -0.4736795127391815
Final reward: -0.42456719279289246
Final reward: -0.3664616048336029
Final reward: -0.2947634160518646
Final reward: -0.19186612963676453
Final reward: -0.22380991280078888
Final reward: -0.2935589551925659
Final reward: -0.3544970154762268
Final reward: -0.3124997913837433
Final reward: -0.20015345513820648
Final reward: -0.16919122636318207
Final reward: -0.1933727264404297
Final reward: -0.2268018126487732
Final reward: -0.3094575107097626
Final reward: -0.34748542308807373
Final reward: -0.29444244503974915
Final reward: -0.053423501551151276
Final reward: -0.5933979153633118
Final reward: -0.593862771987915
Final reward: -0.594912052154541
Final reward: -0.5969326496124268
Final reward: -0.6004383563995361
Final reward: -0.605991780757904
Final reward: -0.614070475101471
Final reward: -0.6248759031295776
Final reward: -0.6381093859672546
Final reward: -0.652772068977356
Final reward: -0.66706782579422
Final reward: -0.6784898638725281
Final reward: -0.6846639513969421
Final reward: -0.6867157816886902
Final reward: -0.6874378323554993
Final reward: -0.6858751773834229
Final reward: -0.6828590631484985
Final reward: -0.6804125308990479
Final reward: -0.673309326171875
Final reward: -0.6561021208763123
Final reward: -0.6349051594734192
Final reward: -0.6110010743141174
Final reward: -0.5789311528205872
Final reward: -0.5430544018745422
Final reward: -0.5020840167999268
Final reward: -0.4524744749069214
Final reward: -0.39424964785575867
Final reward: -0.3148767352104187
Final reward: -0.22952987253665924
Final reward: -0.23303532600402832
Final reward: -0.29785269498825073
Final reward: -0.35986149311065674
Final reward: -0.30003949999809265
Final reward: -0.17081142961978912
Final reward: -0.15621089935302734
Final reward: -0.3083997666835785
Final reward: -0.38342514634132385
Final reward: -0.40744549036026
Final reward: -0.32444363832473755
Final reward: -0.20139776170253754
Final reward: -0.25224462151527405
Final reward: -0.36698174476623535
Final reward: -0.40642470121383667
Final reward: -0.3188532590866089
Final reward: -0.21425645053386688
Final reward: -0.33110371232032776
Final reward: -0.3962068259716034
Final reward: -0.369951069355011
Final reward: -0.2146841585636139
Final reward: -0.2756543457508087
Final reward: -0.38286134600639343
Final reward: -0.42957451939582825
Final reward: -0.35920241475105286
Final reward: -0.23524218797683716
Final reward: -0.20019474625587463
Final reward: -0.2910178303718567
Final reward: -0.360291987657547
Final reward: -0.31817740201950073
Final reward: -0.10856422781944275
Final reward: -0.6871106624603271
Final reward: -0.6875121593475342
Final reward: -0.6884187459945679
Final reward: -0.690165638923645
Final reward: -0.6931999921798706
Final reward: -0.6980157494544983
Final reward: -0.7050408124923706
Final reward: -0.7144717574119568
Final reward: -0.7260740399360657
Final reward: -0.7389934659004211
Final reward: -0.7516511678695679
Final reward: -0.761806070804596
Final reward: -0.7669370770454407
Final reward: -0.7654020190238953
Final reward: -0.7656715512275696
Final reward: -0.7579239010810852
Final reward: -0.7462713122367859
Final reward: -0.7298234701156616
Final reward: -0.7140692472457886
Final reward: -0.6938516497612
Final reward: -0.6657835841178894
Final reward: -0.6361864805221558
Final reward: -0.6078199744224548
Final reward: -0.5751480460166931
Final reward: -0.536520779132843
Final reward: -0.49429428577423096
Final reward: -0.43831667304039
Final reward: -0.37803468108177185
Final reward: -0.310027152299881
Final reward: -0.2244240939617157
Final reward: -0.24068495631217957
Final reward: -0.290764719247818
Final reward: -0.26148995757102966
Final reward: -0.21791662275791168
Final reward: -0.2291015386581421
Final reward: -0.22788342833518982
Final reward: -0.2845292389392853
Final reward: -0.2923852503299713
Final reward: -0.13699717819690704
Final reward: -0.25453659892082214
Final reward: -0.25569412112236023
Final reward: -0.3294377624988556
Final reward: -0.29155805706977844
Final reward: -0.1343562752008438
Final reward: -0.2293825000524521
Final reward: -0.3065233826637268
Final reward: -0.35352185368537903
Final reward: -0.2634707987308502
Final reward: -0.1725391447544098
Final reward: -0.26047903299331665
Final reward: -0.3400901257991791
Final reward: -0.31377536058425903
Final reward: -0.08689312636852264
Final reward: -0.8672491312026978
Final reward: -0.8675673007965088
Final reward: -0.8682858943939209
Final reward: -0.8696715235710144
Final reward: -0.8720815777778625
Final reward: -0.8759143948554993
Final reward: -0.8815228343009949
Final reward: -0.889083743095398
Final reward: -0.8984339237213135
Final reward: -0.9089066982269287
Final reward: -0.919227659702301
Final reward: -0.9275497198104858
Final reward: -0.9317024946212769
Final reward: -0.9356585144996643
Final reward: -0.9337612986564636
Final reward: -0.921725869178772
Final reward: -0.9047008752822876
Final reward: -0.8860846757888794
Final reward: -0.8686257600784302
Final reward: -0.8472537994384766
Final reward: -0.821707010269165
Final reward: -0.7994493842124939
Final reward: -0.7710906863212585
Final reward: -0.7418957352638245
Final reward: -0.7136391401290894
Final reward: -0.6779957413673401
Final reward: -0.6366686224937439
Final reward: -0.6010388135910034
Final reward: -0.5545010566711426
Final reward: -0.4970646798610687
Final reward: -0.4345576763153076
Final reward: -0.36156946420669556
Final reward: -0.2601531744003296
Final reward: -0.15293458104133606
Final reward: -0.2510034441947937
Final reward: -0.2665777802467346
Final reward: -0.3120434880256653
Final reward: -0.2842775583267212
Final reward: -0.15495263040065765
Final reward: -0.23619617521762848
Final reward: -0.2832905948162079
Final reward: -0.2930408716201782
Final reward: -0.31204041838645935
Final reward: -0.19503003358840942
Final reward: -0.19559943675994873
Final reward: -0.26185569167137146
Final reward: -0.3322313725948334
Final reward: -0.2233409732580185
Final reward: -0.28497034311294556
Final reward: -0.23796433210372925
Final reward: -0.2045322060585022
Final reward: -0.2738838195800781
Final reward: -0.2796512544155121
Final reward: -0.3193609118461609
Final reward: -0.20118014514446259
Final reward: -0.23396408557891846
Final reward: -0.23469315469264984
Final reward: -0.315204918384552
Final reward: -0.269602507352829
Final reward: -0.1595691740512848
Final reward: -0.2458113431930542
Final reward: -0.3215444087982178
Final reward: -0.3755843937397003
Final reward: -0.32135674357414246
Final reward: -0.09902749955654144
Final reward: -0.8414992690086365
Final reward: -0.8418272137641907
Final reward: -0.8425677418708801
Final reward: -0.8439956307411194
Final reward: -0.8464787006378174
Final reward: -0.850426971912384
Final reward: -0.8562023639678955
Final reward: -0.8639848828315735
Final reward: -0.8736037611961365
Final reward: -0.8843705654144287
Final reward: -0.8949745893478394
Final reward: -0.9035200476646423
Final reward: -0.9077827334403992
Final reward: -0.9118425250053406
Final reward: -0.9121314287185669
Final reward: -0.9021456241607666
Final reward: -0.882987916469574
Final reward: -0.8621115684509277
Final reward: -0.8391096591949463
Final reward: -0.8149769306182861
Final reward: -0.7891384959220886
Final reward: -0.760074257850647
Final reward: -0.7291164994239807
Final reward: -0.6971948742866516
Final reward: -0.6590903997421265
Final reward: -0.6209254264831543
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.5793165564537048
Final reward: -0.5430623888969421
Final reward: -0.4940859377384186
Final reward: -0.43892067670822144
Final reward: -0.36449748277664185
Final reward: -0.2434360831975937
Final reward: -0.12875457108020782
Final reward: -0.2656979262828827
Final reward: -0.33043184876441956
Final reward: -0.36964723467826843
Final reward: -0.2762642800807953
Final reward: -0.21203143894672394
Final reward: -0.23526349663734436
Final reward: -0.24563856422901154
Final reward: -0.30771857500076294
Final reward: -0.19566701352596283
Final reward: -0.27867937088012695
Final reward: -0.2419714778661728
Final reward: -0.22455233335494995
Final reward: -0.2573300898075104
Final reward: -0.28324025869369507
Final reward: -0.3385992646217346
Final reward: -0.3047575354576111
Final reward: -0.1323634386062622
Final reward: -0.1996702253818512
Final reward: -0.3338484466075897
Final reward: -0.38014018535614014
Final reward: -0.3408879339694977
Final reward: -0.15140874683856964
Final reward: -0.22651880979537964
Final reward: -0.34737464785575867
Final reward: -0.38098448514938354
Final reward: -0.29270532727241516
Final reward: -0.1551222950220108
Final reward: -0.28658270835876465
Final reward: -0.36310815811157227
Final reward: -0.35481539368629456
Final reward: -0.18733960390090942
Final reward: -0.22120437026023865
Final reward: -0.3455372750759125
Final reward: -0.39722535014152527
Final reward: -0.3306255340576172
Final reward: -0.13548986613750458
Final reward: -0.21791419386863708
Final reward: -0.34118399024009705
Final reward: -0.37565290927886963
Final reward: -0.2645519971847534
Final reward: -0.1895936280488968
Final reward: -0.3045158386230469
Final reward: -0.37063854932785034
Final reward: -0.32736727595329285
Final reward: -0.13710062205791473
Final reward: -0.25102004408836365
Final reward: -0.36292654275894165
Final reward: -0.3942050039768219
Final reward: -0.28816357254981995
Final reward: -0.20255371928215027
Final reward: -0.330020010471344
Final reward: -0.3909777104854584
Final reward: -0.3422974944114685
Final reward: -0.16422927379608154
Final reward: -0.20121389627456665
Final reward: -0.3260117769241333
Final reward: -0.3739252984523773
Final reward: -0.2866121530532837
Final reward: -0.14423267543315887
Final reward: -0.2817184627056122
Final reward: -0.3580663502216339
Final reward: -0.34142738580703735
Final reward: -0.15984392166137695
Final reward: -0.2222002148628235
Final reward: -0.3437603712081909
Final reward: -0.37602293491363525
Final reward: -0.2615967094898224
Final reward: -0.1736195832490921
Final reward: -0.2999936640262604
Final reward: -0.36942100524902344
Final reward: -0.33644911646842957
Final reward: -0.151059091091156
Final reward: -0.24524196982383728
Final reward: -0.35667696595191956
Final reward: -0.3830379247665405
Final reward: -0.26388299465179443
Final reward: -0.19113576412200928
Final reward: -0.32517409324645996
Final reward: -0.3837929368019104
Final reward: -0.32132115960121155
Final reward: -0.1780310869216919
Final reward: -0.23231305181980133
Final reward: -0.26864752173423767
Final reward: -0.3305760324001312
Final reward: -0.26460468769073486
Final reward: -0.17222359776496887
Final reward: -0.21417473256587982
Final reward: -0.31441497802734375
Final reward: -0.32407861948013306
Final reward: -0.17661970853805542
Final reward: -0.21270905435085297
Final reward: -0.286115437746048
Final reward: -0.34502676129341125
Final reward: -0.27979519963264465
Final reward: -0.14859125018119812
Final reward: -0.23227746784687042
Final reward: -0.3228483498096466
Final reward: -0.31793951988220215
Final reward: -0.1271362602710724
Final reward: -0.2210652381181717
Final reward: -0.31339016556739807
Final reward: -0.3604882061481476
Final reward: -0.2849716544151306
Final reward: -0.13183756172657013
Final reward: -0.26263734698295593
Final reward: -0.343784898519516
Final reward: -0.32849013805389404
Final reward: -0.13385015726089478
Final reward: -0.19487132132053375
Final reward: -0.335172563791275
Final reward: -0.3883102834224701
Final reward: -0.32049232721328735
Final reward: -0.12625652551651
Final reward: -0.24852803349494934
Final reward: -0.35376283526420593
Final reward: -0.3732678294181824
Final reward: -0.2474643439054489
Final reward: -0.17940755188465118
Final reward: -0.315758615732193
Final reward: -0.37910187244415283
Final reward: -0.3302946984767914
Final reward: -0.16114848852157593
Final reward: -0.21716806292533875
Final reward: -0.30364990234375
Final reward: -0.3535272181034088
Final reward: -0.2674667239189148
Final reward: -0.16800805926322937
Final reward: -0.256183385848999
Final reward: -0.3378705680370331
Final reward: -0.3171765208244324
Final reward: -0.09783672541379929
Final reward: -0.6573591828346252
Final reward: -0.6577788591384888
Final reward: -0.6587263345718384
Final reward: -0.6605517268180847
Final reward: -0.66372150182724
Final reward: -0.6687495708465576
Final reward: -0.6760787963867188
Final reward: -0.6859080791473389
Final reward: -0.6979853510856628
Final reward: -0.7114150524139404
Final reward: -0.724554717540741
Final reward: -0.7350839972496033
Final reward: -0.7405832409858704
Final reward: -0.7405432462692261
Final reward: -0.7379136085510254
Final reward: -0.7348492741584778
Final reward: -0.7293955087661743
Final reward: -0.7209097146987915
Final reward: -0.7048498392105103
Final reward: -0.6831488609313965
Final reward: -0.6577393412590027
Final reward: -0.6315079927444458
Final reward: -0.6002654433250427
Final reward: -0.5625587105751038
Final reward: -0.5239532589912415
Final reward: -0.4815184473991394
Final reward: -0.4239264726638794
Final reward: -0.35853856801986694
Final reward: -0.2806970179080963
Final reward: -0.16412149369716644
Final reward: -0.2521902918815613
Final reward: -0.3184136748313904
Final reward: -0.25624802708625793
Final reward: -0.22891944646835327
Final reward: -0.19596640765666962
Final reward: -0.24774926900863647
Final reward: -0.3399882912635803
Final reward: -0.35738006234169006
Final reward: -0.2693190574645996
Final reward: -0.11204647272825241
Final reward: -0.8414992690086365
Final reward: -0.8418272137641907
Final reward: -0.8425677418708801
Final reward: -0.8439956307411194
Final reward: -0.8464787006378174
Final reward: -0.850426971912384
Final reward: -0.8562023639678955
Final reward: -0.8639848828315735
Final reward: -0.8736037611961365
Final reward: -0.8843705654144287
Final reward: -0.8949745893478394
Final reward: -0.9035200476646423
Final reward: -0.9077827334403992
Final reward: -0.9118425250053406
Final reward: -0.9121314287185669
Final reward: -0.9024330377578735
Final reward: -0.8832340240478516
Final reward: -0.8621960878372192
Final reward: -0.8399741053581238
Final reward: -0.8151333928108215
Final reward: -0.7890598773956299
Final reward: -0.7604555487632751
Final reward: -0.7296974658966064
Final reward: -0.6961414813995361
Final reward: -0.6580539345741272
Final reward: -0.6213276982307434
Final reward: -0.5805459022521973
Final reward: -0.5407995581626892
Final reward: -0.4917083978652954
Final reward: -0.4334731101989746
Final reward: -0.3597468137741089
Final reward: -0.24933411180973053
Final reward: -0.19257141649723053
Final reward: -0.20515872538089752
Final reward: -0.2726346254348755
Final reward: -0.31977367401123047
Final reward: -0.2718387842178345
Final reward: -0.1939229965209961
Final reward: -0.19173403084278107
Final reward: -0.283109188079834
Final reward: -0.32432693243026733
Final reward: -0.18239465355873108
Final reward: -0.26160702109336853
Final reward: -0.21573027968406677
Final reward: -0.25257182121276855
Final reward: -0.2768801748752594
Final reward: -0.2561761736869812
Final reward: -0.3180757462978363
Final reward: -0.2735665738582611
Final reward: -0.1842525452375412
Final reward: -0.22496183216571808
Final reward: -0.29568663239479065
Final reward: -0.3445487320423126
Final reward: -0.27309295535087585
Final reward: -0.13009636104106903
Final reward: -0.2265596091747284
Final reward: -0.31498265266418457
Final reward: -0.3544260859489441
Final reward: -0.2542985677719116
Final reward: -0.1800023466348648
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.2747281789779663
Final reward: -0.34770068526268005
Final reward: -0.3086015582084656
Final reward: -0.05387669429183006
Final reward: -0.6229936480522156
Final reward: -0.623436450958252
Final reward: -0.6244360208511353
Final reward: -0.6263613700866699
Final reward: -0.6297032833099365
Final reward: -0.6350008249282837
Final reward: -0.6427149772644043
Final reward: -0.6530466079711914
Final reward: -0.6657203435897827
Final reward: -0.6797876954078674
Final reward: -0.6935268640518188
Final reward: -0.704520046710968
Final reward: -0.7099785208702087
Final reward: -0.7151620984077454
Final reward: -0.7155303955078125
Final reward: -0.698125958442688
Final reward: -0.6751332879066467
Final reward: -0.6498629450798035
Final reward: -0.6193740963935852
Final reward: -0.5873658657073975
Final reward: -0.5497192740440369
Final reward: -0.5078645944595337
Final reward: -0.46100467443466187
Final reward: -0.4072815477848053
Final reward: -0.34643301367759705
Final reward: -0.26342785358428955
Final reward: -0.11605066061019897
Final reward: -0.5216522216796875
Final reward: -0.5221810340881348
Final reward: -0.5233740210533142
Final reward: -0.5256696343421936
Final reward: -0.5296472907066345
Final reward: -0.5359346866607666
Final reward: -0.5450527667999268
Final reward: -0.5571982264518738
Final reward: -0.5719996094703674
Final reward: -0.5883122682571411
Final reward: -0.6041353344917297
Final reward: -0.6167240142822266
Final reward: -0.6236799955368042
Final reward: -0.6280781626701355
Final reward: -0.6318622827529907
Final reward: -0.6363144516944885
Final reward: -0.6400008797645569
Final reward: -0.6404858827590942
Final reward: -0.6392938494682312
Final reward: -0.633395254611969
Final reward: -0.6286622285842896
Final reward: -0.6242178678512573
Final reward: -0.5988951921463013
Final reward: -0.5665084719657898
Final reward: -0.5336452126502991
Final reward: -0.48888275027275085
Final reward: -0.43195781111717224
Final reward: -0.3765891194343567
Final reward: -0.311868816614151
Final reward: -0.21693716943264008
Final reward: -0.24629783630371094
Final reward: -0.2889350652694702
Final reward: -0.23046693205833435
Final reward: -0.2285347729921341
Final reward: -0.2466815710067749
Final reward: -0.24735060334205627
Final reward: -0.32617315649986267
Final reward: -0.33491578698158264
Final reward: -0.2020314633846283
Final reward: -0.18097898364067078
Final reward: -0.26497882604599
Final reward: -0.34390372037887573
Final reward: -0.3198484480381012
Final reward: -0.10650626569986343
Final reward: -0.5178040862083435
Final reward: -0.5183367729187012
Final reward: -0.5195386409759521
Final reward: -0.521851122379303
Final reward: -0.5258576273918152
Final reward: -0.5321898460388184
Final reward: -0.5413709878921509
Final reward: -0.5535972118377686
Final reward: -0.5684923529624939
Final reward: -0.584902822971344
Final reward: -0.6008157134056091
Final reward: -0.6134725213050842
Final reward: -0.6197333931922913
Final reward: -0.6256650686264038
Final reward: -0.6238405108451843
Final reward: -0.6056464314460754
Final reward: -0.581423819065094
Final reward: -0.5503270030021667
Final reward: -0.5147584676742554
Final reward: -0.474954217672348
Final reward: -0.42849239706993103
Final reward: -0.3758489489555359
Final reward: -0.30879464745521545
Final reward: -0.2171388566493988
Final reward: -0.21282696723937988
Final reward: -0.28885799646377563
Final reward: -0.35317566990852356
Final reward: -0.3505200445652008
Final reward: -0.2514202892780304
Final reward: -0.20909357070922852
Final reward: -0.2312222570180893
Final reward: -0.2638656198978424
Final reward: -0.2200196236371994
Final reward: -0.30525460839271545
Final reward: -0.32518821954727173
Final reward: -0.24108067154884338
Final reward: -0.17614571750164032
Final reward: -0.21515518426895142
Final reward: -0.3220176696777344
Final reward: -0.363628625869751
Final reward: -0.3103742301464081
Final reward: -0.10574525594711304
Final reward: -0.8672491312026978
Final reward: -0.8675673007965088
Final reward: -0.8682858943939209
Final reward: -0.8696715235710144
Final reward: -0.8720815777778625
Final reward: -0.8759143948554993
Final reward: -0.8815228343009949
Final reward: -0.889083743095398
Final reward: -0.8984339237213135
Final reward: -0.9089066982269287
Final reward: -0.919227659702301
Final reward: -0.9275497198104858
Final reward: -0.9317024946212769
Final reward: -0.9356585144996643
Final reward: -0.933386504650116
Final reward: -0.9213476777076721
Final reward: -0.9054209589958191
Final reward: -0.8870497941970825
Final reward: -0.8673716187477112
Final reward: -0.8457974791526794
Final reward: -0.8243929147720337
Final reward: -0.8000342845916748
Final reward: -0.7714983224868774
Final reward: -0.743342399597168
Final reward: -0.7124490737915039
Final reward: -0.6786929965019226
Final reward: -0.6409324407577515
Final reward: -0.5965145230293274
Final reward: -0.5503724813461304
Final reward: -0.49398720264434814
Final reward: -0.4473336637020111
Final reward: -0.3803456723690033
Final reward: -0.29223519563674927
Final reward: -0.16732573509216309
Final reward: -0.22293341159820557
Final reward: -0.24822638928890228
Final reward: -0.30631837248802185
Final reward: -0.29512009024620056
Final reward: -0.16859759390354156
Final reward: -0.218159481883049
Final reward: -0.27602121233940125
Final reward: -0.319873183965683
Final reward: -0.22460269927978516
Final reward: -0.27525660395622253
Final reward: -0.2799144685268402
Final reward: -0.18959802389144897
Final reward: -0.252488374710083
Final reward: -0.25379300117492676
Final reward: -0.32016900181770325
Final reward: -0.24745166301727295
Final reward: -0.19070611894130707
Final reward: -0.26833465695381165
Final reward: -0.29089149832725525
Final reward: -0.3380500078201294
Final reward: -0.23155170679092407
Final reward: -0.21216966211795807
Final reward: -0.24302417039871216
Final reward: -0.32593950629234314
Final reward: -0.2931995689868927
Final reward: -0.1200946569442749
Final reward: -0.24497480690479279
Final reward: -0.3202105760574341
Final reward: -0.36516422033309937
Final reward: -0.27915093302726746
Final reward: -0.1455402672290802
Final reward: -0.27660566568374634
Final reward: -0.3524584472179413
Final reward: -0.32640698552131653
Final reward: -0.12514902651309967
Final reward: -0.21111515164375305
Final reward: -0.33983945846557617
Final reward: -0.38359832763671875
Final reward: -0.29364386200904846
Final reward: -0.1641906201839447
Final reward: -0.2985956370830536
Final reward: -0.3704701066017151
Final reward: -0.34849801659584045
Final reward: -0.17460012435913086
Final reward: -0.24053683876991272
Final reward: -0.35835379362106323
Final reward: -0.39700692892074585
Final reward: -0.30454733967781067
Final reward: -0.19705890119075775
Final reward: -0.3208998739719391
Final reward: -0.3872315585613251
Final reward: -0.35889649391174316
Final reward: -0.19543305039405823
Final reward: -0.26747459173202515
Final reward: -0.37693846225738525
Final reward: -0.41373953223228455
Final reward: -0.32582828402519226
Final reward: -0.22904670238494873
Final reward: -0.34158289432525635
Final reward: -0.404478520154953
Final reward: -0.3771630823612213
Final reward: -0.22728832066059113
Final reward: -0.2946488857269287
Final reward: -0.38904935121536255
Final reward: -0.4075556695461273
Final reward: -0.29088619351387024
Final reward: -0.24816463887691498
Final reward: -0.36336132884025574
Final reward: -0.4128634035587311
Final reward: -0.34874647855758667
Final reward: -0.17528124153614044
Final reward: -0.22530251741409302
Final reward: -0.34493154287338257
Final reward: -0.3752162456512451
Final reward: -0.2572776675224304
Final reward: -0.20447207987308502
Final reward: -0.3106394112110138
Final reward: -0.37346088886260986
Final reward: -0.3196113705635071
Final reward: -0.10911325365304947
Final reward: -0.6543096303939819
Final reward: -0.654731273651123
Final reward: -0.655683159828186
Final reward: -0.6575170159339905
Final reward: -0.660701334476471
Final reward: -0.6657522320747375
Final reward: -0.6731140613555908
Final reward: -0.6829859614372253
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.6951140761375427
Final reward: -0.7085981369018555
Final reward: -0.7217891216278076
Final reward: -0.7323582172393799
Final reward: -0.7376106977462769
Final reward: -0.7426013946533203
Final reward: -0.7429560422897339
Final reward: -0.7268950939178467
Final reward: -0.7054149508476257
Final reward: -0.6790282130241394
Final reward: -0.6504026651382446
Final reward: -0.6185595393180847
Final reward: -0.5848163366317749
Final reward: -0.546134352684021
Final reward: -0.501204788684845
Final reward: -0.45237797498703003
Final reward: -0.39294737577438354
Final reward: -0.33215004205703735
Final reward: -0.25429579615592957
Final reward: -0.1856885403394699
Final reward: -0.2550610303878784
Final reward: -0.26723262667655945
Final reward: -0.24720239639282227
Final reward: -0.27495482563972473
Final reward: -0.27849581837654114
Final reward: -0.21955247223377228
Final reward: -0.29555970430374146
Final reward: -0.3403817117214203
Final reward: -0.22900743782520294
Final reward: -0.1562800258398056
Final reward: -0.24776031076908112
Final reward: -0.2938561737537384
Final reward: -0.35757485032081604
Final reward: -0.30056366324424744
Final reward: -0.11772525310516357
Final reward: -0.7430484890937805
Final reward: -0.7434198260307312
Final reward: -0.7442582845687866
Final reward: -0.7458744049072266
Final reward: -0.748682975769043
Final reward: -0.7531440854072571
Final reward: -0.759659469127655
Final reward: -0.7684203386306763
Final reward: -0.7792198061943054
Final reward: -0.791271984577179
Final reward: -0.8031061291694641
Final reward: -0.8126183152198792
Final reward: -0.817355215549469
Final reward: -0.8169524669647217
Final reward: -0.8157814741134644
Final reward: -0.8080957531929016
Final reward: -0.7949532866477966
Final reward: -0.7781651020050049
Final reward: -0.759528398513794
Final reward: -0.7334014177322388
Final reward: -0.7097806930541992
Final reward: -0.6832720637321472
Final reward: -0.6561332941055298
Final reward: -0.6222330927848816
Final reward: -0.5816807150840759
Final reward: -0.5438940525054932
Final reward: -0.49613338708877563
Final reward: -0.44528311491012573
Final reward: -0.3765195608139038
Final reward: -0.29656219482421875
Final reward: -0.16263128817081451
Final reward: -0.23268833756446838
Final reward: -0.2953614890575409
Final reward: -0.23335906863212585
Final reward: -0.26927217841148376
Final reward: -0.29163217544555664
Final reward: -0.27425479888916016
Final reward: -0.26796799898147583
Final reward: -0.29142525792121887
Final reward: -0.13927149772644043
Final reward: -0.2724060118198395
Final reward: -0.22150155901908875
Final reward: -0.29760777950286865
Final reward: -0.22657325863838196
Final reward: -0.21938957273960114
Final reward: -0.2924458980560303
Final reward: -0.25376319885253906
Final reward: -0.30425021052360535
Final reward: -0.17440372705459595
Final reward: -0.2597895860671997
Final reward: -0.24304671585559845
Final reward: -0.29324793815612793
Final reward: -0.24937006831169128
Final reward: -0.190763458609581
Final reward: -0.2826637625694275
Final reward: -0.2820947766304016
Final reward: -0.32210153341293335
Final reward: -0.1934058517217636
Final reward: -0.24107249081134796
Final reward: -0.2369435876607895
Final reward: -0.316980242729187
Final reward: -0.26471391320228577
Final reward: -0.1649090051651001
Final reward: -0.25254711508750916
Final reward: -0.32234811782836914
Final reward: -0.3799070417881012
Final reward: -0.3134553134441376
Final reward: -0.14909978210926056
Final reward: -0.23819682002067566
Final reward: -0.27814656496047974
Final reward: -0.3478129506111145
Final reward: -0.30179405212402344
Final reward: -0.07366199791431427
Final reward: -0.5900178551673889
Final reward: -0.5904853940010071
Final reward: -0.5915406942367554
Final reward: -0.593572735786438
Final reward: -0.597098171710968
Final reward: -0.60268235206604
Final reward: -0.6108047962188721
Final reward: -0.6216670274734497
Final reward: -0.6349673867225647
Final reward: -0.649700939655304
Final reward: -0.6640628576278687
Final reward: -0.6755357384681702
Final reward: -0.6812264919281006
Final reward: -0.6866271495819092
Final reward: -0.6846812963485718
Final reward: -0.6711689829826355
Final reward: -0.6461134552955627
Final reward: -0.6180478930473328
Final reward: -0.5879684686660767
Final reward: -0.5524910092353821
Final reward: -0.5123807191848755
Final reward: -0.468290239572525
Final reward: -0.41563478112220764
Final reward: -0.3533305823802948
Final reward: -0.273042231798172
Final reward: -0.14881354570388794
Final reward: -0.24842673540115356
Final reward: -0.32410362362861633
Final reward: -0.34528014063835144
Final reward: -0.25125807523727417
Final reward: -0.2194499522447586
Final reward: -0.1960190385580063
Final reward: -0.25693991780281067
Final reward: -0.2643260657787323
Final reward: -0.32805725932121277
Final reward: -0.33069390058517456
Final reward: -0.208859384059906
Final reward: -0.1835305094718933
Final reward: -0.26094144582748413
Final reward: -0.33684831857681274
Final reward: -0.32141295075416565
Final reward: -0.11423061788082123
Final reward: -0.4776202142238617
Final reward: -0.4781976640224457
Final reward: -0.4795001447200775
Final reward: -0.4820047616958618
Final reward: -0.48633962869644165
Final reward: -0.4931795001029968
Final reward: -0.5030730962753296
Final reward: -0.5162071585655212
Final reward: -0.5321499109268188
Final reward: -0.5496465563774109
Final reward: -0.5665505528450012
Final reward: -0.5799556374549866
Final reward: -0.586574375629425
Final reward: -0.592837929725647
Final reward: -0.5877040028572083
Final reward: -0.5714871287345886
Final reward: -0.546076238155365
Final reward: -0.5165475606918335
Final reward: -0.47895577549934387
Final reward: -0.4356856346130371
Final reward: -0.3863886296749115
Final reward: -0.3241245448589325
Final reward: -0.24278169870376587
Final reward: -0.20304062962532043
Final reward: -0.2830870449542999
Final reward: -0.3469691574573517
Final reward: -0.36429229378700256
Final reward: -0.2882753610610962
Final reward: -0.2251744121313095
Final reward: -0.23276618123054504
Final reward: -0.24856141209602356
Final reward: -0.281330943107605
Final reward: -0.25887182354927063
Final reward: -0.31666573882102966
Final reward: -0.3086845576763153
Final reward: -0.16072878241539001
Final reward: -0.21885044872760773
Final reward: -0.24281999468803406
Final reward: -0.3179415762424469
Final reward: -0.30271658301353455
Final reward: -0.10301829874515533
Final reward: -0.7430484890937805
Final reward: -0.7434198260307312
Final reward: -0.7442582845687866
Final reward: -0.7458744049072266
Final reward: -0.748682975769043
Final reward: -0.7531440854072571
Final reward: -0.759659469127655
Final reward: -0.7684203386306763
Final reward: -0.7792198061943054
Final reward: -0.791271984577179
Final reward: -0.8031061291694641
Final reward: -0.8126183152198792
Final reward: -0.817355215549469
Final reward: -0.8177690505981445
Final reward: -0.8158633708953857
Final reward: -0.8077924251556396
Final reward: -0.7932077646255493
Final reward: -0.7769396901130676
Final reward: -0.7552413940429688
Final reward: -0.7340073585510254
Final reward: -0.7096635103225708
Final reward: -0.6816964149475098
Final reward: -0.6519667506217957
Final reward: -0.6199992895126343
Final reward: -0.5818928480148315
Final reward: -0.5360643267631531
Final reward: -0.4996791481971741
Final reward: -0.4433353841304779
Final reward: -0.37653404474258423
Final reward: -0.3117877244949341
Final reward: -0.2004120647907257
Final reward: -0.24282249808311462
Final reward: -0.30301782488822937
Final reward: -0.2332916259765625
Final reward: -0.241613507270813
Final reward: -0.23008009791374207
Final reward: -0.2673989236354828
Final reward: -0.33160990476608276
Final reward: -0.34206604957580566
Final reward: -0.15568791329860687
Final reward: -0.1496550440788269
Final reward: -0.2994495928287506
Final reward: -0.36621761322021484
Final reward: -0.3350679576396942
Final reward: -0.13417476415634155
Final reward: -0.2089300900697708
Final reward: -0.3404110372066498
Final reward: -0.3966139554977417
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.3372889757156372
Final reward: -0.20397959649562836
Final reward: -0.198232501745224
Final reward: -0.2810933291912079
Final reward: -0.34980446100234985
Final reward: -0.29749730229377747
Final reward: -0.11741533875465393
Final reward: -0.712826132774353
Final reward: -0.7132131457328796
Final reward: -0.7140870690345764
Final reward: -0.7157713174819946
Final reward: -0.7186976075172424
Final reward: -0.7233436107635498
Final reward: -0.7301250100135803
Final reward: -0.7392359972000122
Final reward: -0.7504555583000183
Final reward: -0.7629622220993042
Final reward: -0.7752286791801453
Final reward: -0.7850786447525024
Final reward: -0.7899807095527649
Final reward: -0.7946425676345825
Final reward: -0.7949740290641785
Final reward: -0.7814969420433044
Final reward: -0.759859025478363
Final reward: -0.7358546257019043
Final reward: -0.709025502204895
Final reward: -0.6807435750961304
Final reward: -0.6487065553665161
Final reward: -0.6135419011116028
Final reward: -0.5750024318695068
Final reward: -0.5312204957008362
Final reward: -0.4814661145210266
Final reward: -0.4228045344352722
Final reward: -0.36480119824409485
Final reward: -0.2919231057167053
Final reward: -0.16617096960544586
Final reward: -0.2399653196334839
Final reward: -0.3042507469654083
Final reward: -0.2366555780172348
Final reward: -0.23894557356834412
Final reward: -0.23440027236938477
Final reward: -0.22783514857292175
Final reward: -0.30255621671676636
Final reward: -0.34137076139450073
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.027 MB of 0.027 MB uploaded (0.000 MB deduped)wandb: \ 0.027 MB of 0.027 MB uploaded (0.000 MB deduped)wandb: | 0.027 MB of 0.027 MB uploaded (0.000 MB deduped)wandb: / 0.027 MB of 0.027 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run history:
wandb:                   avg_speed ‚ñà‚ñÇ‚ñÜ‚ñà‚ñÅ‚ñÅ‚ñà‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñÑ‚ñÇ‚ñÉ‚ñà‚ñà‚ñà‚ñà‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñÉ‚ñà‚ñà‚ñÜ‚ñÜ‚ñà‚ñá
wandb:                        cost ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñà‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñÅ‚ñÅ
wandb:                  is_success ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                   max_speed ‚ñà‚ñÇ‚ñÜ‚ñà‚ñÅ‚ñÅ‚ñà‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñÑ‚ñÇ‚ñÉ‚ñà‚ñà‚ñà‚ñà‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñÉ‚ñà‚ñà‚ñÜ‚ñÜ‚ñà‚ñá
wandb:                      reward ‚ñÅ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà
wandb:             train/approx_kl ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñá‚ñÇ‚ñÜ‚ñÇ‚ñÖ‚ñá‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñà‚ñÇ‚ñÉ‚ñÉ‚ñÑ
wandb:         train/clip_fraction ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÑ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñÖ‚ñÜ‚ñá
wandb:            train/clip_range ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:          train/cost_returns ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñÖ‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÖ
wandb:       train/cost_value_loss ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñÉ‚ñÖ‚ñà‚ñÖ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:           train/cost_values ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ
wandb:               train/entropy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:          train/entropy_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:    train/explained_variance ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñà‚ñá‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñÜ‚ñá‚ñá
wandb: train/lagrangian_multiplier ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÇ‚ñÖ‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñà‚ñÑ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÅ
wandb:         train/learning_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                  train/loss ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:             train/n_updates ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:  train/policy_gradient_loss ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñÉ‚ñÉ‚ñá‚ñà‚ñÜ‚ñá‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÑ
wandb:                   train/std ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:            train/value_loss ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                   avg_speed 8.0
wandb:                        cost 0
wandb:                  is_success 0
wandb:                   max_speed 8.0
wandb:                      reward -0.23721
wandb:             train/approx_kl 0.01687
wandb:         train/clip_fraction 0.18105
wandb:            train/clip_range 0.2
wandb:          train/cost_returns 4.00241
wandb:       train/cost_value_loss 6.77297
wandb:           train/cost_values 1.97597
wandb:               train/entropy 0.33314
wandb:          train/entropy_loss 0.32943
wandb:    train/explained_variance 0.79255
wandb: train/lagrangian_multiplier 0.0003
wandb:         train/learning_rate 0.0003
wandb:                  train/loss 6.18559
wandb:             train/n_updates 14690
wandb:  train/policy_gradient_loss 0.00124
wandb:                   train/std 0.28882
wandb:            train/value_loss 6.77709
wandb: 
wandb: üöÄ View run abundant-dragon-29 at: https://wandb.ai/ecrl/ent-coefficient-ppol/runs/vlorgroe
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240213_121132-vlorgroe/logs
