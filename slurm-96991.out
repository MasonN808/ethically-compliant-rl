wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20231119_174542-nxgx8r5s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ppo-KLpenalty-beta(dynamic)-parking
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/PPO-Penalty-Report5
wandb: üöÄ View run at https://wandb.ai/ecrl/PPO-Penalty-Report5/runs/nxgx8r5s
Using cpu device
-------------------------------------
| reward             | [-0.7443971] |
| time/              |              |
|    fps             | 158          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 2048         |
-------------------------------------
----------------------------------------------
| reward                      | [-0.8740546] |
| time/                       |              |
|    fps                      | 33           |
|    iterations               | 2            |
|    time_elapsed             | 123          |
|    total_timesteps          | 4096         |
| train/                      |              |
|    approx_kl                | 4.3335443    |
|    approx_ln(kl)            | 1.4663857    |
|    clip_range               | 0.2          |
|    entropy_loss             | -2.79        |
|    explained_variance       | 0.0689       |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 10           |
|    policy_gradient_loss     | inf          |
|    std                      | 0.896        |
|    value_loss               | 32.7         |
----------------------------------------------
----------------------------------------------
| reward                      | [-0.5468913] |
| time/                       |              |
|    fps                      | 27           |
|    iterations               | 3            |
|    time_elapsed             | 226          |
|    total_timesteps          | 6144         |
| train/                      |              |
|    approx_kl                | 10.4154625   |
|    approx_ln(kl)            | 2.3432915    |
|    clip_range               | 0.2          |
|    entropy_loss             | -2.55        |
|    explained_variance       | 0.194        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 20           |
|    policy_gradient_loss     | inf          |
|    std                      | 0.814        |
|    value_loss               | 12.9         |
----------------------------------------------
-----------------------------------------------
| reward                      | [-0.45751125] |
| time/                       |               |
|    fps                      | 33            |
|    iterations               | 4             |
|    time_elapsed             | 241           |
|    total_timesteps          | 8192          |
| train/                      |               |
|    approx_kl                | 13.773245     |
|    approx_ln(kl)            | 2.6227279     |
|    clip_range               | 0.2           |
|    entropy_loss             | -2.38         |
|    explained_variance       | -2.33         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 30            |
|    policy_gradient_loss     | inf           |
|    std                      | 0.78          |
|    value_loss               | 31.8          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: overflow encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.4534693] |
| time/                       |              |
|    fps                      | 40           |
|    iterations               | 5            |
|    time_elapsed             | 254          |
|    total_timesteps          | 10240        |
| train/                      |              |
|    approx_kl                | 9.210163     |
|    approx_ln(kl)            | 2.2203076    |
|    clip_range               | 0.2          |
|    entropy_loss             | -2.3         |
|    explained_variance       | 0.462        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 40           |
|    policy_gradient_loss     | inf          |
|    std                      | 0.742        |
|    value_loss               | 19.4         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.47608358] |
| time/                       |               |
|    fps                      | 45            |
|    iterations               | 6             |
|    time_elapsed             | 268           |
|    total_timesteps          | 12288         |
| train/                      |               |
|    approx_kl                | 8.806732      |
|    approx_ln(kl)            | 2.1755164     |
|    clip_range               | 0.2           |
|    entropy_loss             | -2.23         |
|    explained_variance       | 0.668         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 50            |
|    policy_gradient_loss     | nan           |
|    std                      | 0.737         |
|    value_loss               | 193           |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.49856785] |
| time/                       |               |
|    fps                      | 50            |
|    iterations               | 7             |
|    time_elapsed             | 282           |
|    total_timesteps          | 14336         |
| train/                      |               |
|    approx_kl                | 15.578406     |
|    approx_ln(kl)            | 2.7458858     |
|    clip_range               | 0.2           |
|    entropy_loss             | -2.23         |
|    explained_variance       | 0.824         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 60            |
|    policy_gradient_loss     | nan           |
|    std                      | 0.738         |
|    value_loss               | 301           |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.35783875] |
| time/                       |               |
|    fps                      | 55            |
|    iterations               | 8             |
|    time_elapsed             | 296           |
|    total_timesteps          | 16384         |
| train/                      |               |
|    approx_kl                | 12.0260315    |
|    approx_ln(kl)            | 2.4870737     |
|    clip_range               | 0.2           |
|    entropy_loss             | -2.24         |
|    explained_variance       | 0.959         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 70            |
|    policy_gradient_loss     | nan           |
|    std                      | 0.733         |
|    value_loss               | 33.7          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.3792111] |
| time/                       |              |
|    fps                      | 59           |
|    iterations               | 9            |
|    time_elapsed             | 311          |
|    total_timesteps          | 18432        |
| train/                      |              |
|    approx_kl                | 8.100406     |
|    approx_ln(kl)            | 2.0919142    |
|    clip_range               | 0.2          |
|    entropy_loss             | -2.2         |
|    explained_variance       | 0.972        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 80           |
|    policy_gradient_loss     | nan          |
|    std                      | 0.719        |
|    value_loss               | 11.3         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.2497671] |
| time/                       |              |
|    fps                      | 62           |
|    iterations               | 10           |
|    time_elapsed             | 325          |
|    total_timesteps          | 20480        |
| train/                      |              |
|    approx_kl                | 19.341175    |
|    approx_ln(kl)            | 2.9622362    |
|    clip_range               | 0.2          |
|    entropy_loss             | -2.14        |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 90           |
|    policy_gradient_loss     | nan          |
|    std                      | 0.681        |
|    value_loss               | 0.811        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.55464613] |
| time/                       |               |
|    fps                      | 66            |
|    iterations               | 11            |
|    time_elapsed             | 339           |
|    total_timesteps          | 22528         |
| train/                      |               |
|    approx_kl                | 9.621822      |
|    approx_ln(kl)            | 2.2640338     |
|    clip_range               | 0.2           |
|    entropy_loss             | -2.04         |
|    explained_variance       | 0.997         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 100           |
|    policy_gradient_loss     | nan           |
|    std                      | 0.664         |
|    value_loss               | 0.393         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.9806148] |
| time/                       |              |
|    fps                      | 55           |
|    iterations               | 12           |
|    time_elapsed             | 442          |
|    total_timesteps          | 24576        |
| train/                      |              |
|    approx_kl                | 4.9656515    |
|    approx_ln(kl)            | 1.6025445    |
|    clip_range               | 0.2          |
|    entropy_loss             | -2.01        |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 110          |
|    policy_gradient_loss     | nan          |
|    std                      | 0.651        |
|    value_loss               | 0.46         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0022174] |
| time/                       |              |
|    fps                      | 48           |
|    iterations               | 13           |
|    time_elapsed             | 546          |
|    total_timesteps          | 26624        |
| train/                      |              |
|    approx_kl                | 9.022474     |
|    approx_ln(kl)            | 2.1997187    |
|    clip_range               | 0.2          |
|    entropy_loss             | -1.97        |
|    explained_variance       | 0.803        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 120          |
|    policy_gradient_loss     | nan          |
|    std                      | 0.65         |
|    value_loss               | 3.34         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-1.127823] |
| time/                       |             |
|    fps                      | 43          |
|    iterations               | 14          |
|    time_elapsed             | 659         |
|    total_timesteps          | 28672       |
| train/                      |             |
|    approx_kl                | 8.873821    |
|    approx_ln(kl)            | 2.1831055   |
|    clip_range               | 0.2         |
|    entropy_loss             | -1.97       |
|    explained_variance       | 0.854       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 130         |
|    policy_gradient_loss     | nan         |
|    std                      | 0.639       |
|    value_loss               | 2.3         |
---------------------------------------------
----------------------------------------------
| reward                      | [-1.8046834] |
| time/                       |              |
|    fps                      | 39           |
|    iterations               | 15           |
|    time_elapsed             | 769          |
|    total_timesteps          | 30720        |
| train/                      |              |
|    approx_kl                | 3.0870957    |
|    approx_ln(kl)            | 1.1272308    |
|    clip_range               | 0.2          |
|    entropy_loss             | -1.93        |
|    explained_variance       | 0.915        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 140          |
|    policy_gradient_loss     | inf          |
|    std                      | 0.636        |
|    value_loss               | 78.3         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/numpy/core/_methods.py:181: RuntimeWarning: invalid value encountered in reduce
  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)
----------------------------------------------
| reward                      | [-1.8419158] |
| time/                       |              |
|    fps                      | 37           |
|    iterations               | 16           |
|    time_elapsed             | 871          |
|    total_timesteps          | 32768        |
| train/                      |              |
|    approx_kl                | 1.3190358    |
|    approx_ln(kl)            | 0.27690098   |
|    clip_range               | 0.2          |
|    entropy_loss             | -1.92        |
|    explained_variance       | 0.936        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 150          |
|    policy_gradient_loss     | nan          |
|    std                      | 0.631        |
|    value_loss               | 44.4         |
----------------------------------------------
----------------------------------------------
| reward                      | [-2.0614004] |
| time/                       |              |
|    fps                      | 35           |
|    iterations               | 17           |
|    time_elapsed             | 974          |
|    total_timesteps          | 34816        |
| train/                      |              |
|    approx_kl                | 5.471349     |
|    approx_ln(kl)            | 1.6995251    |
|    clip_range               | 0.2          |
|    entropy_loss             | -1.91        |
|    explained_variance       | 0.863        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 160          |
|    policy_gradient_loss     | inf          |
|    std                      | 0.627        |
|    value_loss               | 68.6         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
--------------------------------------------
| reward                      | [-3.07884] |
| time/                       |            |
|    fps                      | 34         |
|    iterations               | 18         |
|    time_elapsed             | 1083       |
|    total_timesteps          | 36864      |
| train/                      |            |
|    approx_kl                | 7.85724    |
|    approx_ln(kl)            | 2.0614355  |
|    clip_range               | 0.2        |
|    entropy_loss             | -1.9       |
|    explained_variance       | 0.964      |
|    learning_rate            | 0.001      |
|    ln(loss)                 | inf        |
|    ln(policy_gradient_loss) | nan        |
|    loss                     | inf        |
|    n_updates                | 170        |
|    policy_gradient_loss     | nan        |
|    std                      | 0.623      |
|    value_loss               | 25.9       |
--------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.0757096] |
| time/                       |              |
|    fps                      | 35           |
|    iterations               | 19           |
|    time_elapsed             | 1100         |
|    total_timesteps          | 38912        |
| train/                      |              |
|    approx_kl                | 2.5284688    |
|    approx_ln(kl)            | 0.927614     |
|    clip_range               | 0.2          |
|    entropy_loss             | -1.89        |
|    explained_variance       | 0.883        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 180          |
|    policy_gradient_loss     | nan          |
|    std                      | 0.622        |
|    value_loss               | 20           |
----------------------------------------------
----------------------------------------------
| reward                      | [-3.1276526] |
| time/                       |              |
|    fps                      | 36           |
|    iterations               | 20           |
|    time_elapsed             | 1115         |
|    total_timesteps          | 40960        |
| train/                      |              |
|    approx_kl                | 1.0244658    |
|    approx_ln(kl)            | 0.024171306  |
|    clip_range               | 0.2          |
|    entropy_loss             | -1.89        |
|    explained_variance       | 0.94         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 190          |
|    policy_gradient_loss     | inf          |
|    std                      | 0.621        |
|    value_loss               | 58.6         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.35424668] |
| time/                       |               |
|    fps                      | 38            |
|    iterations               | 21            |
|    time_elapsed             | 1130          |
|    total_timesteps          | 43008         |
| train/                      |               |
|    approx_kl                | 2.342947      |
|    approx_ln(kl)            | 0.85140955    |
|    clip_range               | 0.2           |
|    entropy_loss             | -1.86         |
|    explained_variance       | 0.9           |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 200           |
|    policy_gradient_loss     | nan           |
|    std                      | 0.608         |
|    value_loss               | 55.4          |
-----------------------------------------------
-----------------------------------------------
| reward                      | [-0.92089516] |
| time/                       |               |
|    fps                      | 39            |
|    iterations               | 22            |
|    time_elapsed             | 1145          |
|    total_timesteps          | 45056         |
| train/                      |               |
|    approx_kl                | 5.3161445     |
|    approx_ln(kl)            | 1.6707484     |
|    clip_range               | 0.2           |
|    entropy_loss             | -1.84         |
|    explained_variance       | 0.945         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 210           |
|    policy_gradient_loss     | inf           |
|    std                      | 0.607         |
|    value_loss               | 49.9          |
-----------------------------------------------
----------------------------------------------
| reward                      | [-1.1448184] |
| time/                       |              |
|    fps                      | 40           |
|    iterations               | 23           |
|    time_elapsed             | 1159         |
|    total_timesteps          | 47104        |
| train/                      |              |
|    approx_kl                | 7.2937584    |
|    approx_ln(kl)            | 1.987019     |
|    clip_range               | 0.2          |
|    entropy_loss             | -1.84        |
|    explained_variance       | 0.948        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 220          |
|    policy_gradient_loss     | inf          |
|    std                      | 0.608        |
|    value_loss               | 71.4         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.1776581] |
| time/                       |              |
|    fps                      | 41           |
|    iterations               | 24           |
|    time_elapsed             | 1180         |
|    total_timesteps          | 49152        |
| train/                      |              |
|    approx_kl                | 8.26569      |
|    approx_ln(kl)            | 2.1121132    |
|    clip_range               | 0.2          |
|    entropy_loss             | -1.84        |
|    explained_variance       | 0.923        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 230          |
|    policy_gradient_loss     | nan          |
|    std                      | 0.607        |
|    value_loss               | 101          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/numpy/core/_methods.py:181: RuntimeWarning: invalid value encountered in reduce
  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)
----------------------------------------------
| reward                      | [-1.5945467] |
| time/                       |              |
|    fps                      | 42           |
|    iterations               | 25           |
|    time_elapsed             | 1194         |
|    total_timesteps          | 51200        |
| train/                      |              |
|    approx_kl                | 3.3727484    |
|    approx_ln(kl)            | 1.2157279    |
|    clip_range               | 0.2          |
|    entropy_loss             | -1.83        |
|    explained_variance       | 0.968        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 240          |
|    policy_gradient_loss     | nan          |
|    std                      | 0.606        |
|    value_loss               | 55.1         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/numpy/core/_methods.py:181: RuntimeWarning: invalid value encountered in reduce
  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)
---------------------------------------------
| reward                      | [-1.455405] |
| time/                       |             |
|    fps                      | 40          |
|    iterations               | 26          |
|    time_elapsed             | 1303        |
|    total_timesteps          | 53248       |
| train/                      |             |
|    approx_kl                | 59.027405   |
|    approx_ln(kl)            | 4.078002    |
|    clip_range               | 0.2         |
|    entropy_loss             | -1.84       |
|    explained_variance       | 0.977       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 250         |
|    policy_gradient_loss     | nan         |
|    std                      | 0.608       |
|    value_loss               | 37.4        |
---------------------------------------------
----------------------------------------------
| reward                      | [-1.4515188] |
| time/                       |              |
|    fps                      | 38           |
|    iterations               | 27           |
|    time_elapsed             | 1419         |
|    total_timesteps          | 55296        |
| train/                      |              |
|    approx_kl                | 8.12982      |
|    approx_ln(kl)            | 2.0955389    |
|    clip_range               | 0.2          |
|    entropy_loss             | -1.82        |
|    explained_variance       | 0.956        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 260          |
|    policy_gradient_loss     | inf          |
|    std                      | 0.6          |
|    value_loss               | 7.26         |
----------------------------------------------
---------------------------------------------
| reward                      | [-1.565656] |
| time/                       |             |
|    fps                      | 37          |
|    iterations               | 28          |
|    time_elapsed             | 1523        |
|    total_timesteps          | 57344       |
| train/                      |             |
|    approx_kl                | 18.515219   |
|    approx_ln(kl)            | 2.918593    |
|    clip_range               | 0.2         |
|    entropy_loss             | -1.84       |
|    explained_variance       | 0.947       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | inf         |
|    loss                     | inf         |
|    n_updates                | 270         |
|    policy_gradient_loss     | inf         |
|    std                      | 0.617       |
|    value_loss               | 6.6         |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/numpy/core/_methods.py:181: RuntimeWarning: invalid value encountered in reduce
  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)
---------------------------------------------
| reward                      | [-1.715986] |
| time/                       |             |
|    fps                      | 38          |
|    iterations               | 29          |
|    time_elapsed             | 1537        |
|    total_timesteps          | 59392       |
| train/                      |             |
|    approx_kl                | 8.673699    |
|    approx_ln(kl)            | 2.1602955   |
|    clip_range               | 0.2         |
|    entropy_loss             | -1.85       |
|    explained_variance       | 0.973       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 280         |
|    policy_gradient_loss     | nan         |
|    std                      | 0.6         |
|    value_loss               | 9.43        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/numpy/core/_methods.py:181: RuntimeWarning: invalid value encountered in reduce
  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)
----------------------------------------------
| reward                      | [-3.0243795] |
| time/                       |              |
|    fps                      | 39           |
|    iterations               | 30           |
|    time_elapsed             | 1550         |
|    total_timesteps          | 61440        |
| train/                      |              |
|    approx_kl                | 7.003627     |
|    approx_ln(kl)            | 1.9464282    |
|    clip_range               | 0.2          |
|    entropy_loss             | -1.81        |
|    explained_variance       | 0.855        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 290          |
|    policy_gradient_loss     | nan          |
|    std                      | 0.6          |
|    value_loss               | 12           |
----------------------------------------------
----------------------------------------------
| reward                      | [-3.6602507] |
| time/                       |              |
|    fps                      | 40           |
|    iterations               | 31           |
|    time_elapsed             | 1565         |
|    total_timesteps          | 63488        |
| train/                      |              |
|    approx_kl                | 17.801256    |
|    approx_ln(kl)            | 2.8792691    |
|    clip_range               | 0.2          |
|    entropy_loss             | -1.82        |
|    explained_variance       | 0.872        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 300          |
|    policy_gradient_loss     | inf          |
|    std                      | 0.605        |
|    value_loss               | 17.8         |
----------------------------------------------
----------------------------------------------
| reward                      | [-0.7364158] |
| time/                       |              |
|    fps                      | 41           |
|    iterations               | 32           |
|    time_elapsed             | 1579         |
|    total_timesteps          | 65536        |
| train/                      |              |
|    approx_kl                | 9.96274      |
|    approx_ln(kl)            | 2.2988522    |
|    clip_range               | 0.2          |
|    entropy_loss             | -1.82        |
|    explained_variance       | 0.926        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 310          |
|    policy_gradient_loss     | inf          |
|    std                      | 0.6          |
|    value_loss               | 24           |
----------------------------------------------
-----------------------------------------------
| reward                      | [-0.87709063] |
| time/                       |               |
|    fps                      | 42            |
|    iterations               | 33            |
|    time_elapsed             | 1593          |
|    total_timesteps          | 67584         |
| train/                      |               |
|    approx_kl                | 6.0532775     |
|    approx_ln(kl)            | 1.8005998     |
|    clip_range               | 0.2           |
|    entropy_loss             | -1.81         |
|    explained_variance       | 0.919         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 320           |
|    policy_gradient_loss     | inf           |
|    std                      | 0.601         |
|    value_loss               | 47.2          |
-----------------------------------------------
----------------------------------------------
| reward                      | [-1.3884573] |
| time/                       |              |
|    fps                      | 43           |
|    iterations               | 34           |
|    time_elapsed             | 1607         |
|    total_timesteps          | 69632        |
| train/                      |              |
|    approx_kl                | 27.520645    |
|    approx_ln(kl)            | 3.3149364    |
|    clip_range               | 0.2          |
|    entropy_loss             | -1.81        |
|    explained_variance       | 0.991        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 330          |
|    policy_gradient_loss     | inf          |
|    std                      | 0.601        |
|    value_loss               | 12.3         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.0225644] |
| time/                       |              |
|    fps                      | 44           |
|    iterations               | 35           |
|    time_elapsed             | 1621         |
|    total_timesteps          | 71680        |
| train/                      |              |
|    approx_kl                | 18.172394    |
|    approx_ln(kl)            | 2.8999035    |
|    clip_range               | 0.2          |
|    entropy_loss             | -1.72        |
|    explained_variance       | 0.987        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 340          |
|    policy_gradient_loss     | nan          |
|    std                      | 0.557        |
|    value_loss               | 8.16         |
----------------------------------------------
----------------------------------------------
| reward                      | [-2.3661416] |
| time/                       |              |
|    fps                      | 45           |
|    iterations               | 36           |
|    time_elapsed             | 1635         |
|    total_timesteps          | 73728        |
| train/                      |              |
|    approx_kl                | 6.8454075    |
|    approx_ln(kl)            | 1.923578     |
|    clip_range               | 0.2          |
|    entropy_loss             | -1.66        |
|    explained_variance       | 0.988        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 350          |
|    policy_gradient_loss     | inf          |
|    std                      | 0.559        |
|    value_loss               | 20.2         |
----------------------------------------------
---------------------------------------------
| reward                      | [-2.267069] |
| time/                       |             |
|    fps                      | 45          |
|    iterations               | 37          |
|    time_elapsed             | 1649        |
|    total_timesteps          | 75776       |
| train/                      |             |
|    approx_kl                | 4.062958    |
|    approx_ln(kl)            | 1.4019113   |
|    clip_range               | 0.2         |
|    entropy_loss             | -1.67       |
|    explained_variance       | 0.985       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | inf         |
|    loss                     | inf         |
|    n_updates                | 360         |
|    policy_gradient_loss     | inf         |
|    std                      | 0.562       |
|    value_loss               | 10.3        |
---------------------------------------------
----------------------------------------------
| reward                      | [-2.1722054] |
| time/                       |              |
|    fps                      | 46           |
|    iterations               | 38           |
|    time_elapsed             | 1663         |
|    total_timesteps          | 77824        |
| train/                      |              |
|    approx_kl                | 2.4908392    |
|    approx_ln(kl)            | 0.9126197    |
|    clip_range               | 0.2          |
|    entropy_loss             | -1.67        |
|    explained_variance       | 0.991        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 370          |
|    policy_gradient_loss     | inf          |
|    std                      | 0.562        |
|    value_loss               | 15.1         |
----------------------------------------------
----------------------------------------------
| reward                      | [-2.7576325] |
| time/                       |              |
|    fps                      | 47           |
|    iterations               | 39           |
|    time_elapsed             | 1677         |
|    total_timesteps          | 79872        |
| train/                      |              |
|    approx_kl                | 1.2934382    |
|    approx_ln(kl)            | 0.25730395   |
|    clip_range               | 0.2          |
|    entropy_loss             | -1.67        |
|    explained_variance       | 0.983        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 380          |
|    policy_gradient_loss     | inf          |
|    std                      | 0.561        |
|    value_loss               | 16.7         |
----------------------------------------------
----------------------------------------------
| reward                      | [-3.3530438] |
| time/                       |              |
|    fps                      | 48           |
|    iterations               | 40           |
|    time_elapsed             | 1690         |
|    total_timesteps          | 81920        |
| train/                      |              |
|    approx_kl                | 14.923737    |
|    approx_ln(kl)            | 2.702953     |
|    clip_range               | 0.2          |
|    entropy_loss             | -1.67        |
|    explained_variance       | 0.984        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 390          |
|    policy_gradient_loss     | inf          |
|    std                      | 0.562        |
|    value_loss               | 13.3         |
----------------------------------------------
----------------------------------------------
| reward                      | [-3.1975381] |
| time/                       |              |
|    fps                      | 49           |
|    iterations               | 41           |
|    time_elapsed             | 1704         |
|    total_timesteps          | 83968        |
| train/                      |              |
|    approx_kl                | 13.817461    |
|    approx_ln(kl)            | 2.6259332    |
|    clip_range               | 0.2          |
|    entropy_loss             | -1.68        |
|    explained_variance       | 0.966        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 400          |
|    policy_gradient_loss     | inf          |
|    std                      | 0.56         |
|    value_loss               | 11.5         |
----------------------------------------------
----------------------------------------------
| reward                      | [-0.5735713] |
| time/                       |              |
|    fps                      | 50           |
|    iterations               | 42           |
|    time_elapsed             | 1718         |
|    total_timesteps          | 86016        |
| train/                      |              |
|    approx_kl                | 5.511853     |
|    approx_ln(kl)            | 1.7069008    |
|    clip_range               | 0.2          |
|    entropy_loss             | -1.66        |
|    explained_variance       | 0.976        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 410          |
|    policy_gradient_loss     | inf          |
|    std                      | 0.561        |
|    value_loss               | 30.2         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.9719631] |
| time/                       |              |
|    fps                      | 50           |
|    iterations               | 43           |
|    time_elapsed             | 1732         |
|    total_timesteps          | 88064        |
| train/                      |              |
|    approx_kl                | 1.8681113    |
|    approx_ln(kl)            | 0.6249279    |
|    clip_range               | 0.2          |
|    entropy_loss             | -1.66        |
|    explained_variance       | 0.97         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 420          |
|    policy_gradient_loss     | nan          |
|    std                      | 0.561        |
|    value_loss               | 62.9         |
----------------------------------------------
----------------------------------------------
| reward                      | [-1.4872783] |
| time/                       |              |
|    fps                      | 51           |
|    iterations               | 44           |
|    time_elapsed             | 1746         |
|    total_timesteps          | 90112        |
| train/                      |              |
|    approx_kl                | 4.3114777    |
|    approx_ln(kl)            | 1.4612807    |
|    clip_range               | 0.2          |
|    entropy_loss             | -1.66        |
|    explained_variance       | 0.976        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 430          |
|    policy_gradient_loss     | inf          |
|    std                      | 0.559        |
|    value_loss               | 21.9         |
----------------------------------------------
----------------------------------------------
| reward                      | [-1.2561432] |
| time/                       |              |
|    fps                      | 52           |
|    iterations               | 45           |
|    time_elapsed             | 1760         |
|    total_timesteps          | 92160        |
| train/                      |              |
|    approx_kl                | 6.7247734    |
|    approx_ln(kl)            | 1.9057982    |
|    clip_range               | 0.2          |
|    entropy_loss             | -1.64        |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 440          |
|    policy_gradient_loss     | inf          |
|    std                      | 0.55         |
|    value_loss               | 5.39         |
----------------------------------------------
---------------------------------------------
| reward                      | [-2.126725] |
| time/                       |             |
|    fps                      | 53          |
|    iterations               | 46          |
|    time_elapsed             | 1773        |
|    total_timesteps          | 94208       |
| train/                      |             |
|    approx_kl                | 5.192726    |
|    approx_ln(kl)            | 1.6472589   |
|    clip_range               | 0.2         |
|    entropy_loss             | -1.62       |
|    explained_variance       | 0.975       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | inf         |
|    loss                     | inf         |
|    n_updates                | 450         |
|    policy_gradient_loss     | inf         |
|    std                      | 0.552       |
|    value_loss               | 30.2        |
---------------------------------------------
----------------------------------------------
| reward                      | [-2.2727544] |
| time/                       |              |
|    fps                      | 53           |
|    iterations               | 47           |
|    time_elapsed             | 1787         |
|    total_timesteps          | 96256        |
| train/                      |              |
|    approx_kl                | 7.8861017    |
|    approx_ln(kl)            | 2.0651019    |
|    clip_range               | 0.2          |
|    entropy_loss             | -1.62        |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 460          |
|    policy_gradient_loss     | inf          |
|    std                      | 0.551        |
|    value_loss               | 5.13         |
----------------------------------------------
----------------------------------------------
| reward                      | [-2.5399969] |
| time/                       |              |
|    fps                      | 54           |
|    iterations               | 48           |
|    time_elapsed             | 1801         |
|    total_timesteps          | 98304        |
| train/                      |              |
|    approx_kl                | 1.9606531    |
|    approx_ln(kl)            | 0.6732776    |
|    clip_range               | 0.2          |
|    entropy_loss             | -1.62        |
|    explained_variance       | 0.981        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 470          |
|    policy_gradient_loss     | inf          |
|    std                      | 0.544        |
|    value_loss               | 6.74         |
----------------------------------------------
----------------------------------------------
| reward                      | [-2.3272536] |
| time/                       |              |
|    fps                      | 55           |
|    iterations               | 49           |
|    time_elapsed             | 1814         |
|    total_timesteps          | 100352       |
| train/                      |              |
|    approx_kl                | 6.0816727    |
|    approx_ln(kl)            | 1.8052797    |
|    clip_range               | 0.2          |
|    entropy_loss             | -1.61        |
|    explained_variance       | 0.985        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 480          |
|    policy_gradient_loss     | inf          |
|    std                      | 0.54         |
|    value_loss               | 15           |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/save_util.py:283: UserWarning: Path 'PPO_penalty/models/dynamic' does not exist. Will create it.
  warnings.warn(f"Path '{path.parent}' does not exist. Will create it.")
-------------------------------------
| reward             | [-1.0942369] |
| time/              |              |
|    fps             | 162          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 102400       |
-------------------------------------
/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/numpy/core/_methods.py:181: RuntimeWarning: invalid value encountered in reduce
  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)
----------------------------------------------
| reward                      | [-1.7605783] |
| time/                       |              |
|    fps                      | 156          |
|    iterations               | 2            |
|    time_elapsed             | 26           |
|    total_timesteps          | 104448       |
| train/                      |              |
|    approx_kl                | 12.298466    |
|    approx_ln(kl)            | 2.5094745    |
|    clip_range               | 0.2          |
|    entropy_loss             | -1.6         |
|    explained_variance       | 0.905        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 500          |
|    policy_gradient_loss     | nan          |
|    std                      | 0.541        |
|    value_loss               | 22.2         |
----------------------------------------------
----------------------------------------------
| reward                      | [-2.3043547] |
| time/                       |              |
|    fps                      | 154          |
|    iterations               | 3            |
|    time_elapsed             | 39           |
|    total_timesteps          | 106496       |
| train/                      |              |
|    approx_kl                | 31.049496    |
|    approx_ln(kl)            | 3.4355826    |
|    clip_range               | 0.2          |
|    entropy_loss             | -1.61        |
|    explained_variance       | 0.389        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 510          |
|    policy_gradient_loss     | inf          |
|    std                      | 0.546        |
|    value_loss               | 47.8         |
----------------------------------------------
-----------------------------------------------
| reward                      | [-0.65819925] |
| time/                       |               |
|    fps                      | 153           |
|    iterations               | 4             |
|    time_elapsed             | 53            |
|    total_timesteps          | 108544        |
| train/                      |               |
|    approx_kl                | 19.621382     |
|    approx_ln(kl)            | 2.97662       |
|    clip_range               | 0.2           |
|    entropy_loss             | -1.61         |
|    explained_variance       | 0.481         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 520           |
|    policy_gradient_loss     | inf           |
|    std                      | 0.547         |
|    value_loss               | 17.8          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/numpy/core/_methods.py:181: RuntimeWarning: invalid value encountered in reduce
  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)
----------------------------------------------
| reward                      | [-1.0235294] |
| time/                       |              |
|    fps                      | 152          |
|    iterations               | 5            |
|    time_elapsed             | 67           |
|    total_timesteps          | 110592       |
| train/                      |              |
|    approx_kl                | 15.560795    |
|    approx_ln(kl)            | 2.7447546    |
|    clip_range               | 0.2          |
|    entropy_loss             | -1.55        |
|    explained_variance       | 0.639        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 530          |
|    policy_gradient_loss     | nan          |
|    std                      | 0.504        |
|    value_loss               | 5.95         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/numpy/core/_methods.py:181: RuntimeWarning: invalid value encountered in reduce
  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)
----------------------------------------------
| reward                      | [-0.9512533] |
| time/                       |              |
|    fps                      | 152          |
|    iterations               | 6            |
|    time_elapsed             | 80           |
|    total_timesteps          | 112640       |
| train/                      |              |
|    approx_kl                | 22.5335      |
|    approx_ln(kl)            | 3.115003     |
|    clip_range               | 0.2          |
|    entropy_loss             | -1.48        |
|    explained_variance       | 0.75         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 540          |
|    policy_gradient_loss     | nan          |
|    std                      | 0.495        |
|    value_loss               | 1.42         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.1545548] |
| time/                       |              |
|    fps                      | 151          |
|    iterations               | 7            |
|    time_elapsed             | 94           |
|    total_timesteps          | 114688       |
| train/                      |              |
|    approx_kl                | 16.7496      |
|    approx_ln(kl)            | 2.8183744    |
|    clip_range               | 0.2          |
|    entropy_loss             | -1.4         |
|    explained_variance       | 0.92         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 550          |
|    policy_gradient_loss     | nan          |
|    std                      | 0.472        |
|    value_loss               | 4.36         |
----------------------------------------------
----------------------------------------------
| reward                      | [-0.8749993] |
| time/                       |              |
|    fps                      | 151          |
|    iterations               | 8            |
|    time_elapsed             | 107          |
|    total_timesteps          | 116736       |
| train/                      |              |
|    approx_kl                | 4.3171372    |
|    approx_ln(kl)            | 1.4625925    |
|    clip_range               | 0.2          |
|    entropy_loss             | -1.31        |
|    explained_variance       | 0.91         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 560          |
|    policy_gradient_loss     | inf          |
|    std                      | 0.458        |
|    value_loss               | 2.42         |
----------------------------------------------
----------------------------------------------
| reward                      | [-0.8496282] |
| time/                       |              |
|    fps                      | 151          |
|    iterations               | 9            |
|    time_elapsed             | 121          |
|    total_timesteps          | 118784       |
| train/                      |              |
|    approx_kl                | 6.4478455    |
|    approx_ln(kl)            | 1.863746     |
|    clip_range               | 0.2          |
|    entropy_loss             | -1.27        |
|    explained_variance       | 0.843        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 570          |
|    policy_gradient_loss     | inf          |
|    std                      | 0.457        |
|    value_loss               | 8.16         |
----------------------------------------------
----------------------------------------------
| reward                      | [-0.7460092] |
| time/                       |              |
|    fps                      | 151          |
|    iterations               | 10           |
|    time_elapsed             | 135          |
|    total_timesteps          | 120832       |
| train/                      |              |
|    approx_kl                | 7.714504     |
|    approx_ln(kl)            | 2.0431023    |
|    clip_range               | 0.2          |
|    entropy_loss             | -1.21        |
|    explained_variance       | 0.275        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 580          |
|    policy_gradient_loss     | inf          |
|    std                      | 0.43         |
|    value_loss               | 1.91         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/.venv/lib/python3.9/site-packages/numpy/core/_methods.py:181: RuntimeWarning: invalid value encountered in reduce
  ret = umr_sum(arr, axis, dtype, out, keepdims, where=where)
----------------------------------------------
| reward                      | [-1.9390038] |
| time/                       |              |
|    fps                      | 151          |
|    iterations               | 11           |
|    time_elapsed             | 148          |
|    total_timesteps          | 122880       |
| train/                      |              |
|    approx_kl                | 29.426832    |
|    approx_ln(kl)            | 3.381907     |
|    clip_range               | 0.2          |
|    entropy_loss             | -1.1         |
|    explained_variance       | 0.971        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 590          |
|    policy_gradient_loss     | nan          |
|    std                      | 0.393        |
|    value_loss               | 0.641        |
----------------------------------------------
-----------------------------------------------
| reward                      | [-0.38058004] |
| time/                       |               |
|    fps                      | 151           |
|    iterations               | 12            |
|    time_elapsed             | 162           |
|    total_timesteps          | 124928        |
| train/                      |               |
|    approx_kl                | 38.132027     |
|    approx_ln(kl)            | 3.6410546     |
|    clip_range               | 0.2           |
|    entropy_loss             | -0.948        |
|    explained_variance       | 0.807         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 600           |
|    policy_gradient_loss     | inf           |
|    std                      | 0.393         |
|    value_loss               | 4.32          |
-----------------------------------------------
----------------------------------------------
| reward                      | [-1.6910639] |
| time/                       |              |
|    fps                      | 151          |
|    iterations               | 13           |
|    time_elapsed             | 175          |
|    total_timesteps          | 126976       |
| train/                      |              |
|    approx_kl                | 2.8412547    |
|    approx_ln(kl)            | 1.0442457    |
|    clip_range               | 0.2          |
|    entropy_loss             | -0.943       |
|    explained_variance       | 0.526        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 610          |
|    policy_gradient_loss     | inf          |
|    std                      | 0.384        |
|    value_loss               | 2.74         |
----------------------------------------------
-----------------------------------------------
| reward                      | [-0.34121394] |
| time/                       |               |
|    fps                      | 151           |
|    iterations               | 14            |
|    time_elapsed             | 189           |
|    total_timesteps          | 129024        |
| train/                      |               |
|    approx_kl                | 28.24028      |
|    approx_ln(kl)            | 3.3407493     |
|    clip_range               | 0.2           |
|    entropy_loss             | -0.876        |
|    explained_variance       | 0.988         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 620           |
|    policy_gradient_loss     | inf           |
|    std                      | 0.367         |
|    value_loss               | 1.29          |
-----------------------------------------------
-----------------------------------------------
| reward                      | [-0.52465963] |
| time/                       |               |
|    fps                      | 151           |
|    iterations               | 15            |
|    time_elapsed             | 202           |
|    total_timesteps          | 131072        |
| train/                      |               |
|    approx_kl                | 64.79652      |
|    approx_ln(kl)            | 4.171252      |
|    clip_range               | 0.2           |
|    entropy_loss             | -0.719        |
|    explained_variance       | 0.996         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 630           |
|    policy_gradient_loss     | inf           |
|    std                      | 0.334         |
|    value_loss               | 0.295         |
-----------------------------------------------
-----------------------------------------------
| reward                      | [-0.84342825] |
| time/                       |               |
|    fps                      | 151           |
|    iterations               | 16            |
|    time_elapsed             | 216           |
|    total_timesteps          | 133120        |
| train/                      |               |
|    approx_kl                | 21.8218       |
|    approx_ln(kl)            | 3.0829096     |
|    clip_range               | 0.2           |
|    entropy_loss             | -0.56         |
|    explained_variance       | 0.996         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 640           |
|    policy_gradient_loss     | inf           |
|    std                      | 0.313         |
|    value_loss               | 0.57          |
-----------------------------------------------
----------------------------------------------
| reward                      | [-0.5783403] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 17           |
|    time_elapsed             | 232          |
|    total_timesteps          | 135168       |
| train/                      |              |
|    approx_kl                | 4.815834     |
|    approx_ln(kl)            | 1.5719092    |
|    clip_range               | 0.2          |
|    entropy_loss             | -0.463       |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 650          |
|    policy_gradient_loss     | inf          |
|    std                      | 0.298        |
|    value_loss               | 0.516        |
----------------------------------------------
-----------------------------------------------
| reward                      | [-0.34859127] |
| time/                       |               |
|    fps                      | 148           |
|    iterations               | 18            |
|    time_elapsed             | 248           |
|    total_timesteps          | 137216        |
| train/                      |               |
|    approx_kl                | 25.562805     |
|    approx_ln(kl)            | 3.2411385     |
|    clip_range               | 0.2           |
|    entropy_loss             | -0.342        |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 660           |
|    policy_gradient_loss     | inf           |
|    std                      | 0.283         |
|    value_loss               | 0.155         |
-----------------------------------------------
----------------------------------------------
| reward                      | [-0.9329883] |
| time/                       |              |
|    fps                      | 131          |
|    iterations               | 19           |
|    time_elapsed             | 295          |
|    total_timesteps          | 139264       |
| train/                      |              |
|    approx_kl                | 127.53418    |
|    approx_ln(kl)            | 4.8483844    |
|    clip_range               | 0.2          |
|    entropy_loss             | -0.173       |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 670          |
|    policy_gradient_loss     | inf          |
|    std                      | 0.256        |
|    value_loss               | 0.254        |
----------------------------------------------
----------------------------------------------
| reward                      | [-1.0218486] |
| time/                       |              |
|    fps                      | 102          |
|    iterations               | 20           |
|    time_elapsed             | 399          |
|    total_timesteps          | 141312       |
| train/                      |              |
|    approx_kl                | 77.89385     |
|    approx_ln(kl)            | 4.355347     |
|    clip_range               | 0.2          |
|    entropy_loss             | -0.0356      |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 680          |
|    policy_gradient_loss     | inf          |
|    std                      | 0.249        |
|    value_loss               | 0.193        |
----------------------------------------------
----------------------------------------------
| reward                      | [-0.4542504] |
| time/                       |              |
|    fps                      | 104          |
|    iterations               | 21           |
|    time_elapsed             | 413          |
|    total_timesteps          | 143360       |
| train/                      |              |
|    approx_kl                | 61.56249     |
|    approx_ln(kl)            | 4.120053     |
|    clip_range               | 0.2          |
|    entropy_loss             | 0.00497      |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 690          |
|    policy_gradient_loss     | inf          |
|    std                      | 0.246        |
|    value_loss               | 0.121        |
----------------------------------------------
----------------------------------------------
| reward                      | [-1.2581853] |
| time/                       |              |
|    fps                      | 105          |
|    iterations               | 22           |
|    time_elapsed             | 426          |
|    total_timesteps          | 145408       |
| train/                      |              |
|    approx_kl                | 53.678364    |
|    approx_ln(kl)            | 3.98301      |
|    clip_range               | 0.2          |
|    entropy_loss             | 0.113        |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 700          |
|    policy_gradient_loss     | inf          |
|    std                      | 0.221        |
|    value_loss               | 0.0349       |
----------------------------------------------
-----------------------------------------------
| reward                      | [-0.46542367] |
| time/                       |               |
|    fps                      | 106           |
|    iterations               | 23            |
|    time_elapsed             | 440           |
|    total_timesteps          | 147456        |
| train/                      |               |
|    approx_kl                | 10.892404     |
|    approx_ln(kl)            | 2.3880656     |
|    clip_range               | 0.2           |
|    entropy_loss             | 0.25          |
|    explained_variance       | 1             |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 710           |
|    policy_gradient_loss     | inf           |
|    std                      | 0.215         |
|    value_loss               | 0.0529        |
-----------------------------------------------
-----------------------------------------------
| reward                      | [-0.37739044] |
| time/                       |               |
|    fps                      | 108           |
|    iterations               | 24            |
|    time_elapsed             | 454           |
|    total_timesteps          | 149504        |
| train/                      |               |
|    approx_kl                | 17.93935      |
|    approx_ln(kl)            | 2.8869967     |
|    clip_range               | 0.2           |
|    entropy_loss             | 0.324         |
|    explained_variance       | 1             |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 720           |
|    policy_gradient_loss     | inf           |
|    std                      | 0.202         |
|    value_loss               | 0.0496        |
-----------------------------------------------
----------------------------------------------
| reward                      | [-0.6385497] |
| time/                       |              |
|    fps                      | 109          |
|    iterations               | 25           |
|    time_elapsed             | 468          |
|    total_timesteps          | 151552       |
| train/                      |              |
|    approx_kl                | 57.162163    |
|    approx_ln(kl)            | 4.0458922    |
|    clip_range               | 0.2          |
|    entropy_loss             | 0.482        |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 730          |
|    policy_gradient_loss     | inf          |
|    std                      | 0.187        |
|    value_loss               | 0.117        |
----------------------------------------------
-----------------------------------------------
| reward                      | [-0.79324216] |
| time/                       |               |
|    fps                      | 110           |
|    iterations               | 26            |
|    time_elapsed             | 482           |
|    total_timesteps          | 153600        |
| train/                      |               |
|    approx_kl                | 9.652151      |
|    approx_ln(kl)            | 2.267181      |
|    clip_range               | 0.2           |
|    entropy_loss             | 0.621         |
|    explained_variance       | 0.994         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 740           |
|    policy_gradient_loss     | inf           |
|    std                      | 0.176         |
|    value_loss               | 0.123         |
-----------------------------------------------
----------------------------------------------
| reward                      | [-0.5860017] |
| time/                       |              |
|    fps                      | 111          |
|    iterations               | 27           |
|    time_elapsed             | 496          |
|    total_timesteps          | 155648       |
| train/                      |              |
|    approx_kl                | 26.626707    |
|    approx_ln(kl)            | 3.2819147    |
|    clip_range               | 0.2          |
|    entropy_loss             | 0.72         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 750          |
|    policy_gradient_loss     | inf          |
|    std                      | 0.166        |
|    value_loss               | 0.0786       |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.79650646] |
| time/                       |               |
|    fps                      | 112           |
|    iterations               | 28            |
|    time_elapsed             | 510           |
|    total_timesteps          | 157696        |
| train/                      |               |
|    approx_kl                | 33.217556     |
|    approx_ln(kl)            | 3.5030785     |
|    clip_range               | 0.2           |
|    entropy_loss             | 0.816         |
|    explained_variance       | 1             |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 760           |
|    policy_gradient_loss     | nan           |
|    std                      | 0.161         |
|    value_loss               | 0.0956        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4144781] |
| time/                       |              |
|    fps                      | 113          |
|    iterations               | 29           |
|    time_elapsed             | 524          |
|    total_timesteps          | 159744       |
| train/                      |              |
|    approx_kl                | 30.565844    |
|    approx_ln(kl)            | 3.4198833    |
|    clip_range               | 0.2          |
|    entropy_loss             | 0.903        |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 770          |
|    policy_gradient_loss     | nan          |
|    std                      | 0.153        |
|    value_loss               | 0.175        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-0.393503] |
| time/                       |             |
|    fps                      | 102         |
|    iterations               | 30          |
|    time_elapsed             | 598         |
|    total_timesteps          | 161792      |
| train/                      |             |
|    approx_kl                | 55.109676   |
|    approx_ln(kl)            | 4.0093255   |
|    clip_range               | 0.2         |
|    entropy_loss             | 1.03        |
|    explained_variance       | 0.996       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 780         |
|    policy_gradient_loss     | nan         |
|    std                      | 0.14        |
|    value_loss               | 0.0752      |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.9549365] |
| time/                       |              |
|    fps                      | 103          |
|    iterations               | 31           |
|    time_elapsed             | 615          |
|    total_timesteps          | 163840       |
| train/                      |              |
|    approx_kl                | 24.696722    |
|    approx_ln(kl)            | 3.2066705    |
|    clip_range               | 0.2          |
|    entropy_loss             | 1.18         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 790          |
|    policy_gradient_loss     | nan          |
|    std                      | 0.134        |
|    value_loss               | 0.0726       |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.41381785] |
| time/                       |               |
|    fps                      | 103           |
|    iterations               | 32            |
|    time_elapsed             | 631           |
|    total_timesteps          | 165888        |
| train/                      |               |
|    approx_kl                | 11.18215      |
|    approx_ln(kl)            | 2.4143188     |
|    clip_range               | 0.2           |
|    entropy_loss             | 1.31          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 800           |
|    policy_gradient_loss     | nan           |
|    std                      | 0.124         |
|    value_loss               | 0.0619        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.51530033] |
| time/                       |               |
|    fps                      | 104           |
|    iterations               | 33            |
|    time_elapsed             | 648           |
|    total_timesteps          | 167936        |
| train/                      |               |
|    approx_kl                | 39.60106      |
|    approx_ln(kl)            | 3.678856      |
|    clip_range               | 0.2           |
|    entropy_loss             | 1.41          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 810           |
|    policy_gradient_loss     | nan           |
|    std                      | 0.12          |
|    value_loss               | 0.113         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4364075] |
| time/                       |              |
|    fps                      | 101          |
|    iterations               | 34           |
|    time_elapsed             | 683          |
|    total_timesteps          | 169984       |
| train/                      |              |
|    approx_kl                | 10.204178    |
|    approx_ln(kl)            | 2.3227973    |
|    clip_range               | 0.2          |
|    entropy_loss             | 1.48         |
|    explained_variance       | 0.937        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 820          |
|    policy_gradient_loss     | nan          |
|    std                      | 0.114        |
|    value_loss               | 0.0497       |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.44130942] |
| time/                       |               |
|    fps                      | 102           |
|    iterations               | 35            |
|    time_elapsed             | 699           |
|    total_timesteps          | 172032        |
| train/                      |               |
|    approx_kl                | 24.38884      |
|    approx_ln(kl)            | 3.1941257     |
|    clip_range               | 0.2           |
|    entropy_loss             | 1.59          |
|    explained_variance       | 0.997         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 830           |
|    policy_gradient_loss     | nan           |
|    std                      | 0.107         |
|    value_loss               | 0.0462        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.41216105] |
| time/                       |               |
|    fps                      | 103           |
|    iterations               | 36            |
|    time_elapsed             | 715           |
|    total_timesteps          | 174080        |
| train/                      |               |
|    approx_kl                | 18.44912      |
|    approx_ln(kl)            | 2.9150167     |
|    clip_range               | 0.2           |
|    entropy_loss             | 1.68          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 840           |
|    policy_gradient_loss     | nan           |
|    std                      | 0.104         |
|    value_loss               | 0.0577        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.62238806] |
| time/                       |               |
|    fps                      | 103           |
|    iterations               | 37            |
|    time_elapsed             | 731           |
|    total_timesteps          | 176128        |
| train/                      |               |
|    approx_kl                | 47.291656     |
|    approx_ln(kl)            | 3.856334      |
|    clip_range               | 0.2           |
|    entropy_loss             | 1.78          |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 850           |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0981        |
|    value_loss               | 0.0461        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4597784] |
| time/                       |              |
|    fps                      | 104          |
|    iterations               | 38           |
|    time_elapsed             | 747          |
|    total_timesteps          | 178176       |
| train/                      |              |
|    approx_kl                | 15.661479    |
|    approx_ln(kl)            | 2.7512043    |
|    clip_range               | 0.2          |
|    entropy_loss             | 1.89         |
|    explained_variance       | 0.84         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 860          |
|    policy_gradient_loss     | nan          |
|    std                      | 0.093        |
|    value_loss               | 1.04         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.49466616] |
| time/                       |               |
|    fps                      | 104           |
|    iterations               | 39            |
|    time_elapsed             | 764           |
|    total_timesteps          | 180224        |
| train/                      |               |
|    approx_kl                | 22.143595     |
|    approx_ln(kl)            | 3.0975482     |
|    clip_range               | 0.2           |
|    entropy_loss             | 2.01          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 870           |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0867        |
|    value_loss               | 0.0501        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.76826125] |
| time/                       |               |
|    fps                      | 104           |
|    iterations               | 40            |
|    time_elapsed             | 780           |
|    total_timesteps          | 182272        |
| train/                      |               |
|    approx_kl                | 51.28858      |
|    approx_ln(kl)            | 3.937468      |
|    clip_range               | 0.2           |
|    entropy_loss             | 2.12          |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 880           |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0838        |
|    value_loss               | 0.0514        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-1.031157] |
| time/                       |             |
|    fps                      | 94          |
|    iterations               | 41          |
|    time_elapsed             | 886         |
|    total_timesteps          | 184320      |
| train/                      |             |
|    approx_kl                | 39.85717    |
|    approx_ln(kl)            | 3.6853023   |
|    clip_range               | 0.2         |
|    entropy_loss             | 2.18        |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 890         |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0812      |
|    value_loss               | 0.0411      |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0291504] |
| time/                       |              |
|    fps                      | 94           |
|    iterations               | 42           |
|    time_elapsed             | 907          |
|    total_timesteps          | 186368       |
| train/                      |              |
|    approx_kl                | 21.218164    |
|    approx_ln(kl)            | 3.0548577    |
|    clip_range               | 0.2          |
|    entropy_loss             | 2.28         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 900          |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0762       |
|    value_loss               | 0.0502       |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.2241321] |
| time/                       |              |
|    fps                      | 95           |
|    iterations               | 43           |
|    time_elapsed             | 923          |
|    total_timesteps          | 188416       |
| train/                      |              |
|    approx_kl                | 95.24953     |
|    approx_ln(kl)            | 4.5565       |
|    clip_range               | 0.2          |
|    entropy_loss             | 2.38         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 910          |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0737       |
|    value_loss               | 0.146        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.46556327] |
| time/                       |               |
|    fps                      | 96            |
|    iterations               | 44            |
|    time_elapsed             | 936           |
|    total_timesteps          | 190464        |
| train/                      |               |
|    approx_kl                | 529.1934      |
|    approx_ln(kl)            | 6.271354      |
|    clip_range               | 0.2           |
|    entropy_loss             | 2.46          |
|    explained_variance       | 0.994         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 920           |
|    policy_gradient_loss     | nan           |
|    std                      | 0.069         |
|    value_loss               | 0.301         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5692645] |
| time/                       |              |
|    fps                      | 96           |
|    iterations               | 45           |
|    time_elapsed             | 950          |
|    total_timesteps          | 192512       |
| train/                      |              |
|    approx_kl                | 18.586311    |
|    approx_ln(kl)            | 2.9224253    |
|    clip_range               | 0.2          |
|    entropy_loss             | 2.55         |
|    explained_variance       | 0.976        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 930          |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0681       |
|    value_loss               | 1.05         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.8592693] |
| time/                       |              |
|    fps                      | 97           |
|    iterations               | 46           |
|    time_elapsed             | 965          |
|    total_timesteps          | 194560       |
| train/                      |              |
|    approx_kl                | 36.21382     |
|    approx_ln(kl)            | 3.5894408    |
|    clip_range               | 0.2          |
|    entropy_loss             | 2.62         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 940          |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0645       |
|    value_loss               | 0.0523       |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.61202174] |
| time/                       |               |
|    fps                      | 97            |
|    iterations               | 47            |
|    time_elapsed             | 984           |
|    total_timesteps          | 196608        |
| train/                      |               |
|    approx_kl                | 1474.6106     |
|    approx_ln(kl)            | 7.2961493     |
|    clip_range               | 0.2           |
|    entropy_loss             | 2.74          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 950           |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0598        |
|    value_loss               | 0.151         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.42320898] |
| time/                       |               |
|    fps                      | 98            |
|    iterations               | 48            |
|    time_elapsed             | 1000          |
|    total_timesteps          | 198656        |
| train/                      |               |
|    approx_kl                | 181.49966     |
|    approx_ln(kl)            | 5.201254      |
|    clip_range               | 0.2           |
|    entropy_loss             | 2.82          |
|    explained_variance       | 1             |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 960           |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0601        |
|    value_loss               | 0.0427        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.2555252] |
| time/                       |              |
|    fps                      | 98           |
|    iterations               | 49           |
|    time_elapsed             | 1017         |
|    total_timesteps          | 200704       |
| train/                      |              |
|    approx_kl                | 100.38281    |
|    approx_ln(kl)            | 4.608991     |
|    clip_range               | 0.2          |
|    entropy_loss             | 2.82         |
|    explained_variance       | 0.778        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 970          |
|    policy_gradient_loss     | nan          |
|    std                      | 0.06         |
|    value_loss               | 8.57         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
--------------------------------------
| reward             | [-0.47320226] |
| time/              |               |
|    fps             | 133           |
|    iterations      | 1             |
|    time_elapsed    | 15            |
|    total_timesteps | 202752        |
--------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.45801508] |
| time/                       |               |
|    fps                      | 131           |
|    iterations               | 2             |
|    time_elapsed             | 31            |
|    total_timesteps          | 204800        |
| train/                      |               |
|    approx_kl                | 193.02802     |
|    approx_ln(kl)            | 5.2628355     |
|    clip_range               | 0.2           |
|    entropy_loss             | 2.83          |
|    explained_variance       | 0.997         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 990           |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0582        |
|    value_loss               | 0.119         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.3172749] |
| time/                       |              |
|    fps                      | 137          |
|    iterations               | 3            |
|    time_elapsed             | 44           |
|    total_timesteps          | 206848       |
| train/                      |              |
|    approx_kl                | 329.0244     |
|    approx_ln(kl)            | 5.796132     |
|    clip_range               | 0.2          |
|    entropy_loss             | 2.91         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1000         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0559       |
|    value_loss               | 0.562        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6399069] |
| time/                       |              |
|    fps                      | 140          |
|    iterations               | 4            |
|    time_elapsed             | 58           |
|    total_timesteps          | 208896       |
| train/                      |              |
|    approx_kl                | 356.90112    |
|    approx_ln(kl)            | 5.8774586    |
|    clip_range               | 0.2          |
|    entropy_loss             | 2.98         |
|    explained_variance       | 0.762        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1010         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0554       |
|    value_loss               | 15.7         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5330532] |
| time/                       |              |
|    fps                      | 141          |
|    iterations               | 5            |
|    time_elapsed             | 72           |
|    total_timesteps          | 210944       |
| train/                      |              |
|    approx_kl                | 689.5375     |
|    approx_ln(kl)            | 6.536021     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3            |
|    explained_variance       | 0.907        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1020         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0546       |
|    value_loss               | 6.28         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-1.346257] |
| time/                       |             |
|    fps                      | 143         |
|    iterations               | 6           |
|    time_elapsed             | 85          |
|    total_timesteps          | 212992      |
| train/                      |             |
|    approx_kl                | 61.61074    |
|    approx_ln(kl)            | 4.1208363   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.04        |
|    explained_variance       | 0.983       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 1030        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0532      |
|    value_loss               | 1.2         |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.48254997] |
| time/                       |               |
|    fps                      | 143           |
|    iterations               | 7             |
|    time_elapsed             | 99            |
|    total_timesteps          | 215040        |
| train/                      |               |
|    approx_kl                | 217.84413     |
|    approx_ln(kl)            | 5.38378       |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.11          |
|    explained_variance       | 0.985         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 1040          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0517        |
|    value_loss               | 1.55          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-1.346329] |
| time/                       |             |
|    fps                      | 144         |
|    iterations               | 8           |
|    time_elapsed             | 113         |
|    total_timesteps          | 217088      |
| train/                      |             |
|    approx_kl                | 3732.6616   |
|    approx_ln(kl)            | 8.224876    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.16        |
|    explained_variance       | 0.992       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 1050        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0507      |
|    value_loss               | 0.279       |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5262356] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 9            |
|    time_elapsed             | 126          |
|    total_timesteps          | 219136       |
| train/                      |              |
|    approx_kl                | 97.90924     |
|    approx_ln(kl)            | 4.584041     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.18         |
|    explained_variance       | 0.984        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1060         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0505       |
|    value_loss               | 1.53         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.40034854] |
| time/                       |               |
|    fps                      | 145           |
|    iterations               | 10            |
|    time_elapsed             | 141           |
|    total_timesteps          | 221184        |
| train/                      |               |
|    approx_kl                | 479.08282     |
|    approx_ln(kl)            | 6.1718736     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.22          |
|    explained_variance       | 0.996         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 1070          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0487        |
|    value_loss               | 0.943         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.8572511] |
| time/                       |              |
|    fps                      | 144          |
|    iterations               | 11           |
|    time_elapsed             | 155          |
|    total_timesteps          | 223232       |
| train/                      |              |
|    approx_kl                | 1343.1057    |
|    approx_ln(kl)            | 7.2027397    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.28         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1080         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0486       |
|    value_loss               | 0.158        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.6116198] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 12           |
|    time_elapsed             | 169          |
|    total_timesteps          | 225280       |
| train/                      |              |
|    approx_kl                | 224.2931     |
|    approx_ln(kl)            | 5.412954     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.27         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1090         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0488       |
|    value_loss               | 0.332        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.1188663] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 13           |
|    time_elapsed             | 182          |
|    total_timesteps          | 227328       |
| train/                      |              |
|    approx_kl                | 255.65613    |
|    approx_ln(kl)            | 5.5438333    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.3          |
|    explained_variance       | 0.972        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1100         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0478       |
|    value_loss               | 2.53         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.3061105] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 14           |
|    time_elapsed             | 196          |
|    total_timesteps          | 229376       |
| train/                      |              |
|    approx_kl                | 1213.7015    |
|    approx_ln(kl)            | 7.10143      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.33         |
|    explained_variance       | 0.966        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1110         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0476       |
|    value_loss               | 2.36         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.99671984] |
| time/                       |               |
|    fps                      | 145           |
|    iterations               | 15            |
|    time_elapsed             | 210           |
|    total_timesteps          | 231424        |
| train/                      |               |
|    approx_kl                | 227.44376     |
|    approx_ln(kl)            | 5.426903      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.35          |
|    explained_variance       | 0.95          |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 1120          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0466        |
|    value_loss               | 4.8           |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.45769826] |
| time/                       |               |
|    fps                      | 145           |
|    iterations               | 16            |
|    time_elapsed             | 224           |
|    total_timesteps          | 233472        |
| train/                      |               |
|    approx_kl                | 1117.658      |
|    approx_ln(kl)            | 7.0189905     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.35          |
|    explained_variance       | 0.997         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 1130          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0469        |
|    value_loss               | 0.484         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.58707756] |
| time/                       |               |
|    fps                      | 144           |
|    iterations               | 17            |
|    time_elapsed             | 241           |
|    total_timesteps          | 235520        |
| train/                      |               |
|    approx_kl                | 966.5521      |
|    approx_ln(kl)            | 6.8737354     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.35          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 1140          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0471        |
|    value_loss               | 0.141         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.9213838] |
| time/                       |              |
|    fps                      | 144          |
|    iterations               | 18           |
|    time_elapsed             | 255          |
|    total_timesteps          | 237568       |
| train/                      |              |
|    approx_kl                | 2358.8438    |
|    approx_ln(kl)            | 7.765927     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.34         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1150         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0476       |
|    value_loss               | 0.429        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.8703927] |
| time/                       |              |
|    fps                      | 144          |
|    iterations               | 19           |
|    time_elapsed             | 269          |
|    total_timesteps          | 239616       |
| train/                      |              |
|    approx_kl                | 453.1549     |
|    approx_ln(kl)            | 6.116234     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.31         |
|    explained_variance       | 0.991        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1160         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0479       |
|    value_loss               | 0.585        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5849171] |
| time/                       |              |
|    fps                      | 144          |
|    iterations               | 20           |
|    time_elapsed             | 283          |
|    total_timesteps          | 241664       |
| train/                      |              |
|    approx_kl                | 1521.5345    |
|    approx_ln(kl)            | 7.3274746    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.3          |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1170         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0481       |
|    value_loss               | 0.0395       |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.94048655] |
| time/                       |               |
|    fps                      | 144           |
|    iterations               | 21            |
|    time_elapsed             | 297           |
|    total_timesteps          | 243712        |
| train/                      |               |
|    approx_kl                | 3230.9246     |
|    approx_ln(kl)            | 8.0805235     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.3           |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 1180          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0483        |
|    value_loss               | 0.0502        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5704733] |
| time/                       |              |
|    fps                      | 144          |
|    iterations               | 22           |
|    time_elapsed             | 310          |
|    total_timesteps          | 245760       |
| train/                      |              |
|    approx_kl                | 1056.2488    |
|    approx_ln(kl)            | 6.962479     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.24         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1190         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0497       |
|    value_loss               | 0.0315       |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.31964523] |
| time/                       |               |
|    fps                      | 145           |
|    iterations               | 23            |
|    time_elapsed             | 324           |
|    total_timesteps          | 247808        |
| train/                      |               |
|    approx_kl                | 550.76227     |
|    approx_ln(kl)            | 6.311303      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.24          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 1200          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0495        |
|    value_loss               | 0.0567        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-0.550812] |
| time/                       |             |
|    fps                      | 145         |
|    iterations               | 24          |
|    time_elapsed             | 338         |
|    total_timesteps          | 249856      |
| train/                      |             |
|    approx_kl                | 961.543     |
|    approx_ln(kl)            | 6.8685393   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.22        |
|    explained_variance       | 0.995       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 1210        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0496      |
|    value_loss               | 0.198       |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4382443] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 25           |
|    time_elapsed             | 352          |
|    total_timesteps          | 251904       |
| train/                      |              |
|    approx_kl                | 719.16016    |
|    approx_ln(kl)            | 6.578084     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.25         |
|    explained_variance       | 0.809        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1220         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0494       |
|    value_loss               | 1.72         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5713076] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 26           |
|    time_elapsed             | 366          |
|    total_timesteps          | 253952       |
| train/                      |              |
|    approx_kl                | 1369.4404    |
|    approx_ln(kl)            | 7.2221575    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.25         |
|    explained_variance       | 0.885        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1230         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0493       |
|    value_loss               | 0.932        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-61.155407] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 27           |
|    time_elapsed             | 379          |
|    total_timesteps          | 256000       |
| train/                      |              |
|    approx_kl                | 627.5929     |
|    approx_ln(kl)            | 6.4418917    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.26         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1240         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.049        |
|    value_loss               | 0.182        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.41126445] |
| time/                       |               |
|    fps                      | 145           |
|    iterations               | 28            |
|    time_elapsed             | 393           |
|    total_timesteps          | 258048        |
| train/                      |               |
|    approx_kl                | 506.64105     |
|    approx_ln(kl)            | 6.2278028     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.26          |
|    explained_variance       | 0.943         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 1250          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.049         |
|    value_loss               | 0.65          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0206435] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 29           |
|    time_elapsed             | 407          |
|    total_timesteps          | 260096       |
| train/                      |              |
|    approx_kl                | 640.32324    |
|    approx_ln(kl)            | 6.461973     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.22         |
|    explained_variance       | 0.981        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1260         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0501       |
|    value_loss               | 0.342        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-0.471889] |
| time/                       |             |
|    fps                      | 145         |
|    iterations               | 30          |
|    time_elapsed             | 421         |
|    total_timesteps          | 262144      |
| train/                      |             |
|    approx_kl                | 2252.7578   |
|    approx_ln(kl)            | 7.7199106   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.24        |
|    explained_variance       | 0.965       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 1270        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0493      |
|    value_loss               | 1.05        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.42920342] |
| time/                       |               |
|    fps                      | 145           |
|    iterations               | 31            |
|    time_elapsed             | 434           |
|    total_timesteps          | 264192        |
| train/                      |               |
|    approx_kl                | 717.96594     |
|    approx_ln(kl)            | 6.576422      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.25          |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 1280          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0491        |
|    value_loss               | 0.0447        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-0.320384] |
| time/                       |             |
|    fps                      | 146         |
|    iterations               | 32          |
|    time_elapsed             | 448         |
|    total_timesteps          | 266240      |
| train/                      |             |
|    approx_kl                | 348.62677   |
|    approx_ln(kl)            | 5.854002    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.21        |
|    explained_variance       | 0.997       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 1290        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0501      |
|    value_loss               | 0.154       |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5123617] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 33           |
|    time_elapsed             | 462          |
|    total_timesteps          | 268288       |
| train/                      |              |
|    approx_kl                | 2545.6255    |
|    approx_ln(kl)            | 7.8421316    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.21         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1300         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0501       |
|    value_loss               | 0.259        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.8732159] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 34           |
|    time_elapsed             | 476          |
|    total_timesteps          | 270336       |
| train/                      |              |
|    approx_kl                | 3752.3591    |
|    approx_ln(kl)            | 8.23014      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.24         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1310         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0494       |
|    value_loss               | 0.261        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.2514981] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 35           |
|    time_elapsed             | 489          |
|    total_timesteps          | 272384       |
| train/                      |              |
|    approx_kl                | 1293.7886    |
|    approx_ln(kl)            | 7.16533      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.23         |
|    explained_variance       | 0.935        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1320         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0495       |
|    value_loss               | 2.86         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.2414372] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 36           |
|    time_elapsed             | 503          |
|    total_timesteps          | 274432       |
| train/                      |              |
|    approx_kl                | 2789.3223    |
|    approx_ln(kl)            | 7.933554     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.24         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1330         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0494       |
|    value_loss               | 0.176        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7342464] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 37           |
|    time_elapsed             | 516          |
|    total_timesteps          | 276480       |
| train/                      |              |
|    approx_kl                | 1658.5361    |
|    approx_ln(kl)            | 7.4136906    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.25         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1340         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0491       |
|    value_loss               | 0.646        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.29906386] |
| time/                       |               |
|    fps                      | 125           |
|    iterations               | 38            |
|    time_elapsed             | 621           |
|    total_timesteps          | 278528        |
| train/                      |               |
|    approx_kl                | 1950.3527     |
|    approx_ln(kl)            | 7.5757656     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.26          |
|    explained_variance       | 0.993         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 1350          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0488        |
|    value_loss               | 0.812         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.36207187] |
| time/                       |               |
|    fps                      | 110           |
|    iterations               | 39            |
|    time_elapsed             | 725           |
|    total_timesteps          | 280576        |
| train/                      |               |
|    approx_kl                | 2140.705      |
|    approx_ln(kl)            | 7.6688905     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.26          |
|    explained_variance       | 0.979         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 1360          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0488        |
|    value_loss               | 3.14          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.70665216] |
| time/                       |               |
|    fps                      | 110           |
|    iterations               | 40            |
|    time_elapsed             | 738           |
|    total_timesteps          | 282624        |
| train/                      |               |
|    approx_kl                | 3138.983      |
|    approx_ln(kl)            | 8.051654      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.25          |
|    explained_variance       | 0.984         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 1370          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0493        |
|    value_loss               | 0.798         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.8162735] |
| time/                       |              |
|    fps                      | 111          |
|    iterations               | 41           |
|    time_elapsed             | 752          |
|    total_timesteps          | 284672       |
| train/                      |              |
|    approx_kl                | 783.5415     |
|    approx_ln(kl)            | 6.663824     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.24         |
|    explained_variance       | 0.989        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1380         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0496       |
|    value_loss               | 0.644        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.57666045] |
| time/                       |               |
|    fps                      | 106           |
|    iterations               | 42            |
|    time_elapsed             | 808           |
|    total_timesteps          | 286720        |
| train/                      |               |
|    approx_kl                | 928.8689      |
|    approx_ln(kl)            | 6.8339677     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.24          |
|    explained_variance       | 0.991         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 1390          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0498        |
|    value_loss               | 0.788         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.1149971] |
| time/                       |              |
|    fps                      | 107          |
|    iterations               | 43           |
|    time_elapsed             | 822          |
|    total_timesteps          | 288768       |
| train/                      |              |
|    approx_kl                | 2692.426     |
|    approx_ln(kl)            | 7.898198     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.24         |
|    explained_variance       | 0.979        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1400         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0494       |
|    value_loss               | 0.423        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.80656576] |
| time/                       |               |
|    fps                      | 107           |
|    iterations               | 44            |
|    time_elapsed             | 835           |
|    total_timesteps          | 290816        |
| train/                      |               |
|    approx_kl                | 1720.8679     |
|    approx_ln(kl)            | 7.450584      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.24          |
|    explained_variance       | 0.996         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 1410          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0496        |
|    value_loss               | 0.188         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-0.552795] |
| time/                       |             |
|    fps                      | 108         |
|    iterations               | 45          |
|    time_elapsed             | 849         |
|    total_timesteps          | 292864      |
| train/                      |             |
|    approx_kl                | 2597.4187   |
|    approx_ln(kl)            | 7.862273    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.24        |
|    explained_variance       | 0.99        |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 1420        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0493      |
|    value_loss               | 0.358       |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.38976735] |
| time/                       |               |
|    fps                      | 109           |
|    iterations               | 46            |
|    time_elapsed             | 863           |
|    total_timesteps          | 294912        |
| train/                      |               |
|    approx_kl                | 1187.5404     |
|    approx_ln(kl)            | 7.0796394     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.18          |
|    explained_variance       | 0.988         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 1430          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.051         |
|    value_loss               | 0.367         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.85654056] |
| time/                       |               |
|    fps                      | 109           |
|    iterations               | 47            |
|    time_elapsed             | 876           |
|    total_timesteps          | 296960        |
| train/                      |               |
|    approx_kl                | 211.76822     |
|    approx_ln(kl)            | 5.3554926     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.19          |
|    explained_variance       | 0.335         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 1440          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0505        |
|    value_loss               | 6.29          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5660398] |
| time/                       |              |
|    fps                      | 110          |
|    iterations               | 48           |
|    time_elapsed             | 890          |
|    total_timesteps          | 299008       |
| train/                      |              |
|    approx_kl                | 2912.4065    |
|    approx_ln(kl)            | 7.976735     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.18         |
|    explained_variance       | 0.989        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1450         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0508       |
|    value_loss               | 1.17         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.79160994] |
| time/                       |               |
|    fps                      | 110           |
|    iterations               | 49            |
|    time_elapsed             | 904           |
|    total_timesteps          | 301056        |
| train/                      |               |
|    approx_kl                | 3065.222      |
|    approx_ln(kl)            | 8.027875      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.16          |
|    explained_variance       | 0.997         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 1460          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0513        |
|    value_loss               | 0.253         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-------------------------------------
| reward             | [-0.5173767] |
| time/              |              |
|    fps             | 161          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 303104       |
-------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.47652885] |
| time/                       |               |
|    fps                      | 155           |
|    iterations               | 2             |
|    time_elapsed             | 26            |
|    total_timesteps          | 305152        |
| train/                      |               |
|    approx_kl                | 2466.541      |
|    approx_ln(kl)            | 7.810572      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.07          |
|    explained_variance       | 0.79          |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 1480          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0543        |
|    value_loss               | 8.3           |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.8348255] |
| time/                       |              |
|    fps                      | 154          |
|    iterations               | 3            |
|    time_elapsed             | 39           |
|    total_timesteps          | 307200       |
| train/                      |              |
|    approx_kl                | 527.76733    |
|    approx_ln(kl)            | 6.268656     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.06         |
|    explained_variance       | 0.952        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1490         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0541       |
|    value_loss               | 4.25         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.37698743] |
| time/                       |               |
|    fps                      | 152           |
|    iterations               | 4             |
|    time_elapsed             | 53            |
|    total_timesteps          | 309248        |
| train/                      |               |
|    approx_kl                | 318.45593     |
|    approx_ln(kl)            | 5.763484      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.05          |
|    explained_variance       | 0.977         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 1500          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0545        |
|    value_loss               | 2.93          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.42966998] |
| time/                       |               |
|    fps                      | 64            |
|    iterations               | 5             |
|    time_elapsed             | 158           |
|    total_timesteps          | 311296        |
| train/                      |               |
|    approx_kl                | 1073.7607     |
|    approx_ln(kl)            | 6.9789224     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.04          |
|    explained_variance       | 0.985         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 1510          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0549        |
|    value_loss               | 1.87          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.0973186] |
| time/                       |              |
|    fps                      | 46           |
|    iterations               | 6            |
|    time_elapsed             | 262          |
|    total_timesteps          | 313344       |
| train/                      |              |
|    approx_kl                | 2204.77      |
|    approx_ln(kl)            | 7.6983786    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.02         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1520         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0554       |
|    value_loss               | 0.594        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0210445] |
| time/                       |              |
|    fps                      | 51           |
|    iterations               | 7            |
|    time_elapsed             | 276          |
|    total_timesteps          | 315392       |
| train/                      |              |
|    approx_kl                | 774.41846    |
|    approx_ln(kl)            | 6.6521125    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.02         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1530         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0553       |
|    value_loss               | 0.705        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.4656013] |
| time/                       |              |
|    fps                      | 56           |
|    iterations               | 8            |
|    time_elapsed             | 290          |
|    total_timesteps          | 317440       |
| train/                      |              |
|    approx_kl                | 1454.4253    |
|    approx_ln(kl)            | 7.2823663    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.04         |
|    explained_variance       | 0.877        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1540         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0546       |
|    value_loss               | 22.5         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.6419218] |
| time/                       |              |
|    fps                      | 60           |
|    iterations               | 9            |
|    time_elapsed             | 304          |
|    total_timesteps          | 319488       |
| train/                      |              |
|    approx_kl                | 1244.3909    |
|    approx_ln(kl)            | 7.1264014    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.03         |
|    explained_variance       | 0.961        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1550         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0551       |
|    value_loss               | 29.4         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.91610986] |
| time/                       |               |
|    fps                      | 64            |
|    iterations               | 10            |
|    time_elapsed             | 318           |
|    total_timesteps          | 321536        |
| train/                      |               |
|    approx_kl                | 1583.9695     |
|    approx_ln(kl)            | 7.367689      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.02          |
|    explained_variance       | 0.989         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 1560          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0551        |
|    value_loss               | 2.33          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.7987018] |
| time/                       |              |
|    fps                      | 67           |
|    iterations               | 11           |
|    time_elapsed             | 331          |
|    total_timesteps          | 323584       |
| train/                      |              |
|    approx_kl                | 550.4169     |
|    approx_ln(kl)            | 6.310676     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.05         |
|    explained_variance       | 0.816        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1570         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0539       |
|    value_loss               | 34.5         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.6609614] |
| time/                       |              |
|    fps                      | 71           |
|    iterations               | 12           |
|    time_elapsed             | 345          |
|    total_timesteps          | 325632       |
| train/                      |              |
|    approx_kl                | 840.71185    |
|    approx_ln(kl)            | 6.734249     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.08         |
|    explained_variance       | 0.928        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1580         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0532       |
|    value_loss               | 26           |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7442943] |
| time/                       |              |
|    fps                      | 74           |
|    iterations               | 13           |
|    time_elapsed             | 358          |
|    total_timesteps          | 327680       |
| train/                      |              |
|    approx_kl                | 622.63464    |
|    approx_ln(kl)            | 6.43396      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.11         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1590         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0522       |
|    value_loss               | 0.475        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4263819] |
| time/                       |              |
|    fps                      | 76           |
|    iterations               | 14           |
|    time_elapsed             | 372          |
|    total_timesteps          | 329728       |
| train/                      |              |
|    approx_kl                | 1524.5676    |
|    approx_ln(kl)            | 7.3294663    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.13         |
|    explained_variance       | 0.99         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1600         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0517       |
|    value_loss               | 1.02         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.60014224] |
| time/                       |               |
|    fps                      | 79            |
|    iterations               | 15            |
|    time_elapsed             | 386           |
|    total_timesteps          | 331776        |
| train/                      |               |
|    approx_kl                | 590.6476      |
|    approx_ln(kl)            | 6.3812194     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.23          |
|    explained_variance       | 0.92          |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 1610          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0484        |
|    value_loss               | 1.46          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.1928086] |
| time/                       |              |
|    fps                      | 81           |
|    iterations               | 16           |
|    time_elapsed             | 400          |
|    total_timesteps          | 333824       |
| train/                      |              |
|    approx_kl                | 491.09363    |
|    approx_ln(kl)            | 6.196635     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.25         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1620         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0486       |
|    value_loss               | 1.15         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.9839648] |
| time/                       |              |
|    fps                      | 84           |
|    iterations               | 17           |
|    time_elapsed             | 414          |
|    total_timesteps          | 335872       |
| train/                      |              |
|    approx_kl                | 454.59192    |
|    approx_ln(kl)            | 6.1194       |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.25         |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1630         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0487       |
|    value_loss               | 0.915        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.4835254] |
| time/                       |              |
|    fps                      | 86           |
|    iterations               | 18           |
|    time_elapsed             | 427          |
|    total_timesteps          | 337920       |
| train/                      |              |
|    approx_kl                | 1912.2965    |
|    approx_ln(kl)            | 7.5560603    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.25         |
|    explained_variance       | 0.971        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1640         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0488       |
|    value_loss               | 0.698        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.2935243] |
| time/                       |              |
|    fps                      | 88           |
|    iterations               | 19           |
|    time_elapsed             | 441          |
|    total_timesteps          | 339968       |
| train/                      |              |
|    approx_kl                | 1760.9283    |
|    approx_ln(kl)            | 7.4735966    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.24         |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1650         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0489       |
|    value_loss               | 0.367        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4475459] |
| time/                       |              |
|    fps                      | 89           |
|    iterations               | 20           |
|    time_elapsed             | 455          |
|    total_timesteps          | 342016       |
| train/                      |              |
|    approx_kl                | 876.1493     |
|    approx_ln(kl)            | 6.7755365    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.23         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1660         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0492       |
|    value_loss               | 0.305        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4903279] |
| time/                       |              |
|    fps                      | 91           |
|    iterations               | 21           |
|    time_elapsed             | 468          |
|    total_timesteps          | 344064       |
| train/                      |              |
|    approx_kl                | 922.685      |
|    approx_ln(kl)            | 6.8272877    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.23         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1670         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.049        |
|    value_loss               | 0.209        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.44840467] |
| time/                       |               |
|    fps                      | 93            |
|    iterations               | 22            |
|    time_elapsed             | 482           |
|    total_timesteps          | 346112        |
| train/                      |               |
|    approx_kl                | 631.2324      |
|    approx_ln(kl)            | 6.4476743     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.2           |
|    explained_variance       | 0.996         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 1680          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0497        |
|    value_loss               | 0.25          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-1.545677] |
| time/                       |             |
|    fps                      | 94          |
|    iterations               | 23          |
|    time_elapsed             | 496         |
|    total_timesteps          | 348160      |
| train/                      |             |
|    approx_kl                | 1390.026    |
|    approx_ln(kl)            | 7.2370777   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.23        |
|    explained_variance       | 0.997       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 1690        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0489      |
|    value_loss               | 0.143       |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.63447285] |
| time/                       |               |
|    fps                      | 96            |
|    iterations               | 24            |
|    time_elapsed             | 509           |
|    total_timesteps          | 350208        |
| train/                      |               |
|    approx_kl                | 1755.963      |
|    approx_ln(kl)            | 7.4707727     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.25          |
|    explained_variance       | 0.997         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 1700          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0486        |
|    value_loss               | 0.303         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.1412431] |
| time/                       |              |
|    fps                      | 97           |
|    iterations               | 25           |
|    time_elapsed             | 523          |
|    total_timesteps          | 352256       |
| train/                      |              |
|    approx_kl                | 400.16992    |
|    approx_ln(kl)            | 5.9918895    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.24         |
|    explained_variance       | 0.992        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1710         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0487       |
|    value_loss               | 0.865        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.64846015] |
| time/                       |               |
|    fps                      | 99            |
|    iterations               | 26            |
|    time_elapsed             | 537           |
|    total_timesteps          | 354304        |
| train/                      |               |
|    approx_kl                | 470.0926      |
|    approx_ln(kl)            | 6.15293       |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.24          |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 1720          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0488        |
|    value_loss               | 0.413         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.2254248] |
| time/                       |              |
|    fps                      | 100          |
|    iterations               | 27           |
|    time_elapsed             | 551          |
|    total_timesteps          | 356352       |
| train/                      |              |
|    approx_kl                | 1829.3295    |
|    approx_ln(kl)            | 7.511705     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.24         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1730         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0487       |
|    value_loss               | 0.133        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.61297584] |
| time/                       |               |
|    fps                      | 101           |
|    iterations               | 28            |
|    time_elapsed             | 565           |
|    total_timesteps          | 358400        |
| train/                      |               |
|    approx_kl                | 470.3405      |
|    approx_ln(kl)            | 6.153457      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.24          |
|    explained_variance       | 0.997         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 1740          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0487        |
|    value_loss               | 0.202         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.5876446] |
| time/                       |              |
|    fps                      | 102          |
|    iterations               | 29           |
|    time_elapsed             | 578          |
|    total_timesteps          | 360448       |
| train/                      |              |
|    approx_kl                | 1885.5619    |
|    approx_ln(kl)            | 7.541981     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.27         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1750         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0481       |
|    value_loss               | 0.091        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.8325734] |
| time/                       |              |
|    fps                      | 103          |
|    iterations               | 30           |
|    time_elapsed             | 592          |
|    total_timesteps          | 362496       |
| train/                      |              |
|    approx_kl                | 1280.4275    |
|    approx_ln(kl)            | 7.154949     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.28         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1760         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0476       |
|    value_loss               | 0.137        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6312069] |
| time/                       |              |
|    fps                      | 104          |
|    iterations               | 31           |
|    time_elapsed             | 606          |
|    total_timesteps          | 364544       |
| train/                      |              |
|    approx_kl                | 2627.8535    |
|    approx_ln(kl)            | 7.873923     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.28         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1770         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0475       |
|    value_loss               | 0.103        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.24910724] |
| time/                       |               |
|    fps                      | 105           |
|    iterations               | 32            |
|    time_elapsed             | 620           |
|    total_timesteps          | 366592        |
| train/                      |               |
|    approx_kl                | 895.45074     |
|    approx_ln(kl)            | 6.797327      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.3           |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 1780          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0471        |
|    value_loss               | 0.242         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7917328] |
| time/                       |              |
|    fps                      | 106          |
|    iterations               | 33           |
|    time_elapsed             | 633          |
|    total_timesteps          | 368640       |
| train/                      |              |
|    approx_kl                | 1959.8123    |
|    approx_ln(kl)            | 7.580604     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.32         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1790         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0468       |
|    value_loss               | 0.0533       |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7345041] |
| time/                       |              |
|    fps                      | 107          |
|    iterations               | 34           |
|    time_elapsed             | 647          |
|    total_timesteps          | 370688       |
| train/                      |              |
|    approx_kl                | 1239.7593    |
|    approx_ln(kl)            | 7.1226726    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.27         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1800         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.048        |
|    value_loss               | 0.189        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.4316095] |
| time/                       |              |
|    fps                      | 108          |
|    iterations               | 35           |
|    time_elapsed             | 661          |
|    total_timesteps          | 372736       |
| train/                      |              |
|    approx_kl                | 978.17755    |
|    approx_ln(kl)            | 6.885691     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.28         |
|    explained_variance       | 0.986        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1810         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.048        |
|    value_loss               | 0.179        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0751195] |
| time/                       |              |
|    fps                      | 108          |
|    iterations               | 36           |
|    time_elapsed             | 676          |
|    total_timesteps          | 374784       |
| train/                      |              |
|    approx_kl                | 617.5509     |
|    approx_ln(kl)            | 6.4257617    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.31         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1820         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0475       |
|    value_loss               | 0.631        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.5950816] |
| time/                       |              |
|    fps                      | 109          |
|    iterations               | 37           |
|    time_elapsed             | 692          |
|    total_timesteps          | 376832       |
| train/                      |              |
|    approx_kl                | 823.07495    |
|    approx_ln(kl)            | 6.7130475    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.3          |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1830         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0477       |
|    value_loss               | 0.183        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.0704267] |
| time/                       |              |
|    fps                      | 109          |
|    iterations               | 38           |
|    time_elapsed             | 707          |
|    total_timesteps          | 378880       |
| train/                      |              |
|    approx_kl                | 758.8732     |
|    approx_ln(kl)            | 6.631835     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.33         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1840         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.047        |
|    value_loss               | 0.0768       |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.9072331] |
| time/                       |              |
|    fps                      | 110          |
|    iterations               | 39           |
|    time_elapsed             | 721          |
|    total_timesteps          | 380928       |
| train/                      |              |
|    approx_kl                | 825.7369     |
|    approx_ln(kl)            | 6.716276     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.38         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1850         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0458       |
|    value_loss               | 0.309        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.61997116] |
| time/                       |               |
|    fps                      | 111           |
|    iterations               | 40            |
|    time_elapsed             | 735           |
|    total_timesteps          | 382976        |
| train/                      |               |
|    approx_kl                | 581.24225     |
|    approx_ln(kl)            | 6.3651676     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.37          |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 1860          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0463        |
|    value_loss               | 0.284         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4106727] |
| time/                       |              |
|    fps                      | 112          |
|    iterations               | 41           |
|    time_elapsed             | 748          |
|    total_timesteps          | 385024       |
| train/                      |              |
|    approx_kl                | 786.7455     |
|    approx_ln(kl)            | 6.667905     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.35         |
|    explained_variance       | 0.95         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1870         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0466       |
|    value_loss               | 0.358        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.31949246] |
| time/                       |               |
|    fps                      | 112           |
|    iterations               | 42            |
|    time_elapsed             | 762           |
|    total_timesteps          | 387072        |
| train/                      |               |
|    approx_kl                | 1530.4794     |
|    approx_ln(kl)            | 7.3333364     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.36          |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 1880          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0466        |
|    value_loss               | 0.0807        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.3857769] |
| time/                       |              |
|    fps                      | 113          |
|    iterations               | 43           |
|    time_elapsed             | 776          |
|    total_timesteps          | 389120       |
| train/                      |              |
|    approx_kl                | 994.2217     |
|    approx_ln(kl)            | 6.9019604    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.37         |
|    explained_variance       | 0.972        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1890         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0463       |
|    value_loss               | 0.497        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.37720233] |
| time/                       |               |
|    fps                      | 114           |
|    iterations               | 44            |
|    time_elapsed             | 789           |
|    total_timesteps          | 391168        |
| train/                      |               |
|    approx_kl                | 574.9235      |
|    approx_ln(kl)            | 6.354237      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.36          |
|    explained_variance       | 0.276         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 1900          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0465        |
|    value_loss               | 1.76          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6988612] |
| time/                       |              |
|    fps                      | 114          |
|    iterations               | 45           |
|    time_elapsed             | 803          |
|    total_timesteps          | 393216       |
| train/                      |              |
|    approx_kl                | 1266.2231    |
|    approx_ln(kl)            | 7.143794     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.35         |
|    explained_variance       | 0.967        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1910         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0465       |
|    value_loss               | 0.391        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0343124] |
| time/                       |              |
|    fps                      | 115          |
|    iterations               | 46           |
|    time_elapsed             | 817          |
|    total_timesteps          | 395264       |
| train/                      |              |
|    approx_kl                | 1191.1333    |
|    approx_ln(kl)            | 7.0826607    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.34         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1920         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0468       |
|    value_loss               | 0.121        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7937841] |
| time/                       |              |
|    fps                      | 115          |
|    iterations               | 47           |
|    time_elapsed             | 830          |
|    total_timesteps          | 397312       |
| train/                      |              |
|    approx_kl                | 358.62366    |
|    approx_ln(kl)            | 5.8822737    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.36         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 1930         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0464       |
|    value_loss               | 0.127        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.34957638] |
| time/                       |               |
|    fps                      | 116           |
|    iterations               | 48            |
|    time_elapsed             | 844           |
|    total_timesteps          | 399360        |
| train/                      |               |
|    approx_kl                | 1365.1416     |
|    approx_ln(kl)            | 7.2190137     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.36          |
|    explained_variance       | 0.997         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 1940          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0463        |
|    value_loss               | 0.0891        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.57882136] |
| time/                       |               |
|    fps                      | 116           |
|    iterations               | 49            |
|    time_elapsed             | 858           |
|    total_timesteps          | 401408        |
| train/                      |               |
|    approx_kl                | 609.86584     |
|    approx_ln(kl)            | 6.413239      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.38          |
|    explained_variance       | 0.974         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 1950          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0458        |
|    value_loss               | 0.385         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-------------------------------------
| reward             | [-0.3925314] |
| time/              |              |
|    fps             | 163          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 403456       |
-------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.33558002] |
| time/                       |               |
|    fps                      | 149           |
|    iterations               | 2             |
|    time_elapsed             | 27            |
|    total_timesteps          | 405504        |
| train/                      |               |
|    approx_kl                | 230.73338     |
|    approx_ln(kl)            | 5.4412627     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.37          |
|    explained_variance       | -1.16         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 1970          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0459        |
|    value_loss               | 27.3          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.35348108] |
| time/                       |               |
|    fps                      | 146           |
|    iterations               | 3             |
|    time_elapsed             | 41            |
|    total_timesteps          | 407552        |
| train/                      |               |
|    approx_kl                | 1945.077      |
|    approx_ln(kl)            | 7.5730567     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.4           |
|    explained_variance       | 0.995         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 1980          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0452        |
|    value_loss               | 0.178         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.51001626] |
| time/                       |               |
|    fps                      | 146           |
|    iterations               | 4             |
|    time_elapsed             | 55            |
|    total_timesteps          | 409600        |
| train/                      |               |
|    approx_kl                | 3130.9746     |
|    approx_ln(kl)            | 8.0491        |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.42          |
|    explained_variance       | 0.986         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 1990          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.045         |
|    value_loss               | 0.0888        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.40916222] |
| time/                       |               |
|    fps                      | 147           |
|    iterations               | 5             |
|    time_elapsed             | 69            |
|    total_timesteps          | 411648        |
| train/                      |               |
|    approx_kl                | 666.17163     |
|    approx_ln(kl)            | 6.5015473     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.44          |
|    explained_variance       | 0.963         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 2000          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0444        |
|    value_loss               | 0.216         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.48011446] |
| time/                       |               |
|    fps                      | 147           |
|    iterations               | 6             |
|    time_elapsed             | 83            |
|    total_timesteps          | 413696        |
| train/                      |               |
|    approx_kl                | 1077.6582     |
|    approx_ln(kl)            | 6.982546      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.47          |
|    explained_variance       | 0.979         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 2010          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0438        |
|    value_loss               | 0.332         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5585476] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 7            |
|    time_elapsed             | 97           |
|    total_timesteps          | 415744       |
| train/                      |              |
|    approx_kl                | 1151.3787    |
|    approx_ln(kl)            | 7.0487156    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.46         |
|    explained_variance       | 0.465        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2020         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.044        |
|    value_loss               | 0.213        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5120635] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 8            |
|    time_elapsed             | 110          |
|    total_timesteps          | 417792       |
| train/                      |              |
|    approx_kl                | 966.48804    |
|    approx_ln(kl)            | 6.873669     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.44         |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2030         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0447       |
|    value_loss               | 0.0507       |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4704218] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 9            |
|    time_elapsed             | 124          |
|    total_timesteps          | 419840       |
| train/                      |              |
|    approx_kl                | 1225.0848    |
|    approx_ln(kl)            | 7.1107655    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.39         |
|    explained_variance       | 0.984        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2040         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0457       |
|    value_loss               | 0.0302       |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.31908008] |
| time/                       |               |
|    fps                      | 148           |
|    iterations               | 10            |
|    time_elapsed             | 138           |
|    total_timesteps          | 421888        |
| train/                      |               |
|    approx_kl                | 1255.5671     |
|    approx_ln(kl)            | 7.1353426     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.4           |
|    explained_variance       | 0.922         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 2050          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0455        |
|    value_loss               | 0.101         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.51708144] |
| time/                       |               |
|    fps                      | 148           |
|    iterations               | 11            |
|    time_elapsed             | 151           |
|    total_timesteps          | 423936        |
| train/                      |               |
|    approx_kl                | 4077.7002     |
|    approx_ln(kl)            | 8.313289      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.39          |
|    explained_variance       | 0.942         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 2060          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0457        |
|    value_loss               | 0.122         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.35484484] |
| time/                       |               |
|    fps                      | 147           |
|    iterations               | 12            |
|    time_elapsed             | 166           |
|    total_timesteps          | 425984        |
| train/                      |               |
|    approx_kl                | 782.9387      |
|    approx_ln(kl)            | 6.6630545     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.36          |
|    explained_variance       | 0.994         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 2070          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0463        |
|    value_loss               | 0.156         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.47454008] |
| time/                       |               |
|    fps                      | 130           |
|    iterations               | 13            |
|    time_elapsed             | 203           |
|    total_timesteps          | 428032        |
| train/                      |               |
|    approx_kl                | 1584.2252     |
|    approx_ln(kl)            | 7.367851      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.36          |
|    explained_variance       | 0.978         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 2080          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0464        |
|    value_loss               | 0.114         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-0.510996] |
| time/                       |             |
|    fps                      | 101         |
|    iterations               | 14          |
|    time_elapsed             | 283         |
|    total_timesteps          | 430080      |
| train/                      |             |
|    approx_kl                | 3760.537    |
|    approx_ln(kl)            | 8.232317    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.41        |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 2090        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0452      |
|    value_loss               | 0.0169      |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.58911747] |
| time/                       |               |
|    fps                      | 100           |
|    iterations               | 15            |
|    time_elapsed             | 306           |
|    total_timesteps          | 432128        |
| train/                      |               |
|    approx_kl                | 2270.6184     |
|    approx_ln(kl)            | 7.7278075     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.41          |
|    explained_variance       | 0.968         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 2100          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0453        |
|    value_loss               | 0.0342        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.51587266] |
| time/                       |               |
|    fps                      | 93            |
|    iterations               | 16            |
|    time_elapsed             | 350           |
|    total_timesteps          | 434176        |
| train/                      |               |
|    approx_kl                | 1088.3887     |
|    approx_ln(kl)            | 6.9924536     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.42          |
|    explained_variance       | 0.991         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 2110          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0451        |
|    value_loss               | 0.0344        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.3143386] |
| time/                       |              |
|    fps                      | 94           |
|    iterations               | 17           |
|    time_elapsed             | 367          |
|    total_timesteps          | 436224       |
| train/                      |              |
|    approx_kl                | 1324.702     |
|    approx_ln(kl)            | 7.188943     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.44         |
|    explained_variance       | -2.17        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2120         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0447       |
|    value_loss               | 61.2         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.58366084] |
| time/                       |               |
|    fps                      | 94            |
|    iterations               | 18            |
|    time_elapsed             | 388           |
|    total_timesteps          | 438272        |
| train/                      |               |
|    approx_kl                | 1257.253      |
|    approx_ln(kl)            | 7.1366844     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.43          |
|    explained_variance       | -2.01         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 2130          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0448        |
|    value_loss               | 7.14          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.859492] |
| time/                       |             |
|    fps                      | 82          |
|    iterations               | 19          |
|    time_elapsed             | 470         |
|    total_timesteps          | 440320      |
| train/                      |             |
|    approx_kl                | 2073.8435   |
|    approx_ln(kl)            | 7.637159    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.42        |
|    explained_variance       | 0.967       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 2140        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.045       |
|    value_loss               | 0.0675      |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.1164684] |
| time/                       |              |
|    fps                      | 84           |
|    iterations               | 20           |
|    time_elapsed             | 483          |
|    total_timesteps          | 442368       |
| train/                      |              |
|    approx_kl                | 4472.3774    |
|    approx_ln(kl)            | 8.405676     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.41         |
|    explained_variance       | -1.56        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2150         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.045        |
|    value_loss               | 48           |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.8803901] |
| time/                       |              |
|    fps                      | 73           |
|    iterations               | 21           |
|    time_elapsed             | 584          |
|    total_timesteps          | 444416       |
| train/                      |              |
|    approx_kl                | 689.41626    |
|    approx_ln(kl)            | 6.5358453    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.42         |
|    explained_variance       | 0.487        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2160         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0448       |
|    value_loss               | 87.2         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.67393136] |
| time/                       |               |
|    fps                      | 64            |
|    iterations               | 22            |
|    time_elapsed             | 693           |
|    total_timesteps          | 446464        |
| train/                      |               |
|    approx_kl                | 434.2035      |
|    approx_ln(kl)            | 6.0735135     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.44          |
|    explained_variance       | 0.855         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 2170          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0445        |
|    value_loss               | 76.1          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.31774694] |
| time/                       |               |
|    fps                      | 58            |
|    iterations               | 23            |
|    time_elapsed             | 807           |
|    total_timesteps          | 448512        |
| train/                      |               |
|    approx_kl                | 1234.0708     |
|    approx_ln(kl)            | 7.1180735     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.44          |
|    explained_variance       | 0.903         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 2180          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0445        |
|    value_loss               | 61.7          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5662191] |
| time/                       |              |
|    fps                      | 53           |
|    iterations               | 24           |
|    time_elapsed             | 921          |
|    total_timesteps          | 450560       |
| train/                      |              |
|    approx_kl                | 684.7211     |
|    approx_ln(kl)            | 6.5290117    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.43         |
|    explained_variance       | 0.95         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2190         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0448       |
|    value_loss               | 62.6         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.4909103] |
| time/                       |              |
|    fps                      | 50           |
|    iterations               | 25           |
|    time_elapsed             | 1022         |
|    total_timesteps          | 452608       |
| train/                      |              |
|    approx_kl                | 950.75635    |
|    approx_ln(kl)            | 6.857258     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.46         |
|    explained_variance       | 0.977        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2200         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0438       |
|    value_loss               | 57.3         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.1502333] |
| time/                       |              |
|    fps                      | 51           |
|    iterations               | 26           |
|    time_elapsed             | 1036         |
|    total_timesteps          | 454656       |
| train/                      |              |
|    approx_kl                | 488.4087     |
|    approx_ln(kl)            | 6.1911526    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.49         |
|    explained_variance       | 0.975        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2210         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0432       |
|    value_loss               | 35.6         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.7953964] |
| time/                       |              |
|    fps                      | 52           |
|    iterations               | 27           |
|    time_elapsed             | 1050         |
|    total_timesteps          | 456704       |
| train/                      |              |
|    approx_kl                | 1213.918     |
|    approx_ln(kl)            | 7.1016083    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.49         |
|    explained_variance       | 0.987        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2220         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0434       |
|    value_loss               | 50.4         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.4478996] |
| time/                       |              |
|    fps                      | 53           |
|    iterations               | 28           |
|    time_elapsed             | 1064         |
|    total_timesteps          | 458752       |
| train/                      |              |
|    approx_kl                | 457.8804     |
|    approx_ln(kl)            | 6.126608     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.48         |
|    explained_variance       | 0.989        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2230         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0435       |
|    value_loss               | 36.2         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.2077134] |
| time/                       |              |
|    fps                      | 50           |
|    iterations               | 29           |
|    time_elapsed             | 1168         |
|    total_timesteps          | 460800       |
| train/                      |              |
|    approx_kl                | 504.49725    |
|    approx_ln(kl)            | 6.2235622    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.47         |
|    explained_variance       | 0.978        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2240         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0436       |
|    value_loss               | 12.1         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
--------------------------------------------
| reward                      | [-2.31471] |
| time/                       |            |
|    fps                      | 51         |
|    iterations               | 30         |
|    time_elapsed             | 1182       |
|    total_timesteps          | 462848     |
| train/                      |            |
|    approx_kl                | 410.25418  |
|    approx_ln(kl)            | 6.016777   |
|    clip_range               | 0.2        |
|    entropy_loss             | 3.47       |
|    explained_variance       | 0.994      |
|    learning_rate            | 0.001      |
|    ln(loss)                 | inf        |
|    ln(policy_gradient_loss) | nan        |
|    loss                     | inf        |
|    n_updates                | 2250       |
|    policy_gradient_loss     | nan        |
|    std                      | 0.0436     |
|    value_loss               | 7.48       |
--------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.6581635] |
| time/                       |              |
|    fps                      | 52           |
|    iterations               | 31           |
|    time_elapsed             | 1199         |
|    total_timesteps          | 464896       |
| train/                      |              |
|    approx_kl                | 543.88885    |
|    approx_ln(kl)            | 6.298745     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.47         |
|    explained_variance       | 0.99         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2260         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0436       |
|    value_loss               | 3.56         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.1848623] |
| time/                       |              |
|    fps                      | 53           |
|    iterations               | 32           |
|    time_elapsed             | 1221         |
|    total_timesteps          | 466944       |
| train/                      |              |
|    approx_kl                | 834.2477     |
|    approx_ln(kl)            | 6.7265306    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.44         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2270         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0443       |
|    value_loss               | 2.73         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-1.524802] |
| time/                       |             |
|    fps                      | 54          |
|    iterations               | 33          |
|    time_elapsed             | 1237        |
|    total_timesteps          | 468992      |
| train/                      |             |
|    approx_kl                | 1165.423    |
|    approx_ln(kl)            | 7.060839    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.44        |
|    explained_variance       | 0.977       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 2280        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0443      |
|    value_loss               | 2.89        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.1043377] |
| time/                       |              |
|    fps                      | 55           |
|    iterations               | 34           |
|    time_elapsed             | 1254         |
|    total_timesteps          | 471040       |
| train/                      |              |
|    approx_kl                | 1694.813     |
|    approx_ln(kl)            | 7.4353275    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.47         |
|    explained_variance       | 0.982        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2290         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0434       |
|    value_loss               | 1.07         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.7634915] |
| time/                       |              |
|    fps                      | 56           |
|    iterations               | 35           |
|    time_elapsed             | 1270         |
|    total_timesteps          | 473088       |
| train/                      |              |
|    approx_kl                | 1891.7991    |
|    approx_ln(kl)            | 7.545284     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.47         |
|    explained_variance       | 0.707        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2300         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0429       |
|    value_loss               | 31.9         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.2654462] |
| time/                       |              |
|    fps                      | 57           |
|    iterations               | 36           |
|    time_elapsed             | 1286         |
|    total_timesteps          | 475136       |
| train/                      |              |
|    approx_kl                | 484.95004    |
|    approx_ln(kl)            | 6.184046     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.47         |
|    explained_variance       | 0.626        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2310         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0435       |
|    value_loss               | 452          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.0279794] |
| time/                       |              |
|    fps                      | 58           |
|    iterations               | 37           |
|    time_elapsed             | 1302         |
|    total_timesteps          | 477184       |
| train/                      |              |
|    approx_kl                | 233.43515    |
|    approx_ln(kl)            | 5.452904     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.45         |
|    explained_variance       | 0.585        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2320         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0438       |
|    value_loss               | 207          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.5163774] |
| time/                       |              |
|    fps                      | 59           |
|    iterations               | 38           |
|    time_elapsed             | 1318         |
|    total_timesteps          | 479232       |
| train/                      |              |
|    approx_kl                | 195.78935    |
|    approx_ln(kl)            | 5.2770395    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.45         |
|    explained_variance       | 0.88         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2330         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0437       |
|    value_loss               | 131          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.1906123] |
| time/                       |              |
|    fps                      | 59           |
|    iterations               | 39           |
|    time_elapsed             | 1333         |
|    total_timesteps          | 481280       |
| train/                      |              |
|    approx_kl                | 130.88565    |
|    approx_ln(kl)            | 4.874324     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.47         |
|    explained_variance       | -0.765       |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2340         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0433       |
|    value_loss               | 115          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.2293553] |
| time/                       |              |
|    fps                      | 60           |
|    iterations               | 40           |
|    time_elapsed             | 1349         |
|    total_timesteps          | 483328       |
| train/                      |              |
|    approx_kl                | 664.2511     |
|    approx_ln(kl)            | 6.49866      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.45         |
|    explained_variance       | 0.922        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2350         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0439       |
|    value_loss               | 97.3         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.300074] |
| time/                       |             |
|    fps                      | 61          |
|    iterations               | 41          |
|    time_elapsed             | 1364        |
|    total_timesteps          | 485376      |
| train/                      |             |
|    approx_kl                | 434.00024   |
|    approx_ln(kl)            | 6.0730453   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.45        |
|    explained_variance       | 0.889       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 2360        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0437      |
|    value_loss               | 82.5        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.8141794] |
| time/                       |              |
|    fps                      | 62           |
|    iterations               | 42           |
|    time_elapsed             | 1380         |
|    total_timesteps          | 487424       |
| train/                      |              |
|    approx_kl                | 131.41925    |
|    approx_ln(kl)            | 4.8783927    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.45         |
|    explained_variance       | 0.95         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2370         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0438       |
|    value_loss               | 60.1         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-5.112546] |
| time/                       |             |
|    fps                      | 63          |
|    iterations               | 43          |
|    time_elapsed             | 1396        |
|    total_timesteps          | 489472      |
| train/                      |             |
|    approx_kl                | 126.847496  |
|    approx_ln(kl)            | 4.8429856   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.46        |
|    explained_variance       | 0.921       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 2380        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0433      |
|    value_loss               | 73.4        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.32344323] |
| time/                       |               |
|    fps                      | 63            |
|    iterations               | 44            |
|    time_elapsed             | 1412          |
|    total_timesteps          | 491520        |
| train/                      |               |
|    approx_kl                | 559.38403     |
|    approx_ln(kl)            | 6.326836      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.48          |
|    explained_variance       | 0.929         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 2390          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0433        |
|    value_loss               | 47.7          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.6261983] |
| time/                       |              |
|    fps                      | 64           |
|    iterations               | 45           |
|    time_elapsed             | 1429         |
|    total_timesteps          | 493568       |
| train/                      |              |
|    approx_kl                | 345.2929     |
|    approx_ln(kl)            | 5.8443933    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.44         |
|    explained_variance       | 0.964        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2400         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.044        |
|    value_loss               | 51.8         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.2576091] |
| time/                       |              |
|    fps                      | 65           |
|    iterations               | 46           |
|    time_elapsed             | 1445         |
|    total_timesteps          | 495616       |
| train/                      |              |
|    approx_kl                | 872.44183    |
|    approx_ln(kl)            | 6.771296     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.43         |
|    explained_variance       | 0.98         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2410         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.044        |
|    value_loss               | 25.9         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.3109295] |
| time/                       |              |
|    fps                      | 64           |
|    iterations               | 47           |
|    time_elapsed             | 1495         |
|    total_timesteps          | 497664       |
| train/                      |              |
|    approx_kl                | 949.1065     |
|    approx_ln(kl)            | 6.855521     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.46         |
|    explained_variance       | 0.979        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2420         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0434       |
|    value_loss               | 7.46         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-1.024888] |
| time/                       |             |
|    fps                      | 64          |
|    iterations               | 48          |
|    time_elapsed             | 1519        |
|    total_timesteps          | 499712      |
| train/                      |             |
|    approx_kl                | 622.08594   |
|    approx_ln(kl)            | 6.4330783   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.44        |
|    explained_variance       | 0.992       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 2430        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0441      |
|    value_loss               | 4.1         |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.4753978] |
| time/                       |              |
|    fps                      | 65           |
|    iterations               | 49           |
|    time_elapsed             | 1534         |
|    total_timesteps          | 501760       |
| train/                      |              |
|    approx_kl                | 1180.4216    |
|    approx_ln(kl)            | 7.073627     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.44         |
|    explained_variance       | 0.992        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2440         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0439       |
|    value_loss               | 2.92         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-------------------------------------
| reward             | [-2.0293458] |
| time/              |              |
|    fps             | 147          |
|    iterations      | 1            |
|    time_elapsed    | 13           |
|    total_timesteps | 503808       |
-------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.067297] |
| time/                       |             |
|    fps                      | 139         |
|    iterations               | 2           |
|    time_elapsed             | 29          |
|    total_timesteps          | 505856      |
| train/                      |             |
|    approx_kl                | 1433.5112   |
|    approx_ln(kl)            | 7.2678823   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.42        |
|    explained_variance       | 0.983       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 2460        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0444      |
|    value_loss               | 8.68        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-1.515519] |
| time/                       |             |
|    fps                      | 106         |
|    iterations               | 3           |
|    time_elapsed             | 57          |
|    total_timesteps          | 507904      |
| train/                      |             |
|    approx_kl                | 1149.4822   |
|    approx_ln(kl)            | 7.0470667   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.42        |
|    explained_variance       | 0.968       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 2470        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0444      |
|    value_loss               | 23.3        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
--------------------------------------------
| reward                      | [-4.37745] |
| time/                       |            |
|    fps                      | 113        |
|    iterations               | 4          |
|    time_elapsed             | 72         |
|    total_timesteps          | 509952     |
| train/                      |            |
|    approx_kl                | 416.59137  |
|    approx_ln(kl)            | 6.032106   |
|    clip_range               | 0.2        |
|    entropy_loss             | 3.37       |
|    explained_variance       | 0.948      |
|    learning_rate            | 0.001      |
|    ln(loss)                 | inf        |
|    ln(policy_gradient_loss) | nan        |
|    loss                     | inf        |
|    n_updates                | 2480       |
|    policy_gradient_loss     | nan        |
|    std                      | 0.0455     |
|    value_loss               | 11         |
--------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [178.81621] |
| time/                       |             |
|    fps                      | 57          |
|    iterations               | 5           |
|    time_elapsed             | 176         |
|    total_timesteps          | 512000      |
| train/                      |             |
|    approx_kl                | 546.5552    |
|    approx_ln(kl)            | 6.303635    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.4         |
|    explained_variance       | 0.905       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 2490        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0445      |
|    value_loss               | 143         |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.49803293] |
| time/                       |               |
|    fps                      | 43            |
|    iterations               | 6             |
|    time_elapsed             | 280           |
|    total_timesteps          | 514048        |
| train/                      |               |
|    approx_kl                | 302.49075     |
|    approx_ln(kl)            | 5.712051      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.41          |
|    explained_variance       | 0.699         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 2500          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0443        |
|    value_loss               | 171           |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.32844225] |
| time/                       |               |
|    fps                      | 48            |
|    iterations               | 7             |
|    time_elapsed             | 294           |
|    total_timesteps          | 516096        |
| train/                      |               |
|    approx_kl                | 213.15668     |
|    approx_ln(kl)            | 5.3620276     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.42          |
|    explained_variance       | 0.829         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 2510          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0444        |
|    value_loss               | 62.9          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.7834076] |
| time/                       |              |
|    fps                      | 53           |
|    iterations               | 8            |
|    time_elapsed             | 307          |
|    total_timesteps          | 518144       |
| train/                      |              |
|    approx_kl                | 101.18755    |
|    approx_ln(kl)            | 4.616976     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.43         |
|    explained_variance       | 0.826        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2520         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0439       |
|    value_loss               | 78.9         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5172969] |
| time/                       |              |
|    fps                      | 57           |
|    iterations               | 9            |
|    time_elapsed             | 321          |
|    total_timesteps          | 520192       |
| train/                      |              |
|    approx_kl                | 1063.2037    |
|    approx_ln(kl)            | 6.969042     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.46         |
|    explained_variance       | 0.792        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2530         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0431       |
|    value_loss               | 65.2         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6082699] |
| time/                       |              |
|    fps                      | 61           |
|    iterations               | 10           |
|    time_elapsed             | 335          |
|    total_timesteps          | 522240       |
| train/                      |              |
|    approx_kl                | 805.45776    |
|    approx_ln(kl)            | 6.6914105    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.47         |
|    explained_variance       | 0.372        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2540         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0431       |
|    value_loss               | 75           |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.85784334] |
| time/                       |               |
|    fps                      | 64            |
|    iterations               | 11            |
|    time_elapsed             | 349           |
|    total_timesteps          | 524288        |
| train/                      |               |
|    approx_kl                | 413.8551      |
|    approx_ln(kl)            | 6.025516      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.48          |
|    explained_variance       | 0.241         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 2550          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0429        |
|    value_loss               | 52.3          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.0667663] |
| time/                       |              |
|    fps                      | 67           |
|    iterations               | 12           |
|    time_elapsed             | 362          |
|    total_timesteps          | 526336       |
| train/                      |              |
|    approx_kl                | 464.0191     |
|    approx_ln(kl)            | 6.139926     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.49         |
|    explained_variance       | 0.703        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2560         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0425       |
|    value_loss               | 17.9         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.82355523] |
| time/                       |               |
|    fps                      | 70            |
|    iterations               | 13            |
|    time_elapsed             | 376           |
|    total_timesteps          | 528384        |
| train/                      |               |
|    approx_kl                | 1081.0719     |
|    approx_ln(kl)            | 6.985708      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.49          |
|    explained_variance       | -0.951        |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 2570          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0427        |
|    value_loss               | 56.7          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0048848] |
| time/                       |              |
|    fps                      | 73           |
|    iterations               | 14           |
|    time_elapsed             | 390          |
|    total_timesteps          | 530432       |
| train/                      |              |
|    approx_kl                | 195.66919    |
|    approx_ln(kl)            | 5.2764254    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.48         |
|    explained_variance       | 0.264        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2580         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.043        |
|    value_loss               | 41.9         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.8653057] |
| time/                       |              |
|    fps                      | 75           |
|    iterations               | 15           |
|    time_elapsed             | 404          |
|    total_timesteps          | 532480       |
| train/                      |              |
|    approx_kl                | 1735.5208    |
|    approx_ln(kl)            | 7.4590626    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.47         |
|    explained_variance       | 0.87         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2590         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0432       |
|    value_loss               | 13.1         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.64539135] |
| time/                       |               |
|    fps                      | 78            |
|    iterations               | 16            |
|    time_elapsed             | 417           |
|    total_timesteps          | 534528        |
| train/                      |               |
|    approx_kl                | 512.3995      |
|    approx_ln(kl)            | 6.2391047     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.46          |
|    explained_variance       | 0.802         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 2600          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0432        |
|    value_loss               | 18.7          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0576383] |
| time/                       |              |
|    fps                      | 80           |
|    iterations               | 17           |
|    time_elapsed             | 431          |
|    total_timesteps          | 536576       |
| train/                      |              |
|    approx_kl                | 683.1443     |
|    approx_ln(kl)            | 6.526706     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.44         |
|    explained_variance       | 0.366        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2610         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0437       |
|    value_loss               | 38.3         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.38296017] |
| time/                       |               |
|    fps                      | 82            |
|    iterations               | 18            |
|    time_elapsed             | 445           |
|    total_timesteps          | 538624        |
| train/                      |               |
|    approx_kl                | 283.852       |
|    approx_ln(kl)            | 5.6484528     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.45          |
|    explained_variance       | 0.777         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 2620          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0435        |
|    value_loss               | 164           |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.353708] |
| time/                       |             |
|    fps                      | 84          |
|    iterations               | 19          |
|    time_elapsed             | 459         |
|    total_timesteps          | 540672      |
| train/                      |             |
|    approx_kl                | 660.63684   |
|    approx_ln(kl)            | 6.493204    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.42        |
|    explained_variance       | 0.934       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 2630        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0442      |
|    value_loss               | 54.4        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.6509051] |
| time/                       |              |
|    fps                      | 86           |
|    iterations               | 20           |
|    time_elapsed             | 472          |
|    total_timesteps          | 542720       |
| train/                      |              |
|    approx_kl                | 460.91537    |
|    approx_ln(kl)            | 6.1332145    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.38         |
|    explained_variance       | 0.964        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2640         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0452       |
|    value_loss               | 14.7         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.2867773] |
| time/                       |              |
|    fps                      | 88           |
|    iterations               | 21           |
|    time_elapsed             | 486          |
|    total_timesteps          | 544768       |
| train/                      |              |
|    approx_kl                | 262.13797    |
|    approx_ln(kl)            | 5.568871     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.38         |
|    explained_variance       | 0.987        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2650         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0451       |
|    value_loss               | 13.6         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.6529686] |
| time/                       |              |
|    fps                      | 90           |
|    iterations               | 22           |
|    time_elapsed             | 500          |
|    total_timesteps          | 546816       |
| train/                      |              |
|    approx_kl                | 71.104965    |
|    approx_ln(kl)            | 4.2641573    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.37         |
|    explained_variance       | 0.975        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2660         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0454       |
|    value_loss               | 12.4         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.2243617] |
| time/                       |              |
|    fps                      | 91           |
|    iterations               | 23           |
|    time_elapsed             | 513          |
|    total_timesteps          | 548864       |
| train/                      |              |
|    approx_kl                | 215.35008    |
|    approx_ln(kl)            | 5.372265     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.37         |
|    explained_variance       | 0.98         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2670         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0452       |
|    value_loss               | 9.81         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.8299325] |
| time/                       |              |
|    fps                      | 93           |
|    iterations               | 24           |
|    time_elapsed             | 527          |
|    total_timesteps          | 550912       |
| train/                      |              |
|    approx_kl                | 786.1587     |
|    approx_ln(kl)            | 6.6671586    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.37         |
|    explained_variance       | 0.988        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2680         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0453       |
|    value_loss               | 6.63         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.0983686] |
| time/                       |              |
|    fps                      | 94           |
|    iterations               | 25           |
|    time_elapsed             | 541          |
|    total_timesteps          | 552960       |
| train/                      |              |
|    approx_kl                | 153.99794    |
|    approx_ln(kl)            | 5.036939     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.35         |
|    explained_variance       | 0.991        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2690         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0457       |
|    value_loss               | 5.96         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.59274566] |
| time/                       |               |
|    fps                      | 95            |
|    iterations               | 26            |
|    time_elapsed             | 555           |
|    total_timesteps          | 555008        |
| train/                      |               |
|    approx_kl                | 501.89215     |
|    approx_ln(kl)            | 6.218385      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.37          |
|    explained_variance       | 0.995         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 2700          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0451        |
|    value_loss               | 6.1           |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.2239074] |
| time/                       |              |
|    fps                      | 97           |
|    iterations               | 27           |
|    time_elapsed             | 569          |
|    total_timesteps          | 557056       |
| train/                      |              |
|    approx_kl                | 616.21277    |
|    approx_ln(kl)            | 6.423592     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.37         |
|    explained_variance       | 0.984        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2710         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0454       |
|    value_loss               | 4.37         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.0634704] |
| time/                       |              |
|    fps                      | 98           |
|    iterations               | 28           |
|    time_elapsed             | 582          |
|    total_timesteps          | 559104       |
| train/                      |              |
|    approx_kl                | 460.39795    |
|    approx_ln(kl)            | 6.132091     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.37         |
|    explained_variance       | 0.986        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2720         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0455       |
|    value_loss               | 9.01         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.2466652] |
| time/                       |              |
|    fps                      | 99           |
|    iterations               | 29           |
|    time_elapsed             | 596          |
|    total_timesteps          | 561152       |
| train/                      |              |
|    approx_kl                | 898.2761     |
|    approx_ln(kl)            | 6.8004775    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.36         |
|    explained_variance       | 0.979        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2730         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0457       |
|    value_loss               | 7.56         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.8533547] |
| time/                       |              |
|    fps                      | 100          |
|    iterations               | 30           |
|    time_elapsed             | 610          |
|    total_timesteps          | 563200       |
| train/                      |              |
|    approx_kl                | 376.9562     |
|    approx_ln(kl)            | 5.932129     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.36         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2740         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0459       |
|    value_loss               | 2.97         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.237986] |
| time/                       |             |
|    fps                      | 101         |
|    iterations               | 31          |
|    time_elapsed             | 625         |
|    total_timesteps          | 565248      |
| train/                      |             |
|    approx_kl                | 162.92627   |
|    approx_ln(kl)            | 5.093298    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.35        |
|    explained_variance       | 0.99        |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 2750        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0461      |
|    value_loss               | 4.95        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.4410129] |
| time/                       |              |
|    fps                      | 102          |
|    iterations               | 32           |
|    time_elapsed             | 639          |
|    total_timesteps          | 567296       |
| train/                      |              |
|    approx_kl                | 286.12744    |
|    approx_ln(kl)            | 5.6564374    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.36         |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2760         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0456       |
|    value_loss               | 4.17         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.5145938] |
| time/                       |              |
|    fps                      | 103          |
|    iterations               | 33           |
|    time_elapsed             | 652          |
|    total_timesteps          | 569344       |
| train/                      |              |
|    approx_kl                | 159.61467    |
|    approx_ln(kl)            | 5.0727625    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.36         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2770         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0458       |
|    value_loss               | 3.78         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.960805] |
| time/                       |             |
|    fps                      | 104         |
|    iterations               | 34          |
|    time_elapsed             | 666         |
|    total_timesteps          | 571392      |
| train/                      |             |
|    approx_kl                | 315.49622   |
|    approx_ln(kl)            | 5.7541466   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.36        |
|    explained_variance       | 0.996       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 2780        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0458      |
|    value_loss               | 2.44        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.329916] |
| time/                       |             |
|    fps                      | 105         |
|    iterations               | 35          |
|    time_elapsed             | 679         |
|    total_timesteps          | 573440      |
| train/                      |             |
|    approx_kl                | 354.7702    |
|    approx_ln(kl)            | 5.8714705   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.37        |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 2790        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0454      |
|    value_loss               | 1.6         |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.5130057] |
| time/                       |              |
|    fps                      | 106          |
|    iterations               | 36           |
|    time_elapsed             | 693          |
|    total_timesteps          | 575488       |
| train/                      |              |
|    approx_kl                | 706.9973     |
|    approx_ln(kl)            | 6.561027     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.36         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2800         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0457       |
|    value_loss               | 2.67         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.9139552] |
| time/                       |              |
|    fps                      | 107          |
|    iterations               | 37           |
|    time_elapsed             | 707          |
|    total_timesteps          | 577536       |
| train/                      |              |
|    approx_kl                | 323.6755     |
|    approx_ln(kl)            | 5.7797413    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.36         |
|    explained_variance       | 0.991        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2810         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0457       |
|    value_loss               | 3.15         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.5179956] |
| time/                       |              |
|    fps                      | 107          |
|    iterations               | 38           |
|    time_elapsed             | 721          |
|    total_timesteps          | 579584       |
| train/                      |              |
|    approx_kl                | 711.29034    |
|    approx_ln(kl)            | 6.5670805    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.35         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2820         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.046        |
|    value_loss               | 3.86         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.323558] |
| time/                       |             |
|    fps                      | 108         |
|    iterations               | 39          |
|    time_elapsed             | 734         |
|    total_timesteps          | 581632      |
| train/                      |             |
|    approx_kl                | 465.7144    |
|    approx_ln(kl)            | 6.1435723   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.35        |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 2830        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0463      |
|    value_loss               | 1.53        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.8159332] |
| time/                       |              |
|    fps                      | 109          |
|    iterations               | 40           |
|    time_elapsed             | 748          |
|    total_timesteps          | 583680       |
| train/                      |              |
|    approx_kl                | 652.1688     |
|    approx_ln(kl)            | 6.4803033    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.32         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2840         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0467       |
|    value_loss               | 1.79         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.0617888] |
| time/                       |              |
|    fps                      | 110          |
|    iterations               | 41           |
|    time_elapsed             | 762          |
|    total_timesteps          | 585728       |
| train/                      |              |
|    approx_kl                | 632.56006    |
|    approx_ln(kl)            | 6.449775     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.31         |
|    explained_variance       | 0.99         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2850         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.047        |
|    value_loss               | 6.26         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.4563603] |
| time/                       |              |
|    fps                      | 110          |
|    iterations               | 42           |
|    time_elapsed             | 776          |
|    total_timesteps          | 587776       |
| train/                      |              |
|    approx_kl                | 764.81445    |
|    approx_ln(kl)            | 6.639633     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.33         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2860         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0463       |
|    value_loss               | 1.77         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.5464704] |
| time/                       |              |
|    fps                      | 111          |
|    iterations               | 43           |
|    time_elapsed             | 789          |
|    total_timesteps          | 589824       |
| train/                      |              |
|    approx_kl                | 173.49078    |
|    approx_ln(kl)            | 5.1561246    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.32         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2870         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0466       |
|    value_loss               | 2.47         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.3695521] |
| time/                       |              |
|    fps                      | 112          |
|    iterations               | 44           |
|    time_elapsed             | 803          |
|    total_timesteps          | 591872       |
| train/                      |              |
|    approx_kl                | 768.9852     |
|    approx_ln(kl)            | 6.645072     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.3          |
|    explained_variance       | 0.965        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2880         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0473       |
|    value_loss               | 6.39         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.4380317] |
| time/                       |              |
|    fps                      | 112          |
|    iterations               | 45           |
|    time_elapsed             | 817          |
|    total_timesteps          | 593920       |
| train/                      |              |
|    approx_kl                | 497.9809     |
|    approx_ln(kl)            | 6.2105618    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.3          |
|    explained_variance       | 0.953        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2890         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0474       |
|    value_loss               | 15.7         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.9501266] |
| time/                       |              |
|    fps                      | 113          |
|    iterations               | 46           |
|    time_elapsed             | 830          |
|    total_timesteps          | 595968       |
| train/                      |              |
|    approx_kl                | 881.228      |
|    approx_ln(kl)            | 6.7813163    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.33         |
|    explained_variance       | 0.982        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2900         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0466       |
|    value_loss               | 2.51         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.50070417] |
| time/                       |               |
|    fps                      | 114           |
|    iterations               | 47            |
|    time_elapsed             | 844           |
|    total_timesteps          | 598016        |
| train/                      |               |
|    approx_kl                | 290.89188     |
|    approx_ln(kl)            | 5.6729517     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.34          |
|    explained_variance       | 0.98          |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 2910          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0465        |
|    value_loss               | 2.75          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-1.299321] |
| time/                       |             |
|    fps                      | 114         |
|    iterations               | 48          |
|    time_elapsed             | 857         |
|    total_timesteps          | 600064      |
| train/                      |             |
|    approx_kl                | 252.44174   |
|    approx_ln(kl)            | 5.5311804   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.35        |
|    explained_variance       | 0.995       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 2920        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0463      |
|    value_loss               | 2.66        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.9053811] |
| time/                       |              |
|    fps                      | 115          |
|    iterations               | 49           |
|    time_elapsed             | 871          |
|    total_timesteps          | 602112       |
| train/                      |              |
|    approx_kl                | 133.09431    |
|    approx_ln(kl)            | 4.891058     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.34         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2930         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0465       |
|    value_loss               | 2.15         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
------------------------------------
| reward             | [-2.543135] |
| time/              |             |
|    fps             | 160         |
|    iterations      | 1           |
|    time_elapsed    | 12          |
|    total_timesteps | 604160      |
------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.622371] |
| time/                       |             |
|    fps                      | 152         |
|    iterations               | 2           |
|    time_elapsed             | 26          |
|    total_timesteps          | 606208      |
| train/                      |             |
|    approx_kl                | 489.25113   |
|    approx_ln(kl)            | 6.192876    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.31        |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 2950        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0479      |
|    value_loss               | 1.12        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.9106896] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 3            |
|    time_elapsed             | 41           |
|    total_timesteps          | 608256       |
| train/                      |              |
|    approx_kl                | 686.424      |
|    approx_ln(kl)            | 6.5314956    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.3          |
|    explained_variance       | 0.971        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2960         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0478       |
|    value_loss               | 4.22         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.0321596] |
| time/                       |              |
|    fps                      | 56           |
|    iterations               | 4            |
|    time_elapsed             | 144          |
|    total_timesteps          | 610304       |
| train/                      |              |
|    approx_kl                | 390.90228    |
|    approx_ln(kl)            | 5.9684577    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.31         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2970         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0476       |
|    value_loss               | 1.33         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.4392154] |
| time/                       |              |
|    fps                      | 64           |
|    iterations               | 5            |
|    time_elapsed             | 157          |
|    total_timesteps          | 612352       |
| train/                      |              |
|    approx_kl                | 983.397      |
|    approx_ln(kl)            | 6.8910127    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.3          |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2980         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0479       |
|    value_loss               | 0.886        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.6175113] |
| time/                       |              |
|    fps                      | 71           |
|    iterations               | 6            |
|    time_elapsed             | 171          |
|    total_timesteps          | 614400       |
| train/                      |              |
|    approx_kl                | 1371.6993    |
|    approx_ln(kl)            | 7.2238054    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.3          |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 2990         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0478       |
|    value_loss               | 1.39         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.4812305] |
| time/                       |              |
|    fps                      | 77           |
|    iterations               | 7            |
|    time_elapsed             | 185          |
|    total_timesteps          | 616448       |
| train/                      |              |
|    approx_kl                | 756.0271     |
|    approx_ln(kl)            | 6.628077     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.32         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3000         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0475       |
|    value_loss               | 2.12         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.0557594] |
| time/                       |              |
|    fps                      | 82           |
|    iterations               | 8            |
|    time_elapsed             | 198          |
|    total_timesteps          | 618496       |
| train/                      |              |
|    approx_kl                | 956.6289     |
|    approx_ln(kl)            | 6.8634157    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.36         |
|    explained_variance       | 0.99         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3010         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0462       |
|    value_loss               | 2.4          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.70646244] |
| time/                       |               |
|    fps                      | 86            |
|    iterations               | 9             |
|    time_elapsed             | 212           |
|    total_timesteps          | 620544        |
| train/                      |               |
|    approx_kl                | 1080.2329     |
|    approx_ln(kl)            | 6.984932      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.38          |
|    explained_variance       | 0.997         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 3020          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.046         |
|    value_loss               | 1.14          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.6443229] |
| time/                       |              |
|    fps                      | 90           |
|    iterations               | 10           |
|    time_elapsed             | 226          |
|    total_timesteps          | 622592       |
| train/                      |              |
|    approx_kl                | 449.70624    |
|    approx_ln(kl)            | 6.1085944    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.39         |
|    explained_variance       | 0.975        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3030         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0458       |
|    value_loss               | 3.74         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.8353131] |
| time/                       |              |
|    fps                      | 93           |
|    iterations               | 11           |
|    time_elapsed             | 239          |
|    total_timesteps          | 624640       |
| train/                      |              |
|    approx_kl                | 1590.4836    |
|    approx_ln(kl)            | 7.3717933    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.39         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3040         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0458       |
|    value_loss               | 1.14         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.3701227] |
| time/                       |              |
|    fps                      | 97           |
|    iterations               | 12           |
|    time_elapsed             | 253          |
|    total_timesteps          | 626688       |
| train/                      |              |
|    approx_kl                | 1003.03467   |
|    approx_ln(kl)            | 6.910785     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.39         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3050         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0461       |
|    value_loss               | 1.22         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.775902] |
| time/                       |             |
|    fps                      | 99          |
|    iterations               | 13          |
|    time_elapsed             | 266         |
|    total_timesteps          | 628736      |
| train/                      |             |
|    approx_kl                | 1356.2452   |
|    approx_ln(kl)            | 7.2124753   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.39        |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 3060        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.046       |
|    value_loss               | 1.08        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.9839025] |
| time/                       |              |
|    fps                      | 102          |
|    iterations               | 14           |
|    time_elapsed             | 280          |
|    total_timesteps          | 630784       |
| train/                      |              |
|    approx_kl                | 746.1816     |
|    approx_ln(kl)            | 6.614969     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.42         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3070         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0455       |
|    value_loss               | 0.842        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.2578855] |
| time/                       |              |
|    fps                      | 104          |
|    iterations               | 15           |
|    time_elapsed             | 294          |
|    total_timesteps          | 632832       |
| train/                      |              |
|    approx_kl                | 1211.1028    |
|    approx_ln(kl)            | 7.0992866    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.41         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3080         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0459       |
|    value_loss               | 0.593        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.5065968] |
| time/                       |              |
|    fps                      | 106          |
|    iterations               | 16           |
|    time_elapsed             | 307          |
|    total_timesteps          | 634880       |
| train/                      |              |
|    approx_kl                | 433.09863    |
|    approx_ln(kl)            | 6.0709653    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.43         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3090         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0452       |
|    value_loss               | 2.44         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.6387646] |
| time/                       |              |
|    fps                      | 108          |
|    iterations               | 17           |
|    time_elapsed             | 321          |
|    total_timesteps          | 636928       |
| train/                      |              |
|    approx_kl                | 587.5979     |
|    approx_ln(kl)            | 6.376043     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.43         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3100         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0451       |
|    value_loss               | 1.33         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.133069] |
| time/                       |             |
|    fps                      | 109         |
|    iterations               | 18          |
|    time_elapsed             | 335         |
|    total_timesteps          | 638976      |
| train/                      |             |
|    approx_kl                | 1916.8401   |
|    approx_ln(kl)            | 7.5584335   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.44        |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 3110        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0451      |
|    value_loss               | 0.855       |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6238713] |
| time/                       |              |
|    fps                      | 111          |
|    iterations               | 19           |
|    time_elapsed             | 349          |
|    total_timesteps          | 641024       |
| train/                      |              |
|    approx_kl                | 1161.3796    |
|    approx_ln(kl)            | 7.057364     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.45         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3120         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0448       |
|    value_loss               | 1.65         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.1667591] |
| time/                       |              |
|    fps                      | 112          |
|    iterations               | 20           |
|    time_elapsed             | 363          |
|    total_timesteps          | 643072       |
| train/                      |              |
|    approx_kl                | 1400.7034    |
|    approx_ln(kl)            | 7.24473      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.47         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3130         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0444       |
|    value_loss               | 0.977        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.8342649] |
| time/                       |              |
|    fps                      | 114          |
|    iterations               | 21           |
|    time_elapsed             | 376          |
|    total_timesteps          | 645120       |
| train/                      |              |
|    approx_kl                | 2056.301     |
|    approx_ln(kl)            | 7.628664     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.5          |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3140         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0436       |
|    value_loss               | 1.07         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.2216697] |
| time/                       |              |
|    fps                      | 115          |
|    iterations               | 22           |
|    time_elapsed             | 390          |
|    total_timesteps          | 647168       |
| train/                      |              |
|    approx_kl                | 602.45166    |
|    approx_ln(kl)            | 6.4010077    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.5          |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3150         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0436       |
|    value_loss               | 1.18         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.5871096] |
| time/                       |              |
|    fps                      | 116          |
|    iterations               | 23           |
|    time_elapsed             | 404          |
|    total_timesteps          | 649216       |
| train/                      |              |
|    approx_kl                | 440.23993    |
|    approx_ln(kl)            | 6.08732      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.47         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3160         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0446       |
|    value_loss               | 0.847        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.1706822] |
| time/                       |              |
|    fps                      | 117          |
|    iterations               | 24           |
|    time_elapsed             | 417          |
|    total_timesteps          | 651264       |
| train/                      |              |
|    approx_kl                | 8203.6455    |
|    approx_ln(kl)            | 9.012334     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.5          |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3170         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0439       |
|    value_loss               | 1.21         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.5398805] |
| time/                       |              |
|    fps                      | 118          |
|    iterations               | 25           |
|    time_elapsed             | 431          |
|    total_timesteps          | 653312       |
| train/                      |              |
|    approx_kl                | 1626.9939    |
|    approx_ln(kl)            | 7.3944893    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.54         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3180         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0431       |
|    value_loss               | 1.61         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.958228] |
| time/                       |             |
|    fps                      | 119         |
|    iterations               | 26          |
|    time_elapsed             | 445         |
|    total_timesteps          | 655360      |
| train/                      |             |
|    approx_kl                | 1691.3691   |
|    approx_ln(kl)            | 7.433294    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.54        |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 3190        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0436      |
|    value_loss               | 2.15        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.0572653] |
| time/                       |              |
|    fps                      | 120          |
|    iterations               | 27           |
|    time_elapsed             | 458          |
|    total_timesteps          | 657408       |
| train/                      |              |
|    approx_kl                | 1580.3282    |
|    approx_ln(kl)            | 7.365388     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.57         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3200         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0426       |
|    value_loss               | 2.71         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.7025995] |
| time/                       |              |
|    fps                      | 121          |
|    iterations               | 28           |
|    time_elapsed             | 472          |
|    total_timesteps          | 659456       |
| train/                      |              |
|    approx_kl                | 4529.308     |
|    approx_ln(kl)            | 8.418324     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.59         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3210         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0424       |
|    value_loss               | 2.31         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.3886203] |
| time/                       |              |
|    fps                      | 122          |
|    iterations               | 29           |
|    time_elapsed             | 486          |
|    total_timesteps          | 661504       |
| train/                      |              |
|    approx_kl                | 847.64       |
|    approx_ln(kl)            | 6.742456     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.59         |
|    explained_variance       | 0.992        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3220         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0424       |
|    value_loss               | 5.55         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.2577305] |
| time/                       |              |
|    fps                      | 122          |
|    iterations               | 30           |
|    time_elapsed             | 499          |
|    total_timesteps          | 663552       |
| train/                      |              |
|    approx_kl                | 825.94147    |
|    approx_ln(kl)            | 6.716524     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.6          |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3230         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0423       |
|    value_loss               | 5.32         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.8282541] |
| time/                       |              |
|    fps                      | 123          |
|    iterations               | 31           |
|    time_elapsed             | 513          |
|    total_timesteps          | 665600       |
| train/                      |              |
|    approx_kl                | 1124.89      |
|    approx_ln(kl)            | 7.0254407    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.57         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3240         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0429       |
|    value_loss               | 4.1          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.4448726] |
| time/                       |              |
|    fps                      | 124          |
|    iterations               | 32           |
|    time_elapsed             | 527          |
|    total_timesteps          | 667648       |
| train/                      |              |
|    approx_kl                | 963.9064     |
|    approx_ln(kl)            | 6.870994     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.55         |
|    explained_variance       | 0.987        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3250         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0432       |
|    value_loss               | 6.53         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.155645] |
| time/                       |             |
|    fps                      | 125         |
|    iterations               | 33          |
|    time_elapsed             | 540         |
|    total_timesteps          | 669696      |
| train/                      |             |
|    approx_kl                | 902.29224   |
|    approx_ln(kl)            | 6.8049383   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.55        |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 3260        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0431      |
|    value_loss               | 2.67        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.6230407] |
| time/                       |              |
|    fps                      | 125          |
|    iterations               | 34           |
|    time_elapsed             | 554          |
|    total_timesteps          | 671744       |
| train/                      |              |
|    approx_kl                | 4875.327     |
|    approx_ln(kl)            | 8.491942     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.55         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3270         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0431       |
|    value_loss               | 2.39         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.002834] |
| time/                       |             |
|    fps                      | 126         |
|    iterations               | 35          |
|    time_elapsed             | 567         |
|    total_timesteps          | 673792      |
| train/                      |             |
|    approx_kl                | 419.48102   |
|    approx_ln(kl)            | 6.039018    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.55        |
|    explained_variance       | 0.987       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 3280        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.043       |
|    value_loss               | 20.6        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.278176] |
| time/                       |             |
|    fps                      | 126         |
|    iterations               | 36          |
|    time_elapsed             | 581         |
|    total_timesteps          | 675840      |
| train/                      |             |
|    approx_kl                | 575.91394   |
|    approx_ln(kl)            | 6.3559585   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.56        |
|    explained_variance       | 0.996       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 3290        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0429      |
|    value_loss               | 3.5         |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.3742847] |
| time/                       |              |
|    fps                      | 127          |
|    iterations               | 37           |
|    time_elapsed             | 595          |
|    total_timesteps          | 677888       |
| train/                      |              |
|    approx_kl                | 1520.0559    |
|    approx_ln(kl)            | 7.3265023    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.54         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3300         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0432       |
|    value_loss               | 1.55         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.526825] |
| time/                       |             |
|    fps                      | 127         |
|    iterations               | 38          |
|    time_elapsed             | 609         |
|    total_timesteps          | 679936      |
| train/                      |             |
|    approx_kl                | 2679.0654   |
|    approx_ln(kl)            | 7.8932233   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.55        |
|    explained_variance       | 0.996       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 3310        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0431      |
|    value_loss               | 2.48        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-5.042803] |
| time/                       |             |
|    fps                      | 128         |
|    iterations               | 39          |
|    time_elapsed             | 622         |
|    total_timesteps          | 681984      |
| train/                      |             |
|    approx_kl                | 1769.1995   |
|    approx_ln(kl)            | 7.4782825   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.53        |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 3320        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0436      |
|    value_loss               | 1.08        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.8751339] |
| time/                       |              |
|    fps                      | 128          |
|    iterations               | 40           |
|    time_elapsed             | 636          |
|    total_timesteps          | 684032       |
| train/                      |              |
|    approx_kl                | 632.6133     |
|    approx_ln(kl)            | 6.449859     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.53         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3330         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0435       |
|    value_loss               | 3.26         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.6249894] |
| time/                       |              |
|    fps                      | 129          |
|    iterations               | 41           |
|    time_elapsed             | 649          |
|    total_timesteps          | 686080       |
| train/                      |              |
|    approx_kl                | 800.3636     |
|    approx_ln(kl)            | 6.685066     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.52         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3340         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0436       |
|    value_loss               | 7.26         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.2441216] |
| time/                       |              |
|    fps                      | 129          |
|    iterations               | 42           |
|    time_elapsed             | 663          |
|    total_timesteps          | 688128       |
| train/                      |              |
|    approx_kl                | 1615.8572    |
|    approx_ln(kl)            | 7.387621     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.57         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3350         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0424       |
|    value_loss               | 5.73         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.5230901] |
| time/                       |              |
|    fps                      | 130          |
|    iterations               | 43           |
|    time_elapsed             | 677          |
|    total_timesteps          | 690176       |
| train/                      |              |
|    approx_kl                | 4088.83      |
|    approx_ln(kl)            | 8.316014     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.58         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3360         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0424       |
|    value_loss               | 1.65         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.7540276] |
| time/                       |              |
|    fps                      | 130          |
|    iterations               | 44           |
|    time_elapsed             | 690          |
|    total_timesteps          | 692224       |
| train/                      |              |
|    approx_kl                | 666.1355     |
|    approx_ln(kl)            | 6.501493     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.57         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3370         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0424       |
|    value_loss               | 3.91         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.3381355] |
| time/                       |              |
|    fps                      | 130          |
|    iterations               | 45           |
|    time_elapsed             | 704          |
|    total_timesteps          | 694272       |
| train/                      |              |
|    approx_kl                | 8666.98      |
|    approx_ln(kl)            | 9.067276     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.58         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3380         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0413       |
|    value_loss               | 0.713        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.4579039] |
| time/                       |              |
|    fps                      | 131          |
|    iterations               | 46           |
|    time_elapsed             | 718          |
|    total_timesteps          | 696320       |
| train/                      |              |
|    approx_kl                | 2081.8901    |
|    approx_ln(kl)            | 7.6410313    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.62         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3390         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0413       |
|    value_loss               | 2.78         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.0145235] |
| time/                       |              |
|    fps                      | 131          |
|    iterations               | 47           |
|    time_elapsed             | 731          |
|    total_timesteps          | 698368       |
| train/                      |              |
|    approx_kl                | 1433.9011    |
|    approx_ln(kl)            | 7.268154     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.61         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3400         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0414       |
|    value_loss               | 1.75         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.4260736] |
| time/                       |              |
|    fps                      | 131          |
|    iterations               | 48           |
|    time_elapsed             | 745          |
|    total_timesteps          | 700416       |
| train/                      |              |
|    approx_kl                | 2722.4333    |
|    approx_ln(kl)            | 7.9092813    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.62         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3410         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0411       |
|    value_loss               | 0.94         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.6427693] |
| time/                       |              |
|    fps                      | 132          |
|    iterations               | 49           |
|    time_elapsed             | 759          |
|    total_timesteps          | 702464       |
| train/                      |              |
|    approx_kl                | 437.9883     |
|    approx_ln(kl)            | 6.0821924    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.56         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3420         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0424       |
|    value_loss               | 1.04         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-------------------------------------
| reward             | [-0.5762566] |
| time/              |              |
|    fps             | 160          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 704512       |
-------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-1.221977] |
| time/                       |             |
|    fps                      | 155         |
|    iterations               | 2           |
|    time_elapsed             | 26          |
|    total_timesteps          | 706560      |
| train/                      |             |
|    approx_kl                | 1946.8358   |
|    approx_ln(kl)            | 7.573961    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.56        |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 3440        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0421      |
|    value_loss               | 1.1         |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
--------------------------------------------
| reward                      | [-1.69952] |
| time/                       |            |
|    fps                      | 153        |
|    iterations               | 3          |
|    time_elapsed             | 39         |
|    total_timesteps          | 708608     |
| train/                      |            |
|    approx_kl                | 2188.704   |
|    approx_ln(kl)            | 7.691065   |
|    clip_range               | 0.2        |
|    entropy_loss             | 3.55       |
|    explained_variance       | 1          |
|    learning_rate            | 0.001      |
|    ln(loss)                 | inf        |
|    ln(policy_gradient_loss) | nan        |
|    loss                     | inf        |
|    n_updates                | 3450       |
|    policy_gradient_loss     | nan        |
|    std                      | 0.0428     |
|    value_loss               | 0.839      |
--------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.1000662] |
| time/                       |              |
|    fps                      | 153          |
|    iterations               | 4            |
|    time_elapsed             | 53           |
|    total_timesteps          | 710656       |
| train/                      |              |
|    approx_kl                | 897.40027    |
|    approx_ln(kl)            | 6.799502     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.55         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3460         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0428       |
|    value_loss               | 0.844        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.4508727] |
| time/                       |              |
|    fps                      | 152          |
|    iterations               | 5            |
|    time_elapsed             | 67           |
|    total_timesteps          | 712704       |
| train/                      |              |
|    approx_kl                | 2250.9668    |
|    approx_ln(kl)            | 7.7191153    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.56         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3470         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0427       |
|    value_loss               | 1            |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.0277052] |
| time/                       |              |
|    fps                      | 152          |
|    iterations               | 6            |
|    time_elapsed             | 80           |
|    total_timesteps          | 714752       |
| train/                      |              |
|    approx_kl                | 11383.886    |
|    approx_ln(kl)            | 9.339954     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.57         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3480         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0425       |
|    value_loss               | 0.658        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.7874932] |
| time/                       |              |
|    fps                      | 152          |
|    iterations               | 7            |
|    time_elapsed             | 94           |
|    total_timesteps          | 716800       |
| train/                      |              |
|    approx_kl                | 881.6817     |
|    approx_ln(kl)            | 6.7818313    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.57         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3490         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0423       |
|    value_loss               | 1.98         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.9133954] |
| time/                       |              |
|    fps                      | 151          |
|    iterations               | 8            |
|    time_elapsed             | 107          |
|    total_timesteps          | 718848       |
| train/                      |              |
|    approx_kl                | 1794.6001    |
|    approx_ln(kl)            | 7.4925375    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.55         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3500         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0427       |
|    value_loss               | 2.99         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.234099] |
| time/                       |             |
|    fps                      | 151         |
|    iterations               | 9           |
|    time_elapsed             | 121         |
|    total_timesteps          | 720896      |
| train/                      |             |
|    approx_kl                | 1808.8416   |
|    approx_ln(kl)            | 7.500442    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.56        |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 3510        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0425      |
|    value_loss               | 3.26        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.1086993] |
| time/                       |              |
|    fps                      | 151          |
|    iterations               | 10           |
|    time_elapsed             | 135          |
|    total_timesteps          | 722944       |
| train/                      |              |
|    approx_kl                | 4026.3557    |
|    approx_ln(kl)            | 8.300617     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.58         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3520         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.042        |
|    value_loss               | 2.32         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.416969] |
| time/                       |             |
|    fps                      | 151         |
|    iterations               | 11          |
|    time_elapsed             | 148         |
|    total_timesteps          | 724992      |
| train/                      |             |
|    approx_kl                | 1480.2688   |
|    approx_ln(kl)            | 7.299979    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.57        |
|    explained_variance       | 0.995       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 3530        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0425      |
|    value_loss               | 2.11        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7245658] |
| time/                       |              |
|    fps                      | 150          |
|    iterations               | 12           |
|    time_elapsed             | 162          |
|    total_timesteps          | 727040       |
| train/                      |              |
|    approx_kl                | 2851.9072    |
|    approx_ln(kl)            | 7.9557433    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.56         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3540         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0425       |
|    value_loss               | 1.06         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.7812483] |
| time/                       |              |
|    fps                      | 150          |
|    iterations               | 13           |
|    time_elapsed             | 176          |
|    total_timesteps          | 729088       |
| train/                      |              |
|    approx_kl                | 1971.7052    |
|    approx_ln(kl)            | 7.586654     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.57         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3550         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0425       |
|    value_loss               | 0.679        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.3391242] |
| time/                       |              |
|    fps                      | 150          |
|    iterations               | 14           |
|    time_elapsed             | 190          |
|    total_timesteps          | 731136       |
| train/                      |              |
|    approx_kl                | 1798.1736    |
|    approx_ln(kl)            | 7.494527     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.64         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3560         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0412       |
|    value_loss               | 1.07         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.6866732] |
| time/                       |              |
|    fps                      | 150          |
|    iterations               | 15           |
|    time_elapsed             | 204          |
|    total_timesteps          | 733184       |
| train/                      |              |
|    approx_kl                | 5596.382     |
|    approx_ln(kl)            | 8.629875     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.64         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3570         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0412       |
|    value_loss               | 1.25         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.8705025] |
| time/                       |              |
|    fps                      | 150          |
|    iterations               | 16           |
|    time_elapsed             | 217          |
|    total_timesteps          | 735232       |
| train/                      |              |
|    approx_kl                | 569.5608     |
|    approx_ln(kl)            | 6.3448653    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.63         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3580         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0413       |
|    value_loss               | 1.13         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.3246274] |
| time/                       |              |
|    fps                      | 150          |
|    iterations               | 17           |
|    time_elapsed             | 231          |
|    total_timesteps          | 737280       |
| train/                      |              |
|    approx_kl                | 1517.5774    |
|    approx_ln(kl)            | 7.3248706    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.62         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3590         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0416       |
|    value_loss               | 0.947        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.2490375] |
| time/                       |              |
|    fps                      | 150          |
|    iterations               | 18           |
|    time_elapsed             | 245          |
|    total_timesteps          | 739328       |
| train/                      |              |
|    approx_kl                | 1927.8751    |
|    approx_ln(kl)            | 7.5641737    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.62         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3600         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.041        |
|    value_loss               | 0.688        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.0640628] |
| time/                       |              |
|    fps                      | 150          |
|    iterations               | 19           |
|    time_elapsed             | 259          |
|    total_timesteps          | 741376       |
| train/                      |              |
|    approx_kl                | 1640.935     |
|    approx_ln(kl)            | 7.4030213    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.65         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3610         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0406       |
|    value_loss               | 1.1          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.7380686] |
| time/                       |              |
|    fps                      | 150          |
|    iterations               | 20           |
|    time_elapsed             | 272          |
|    total_timesteps          | 743424       |
| train/                      |              |
|    approx_kl                | 4083.2554    |
|    approx_ln(kl)            | 8.31465      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.68         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3620         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0399       |
|    value_loss               | 2.69         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.8949306] |
| time/                       |              |
|    fps                      | 150          |
|    iterations               | 21           |
|    time_elapsed             | 286          |
|    total_timesteps          | 745472       |
| train/                      |              |
|    approx_kl                | 1474.8942    |
|    approx_ln(kl)            | 7.2963414    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.67         |
|    explained_variance       | 0.966        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3630         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0403       |
|    value_loss               | 14.4         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.46215358] |
| time/                       |               |
|    fps                      | 150           |
|    iterations               | 22            |
|    time_elapsed             | 300           |
|    total_timesteps          | 747520        |
| train/                      |               |
|    approx_kl                | 454.95593     |
|    approx_ln(kl)            | 6.1202006     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.66          |
|    explained_variance       | 0.939         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 3640          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0403        |
|    value_loss               | 8.8           |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.4677058] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 23           |
|    time_elapsed             | 314          |
|    total_timesteps          | 749568       |
| train/                      |              |
|    approx_kl                | 5887.2505    |
|    approx_ln(kl)            | 8.680544     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.67         |
|    explained_variance       | 0.992        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3650         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0402       |
|    value_loss               | 4.08         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.2604687] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 24           |
|    time_elapsed             | 328          |
|    total_timesteps          | 751616       |
| train/                      |              |
|    approx_kl                | 1322.5608    |
|    approx_ln(kl)            | 7.187325     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.66         |
|    explained_variance       | 0.992        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3660         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0404       |
|    value_loss               | 3.45         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.7770844] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 25           |
|    time_elapsed             | 342          |
|    total_timesteps          | 753664       |
| train/                      |              |
|    approx_kl                | 2127.8938    |
|    approx_ln(kl)            | 7.662888     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.69         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3670         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0397       |
|    value_loss               | 2.32         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.2091253] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 26           |
|    time_elapsed             | 355          |
|    total_timesteps          | 755712       |
| train/                      |              |
|    approx_kl                | 4287.7383    |
|    approx_ln(kl)            | 8.363515     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.68         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3680         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0402       |
|    value_loss               | 2.52         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.6889713] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 27           |
|    time_elapsed             | 369          |
|    total_timesteps          | 757760       |
| train/                      |              |
|    approx_kl                | 456.61795    |
|    approx_ln(kl)            | 6.123847     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.67         |
|    explained_variance       | 0.964        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3690         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.04         |
|    value_loss               | 186          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.9958186] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 28           |
|    time_elapsed             | 382          |
|    total_timesteps          | 759808       |
| train/                      |              |
|    approx_kl                | 3089.7844    |
|    approx_ln(kl)            | 8.035856     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.65         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3700         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0404       |
|    value_loss               | 2.89         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.2920775] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 29           |
|    time_elapsed             | 396          |
|    total_timesteps          | 761856       |
| train/                      |              |
|    approx_kl                | 1142.3385    |
|    approx_ln(kl)            | 7.040833     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.63         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3710         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0407       |
|    value_loss               | 3.1          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.598828] |
| time/                       |             |
|    fps                      | 149         |
|    iterations               | 30          |
|    time_elapsed             | 410         |
|    total_timesteps          | 763904      |
| train/                      |             |
|    approx_kl                | 734.99963   |
|    approx_ln(kl)            | 6.59987     |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.59        |
|    explained_variance       | 1           |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 3720        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0418      |
|    value_loss               | 0.899       |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.930652] |
| time/                       |             |
|    fps                      | 149         |
|    iterations               | 31          |
|    time_elapsed             | 423         |
|    total_timesteps          | 765952      |
| train/                      |             |
|    approx_kl                | 1526.0511   |
|    approx_ln(kl)            | 7.3304386   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.57        |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 3730        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0417      |
|    value_loss               | 1.07        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-466.42548] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 32           |
|    time_elapsed             | 437          |
|    total_timesteps          | 768000       |
| train/                      |              |
|    approx_kl                | 1729.8936    |
|    approx_ln(kl)            | 7.4558153    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.58         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3740         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0417       |
|    value_loss               | 0.602        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7371931] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 33           |
|    time_elapsed             | 451          |
|    total_timesteps          | 770048       |
| train/                      |              |
|    approx_kl                | 1308.8657    |
|    approx_ln(kl)            | 7.176916     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.56         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3750         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0423       |
|    value_loss               | 1.69         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.2501204] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 34           |
|    time_elapsed             | 464          |
|    total_timesteps          | 772096       |
| train/                      |              |
|    approx_kl                | 3176.236     |
|    approx_ln(kl)            | 8.063452     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.56         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3760         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0422       |
|    value_loss               | 6.48         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-1.055065] |
| time/                       |             |
|    fps                      | 149         |
|    iterations               | 35          |
|    time_elapsed             | 478         |
|    total_timesteps          | 774144      |
| train/                      |             |
|    approx_kl                | 2714.671    |
|    approx_ln(kl)            | 7.906426    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.55        |
|    explained_variance       | 0.995       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 3770        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0424      |
|    value_loss               | 3.05        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.1589084] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 36           |
|    time_elapsed             | 491          |
|    total_timesteps          | 776192       |
| train/                      |              |
|    approx_kl                | 515.64124    |
|    approx_ln(kl)            | 6.2454114    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.55         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3780         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0424       |
|    value_loss               | 3.47         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0741677] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 37           |
|    time_elapsed             | 505          |
|    total_timesteps          | 778240       |
| train/                      |              |
|    approx_kl                | 2845.996     |
|    approx_ln(kl)            | 7.9536686    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.54         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3790         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0428       |
|    value_loss               | 5.11         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.2328461] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 38           |
|    time_elapsed             | 518          |
|    total_timesteps          | 780288       |
| train/                      |              |
|    approx_kl                | 5194.1987    |
|    approx_ln(kl)            | 8.555298     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.55         |
|    explained_variance       | 0.986        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3800         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0427       |
|    value_loss               | 4.73         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.3803983] |
| time/                       |              |
|    fps                      | 150          |
|    iterations               | 39           |
|    time_elapsed             | 532          |
|    total_timesteps          | 782336       |
| train/                      |              |
|    approx_kl                | 1185.6895    |
|    approx_ln(kl)            | 7.0780797    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.55         |
|    explained_variance       | 0.968        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3810         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0425       |
|    value_loss               | 4.41         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.4098287] |
| time/                       |              |
|    fps                      | 150          |
|    iterations               | 40           |
|    time_elapsed             | 545          |
|    total_timesteps          | 784384       |
| train/                      |              |
|    approx_kl                | 9593.819     |
|    approx_ln(kl)            | 9.168875     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.55         |
|    explained_variance       | 0.985        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3820         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0428       |
|    value_loss               | 2.92         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.6477523] |
| time/                       |              |
|    fps                      | 150          |
|    iterations               | 41           |
|    time_elapsed             | 559          |
|    total_timesteps          | 786432       |
| train/                      |              |
|    approx_kl                | 867.89874    |
|    approx_ln(kl)            | 6.766075     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.56         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3830         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0425       |
|    value_loss               | 1.08         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.5001801] |
| time/                       |              |
|    fps                      | 150          |
|    iterations               | 42           |
|    time_elapsed             | 573          |
|    total_timesteps          | 788480       |
| train/                      |              |
|    approx_kl                | 4725.9834    |
|    approx_ln(kl)            | 8.460831     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.59         |
|    explained_variance       | 0.992        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3840         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.042        |
|    value_loss               | 1.61         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.46099374] |
| time/                       |               |
|    fps                      | 149           |
|    iterations               | 43            |
|    time_elapsed             | 587           |
|    total_timesteps          | 790528        |
| train/                      |               |
|    approx_kl                | 4238.176      |
|    approx_ln(kl)            | 8.351889      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.61          |
|    explained_variance       | 0.975         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 3850          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0414        |
|    value_loss               | 3.66          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.68701744] |
| time/                       |               |
|    fps                      | 148           |
|    iterations               | 44            |
|    time_elapsed             | 606           |
|    total_timesteps          | 792576        |
| train/                      |               |
|    approx_kl                | 940.8782      |
|    approx_ln(kl)            | 6.8468137     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.63          |
|    explained_variance       | 0.942         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 3860          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.041         |
|    value_loss               | 13.4          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.8165406] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 45           |
|    time_elapsed             | 620          |
|    total_timesteps          | 794624       |
| train/                      |              |
|    approx_kl                | 1146.2052    |
|    approx_ln(kl)            | 7.044212     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.62         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3870         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0411       |
|    value_loss               | 1.22         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.4295317] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 46           |
|    time_elapsed             | 636          |
|    total_timesteps          | 796672       |
| train/                      |              |
|    approx_kl                | 5440.079     |
|    approx_ln(kl)            | 8.601549     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.62         |
|    explained_variance       | 0.992        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3880         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0412       |
|    value_loss               | 1.32         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.6944965] |
| time/                       |              |
|    fps                      | 142          |
|    iterations               | 47           |
|    time_elapsed             | 676          |
|    total_timesteps          | 798720       |
| train/                      |              |
|    approx_kl                | 1777.2842    |
|    approx_ln(kl)            | 7.482842     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.62         |
|    explained_variance       | 0.984        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3890         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0411       |
|    value_loss               | 3.79         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.49988553] |
| time/                       |               |
|    fps                      | 142           |
|    iterations               | 48            |
|    time_elapsed             | 691           |
|    total_timesteps          | 800768        |
| train/                      |               |
|    approx_kl                | 666.8747      |
|    approx_ln(kl)            | 6.502602      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.63          |
|    explained_variance       | 0.993         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 3900          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0409        |
|    value_loss               | 4.69          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-0.679716] |
| time/                       |             |
|    fps                      | 142         |
|    iterations               | 49          |
|    time_elapsed             | 706         |
|    total_timesteps          | 802816      |
| train/                      |             |
|    approx_kl                | 14192.976   |
|    approx_ln(kl)            | 9.560502    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.66        |
|    explained_variance       | 0.995       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 3910        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.04        |
|    value_loss               | 5.78        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-------------------------------------
| reward             | [-1.5949671] |
| time/              |              |
|    fps             | 152          |
|    iterations      | 1            |
|    time_elapsed    | 13           |
|    total_timesteps | 804864       |
-------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.7338002] |
| time/                       |              |
|    fps                      | 127          |
|    iterations               | 2            |
|    time_elapsed             | 32           |
|    total_timesteps          | 806912       |
| train/                      |              |
|    approx_kl                | 663.7809     |
|    approx_ln(kl)            | 6.497952     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.66         |
|    explained_variance       | 0.94         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3930         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.04         |
|    value_loss               | 53.6         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.1534383] |
| time/                       |              |
|    fps                      | 131          |
|    iterations               | 3            |
|    time_elapsed             | 46           |
|    total_timesteps          | 808960       |
| train/                      |              |
|    approx_kl                | 2426.3215    |
|    approx_ln(kl)            | 7.7941318    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.66         |
|    explained_variance       | 0.954        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3940         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0399       |
|    value_loss               | 59.8         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5368885] |
| time/                       |              |
|    fps                      | 113          |
|    iterations               | 4            |
|    time_elapsed             | 72           |
|    total_timesteps          | 811008       |
| train/                      |              |
|    approx_kl                | 2252.3076    |
|    approx_ln(kl)            | 7.719711     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.66         |
|    explained_variance       | 0.961        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3950         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0404       |
|    value_loss               | 38.9         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.54636943] |
| time/                       |               |
|    fps                      | 119           |
|    iterations               | 5             |
|    time_elapsed             | 85            |
|    total_timesteps          | 813056        |
| train/                      |               |
|    approx_kl                | 2534.6426     |
|    approx_ln(kl)            | 7.837808      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.66          |
|    explained_variance       | 0.989         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 3960          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0398        |
|    value_loss               | 12.7          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.95134616] |
| time/                       |               |
|    fps                      | 123           |
|    iterations               | 6             |
|    time_elapsed             | 99            |
|    total_timesteps          | 815104        |
| train/                      |               |
|    approx_kl                | 172.15193     |
|    approx_ln(kl)            | 5.1483774     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.67          |
|    explained_variance       | 0.989         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 3970          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0398        |
|    value_loss               | 10.8          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0487962] |
| time/                       |              |
|    fps                      | 126          |
|    iterations               | 7            |
|    time_elapsed             | 113          |
|    total_timesteps          | 817152       |
| train/                      |              |
|    approx_kl                | 1309.6195    |
|    approx_ln(kl)            | 7.177492     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.68         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3980         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0396       |
|    value_loss               | 3.43         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0966699] |
| time/                       |              |
|    fps                      | 128          |
|    iterations               | 8            |
|    time_elapsed             | 127          |
|    total_timesteps          | 819200       |
| train/                      |              |
|    approx_kl                | 4779.978     |
|    approx_ln(kl)            | 8.472191     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.68         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 3990         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0394       |
|    value_loss               | 5.55         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.5261189] |
| time/                       |              |
|    fps                      | 130          |
|    iterations               | 9            |
|    time_elapsed             | 141          |
|    total_timesteps          | 821248       |
| train/                      |              |
|    approx_kl                | 1545.4569    |
|    approx_ln(kl)            | 7.343075     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.72         |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4000         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0387       |
|    value_loss               | 5.01         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-1.532478] |
| time/                       |             |
|    fps                      | 132         |
|    iterations               | 10          |
|    time_elapsed             | 155         |
|    total_timesteps          | 823296      |
| train/                      |             |
|    approx_kl                | 3615.5027   |
|    approx_ln(kl)            | 8.1929865   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.69        |
|    explained_variance       | 0.991       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 4010        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0393      |
|    value_loss               | 3.48        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.8271133] |
| time/                       |              |
|    fps                      | 133          |
|    iterations               | 11           |
|    time_elapsed             | 168          |
|    total_timesteps          | 825344       |
| train/                      |              |
|    approx_kl                | 1488.5974    |
|    approx_ln(kl)            | 7.3055897    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.69         |
|    explained_variance       | 0.959        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4020         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0394       |
|    value_loss               | 10.2         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.4191885] |
| time/                       |              |
|    fps                      | 134          |
|    iterations               | 12           |
|    time_elapsed             | 182          |
|    total_timesteps          | 827392       |
| train/                      |              |
|    approx_kl                | 1549.4026    |
|    approx_ln(kl)            | 7.345625     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.69         |
|    explained_variance       | 0.927        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4030         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0391       |
|    value_loss               | 20.4         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.7098528] |
| time/                       |              |
|    fps                      | 135          |
|    iterations               | 13           |
|    time_elapsed             | 195          |
|    total_timesteps          | 829440       |
| train/                      |              |
|    approx_kl                | 2637.416     |
|    approx_ln(kl)            | 7.877555     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.69         |
|    explained_variance       | 0.852        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4040         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0395       |
|    value_loss               | 16           |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.2985722] |
| time/                       |              |
|    fps                      | 95           |
|    iterations               | 14           |
|    time_elapsed             | 299          |
|    total_timesteps          | 831488       |
| train/                      |              |
|    approx_kl                | 2287.0742    |
|    approx_ln(kl)            | 7.7350287    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.73         |
|    explained_variance       | 0.888        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4050         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0387       |
|    value_loss               | 15.3         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.69106257] |
| time/                       |               |
|    fps                      | 76            |
|    iterations               | 15            |
|    time_elapsed             | 403           |
|    total_timesteps          | 833536        |
| train/                      |               |
|    approx_kl                | 2299.5276     |
|    approx_ln(kl)            | 7.740459      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.71          |
|    explained_variance       | 0.703         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 4060          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0394        |
|    value_loss               | 6.32          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7375272] |
| time/                       |              |
|    fps                      | 64           |
|    iterations               | 16           |
|    time_elapsed             | 507          |
|    total_timesteps          | 835584       |
| train/                      |              |
|    approx_kl                | 983.0753     |
|    approx_ln(kl)            | 6.8906856    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.7          |
|    explained_variance       | 0.821        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4070         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0396       |
|    value_loss               | 12.6         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7347644] |
| time/                       |              |
|    fps                      | 56           |
|    iterations               | 17           |
|    time_elapsed             | 610          |
|    total_timesteps          | 837632       |
| train/                      |              |
|    approx_kl                | 1790.9475    |
|    approx_ln(kl)            | 7.4905       |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.65         |
|    explained_variance       | 0.938        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4080         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0402       |
|    value_loss               | 7.14         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7478619] |
| time/                       |              |
|    fps                      | 59           |
|    iterations               | 18           |
|    time_elapsed             | 624          |
|    total_timesteps          | 839680       |
| train/                      |              |
|    approx_kl                | 721.73175    |
|    approx_ln(kl)            | 6.5816536    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.66         |
|    explained_variance       | 0.961        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4090         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.04         |
|    value_loss               | 7.84         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.65747577] |
| time/                       |               |
|    fps                      | 60            |
|    iterations               | 19            |
|    time_elapsed             | 638           |
|    total_timesteps          | 841728        |
| train/                      |               |
|    approx_kl                | 671.66846     |
|    approx_ln(kl)            | 6.5097647     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.67          |
|    explained_variance       | 0.991         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 4100          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0399        |
|    value_loss               | 3.79          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0937175] |
| time/                       |              |
|    fps                      | 62           |
|    iterations               | 20           |
|    time_elapsed             | 652          |
|    total_timesteps          | 843776       |
| train/                      |              |
|    approx_kl                | 1445.6761    |
|    approx_ln(kl)            | 7.2763324    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.7          |
|    explained_variance       | 0.965        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4110         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0393       |
|    value_loss               | 4.78         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-1.135594] |
| time/                       |             |
|    fps                      | 64          |
|    iterations               | 21          |
|    time_elapsed             | 666         |
|    total_timesteps          | 845824      |
| train/                      |             |
|    approx_kl                | 1576.7036   |
|    approx_ln(kl)            | 7.3630915   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.69        |
|    explained_variance       | 0.985       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 4120        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0395      |
|    value_loss               | 1.68        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.4256282] |
| time/                       |              |
|    fps                      | 66           |
|    iterations               | 22           |
|    time_elapsed             | 680          |
|    total_timesteps          | 847872       |
| train/                      |              |
|    approx_kl                | 6192.5693    |
|    approx_ln(kl)            | 8.731106     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.7          |
|    explained_variance       | 0.963        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4130         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0393       |
|    value_loss               | 1.95         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.4046212] |
| time/                       |              |
|    fps                      | 67           |
|    iterations               | 23           |
|    time_elapsed             | 693          |
|    total_timesteps          | 849920       |
| train/                      |              |
|    approx_kl                | 688.0071     |
|    approx_ln(kl)            | 6.533799     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.7          |
|    explained_variance       | 0.979        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4140         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0397       |
|    value_loss               | 2.68         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.2829666] |
| time/                       |              |
|    fps                      | 69           |
|    iterations               | 24           |
|    time_elapsed             | 707          |
|    total_timesteps          | 851968       |
| train/                      |              |
|    approx_kl                | 1830.5677    |
|    approx_ln(kl)            | 7.5123816    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.69         |
|    explained_variance       | 0.989        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4150         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0395       |
|    value_loss               | 1.73         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.57828265] |
| time/                       |               |
|    fps                      | 70            |
|    iterations               | 25            |
|    time_elapsed             | 722           |
|    total_timesteps          | 854016        |
| train/                      |               |
|    approx_kl                | 1404.9838     |
|    approx_ln(kl)            | 7.247781      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.7           |
|    explained_variance       | 0.971         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 4160          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0388        |
|    value_loss               | 8.44          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.38702953] |
| time/                       |               |
|    fps                      | 72            |
|    iterations               | 26            |
|    time_elapsed             | 738           |
|    total_timesteps          | 856064        |
| train/                      |               |
|    approx_kl                | 475.90506     |
|    approx_ln(kl)            | 6.1652184     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.72          |
|    explained_variance       | 0.967         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 4170          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0387        |
|    value_loss               | 9.93          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.8464122] |
| time/                       |              |
|    fps                      | 73           |
|    iterations               | 27           |
|    time_elapsed             | 754          |
|    total_timesteps          | 858112       |
| train/                      |              |
|    approx_kl                | 1051.541     |
|    approx_ln(kl)            | 6.958012     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.7          |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4180         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0389       |
|    value_loss               | 2.26         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6585654] |
| time/                       |              |
|    fps                      | 74           |
|    iterations               | 28           |
|    time_elapsed             | 768          |
|    total_timesteps          | 860160       |
| train/                      |              |
|    approx_kl                | 1177.2273    |
|    approx_ln(kl)            | 7.070917     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.66         |
|    explained_variance       | 0.972        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4190         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0396       |
|    value_loss               | 7.66         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.5253855] |
| time/                       |              |
|    fps                      | 68           |
|    iterations               | 29           |
|    time_elapsed             | 871          |
|    total_timesteps          | 862208       |
| train/                      |              |
|    approx_kl                | 572.89233    |
|    approx_ln(kl)            | 6.350698     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.66         |
|    explained_variance       | 0.949        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4200         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0397       |
|    value_loss               | 8.1          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0576022] |
| time/                       |              |
|    fps                      | 69           |
|    iterations               | 30           |
|    time_elapsed             | 886          |
|    total_timesteps          | 864256       |
| train/                      |              |
|    approx_kl                | 1235.0298    |
|    approx_ln(kl)            | 7.11885      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.67         |
|    explained_variance       | 0.924        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4210         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0393       |
|    value_loss               | 17.3         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.9560307] |
| time/                       |              |
|    fps                      | 70           |
|    iterations               | 31           |
|    time_elapsed             | 901          |
|    total_timesteps          | 866304       |
| train/                      |              |
|    approx_kl                | 560.7649     |
|    approx_ln(kl)            | 6.329302     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.68         |
|    explained_variance       | 0.909        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4220         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0391       |
|    value_loss               | 21           |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.8860021] |
| time/                       |              |
|    fps                      | 71           |
|    iterations               | 32           |
|    time_elapsed             | 916          |
|    total_timesteps          | 868352       |
| train/                      |              |
|    approx_kl                | 590.0442     |
|    approx_ln(kl)            | 6.3801975    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.68         |
|    explained_variance       | 0.971        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4230         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0392       |
|    value_loss               | 5.39         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.2331824] |
| time/                       |              |
|    fps                      | 72           |
|    iterations               | 33           |
|    time_elapsed             | 930          |
|    total_timesteps          | 870400       |
| train/                      |              |
|    approx_kl                | 1205.457     |
|    approx_ln(kl)            | 7.094614     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.63         |
|    explained_variance       | 0.967        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4240         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0405       |
|    value_loss               | 7.51         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.3783414] |
| time/                       |              |
|    fps                      | 73           |
|    iterations               | 34           |
|    time_elapsed             | 945          |
|    total_timesteps          | 872448       |
| train/                      |              |
|    approx_kl                | 1449.3647    |
|    approx_ln(kl)            | 7.2788806    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.61         |
|    explained_variance       | 0.986        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4250         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0406       |
|    value_loss               | 2.53         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.2113278] |
| time/                       |              |
|    fps                      | 74           |
|    iterations               | 35           |
|    time_elapsed             | 959          |
|    total_timesteps          | 874496       |
| train/                      |              |
|    approx_kl                | 528.0049     |
|    approx_ln(kl)            | 6.2691054    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.6          |
|    explained_variance       | 0.983        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4260         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0408       |
|    value_loss               | 3.33         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7325893] |
| time/                       |              |
|    fps                      | 75           |
|    iterations               | 36           |
|    time_elapsed             | 974          |
|    total_timesteps          | 876544       |
| train/                      |              |
|    approx_kl                | 713.01624    |
|    approx_ln(kl)            | 6.5695043    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.6          |
|    explained_variance       | 0.951        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4270         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0408       |
|    value_loss               | 5.56         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.2279814] |
| time/                       |              |
|    fps                      | 76           |
|    iterations               | 37           |
|    time_elapsed             | 988          |
|    total_timesteps          | 878592       |
| train/                      |              |
|    approx_kl                | 410.10797    |
|    approx_ln(kl)            | 6.0164204    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.59         |
|    explained_variance       | 0.981        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4280         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.041        |
|    value_loss               | 2.51         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.73190004] |
| time/                       |               |
|    fps                      | 77            |
|    iterations               | 38            |
|    time_elapsed             | 1003          |
|    total_timesteps          | 880640        |
| train/                      |               |
|    approx_kl                | 425.21472     |
|    approx_ln(kl)            | 6.052594      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.61          |
|    explained_variance       | 0.964         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 4290          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0407        |
|    value_loss               | 5.89          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
--------------------------------------------
| reward                      | [-1.25228] |
| time/                       |            |
|    fps                      | 78         |
|    iterations               | 39         |
|    time_elapsed             | 1017       |
|    total_timesteps          | 882688     |
| train/                      |            |
|    approx_kl                | 1360.7979  |
|    approx_ln(kl)            | 7.2158265  |
|    clip_range               | 0.2        |
|    entropy_loss             | 3.6        |
|    explained_variance       | 0.979      |
|    learning_rate            | 0.001      |
|    ln(loss)                 | inf        |
|    ln(policy_gradient_loss) | nan        |
|    loss                     | inf        |
|    n_updates                | 4300       |
|    policy_gradient_loss     | nan        |
|    std                      | 0.0407     |
|    value_loss               | 4.26       |
--------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.2657002] |
| time/                       |              |
|    fps                      | 79           |
|    iterations               | 40           |
|    time_elapsed             | 1032         |
|    total_timesteps          | 884736       |
| train/                      |              |
|    approx_kl                | 599.6043     |
|    approx_ln(kl)            | 6.39627      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.59         |
|    explained_variance       | 0.667        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4310         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0409       |
|    value_loss               | 18.4         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.1660067] |
| time/                       |              |
|    fps                      | 80           |
|    iterations               | 41           |
|    time_elapsed             | 1046         |
|    total_timesteps          | 886784       |
| train/                      |              |
|    approx_kl                | 1012.1637    |
|    approx_ln(kl)            | 6.9198456    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.6          |
|    explained_variance       | 0.691        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4320         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0405       |
|    value_loss               | 12.9         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-1.469906] |
| time/                       |             |
|    fps                      | 77          |
|    iterations               | 42          |
|    time_elapsed             | 1103        |
|    total_timesteps          | 888832      |
| train/                      |             |
|    approx_kl                | 1306.9758   |
|    approx_ln(kl)            | 7.1754713   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.6         |
|    explained_variance       | 0.843       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 4330        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0405      |
|    value_loss               | 4.37        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.2337515] |
| time/                       |              |
|    fps                      | 78           |
|    iterations               | 43           |
|    time_elapsed             | 1117         |
|    total_timesteps          | 890880       |
| train/                      |              |
|    approx_kl                | 580.33655    |
|    approx_ln(kl)            | 6.3636084    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.59         |
|    explained_variance       | 0.844        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4340         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0407       |
|    value_loss               | 9.33         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.6710278] |
| time/                       |              |
|    fps                      | 78           |
|    iterations               | 44           |
|    time_elapsed             | 1149         |
|    total_timesteps          | 892928       |
| train/                      |              |
|    approx_kl                | 1222.4231    |
|    approx_ln(kl)            | 7.10859      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.6          |
|    explained_variance       | 0.907        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4350         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0404       |
|    value_loss               | 4.69         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.4089873] |
| time/                       |              |
|    fps                      | 78           |
|    iterations               | 45           |
|    time_elapsed             | 1168         |
|    total_timesteps          | 894976       |
| train/                      |              |
|    approx_kl                | 323.892      |
|    approx_ln(kl)            | 5.7804103    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.61         |
|    explained_variance       | 0.7          |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4360         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0403       |
|    value_loss               | 32.9         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.1029284] |
| time/                       |              |
|    fps                      | 79           |
|    iterations               | 46           |
|    time_elapsed             | 1182         |
|    total_timesteps          | 897024       |
| train/                      |              |
|    approx_kl                | 250.43607    |
|    approx_ln(kl)            | 5.523204     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.6          |
|    explained_variance       | 0.884        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4370         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0405       |
|    value_loss               | 28.5         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.9455945] |
| time/                       |              |
|    fps                      | 80           |
|    iterations               | 47           |
|    time_elapsed             | 1195         |
|    total_timesteps          | 899072       |
| train/                      |              |
|    approx_kl                | 393.2423     |
|    approx_ln(kl)            | 5.974426     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.59         |
|    explained_variance       | 0.902        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4380         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0405       |
|    value_loss               | 7.29         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.9938585] |
| time/                       |              |
|    fps                      | 81           |
|    iterations               | 48           |
|    time_elapsed             | 1209         |
|    total_timesteps          | 901120       |
| train/                      |              |
|    approx_kl                | 785.74884    |
|    approx_ln(kl)            | 6.6666374    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.62         |
|    explained_variance       | 0.943        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4390         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0398       |
|    value_loss               | 3.63         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-0.601026] |
| time/                       |             |
|    fps                      | 82          |
|    iterations               | 49          |
|    time_elapsed             | 1223        |
|    total_timesteps          | 903168      |
| train/                      |             |
|    approx_kl                | 795.8253    |
|    approx_ln(kl)            | 6.67938     |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.64        |
|    explained_variance       | 0.972       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 4400        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0398      |
|    value_loss               | 4.24        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-------------------------------------
| reward             | [-1.7265496] |
| time/              |              |
|    fps             | 162          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 905216       |
-------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.64813864] |
| time/                       |               |
|    fps                      | 154           |
|    iterations               | 2             |
|    time_elapsed             | 26            |
|    total_timesteps          | 907264        |
| train/                      |               |
|    approx_kl                | 594.23254     |
|    approx_ln(kl)            | 6.387271      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.63          |
|    explained_variance       | 0.967         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 4420          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0397        |
|    value_loss               | 3.99          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0451853] |
| time/                       |              |
|    fps                      | 150          |
|    iterations               | 3            |
|    time_elapsed             | 40           |
|    total_timesteps          | 909312       |
| train/                      |              |
|    approx_kl                | 233.45532    |
|    approx_ln(kl)            | 5.4529905    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.61         |
|    explained_variance       | 0.982        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4430         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0401       |
|    value_loss               | 4.42         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0600389] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 4            |
|    time_elapsed             | 54           |
|    total_timesteps          | 911360       |
| train/                      |              |
|    approx_kl                | 486.7158     |
|    approx_ln(kl)            | 6.1876802    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.61         |
|    explained_variance       | 0.98         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4440         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.04         |
|    value_loss               | 2.97         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.4521812] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 5            |
|    time_elapsed             | 69           |
|    total_timesteps          | 913408       |
| train/                      |              |
|    approx_kl                | 620.3457     |
|    approx_ln(kl)            | 6.430277     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.61         |
|    explained_variance       | 0.936        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4450         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0401       |
|    value_loss               | 5.61         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.7154778] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 6            |
|    time_elapsed             | 83           |
|    total_timesteps          | 915456       |
| train/                      |              |
|    approx_kl                | 428.06326    |
|    approx_ln(kl)            | 6.059271     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.58         |
|    explained_variance       | 0.949        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4460         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0407       |
|    value_loss               | 3.11         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-1.258173] |
| time/                       |             |
|    fps                      | 147         |
|    iterations               | 7           |
|    time_elapsed             | 97          |
|    total_timesteps          | 917504      |
| train/                      |             |
|    approx_kl                | 1029.6598   |
|    approx_ln(kl)            | 6.9369836   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.56        |
|    explained_variance       | 0.855       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 4470        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0409      |
|    value_loss               | 5.08        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.0901105] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 8            |
|    time_elapsed             | 110          |
|    total_timesteps          | 919552       |
| train/                      |              |
|    approx_kl                | 558.83325    |
|    approx_ln(kl)            | 6.325851     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.56         |
|    explained_variance       | 0.743        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4480         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0407       |
|    value_loss               | 7.94         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.6464946] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 9            |
|    time_elapsed             | 124          |
|    total_timesteps          | 921600       |
| train/                      |              |
|    approx_kl                | 200.6706     |
|    approx_ln(kl)            | 5.301665     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.58         |
|    explained_variance       | 0.802        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4490         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0406       |
|    value_loss               | 7.04         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.9217446] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 10           |
|    time_elapsed             | 138          |
|    total_timesteps          | 923648       |
| train/                      |              |
|    approx_kl                | 268.93967    |
|    approx_ln(kl)            | 5.594487     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.56         |
|    explained_variance       | 0.877        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4500         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0411       |
|    value_loss               | 6.66         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.8353416] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 11           |
|    time_elapsed             | 151          |
|    total_timesteps          | 925696       |
| train/                      |              |
|    approx_kl                | 569.677      |
|    approx_ln(kl)            | 6.3450694    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.56         |
|    explained_variance       | 0.864        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4510         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.041        |
|    value_loss               | 9.1          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.50372475] |
| time/                       |               |
|    fps                      | 148           |
|    iterations               | 12            |
|    time_elapsed             | 165           |
|    total_timesteps          | 927744        |
| train/                      |               |
|    approx_kl                | 1515.5757     |
|    approx_ln(kl)            | 7.3235507     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.57          |
|    explained_variance       | 0.964         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 4520          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0408        |
|    value_loss               | 2.86          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-0.918158] |
| time/                       |             |
|    fps                      | 148         |
|    iterations               | 13          |
|    time_elapsed             | 178         |
|    total_timesteps          | 929792      |
| train/                      |             |
|    approx_kl                | 1709.5903   |
|    approx_ln(kl)            | 7.444009    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.56        |
|    explained_variance       | 0.913       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 4530        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0409      |
|    value_loss               | 2.59        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.9348253] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 14           |
|    time_elapsed             | 192          |
|    total_timesteps          | 931840       |
| train/                      |              |
|    approx_kl                | 3549.3672    |
|    approx_ln(kl)            | 8.174524     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.59         |
|    explained_variance       | 0.979        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4540         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0403       |
|    value_loss               | 1.51         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.4554071] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 15           |
|    time_elapsed             | 206          |
|    total_timesteps          | 933888       |
| train/                      |              |
|    approx_kl                | 3657.5522    |
|    approx_ln(kl)            | 8.20455      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.58         |
|    explained_variance       | 0.863        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4550         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0408       |
|    value_loss               | 1.17         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-1.574592] |
| time/                       |             |
|    fps                      | 148         |
|    iterations               | 16          |
|    time_elapsed             | 220         |
|    total_timesteps          | 935936      |
| train/                      |             |
|    approx_kl                | 2936.81     |
|    approx_ln(kl)            | 7.9850793   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.55        |
|    explained_variance       | 0.973       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 4560        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0411      |
|    value_loss               | 1.05        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.6821293] |
| time/                       |              |
|    fps                      | 100          |
|    iterations               | 17           |
|    time_elapsed             | 345          |
|    total_timesteps          | 937984       |
| train/                      |              |
|    approx_kl                | 405.069      |
|    approx_ln(kl)            | 6.0040574    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.55         |
|    explained_variance       | 0.975        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4570         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0412       |
|    value_loss               | 2.9          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.375522] |
| time/                       |             |
|    fps                      | 84          |
|    iterations               | 18          |
|    time_elapsed             | 435         |
|    total_timesteps          | 940032      |
| train/                      |             |
|    approx_kl                | 870.417     |
|    approx_ln(kl)            | 6.7689724   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.6         |
|    explained_variance       | 0.993       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 4580        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0401      |
|    value_loss               | 1.03        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.6603757] |
| time/                       |              |
|    fps                      | 86           |
|    iterations               | 19           |
|    time_elapsed             | 452          |
|    total_timesteps          | 942080       |
| train/                      |              |
|    approx_kl                | 2807.395     |
|    approx_ln(kl)            | 7.9400125    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.6          |
|    explained_variance       | 0.98         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4590         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0402       |
|    value_loss               | 1.22         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.2362423] |
| time/                       |              |
|    fps                      | 86           |
|    iterations               | 20           |
|    time_elapsed             | 471          |
|    total_timesteps          | 944128       |
| train/                      |              |
|    approx_kl                | 745.2905     |
|    approx_ln(kl)            | 6.6137743    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.61         |
|    explained_variance       | 0.975        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4600         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.04         |
|    value_loss               | 2.9          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.8447783] |
| time/                       |              |
|    fps                      | 87           |
|    iterations               | 21           |
|    time_elapsed             | 492          |
|    total_timesteps          | 946176       |
| train/                      |              |
|    approx_kl                | 1041.9791    |
|    approx_ln(kl)            | 6.9488773    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.6          |
|    explained_variance       | 0.949        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4610         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0392       |
|    value_loss               | 7.1          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.9858184] |
| time/                       |              |
|    fps                      | 88           |
|    iterations               | 22           |
|    time_elapsed             | 511          |
|    total_timesteps          | 948224       |
| train/                      |              |
|    approx_kl                | 569.9836     |
|    approx_ln(kl)            | 6.3456078    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.64         |
|    explained_variance       | 0.904        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4620         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0392       |
|    value_loss               | 22.6         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.9402076] |
| time/                       |              |
|    fps                      | 88           |
|    iterations               | 23           |
|    time_elapsed             | 530          |
|    total_timesteps          | 950272       |
| train/                      |              |
|    approx_kl                | 799.9675     |
|    approx_ln(kl)            | 6.6845713    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.67         |
|    explained_variance       | 0.979        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4630         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0386       |
|    value_loss               | 7            |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7029627] |
| time/                       |              |
|    fps                      | 89           |
|    iterations               | 24           |
|    time_elapsed             | 549          |
|    total_timesteps          | 952320       |
| train/                      |              |
|    approx_kl                | 486.62534    |
|    approx_ln(kl)            | 6.1874943    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.7          |
|    explained_variance       | 0.951        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4640         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0381       |
|    value_loss               | 2.47         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.9738773] |
| time/                       |              |
|    fps                      | 85           |
|    iterations               | 25           |
|    time_elapsed             | 596          |
|    total_timesteps          | 954368       |
| train/                      |              |
|    approx_kl                | 2278.9175    |
|    approx_ln(kl)            | 7.731456     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.68         |
|    explained_variance       | 0.989        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4650         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0386       |
|    value_loss               | 1.59         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.9272486] |
| time/                       |              |
|    fps                      | 75           |
|    iterations               | 26           |
|    time_elapsed             | 701          |
|    total_timesteps          | 956416       |
| train/                      |              |
|    approx_kl                | 7551.913     |
|    approx_ln(kl)            | 8.929556     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.68         |
|    explained_variance       | 0.967        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4660         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0387       |
|    value_loss               | 1.12         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.2033293] |
| time/                       |              |
|    fps                      | 68           |
|    iterations               | 27           |
|    time_elapsed             | 808          |
|    total_timesteps          | 958464       |
| train/                      |              |
|    approx_kl                | 2973.6304    |
|    approx_ln(kl)            | 7.9975386    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.69         |
|    explained_variance       | 0.985        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4670         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0385       |
|    value_loss               | 1.95         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0370212] |
| time/                       |              |
|    fps                      | 68           |
|    iterations               | 28           |
|    time_elapsed             | 838          |
|    total_timesteps          | 960512       |
| train/                      |              |
|    approx_kl                | 975.71014    |
|    approx_ln(kl)            | 6.8831654    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.7          |
|    explained_variance       | 0.99         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4680         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0385       |
|    value_loss               | 4.47         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.3750648] |
| time/                       |              |
|    fps                      | 69           |
|    iterations               | 29           |
|    time_elapsed             | 855          |
|    total_timesteps          | 962560       |
| train/                      |              |
|    approx_kl                | 1574.2153    |
|    approx_ln(kl)            | 7.361512     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.71         |
|    explained_variance       | 0.976        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4690         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.038        |
|    value_loss               | 16.1         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.9855213] |
| time/                       |              |
|    fps                      | 70           |
|    iterations               | 30           |
|    time_elapsed             | 874          |
|    total_timesteps          | 964608       |
| train/                      |              |
|    approx_kl                | 2146.1277    |
|    approx_ln(kl)            | 7.6714206    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.7          |
|    explained_variance       | 0.992        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4700         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0384       |
|    value_loss               | 2.83         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-5.6786838] |
| time/                       |              |
|    fps                      | 71           |
|    iterations               | 31           |
|    time_elapsed             | 891          |
|    total_timesteps          | 966656       |
| train/                      |              |
|    approx_kl                | 926.60547    |
|    approx_ln(kl)            | 6.8315277    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.69         |
|    explained_variance       | 0.805        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4710         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0385       |
|    value_loss               | 75.8         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-5.9457297] |
| time/                       |              |
|    fps                      | 72           |
|    iterations               | 32           |
|    time_elapsed             | 906          |
|    total_timesteps          | 968704       |
| train/                      |              |
|    approx_kl                | 206.3371     |
|    approx_ln(kl)            | 5.329511     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.7          |
|    explained_variance       | 0.93         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4720         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0384       |
|    value_loss               | 61.8         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.45998812] |
| time/                       |               |
|    fps                      | 73            |
|    iterations               | 33            |
|    time_elapsed             | 920           |
|    total_timesteps          | 970752        |
| train/                      |               |
|    approx_kl                | 1397.5892     |
|    approx_ln(kl)            | 7.242504      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.7           |
|    explained_variance       | 0.956         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 4730          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0383        |
|    value_loss               | 50.1          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.9488549] |
| time/                       |              |
|    fps                      | 74           |
|    iterations               | 34           |
|    time_elapsed             | 935          |
|    total_timesteps          | 972800       |
| train/                      |              |
|    approx_kl                | 404.37146    |
|    approx_ln(kl)            | 6.002334     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.7          |
|    explained_variance       | 0.989        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4740         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0383       |
|    value_loss               | 8.52         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.854052] |
| time/                       |             |
|    fps                      | 75          |
|    iterations               | 35          |
|    time_elapsed             | 948         |
|    total_timesteps          | 974848      |
| train/                      |             |
|    approx_kl                | 913.814     |
|    approx_ln(kl)            | 6.817627    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.71        |
|    explained_variance       | 0.989       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 4750        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0381      |
|    value_loss               | 7.55        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.4089422] |
| time/                       |              |
|    fps                      | 71           |
|    iterations               | 36           |
|    time_elapsed             | 1026         |
|    total_timesteps          | 976896       |
| train/                      |              |
|    approx_kl                | 1046.0944    |
|    approx_ln(kl)            | 6.952819     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.71         |
|    explained_variance       | 0.953        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4760         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0381       |
|    value_loss               | 27.2         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.0955336] |
| time/                       |              |
|    fps                      | 72           |
|    iterations               | 37           |
|    time_elapsed             | 1040         |
|    total_timesteps          | 978944       |
| train/                      |              |
|    approx_kl                | 757.7572     |
|    approx_ln(kl)            | 6.630363     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.72         |
|    explained_variance       | 0.982        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4770         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.038        |
|    value_loss               | 22.3         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.263996] |
| time/                       |             |
|    fps                      | 73          |
|    iterations               | 38          |
|    time_elapsed             | 1054        |
|    total_timesteps          | 980992      |
| train/                      |             |
|    approx_kl                | 512.3233    |
|    approx_ln(kl)            | 6.238956    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.73        |
|    explained_variance       | 0.799       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 4780        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0378      |
|    value_loss               | 43.2        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.668055] |
| time/                       |             |
|    fps                      | 74          |
|    iterations               | 39          |
|    time_elapsed             | 1067        |
|    total_timesteps          | 983040      |
| train/                      |             |
|    approx_kl                | 912.9752    |
|    approx_ln(kl)            | 6.8167086   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.75        |
|    explained_variance       | 0.967       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 4790        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0376      |
|    value_loss               | 25.2        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-5.0490804] |
| time/                       |              |
|    fps                      | 75           |
|    iterations               | 40           |
|    time_elapsed             | 1081         |
|    total_timesteps          | 985088       |
| train/                      |              |
|    approx_kl                | 896.9645     |
|    approx_ln(kl)            | 6.7990165    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.73         |
|    explained_variance       | 0.982        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4800         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0381       |
|    value_loss               | 21.2         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-5.440291] |
| time/                       |             |
|    fps                      | 76          |
|    iterations               | 41          |
|    time_elapsed             | 1094        |
|    total_timesteps          | 987136      |
| train/                      |             |
|    approx_kl                | 336.2668    |
|    approx_ln(kl)            | 5.817905    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.72        |
|    explained_variance       | 0.99        |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 4810        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0383      |
|    value_loss               | 18.2        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.2872381] |
| time/                       |              |
|    fps                      | 77           |
|    iterations               | 42           |
|    time_elapsed             | 1108         |
|    total_timesteps          | 989184       |
| train/                      |              |
|    approx_kl                | 1850.3423    |
|    approx_ln(kl)            | 7.523126     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.71         |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4820         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0384       |
|    value_loss               | 20.7         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.52991754] |
| time/                       |               |
|    fps                      | 78            |
|    iterations               | 43            |
|    time_elapsed             | 1122          |
|    total_timesteps          | 991232        |
| train/                      |               |
|    approx_kl                | 699.0531      |
|    approx_ln(kl)            | 6.5497265     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.72          |
|    explained_variance       | 0.953         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 4830          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0381        |
|    value_loss               | 29            |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.5625181] |
| time/                       |              |
|    fps                      | 79           |
|    iterations               | 44           |
|    time_elapsed             | 1136         |
|    total_timesteps          | 993280       |
| train/                      |              |
|    approx_kl                | 1650.6666    |
|    approx_ln(kl)            | 7.4089346    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.73         |
|    explained_variance       | 0.98         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4840         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.038        |
|    value_loss               | 7.02         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.2441628] |
| time/                       |              |
|    fps                      | 80           |
|    iterations               | 45           |
|    time_elapsed             | 1149         |
|    total_timesteps          | 995328       |
| train/                      |              |
|    approx_kl                | 1637.0781    |
|    approx_ln(kl)            | 7.400668     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.71         |
|    explained_variance       | 0.989        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4850         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0383       |
|    value_loss               | 9.87         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.4440138] |
| time/                       |              |
|    fps                      | 80           |
|    iterations               | 46           |
|    time_elapsed             | 1163         |
|    total_timesteps          | 997376       |
| train/                      |              |
|    approx_kl                | 1944.0872    |
|    approx_ln(kl)            | 7.572548     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.69         |
|    explained_variance       | 0.992        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4860         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0386       |
|    value_loss               | 10.4         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.930612] |
| time/                       |             |
|    fps                      | 81          |
|    iterations               | 47          |
|    time_elapsed             | 1177        |
|    total_timesteps          | 999424      |
| train/                      |             |
|    approx_kl                | 1370.3341   |
|    approx_ln(kl)            | 7.22281     |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.71        |
|    explained_variance       | 0.891       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 4870        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0383      |
|    value_loss               | 18.6        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.9665303] |
| time/                       |              |
|    fps                      | 82           |
|    iterations               | 48           |
|    time_elapsed             | 1190         |
|    total_timesteps          | 1001472      |
| train/                      |              |
|    approx_kl                | 710.0918     |
|    approx_ln(kl)            | 6.5653944    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.69         |
|    explained_variance       | 0.98         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4880         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0389       |
|    value_loss               | 6.62         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.786964] |
| time/                       |             |
|    fps                      | 83          |
|    iterations               | 49          |
|    time_elapsed             | 1204        |
|    total_timesteps          | 1003520     |
| train/                      |             |
|    approx_kl                | 466.82913   |
|    approx_ln(kl)            | 6.145963    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.68        |
|    explained_variance       | 0.99        |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 4890        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0391      |
|    value_loss               | 5.68        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-------------------------------------
| reward             | [-2.7024782] |
| time/              |              |
|    fps             | 157          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 1005568      |
-------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.169208] |
| time/                       |             |
|    fps                      | 152         |
|    iterations               | 2           |
|    time_elapsed             | 26          |
|    total_timesteps          | 1007616     |
| train/                      |             |
|    approx_kl                | 931.9105    |
|    approx_ln(kl)            | 6.837237    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.67        |
|    explained_variance       | 0.992       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 4910        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0391      |
|    value_loss               | 3.51        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.513901] |
| time/                       |             |
|    fps                      | 150         |
|    iterations               | 3           |
|    time_elapsed             | 40          |
|    total_timesteps          | 1009664     |
| train/                      |             |
|    approx_kl                | 1601.4427   |
|    approx_ln(kl)            | 7.37866     |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.69        |
|    explained_variance       | 0.994       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 4920        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0389      |
|    value_loss               | 6.07        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.2605762] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 4            |
|    time_elapsed             | 54           |
|    total_timesteps          | 1011712      |
| train/                      |              |
|    approx_kl                | 939.5654     |
|    approx_ln(kl)            | 6.8454175    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.68         |
|    explained_variance       | 0.991        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4930         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0391       |
|    value_loss               | 7.71         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-0.729352] |
| time/                       |             |
|    fps                      | 149         |
|    iterations               | 5           |
|    time_elapsed             | 68          |
|    total_timesteps          | 1013760     |
| train/                      |             |
|    approx_kl                | 353.1363    |
|    approx_ln(kl)            | 5.866854    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.64        |
|    explained_variance       | 0.95        |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 4940        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0398      |
|    value_loss               | 4.69        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.1790379] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 6            |
|    time_elapsed             | 82           |
|    total_timesteps          | 1015808      |
| train/                      |              |
|    approx_kl                | 399.45868    |
|    approx_ln(kl)            | 5.9901104    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.64         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4950         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.04         |
|    value_loss               | 2.96         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.4692376] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 7            |
|    time_elapsed             | 96           |
|    total_timesteps          | 1017856      |
| train/                      |              |
|    approx_kl                | 953.6743     |
|    approx_ln(kl)            | 6.8603225    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.62         |
|    explained_variance       | 0.981        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4960         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0405       |
|    value_loss               | 2.18         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.135827] |
| time/                       |             |
|    fps                      | 143         |
|    iterations               | 8           |
|    time_elapsed             | 113         |
|    total_timesteps          | 1019904     |
| train/                      |             |
|    approx_kl                | 1116.2732   |
|    approx_ln(kl)            | 7.0177507   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.63        |
|    explained_variance       | 0.983       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 4970        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0401      |
|    value_loss               | 7.59        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.1948166] |
| time/                       |              |
|    fps                      | 144          |
|    iterations               | 9            |
|    time_elapsed             | 127          |
|    total_timesteps          | 1021952      |
| train/                      |              |
|    approx_kl                | 551.70337    |
|    approx_ln(kl)            | 6.3130107    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.63         |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4980         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0406       |
|    value_loss               | 4.76         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.8474278] |
| time/                       |              |
|    fps                      | 144          |
|    iterations               | 10           |
|    time_elapsed             | 141          |
|    total_timesteps          | 1024000      |
| train/                      |              |
|    approx_kl                | 1293.656     |
|    approx_ln(kl)            | 7.1652274    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.65         |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 4990         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0399       |
|    value_loss               | 5.34         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.318034] |
| time/                       |             |
|    fps                      | 144         |
|    iterations               | 11          |
|    time_elapsed             | 155         |
|    total_timesteps          | 1026048     |
| train/                      |             |
|    approx_kl                | 630.3594    |
|    approx_ln(kl)            | 6.44629     |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.63        |
|    explained_variance       | 0.991       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 5000        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.04        |
|    value_loss               | 9.16        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.2063668] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 12           |
|    time_elapsed             | 169          |
|    total_timesteps          | 1028096      |
| train/                      |              |
|    approx_kl                | 696.3563     |
|    approx_ln(kl)            | 6.5458612    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.62         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5010         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0401       |
|    value_loss               | 2.98         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.0819626] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 13           |
|    time_elapsed             | 183          |
|    total_timesteps          | 1030144      |
| train/                      |              |
|    approx_kl                | 843.8639     |
|    approx_ln(kl)            | 6.7379913    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.63         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5020         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0397       |
|    value_loss               | 4.76         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.413019] |
| time/                       |             |
|    fps                      | 145         |
|    iterations               | 14          |
|    time_elapsed             | 197         |
|    total_timesteps          | 1032192     |
| train/                      |             |
|    approx_kl                | 1219.3086   |
|    approx_ln(kl)            | 7.106039    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.64        |
|    explained_variance       | 0.993       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 5030        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0399      |
|    value_loss               | 3.01        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5161008] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 15           |
|    time_elapsed             | 211          |
|    total_timesteps          | 1034240      |
| train/                      |              |
|    approx_kl                | 182.67581    |
|    approx_ln(kl)            | 5.207713     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.63         |
|    explained_variance       | 0.991        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5040         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0399       |
|    value_loss               | 3.96         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.8960606] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 16           |
|    time_elapsed             | 225          |
|    total_timesteps          | 1036288      |
| train/                      |              |
|    approx_kl                | 872.7763     |
|    approx_ln(kl)            | 6.7716794    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.64         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5050         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0398       |
|    value_loss               | 2.52         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.3007482] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 17           |
|    time_elapsed             | 239          |
|    total_timesteps          | 1038336      |
| train/                      |              |
|    approx_kl                | 1574.7214    |
|    approx_ln(kl)            | 7.3618336    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.65         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5060         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0395       |
|    value_loss               | 3.03         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.5929967] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 18           |
|    time_elapsed             | 253          |
|    total_timesteps          | 1040384      |
| train/                      |              |
|    approx_kl                | 536.71674    |
|    approx_ln(kl)            | 6.2854705    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.68         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5070         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0389       |
|    value_loss               | 3.71         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.5453062] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 19           |
|    time_elapsed             | 267          |
|    total_timesteps          | 1042432      |
| train/                      |              |
|    approx_kl                | 562.36804    |
|    approx_ln(kl)            | 6.3321567    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.68         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5080         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0388       |
|    value_loss               | 4.12         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.9168198] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 20           |
|    time_elapsed             | 281          |
|    total_timesteps          | 1044480      |
| train/                      |              |
|    approx_kl                | 1802.9043    |
|    approx_ln(kl)            | 7.497154     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.67         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5090         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0392       |
|    value_loss               | 2.62         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.1500726] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 21           |
|    time_elapsed             | 295          |
|    total_timesteps          | 1046528      |
| train/                      |              |
|    approx_kl                | 743.2665     |
|    approx_ln(kl)            | 6.6110544    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.66         |
|    explained_variance       | 0.987        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5100         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0394       |
|    value_loss               | 3.42         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.6093082] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 22           |
|    time_elapsed             | 309          |
|    total_timesteps          | 1048576      |
| train/                      |              |
|    approx_kl                | 647.5746     |
|    approx_ln(kl)            | 6.473234     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.67         |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5110         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0392       |
|    value_loss               | 4.74         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.665695] |
| time/                       |             |
|    fps                      | 126         |
|    iterations               | 23          |
|    time_elapsed             | 372         |
|    total_timesteps          | 1050624     |
| train/                      |             |
|    approx_kl                | 1238.7302   |
|    approx_ln(kl)            | 7.1218424   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.7         |
|    explained_variance       | 0.997       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 5120        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0385      |
|    value_loss               | 3.93        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.5337336] |
| time/                       |              |
|    fps                      | 127          |
|    iterations               | 24           |
|    time_elapsed             | 385          |
|    total_timesteps          | 1052672      |
| train/                      |              |
|    approx_kl                | 327.54688    |
|    approx_ln(kl)            | 5.791631     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.73         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5130         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.038        |
|    value_loss               | 7.41         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.253134] |
| time/                       |             |
|    fps                      | 128         |
|    iterations               | 25          |
|    time_elapsed             | 399         |
|    total_timesteps          | 1054720     |
| train/                      |             |
|    approx_kl                | 834.22815   |
|    approx_ln(kl)            | 6.726507    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.73        |
|    explained_variance       | 0.996       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 5140        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.038       |
|    value_loss               | 2.88        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.2492132] |
| time/                       |              |
|    fps                      | 128          |
|    iterations               | 26           |
|    time_elapsed             | 413          |
|    total_timesteps          | 1056768      |
| train/                      |              |
|    approx_kl                | 911.9531     |
|    approx_ln(kl)            | 6.8155885    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.73         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5150         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0379       |
|    value_loss               | 6.07         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.9367987] |
| time/                       |              |
|    fps                      | 129          |
|    iterations               | 27           |
|    time_elapsed             | 427          |
|    total_timesteps          | 1058816      |
| train/                      |              |
|    approx_kl                | 1357.7975    |
|    approx_ln(kl)            | 7.213619     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.72         |
|    explained_variance       | 0.986        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5160         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0381       |
|    value_loss               | 8.5          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.315537] |
| time/                       |             |
|    fps                      | 128         |
|    iterations               | 28          |
|    time_elapsed             | 447         |
|    total_timesteps          | 1060864     |
| train/                      |             |
|    approx_kl                | 982.72546   |
|    approx_ln(kl)            | 6.89033     |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.72        |
|    explained_variance       | 0.994       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 5170        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.038       |
|    value_loss               | 1.99        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.2473602] |
| time/                       |              |
|    fps                      | 128          |
|    iterations               | 29           |
|    time_elapsed             | 461          |
|    total_timesteps          | 1062912      |
| train/                      |              |
|    approx_kl                | 940.1392     |
|    approx_ln(kl)            | 6.846028     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.72         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5180         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0381       |
|    value_loss               | 1.97         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.1223934] |
| time/                       |              |
|    fps                      | 129          |
|    iterations               | 30           |
|    time_elapsed             | 476          |
|    total_timesteps          | 1064960      |
| train/                      |              |
|    approx_kl                | 1414.0453    |
|    approx_ln(kl)            | 7.25421      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.72         |
|    explained_variance       | 0.982        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5190         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0381       |
|    value_loss               | 3.88         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.598418] |
| time/                       |             |
|    fps                      | 129         |
|    iterations               | 31          |
|    time_elapsed             | 490         |
|    total_timesteps          | 1067008     |
| train/                      |             |
|    approx_kl                | 758.286     |
|    approx_ln(kl)            | 6.6310606   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.71        |
|    explained_variance       | 0.958       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 5200        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0382      |
|    value_loss               | 12.6        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.9676013] |
| time/                       |              |
|    fps                      | 129          |
|    iterations               | 32           |
|    time_elapsed             | 504          |
|    total_timesteps          | 1069056      |
| train/                      |              |
|    approx_kl                | 2131.7468    |
|    approx_ln(kl)            | 7.664697     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.71         |
|    explained_variance       | 0.989        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5210         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0382       |
|    value_loss               | 6.66         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.8083673] |
| time/                       |              |
|    fps                      | 130          |
|    iterations               | 33           |
|    time_elapsed             | 518          |
|    total_timesteps          | 1071104      |
| train/                      |              |
|    approx_kl                | 3017.5894    |
|    approx_ln(kl)            | 8.012214     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.73         |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5220         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0379       |
|    value_loss               | 5.91         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.6256194] |
| time/                       |              |
|    fps                      | 130          |
|    iterations               | 34           |
|    time_elapsed             | 532          |
|    total_timesteps          | 1073152      |
| train/                      |              |
|    approx_kl                | 1641.1973    |
|    approx_ln(kl)            | 7.403181     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.74         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5230         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0375       |
|    value_loss               | 3.29         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.0118873] |
| time/                       |              |
|    fps                      | 130          |
|    iterations               | 35           |
|    time_elapsed             | 548          |
|    total_timesteps          | 1075200      |
| train/                      |              |
|    approx_kl                | 1045.9249    |
|    approx_ln(kl)            | 6.9526567    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.74         |
|    explained_variance       | 0.988        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5240         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0374       |
|    value_loss               | 10.2         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.49062353] |
| time/                       |               |
|    fps                      | 131           |
|    iterations               | 36            |
|    time_elapsed             | 561           |
|    total_timesteps          | 1077248       |
| train/                      |               |
|    approx_kl                | 708.929       |
|    approx_ln(kl)            | 6.5637555     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.76          |
|    explained_variance       | 0.971         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 5250          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0373        |
|    value_loss               | 7.08          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-0.698965] |
| time/                       |             |
|    fps                      | 131         |
|    iterations               | 37          |
|    time_elapsed             | 575         |
|    total_timesteps          | 1079296     |
| train/                      |             |
|    approx_kl                | 986.58386   |
|    approx_ln(kl)            | 6.8942485   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.75        |
|    explained_variance       | 0.97        |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 5260        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0374      |
|    value_loss               | 11.7        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5851337] |
| time/                       |              |
|    fps                      | 131          |
|    iterations               | 38           |
|    time_elapsed             | 589          |
|    total_timesteps          | 1081344      |
| train/                      |              |
|    approx_kl                | 3446.7412    |
|    approx_ln(kl)            | 8.1451845    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.75         |
|    explained_variance       | 0.92         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5270         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0375       |
|    value_loss               | 11.4         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.3724962] |
| time/                       |              |
|    fps                      | 132          |
|    iterations               | 39           |
|    time_elapsed             | 603          |
|    total_timesteps          | 1083392      |
| train/                      |              |
|    approx_kl                | 834.89624    |
|    approx_ln(kl)            | 6.7273073    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.77         |
|    explained_variance       | 0.96         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5280         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.037        |
|    value_loss               | 6.5          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.4296339] |
| time/                       |              |
|    fps                      | 132          |
|    iterations               | 40           |
|    time_elapsed             | 617          |
|    total_timesteps          | 1085440      |
| train/                      |              |
|    approx_kl                | 970.68744    |
|    approx_ln(kl)            | 6.8780046    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.78         |
|    explained_variance       | 0.977        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5290         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0369       |
|    value_loss               | 10.1         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.2174124] |
| time/                       |              |
|    fps                      | 133          |
|    iterations               | 41           |
|    time_elapsed             | 631          |
|    total_timesteps          | 1087488      |
| train/                      |              |
|    approx_kl                | 1619.4064    |
|    approx_ln(kl)            | 7.389815     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.75         |
|    explained_variance       | 0.985        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5300         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0374       |
|    value_loss               | 5.48         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0462896] |
| time/                       |              |
|    fps                      | 133          |
|    iterations               | 42           |
|    time_elapsed             | 644          |
|    total_timesteps          | 1089536      |
| train/                      |              |
|    approx_kl                | 648.3937     |
|    approx_ln(kl)            | 6.4744983    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.77         |
|    explained_variance       | 0.976        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5310         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0369       |
|    value_loss               | 3.52         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.6144066] |
| time/                       |              |
|    fps                      | 133          |
|    iterations               | 43           |
|    time_elapsed             | 658          |
|    total_timesteps          | 1091584      |
| train/                      |              |
|    approx_kl                | 1269.707     |
|    approx_ln(kl)            | 7.1465416    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.76         |
|    explained_variance       | 0.982        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5320         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0373       |
|    value_loss               | 4.86         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-1.789468] |
| time/                       |             |
|    fps                      | 133         |
|    iterations               | 44          |
|    time_elapsed             | 672         |
|    total_timesteps          | 1093632     |
| train/                      |             |
|    approx_kl                | 791.83344   |
|    approx_ln(kl)            | 6.674351    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.77        |
|    explained_variance       | 0.971       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 5330        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0371      |
|    value_loss               | 4.47        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.1629395] |
| time/                       |              |
|    fps                      | 134          |
|    iterations               | 45           |
|    time_elapsed             | 686          |
|    total_timesteps          | 1095680      |
| train/                      |              |
|    approx_kl                | 369.9536     |
|    approx_ln(kl)            | 5.913378     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.77         |
|    explained_variance       | 0.965        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5340         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.037        |
|    value_loss               | 5.03         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4285734] |
| time/                       |              |
|    fps                      | 134          |
|    iterations               | 46           |
|    time_elapsed             | 700          |
|    total_timesteps          | 1097728      |
| train/                      |              |
|    approx_kl                | 382.80655    |
|    approx_ln(kl)            | 5.94753      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.81         |
|    explained_variance       | 0.988        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5350         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0362       |
|    value_loss               | 2.41         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.2935306] |
| time/                       |              |
|    fps                      | 134          |
|    iterations               | 47           |
|    time_elapsed             | 714          |
|    total_timesteps          | 1099776      |
| train/                      |              |
|    approx_kl                | 2238.9746    |
|    approx_ln(kl)            | 7.7137733    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.8          |
|    explained_variance       | 0.982        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5360         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0365       |
|    value_loss               | 1.3          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4047513] |
| time/                       |              |
|    fps                      | 134          |
|    iterations               | 48           |
|    time_elapsed             | 728          |
|    total_timesteps          | 1101824      |
| train/                      |              |
|    approx_kl                | 1283.2932    |
|    approx_ln(kl)            | 7.157185     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.81         |
|    explained_variance       | 0.909        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5370         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0363       |
|    value_loss               | 2.63         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.64016646] |
| time/                       |               |
|    fps                      | 135           |
|    iterations               | 49            |
|    time_elapsed             | 742           |
|    total_timesteps          | 1103872       |
| train/                      |               |
|    approx_kl                | 581.2544      |
|    approx_ln(kl)            | 6.3651886     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.81          |
|    explained_variance       | 0.979         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 5380          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.036         |
|    value_loss               | 2             |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
--------------------------------------
| reward             | [-0.34748828] |
| time/              |               |
|    fps             | 158           |
|    iterations      | 1             |
|    time_elapsed    | 12            |
|    total_timesteps | 1105920       |
--------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.9453019] |
| time/                       |              |
|    fps                      | 153          |
|    iterations               | 2            |
|    time_elapsed             | 26           |
|    total_timesteps          | 1107968      |
| train/                      |              |
|    approx_kl                | 619.0763     |
|    approx_ln(kl)            | 6.4282284    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.81         |
|    explained_variance       | 0.991        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5400         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0363       |
|    value_loss               | 3.91         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.7397135] |
| time/                       |              |
|    fps                      | 151          |
|    iterations               | 3            |
|    time_elapsed             | 40           |
|    total_timesteps          | 1110016      |
| train/                      |              |
|    approx_kl                | 767.05035    |
|    approx_ln(kl)            | 6.6425524    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.81         |
|    explained_variance       | 0.985        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5410         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0361       |
|    value_loss               | 2.93         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.2591501] |
| time/                       |              |
|    fps                      | 150          |
|    iterations               | 4            |
|    time_elapsed             | 54           |
|    total_timesteps          | 1112064      |
| train/                      |              |
|    approx_kl                | 749.1024     |
|    approx_ln(kl)            | 6.6188755    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.85         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5420         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0356       |
|    value_loss               | 4.34         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.61025435] |
| time/                       |               |
|    fps                      | 149           |
|    iterations               | 5             |
|    time_elapsed             | 68            |
|    total_timesteps          | 1114112       |
| train/                      |               |
|    approx_kl                | 924.0415      |
|    approx_ln(kl)            | 6.828757      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.85          |
|    explained_variance       | 0.994         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 5430          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0356        |
|    value_loss               | 2.27          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.34021616] |
| time/                       |               |
|    fps                      | 149           |
|    iterations               | 6             |
|    time_elapsed             | 82            |
|    total_timesteps          | 1116160       |
| train/                      |               |
|    approx_kl                | 1956.9773     |
|    approx_ln(kl)            | 7.5791564     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.83          |
|    explained_variance       | 0.601         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 5440          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.036         |
|    value_loss               | 0.635         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4438931] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 7            |
|    time_elapsed             | 95           |
|    total_timesteps          | 1118208      |
| train/                      |              |
|    approx_kl                | 1108.7539    |
|    approx_ln(kl)            | 7.010992     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.83         |
|    explained_variance       | 0.79         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5450         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0359       |
|    value_loss               | 1.37         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.36019525] |
| time/                       |               |
|    fps                      | 149           |
|    iterations               | 8             |
|    time_elapsed             | 109           |
|    total_timesteps          | 1120256       |
| train/                      |               |
|    approx_kl                | 1156.0106     |
|    approx_ln(kl)            | 7.05273       |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.78          |
|    explained_variance       | 0.3           |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 5460          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0372        |
|    value_loss               | 1.11          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6088404] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 9            |
|    time_elapsed             | 123          |
|    total_timesteps          | 1122304      |
| train/                      |              |
|    approx_kl                | 1236.9231    |
|    approx_ln(kl)            | 7.1203823    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.79         |
|    explained_variance       | 0.855        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5470         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0365       |
|    value_loss               | 0.346        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.0357745] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 10           |
|    time_elapsed             | 137          |
|    total_timesteps          | 1124352      |
| train/                      |              |
|    approx_kl                | 992.2471     |
|    approx_ln(kl)            | 6.899972     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.79         |
|    explained_variance       | -0.353       |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5480         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0367       |
|    value_loss               | 6.51         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.69465303] |
| time/                       |               |
|    fps                      | 149           |
|    iterations               | 11            |
|    time_elapsed             | 150           |
|    total_timesteps          | 1126400       |
| train/                      |               |
|    approx_kl                | 766.60455     |
|    approx_ln(kl)            | 6.641971      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.8           |
|    explained_variance       | 0.983         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 5490          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0365        |
|    value_loss               | 6.9           |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5946322] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 12           |
|    time_elapsed             | 165          |
|    total_timesteps          | 1128448      |
| train/                      |              |
|    approx_kl                | 955.2912     |
|    approx_ln(kl)            | 6.862016     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.83         |
|    explained_variance       | 0.874        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5500         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0359       |
|    value_loss               | 18.1         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.7194464] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 13           |
|    time_elapsed             | 179          |
|    total_timesteps          | 1130496      |
| train/                      |              |
|    approx_kl                | 364.98022    |
|    approx_ln(kl)            | 5.899843     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.83         |
|    explained_variance       | 0.966        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5510         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0359       |
|    value_loss               | 1.86         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-0.588372] |
| time/                       |             |
|    fps                      | 117         |
|    iterations               | 14          |
|    time_elapsed             | 243         |
|    total_timesteps          | 1132544     |
| train/                      |             |
|    approx_kl                | 780.31433   |
|    approx_ln(kl)            | 6.659697    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.84        |
|    explained_variance       | 0.967       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 5520        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0358      |
|    value_loss               | 16.3        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.5280901] |
| time/                       |              |
|    fps                      | 119          |
|    iterations               | 15           |
|    time_elapsed             | 256          |
|    total_timesteps          | 1134592      |
| train/                      |              |
|    approx_kl                | 707.2295     |
|    approx_ln(kl)            | 6.561355     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.85         |
|    explained_variance       | 0.954        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5530         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0356       |
|    value_loss               | 8.97         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-1.464105] |
| time/                       |             |
|    fps                      | 121         |
|    iterations               | 16          |
|    time_elapsed             | 270         |
|    total_timesteps          | 1136640     |
| train/                      |             |
|    approx_kl                | 1165.2462   |
|    approx_ln(kl)            | 7.0606875   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.87        |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 5540        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0352      |
|    value_loss               | 0.448       |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.9275055] |
| time/                       |              |
|    fps                      | 122          |
|    iterations               | 17           |
|    time_elapsed             | 284          |
|    total_timesteps          | 1138688      |
| train/                      |              |
|    approx_kl                | 1636.7086    |
|    approx_ln(kl)            | 7.4004426    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.89         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5550         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0347       |
|    value_loss               | 1.31         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5993886] |
| time/                       |              |
|    fps                      | 123          |
|    iterations               | 18           |
|    time_elapsed             | 298          |
|    total_timesteps          | 1140736      |
| train/                      |              |
|    approx_kl                | 1819.7756    |
|    approx_ln(kl)            | 7.5064683    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.91         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5560         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0344       |
|    value_loss               | 1.14         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.56604886] |
| time/                       |               |
|    fps                      | 124           |
|    iterations               | 19            |
|    time_elapsed             | 313           |
|    total_timesteps          | 1142784       |
| train/                      |               |
|    approx_kl                | 1159.8162     |
|    approx_ln(kl)            | 7.056017      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.95          |
|    explained_variance       | 0.982         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 5570          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0337        |
|    value_loss               | 4.16          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.30939582] |
| time/                       |               |
|    fps                      | 125           |
|    iterations               | 20            |
|    time_elapsed             | 327           |
|    total_timesteps          | 1144832       |
| train/                      |               |
|    approx_kl                | 2235.2397     |
|    approx_ln(kl)            | 7.712104      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.97          |
|    explained_variance       | 0.679         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 5580          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0335        |
|    value_loss               | 2             |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.2118235] |
| time/                       |              |
|    fps                      | 126          |
|    iterations               | 21           |
|    time_elapsed             | 340          |
|    total_timesteps          | 1146880      |
| train/                      |              |
|    approx_kl                | 7037.5103    |
|    approx_ln(kl)            | 8.85901      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.99         |
|    explained_variance       | 0.924        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5590         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0331       |
|    value_loss               | 0.512        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.7753913] |
| time/                       |              |
|    fps                      | 126          |
|    iterations               | 22           |
|    time_elapsed             | 354          |
|    total_timesteps          | 1148928      |
| train/                      |              |
|    approx_kl                | 383.4822     |
|    approx_ln(kl)            | 5.949293     |
|    clip_range               | 0.2          |
|    entropy_loss             | 4            |
|    explained_variance       | 0.992        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5600         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0329       |
|    value_loss               | 8.27         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.48717168] |
| time/                       |               |
|    fps                      | 127           |
|    iterations               | 23            |
|    time_elapsed             | 368           |
|    total_timesteps          | 1150976       |
| train/                      |               |
|    approx_kl                | 626.9838      |
|    approx_ln(kl)            | 6.440921      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.99          |
|    explained_variance       | 0.995         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 5610          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0332        |
|    value_loss               | 9.46          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.7212946] |
| time/                       |              |
|    fps                      | 128          |
|    iterations               | 24           |
|    time_elapsed             | 383          |
|    total_timesteps          | 1153024      |
| train/                      |              |
|    approx_kl                | 390.237      |
|    approx_ln(kl)            | 5.9667544    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.96         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5620         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0338       |
|    value_loss               | 4.4          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5894689] |
| time/                       |              |
|    fps                      | 128          |
|    iterations               | 25           |
|    time_elapsed             | 397          |
|    total_timesteps          | 1155072      |
| train/                      |              |
|    approx_kl                | 535.2916     |
|    approx_ln(kl)            | 6.2828116    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.98         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5630         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0331       |
|    value_loss               | 4.4          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.6044817] |
| time/                       |              |
|    fps                      | 129          |
|    iterations               | 26           |
|    time_elapsed             | 411          |
|    total_timesteps          | 1157120      |
| train/                      |              |
|    approx_kl                | 341.94293    |
|    approx_ln(kl)            | 5.834644     |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.01         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5640         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0327       |
|    value_loss               | 3.59         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.56388897] |
| time/                       |               |
|    fps                      | 130           |
|    iterations               | 27            |
|    time_elapsed             | 425           |
|    total_timesteps          | 1159168       |
| train/                      |               |
|    approx_kl                | 2147.3198     |
|    approx_ln(kl)            | 7.6719756     |
|    clip_range               | 0.2           |
|    entropy_loss             | 4.04          |
|    explained_variance       | 0.995         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 5650          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0324        |
|    value_loss               | 9.09          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.3150141] |
| time/                       |              |
|    fps                      | 130          |
|    iterations               | 28           |
|    time_elapsed             | 439          |
|    total_timesteps          | 1161216      |
| train/                      |              |
|    approx_kl                | 952.1185     |
|    approx_ln(kl)            | 6.85869      |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.09         |
|    explained_variance       | 0.761        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5660         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0315       |
|    value_loss               | 190          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.36618823] |
| time/                       |               |
|    fps                      | 131           |
|    iterations               | 29            |
|    time_elapsed             | 452           |
|    total_timesteps          | 1163264       |
| train/                      |               |
|    approx_kl                | 1411.0745     |
|    approx_ln(kl)            | 7.2521067     |
|    clip_range               | 0.2           |
|    entropy_loss             | 4.09          |
|    explained_variance       | -3.95         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 5670          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0318        |
|    value_loss               | 39.7          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.0112681] |
| time/                       |              |
|    fps                      | 115          |
|    iterations               | 30           |
|    time_elapsed             | 531          |
|    total_timesteps          | 1165312      |
| train/                      |              |
|    approx_kl                | 385.3298     |
|    approx_ln(kl)            | 5.9540997    |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.1          |
|    explained_variance       | 0.793        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5680         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0313       |
|    value_loss               | 64.2         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.33382717] |
| time/                       |               |
|    fps                      | 102           |
|    iterations               | 31            |
|    time_elapsed             | 619           |
|    total_timesteps          | 1167360       |
| train/                      |               |
|    approx_kl                | 1207.7208     |
|    approx_ln(kl)            | 7.0964904     |
|    clip_range               | 0.2           |
|    entropy_loss             | 4.07          |
|    explained_variance       | 0.929         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 5690          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0319        |
|    value_loss               | 82.8          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.0692194] |
| time/                       |              |
|    fps                      | 103          |
|    iterations               | 32           |
|    time_elapsed             | 633          |
|    total_timesteps          | 1169408      |
| train/                      |              |
|    approx_kl                | 525.5005     |
|    approx_ln(kl)            | 6.2643514    |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.06         |
|    explained_variance       | 0.958        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5700         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.032        |
|    value_loss               | 62.9         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.757722] |
| time/                       |             |
|    fps                      | 104         |
|    iterations               | 33          |
|    time_elapsed             | 646         |
|    total_timesteps          | 1171456     |
| train/                      |             |
|    approx_kl                | 729.3024    |
|    approx_ln(kl)            | 6.5920887   |
|    clip_range               | 0.2         |
|    entropy_loss             | 4.07        |
|    explained_variance       | 0.961       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 5710        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0319      |
|    value_loss               | 22.7        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.8885465] |
| time/                       |              |
|    fps                      | 105          |
|    iterations               | 34           |
|    time_elapsed             | 660          |
|    total_timesteps          | 1173504      |
| train/                      |              |
|    approx_kl                | 909.43896    |
|    approx_ln(kl)            | 6.812828     |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.06         |
|    explained_variance       | 0.954        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5720         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.032        |
|    value_loss               | 52.7         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.5490613] |
| time/                       |              |
|    fps                      | 106          |
|    iterations               | 35           |
|    time_elapsed             | 674          |
|    total_timesteps          | 1175552      |
| train/                      |              |
|    approx_kl                | 2155.3943    |
|    approx_ln(kl)            | 7.675729     |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.04         |
|    explained_variance       | 0.984        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5730         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0323       |
|    value_loss               | 35.2         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.554867] |
| time/                       |             |
|    fps                      | 107         |
|    iterations               | 36          |
|    time_elapsed             | 687         |
|    total_timesteps          | 1177600     |
| train/                      |             |
|    approx_kl                | 868.815     |
|    approx_ln(kl)            | 6.7671304   |
|    clip_range               | 0.2         |
|    entropy_loss             | 4.05        |
|    explained_variance       | 0.955       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 5740        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0319      |
|    value_loss               | 63.7        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.8902655] |
| time/                       |              |
|    fps                      | 107          |
|    iterations               | 37           |
|    time_elapsed             | 701          |
|    total_timesteps          | 1179648      |
| train/                      |              |
|    approx_kl                | 828.97986    |
|    approx_ln(kl)            | 6.720196     |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.06         |
|    explained_variance       | 0.955        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5750         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.032        |
|    value_loss               | 80           |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-5.679358] |
| time/                       |             |
|    fps                      | 107         |
|    iterations               | 38          |
|    time_elapsed             | 723         |
|    total_timesteps          | 1181696     |
| train/                      |             |
|    approx_kl                | 1039.7219   |
|    approx_ln(kl)            | 6.9467087   |
|    clip_range               | 0.2         |
|    entropy_loss             | 4.04        |
|    explained_variance       | 0.981       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 5760        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0327      |
|    value_loss               | 31.6        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.44970927] |
| time/                       |               |
|    fps                      | 108           |
|    iterations               | 39            |
|    time_elapsed             | 737           |
|    total_timesteps          | 1183744       |
| train/                      |               |
|    approx_kl                | 926.66003     |
|    approx_ln(kl)            | 6.831587      |
|    clip_range               | 0.2           |
|    entropy_loss             | 4.05          |
|    explained_variance       | 0.986         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 5770          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0321        |
|    value_loss               | 23.5          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.5817343] |
| time/                       |              |
|    fps                      | 109          |
|    iterations               | 40           |
|    time_elapsed             | 751          |
|    total_timesteps          | 1185792      |
| train/                      |              |
|    approx_kl                | 544.77734    |
|    approx_ln(kl)            | 6.3003774    |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.02         |
|    explained_variance       | 0.97         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5780         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0327       |
|    value_loss               | 25.9         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.317062] |
| time/                       |             |
|    fps                      | 109         |
|    iterations               | 41          |
|    time_elapsed             | 765         |
|    total_timesteps          | 1187840     |
| train/                      |             |
|    approx_kl                | 261.513     |
|    approx_ln(kl)            | 5.566484    |
|    clip_range               | 0.2         |
|    entropy_loss             | 4.02        |
|    explained_variance       | 0.894       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 5790        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0326      |
|    value_loss               | 57.5        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.3057334] |
| time/                       |              |
|    fps                      | 110          |
|    iterations               | 42           |
|    time_elapsed             | 778          |
|    total_timesteps          | 1189888      |
| train/                      |              |
|    approx_kl                | 412.94897    |
|    approx_ln(kl)            | 6.023324     |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.02         |
|    explained_variance       | 0.899        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5800         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0326       |
|    value_loss               | 87.1         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.277102] |
| time/                       |             |
|    fps                      | 111         |
|    iterations               | 43          |
|    time_elapsed             | 792         |
|    total_timesteps          | 1191936     |
| train/                      |             |
|    approx_kl                | 1019.5945   |
|    approx_ln(kl)            | 6.9271603   |
|    clip_range               | 0.2         |
|    entropy_loss             | 4           |
|    explained_variance       | 0.987       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 5810        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0331      |
|    value_loss               | 7.68        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.5142202] |
| time/                       |              |
|    fps                      | 111          |
|    iterations               | 44           |
|    time_elapsed             | 806          |
|    total_timesteps          | 1193984      |
| train/                      |              |
|    approx_kl                | 457.89233    |
|    approx_ln(kl)            | 6.126634     |
|    clip_range               | 0.2          |
|    entropy_loss             | 4            |
|    explained_variance       | 0.956        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5820         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0331       |
|    value_loss               | 49.4         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.393634] |
| time/                       |             |
|    fps                      | 112         |
|    iterations               | 45          |
|    time_elapsed             | 820         |
|    total_timesteps          | 1196032     |
| train/                      |             |
|    approx_kl                | 1694.1526   |
|    approx_ln(kl)            | 7.434938    |
|    clip_range               | 0.2         |
|    entropy_loss             | 4           |
|    explained_variance       | 0.492       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 5830        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.033       |
|    value_loss               | 74.8        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.140552] |
| time/                       |             |
|    fps                      | 112         |
|    iterations               | 46          |
|    time_elapsed             | 834         |
|    total_timesteps          | 1198080     |
| train/                      |             |
|    approx_kl                | 1133.3428   |
|    approx_ln(kl)            | 7.0329266   |
|    clip_range               | 0.2         |
|    entropy_loss             | 4.02        |
|    explained_variance       | 0.945       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 5840        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0327      |
|    value_loss               | 25.3        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.350015] |
| time/                       |             |
|    fps                      | 113         |
|    iterations               | 47          |
|    time_elapsed             | 849         |
|    total_timesteps          | 1200128     |
| train/                      |             |
|    approx_kl                | 1779.3947   |
|    approx_ln(kl)            | 7.4840283   |
|    clip_range               | 0.2         |
|    entropy_loss             | 4.07        |
|    explained_variance       | 0.954       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 5850        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.032       |
|    value_loss               | 23.1        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.6852736] |
| time/                       |              |
|    fps                      | 113          |
|    iterations               | 48           |
|    time_elapsed             | 863          |
|    total_timesteps          | 1202176      |
| train/                      |              |
|    approx_kl                | 1151.3942    |
|    approx_ln(kl)            | 7.048729     |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.09         |
|    explained_variance       | 0.528        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5860         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0317       |
|    value_loss               | 35.7         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.7158093] |
| time/                       |              |
|    fps                      | 114          |
|    iterations               | 49           |
|    time_elapsed             | 877          |
|    total_timesteps          | 1204224      |
| train/                      |              |
|    approx_kl                | 868.49066    |
|    approx_ln(kl)            | 6.766757     |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.08         |
|    explained_variance       | 0.743        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5870         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0318       |
|    value_loss               | 33.7         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
------------------------------------
| reward             | [-1.313728] |
| time/              |             |
|    fps             | 161         |
|    iterations      | 1           |
|    time_elapsed    | 12          |
|    total_timesteps | 1206272     |
------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.7298334] |
| time/                       |              |
|    fps                      | 155          |
|    iterations               | 2            |
|    time_elapsed             | 26           |
|    total_timesteps          | 1208320      |
| train/                      |              |
|    approx_kl                | 905.8413     |
|    approx_ln(kl)            | 6.808864     |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.08         |
|    explained_variance       | 0.951        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5890         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0319       |
|    value_loss               | 18.2         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.5600479] |
| time/                       |              |
|    fps                      | 152          |
|    iterations               | 3            |
|    time_elapsed             | 40           |
|    total_timesteps          | 1210368      |
| train/                      |              |
|    approx_kl                | 3795.263     |
|    approx_ln(kl)            | 8.241509     |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.08         |
|    explained_variance       | 0.94         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5900         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0318       |
|    value_loss               | 20           |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.8324246] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 4            |
|    time_elapsed             | 54           |
|    total_timesteps          | 1212416      |
| train/                      |              |
|    approx_kl                | 2112.0977    |
|    approx_ln(kl)            | 7.655437     |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.08         |
|    explained_variance       | 0.988        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5910         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0318       |
|    value_loss               | 10.6         |
----------------------------------------------
----------------------------------------------
| reward                      | [-1.4767219] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 5            |
|    time_elapsed             | 69           |
|    total_timesteps          | 1214464      |
| train/                      |              |
|    approx_kl                | 964.10614    |
|    approx_ln(kl)            | 6.8712015    |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.04         |
|    explained_variance       | 0.988        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 5920         |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0324       |
|    value_loss               | 12.2         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.35833305] |
| time/                       |               |
|    fps                      | 147           |
|    iterations               | 6             |
|    time_elapsed             | 83            |
|    total_timesteps          | 1216512       |
| train/                      |               |
|    approx_kl                | 2737.0908     |
|    approx_ln(kl)            | 7.914651      |
|    clip_range               | 0.2           |
|    entropy_loss             | 4.02          |
|    explained_variance       | 0.977         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 5930          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0327        |
|    value_loss               | 6.86          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.899506] |
| time/                       |             |
|    fps                      | 147         |
|    iterations               | 7           |
|    time_elapsed             | 97          |
|    total_timesteps          | 1218560     |
| train/                      |             |
|    approx_kl                | 984.8436    |
|    approx_ln(kl)            | 6.8924828   |
|    clip_range               | 0.2         |
|    entropy_loss             | 4           |
|    explained_variance       | 0.903       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 5940        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0329      |
|    value_loss               | 11.5        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.1394391] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 8            |
|    time_elapsed             | 111          |
|    total_timesteps          | 1220608      |
| train/                      |              |
|    approx_kl                | 1444.2856    |
|    approx_ln(kl)            | 7.27537      |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.03         |
|    explained_variance       | 0.968        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5950         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0324       |
|    value_loss               | 22.3         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.9351841] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 9            |
|    time_elapsed             | 124          |
|    total_timesteps          | 1222656      |
| train/                      |              |
|    approx_kl                | 1254.8524    |
|    approx_ln(kl)            | 7.1347733    |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.04         |
|    explained_variance       | 0.952        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 5960         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0322       |
|    value_loss               | 22.3         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-5.487519] |
| time/                       |             |
|    fps                      | 147         |
|    iterations               | 10          |
|    time_elapsed             | 138         |
|    total_timesteps          | 1224704     |
| train/                      |             |
|    approx_kl                | 2613.6414   |
|    approx_ln(kl)            | 7.8684998   |
|    clip_range               | 0.2         |
|    entropy_loss             | 4.04        |
|    explained_variance       | 0.931       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 5970        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0323      |
|    value_loss               | 10.7        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.64136523] |
| time/                       |               |
|    fps                      | 147           |
|    iterations               | 11            |
|    time_elapsed             | 152           |
|    total_timesteps          | 1226752       |
| train/                      |               |
|    approx_kl                | 2860.112      |
|    approx_ln(kl)            | 7.9586163     |
|    clip_range               | 0.2           |
|    entropy_loss             | 4.03          |
|    explained_variance       | 0.983         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 5980          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0324        |
|    value_loss               | 18.1          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.45568746] |
| time/                       |               |
|    fps                      | 147           |
|    iterations               | 12            |
|    time_elapsed             | 166           |
|    total_timesteps          | 1228800       |
| train/                      |               |
|    approx_kl                | 696.40295     |
|    approx_ln(kl)            | 6.5459285     |
|    clip_range               | 0.2           |
|    entropy_loss             | 4.02          |
|    explained_variance       | 0.989         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 5990          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0325        |
|    value_loss               | 7.98          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
--------------------------------------------
| reward                      | [-2.40389] |
| time/                       |            |
|    fps                      | 147        |
|    iterations               | 13         |
|    time_elapsed             | 180        |
|    total_timesteps          | 1230848    |
| train/                      |            |
|    approx_kl                | 2308.9805  |
|    approx_ln(kl)            | 7.744561   |
|    clip_range               | 0.2        |
|    entropy_loss             | 4.02       |
|    explained_variance       | 0.981      |
|    learning_rate            | 0.001      |
|    ln(loss)                 | inf        |
|    ln(policy_gradient_loss) | nan        |
|    loss                     | inf        |
|    n_updates                | 6000       |
|    policy_gradient_loss     | nan        |
|    std                      | 0.0327     |
|    value_loss               | 6.88       |
--------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.8344397] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 14           |
|    time_elapsed             | 194          |
|    total_timesteps          | 1232896      |
| train/                      |              |
|    approx_kl                | 1105.409     |
|    approx_ln(kl)            | 7.007971     |
|    clip_range               | 0.2          |
|    entropy_loss             | 4            |
|    explained_variance       | 0.966        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6010         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0329       |
|    value_loss               | 7.75         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.6110177] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 15           |
|    time_elapsed             | 208          |
|    total_timesteps          | 1234944      |
| train/                      |              |
|    approx_kl                | 787.9247     |
|    approx_ln(kl)            | 6.6694026    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.99         |
|    explained_variance       | 0.979        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6020         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0329       |
|    value_loss               | 18.5         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.010475] |
| time/                       |             |
|    fps                      | 104         |
|    iterations               | 16          |
|    time_elapsed             | 314         |
|    total_timesteps          | 1236992     |
| train/                      |             |
|    approx_kl                | 425.42023   |
|    approx_ln(kl)            | 6.0530777   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.99        |
|    explained_variance       | 0.976       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 6030        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0332      |
|    value_loss               | 27.1        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.2777658] |
| time/                       |              |
|    fps                      | 101          |
|    iterations               | 17           |
|    time_elapsed             | 343          |
|    total_timesteps          | 1239040      |
| train/                      |              |
|    approx_kl                | 939.3385     |
|    approx_ln(kl)            | 6.8451757    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.97         |
|    explained_variance       | 0.985        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6040         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0333       |
|    value_loss               | 13.3         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-1.045212] |
| time/                       |             |
|    fps                      | 103         |
|    iterations               | 18          |
|    time_elapsed             | 357         |
|    total_timesteps          | 1241088     |
| train/                      |             |
|    approx_kl                | 1318.5559   |
|    approx_ln(kl)            | 7.1842923   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.97        |
|    explained_variance       | 0.991       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 6050        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0333      |
|    value_loss               | 9.27        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-0.930018] |
| time/                       |             |
|    fps                      | 104         |
|    iterations               | 19          |
|    time_elapsed             | 371         |
|    total_timesteps          | 1243136     |
| train/                      |             |
|    approx_kl                | 2325.063    |
|    approx_ln(kl)            | 7.7515025   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.99        |
|    explained_variance       | 0.996       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 6060        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.033       |
|    value_loss               | 4.96        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.9879812] |
| time/                       |              |
|    fps                      | 106          |
|    iterations               | 20           |
|    time_elapsed             | 384          |
|    total_timesteps          | 1245184      |
| train/                      |              |
|    approx_kl                | 1676.2798    |
|    approx_ln(kl)            | 7.424332     |
|    clip_range               | 0.2          |
|    entropy_loss             | 4            |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6070         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0328       |
|    value_loss               | 2.79         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4592913] |
| time/                       |              |
|    fps                      | 107          |
|    iterations               | 21           |
|    time_elapsed             | 398          |
|    total_timesteps          | 1247232      |
| train/                      |              |
|    approx_kl                | 1469.4006    |
|    approx_ln(kl)            | 7.2926097    |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.01         |
|    explained_variance       | 0.979        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6080         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0327       |
|    value_loss               | 7.51         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7614547] |
| time/                       |              |
|    fps                      | 109          |
|    iterations               | 22           |
|    time_elapsed             | 412          |
|    total_timesteps          | 1249280      |
| train/                      |              |
|    approx_kl                | 1679.9541    |
|    approx_ln(kl)            | 7.426522     |
|    clip_range               | 0.2          |
|    entropy_loss             | 4            |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6090         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0325       |
|    value_loss               | 1.83         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.63041747] |
| time/                       |               |
|    fps                      | 110           |
|    iterations               | 23            |
|    time_elapsed             | 426           |
|    total_timesteps          | 1251328       |
| train/                      |               |
|    approx_kl                | 6551.739      |
|    approx_ln(kl)            | 8.787486      |
|    clip_range               | 0.2           |
|    entropy_loss             | 4.04          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 6100          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0321        |
|    value_loss               | 0.463         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.1502001] |
| time/                       |              |
|    fps                      | 111          |
|    iterations               | 24           |
|    time_elapsed             | 440          |
|    total_timesteps          | 1253376      |
| train/                      |              |
|    approx_kl                | 2841.798     |
|    approx_ln(kl)            | 7.9521923    |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.04         |
|    explained_variance       | 0.976        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6110         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0322       |
|    value_loss               | 2.08         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.1979238] |
| time/                       |              |
|    fps                      | 112          |
|    iterations               | 25           |
|    time_elapsed             | 454          |
|    total_timesteps          | 1255424      |
| train/                      |              |
|    approx_kl                | 2544.126     |
|    approx_ln(kl)            | 7.8415422    |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.01         |
|    explained_variance       | 0.974        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6120         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0326       |
|    value_loss               | 2.35         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.4391271] |
| time/                       |              |
|    fps                      | 113          |
|    iterations               | 26           |
|    time_elapsed             | 468          |
|    total_timesteps          | 1257472      |
| train/                      |              |
|    approx_kl                | 14974.434    |
|    approx_ln(kl)            | 9.6140995    |
|    clip_range               | 0.2          |
|    entropy_loss             | 4            |
|    explained_variance       | 0.97         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6130         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0329       |
|    value_loss               | 2.09         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.5043781] |
| time/                       |              |
|    fps                      | 114          |
|    iterations               | 27           |
|    time_elapsed             | 482          |
|    total_timesteps          | 1259520      |
| train/                      |              |
|    approx_kl                | 3739.306     |
|    approx_ln(kl)            | 8.226655     |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.02         |
|    explained_variance       | 0.989        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6140         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0323       |
|    value_loss               | 0.411        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.9452833] |
| time/                       |              |
|    fps                      | 115          |
|    iterations               | 28           |
|    time_elapsed             | 495          |
|    total_timesteps          | 1261568      |
| train/                      |              |
|    approx_kl                | 2897.3462    |
|    approx_ln(kl)            | 7.9715505    |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.03         |
|    explained_variance       | 0.991        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6150         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0323       |
|    value_loss               | 0.744        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.72282755] |
| time/                       |               |
|    fps                      | 116           |
|    iterations               | 29            |
|    time_elapsed             | 509           |
|    total_timesteps          | 1263616       |
| train/                      |               |
|    approx_kl                | 6333.26       |
|    approx_ln(kl)            | 8.753571      |
|    clip_range               | 0.2           |
|    entropy_loss             | 4.02          |
|    explained_variance       | 0.997         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 6160          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0325        |
|    value_loss               | 1.07          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6657745] |
| time/                       |              |
|    fps                      | 117          |
|    iterations               | 30           |
|    time_elapsed             | 523          |
|    total_timesteps          | 1265664      |
| train/                      |              |
|    approx_kl                | 5306.1416    |
|    approx_ln(kl)            | 8.57662      |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.02         |
|    explained_variance       | 0.989        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6170         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0324       |
|    value_loss               | 0.326        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4205354] |
| time/                       |              |
|    fps                      | 118          |
|    iterations               | 31           |
|    time_elapsed             | 537          |
|    total_timesteps          | 1267712      |
| train/                      |              |
|    approx_kl                | 1635.3586    |
|    approx_ln(kl)            | 7.399617     |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.01         |
|    explained_variance       | 0.991        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6180         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0326       |
|    value_loss               | 0.658        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4449185] |
| time/                       |              |
|    fps                      | 118          |
|    iterations               | 32           |
|    time_elapsed             | 551          |
|    total_timesteps          | 1269760      |
| train/                      |              |
|    approx_kl                | 3253.231     |
|    approx_ln(kl)            | 8.087404     |
|    clip_range               | 0.2          |
|    entropy_loss             | 4            |
|    explained_variance       | 0.885        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6190         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0328       |
|    value_loss               | 1.81         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5390752] |
| time/                       |              |
|    fps                      | 119          |
|    iterations               | 33           |
|    time_elapsed             | 564          |
|    total_timesteps          | 1271808      |
| train/                      |              |
|    approx_kl                | 4802.8135    |
|    approx_ln(kl)            | 8.476957     |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.01         |
|    explained_variance       | 0.919        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6200         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0327       |
|    value_loss               | 1.1          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.61442757] |
| time/                       |               |
|    fps                      | 120           |
|    iterations               | 34            |
|    time_elapsed             | 579           |
|    total_timesteps          | 1273856       |
| train/                      |               |
|    approx_kl                | 8330.232      |
|    approx_ln(kl)            | 9.027647      |
|    clip_range               | 0.2           |
|    entropy_loss             | 4             |
|    explained_variance       | 0.937         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 6210          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0327        |
|    value_loss               | 0.538         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6288196] |
| time/                       |              |
|    fps                      | 120          |
|    iterations               | 35           |
|    time_elapsed             | 594          |
|    total_timesteps          | 1275904      |
| train/                      |              |
|    approx_kl                | 4512.4585    |
|    approx_ln(kl)            | 8.4145975    |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.02         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6220         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0324       |
|    value_loss               | 1.46         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4490581] |
| time/                       |              |
|    fps                      | 121          |
|    iterations               | 36           |
|    time_elapsed             | 608          |
|    total_timesteps          | 1277952      |
| train/                      |              |
|    approx_kl                | 13822.372    |
|    approx_ln(kl)            | 9.534043     |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.02         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6230         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0325       |
|    value_loss               | 0.302        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6267098] |
| time/                       |              |
|    fps                      | 121          |
|    iterations               | 37           |
|    time_elapsed             | 622          |
|    total_timesteps          | 1280000      |
| train/                      |              |
|    approx_kl                | 8614.658     |
|    approx_ln(kl)            | 9.06122      |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.03         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6240         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0322       |
|    value_loss               | 0.17         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.47663704] |
| time/                       |               |
|    fps                      | 122           |
|    iterations               | 38            |
|    time_elapsed             | 635           |
|    total_timesteps          | 1282048       |
| train/                      |               |
|    approx_kl                | 14132.637     |
|    approx_ln(kl)            | 9.556242      |
|    clip_range               | 0.2           |
|    entropy_loss             | 4.03          |
|    explained_variance       | 0.993         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 6250          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0323        |
|    value_loss               | 0.0963        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.91107506] |
| time/                       |               |
|    fps                      | 122           |
|    iterations               | 39            |
|    time_elapsed             | 649           |
|    total_timesteps          | 1284096       |
| train/                      |               |
|    approx_kl                | 3994.3997     |
|    approx_ln(kl)            | 8.292648      |
|    clip_range               | 0.2           |
|    entropy_loss             | 4.02          |
|    explained_variance       | 0.995         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 6260          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0325        |
|    value_loss               | 0.538         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.89838606] |
| time/                       |               |
|    fps                      | 123           |
|    iterations               | 40            |
|    time_elapsed             | 663           |
|    total_timesteps          | 1286144       |
| train/                      |               |
|    approx_kl                | 1512.5349     |
|    approx_ln(kl)            | 7.3215423     |
|    clip_range               | 0.2           |
|    entropy_loss             | 4.02          |
|    explained_variance       | 0.98          |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 6270          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0325        |
|    value_loss               | 0.526         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.2918588] |
| time/                       |              |
|    fps                      | 123          |
|    iterations               | 41           |
|    time_elapsed             | 677          |
|    total_timesteps          | 1288192      |
| train/                      |              |
|    approx_kl                | 5021.0737    |
|    approx_ln(kl)            | 8.5213995    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.97         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6280         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0333       |
|    value_loss               | 0.317        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.42023957] |
| time/                       |               |
|    fps                      | 124           |
|    iterations               | 42            |
|    time_elapsed             | 691           |
|    total_timesteps          | 1290240       |
| train/                      |               |
|    approx_kl                | 1824.7804     |
|    approx_ln(kl)            | 7.509215      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.95          |
|    explained_variance       | 0.997         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 6290          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0336        |
|    value_loss               | 0.221         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7837841] |
| time/                       |              |
|    fps                      | 124          |
|    iterations               | 43           |
|    time_elapsed             | 704          |
|    total_timesteps          | 1292288      |
| train/                      |              |
|    approx_kl                | 3163.062     |
|    approx_ln(kl)            | 8.059296     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.94         |
|    explained_variance       | 0.983        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6300         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0337       |
|    value_loss               | 0.347        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.77215976] |
| time/                       |               |
|    fps                      | 125           |
|    iterations               | 44            |
|    time_elapsed             | 718           |
|    total_timesteps          | 1294336       |
| train/                      |               |
|    approx_kl                | 2728.9175     |
|    approx_ln(kl)            | 7.91166       |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.88          |
|    explained_variance       | 0.992         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 6310          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0348        |
|    value_loss               | 0.339         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4375482] |
| time/                       |              |
|    fps                      | 125          |
|    iterations               | 45           |
|    time_elapsed             | 732          |
|    total_timesteps          | 1296384      |
| train/                      |              |
|    approx_kl                | 3189.3196    |
|    approx_ln(kl)            | 8.067563     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.85         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6320         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0353       |
|    value_loss               | 0.214        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6687493] |
| time/                       |              |
|    fps                      | 126          |
|    iterations               | 46           |
|    time_elapsed             | 746          |
|    total_timesteps          | 1298432      |
| train/                      |              |
|    approx_kl                | 3135.5752    |
|    approx_ln(kl)            | 8.050568     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.84         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6330         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0356       |
|    value_loss               | 0.0754       |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.6607463] |
| time/                       |              |
|    fps                      | 126          |
|    iterations               | 47           |
|    time_elapsed             | 760          |
|    total_timesteps          | 1300480      |
| train/                      |              |
|    approx_kl                | 1831.871     |
|    approx_ln(kl)            | 7.513093     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.8          |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6340         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0363       |
|    value_loss               | 0.088        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.4252115] |
| time/                       |              |
|    fps                      | 127          |
|    iterations               | 48           |
|    time_elapsed             | 774          |
|    total_timesteps          | 1302528      |
| train/                      |              |
|    approx_kl                | 2500.9766    |
|    approx_ln(kl)            | 7.8244367    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.79         |
|    explained_variance       | 0.98         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6350         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0363       |
|    value_loss               | 3.22         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7836661] |
| time/                       |              |
|    fps                      | 127          |
|    iterations               | 49           |
|    time_elapsed             | 788          |
|    total_timesteps          | 1304576      |
| train/                      |              |
|    approx_kl                | 1487.0581    |
|    approx_ln(kl)            | 7.304555     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.8          |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6360         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0363       |
|    value_loss               | 1.55         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------
| reward             | [-0.54408] |
| time/              |            |
|    fps             | 162        |
|    iterations      | 1          |
|    time_elapsed    | 12         |
|    total_timesteps | 1306624    |
-----------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.7370403] |
| time/                       |              |
|    fps                      | 155          |
|    iterations               | 2            |
|    time_elapsed             | 26           |
|    total_timesteps          | 1308672      |
| train/                      |              |
|    approx_kl                | 3564.8936    |
|    approx_ln(kl)            | 8.178889     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.81         |
|    explained_variance       | 0.978        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6380         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0361       |
|    value_loss               | 2.32         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.5952353] |
| time/                       |              |
|    fps                      | 152          |
|    iterations               | 3            |
|    time_elapsed             | 40           |
|    total_timesteps          | 1310720      |
| train/                      |              |
|    approx_kl                | 662.20496    |
|    approx_ln(kl)            | 6.495575     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.8          |
|    explained_variance       | 0.98         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6390         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0364       |
|    value_loss               | 4.31         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0525981] |
| time/                       |              |
|    fps                      | 150          |
|    iterations               | 4            |
|    time_elapsed             | 54           |
|    total_timesteps          | 1312768      |
| train/                      |              |
|    approx_kl                | 712.10394    |
|    approx_ln(kl)            | 6.568224     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.79         |
|    explained_variance       | 0.971        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6400         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0366       |
|    value_loss               | 7.33         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.93345124] |
| time/                       |               |
|    fps                      | 148           |
|    iterations               | 5             |
|    time_elapsed             | 68            |
|    total_timesteps          | 1314816       |
| train/                      |               |
|    approx_kl                | 2212.103      |
|    approx_ln(kl)            | 7.701699      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.77          |
|    explained_variance       | 0.994         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 6410          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0367        |
|    value_loss               | 2.01          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.2870097] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 6            |
|    time_elapsed             | 82           |
|    total_timesteps          | 1316864      |
| train/                      |              |
|    approx_kl                | 650.6613     |
|    approx_ln(kl)            | 6.477989     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.77         |
|    explained_variance       | 0.986        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6420         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0368       |
|    value_loss               | 7.02         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.4889193] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 7            |
|    time_elapsed             | 96           |
|    total_timesteps          | 1318912      |
| train/                      |              |
|    approx_kl                | 1177.7603    |
|    approx_ln(kl)            | 7.0713696    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.77         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6430         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0368       |
|    value_loss               | 2.61         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.1168672] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 8            |
|    time_elapsed             | 110          |
|    total_timesteps          | 1320960      |
| train/                      |              |
|    approx_kl                | 6630.088     |
|    approx_ln(kl)            | 8.799374     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.77         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6440         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0367       |
|    value_loss               | 1.93         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
--------------------------------------------
| reward                      | [-1.87937] |
| time/                       |            |
|    fps                      | 148        |
|    iterations               | 9          |
|    time_elapsed             | 124        |
|    total_timesteps          | 1323008    |
| train/                      |            |
|    approx_kl                | 1402.7788  |
|    approx_ln(kl)            | 7.2462106  |
|    clip_range               | 0.2        |
|    entropy_loss             | 3.75       |
|    explained_variance       | 0.995      |
|    learning_rate            | 0.001      |
|    ln(loss)                 | inf        |
|    ln(policy_gradient_loss) | nan        |
|    loss                     | inf        |
|    n_updates                | 6450       |
|    policy_gradient_loss     | nan        |
|    std                      | 0.0374     |
|    value_loss               | 4.27       |
--------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.7098204] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 10           |
|    time_elapsed             | 138          |
|    total_timesteps          | 1325056      |
| train/                      |              |
|    approx_kl                | 3820.543     |
|    approx_ln(kl)            | 8.248148     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.69         |
|    explained_variance       | 0.988        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6460         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0384       |
|    value_loss               | 1.7          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.4927152] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 11           |
|    time_elapsed             | 152          |
|    total_timesteps          | 1327104      |
| train/                      |              |
|    approx_kl                | 2059.9124    |
|    approx_ln(kl)            | 7.630419     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.69         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6470         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0384       |
|    value_loss               | 0.515        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.2462002] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 12           |
|    time_elapsed             | 166          |
|    total_timesteps          | 1329152      |
| train/                      |              |
|    approx_kl                | 2641.0425    |
|    approx_ln(kl)            | 7.878929     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.69         |
|    explained_variance       | 0.941        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6480         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0384       |
|    value_loss               | 0.946        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.58658993] |
| time/                       |               |
|    fps                      | 122           |
|    iterations               | 13            |
|    time_elapsed             | 217           |
|    total_timesteps          | 1331200       |
| train/                      |               |
|    approx_kl                | 4468.5703     |
|    approx_ln(kl)            | 8.404824      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.69          |
|    explained_variance       | 0.997         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 6490          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0383        |
|    value_loss               | 1.43          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5044794] |
| time/                       |              |
|    fps                      | 124          |
|    iterations               | 14           |
|    time_elapsed             | 230          |
|    total_timesteps          | 1333248      |
| train/                      |              |
|    approx_kl                | 2490.0127    |
|    approx_ln(kl)            | 7.820043     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.67         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6500         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0386       |
|    value_loss               | 0.497        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.4223046] |
| time/                       |              |
|    fps                      | 125          |
|    iterations               | 15           |
|    time_elapsed             | 244          |
|    total_timesteps          | 1335296      |
| train/                      |              |
|    approx_kl                | 2175.4976    |
|    approx_ln(kl)            | 7.685013     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.66         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6510         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0388       |
|    value_loss               | 0.84         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7715358] |
| time/                       |              |
|    fps                      | 126          |
|    iterations               | 16           |
|    time_elapsed             | 258          |
|    total_timesteps          | 1337344      |
| train/                      |              |
|    approx_kl                | 4684.4883    |
|    approx_ln(kl)            | 8.452012     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.63         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6520         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0395       |
|    value_loss               | 0.161        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.8065776] |
| time/                       |              |
|    fps                      | 127          |
|    iterations               | 17           |
|    time_elapsed             | 272          |
|    total_timesteps          | 1339392      |
| train/                      |              |
|    approx_kl                | 2715.8599    |
|    approx_ln(kl)            | 7.906864     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.64         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6530         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0391       |
|    value_loss               | 0.202        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0388795] |
| time/                       |              |
|    fps                      | 128          |
|    iterations               | 18           |
|    time_elapsed             | 287          |
|    total_timesteps          | 1341440      |
| train/                      |              |
|    approx_kl                | 3024.7998    |
|    approx_ln(kl)            | 8.0146       |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.65         |
|    explained_variance       | 0.992        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6540         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0391       |
|    value_loss               | 0.443        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.94585145] |
| time/                       |               |
|    fps                      | 124           |
|    iterations               | 19            |
|    time_elapsed             | 312           |
|    total_timesteps          | 1343488       |
| train/                      |               |
|    approx_kl                | 774.9983      |
|    approx_ln(kl)            | 6.6528606     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.65          |
|    explained_variance       | 0.997         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 6550          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0391        |
|    value_loss               | 0.735         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.45789477] |
| time/                       |               |
|    fps                      | 124           |
|    iterations               | 20            |
|    time_elapsed             | 328           |
|    total_timesteps          | 1345536       |
| train/                      |               |
|    approx_kl                | 1698.5078     |
|    approx_ln(kl)            | 7.4375052     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.62          |
|    explained_variance       | 0.996         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 6560          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0401        |
|    value_loss               | 0.508         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.61960095] |
| time/                       |               |
|    fps                      | 101           |
|    iterations               | 21            |
|    time_elapsed             | 423           |
|    total_timesteps          | 1347584       |
| train/                      |               |
|    approx_kl                | 989.1087      |
|    approx_ln(kl)            | 6.8968043     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.6           |
|    explained_variance       | 0.995         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 6570          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0402        |
|    value_loss               | 0.458         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.50984365] |
| time/                       |               |
|    fps                      | 102           |
|    iterations               | 22            |
|    time_elapsed             | 440           |
|    total_timesteps          | 1349632       |
| train/                      |               |
|    approx_kl                | 2250.9727     |
|    approx_ln(kl)            | 7.7191176     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.55          |
|    explained_variance       | 0.991         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 6580          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0411        |
|    value_loss               | 0.232         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.2064431] |
| time/                       |              |
|    fps                      | 103          |
|    iterations               | 23           |
|    time_elapsed             | 454          |
|    total_timesteps          | 1351680      |
| train/                      |              |
|    approx_kl                | 4104.9844    |
|    approx_ln(kl)            | 8.319957     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.53         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6590         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0414       |
|    value_loss               | 0.0877       |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.25041676] |
| time/                       |               |
|    fps                      | 104           |
|    iterations               | 24            |
|    time_elapsed             | 468           |
|    total_timesteps          | 1353728       |
| train/                      |               |
|    approx_kl                | 3259.9558     |
|    approx_ln(kl)            | 8.089469      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.53          |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 6600          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0414        |
|    value_loss               | 0.158         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.89005184] |
| time/                       |               |
|    fps                      | 106           |
|    iterations               | 25            |
|    time_elapsed             | 481           |
|    total_timesteps          | 1355776       |
| train/                      |               |
|    approx_kl                | 9538.801      |
|    approx_ln(kl)            | 9.163123      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.56          |
|    explained_variance       | 0.983         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 6610          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0408        |
|    value_loss               | 0.753         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.51314443] |
| time/                       |               |
|    fps                      | 107           |
|    iterations               | 26            |
|    time_elapsed             | 495           |
|    total_timesteps          | 1357824       |
| train/                      |               |
|    approx_kl                | 4321.796      |
|    approx_ln(kl)            | 8.371427      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.57          |
|    explained_variance       | 0.997         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 6620          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0405        |
|    value_loss               | 0.302         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.58670527] |
| time/                       |               |
|    fps                      | 108           |
|    iterations               | 27            |
|    time_elapsed             | 509           |
|    total_timesteps          | 1359872       |
| train/                      |               |
|    approx_kl                | 5044.5513     |
|    approx_ln(kl)            | 8.526064      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.57          |
|    explained_variance       | 1             |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 6630          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0407        |
|    value_loss               | 0.0847        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-1.264928] |
| time/                       |             |
|    fps                      | 109         |
|    iterations               | 28          |
|    time_elapsed             | 522         |
|    total_timesteps          | 1361920     |
| train/                      |             |
|    approx_kl                | 4828.409    |
|    approx_ln(kl)            | 8.482272    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.53        |
|    explained_variance       | 1           |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 6640        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0414      |
|    value_loss               | 0.0824      |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5842797] |
| time/                       |              |
|    fps                      | 110          |
|    iterations               | 29           |
|    time_elapsed             | 536          |
|    total_timesteps          | 1363968      |
| train/                      |              |
|    approx_kl                | 2205.144     |
|    approx_ln(kl)            | 7.6985483    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.52         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6650         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0416       |
|    value_loss               | 0.105        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.46027994] |
| time/                       |               |
|    fps                      | 111           |
|    iterations               | 30            |
|    time_elapsed             | 550           |
|    total_timesteps          | 1366016       |
| train/                      |               |
|    approx_kl                | 4530.9556     |
|    approx_ln(kl)            | 8.418688      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.55          |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 6660          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0409        |
|    value_loss               | 0.111         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.3958171] |
| time/                       |              |
|    fps                      | 112          |
|    iterations               | 31           |
|    time_elapsed             | 564          |
|    total_timesteps          | 1368064      |
| train/                      |              |
|    approx_kl                | 2686.107     |
|    approx_ln(kl)            | 7.8958483    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.56         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6670         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0408       |
|    value_loss               | 0.0534       |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.58290327] |
| time/                       |               |
|    fps                      | 98            |
|    iterations               | 32            |
|    time_elapsed             | 667           |
|    total_timesteps          | 1370112       |
| train/                      |               |
|    approx_kl                | 5614.8823     |
|    approx_ln(kl)            | 8.633176      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.56          |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 6680          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0409        |
|    value_loss               | 0.13          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.3515159] |
| time/                       |              |
|    fps                      | 99           |
|    iterations               | 33           |
|    time_elapsed             | 681          |
|    total_timesteps          | 1372160      |
| train/                      |              |
|    approx_kl                | 3412.037     |
|    approx_ln(kl)            | 8.135065     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.55         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6690         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.041        |
|    value_loss               | 0.267        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.51331073] |
| time/                       |               |
|    fps                      | 99            |
|    iterations               | 34            |
|    time_elapsed             | 696           |
|    total_timesteps          | 1374208       |
| train/                      |               |
|    approx_kl                | 1814.2919     |
|    approx_ln(kl)            | 7.5034504     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.54          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 6700          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0413        |
|    value_loss               | 0.144         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.58779925] |
| time/                       |               |
|    fps                      | 100           |
|    iterations               | 35            |
|    time_elapsed             | 710           |
|    total_timesteps          | 1376256       |
| train/                      |               |
|    approx_kl                | 2238.7102     |
|    approx_ln(kl)            | 7.713655      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.53          |
|    explained_variance       | 0.996         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 6710          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0415        |
|    value_loss               | 0.733         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.42744425] |
| time/                       |               |
|    fps                      | 101           |
|    iterations               | 36            |
|    time_elapsed             | 724           |
|    total_timesteps          | 1378304       |
| train/                      |               |
|    approx_kl                | 506.648       |
|    approx_ln(kl)            | 6.2278166     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.56          |
|    explained_variance       | 0.997         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 6720          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0407        |
|    value_loss               | 0.177         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.3690392] |
| time/                       |              |
|    fps                      | 102          |
|    iterations               | 37           |
|    time_elapsed             | 738          |
|    total_timesteps          | 1380352      |
| train/                      |              |
|    approx_kl                | 2201.36      |
|    approx_ln(kl)            | 7.6968307    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.58         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6730         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0404       |
|    value_loss               | 0.105        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.49382633] |
| time/                       |               |
|    fps                      | 103           |
|    iterations               | 38            |
|    time_elapsed             | 752           |
|    total_timesteps          | 1382400       |
| train/                      |               |
|    approx_kl                | 2044.7        |
|    approx_ln(kl)            | 7.6230063     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.59          |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 6740          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0401        |
|    value_loss               | 0.174         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-0.366691] |
| time/                       |             |
|    fps                      | 104         |
|    iterations               | 39          |
|    time_elapsed             | 765         |
|    total_timesteps          | 1384448     |
| train/                      |             |
|    approx_kl                | 1043.4761   |
|    approx_ln(kl)            | 6.9503126   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.6         |
|    explained_variance       | 0.977       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 6750        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0401      |
|    value_loss               | 1.8         |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5180535] |
| time/                       |              |
|    fps                      | 104          |
|    iterations               | 40           |
|    time_elapsed             | 780          |
|    total_timesteps          | 1386496      |
| train/                      |              |
|    approx_kl                | 1059.3884    |
|    approx_ln(kl)            | 6.965447     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.59         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6760         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0403       |
|    value_loss               | 0.569        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.3995765] |
| time/                       |              |
|    fps                      | 105          |
|    iterations               | 41           |
|    time_elapsed             | 794          |
|    total_timesteps          | 1388544      |
| train/                      |              |
|    approx_kl                | 1153.0148    |
|    approx_ln(kl)            | 7.050135     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.58         |
|    explained_variance       | 0.986        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6770         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0404       |
|    value_loss               | 0.773        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.54348594] |
| time/                       |               |
|    fps                      | 106           |
|    iterations               | 42            |
|    time_elapsed             | 807           |
|    total_timesteps          | 1390592       |
| train/                      |               |
|    approx_kl                | 2901.5757     |
|    approx_ln(kl)            | 7.973009      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.58          |
|    explained_variance       | 0.977         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 6780          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0405        |
|    value_loss               | 0.435         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.42000026] |
| time/                       |               |
|    fps                      | 107           |
|    iterations               | 43            |
|    time_elapsed             | 821           |
|    total_timesteps          | 1392640       |
| train/                      |               |
|    approx_kl                | 1884.9971     |
|    approx_ln(kl)            | 7.541682      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.56          |
|    explained_variance       | 0.946         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 6790          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0408        |
|    value_loss               | 0.572         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.28080982] |
| time/                       |               |
|    fps                      | 107           |
|    iterations               | 44            |
|    time_elapsed             | 836           |
|    total_timesteps          | 1394688       |
| train/                      |               |
|    approx_kl                | 1874.4954     |
|    approx_ln(kl)            | 7.5360947     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.58          |
|    explained_variance       | 0.991         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 6800          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0405        |
|    value_loss               | 0.73          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-0.462442] |
| time/                       |             |
|    fps                      | 108         |
|    iterations               | 45          |
|    time_elapsed             | 850         |
|    total_timesteps          | 1396736     |
| train/                      |             |
|    approx_kl                | 726.9954    |
|    approx_ln(kl)            | 6.58892     |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.58        |
|    explained_variance       | 0.96        |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 6810        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0403      |
|    value_loss               | 2.62        |
---------------------------------------------
-----------------------------------------------
| reward                      | [-0.48455623] |
| time/                       |               |
|    fps                      | 108           |
|    iterations               | 46            |
|    time_elapsed             | 864           |
|    total_timesteps          | 1398784       |
| train/                      |               |
|    approx_kl                | 4726.6123     |
|    approx_ln(kl)            | 8.460964      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.64          |
|    explained_variance       | 0.97          |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 6820          |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0392        |
|    value_loss               | 0.466         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.34484425] |
| time/                       |               |
|    fps                      | 109           |
|    iterations               | 47            |
|    time_elapsed             | 878           |
|    total_timesteps          | 1400832       |
| train/                      |               |
|    approx_kl                | 2861.4043     |
|    approx_ln(kl)            | 7.959068      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.63          |
|    explained_variance       | 0.938         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 6830          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0393        |
|    value_loss               | 0.204         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5413539] |
| time/                       |              |
|    fps                      | 110          |
|    iterations               | 48           |
|    time_elapsed             | 893          |
|    total_timesteps          | 1402880      |
| train/                      |              |
|    approx_kl                | 2026.4869    |
|    approx_ln(kl)            | 7.614059     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.65         |
|    explained_variance       | 0.965        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6840         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0391       |
|    value_loss               | 0.181        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.58998305] |
| time/                       |               |
|    fps                      | 110           |
|    iterations               | 49            |
|    time_elapsed             | 906           |
|    total_timesteps          | 1404928       |
| train/                      |               |
|    approx_kl                | 908.61395     |
|    approx_ln(kl)            | 6.81192       |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.66          |
|    explained_variance       | 0.847         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 6850          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0389        |
|    value_loss               | 0.239         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
--------------------------------------
| reward             | [-0.30286577] |
| time/              |               |
|    fps             | 159           |
|    iterations      | 1             |
|    time_elapsed    | 12            |
|    total_timesteps | 1406976       |
--------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.40106204] |
| time/                       |               |
|    fps                      | 151           |
|    iterations               | 2             |
|    time_elapsed             | 26            |
|    total_timesteps          | 1409024       |
| train/                      |               |
|    approx_kl                | 2933.003      |
|    approx_ln(kl)            | 7.9837823     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.68          |
|    explained_variance       | 0.98          |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 6870          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0384        |
|    value_loss               | 0.0448        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5120421] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 3            |
|    time_elapsed             | 40           |
|    total_timesteps          | 1411072      |
| train/                      |              |
|    approx_kl                | 3437.3552    |
|    approx_ln(kl)            | 8.142458     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.68         |
|    explained_variance       | 0.978        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6880         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0384       |
|    value_loss               | 0.103        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5863884] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 4            |
|    time_elapsed             | 55           |
|    total_timesteps          | 1413120      |
| train/                      |              |
|    approx_kl                | 2373.5957    |
|    approx_ln(kl)            | 7.7721615    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.68         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6890         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0385       |
|    value_loss               | 0.028        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.53544366] |
| time/                       |               |
|    fps                      | 148           |
|    iterations               | 5             |
|    time_elapsed             | 69            |
|    total_timesteps          | 1415168       |
| train/                      |               |
|    approx_kl                | 3448.543      |
|    approx_ln(kl)            | 8.145707      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.7           |
|    explained_variance       | 0.937         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 6900          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0381        |
|    value_loss               | 0.0707        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5375906] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 6            |
|    time_elapsed             | 83           |
|    total_timesteps          | 1417216      |
| train/                      |              |
|    approx_kl                | 969.88666    |
|    approx_ln(kl)            | 6.877179     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.67         |
|    explained_variance       | 0.991        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6910         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0387       |
|    value_loss               | 0.0247       |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5157436] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 7            |
|    time_elapsed             | 97           |
|    total_timesteps          | 1419264      |
| train/                      |              |
|    approx_kl                | 3896.542     |
|    approx_ln(kl)            | 8.267845     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.66         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6920         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0388       |
|    value_loss               | 0.0215       |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.30549893] |
| time/                       |               |
|    fps                      | 143           |
|    iterations               | 8             |
|    time_elapsed             | 114           |
|    total_timesteps          | 1421312       |
| train/                      |               |
|    approx_kl                | 7029.1865     |
|    approx_ln(kl)            | 8.857826      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.68          |
|    explained_variance       | 0.976         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 6930          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0383        |
|    value_loss               | 0.0292        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.36500823] |
| time/                       |               |
|    fps                      | 134           |
|    iterations               | 9             |
|    time_elapsed             | 137           |
|    total_timesteps          | 1423360       |
| train/                      |               |
|    approx_kl                | 1351.834      |
|    approx_ln(kl)            | 7.2092175     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.67          |
|    explained_variance       | 0.902         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 6940          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0387        |
|    value_loss               | 0.0778        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4209957] |
| time/                       |              |
|    fps                      | 135          |
|    iterations               | 10           |
|    time_elapsed             | 150          |
|    total_timesteps          | 1425408      |
| train/                      |              |
|    approx_kl                | 3581.4258    |
|    approx_ln(kl)            | 8.1835165    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.67         |
|    explained_variance       | 0.972        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 6950         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0386       |
|    value_loss               | 0.0766       |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.50355667] |
| time/                       |               |
|    fps                      | 136           |
|    iterations               | 11            |
|    time_elapsed             | 165           |
|    total_timesteps          | 1427456       |
| train/                      |               |
|    approx_kl                | 2613.874      |
|    approx_ln(kl)            | 7.868589      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.66          |
|    explained_variance       | 0.979         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 6960          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0388        |
|    value_loss               | 0.0646        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.49351606] |
| time/                       |               |
|    fps                      | 137           |
|    iterations               | 12            |
|    time_elapsed             | 178           |
|    total_timesteps          | 1429504       |
| train/                      |               |
|    approx_kl                | 2044.8647     |
|    approx_ln(kl)            | 7.623087      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.68          |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 6970          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0384        |
|    value_loss               | 0.0291        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.57331353] |
| time/                       |               |
|    fps                      | 138           |
|    iterations               | 13            |
|    time_elapsed             | 192           |
|    total_timesteps          | 1431552       |
| train/                      |               |
|    approx_kl                | 2692.5073     |
|    approx_ln(kl)            | 7.898228      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.66          |
|    explained_variance       | 0.997         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 6980          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0389        |
|    value_loss               | 0.0199        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.53924054] |
| time/                       |               |
|    fps                      | 138           |
|    iterations               | 14            |
|    time_elapsed             | 206           |
|    total_timesteps          | 1433600       |
| train/                      |               |
|    approx_kl                | 2486.858      |
|    approx_ln(kl)            | 7.818775      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.67          |
|    explained_variance       | 0.981         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 6990          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0386        |
|    value_loss               | 0.0289        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.36221242] |
| time/                       |               |
|    fps                      | 139           |
|    iterations               | 15            |
|    time_elapsed             | 220           |
|    total_timesteps          | 1435648       |
| train/                      |               |
|    approx_kl                | 3859.8718     |
|    approx_ln(kl)            | 8.258389      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.67          |
|    explained_variance       | 0.989         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 7000          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0386        |
|    value_loss               | 0.0148        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5565499] |
| time/                       |              |
|    fps                      | 139          |
|    iterations               | 16           |
|    time_elapsed             | 234          |
|    total_timesteps          | 1437696      |
| train/                      |              |
|    approx_kl                | 1930.0686    |
|    approx_ln(kl)            | 7.565311     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.67         |
|    explained_variance       | 0.99         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7010         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0386       |
|    value_loss               | 0.0286       |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5135064] |
| time/                       |              |
|    fps                      | 140          |
|    iterations               | 17           |
|    time_elapsed             | 248          |
|    total_timesteps          | 1439744      |
| train/                      |              |
|    approx_kl                | 2003.0255    |
|    approx_ln(kl)            | 7.602414     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.66         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7020         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0388       |
|    value_loss               | 0.0306       |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.3324567] |
| time/                       |              |
|    fps                      | 140          |
|    iterations               | 18           |
|    time_elapsed             | 262          |
|    total_timesteps          | 1441792      |
| train/                      |              |
|    approx_kl                | 1540.5054    |
|    approx_ln(kl)            | 7.3398657    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.64         |
|    explained_variance       | 0.949        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7030         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0392       |
|    value_loss               | 0.0538       |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5537346] |
| time/                       |              |
|    fps                      | 141          |
|    iterations               | 19           |
|    time_elapsed             | 275          |
|    total_timesteps          | 1443840      |
| train/                      |              |
|    approx_kl                | 1053.7649    |
|    approx_ln(kl)            | 6.9601245    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.63         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7040         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0394       |
|    value_loss               | 0.0364       |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.25988546] |
| time/                       |               |
|    fps                      | 141           |
|    iterations               | 20            |
|    time_elapsed             | 289           |
|    total_timesteps          | 1445888       |
| train/                      |               |
|    approx_kl                | 3188.041      |
|    approx_ln(kl)            | 8.067162      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.61          |
|    explained_variance       | 0.974         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 7050          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0397        |
|    value_loss               | 0.0574        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.54630125] |
| time/                       |               |
|    fps                      | 141           |
|    iterations               | 21            |
|    time_elapsed             | 303           |
|    total_timesteps          | 1447936       |
| train/                      |               |
|    approx_kl                | 2236.2136     |
|    approx_ln(kl)            | 7.712539      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.62          |
|    explained_variance       | 0.983         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 7060          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0395        |
|    value_loss               | 0.0382        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5005447] |
| time/                       |              |
|    fps                      | 141          |
|    iterations               | 22           |
|    time_elapsed             | 317          |
|    total_timesteps          | 1449984      |
| train/                      |              |
|    approx_kl                | 2940.3906    |
|    approx_ln(kl)            | 7.9862976    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.6          |
|    explained_variance       | 0.982        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7070         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0399       |
|    value_loss               | 0.0594       |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.46681276] |
| time/                       |               |
|    fps                      | 142           |
|    iterations               | 23            |
|    time_elapsed             | 331           |
|    total_timesteps          | 1452032       |
| train/                      |               |
|    approx_kl                | 4352.4414     |
|    approx_ln(kl)            | 8.378492      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.62          |
|    explained_variance       | 0.996         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 7080          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0396        |
|    value_loss               | 0.0159        |
-----------------------------------------------
----------------------------------------------
| reward                      | [-0.5705925] |
| time/                       |              |
|    fps                      | 142          |
|    iterations               | 24           |
|    time_elapsed             | 345          |
|    total_timesteps          | 1454080      |
| train/                      |              |
|    approx_kl                | 4836.549     |
|    approx_ln(kl)            | 8.483956     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.65         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 7090         |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0389       |
|    value_loss               | 0.0186       |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4237871] |
| time/                       |              |
|    fps                      | 142          |
|    iterations               | 25           |
|    time_elapsed             | 360          |
|    total_timesteps          | 1456128      |
| train/                      |              |
|    approx_kl                | 1704.207     |
|    approx_ln(kl)            | 7.440855     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.68         |
|    explained_variance       | 0.982        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7100         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0385       |
|    value_loss               | 0.0429       |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.57228905] |
| time/                       |               |
|    fps                      | 140           |
|    iterations               | 26            |
|    time_elapsed             | 378           |
|    total_timesteps          | 1458176       |
| train/                      |               |
|    approx_kl                | 4133.5737     |
|    approx_ln(kl)            | 8.326898      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.68          |
|    explained_variance       | 0.983         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 7110          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0385        |
|    value_loss               | 0.0664        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4204798] |
| time/                       |              |
|    fps                      | 139          |
|    iterations               | 27           |
|    time_elapsed             | 395          |
|    total_timesteps          | 1460224      |
| train/                      |              |
|    approx_kl                | 2750.0415    |
|    approx_ln(kl)            | 7.919371     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.69         |
|    explained_variance       | 0.988        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7120         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0383       |
|    value_loss               | 0.0332       |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.47563025] |
| time/                       |               |
|    fps                      | 139           |
|    iterations               | 28            |
|    time_elapsed             | 410           |
|    total_timesteps          | 1462272       |
| train/                      |               |
|    approx_kl                | 2394.7715     |
|    approx_ln(kl)            | 7.781043      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.68          |
|    explained_variance       | 0.992         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 7130          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0384        |
|    value_loss               | 0.0518        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.32724342] |
| time/                       |               |
|    fps                      | 134           |
|    iterations               | 29            |
|    time_elapsed             | 441           |
|    total_timesteps          | 1464320       |
| train/                      |               |
|    approx_kl                | 2590.5078     |
|    approx_ln(kl)            | 7.859609      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.68          |
|    explained_variance       | 0.979         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 7140          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0385        |
|    value_loss               | 0.0367        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5032545] |
| time/                       |              |
|    fps                      | 134          |
|    iterations               | 30           |
|    time_elapsed             | 456          |
|    total_timesteps          | 1466368      |
| train/                      |              |
|    approx_kl                | 5502.453     |
|    approx_ln(kl)            | 8.612949     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.69         |
|    explained_variance       | 0.983        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7150         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0382       |
|    value_loss               | 0.0534       |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.52618563] |
| time/                       |               |
|    fps                      | 135           |
|    iterations               | 31            |
|    time_elapsed             | 469           |
|    total_timesteps          | 1468416       |
| train/                      |               |
|    approx_kl                | 2676.3975     |
|    approx_ln(kl)            | 7.892227      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.71          |
|    explained_variance       | 0.996         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 7160          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0379        |
|    value_loss               | 0.0278        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5030447] |
| time/                       |              |
|    fps                      | 135          |
|    iterations               | 32           |
|    time_elapsed             | 483          |
|    total_timesteps          | 1470464      |
| train/                      |              |
|    approx_kl                | 4757.3647    |
|    approx_ln(kl)            | 8.467449     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.72         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7170         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0378       |
|    value_loss               | 0.00944      |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.38916454] |
| time/                       |               |
|    fps                      | 135           |
|    iterations               | 33            |
|    time_elapsed             | 497           |
|    total_timesteps          | 1472512       |
| train/                      |               |
|    approx_kl                | 2085.9834     |
|    approx_ln(kl)            | 7.642996      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.69          |
|    explained_variance       | 0.995         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 7180          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0383        |
|    value_loss               | 0.0175        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5030891] |
| time/                       |              |
|    fps                      | 136          |
|    iterations               | 34           |
|    time_elapsed             | 511          |
|    total_timesteps          | 1474560      |
| train/                      |              |
|    approx_kl                | 2238.009     |
|    approx_ln(kl)            | 7.7133417    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.69         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7190         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0383       |
|    value_loss               | 0.021        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.38066283] |
| time/                       |               |
|    fps                      | 136           |
|    iterations               | 35            |
|    time_elapsed             | 525           |
|    total_timesteps          | 1476608       |
| train/                      |               |
|    approx_kl                | 2839.7007     |
|    approx_ln(kl)            | 7.951454      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.69          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 7200          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0385        |
|    value_loss               | 0.0162        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5524508] |
| time/                       |              |
|    fps                      | 128          |
|    iterations               | 36           |
|    time_elapsed             | 574          |
|    total_timesteps          | 1478656      |
| train/                      |              |
|    approx_kl                | 5199.604     |
|    approx_ln(kl)            | 8.556337     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.67         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7210         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0388       |
|    value_loss               | 0.0543       |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.30601656] |
| time/                       |               |
|    fps                      | 128           |
|    iterations               | 37            |
|    time_elapsed             | 588           |
|    total_timesteps          | 1480704       |
| train/                      |               |
|    approx_kl                | 4085.791      |
|    approx_ln(kl)            | 8.31527       |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.68          |
|    explained_variance       | 0.997         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 7220          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0387        |
|    value_loss               | 0.0128        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-0.319387] |
| time/                       |             |
|    fps                      | 129         |
|    iterations               | 38          |
|    time_elapsed             | 601         |
|    total_timesteps          | 1482752     |
| train/                      |             |
|    approx_kl                | 5039.91     |
|    approx_ln(kl)            | 8.525144    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.69        |
|    explained_variance       | 0.995       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 7230        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0384      |
|    value_loss               | 0.0231      |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5136689] |
| time/                       |              |
|    fps                      | 129          |
|    iterations               | 39           |
|    time_elapsed             | 615          |
|    total_timesteps          | 1484800      |
| train/                      |              |
|    approx_kl                | 493.5077     |
|    approx_ln(kl)            | 6.2015386    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.71         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7240         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0383       |
|    value_loss               | 0.0298       |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-0.577713] |
| time/                       |             |
|    fps                      | 130         |
|    iterations               | 40          |
|    time_elapsed             | 629         |
|    total_timesteps          | 1486848     |
| train/                      |             |
|    approx_kl                | 1645.5287   |
|    approx_ln(kl)            | 7.405817    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.73        |
|    explained_variance       | 1           |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 7250        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0379      |
|    value_loss               | 0.00869     |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.46203795] |
| time/                       |               |
|    fps                      | 130           |
|    iterations               | 41            |
|    time_elapsed             | 643           |
|    total_timesteps          | 1488896       |
| train/                      |               |
|    approx_kl                | 5797.1367     |
|    approx_ln(kl)            | 8.665119      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.73          |
|    explained_variance       | 0.98          |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 7260          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.038         |
|    value_loss               | 0.0335        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4620025] |
| time/                       |              |
|    fps                      | 130          |
|    iterations               | 42           |
|    time_elapsed             | 657          |
|    total_timesteps          | 1490944      |
| train/                      |              |
|    approx_kl                | 1424.1152    |
|    approx_ln(kl)            | 7.261306     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.72         |
|    explained_variance       | 0.989        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7270         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0379       |
|    value_loss               | 0.0219       |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.37088278] |
| time/                       |               |
|    fps                      | 130           |
|    iterations               | 43            |
|    time_elapsed             | 672           |
|    total_timesteps          | 1492992       |
| train/                      |               |
|    approx_kl                | 2536.8115     |
|    approx_ln(kl)            | 7.838663      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.71          |
|    explained_variance       | 0.995         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 7280          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0381        |
|    value_loss               | 0.00923       |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5513299] |
| time/                       |              |
|    fps                      | 131          |
|    iterations               | 44           |
|    time_elapsed             | 686          |
|    total_timesteps          | 1495040      |
| train/                      |              |
|    approx_kl                | 3073.1       |
|    approx_ln(kl)            | 8.030442     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.7          |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7290         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0383       |
|    value_loss               | 0.0146       |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.55855685] |
| time/                       |               |
|    fps                      | 131           |
|    iterations               | 45            |
|    time_elapsed             | 700           |
|    total_timesteps          | 1497088       |
| train/                      |               |
|    approx_kl                | 4267.8135     |
|    approx_ln(kl)            | 8.358857      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.72          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 7300          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.038         |
|    value_loss               | 0.0107        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4669698] |
| time/                       |              |
|    fps                      | 131          |
|    iterations               | 46           |
|    time_elapsed             | 714          |
|    total_timesteps          | 1499136      |
| train/                      |              |
|    approx_kl                | 4184.941     |
|    approx_ln(kl)            | 8.339248     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.68         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7310         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0386       |
|    value_loss               | 0.017        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.3225208] |
| time/                       |              |
|    fps                      | 132          |
|    iterations               | 47           |
|    time_elapsed             | 728          |
|    total_timesteps          | 1501184      |
| train/                      |              |
|    approx_kl                | 2667.8132    |
|    approx_ln(kl)            | 7.8890142    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.69         |
|    explained_variance       | 0.991        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7320         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0385       |
|    value_loss               | 0.0291       |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.32619575] |
| time/                       |               |
|    fps                      | 132           |
|    iterations               | 48            |
|    time_elapsed             | 742           |
|    total_timesteps          | 1503232       |
| train/                      |               |
|    approx_kl                | 4457.829      |
|    approx_ln(kl)            | 8.402417      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.67          |
|    explained_variance       | 0.99          |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 7330          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0389        |
|    value_loss               | 0.0256        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.3725214] |
| time/                       |              |
|    fps                      | 132          |
|    iterations               | 49           |
|    time_elapsed             | 756          |
|    total_timesteps          | 1505280      |
| train/                      |              |
|    approx_kl                | 2399.5251    |
|    approx_ln(kl)            | 7.783026     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.65         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7340         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0392       |
|    value_loss               | 0.0186       |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
--------------------------------------
| reward             | [-0.46576887] |
| time/              |               |
|    fps             | 159           |
|    iterations      | 1             |
|    time_elapsed    | 12            |
|    total_timesteps | 1507328       |
--------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.32382303] |
| time/                       |               |
|    fps                      | 149           |
|    iterations               | 2             |
|    time_elapsed             | 27            |
|    total_timesteps          | 1509376       |
| train/                      |               |
|    approx_kl                | 3984.5078     |
|    approx_ln(kl)            | 8.290169      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.64          |
|    explained_variance       | 0.991         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 7360          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0395        |
|    value_loss               | 0.0276        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.41672435] |
| time/                       |               |
|    fps                      | 149           |
|    iterations               | 3             |
|    time_elapsed             | 41            |
|    total_timesteps          | 1511424       |
| train/                      |               |
|    approx_kl                | 1556.7074     |
|    approx_ln(kl)            | 7.3503284     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.59          |
|    explained_variance       | 0.975         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 7370          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0405        |
|    value_loss               | 0.0232        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.37576196] |
| time/                       |               |
|    fps                      | 148           |
|    iterations               | 4             |
|    time_elapsed             | 54            |
|    total_timesteps          | 1513472       |
| train/                      |               |
|    approx_kl                | 3448.766      |
|    approx_ln(kl)            | 8.145772      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.58          |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 7380          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0407        |
|    value_loss               | 0.0168        |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0503719] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 5            |
|    time_elapsed             | 68           |
|    total_timesteps          | 1515520      |
| train/                      |              |
|    approx_kl                | 4289.2065    |
|    approx_ln(kl)            | 8.363857     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.56         |
|    explained_variance       | 0.953        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7390         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0411       |
|    value_loss               | 0.591        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0879303] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 6            |
|    time_elapsed             | 82           |
|    total_timesteps          | 1517568      |
| train/                      |              |
|    approx_kl                | 857.2903     |
|    approx_ln(kl)            | 6.7537766    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.53         |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7400         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0417       |
|    value_loss               | 0.353        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5784297] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 7            |
|    time_elapsed             | 97           |
|    total_timesteps          | 1519616      |
| train/                      |              |
|    approx_kl                | 3725.5571    |
|    approx_ln(kl)            | 8.222972     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.52         |
|    explained_variance       | 0.977        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7410         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0419       |
|    value_loss               | 2.65         |
----------------------------------------------
----------------------------------------------
| reward                      | [-0.3238664] |
| time/                       |              |
|    fps                      | 136          |
|    iterations               | 8            |
|    time_elapsed             | 120          |
|    total_timesteps          | 1521664      |
| train/                      |              |
|    approx_kl                | 1733.5212    |
|    approx_ln(kl)            | 7.45791      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.49         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 7420         |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0424       |
|    value_loss               | 0.408        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4334357] |
| time/                       |              |
|    fps                      | 127          |
|    iterations               | 9            |
|    time_elapsed             | 144          |
|    total_timesteps          | 1523712      |
| train/                      |              |
|    approx_kl                | 2440.329     |
|    approx_ln(kl)            | 7.799888     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.51         |
|    explained_variance       | 0.988        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7430         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0422       |
|    value_loss               | 2.8          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4219278] |
| time/                       |              |
|    fps                      | 120          |
|    iterations               | 10           |
|    time_elapsed             | 169          |
|    total_timesteps          | 1525760      |
| train/                      |              |
|    approx_kl                | 2372.337     |
|    approx_ln(kl)            | 7.771631     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.52         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7440         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0419       |
|    value_loss               | 0.205        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.42729014] |
| time/                       |               |
|    fps                      | 115           |
|    iterations               | 11            |
|    time_elapsed             | 195           |
|    total_timesteps          | 1527808       |
| train/                      |               |
|    approx_kl                | 1477.9683     |
|    approx_ln(kl)            | 7.298424      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.53          |
|    explained_variance       | 0.991         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 7450          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0417        |
|    value_loss               | 3.19          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4770607] |
| time/                       |              |
|    fps                      | 79           |
|    iterations               | 12           |
|    time_elapsed             | 310          |
|    total_timesteps          | 1529856      |
| train/                      |              |
|    approx_kl                | 1442.5852    |
|    approx_ln(kl)            | 7.274192     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.52         |
|    explained_variance       | 0.951        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7460         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.042        |
|    value_loss               | 7.34         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5564493] |
| time/                       |              |
|    fps                      | 74           |
|    iterations               | 13           |
|    time_elapsed             | 356          |
|    total_timesteps          | 1531904      |
| train/                      |              |
|    approx_kl                | 1465.3364    |
|    approx_ln(kl)            | 7.28984      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.47         |
|    explained_variance       | 0.991        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7470         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0434       |
|    value_loss               | 1.62         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5031624] |
| time/                       |              |
|    fps                      | 75           |
|    iterations               | 14           |
|    time_elapsed             | 380          |
|    total_timesteps          | 1533952      |
| train/                      |              |
|    approx_kl                | 1268.4302    |
|    approx_ln(kl)            | 7.1455355    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.47         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7480         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0432       |
|    value_loss               | 1.22         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7879344] |
| time/                       |              |
|    fps                      | 75           |
|    iterations               | 15           |
|    time_elapsed             | 407          |
|    total_timesteps          | 1536000      |
| train/                      |              |
|    approx_kl                | 3607.0464    |
|    approx_ln(kl)            | 8.190644     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.48         |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7490         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0429       |
|    value_loss               | 1.19         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.7417121] |
| time/                       |              |
|    fps                      | 76           |
|    iterations               | 16           |
|    time_elapsed             | 430          |
|    total_timesteps          | 1538048      |
| train/                      |              |
|    approx_kl                | 1986.2231    |
|    approx_ln(kl)            | 7.5939903    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.52         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7500         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.042        |
|    value_loss               | 0.973        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.1975293] |
| time/                       |              |
|    fps                      | 72           |
|    iterations               | 17           |
|    time_elapsed             | 481          |
|    total_timesteps          | 1540096      |
| train/                      |              |
|    approx_kl                | 4476.4614    |
|    approx_ln(kl)            | 8.406589     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.51         |
|    explained_variance       | 0.984        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7510         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0424       |
|    value_loss               | 2.21         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.8496972] |
| time/                       |              |
|    fps                      | 72           |
|    iterations               | 18           |
|    time_elapsed             | 505          |
|    total_timesteps          | 1542144      |
| train/                      |              |
|    approx_kl                | 3047.458     |
|    approx_ln(kl)            | 8.022063     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.51         |
|    explained_variance       | 0.985        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7520         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0422       |
|    value_loss               | 3.73         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.9616028] |
| time/                       |              |
|    fps                      | 73           |
|    iterations               | 19           |
|    time_elapsed             | 531          |
|    total_timesteps          | 1544192      |
| train/                      |              |
|    approx_kl                | 887.26306    |
|    approx_ln(kl)            | 6.7881417    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.53         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7530         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0419       |
|    value_loss               | 1.44         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5841838] |
| time/                       |              |
|    fps                      | 73           |
|    iterations               | 20           |
|    time_elapsed             | 557          |
|    total_timesteps          | 1546240      |
| train/                      |              |
|    approx_kl                | 1855.3583    |
|    approx_ln(kl)            | 7.525833     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.52         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7540         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0419       |
|    value_loss               | 1.34         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.3142816] |
| time/                       |              |
|    fps                      | 73           |
|    iterations               | 21           |
|    time_elapsed             | 583          |
|    total_timesteps          | 1548288      |
| train/                      |              |
|    approx_kl                | 1948.8687    |
|    approx_ln(kl)            | 7.575004     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.57         |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7550         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0409       |
|    value_loss               | 1.28         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.7185777] |
| time/                       |              |
|    fps                      | 70           |
|    iterations               | 22           |
|    time_elapsed             | 635          |
|    total_timesteps          | 1550336      |
| train/                      |              |
|    approx_kl                | 1769.0574    |
|    approx_ln(kl)            | 7.4782023    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.56         |
|    explained_variance       | 0.992        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7560         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0411       |
|    value_loss               | 1.88         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
--------------------------------------------
| reward                      | [-1.37447] |
| time/                       |            |
|    fps                      | 72         |
|    iterations               | 23         |
|    time_elapsed             | 653        |
|    total_timesteps          | 1552384    |
| train/                      |            |
|    approx_kl                | 1210.5841  |
|    approx_ln(kl)            | 7.0988584  |
|    clip_range               | 0.2        |
|    entropy_loss             | 3.57       |
|    explained_variance       | 0.994      |
|    learning_rate            | 0.001      |
|    ln(loss)                 | inf        |
|    ln(policy_gradient_loss) | nan        |
|    loss                     | inf        |
|    n_updates                | 7570       |
|    policy_gradient_loss     | nan        |
|    std                      | 0.0409     |
|    value_loss               | 2.23       |
--------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.6654764] |
| time/                       |              |
|    fps                      | 73           |
|    iterations               | 24           |
|    time_elapsed             | 672          |
|    total_timesteps          | 1554432      |
| train/                      |              |
|    approx_kl                | 2450.372     |
|    approx_ln(kl)            | 7.803995     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.57         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7580         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0408       |
|    value_loss               | 3.46         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.381106] |
| time/                       |             |
|    fps                      | 74          |
|    iterations               | 25          |
|    time_elapsed             | 690         |
|    total_timesteps          | 1556480     |
| train/                      |             |
|    approx_kl                | 3032.372    |
|    approx_ln(kl)            | 8.0171      |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.59        |
|    explained_variance       | 0.982       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 7590        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0406      |
|    value_loss               | 2.28        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.3083887] |
| time/                       |              |
|    fps                      | 75           |
|    iterations               | 26           |
|    time_elapsed             | 709          |
|    total_timesteps          | 1558528      |
| train/                      |              |
|    approx_kl                | 2578.3062    |
|    approx_ln(kl)            | 7.854888     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.58         |
|    explained_variance       | 0.989        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7600         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0406       |
|    value_loss               | 2.86         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.4308875] |
| time/                       |              |
|    fps                      | 69           |
|    iterations               | 27           |
|    time_elapsed             | 799          |
|    total_timesteps          | 1560576      |
| train/                      |              |
|    approx_kl                | 985.1323     |
|    approx_ln(kl)            | 6.892776     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.59         |
|    explained_variance       | 0.989        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7610         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0404       |
|    value_loss               | 3.16         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.7427003] |
| time/                       |              |
|    fps                      | 70           |
|    iterations               | 28           |
|    time_elapsed             | 817          |
|    total_timesteps          | 1562624      |
| train/                      |              |
|    approx_kl                | 1365.1599    |
|    approx_ln(kl)            | 7.219027     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.58         |
|    explained_variance       | 0.988        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7620         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0408       |
|    value_loss               | 1.18         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.53420365] |
| time/                       |               |
|    fps                      | 70            |
|    iterations               | 29            |
|    time_elapsed             | 836           |
|    total_timesteps          | 1564672       |
| train/                      |               |
|    approx_kl                | 1219.3768     |
|    approx_ln(kl)            | 7.1060953     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.57          |
|    explained_variance       | 0.994         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 7630          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0409        |
|    value_loss               | 4.19          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.567148] |
| time/                       |             |
|    fps                      | 71          |
|    iterations               | 30          |
|    time_elapsed             | 858         |
|    total_timesteps          | 1566720     |
| train/                      |             |
|    approx_kl                | 4165.0996   |
|    approx_ln(kl)            | 8.334496    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.61        |
|    explained_variance       | 0.991       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 7640        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.04        |
|    value_loss               | 3.7         |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.3266544] |
| time/                       |              |
|    fps                      | 72           |
|    iterations               | 31           |
|    time_elapsed             | 877          |
|    total_timesteps          | 1568768      |
| train/                      |              |
|    approx_kl                | 3507.2266    |
|    approx_ln(kl)            | 8.1625805    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.62         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7650         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0399       |
|    value_loss               | 1.54         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.3682366] |
| time/                       |              |
|    fps                      | 73           |
|    iterations               | 32           |
|    time_elapsed             | 896          |
|    total_timesteps          | 1570816      |
| train/                      |              |
|    approx_kl                | 2991.7644    |
|    approx_ln(kl)            | 8.003618     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.61         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7660         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0401       |
|    value_loss               | 3.29         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.42838168] |
| time/                       |               |
|    fps                      | 73            |
|    iterations               | 33            |
|    time_elapsed             | 914           |
|    total_timesteps          | 1572864       |
| train/                      |               |
|    approx_kl                | 3616.416      |
|    approx_ln(kl)            | 8.193239      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.63          |
|    explained_variance       | 0.995         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 7670          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0398        |
|    value_loss               | 1.5           |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.1982126] |
| time/                       |              |
|    fps                      | 74           |
|    iterations               | 34           |
|    time_elapsed             | 933          |
|    total_timesteps          | 1574912      |
| train/                      |              |
|    approx_kl                | 1637.2131    |
|    approx_ln(kl)            | 7.4007506    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.62         |
|    explained_variance       | 0.967        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7680         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0401       |
|    value_loss               | 0.755        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.5643463] |
| time/                       |              |
|    fps                      | 69           |
|    iterations               | 35           |
|    time_elapsed             | 1036         |
|    total_timesteps          | 1576960      |
| train/                      |              |
|    approx_kl                | 7972.181     |
|    approx_ln(kl)            | 8.983713     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.62         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7690         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.04         |
|    value_loss               | 3.37         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.31895715] |
| time/                       |               |
|    fps                      | 70            |
|    iterations               | 36            |
|    time_elapsed             | 1051          |
|    total_timesteps          | 1579008       |
| train/                      |               |
|    approx_kl                | 5732.5156     |
|    approx_ln(kl)            | 8.65391       |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.62          |
|    explained_variance       | 0.997         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 7700          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.04          |
|    value_loss               | 1.84          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.47022438] |
| time/                       |               |
|    fps                      | 71            |
|    iterations               | 37            |
|    time_elapsed             | 1065          |
|    total_timesteps          | 1581056       |
| train/                      |               |
|    approx_kl                | 1798.2048     |
|    approx_ln(kl)            | 7.494544      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.61          |
|    explained_variance       | 0.994         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 7710          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0403        |
|    value_loss               | 3.53          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.289648] |
| time/                       |             |
|    fps                      | 72          |
|    iterations               | 38          |
|    time_elapsed             | 1078        |
|    total_timesteps          | 1583104     |
| train/                      |             |
|    approx_kl                | 3748.0396   |
|    approx_ln(kl)            | 8.228989    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.59        |
|    explained_variance       | 0.995       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 7720        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0406      |
|    value_loss               | 4.24        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.3591078] |
| time/                       |              |
|    fps                      | 73           |
|    iterations               | 39           |
|    time_elapsed             | 1092         |
|    total_timesteps          | 1585152      |
| train/                      |              |
|    approx_kl                | 3073.8923    |
|    approx_ln(kl)            | 8.0307       |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.63         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7730         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0396       |
|    value_loss               | 0.31         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.8956416] |
| time/                       |              |
|    fps                      | 74           |
|    iterations               | 40           |
|    time_elapsed             | 1106         |
|    total_timesteps          | 1587200      |
| train/                      |              |
|    approx_kl                | 3706.1987    |
|    approx_ln(kl)            | 8.217762     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.63         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7740         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0397       |
|    value_loss               | 6.8          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5188391] |
| time/                       |              |
|    fps                      | 74           |
|    iterations               | 41           |
|    time_elapsed             | 1120         |
|    total_timesteps          | 1589248      |
| train/                      |              |
|    approx_kl                | 8910.768     |
|    approx_ln(kl)            | 9.095016     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.64         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7750         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0394       |
|    value_loss               | 2.09         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
--------------------------------------------
| reward                      | [-1.26829] |
| time/                       |            |
|    fps                      | 75         |
|    iterations               | 42         |
|    time_elapsed             | 1134       |
|    total_timesteps          | 1591296    |
| train/                      |            |
|    approx_kl                | 2236.2942  |
|    approx_ln(kl)            | 7.7125754  |
|    clip_range               | 0.2        |
|    entropy_loss             | 3.64       |
|    explained_variance       | 0.997      |
|    learning_rate            | 0.001      |
|    ln(loss)                 | inf        |
|    ln(policy_gradient_loss) | nan        |
|    loss                     | inf        |
|    n_updates                | 7760       |
|    policy_gradient_loss     | nan        |
|    std                      | 0.0394     |
|    value_loss               | 1.87       |
--------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.8045527] |
| time/                       |              |
|    fps                      | 76           |
|    iterations               | 43           |
|    time_elapsed             | 1148         |
|    total_timesteps          | 1593344      |
| train/                      |              |
|    approx_kl                | 5061.322     |
|    approx_ln(kl)            | 8.529383     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.62         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7770         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0399       |
|    value_loss               | 0.585        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.2598517] |
| time/                       |              |
|    fps                      | 77           |
|    iterations               | 44           |
|    time_elapsed             | 1163         |
|    total_timesteps          | 1595392      |
| train/                      |              |
|    approx_kl                | 7407.377     |
|    approx_ln(kl)            | 8.910232     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.61         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7780         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.04         |
|    value_loss               | 0.61         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.58421266] |
| time/                       |               |
|    fps                      | 78            |
|    iterations               | 45            |
|    time_elapsed             | 1177          |
|    total_timesteps          | 1597440       |
| train/                      |               |
|    approx_kl                | 3052.2822     |
|    approx_ln(kl)            | 8.023644      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.64          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 7790          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0395        |
|    value_loss               | 1.98          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.7261212] |
| time/                       |              |
|    fps                      | 79           |
|    iterations               | 46           |
|    time_elapsed             | 1191         |
|    total_timesteps          | 1599488      |
| train/                      |              |
|    approx_kl                | 5712.4077    |
|    approx_ln(kl)            | 8.650396     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.7          |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7800         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0384       |
|    value_loss               | 0.781        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.7695417] |
| time/                       |              |
|    fps                      | 79           |
|    iterations               | 47           |
|    time_elapsed             | 1205         |
|    total_timesteps          | 1601536      |
| train/                      |              |
|    approx_kl                | 2611.6067    |
|    approx_ln(kl)            | 7.867721     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.66         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7810         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0391       |
|    value_loss               | 0.184        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.32892522] |
| time/                       |               |
|    fps                      | 80            |
|    iterations               | 48            |
|    time_elapsed             | 1219          |
|    total_timesteps          | 1603584       |
| train/                      |               |
|    approx_kl                | 3637.9114     |
|    approx_ln(kl)            | 8.199165      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.66          |
|    explained_variance       | 0.996         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 7820          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0392        |
|    value_loss               | 0.723         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.2927127] |
| time/                       |              |
|    fps                      | 81           |
|    iterations               | 49           |
|    time_elapsed             | 1232         |
|    total_timesteps          | 1605632      |
| train/                      |              |
|    approx_kl                | 4636.7217    |
|    approx_ln(kl)            | 8.441763     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.7          |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7830         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0383       |
|    value_loss               | 0.409        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-------------------------------------
| reward             | [-0.5167169] |
| time/              |              |
|    fps             | 161          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 1607680      |
-------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.37521467] |
| time/                       |               |
|    fps                      | 154           |
|    iterations               | 2             |
|    time_elapsed             | 26            |
|    total_timesteps          | 1609728       |
| train/                      |               |
|    approx_kl                | 5103.89       |
|    approx_ln(kl)            | 8.537758      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.69          |
|    explained_variance       | 1             |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 7850          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0388        |
|    value_loss               | 0.137         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.42525634] |
| time/                       |               |
|    fps                      | 152           |
|    iterations               | 3             |
|    time_elapsed             | 40            |
|    total_timesteps          | 1611776       |
| train/                      |               |
|    approx_kl                | 10084.069     |
|    approx_ln(kl)            | 9.218712      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.68          |
|    explained_variance       | 1             |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 7860          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0389        |
|    value_loss               | 0.154         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.8139707] |
| time/                       |              |
|    fps                      | 151          |
|    iterations               | 4            |
|    time_elapsed             | 54           |
|    total_timesteps          | 1613824      |
| train/                      |              |
|    approx_kl                | 2292.5781    |
|    approx_ln(kl)            | 7.7374325    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.69         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7870         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0387       |
|    value_loss               | 1.82         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5901964] |
| time/                       |              |
|    fps                      | 150          |
|    iterations               | 5            |
|    time_elapsed             | 67           |
|    total_timesteps          | 1615872      |
| train/                      |              |
|    approx_kl                | 3880.8516    |
|    approx_ln(kl)            | 8.26381      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.71         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7880         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0383       |
|    value_loss               | 0.107        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5180625] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 6            |
|    time_elapsed             | 82           |
|    total_timesteps          | 1617920      |
| train/                      |              |
|    approx_kl                | 3231.6982    |
|    approx_ln(kl)            | 8.080763     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.72         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7890         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0383       |
|    value_loss               | 1.07         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.8202556] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 7            |
|    time_elapsed             | 95           |
|    total_timesteps          | 1619968      |
| train/                      |              |
|    approx_kl                | 2396.7112    |
|    approx_ln(kl)            | 7.7818527    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.7          |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7900         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0385       |
|    value_loss               | 0.811        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.5492532] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 8            |
|    time_elapsed             | 109          |
|    total_timesteps          | 1622016      |
| train/                      |              |
|    approx_kl                | 5368.5615    |
|    approx_ln(kl)            | 8.588315     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.69         |
|    explained_variance       | 0.967        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7910         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0387       |
|    value_loss               | 4.33         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.1864605] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 9            |
|    time_elapsed             | 123          |
|    total_timesteps          | 1624064      |
| train/                      |              |
|    approx_kl                | 1453.6356    |
|    approx_ln(kl)            | 7.281823     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.67         |
|    explained_variance       | 0.971        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7920         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0392       |
|    value_loss               | 10.3         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0946121] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 10           |
|    time_elapsed             | 137          |
|    total_timesteps          | 1626112      |
| train/                      |              |
|    approx_kl                | 3539.7476    |
|    approx_ln(kl)            | 8.171811     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.7          |
|    explained_variance       | 0.985        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7930         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0386       |
|    value_loss               | 7.82         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.80684763] |
| time/                       |               |
|    fps                      | 148           |
|    iterations               | 11            |
|    time_elapsed             | 151           |
|    total_timesteps          | 1628160       |
| train/                      |               |
|    approx_kl                | 3864.1934     |
|    approx_ln(kl)            | 8.259508      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.71          |
|    explained_variance       | 0.993         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 7940          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0381        |
|    value_loss               | 19.6          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.80651397] |
| time/                       |               |
|    fps                      | 147           |
|    iterations               | 12            |
|    time_elapsed             | 166           |
|    total_timesteps          | 1630208       |
| train/                      |               |
|    approx_kl                | 2914.8176     |
|    approx_ln(kl)            | 7.9775624     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.71          |
|    explained_variance       | 0.992         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 7950          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0385        |
|    value_loss               | 2.56          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.3539666] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 13           |
|    time_elapsed             | 180          |
|    total_timesteps          | 1632256      |
| train/                      |              |
|    approx_kl                | 5347.294     |
|    approx_ln(kl)            | 8.584346     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.72         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7960         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0383       |
|    value_loss               | 0.665        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.43353653] |
| time/                       |               |
|    fps                      | 147           |
|    iterations               | 14            |
|    time_elapsed             | 194           |
|    total_timesteps          | 1634304       |
| train/                      |               |
|    approx_kl                | 799.9461      |
|    approx_ln(kl)            | 6.6845446     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.7           |
|    explained_variance       | 0.973         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 7970          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0387        |
|    value_loss               | 2.34          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.1394621] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 15           |
|    time_elapsed             | 208          |
|    total_timesteps          | 1636352      |
| train/                      |              |
|    approx_kl                | 3460.5806    |
|    approx_ln(kl)            | 8.149192     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.71         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7980         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0385       |
|    value_loss               | 2.14         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.8225903] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 16           |
|    time_elapsed             | 222          |
|    total_timesteps          | 1638400      |
| train/                      |              |
|    approx_kl                | 8703.982     |
|    approx_ln(kl)            | 9.071536     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.71         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 7990         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0385       |
|    value_loss               | 1.76         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.7174864] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 17           |
|    time_elapsed             | 235          |
|    total_timesteps          | 1640448      |
| train/                      |              |
|    approx_kl                | 10300.588    |
|    approx_ln(kl)            | 9.239956     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.7          |
|    explained_variance       | 0.992        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8000         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0387       |
|    value_loss               | 1.84         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7431122] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 18           |
|    time_elapsed             | 249          |
|    total_timesteps          | 1642496      |
| train/                      |              |
|    approx_kl                | 2847.2612    |
|    approx_ln(kl)            | 7.954113     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.72         |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8010         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0383       |
|    value_loss               | 2.13         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.60493654] |
| time/                       |               |
|    fps                      | 147           |
|    iterations               | 19            |
|    time_elapsed             | 263           |
|    total_timesteps          | 1644544       |
| train/                      |               |
|    approx_kl                | 2716.5034     |
|    approx_ln(kl)            | 7.9071007     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.72          |
|    explained_variance       | 0.987         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 8020          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0383        |
|    value_loss               | 16.3          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.0001512] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 20           |
|    time_elapsed             | 277          |
|    total_timesteps          | 1646592      |
| train/                      |              |
|    approx_kl                | 2372.3994    |
|    approx_ln(kl)            | 7.771657     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.75         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8030         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0377       |
|    value_loss               | 0.542        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6751673] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 21           |
|    time_elapsed             | 290          |
|    total_timesteps          | 1648640      |
| train/                      |              |
|    approx_kl                | 8447.394     |
|    approx_ln(kl)            | 9.041614     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.73         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8040         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.038        |
|    value_loss               | 0.681        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.8252636] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 22           |
|    time_elapsed             | 304          |
|    total_timesteps          | 1650688      |
| train/                      |              |
|    approx_kl                | 2545.0583    |
|    approx_ln(kl)            | 7.841909     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.74         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8050         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0378       |
|    value_loss               | 0.397        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.0067472] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 23           |
|    time_elapsed             | 318          |
|    total_timesteps          | 1652736      |
| train/                      |              |
|    approx_kl                | 11159.176    |
|    approx_ln(kl)            | 9.320018     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.75         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8060         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0377       |
|    value_loss               | 0.49         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.8331857] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 24           |
|    time_elapsed             | 332          |
|    total_timesteps          | 1654784      |
| train/                      |              |
|    approx_kl                | 10712.941    |
|    approx_ln(kl)            | 9.279208     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.71         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8070         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0384       |
|    value_loss               | 0.677        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.94013476] |
| time/                       |               |
|    fps                      | 147           |
|    iterations               | 25            |
|    time_elapsed             | 345           |
|    total_timesteps          | 1656832       |
| train/                      |               |
|    approx_kl                | 2414.1008     |
|    approx_ln(kl)            | 7.789082      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.71          |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 8080          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0385        |
|    value_loss               | 0.409         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-1.121429] |
| time/                       |             |
|    fps                      | 148         |
|    iterations               | 26          |
|    time_elapsed             | 359         |
|    total_timesteps          | 1658880     |
| train/                      |             |
|    approx_kl                | 8562.709    |
|    approx_ln(kl)            | 9.055172    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.71        |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 8090        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0387      |
|    value_loss               | 0.429       |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.7638242] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 27           |
|    time_elapsed             | 373          |
|    total_timesteps          | 1660928      |
| train/                      |              |
|    approx_kl                | 5339.311     |
|    approx_ln(kl)            | 8.582852     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.73         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8100         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0382       |
|    value_loss               | 0.534        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.6582499] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 28           |
|    time_elapsed             | 387          |
|    total_timesteps          | 1662976      |
| train/                      |              |
|    approx_kl                | 5849.552     |
|    approx_ln(kl)            | 8.67412      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.75         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8110         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0377       |
|    value_loss               | 0.298        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-0.380707] |
| time/                       |             |
|    fps                      | 146         |
|    iterations               | 29          |
|    time_elapsed             | 404         |
|    total_timesteps          | 1665024     |
| train/                      |             |
|    approx_kl                | 5691.0903   |
|    approx_ln(kl)            | 8.646657    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.75        |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 8120        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0378      |
|    value_loss               | 0.481       |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.31928134] |
| time/                       |               |
|    fps                      | 146           |
|    iterations               | 30            |
|    time_elapsed             | 418           |
|    total_timesteps          | 1667072       |
| train/                      |               |
|    approx_kl                | 4904.0674     |
|    approx_ln(kl)            | 8.49782       |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.76          |
|    explained_variance       | 0.996         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 8130          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0374        |
|    value_loss               | 0.857         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-1.668279] |
| time/                       |             |
|    fps                      | 146         |
|    iterations               | 31          |
|    time_elapsed             | 432         |
|    total_timesteps          | 1669120     |
| train/                      |             |
|    approx_kl                | 4388.448    |
|    approx_ln(kl)            | 8.386731    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.76        |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 8140        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0372      |
|    value_loss               | 0.998       |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.7801235] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 32           |
|    time_elapsed             | 446          |
|    total_timesteps          | 1671168      |
| train/                      |              |
|    approx_kl                | 4059.6357    |
|    approx_ln(kl)            | 8.308848     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.77         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8150         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0375       |
|    value_loss               | 1.39         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.8987921] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 33           |
|    time_elapsed             | 460          |
|    total_timesteps          | 1673216      |
| train/                      |              |
|    approx_kl                | 3879.1104    |
|    approx_ln(kl)            | 8.263361     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.79         |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8160         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0369       |
|    value_loss               | 5.25         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.8175717] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 34           |
|    time_elapsed             | 473          |
|    total_timesteps          | 1675264      |
| train/                      |              |
|    approx_kl                | 3224.846     |
|    approx_ln(kl)            | 8.078641     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.78         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8170         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0372       |
|    value_loss               | 0.527        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-0.317536] |
| time/                       |             |
|    fps                      | 147         |
|    iterations               | 35          |
|    time_elapsed             | 487         |
|    total_timesteps          | 1677312     |
| train/                      |             |
|    approx_kl                | 4971.5986   |
|    approx_ln(kl)            | 8.511497    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.76        |
|    explained_variance       | 0.997       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 8180        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0378      |
|    value_loss               | 1.06        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7167075] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 36           |
|    time_elapsed             | 501          |
|    total_timesteps          | 1679360      |
| train/                      |              |
|    approx_kl                | 6912.2793    |
|    approx_ln(kl)            | 8.841055     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.73         |
|    explained_variance       | 0.912        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8190         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0382       |
|    value_loss               | 0.482        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.3189485] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 37           |
|    time_elapsed             | 515          |
|    total_timesteps          | 1681408      |
| train/                      |              |
|    approx_kl                | 5828.8027    |
|    approx_ln(kl)            | 8.670567     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.73         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8200         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0381       |
|    value_loss               | 0.23         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.22457425] |
| time/                       |               |
|    fps                      | 147           |
|    iterations               | 38            |
|    time_elapsed             | 529           |
|    total_timesteps          | 1683456       |
| train/                      |               |
|    approx_kl                | 7057.738      |
|    approx_ln(kl)            | 8.86188       |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.75          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 8210          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0377        |
|    value_loss               | 0.187         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.45796424] |
| time/                       |               |
|    fps                      | 147           |
|    iterations               | 39            |
|    time_elapsed             | 543           |
|    total_timesteps          | 1685504       |
| train/                      |               |
|    approx_kl                | 5538.4644     |
|    approx_ln(kl)            | 8.6194725     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.75          |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 8220          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0377        |
|    value_loss               | 0.482         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.5971005] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 40           |
|    time_elapsed             | 556          |
|    total_timesteps          | 1687552      |
| train/                      |              |
|    approx_kl                | 3284.802     |
|    approx_ln(kl)            | 8.097062     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.7          |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8230         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.039        |
|    value_loss               | 0.984        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.9867692] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 41           |
|    time_elapsed             | 570          |
|    total_timesteps          | 1689600      |
| train/                      |              |
|    approx_kl                | 1242.0706    |
|    approx_ln(kl)            | 7.124535     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.68         |
|    explained_variance       | 0.99         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8240         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0391       |
|    value_loss               | 3.83         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.1050634] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 42           |
|    time_elapsed             | 584          |
|    total_timesteps          | 1691648      |
| train/                      |              |
|    approx_kl                | 19056.682    |
|    approx_ln(kl)            | 9.855173     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.68         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8250         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0392       |
|    value_loss               | 3.81         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.4965276] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 43           |
|    time_elapsed             | 598          |
|    total_timesteps          | 1693696      |
| train/                      |              |
|    approx_kl                | 4913.9287    |
|    approx_ln(kl)            | 8.499829     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.68         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8260         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.039        |
|    value_loss               | 1.74         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.4213645] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 44           |
|    time_elapsed             | 612          |
|    total_timesteps          | 1695744      |
| train/                      |              |
|    approx_kl                | 692.3877     |
|    approx_ln(kl)            | 6.540146     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.68         |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8270         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.039        |
|    value_loss               | 7.26         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.720109] |
| time/                       |             |
|    fps                      | 147         |
|    iterations               | 45          |
|    time_elapsed             | 626         |
|    total_timesteps          | 1697792     |
| train/                      |             |
|    approx_kl                | 3204.724    |
|    approx_ln(kl)            | 8.072381    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.68        |
|    explained_variance       | 0.995       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 8280        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0388      |
|    value_loss               | 1.46        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.47562763] |
| time/                       |               |
|    fps                      | 147           |
|    iterations               | 46            |
|    time_elapsed             | 640           |
|    total_timesteps          | 1699840       |
| train/                      |               |
|    approx_kl                | 1461.147      |
|    approx_ln(kl)            | 7.286977      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.69          |
|    explained_variance       | 0.997         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 8290          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0389        |
|    value_loss               | 2.29          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5329716] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 47           |
|    time_elapsed             | 654          |
|    total_timesteps          | 1701888      |
| train/                      |              |
|    approx_kl                | 1231.8157    |
|    approx_ln(kl)            | 7.1162443    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.68         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8300         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.039        |
|    value_loss               | 4.29         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.7546558] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 48           |
|    time_elapsed             | 668          |
|    total_timesteps          | 1703936      |
| train/                      |              |
|    approx_kl                | 1195.8857    |
|    approx_ln(kl)            | 7.0866423    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.71         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8310         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0385       |
|    value_loss               | 3.99         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.342898] |
| time/                       |             |
|    fps                      | 147         |
|    iterations               | 49          |
|    time_elapsed             | 682         |
|    total_timesteps          | 1705984     |
| train/                      |             |
|    approx_kl                | 2595.5278   |
|    approx_ln(kl)            | 7.861545    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.71        |
|    explained_variance       | 0.996       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 8320        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0384      |
|    value_loss               | 3.94        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-------------------------------------
| reward             | [-2.9552226] |
| time/              |              |
|    fps             | 161          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 1708032      |
-------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.1537637] |
| time/                       |              |
|    fps                      | 154          |
|    iterations               | 2            |
|    time_elapsed             | 26           |
|    total_timesteps          | 1710080      |
| train/                      |              |
|    approx_kl                | 579.62       |
|    approx_ln(kl)            | 6.362373     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.73         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8340         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.038        |
|    value_loss               | 8.44         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.7780006] |
| time/                       |              |
|    fps                      | 152          |
|    iterations               | 3            |
|    time_elapsed             | 40           |
|    total_timesteps          | 1712128      |
| train/                      |              |
|    approx_kl                | 1549.4471    |
|    approx_ln(kl)            | 7.3456535    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.75         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8350         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0375       |
|    value_loss               | 16.2         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.6870186] |
| time/                       |              |
|    fps                      | 151          |
|    iterations               | 4            |
|    time_elapsed             | 54           |
|    total_timesteps          | 1714176      |
| train/                      |              |
|    approx_kl                | 1866.4924    |
|    approx_ln(kl)            | 7.5318165    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.74         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8360         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0377       |
|    value_loss               | 6.87         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0141999] |
| time/                       |              |
|    fps                      | 151          |
|    iterations               | 5            |
|    time_elapsed             | 67           |
|    total_timesteps          | 1716224      |
| train/                      |              |
|    approx_kl                | 4029.3052    |
|    approx_ln(kl)            | 8.30135      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.73         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8370         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.038        |
|    value_loss               | 3.08         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.418701] |
| time/                       |             |
|    fps                      | 150         |
|    iterations               | 6           |
|    time_elapsed             | 81          |
|    total_timesteps          | 1718272     |
| train/                      |             |
|    approx_kl                | 6932.8906   |
|    approx_ln(kl)            | 8.844032    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.72        |
|    explained_variance       | 0.997       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 8380        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0382      |
|    value_loss               | 1.03        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.3800551] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 7            |
|    time_elapsed             | 95           |
|    total_timesteps          | 1720320      |
| train/                      |              |
|    approx_kl                | 6389.077     |
|    approx_ln(kl)            | 8.762345     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.72         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8390         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0381       |
|    value_loss               | 2.46         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.2921015] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 8            |
|    time_elapsed             | 109          |
|    total_timesteps          | 1722368      |
| train/                      |              |
|    approx_kl                | 1405.6506    |
|    approx_ln(kl)            | 7.2482557    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.71         |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8400         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0384       |
|    value_loss               | 4.26         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.44259888] |
| time/                       |               |
|    fps                      | 149           |
|    iterations               | 9             |
|    time_elapsed             | 123           |
|    total_timesteps          | 1724416       |
| train/                      |               |
|    approx_kl                | 426.8395      |
|    approx_ln(kl)            | 6.056408      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.74          |
|    explained_variance       | 0.996         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 8410          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0378        |
|    value_loss               | 3.68          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.70164376] |
| time/                       |               |
|    fps                      | 148           |
|    iterations               | 10            |
|    time_elapsed             | 137           |
|    total_timesteps          | 1726464       |
| train/                      |               |
|    approx_kl                | 9886.345      |
|    approx_ln(kl)            | 9.19891       |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.75          |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 8420          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0376        |
|    value_loss               | 3.41          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.7211063] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 11           |
|    time_elapsed             | 151          |
|    total_timesteps          | 1728512      |
| train/                      |              |
|    approx_kl                | 3926.853     |
|    approx_ln(kl)            | 8.275594     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.75         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8430         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0377       |
|    value_loss               | 8.74         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.64563495] |
| time/                       |               |
|    fps                      | 119           |
|    iterations               | 12            |
|    time_elapsed             | 206           |
|    total_timesteps          | 1730560       |
| train/                      |               |
|    approx_kl                | 6272.9307     |
|    approx_ln(kl)            | 8.743999      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.74          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 8440          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0378        |
|    value_loss               | 4.6           |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.943653] |
| time/                       |             |
|    fps                      | 118         |
|    iterations               | 13          |
|    time_elapsed             | 224         |
|    total_timesteps          | 1732608     |
| train/                      |             |
|    approx_kl                | 3129.2744   |
|    approx_ln(kl)            | 8.048556    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.77        |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 8450        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0372      |
|    value_loss               | 3.36        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.785178] |
| time/                       |             |
|    fps                      | 118         |
|    iterations               | 14          |
|    time_elapsed             | 241         |
|    total_timesteps          | 1734656     |
| train/                      |             |
|    approx_kl                | 13211.955   |
|    approx_ln(kl)            | 9.488877    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.76        |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 8460        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0374      |
|    value_loss               | 0.972       |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.5012865] |
| time/                       |              |
|    fps                      | 118          |
|    iterations               | 15           |
|    time_elapsed             | 259          |
|    total_timesteps          | 1736704      |
| train/                      |              |
|    approx_kl                | 1046.3174    |
|    approx_ln(kl)            | 6.953032     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.75         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8470         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0374       |
|    value_loss               | 3.84         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
--------------------------------------------
| reward                      | [-5.02317] |
| time/                       |            |
|    fps                      | 118        |
|    iterations               | 16         |
|    time_elapsed             | 277        |
|    total_timesteps          | 1738752    |
| train/                      |            |
|    approx_kl                | 1735.7355  |
|    approx_ln(kl)            | 7.4591866  |
|    clip_range               | 0.2        |
|    entropy_loss             | 3.75       |
|    explained_variance       | 0.999      |
|    learning_rate            | 0.001      |
|    ln(loss)                 | inf        |
|    ln(policy_gradient_loss) | nan        |
|    loss                     | inf        |
|    n_updates                | 8480       |
|    policy_gradient_loss     | nan        |
|    std                      | 0.0375     |
|    value_loss               | 2.85       |
--------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.57890856] |
| time/                       |               |
|    fps                      | 118           |
|    iterations               | 17            |
|    time_elapsed             | 294           |
|    total_timesteps          | 1740800       |
| train/                      |               |
|    approx_kl                | 11291.445     |
|    approx_ln(kl)            | 9.3318        |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.79          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 8490          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0366        |
|    value_loss               | 2.63          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.73476577] |
| time/                       |               |
|    fps                      | 117           |
|    iterations               | 18            |
|    time_elapsed             | 312           |
|    total_timesteps          | 1742848       |
| train/                      |               |
|    approx_kl                | 3230.1287     |
|    approx_ln(kl)            | 8.080277      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.81          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 8500          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0363        |
|    value_loss               | 2.26          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.2650041] |
| time/                       |              |
|    fps                      | 117          |
|    iterations               | 19           |
|    time_elapsed             | 330          |
|    total_timesteps          | 1744896      |
| train/                      |              |
|    approx_kl                | 12728.434    |
|    approx_ln(kl)            | 9.451593     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.82         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8510         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0362       |
|    value_loss               | 0.938        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.1885183] |
| time/                       |              |
|    fps                      | 117          |
|    iterations               | 20           |
|    time_elapsed             | 348          |
|    total_timesteps          | 1746944      |
| train/                      |              |
|    approx_kl                | 4054.273     |
|    approx_ln(kl)            | 8.307527     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.83         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8520         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.036        |
|    value_loss               | 2            |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5060178] |
| time/                       |              |
|    fps                      | 117          |
|    iterations               | 21           |
|    time_elapsed             | 366          |
|    total_timesteps          | 1748992      |
| train/                      |              |
|    approx_kl                | 5611.5527    |
|    approx_ln(kl)            | 8.632583     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.86         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8530         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0353       |
|    value_loss               | 1.84         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4049334] |
| time/                       |              |
|    fps                      | 117          |
|    iterations               | 22           |
|    time_elapsed             | 384          |
|    total_timesteps          | 1751040      |
| train/                      |              |
|    approx_kl                | 3914.0974    |
|    approx_ln(kl)            | 8.27234      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.87         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8540         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0353       |
|    value_loss               | 3.58         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.57214046] |
| time/                       |               |
|    fps                      | 117           |
|    iterations               | 23            |
|    time_elapsed             | 401           |
|    total_timesteps          | 1753088       |
| train/                      |               |
|    approx_kl                | 5349.172      |
|    approx_ln(kl)            | 8.584697      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.86          |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 8550          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0356        |
|    value_loss               | 3.11          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.2870226] |
| time/                       |              |
|    fps                      | 107          |
|    iterations               | 24           |
|    time_elapsed             | 455          |
|    total_timesteps          | 1755136      |
| train/                      |              |
|    approx_kl                | 6278.309     |
|    approx_ln(kl)            | 8.744856     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.86         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8560         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0355       |
|    value_loss               | 1.21         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.561124] |
| time/                       |             |
|    fps                      | 106         |
|    iterations               | 25          |
|    time_elapsed             | 480         |
|    total_timesteps          | 1757184     |
| train/                      |             |
|    approx_kl                | 1150.2843   |
|    approx_ln(kl)            | 7.0477643   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.86        |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 8570        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0354      |
|    value_loss               | 2.32        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.7378273] |
| time/                       |              |
|    fps                      | 107          |
|    iterations               | 26           |
|    time_elapsed             | 496          |
|    total_timesteps          | 1759232      |
| train/                      |              |
|    approx_kl                | 3920.9202    |
|    approx_ln(kl)            | 8.274081     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.86         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8580         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0353       |
|    value_loss               | 3.38         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.24970461] |
| time/                       |               |
|    fps                      | 108           |
|    iterations               | 27            |
|    time_elapsed             | 510           |
|    total_timesteps          | 1761280       |
| train/                      |               |
|    approx_kl                | 15426.593     |
|    approx_ln(kl)            | 9.643848      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.88          |
|    explained_variance       | 1             |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 8590          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0352        |
|    value_loss               | 1.55          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.38565248] |
| time/                       |               |
|    fps                      | 109           |
|    iterations               | 28            |
|    time_elapsed             | 524           |
|    total_timesteps          | 1763328       |
| train/                      |               |
|    approx_kl                | 17184.27      |
|    approx_ln(kl)            | 9.75175       |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.88          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 8600          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0352        |
|    value_loss               | 1.25          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.40928218] |
| time/                       |               |
|    fps                      | 110           |
|    iterations               | 29            |
|    time_elapsed             | 538           |
|    total_timesteps          | 1765376       |
| train/                      |               |
|    approx_kl                | 1361.0453     |
|    approx_ln(kl)            | 7.216008      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.88          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 8610          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0351        |
|    value_loss               | 1.63          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.4839408] |
| time/                       |              |
|    fps                      | 111          |
|    iterations               | 30           |
|    time_elapsed             | 552          |
|    total_timesteps          | 1767424      |
| train/                      |              |
|    approx_kl                | 14672.416    |
|    approx_ln(kl)            | 9.593724     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.9          |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8620         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0347       |
|    value_loss               | 0.707        |
----------------------------------------------
-----------------------------------------------
| reward                      | [-0.82108927] |
| time/                       |               |
|    fps                      | 112           |
|    iterations               | 31            |
|    time_elapsed             | 566           |
|    total_timesteps          | 1769472       |
| train/                      |               |
|    approx_kl                | 7232.825      |
|    approx_ln(kl)            | 8.886385      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.89          |
|    explained_variance       | 1             |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 8630          |
|    policy_gradient_loss     | inf           |
|    std                      | 0.035         |
|    value_loss               | 0.656         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.39944586] |
| time/                       |               |
|    fps                      | 112           |
|    iterations               | 32            |
|    time_elapsed             | 580           |
|    total_timesteps          | 1771520       |
| train/                      |               |
|    approx_kl                | 2020.4446     |
|    approx_ln(kl)            | 7.611073      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.88          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 8640          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0351        |
|    value_loss               | 1.01          |
-----------------------------------------------
-----------------------------------------------
| reward                      | [-0.47246838] |
| time/                       |               |
|    fps                      | 113           |
|    iterations               | 33            |
|    time_elapsed             | 594           |
|    total_timesteps          | 1773568       |
| train/                      |               |
|    approx_kl                | 5920.501      |
|    approx_ln(kl)            | 8.686176      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.9           |
|    explained_variance       | 1             |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 8650          |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0347        |
|    value_loss               | 1.05          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.8201427] |
| time/                       |              |
|    fps                      | 114          |
|    iterations               | 34           |
|    time_elapsed             | 608          |
|    total_timesteps          | 1775616      |
| train/                      |              |
|    approx_kl                | 21788.922    |
|    approx_ln(kl)            | 9.989157     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.91         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8660         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0346       |
|    value_loss               | 0.721        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.43775418] |
| time/                       |               |
|    fps                      | 115           |
|    iterations               | 35            |
|    time_elapsed             | 622           |
|    total_timesteps          | 1777664       |
| train/                      |               |
|    approx_kl                | 13503.505     |
|    approx_ln(kl)            | 9.510705      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.92          |
|    explained_variance       | 1             |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 8670          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0344        |
|    value_loss               | 0.533         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.3451107] |
| time/                       |              |
|    fps                      | 115          |
|    iterations               | 36           |
|    time_elapsed             | 636          |
|    total_timesteps          | 1779712      |
| train/                      |              |
|    approx_kl                | 23195.3      |
|    approx_ln(kl)            | 10.051705    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.93         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8680         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0342       |
|    value_loss               | 0.293        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.3110689] |
| time/                       |              |
|    fps                      | 116          |
|    iterations               | 37           |
|    time_elapsed             | 650          |
|    total_timesteps          | 1781760      |
| train/                      |              |
|    approx_kl                | 21597.852    |
|    approx_ln(kl)            | 9.98035      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.94         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8690         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.034        |
|    value_loss               | 0.476        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.164967] |
| time/                       |             |
|    fps                      | 117         |
|    iterations               | 38          |
|    time_elapsed             | 664         |
|    total_timesteps          | 1783808     |
| train/                      |             |
|    approx_kl                | 6464.2266   |
|    approx_ln(kl)            | 8.774038    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.9         |
|    explained_variance       | 1           |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 8700        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0348      |
|    value_loss               | 0.411       |
---------------------------------------------
----------------------------------------------
| reward                      | [-0.5373766] |
| time/                       |              |
|    fps                      | 117          |
|    iterations               | 39           |
|    time_elapsed             | 678          |
|    total_timesteps          | 1785856      |
| train/                      |              |
|    approx_kl                | 10725.696    |
|    approx_ln(kl)            | 9.280397     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.89         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 8710         |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0349       |
|    value_loss               | 0.352        |
----------------------------------------------
-----------------------------------------------
| reward                      | [-0.22024147] |
| time/                       |               |
|    fps                      | 118           |
|    iterations               | 40            |
|    time_elapsed             | 691           |
|    total_timesteps          | 1787904       |
| train/                      |               |
|    approx_kl                | 6807.276      |
|    approx_ln(kl)            | 8.8257475     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.89          |
|    explained_variance       | 1             |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 8720          |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0348        |
|    value_loss               | 0.712         |
-----------------------------------------------
----------------------------------------------
| reward                      | [-1.4086943] |
| time/                       |              |
|    fps                      | 118          |
|    iterations               | 41           |
|    time_elapsed             | 706          |
|    total_timesteps          | 1789952      |
| train/                      |              |
|    approx_kl                | 13664.914    |
|    approx_ln(kl)            | 9.522587     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.88         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 8730         |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0351       |
|    value_loss               | 0.762        |
----------------------------------------------
-----------------------------------------------
| reward                      | [-0.46606347] |
| time/                       |               |
|    fps                      | 119           |
|    iterations               | 42            |
|    time_elapsed             | 720           |
|    total_timesteps          | 1792000       |
| train/                      |               |
|    approx_kl                | 14275.523     |
|    approx_ln(kl)            | 9.566301      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.9           |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 8740          |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0347        |
|    value_loss               | 0.255         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.1641912] |
| time/                       |              |
|    fps                      | 119          |
|    iterations               | 43           |
|    time_elapsed             | 734          |
|    total_timesteps          | 1794048      |
| train/                      |              |
|    approx_kl                | 7512.508     |
|    approx_ln(kl)            | 8.924325     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.9          |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8750         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0348       |
|    value_loss               | 0.317        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.3336465] |
| time/                       |              |
|    fps                      | 120          |
|    iterations               | 44           |
|    time_elapsed             | 747          |
|    total_timesteps          | 1796096      |
| train/                      |              |
|    approx_kl                | 17808.984    |
|    approx_ln(kl)            | 9.787458     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.89         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8760         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.035        |
|    value_loss               | 0.182        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.1483327] |
| time/                       |              |
|    fps                      | 120          |
|    iterations               | 45           |
|    time_elapsed             | 761          |
|    total_timesteps          | 1798144      |
| train/                      |              |
|    approx_kl                | 24201.488    |
|    approx_ln(kl)            | 10.09417     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.89         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8770         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0351       |
|    value_loss               | 1.37         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.0944803] |
| time/                       |              |
|    fps                      | 121          |
|    iterations               | 46           |
|    time_elapsed             | 775          |
|    total_timesteps          | 1800192      |
| train/                      |              |
|    approx_kl                | 1627.111     |
|    approx_ln(kl)            | 7.3945613    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.88         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8780         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0353       |
|    value_loss               | 2.2          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.9242806] |
| time/                       |              |
|    fps                      | 121          |
|    iterations               | 47           |
|    time_elapsed             | 789          |
|    total_timesteps          | 1802240      |
| train/                      |              |
|    approx_kl                | 4278.201     |
|    approx_ln(kl)            | 8.361288     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.87         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8790         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0354       |
|    value_loss               | 0.688        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.39359903] |
| time/                       |               |
|    fps                      | 122           |
|    iterations               | 48            |
|    time_elapsed             | 803           |
|    total_timesteps          | 1804288       |
| train/                      |               |
|    approx_kl                | 10062.449     |
|    approx_ln(kl)            | 9.216566      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.88          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 8800          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0354        |
|    value_loss               | 0.685         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.46413445] |
| time/                       |               |
|    fps                      | 122           |
|    iterations               | 49            |
|    time_elapsed             | 817           |
|    total_timesteps          | 1806336       |
| train/                      |               |
|    approx_kl                | 30481.605     |
|    approx_ln(kl)            | 10.324879     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.91          |
|    explained_variance       | 1             |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 8810          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0349        |
|    value_loss               | 0.256         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-------------------------------------
| reward             | [-0.7986077] |
| time/              |              |
|    fps             | 162          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 1808384      |
-------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.1752003] |
| time/                       |              |
|    fps                      | 154          |
|    iterations               | 2            |
|    time_elapsed             | 26           |
|    total_timesteps          | 1810432      |
| train/                      |              |
|    approx_kl                | 33324.1      |
|    approx_ln(kl)            | 10.414036    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.9          |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8830         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0353       |
|    value_loss               | 0.645        |
----------------------------------------------
-----------------------------------------------
| reward                      | [-0.42893356] |
| time/                       |               |
|    fps                      | 148           |
|    iterations               | 3             |
|    time_elapsed             | 41            |
|    total_timesteps          | 1812480       |
| train/                      |               |
|    approx_kl                | 2205.7031     |
|    approx_ln(kl)            | 7.6988015     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.9           |
|    explained_variance       | 0.997         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 8840          |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0352        |
|    value_loss               | 0.515         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.8659036] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 4            |
|    time_elapsed             | 55           |
|    total_timesteps          | 1814528      |
| train/                      |              |
|    approx_kl                | 9443.277     |
|    approx_ln(kl)            | 9.153058     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.9          |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8850         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0353       |
|    value_loss               | 0.712        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.33878076] |
| time/                       |               |
|    fps                      | 147           |
|    iterations               | 5             |
|    time_elapsed             | 69            |
|    total_timesteps          | 1816576       |
| train/                      |               |
|    approx_kl                | 9197.295      |
|    approx_ln(kl)            | 9.126665      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.9           |
|    explained_variance       | 1             |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 8860          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0355        |
|    value_loss               | 0.238         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.4365387] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 6            |
|    time_elapsed             | 84           |
|    total_timesteps          | 1818624      |
| train/                      |              |
|    approx_kl                | 25280.975    |
|    approx_ln(kl)            | 10.137808    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.9          |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8870         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0356       |
|    value_loss               | 0.169        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.303087] |
| time/                       |             |
|    fps                      | 144         |
|    iterations               | 7           |
|    time_elapsed             | 99          |
|    total_timesteps          | 1820672     |
| train/                      |             |
|    approx_kl                | 39799.113   |
|    approx_ln(kl)            | 10.5916     |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.9         |
|    explained_variance       | 1           |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 8880        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0354      |
|    value_loss               | 0.256       |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.27504313] |
| time/                       |               |
|    fps                      | 144           |
|    iterations               | 8             |
|    time_elapsed             | 113           |
|    total_timesteps          | 1822720       |
| train/                      |               |
|    approx_kl                | 6224.013      |
|    approx_ln(kl)            | 8.73617       |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.92          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 8890          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.035         |
|    value_loss               | 1.29          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.6517735] |
| time/                       |              |
|    fps                      | 144          |
|    iterations               | 9            |
|    time_elapsed             | 127          |
|    total_timesteps          | 1824768      |
| train/                      |              |
|    approx_kl                | 3684.4617    |
|    approx_ln(kl)            | 8.21188      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.91         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8900         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0353       |
|    value_loss               | 0.21         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.28427553] |
| time/                       |               |
|    fps                      | 144           |
|    iterations               | 10            |
|    time_elapsed             | 141           |
|    total_timesteps          | 1826816       |
| train/                      |               |
|    approx_kl                | 7684.051      |
|    approx_ln(kl)            | 8.946902      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.93          |
|    explained_variance       | 1             |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 8910          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.035         |
|    value_loss               | 0.293         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.3854366] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 11           |
|    time_elapsed             | 155          |
|    total_timesteps          | 1828864      |
| train/                      |              |
|    approx_kl                | 8472.469     |
|    approx_ln(kl)            | 9.044578     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.99         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8920         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0341       |
|    value_loss               | 0.416        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.3705067] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 12           |
|    time_elapsed             | 169          |
|    total_timesteps          | 1830912      |
| train/                      |              |
|    approx_kl                | 16024.106    |
|    approx_ln(kl)            | 9.6818495    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.98         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8930         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0344       |
|    value_loss               | 0.425        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.4787549] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 13           |
|    time_elapsed             | 182          |
|    total_timesteps          | 1832960      |
| train/                      |              |
|    approx_kl                | 9735.732     |
|    approx_ln(kl)            | 9.183558     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.96         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8940         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0348       |
|    value_loss               | 0.809        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.2809916] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 14           |
|    time_elapsed             | 196          |
|    total_timesteps          | 1835008      |
| train/                      |              |
|    approx_kl                | 18097.867    |
|    approx_ln(kl)            | 9.80355      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.97         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8950         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0347       |
|    value_loss               | 0.201        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.8254905] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 15           |
|    time_elapsed             | 210          |
|    total_timesteps          | 1837056      |
| train/                      |              |
|    approx_kl                | 16195.197    |
|    approx_ln(kl)            | 9.69247      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.97         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8960         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0346       |
|    value_loss               | 0.498        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-0.335418] |
| time/                       |             |
|    fps                      | 145         |
|    iterations               | 16          |
|    time_elapsed             | 224         |
|    total_timesteps          | 1839104     |
| train/                      |             |
|    approx_kl                | 18438.32    |
|    approx_ln(kl)            | 9.822186    |
|    clip_range               | 0.2         |
|    entropy_loss             | 4.01        |
|    explained_variance       | 1           |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 8970        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0337      |
|    value_loss               | 0.172       |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.48423183] |
| time/                       |               |
|    fps                      | 145           |
|    iterations               | 17            |
|    time_elapsed             | 238           |
|    total_timesteps          | 1841152       |
| train/                      |               |
|    approx_kl                | 18857.066     |
|    approx_ln(kl)            | 9.844643      |
|    clip_range               | 0.2           |
|    entropy_loss             | 4.01          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 8980          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0338        |
|    value_loss               | 0.335         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4367976] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 18           |
|    time_elapsed             | 252          |
|    total_timesteps          | 1843200      |
| train/                      |              |
|    approx_kl                | 10467.826    |
|    approx_ln(kl)            | 9.256062     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.99         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 8990         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0341       |
|    value_loss               | 0.138        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5377036] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 19           |
|    time_elapsed             | 266          |
|    total_timesteps          | 1845248      |
| train/                      |              |
|    approx_kl                | 12175.694    |
|    approx_ln(kl)            | 9.407197     |
|    clip_range               | 0.2          |
|    entropy_loss             | 4            |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9000         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.034        |
|    value_loss               | 0.0884       |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.9183863] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 20           |
|    time_elapsed             | 280          |
|    total_timesteps          | 1847296      |
| train/                      |              |
|    approx_kl                | 6575.3584    |
|    approx_ln(kl)            | 8.791084     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.98         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9010         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0341       |
|    value_loss               | 0.0828       |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.67836636] |
| time/                       |               |
|    fps                      | 146           |
|    iterations               | 21            |
|    time_elapsed             | 294           |
|    total_timesteps          | 1849344       |
| train/                      |               |
|    approx_kl                | 7919.7793     |
|    approx_ln(kl)            | 8.9771185     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.99          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 9020          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0339        |
|    value_loss               | 0.493         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7666407] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 22           |
|    time_elapsed             | 308          |
|    total_timesteps          | 1851392      |
| train/                      |              |
|    approx_kl                | 11499.832    |
|    approx_ln(kl)            | 9.350088     |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.02         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9030         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0334       |
|    value_loss               | 0.247        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5936351] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 23           |
|    time_elapsed             | 322          |
|    total_timesteps          | 1853440      |
| train/                      |              |
|    approx_kl                | 2200.222     |
|    approx_ln(kl)            | 7.6963134    |
|    clip_range               | 0.2          |
|    entropy_loss             | 4            |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9040         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0338       |
|    value_loss               | 1.16         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.58421004] |
| time/                       |               |
|    fps                      | 146           |
|    iterations               | 24            |
|    time_elapsed             | 335           |
|    total_timesteps          | 1855488       |
| train/                      |               |
|    approx_kl                | 3873.0876     |
|    approx_ln(kl)            | 8.261807      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.99          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 9050          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0341        |
|    value_loss               | 1.15          |
-----------------------------------------------
----------------------------------------------
| reward                      | [-2.4053833] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 25           |
|    time_elapsed             | 349          |
|    total_timesteps          | 1857536      |
| train/                      |              |
|    approx_kl                | 14237.078    |
|    approx_ln(kl)            | 9.563605     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.98         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 9060         |
|    policy_gradient_loss     | inf          |
|    std                      | 0.034        |
|    value_loss               | 0.422        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.0945232] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 26           |
|    time_elapsed             | 364          |
|    total_timesteps          | 1859584      |
| train/                      |              |
|    approx_kl                | 11331.59     |
|    approx_ln(kl)            | 9.33535      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.98         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9070         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0338       |
|    value_loss               | 1.38         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.9459379] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 27           |
|    time_elapsed             | 377          |
|    total_timesteps          | 1861632      |
| train/                      |              |
|    approx_kl                | 10443.514    |
|    approx_ln(kl)            | 9.2537365    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.99         |
|    explained_variance       | 0.984        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9080         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0338       |
|    value_loss               | 34.8         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.919604] |
| time/                       |             |
|    fps                      | 146         |
|    iterations               | 28          |
|    time_elapsed             | 391         |
|    total_timesteps          | 1863680     |
| train/                      |             |
|    approx_kl                | 1748.5815   |
|    approx_ln(kl)            | 7.4665604   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.99        |
|    explained_variance       | 0.982       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 9090        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0337      |
|    value_loss               | 26.4        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
--------------------------------------------
| reward                      | [-4.42457] |
| time/                       |            |
|    fps                      | 146        |
|    iterations               | 29         |
|    time_elapsed             | 405        |
|    total_timesteps          | 1865728    |
| train/                      |            |
|    approx_kl                | 2328.8997  |
|    approx_ln(kl)            | 7.7531514  |
|    clip_range               | 0.2        |
|    entropy_loss             | 3.96       |
|    explained_variance       | 0.983      |
|    learning_rate            | 0.001      |
|    ln(loss)                 | inf        |
|    ln(policy_gradient_loss) | nan        |
|    loss                     | inf        |
|    n_updates                | 9100       |
|    policy_gradient_loss     | nan        |
|    std                      | 0.0343     |
|    value_loss               | 36.7       |
--------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.545201] |
| time/                       |             |
|    fps                      | 146         |
|    iterations               | 30          |
|    time_elapsed             | 419         |
|    total_timesteps          | 1867776     |
| train/                      |             |
|    approx_kl                | 2174.1335   |
|    approx_ln(kl)            | 7.6843853   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.92        |
|    explained_variance       | 0.981       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 9110        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.035       |
|    value_loss               | 32.7        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.50378567] |
| time/                       |               |
|    fps                      | 146           |
|    iterations               | 31            |
|    time_elapsed             | 433           |
|    total_timesteps          | 1869824       |
| train/                      |               |
|    approx_kl                | 15387.803     |
|    approx_ln(kl)            | 9.641331      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.93          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 9120          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0347        |
|    value_loss               | 1.6           |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7168562] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 32           |
|    time_elapsed             | 446          |
|    total_timesteps          | 1871872      |
| train/                      |              |
|    approx_kl                | 3651.3276    |
|    approx_ln(kl)            | 8.202847     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.93         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9130         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0349       |
|    value_loss               | 2.07         |
----------------------------------------------
----------------------------------------------
| reward                      | [-1.4704021] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 33           |
|    time_elapsed             | 460          |
|    total_timesteps          | 1873920      |
| train/                      |              |
|    approx_kl                | 9710.143     |
|    approx_ln(kl)            | 9.180926     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.91         |
|    explained_variance       | 0.99         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 9140         |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0353       |
|    value_loss               | 17.7         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.8735038] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 34           |
|    time_elapsed             | 475          |
|    total_timesteps          | 1875968      |
| train/                      |              |
|    approx_kl                | 2945.5698    |
|    approx_ln(kl)            | 7.9880576    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.93         |
|    explained_variance       | 0.987        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9150         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.035        |
|    value_loss               | 25           |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.7118971] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 35           |
|    time_elapsed             | 489          |
|    total_timesteps          | 1878016      |
| train/                      |              |
|    approx_kl                | 3579.8774    |
|    approx_ln(kl)            | 8.183084     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.94         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9160         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0349       |
|    value_loss               | 10           |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.3304416] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 36           |
|    time_elapsed             | 502          |
|    total_timesteps          | 1880064      |
| train/                      |              |
|    approx_kl                | 1863.897     |
|    approx_ln(kl)            | 7.5304246    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.92         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9170         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0353       |
|    value_loss               | 4.2          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.0489883] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 37           |
|    time_elapsed             | 516          |
|    total_timesteps          | 1882112      |
| train/                      |              |
|    approx_kl                | 3755.0479    |
|    approx_ln(kl)            | 8.230856     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.92         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9180         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0353       |
|    value_loss               | 3.3          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.0123534] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 38           |
|    time_elapsed             | 530          |
|    total_timesteps          | 1884160      |
| train/                      |              |
|    approx_kl                | 6454.6143    |
|    approx_ln(kl)            | 8.772551     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.93         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9190         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0349       |
|    value_loss               | 2.19         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.1044235] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 39           |
|    time_elapsed             | 544          |
|    total_timesteps          | 1886208      |
| train/                      |              |
|    approx_kl                | 2205.217     |
|    approx_ln(kl)            | 7.698581     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.96         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9200         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0345       |
|    value_loss               | 11.3         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.8586922] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 40           |
|    time_elapsed             | 558          |
|    total_timesteps          | 1888256      |
| train/                      |              |
|    approx_kl                | 562.6273     |
|    approx_ln(kl)            | 6.3326173    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.96         |
|    explained_variance       | 0.991        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9210         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0345       |
|    value_loss               | 14.4         |
----------------------------------------------
----------------------------------------------
| reward                      | [-5.4066763] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 41           |
|    time_elapsed             | 572          |
|    total_timesteps          | 1890304      |
| train/                      |              |
|    approx_kl                | 3998.9165    |
|    approx_ln(kl)            | 8.293778     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.95         |
|    explained_variance       | 0.992        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 9220         |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0346       |
|    value_loss               | 12           |
----------------------------------------------
----------------------------------------------
| reward                      | [-0.7121008] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 42           |
|    time_elapsed             | 586          |
|    total_timesteps          | 1892352      |
| train/                      |              |
|    approx_kl                | 15830.384    |
|    approx_ln(kl)            | 9.669686     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.96         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 9230         |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0344       |
|    value_loss               | 1.62         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7674112] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 43           |
|    time_elapsed             | 599          |
|    total_timesteps          | 1894400      |
| train/                      |              |
|    approx_kl                | 14738.656    |
|    approx_ln(kl)            | 9.598229     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.96         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9240         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0344       |
|    value_loss               | 2.86         |
----------------------------------------------
----------------------------------------------
| reward                      | [-0.7584607] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 44           |
|    time_elapsed             | 613          |
|    total_timesteps          | 1896448      |
| train/                      |              |
|    approx_kl                | 7823.6963    |
|    approx_ln(kl)            | 8.964912     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.94         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 9250         |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0347       |
|    value_loss               | 1.65         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.38569516] |
| time/                       |               |
|    fps                      | 146           |
|    iterations               | 45            |
|    time_elapsed             | 627           |
|    total_timesteps          | 1898496       |
| train/                      |               |
|    approx_kl                | 13334.817     |
|    approx_ln(kl)            | 9.498134      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.9           |
|    explained_variance       | 0.996         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 9260          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0355        |
|    value_loss               | 1.59          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.759843] |
| time/                       |             |
|    fps                      | 146         |
|    iterations               | 46          |
|    time_elapsed             | 641         |
|    total_timesteps          | 1900544     |
| train/                      |             |
|    approx_kl                | 3903.7349   |
|    approx_ln(kl)            | 8.269689    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.9         |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 9270        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0354      |
|    value_loss               | 1.53        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0469058] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 47           |
|    time_elapsed             | 655          |
|    total_timesteps          | 1902592      |
| train/                      |              |
|    approx_kl                | 20328.21     |
|    approx_ln(kl)            | 9.9197645    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.92         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9280         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0351       |
|    value_loss               | 0.548        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.65270126] |
| time/                       |               |
|    fps                      | 146           |
|    iterations               | 48            |
|    time_elapsed             | 669           |
|    total_timesteps          | 1904640       |
| train/                      |               |
|    approx_kl                | 19501.3       |
|    approx_ln(kl)            | 9.878237      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.9           |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 9290          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0356        |
|    value_loss               | 3.66          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0185612] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 49           |
|    time_elapsed             | 683          |
|    total_timesteps          | 1906688      |
| train/                      |              |
|    approx_kl                | 18025.863    |
|    approx_ln(kl)            | 9.799562     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.91         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9300         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0356       |
|    value_loss               | 1.12         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-------------------------------------
| reward             | [-0.6245198] |
| time/              |              |
|    fps             | 159          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 1908736      |
-------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.3272099] |
| time/                       |              |
|    fps                      | 128          |
|    iterations               | 2            |
|    time_elapsed             | 31           |
|    total_timesteps          | 1910784      |
| train/                      |              |
|    approx_kl                | 4206.63      |
|    approx_ln(kl)            | 8.344418     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.92         |
|    explained_variance       | 0.978        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9320         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0354       |
|    value_loss               | 1.95         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.28575704] |
| time/                       |               |
|    fps                      | 133           |
|    iterations               | 3             |
|    time_elapsed             | 45            |
|    total_timesteps          | 1912832       |
| train/                      |               |
|    approx_kl                | 8133.196      |
|    approx_ln(kl)            | 9.003709      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.92          |
|    explained_variance       | 0.3           |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 9330          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0354        |
|    value_loss               | 4.46          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.63792783] |
| time/                       |               |
|    fps                      | 132           |
|    iterations               | 4             |
|    time_elapsed             | 61            |
|    total_timesteps          | 1914880       |
| train/                      |               |
|    approx_kl                | 18322.318     |
|    approx_ln(kl)            | 9.815875      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.89          |
|    explained_variance       | 0.988         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 9340          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0355        |
|    value_loss               | 1.24          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.35727805] |
| time/                       |               |
|    fps                      | 135           |
|    iterations               | 5             |
|    time_elapsed             | 75            |
|    total_timesteps          | 1916928       |
| train/                      |               |
|    approx_kl                | 13508.479     |
|    approx_ln(kl)            | 9.511073      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.89          |
|    explained_variance       | 0.991         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 9350          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0356        |
|    value_loss               | 1.25          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.9767788] |
| time/                       |              |
|    fps                      | 137          |
|    iterations               | 6            |
|    time_elapsed             | 89           |
|    total_timesteps          | 1918976      |
| train/                      |              |
|    approx_kl                | 29110.7      |
|    approx_ln(kl)            | 10.278861    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.92         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9360         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.035        |
|    value_loss               | 0.884        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.0045693] |
| time/                       |              |
|    fps                      | 138          |
|    iterations               | 7            |
|    time_elapsed             | 103          |
|    total_timesteps          | 1921024      |
| train/                      |              |
|    approx_kl                | 21340.137    |
|    approx_ln(kl)            | 9.968345     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.89         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9370         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0355       |
|    value_loss               | 3.96         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.5559936] |
| time/                       |              |
|    fps                      | 139          |
|    iterations               | 8            |
|    time_elapsed             | 117          |
|    total_timesteps          | 1923072      |
| train/                      |              |
|    approx_kl                | 5483.674     |
|    approx_ln(kl)            | 8.60953      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.89         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9380         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0356       |
|    value_loss               | 4.71         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.5785567] |
| time/                       |              |
|    fps                      | 140          |
|    iterations               | 9            |
|    time_elapsed             | 131          |
|    total_timesteps          | 1925120      |
| train/                      |              |
|    approx_kl                | 3908.103     |
|    approx_ln(kl)            | 8.270807     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.89         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9390         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0355       |
|    value_loss               | 3.08         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.281387] |
| time/                       |             |
|    fps                      | 141         |
|    iterations               | 10          |
|    time_elapsed             | 144         |
|    total_timesteps          | 1927168     |
| train/                      |             |
|    approx_kl                | 10738.199   |
|    approx_ln(kl)            | 9.281563    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.91        |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 9400        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0354      |
|    value_loss               | 5.37        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.8073037] |
| time/                       |              |
|    fps                      | 141          |
|    iterations               | 11           |
|    time_elapsed             | 158          |
|    total_timesteps          | 1929216      |
| train/                      |              |
|    approx_kl                | 6988.809     |
|    approx_ln(kl)            | 8.852065     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.9          |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9410         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0352       |
|    value_loss               | 7.31         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.9812076] |
| time/                       |              |
|    fps                      | 142          |
|    iterations               | 12           |
|    time_elapsed             | 172          |
|    total_timesteps          | 1931264      |
| train/                      |              |
|    approx_kl                | 16337.055    |
|    approx_ln(kl)            | 9.701191     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.85         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9420         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0363       |
|    value_loss               | 2.27         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.25261283] |
| time/                       |               |
|    fps                      | 142           |
|    iterations               | 13            |
|    time_elapsed             | 186           |
|    total_timesteps          | 1933312       |
| train/                      |               |
|    approx_kl                | 103782.53     |
|    approx_ln(kl)            | 11.550053     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.85          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 9430          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.036         |
|    value_loss               | 0.351         |
-----------------------------------------------
----------------------------------------------
| reward                      | [-0.5849128] |
| time/                       |              |
|    fps                      | 143          |
|    iterations               | 14           |
|    time_elapsed             | 200          |
|    total_timesteps          | 1935360      |
| train/                      |              |
|    approx_kl                | 9033.68      |
|    approx_ln(kl)            | 9.108715     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.84         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 9440         |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0363       |
|    value_loss               | 2.64         |
----------------------------------------------
----------------------------------------------
| reward                      | [-1.3091664] |
| time/                       |              |
|    fps                      | 143          |
|    iterations               | 15           |
|    time_elapsed             | 213          |
|    total_timesteps          | 1937408      |
| train/                      |              |
|    approx_kl                | 3424.691     |
|    approx_ln(kl)            | 8.138766     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.83         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 9450         |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0364       |
|    value_loss               | 1.69         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.6644937] |
| time/                       |              |
|    fps                      | 143          |
|    iterations               | 16           |
|    time_elapsed             | 227          |
|    total_timesteps          | 1939456      |
| train/                      |              |
|    approx_kl                | 14875.201    |
|    approx_ln(kl)            | 9.6074505    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.82         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9460         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0366       |
|    value_loss               | 1.37         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.66325235] |
| time/                       |               |
|    fps                      | 144           |
|    iterations               | 17            |
|    time_elapsed             | 241           |
|    total_timesteps          | 1941504       |
| train/                      |               |
|    approx_kl                | 29302.828     |
|    approx_ln(kl)            | 10.2854395    |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.81          |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 9470          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0366        |
|    value_loss               | 1.06          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.3669804] |
| time/                       |              |
|    fps                      | 144          |
|    iterations               | 18           |
|    time_elapsed             | 255          |
|    total_timesteps          | 1943552      |
| train/                      |              |
|    approx_kl                | 14981.473    |
|    approx_ln(kl)            | 9.61457      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.84         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9480         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0361       |
|    value_loss               | 0.952        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-1.707574] |
| time/                       |             |
|    fps                      | 144         |
|    iterations               | 19          |
|    time_elapsed             | 269         |
|    total_timesteps          | 1945600     |
| train/                      |             |
|    approx_kl                | 39053.492   |
|    approx_ln(kl)            | 10.572687   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.82        |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 9490        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0365      |
|    value_loss               | 0.86        |
---------------------------------------------
----------------------------------------------
| reward                      | [-1.7002524] |
| time/                       |              |
|    fps                      | 144          |
|    iterations               | 20           |
|    time_elapsed             | 283          |
|    total_timesteps          | 1947648      |
| train/                      |              |
|    approx_kl                | 28023.047    |
|    approx_ln(kl)            | 10.240783    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.81         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 9500         |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0369       |
|    value_loss               | 1.27         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.3661165] |
| time/                       |              |
|    fps                      | 144          |
|    iterations               | 21           |
|    time_elapsed             | 296          |
|    total_timesteps          | 1949696      |
| train/                      |              |
|    approx_kl                | 16527.83     |
|    approx_ln(kl)            | 9.712801     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.79         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9510         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0372       |
|    value_loss               | 1.73         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-5.090521] |
| time/                       |             |
|    fps                      | 145         |
|    iterations               | 22          |
|    time_elapsed             | 310         |
|    total_timesteps          | 1951744     |
| train/                      |             |
|    approx_kl                | 6489.208    |
|    approx_ln(kl)            | 8.777896    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.79        |
|    explained_variance       | 0.997       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 9520        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0372      |
|    value_loss               | 5.89        |
---------------------------------------------
--------------------------------------------
| reward                      | [-5.29836] |
| time/                       |            |
|    fps                      | 145        |
|    iterations               | 23         |
|    time_elapsed             | 324        |
|    total_timesteps          | 1953792    |
| train/                      |            |
|    approx_kl                | 2022.6978  |
|    approx_ln(kl)            | 7.6121874  |
|    clip_range               | 0.2        |
|    entropy_loss             | 3.79       |
|    explained_variance       | 0.996      |
|    learning_rate            | 0.001      |
|    ln(loss)                 | inf        |
|    ln(policy_gradient_loss) | inf        |
|    loss                     | inf        |
|    n_updates                | 9530       |
|    policy_gradient_loss     | inf        |
|    std                      | 0.037      |
|    value_loss               | 16.7       |
--------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.50875103] |
| time/                       |               |
|    fps                      | 145           |
|    iterations               | 24            |
|    time_elapsed             | 338           |
|    total_timesteps          | 1955840       |
| train/                      |               |
|    approx_kl                | 21797.39      |
|    approx_ln(kl)            | 9.989546      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.79          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 9540          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0371        |
|    value_loss               | 3.81          |
-----------------------------------------------
---------------------------------------------
| reward                      | [-1.415631] |
| time/                       |             |
|    fps                      | 145         |
|    iterations               | 25          |
|    time_elapsed             | 351         |
|    total_timesteps          | 1957888     |
| train/                      |             |
|    approx_kl                | 7678.5127   |
|    approx_ln(kl)            | 8.946181    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.78        |
|    explained_variance       | 0.996       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | inf         |
|    loss                     | inf         |
|    n_updates                | 9550        |
|    policy_gradient_loss     | inf         |
|    std                      | 0.0373      |
|    value_loss               | 5.97        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.1283007] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 26           |
|    time_elapsed             | 365          |
|    total_timesteps          | 1959936      |
| train/                      |              |
|    approx_kl                | 5769.832     |
|    approx_ln(kl)            | 8.6603985    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.77         |
|    explained_variance       | 0.99         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9560         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0377       |
|    value_loss               | 9.12         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.674609] |
| time/                       |             |
|    fps                      | 145         |
|    iterations               | 27          |
|    time_elapsed             | 379         |
|    total_timesteps          | 1961984     |
| train/                      |             |
|    approx_kl                | 1218.2891   |
|    approx_ln(kl)            | 7.1052027   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.74        |
|    explained_variance       | 0.995       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 9570        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0378      |
|    value_loss               | 8.89        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.211364] |
| time/                       |             |
|    fps                      | 145         |
|    iterations               | 28          |
|    time_elapsed             | 393         |
|    total_timesteps          | 1964032     |
| train/                      |             |
|    approx_kl                | 7267.239    |
|    approx_ln(kl)            | 8.891131    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.73        |
|    explained_variance       | 0.994       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 9580        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0381      |
|    value_loss               | 10.8        |
---------------------------------------------
----------------------------------------------
| reward                      | [-3.2376082] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 29           |
|    time_elapsed             | 407          |
|    total_timesteps          | 1966080      |
| train/                      |              |
|    approx_kl                | 1789.1084    |
|    approx_ln(kl)            | 7.489473     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.72         |
|    explained_variance       | 0.992        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 9590         |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0382       |
|    value_loss               | 9.88         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.7313547] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 30           |
|    time_elapsed             | 422          |
|    total_timesteps          | 1968128      |
| train/                      |              |
|    approx_kl                | 2552.5696    |
|    approx_ln(kl)            | 7.844856     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.74         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9600         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0376       |
|    value_loss               | 10.5         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.1231937] |
| time/                       |              |
|    fps                      | 143          |
|    iterations               | 31           |
|    time_elapsed             | 442          |
|    total_timesteps          | 1970176      |
| train/                      |              |
|    approx_kl                | 6626.8096    |
|    approx_ln(kl)            | 8.798879     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.76         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9610         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0375       |
|    value_loss               | 4.28         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.463902] |
| time/                       |             |
|    fps                      | 120         |
|    iterations               | 32          |
|    time_elapsed             | 546         |
|    total_timesteps          | 1972224     |
| train/                      |             |
|    approx_kl                | 14723.609   |
|    approx_ln(kl)            | 9.597208    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.73        |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 9620        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0382      |
|    value_loss               | 4.91        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.707431] |
| time/                       |             |
|    fps                      | 115         |
|    iterations               | 33          |
|    time_elapsed             | 585         |
|    total_timesteps          | 1974272     |
| train/                      |             |
|    approx_kl                | 5810.328    |
|    approx_ln(kl)            | 8.667393    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.73        |
|    explained_variance       | 0.995       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 9630        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.038       |
|    value_loss               | 10.3        |
---------------------------------------------
----------------------------------------------
| reward                      | [-0.6318755] |
| time/                       |              |
|    fps                      | 116          |
|    iterations               | 34           |
|    time_elapsed             | 599          |
|    total_timesteps          | 1976320      |
| train/                      |              |
|    approx_kl                | 1453.0092    |
|    approx_ln(kl)            | 7.281392     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.73         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 9640         |
|    policy_gradient_loss     | inf          |
|    std                      | 0.038        |
|    value_loss               | 5.02         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
--------------------------------------------
| reward                      | [-0.71188] |
| time/                       |            |
|    fps                      | 116        |
|    iterations               | 35         |
|    time_elapsed             | 613        |
|    total_timesteps          | 1978368    |
| train/                      |            |
|    approx_kl                | 34917.992  |
|    approx_ln(kl)            | 10.460757  |
|    clip_range               | 0.2        |
|    entropy_loss             | 3.71       |
|    explained_variance       | 0.998      |
|    learning_rate            | 0.001      |
|    ln(loss)                 | inf        |
|    ln(policy_gradient_loss) | nan        |
|    loss                     | inf        |
|    n_updates                | 9650       |
|    policy_gradient_loss     | nan        |
|    std                      | 0.0385     |
|    value_loss               | 1.31       |
--------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.2244337] |
| time/                       |              |
|    fps                      | 117          |
|    iterations               | 36           |
|    time_elapsed             | 626          |
|    total_timesteps          | 1980416      |
| train/                      |              |
|    approx_kl                | 6129.913     |
|    approx_ln(kl)            | 8.720936     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.69         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9660         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0388       |
|    value_loss               | 1.35         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-1.790638] |
| time/                       |             |
|    fps                      | 118         |
|    iterations               | 37          |
|    time_elapsed             | 640         |
|    total_timesteps          | 1982464     |
| train/                      |             |
|    approx_kl                | 17424.65    |
|    approx_ln(kl)            | 9.765641    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.7         |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 9670        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0385      |
|    value_loss               | 1.61        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.0104105] |
| time/                       |              |
|    fps                      | 118          |
|    iterations               | 38           |
|    time_elapsed             | 654          |
|    total_timesteps          | 1984512      |
| train/                      |              |
|    approx_kl                | 9204.484     |
|    approx_ln(kl)            | 9.127446     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.67         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9680         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0393       |
|    value_loss               | 1.35         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.583197] |
| time/                       |             |
|    fps                      | 119         |
|    iterations               | 39          |
|    time_elapsed             | 668         |
|    total_timesteps          | 1986560     |
| train/                      |             |
|    approx_kl                | 37066.145   |
|    approx_ln(kl)            | 10.520459   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.7         |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 9690        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0385      |
|    value_loss               | 0.977       |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.7282934] |
| time/                       |              |
|    fps                      | 120          |
|    iterations               | 40           |
|    time_elapsed             | 682          |
|    total_timesteps          | 1988608      |
| train/                      |              |
|    approx_kl                | 14155.998    |
|    approx_ln(kl)            | 9.557894     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.71         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9700         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0381       |
|    value_loss               | 2.32         |
----------------------------------------------
----------------------------------------------
| reward                      | [-0.5439924] |
| time/                       |              |
|    fps                      | 120          |
|    iterations               | 41           |
|    time_elapsed             | 695          |
|    total_timesteps          | 1990656      |
| train/                      |              |
|    approx_kl                | 12527.842    |
|    approx_ln(kl)            | 9.435709     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.71         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 9710         |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0382       |
|    value_loss               | 1.7          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.47165927] |
| time/                       |               |
|    fps                      | 120           |
|    iterations               | 42            |
|    time_elapsed             | 711           |
|    total_timesteps          | 1992704       |
| train/                      |               |
|    approx_kl                | 6528.4336     |
|    approx_ln(kl)            | 8.783922      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.69          |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 9720          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0387        |
|    value_loss               | 1.94          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.484179] |
| time/                       |             |
|    fps                      | 120         |
|    iterations               | 43          |
|    time_elapsed             | 730         |
|    total_timesteps          | 1994752     |
| train/                      |             |
|    approx_kl                | 18555.482   |
|    approx_ln(kl)            | 9.828521    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.69        |
|    explained_variance       | 0.997       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 9730        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0387      |
|    value_loss               | 4.05        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.903948] |
| time/                       |             |
|    fps                      | 120         |
|    iterations               | 44          |
|    time_elapsed             | 746         |
|    total_timesteps          | 1996800     |
| train/                      |             |
|    approx_kl                | 8434.635    |
|    approx_ln(kl)            | 9.040102    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.7         |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 9740        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0385      |
|    value_loss               | 2.83        |
---------------------------------------------
----------------------------------------------
| reward                      | [-0.7735772] |
| time/                       |              |
|    fps                      | 117          |
|    iterations               | 45           |
|    time_elapsed             | 783          |
|    total_timesteps          | 1998848      |
| train/                      |              |
|    approx_kl                | 5723.4717    |
|    approx_ln(kl)            | 8.65233      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.7          |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 9750         |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0383       |
|    value_loss               | 2.33         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.51882136] |
| time/                       |               |
|    fps                      | 117           |
|    iterations               | 46            |
|    time_elapsed             | 802           |
|    total_timesteps          | 2000896       |
| train/                      |               |
|    approx_kl                | 10945.734     |
|    approx_ln(kl)            | 9.300705      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.76          |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 9760          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0373        |
|    value_loss               | 2.81          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6687173] |
| time/                       |              |
|    fps                      | 106          |
|    iterations               | 47           |
|    time_elapsed             | 905          |
|    total_timesteps          | 2002944      |
| train/                      |              |
|    approx_kl                | 3199.3987    |
|    approx_ln(kl)            | 8.070718     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.77         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9770         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.037        |
|    value_loss               | 1.3          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.41609254] |
| time/                       |               |
|    fps                      | 97            |
|    iterations               | 48            |
|    time_elapsed             | 1009          |
|    total_timesteps          | 2004992       |
| train/                      |               |
|    approx_kl                | 9773.444      |
|    approx_ln(kl)            | 9.187425      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.79          |
|    explained_variance       | 1             |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 9780          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0367        |
|    value_loss               | 0.597         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.63451296] |
| time/                       |               |
|    fps                      | 98            |
|    iterations               | 49            |
|    time_elapsed             | 1023          |
|    total_timesteps          | 2007040       |
| train/                      |               |
|    approx_kl                | 40376.195     |
|    approx_ln(kl)            | 10.605996     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.81          |
|    explained_variance       | 1             |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 9790          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0364        |
|    value_loss               | 1.09          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
------------------------------------
| reward             | [-3.154839] |
| time/              |             |
|    fps             | 162         |
|    iterations      | 1           |
|    time_elapsed    | 12          |
|    total_timesteps | 2009088     |
------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.6154573] |
| time/                       |              |
|    fps                      | 155          |
|    iterations               | 2            |
|    time_elapsed             | 26           |
|    total_timesteps          | 2011136      |
| train/                      |              |
|    approx_kl                | 9503.8125    |
|    approx_ln(kl)            | 9.159449     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.78         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9810         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.037        |
|    value_loss               | 0.39         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.3431647] |
| time/                       |              |
|    fps                      | 152          |
|    iterations               | 3            |
|    time_elapsed             | 40           |
|    total_timesteps          | 2013184      |
| train/                      |              |
|    approx_kl                | 16706.137    |
|    approx_ln(kl)            | 9.723532     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.77         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9820         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0372       |
|    value_loss               | 2.04         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.69421506] |
| time/                       |               |
|    fps                      | 151           |
|    iterations               | 4             |
|    time_elapsed             | 54            |
|    total_timesteps          | 2015232       |
| train/                      |               |
|    approx_kl                | 8437.156      |
|    approx_ln(kl)            | 9.0404005     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.77          |
|    explained_variance       | 0.985         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 9830          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.037         |
|    value_loss               | 7.09          |
-----------------------------------------------
-----------------------------------------------
| reward                      | [-0.61624175] |
| time/                       |               |
|    fps                      | 150           |
|    iterations               | 5             |
|    time_elapsed             | 67            |
|    total_timesteps          | 2017280       |
| train/                      |               |
|    approx_kl                | 24961.406     |
|    approx_ln(kl)            | 10.125086     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.77          |
|    explained_variance       | 0.996         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 9840          |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0371        |
|    value_loss               | 3.08          |
-----------------------------------------------
-----------------------------------------------
| reward                      | [-0.58046436] |
| time/                       |               |
|    fps                      | 149           |
|    iterations               | 6             |
|    time_elapsed             | 81            |
|    total_timesteps          | 2019328       |
| train/                      |               |
|    approx_kl                | 15299.023     |
|    approx_ln(kl)            | 9.635545      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.71          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 9850          |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0385        |
|    value_loss               | 1.45          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-1.140606] |
| time/                       |             |
|    fps                      | 149         |
|    iterations               | 7           |
|    time_elapsed             | 95          |
|    total_timesteps          | 2021376     |
| train/                      |             |
|    approx_kl                | 3618.954    |
|    approx_ln(kl)            | 8.19394     |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.7         |
|    explained_variance       | 0.987       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 9860        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0384      |
|    value_loss               | 7.54        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.6411837] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 8            |
|    time_elapsed             | 109          |
|    total_timesteps          | 2023424      |
| train/                      |              |
|    approx_kl                | 8380.391     |
|    approx_ln(kl)            | 9.033649     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.7          |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9870         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0384       |
|    value_loss               | 4.24         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.4992387] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 9            |
|    time_elapsed             | 123          |
|    total_timesteps          | 2025472      |
| train/                      |              |
|    approx_kl                | 18065.914    |
|    approx_ln(kl)            | 9.801783     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.73         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9880         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0379       |
|    value_loss               | 3.87         |
----------------------------------------------
----------------------------------------------
| reward                      | [-2.9118245] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 10           |
|    time_elapsed             | 137          |
|    total_timesteps          | 2027520      |
| train/                      |              |
|    approx_kl                | 3960.54      |
|    approx_ln(kl)            | 8.284136     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.71         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 9890         |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0382       |
|    value_loss               | 4.32         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.7064595] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 11           |
|    time_elapsed             | 151          |
|    total_timesteps          | 2029568      |
| train/                      |              |
|    approx_kl                | 21825.146    |
|    approx_ln(kl)            | 9.990818     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.73         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9900         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0379       |
|    value_loss               | 3.12         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.1607556] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 12           |
|    time_elapsed             | 165          |
|    total_timesteps          | 2031616      |
| train/                      |              |
|    approx_kl                | 14407.502    |
|    approx_ln(kl)            | 9.575504     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.73         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 9910         |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0378       |
|    value_loss               | 2.43         |
----------------------------------------------
---------------------------------------------
| reward                      | [-4.475567] |
| time/                       |             |
|    fps                      | 148         |
|    iterations               | 13          |
|    time_elapsed             | 179         |
|    total_timesteps          | 2033664     |
| train/                      |             |
|    approx_kl                | 6951.7725   |
|    approx_ln(kl)            | 8.846752    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.73        |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | inf         |
|    loss                     | inf         |
|    n_updates                | 9920        |
|    policy_gradient_loss     | inf         |
|    std                      | 0.0379      |
|    value_loss               | 2.09        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.568585] |
| time/                       |             |
|    fps                      | 148         |
|    iterations               | 14          |
|    time_elapsed             | 193         |
|    total_timesteps          | 2035712     |
| train/                      |             |
|    approx_kl                | 7596.2783   |
|    approx_ln(kl)            | 8.935413    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.73        |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 9930        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.038       |
|    value_loss               | 2.74        |
---------------------------------------------
----------------------------------------------
| reward                      | [-1.1088253] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 15           |
|    time_elapsed             | 206          |
|    total_timesteps          | 2037760      |
| train/                      |              |
|    approx_kl                | 3691.208     |
|    approx_ln(kl)            | 8.213709     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.77         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 9940         |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0371       |
|    value_loss               | 2.86         |
----------------------------------------------
-----------------------------------------------
| reward                      | [-0.41834164] |
| time/                       |               |
|    fps                      | 148           |
|    iterations               | 16            |
|    time_elapsed             | 220           |
|    total_timesteps          | 2039808       |
| train/                      |               |
|    approx_kl                | 9322.307      |
|    approx_ln(kl)            | 9.140165      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.77          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 9950          |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0373        |
|    value_loss               | 1.53          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.53479594] |
| time/                       |               |
|    fps                      | 148           |
|    iterations               | 17            |
|    time_elapsed             | 234           |
|    total_timesteps          | 2041856       |
| train/                      |               |
|    approx_kl                | 9759.168      |
|    approx_ln(kl)            | 9.185963      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.78          |
|    explained_variance       | 0.979         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 9960          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0369        |
|    value_loss               | 3.24          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-1.567683] |
| time/                       |             |
|    fps                      | 148         |
|    iterations               | 18          |
|    time_elapsed             | 248         |
|    total_timesteps          | 2043904     |
| train/                      |             |
|    approx_kl                | 9199.119    |
|    approx_ln(kl)            | 9.1268635   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.78        |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 9970        |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0369      |
|    value_loss               | 2.01        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.46343702] |
| time/                       |               |
|    fps                      | 148           |
|    iterations               | 19            |
|    time_elapsed             | 262           |
|    total_timesteps          | 2045952       |
| train/                      |               |
|    approx_kl                | 20297.504     |
|    approx_ln(kl)            | 9.918253      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.77          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 9980          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0372        |
|    value_loss               | 1.4           |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.26567578] |
| time/                       |               |
|    fps                      | 148           |
|    iterations               | 20            |
|    time_elapsed             | 276           |
|    total_timesteps          | 2048000       |
| train/                      |               |
|    approx_kl                | 7734.763      |
|    approx_ln(kl)            | 8.95348       |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.78          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 9990          |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0369        |
|    value_loss               | 2.08          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5616705] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 21           |
|    time_elapsed             | 290          |
|    total_timesteps          | 2050048      |
| train/                      |              |
|    approx_kl                | 5296.423     |
|    approx_ln(kl)            | 8.574787     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.79         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10000        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0369       |
|    value_loss               | 1.3          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.40443555] |
| time/                       |               |
|    fps                      | 148           |
|    iterations               | 22            |
|    time_elapsed             | 304           |
|    total_timesteps          | 2052096       |
| train/                      |               |
|    approx_kl                | 44442.5       |
|    approx_ln(kl)            | 10.701952     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.74          |
|    explained_variance       | 1             |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 10010         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.038         |
|    value_loss               | 0.732         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.895688] |
| time/                       |             |
|    fps                      | 148         |
|    iterations               | 23          |
|    time_elapsed             | 318         |
|    total_timesteps          | 2054144     |
| train/                      |             |
|    approx_kl                | 7847.759    |
|    approx_ln(kl)            | 8.967983    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.75        |
|    explained_variance       | 0.901       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 10020       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0377      |
|    value_loss               | 0.651       |
---------------------------------------------
-----------------------------------------------
| reward                      | [-0.44590676] |
| time/                       |               |
|    fps                      | 148           |
|    iterations               | 24            |
|    time_elapsed             | 331           |
|    total_timesteps          | 2056192       |
| train/                      |               |
|    approx_kl                | 11183.255     |
|    approx_ln(kl)            | 9.322173      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.75          |
|    explained_variance       | 1             |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 10030         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0375        |
|    value_loss               | 1.27          |
-----------------------------------------------
-----------------------------------------------
| reward                      | [-0.43858406] |
| time/                       |               |
|    fps                      | 148           |
|    iterations               | 25            |
|    time_elapsed             | 345           |
|    total_timesteps          | 2058240       |
| train/                      |               |
|    approx_kl                | 12637.016     |
|    approx_ln(kl)            | 9.444386      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.74          |
|    explained_variance       | 1             |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 10040         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0377        |
|    value_loss               | 0.82          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.3675617] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 26           |
|    time_elapsed             | 359          |
|    total_timesteps          | 2060288      |
| train/                      |              |
|    approx_kl                | 1889.6575    |
|    approx_ln(kl)            | 7.544151     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.76         |
|    explained_variance       | 0.938        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10050        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0373       |
|    value_loss               | 0.132        |
----------------------------------------------
-----------------------------------------------
| reward                      | [-0.37073317] |
| time/                       |               |
|    fps                      | 146           |
|    iterations               | 27            |
|    time_elapsed             | 377           |
|    total_timesteps          | 2062336       |
| train/                      |               |
|    approx_kl                | 3001.29       |
|    approx_ln(kl)            | 8.006798      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.78          |
|    explained_variance       | 1             |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 10060         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0369        |
|    value_loss               | 0.738         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4489437] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 28           |
|    time_elapsed             | 392          |
|    total_timesteps          | 2064384      |
| train/                      |              |
|    approx_kl                | 2585.4265    |
|    approx_ln(kl)            | 7.857646     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.8          |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10070        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0365       |
|    value_loss               | 0.853        |
----------------------------------------------
----------------------------------------------
| reward                      | [-1.5107856] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 29           |
|    time_elapsed             | 405          |
|    total_timesteps          | 2066432      |
| train/                      |              |
|    approx_kl                | 8715.84      |
|    approx_ln(kl)            | 9.072897     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.82         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 10080        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0361       |
|    value_loss               | 0.836        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-1.976035] |
| time/                       |             |
|    fps                      | 146         |
|    iterations               | 30          |
|    time_elapsed             | 419         |
|    total_timesteps          | 2068480     |
| train/                      |             |
|    approx_kl                | 4871.3516   |
|    approx_ln(kl)            | 8.491127    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.82        |
|    explained_variance       | 1           |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 10090       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0362      |
|    value_loss               | 0.751       |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4859994] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 31           |
|    time_elapsed             | 433          |
|    total_timesteps          | 2070528      |
| train/                      |              |
|    approx_kl                | 6444.564     |
|    approx_ln(kl)            | 8.770992     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.81         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10100        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0364       |
|    value_loss               | 0.598        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5554005] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 32           |
|    time_elapsed             | 447          |
|    total_timesteps          | 2072576      |
| train/                      |              |
|    approx_kl                | 4147.413     |
|    approx_ln(kl)            | 8.33024      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.82         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10110        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.036        |
|    value_loss               | 2.9          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.27043688] |
| time/                       |               |
|    fps                      | 146           |
|    iterations               | 33            |
|    time_elapsed             | 461           |
|    total_timesteps          | 2074624       |
| train/                      |               |
|    approx_kl                | 1182.83       |
|    approx_ln(kl)            | 7.075665      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.81          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 10120         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0364        |
|    value_loss               | 1.49          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.2683806] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 34           |
|    time_elapsed             | 475          |
|    total_timesteps          | 2076672      |
| train/                      |              |
|    approx_kl                | 2588.76      |
|    approx_ln(kl)            | 7.8589344    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.82         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10130        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0361       |
|    value_loss               | 0.521        |
----------------------------------------------
-----------------------------------------------
| reward                      | [-0.49635753] |
| time/                       |               |
|    fps                      | 146           |
|    iterations               | 35            |
|    time_elapsed             | 489           |
|    total_timesteps          | 2078720       |
| train/                      |               |
|    approx_kl                | 4394.4585     |
|    approx_ln(kl)            | 8.3881        |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.8           |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 10140         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0366        |
|    value_loss               | 3.98          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.36915034] |
| time/                       |               |
|    fps                      | 146           |
|    iterations               | 36            |
|    time_elapsed             | 502           |
|    total_timesteps          | 2080768       |
| train/                      |               |
|    approx_kl                | 2158.4287     |
|    approx_ln(kl)            | 7.677136      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.79          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 10150         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0367        |
|    value_loss               | 1.07          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.7898471] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 37           |
|    time_elapsed             | 516          |
|    total_timesteps          | 2082816      |
| train/                      |              |
|    approx_kl                | 891.3105     |
|    approx_ln(kl)            | 6.7926927    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.8          |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10160        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0365       |
|    value_loss               | 0.58         |
----------------------------------------------
--------------------------------------------
| reward                      | [-5.23747] |
| time/                       |            |
|    fps                      | 146        |
|    iterations               | 38         |
|    time_elapsed             | 530        |
|    total_timesteps          | 2084864    |
| train/                      |            |
|    approx_kl                | 12304.295  |
|    approx_ln(kl)            | 9.417704   |
|    clip_range               | 0.2        |
|    entropy_loss             | 3.82       |
|    explained_variance       | 0.994      |
|    learning_rate            | 0.001      |
|    ln(loss)                 | inf        |
|    ln(policy_gradient_loss) | inf        |
|    loss                     | inf        |
|    n_updates                | 10170      |
|    policy_gradient_loss     | inf        |
|    std                      | 0.036      |
|    value_loss               | 3.85       |
--------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.8361213] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 39           |
|    time_elapsed             | 544          |
|    total_timesteps          | 2086912      |
| train/                      |              |
|    approx_kl                | 7233.367     |
|    approx_ln(kl)            | 8.88646      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.82         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10180        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0361       |
|    value_loss               | 2.62         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4089283] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 40           |
|    time_elapsed             | 558          |
|    total_timesteps          | 2088960      |
| train/                      |              |
|    approx_kl                | 5972.4043    |
|    approx_ln(kl)            | 8.694905     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.81         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10190        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0363       |
|    value_loss               | 1.16         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.7847267] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 41           |
|    time_elapsed             | 572          |
|    total_timesteps          | 2091008      |
| train/                      |              |
|    approx_kl                | 2854.418     |
|    approx_ln(kl)            | 7.956623     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.83         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10200        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.036        |
|    value_loss               | 0.678        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
--------------------------------------------
| reward                      | [-2.40737] |
| time/                       |            |
|    fps                      | 127        |
|    iterations               | 42         |
|    time_elapsed             | 676        |
|    total_timesteps          | 2093056    |
| train/                      |            |
|    approx_kl                | 4247.3457  |
|    approx_ln(kl)            | 8.35405    |
|    clip_range               | 0.2        |
|    entropy_loss             | 3.84       |
|    explained_variance       | 0.999      |
|    learning_rate            | 0.001      |
|    ln(loss)                 | inf        |
|    ln(policy_gradient_loss) | nan        |
|    loss                     | inf        |
|    n_updates                | 10210      |
|    policy_gradient_loss     | nan        |
|    std                      | 0.0358     |
|    value_loss               | 1.4        |
--------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5579093] |
| time/                       |              |
|    fps                      | 127          |
|    iterations               | 43           |
|    time_elapsed             | 690          |
|    total_timesteps          | 2095104      |
| train/                      |              |
|    approx_kl                | 4216.128     |
|    approx_ln(kl)            | 8.346672     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.83         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10220        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0359       |
|    value_loss               | 0.925        |
----------------------------------------------
-----------------------------------------------
| reward                      | [-0.47895554] |
| time/                       |               |
|    fps                      | 127           |
|    iterations               | 44            |
|    time_elapsed             | 705           |
|    total_timesteps          | 2097152       |
| train/                      |               |
|    approx_kl                | 6364.81       |
|    approx_ln(kl)            | 8.758539      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.84          |
|    explained_variance       | 1             |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 10230         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0358        |
|    value_loss               | 0.265         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.34693775] |
| time/                       |               |
|    fps                      | 128           |
|    iterations               | 45            |
|    time_elapsed             | 719           |
|    total_timesteps          | 2099200       |
| train/                      |               |
|    approx_kl                | 5418.908      |
|    approx_ln(kl)            | 8.59765       |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.85          |
|    explained_variance       | 1             |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 10240         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0356        |
|    value_loss               | 0.131         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.3626309] |
| time/                       |              |
|    fps                      | 128          |
|    iterations               | 46           |
|    time_elapsed             | 733          |
|    total_timesteps          | 2101248      |
| train/                      |              |
|    approx_kl                | 5594.16      |
|    approx_ln(kl)            | 8.629478     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.84         |
|    explained_variance       | 0.987        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10250        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0356       |
|    value_loss               | 0.0933       |
----------------------------------------------
----------------------------------------------
| reward                      | [-0.4167315] |
| time/                       |              |
|    fps                      | 128          |
|    iterations               | 47           |
|    time_elapsed             | 747          |
|    total_timesteps          | 2103296      |
| train/                      |              |
|    approx_kl                | 3488.6426    |
|    approx_ln(kl)            | 8.157268     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.78         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 10260        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.037        |
|    value_loss               | 3.59         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.56468487] |
| time/                       |               |
|    fps                      | 127           |
|    iterations               | 48            |
|    time_elapsed             | 770           |
|    total_timesteps          | 2105344       |
| train/                      |               |
|    approx_kl                | 1599.6348     |
|    approx_ln(kl)            | 7.3775306     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.73          |
|    explained_variance       | 1             |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 10270         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0378        |
|    value_loss               | 0.572         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.3641052] |
| time/                       |              |
|    fps                      | 120          |
|    iterations               | 49           |
|    time_elapsed             | 835          |
|    total_timesteps          | 2107392      |
| train/                      |              |
|    approx_kl                | 1645.3606    |
|    approx_ln(kl)            | 7.405715     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.72         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10280        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0378       |
|    value_loss               | 0.355        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-------------------------------------
| reward             | [-1.1082824] |
| time/              |              |
|    fps             | 159          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 2109440      |
-------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.18873549] |
| time/                       |               |
|    fps                      | 32            |
|    iterations               | 2             |
|    time_elapsed             | 127           |
|    total_timesteps          | 2111488       |
| train/                      |               |
|    approx_kl                | 3883.3745     |
|    approx_ln(kl)            | 8.26446       |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.69          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 10300         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0386        |
|    value_loss               | 0.456         |
-----------------------------------------------
----------------------------------------------
| reward                      | [-0.2997015] |
| time/                       |              |
|    fps                      | 25           |
|    iterations               | 3            |
|    time_elapsed             | 243          |
|    total_timesteps          | 2113536      |
| train/                      |              |
|    approx_kl                | 10456.228    |
|    approx_ln(kl)            | 9.254953     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.66         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 10310        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.039        |
|    value_loss               | 0.227        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.4311914] |
| time/                       |              |
|    fps                      | 22           |
|    iterations               | 4            |
|    time_elapsed             | 368          |
|    total_timesteps          | 2115584      |
| train/                      |              |
|    approx_kl                | 3854.6108    |
|    approx_ln(kl)            | 8.257026     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.65         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10320        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0391       |
|    value_loss               | 0.416        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.28178966] |
| time/                       |               |
|    fps                      | 20            |
|    iterations               | 5             |
|    time_elapsed             | 494           |
|    total_timesteps          | 2117632       |
| train/                      |               |
|    approx_kl                | 7316.3413     |
|    approx_ln(kl)            | 8.897865      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.66          |
|    explained_variance       | 1             |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 10330         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.039         |
|    value_loss               | 0.324         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.50439095] |
| time/                       |               |
|    fps                      | 20            |
|    iterations               | 6             |
|    time_elapsed             | 608           |
|    total_timesteps          | 2119680       |
| train/                      |               |
|    approx_kl                | 5192.3774     |
|    approx_ln(kl)            | 8.554947      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.68          |
|    explained_variance       | 1             |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 10340         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0386        |
|    value_loss               | 0.392         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.2393255] |
| time/                       |              |
|    fps                      | 20           |
|    iterations               | 7            |
|    time_elapsed             | 710          |
|    total_timesteps          | 2121728      |
| train/                      |              |
|    approx_kl                | 6264.6978    |
|    approx_ln(kl)            | 8.742685     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.64         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10350        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0394       |
|    value_loss               | 0.0562       |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5040596] |
| time/                       |              |
|    fps                      | 20           |
|    iterations               | 8            |
|    time_elapsed             | 806          |
|    total_timesteps          | 2123776      |
| train/                      |              |
|    approx_kl                | 6087.8677    |
|    approx_ln(kl)            | 8.714053     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.67         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10360        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0387       |
|    value_loss               | 0.699        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.26180992] |
| time/                       |               |
|    fps                      | 22            |
|    iterations               | 9             |
|    time_elapsed             | 820           |
|    total_timesteps          | 2125824       |
| train/                      |               |
|    approx_kl                | 7640.5513     |
|    approx_ln(kl)            | 8.941225      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.68          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 10370         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0385        |
|    value_loss               | 0.541         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.37729898] |
| time/                       |               |
|    fps                      | 24            |
|    iterations               | 10            |
|    time_elapsed             | 833           |
|    total_timesteps          | 2127872       |
| train/                      |               |
|    approx_kl                | 5146.9575     |
|    approx_ln(kl)            | 8.546161      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.69          |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 10380         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0383        |
|    value_loss               | 1.29          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.22811006] |
| time/                       |               |
|    fps                      | 26            |
|    iterations               | 11            |
|    time_elapsed             | 847           |
|    total_timesteps          | 2129920       |
| train/                      |               |
|    approx_kl                | 12128.178     |
|    approx_ln(kl)            | 9.403287      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.72          |
|    explained_variance       | 0.997         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 10390         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0377        |
|    value_loss               | 1.35          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-0.245335] |
| time/                       |             |
|    fps                      | 28          |
|    iterations               | 12          |
|    time_elapsed             | 861         |
|    total_timesteps          | 2131968     |
| train/                      |             |
|    approx_kl                | 7142.3154   |
|    approx_ln(kl)            | 8.873793    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.74        |
|    explained_variance       | 0.995       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 10400       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0374      |
|    value_loss               | 0.895       |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6063354] |
| time/                       |              |
|    fps                      | 30           |
|    iterations               | 13           |
|    time_elapsed             | 875          |
|    total_timesteps          | 2134016      |
| train/                      |              |
|    approx_kl                | 10362.951    |
|    approx_ln(kl)            | 9.245993     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.74         |
|    explained_variance       | 0.983        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10410        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0373       |
|    value_loss               | 0.54         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.32790452] |
| time/                       |               |
|    fps                      | 32            |
|    iterations               | 14            |
|    time_elapsed             | 889           |
|    total_timesteps          | 2136064       |
| train/                      |               |
|    approx_kl                | 21083.254     |
|    approx_ln(kl)            | 9.956234      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.75          |
|    explained_variance       | 0.997         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 10420         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0372        |
|    value_loss               | 0.482         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.44855455] |
| time/                       |               |
|    fps                      | 34            |
|    iterations               | 15            |
|    time_elapsed             | 902           |
|    total_timesteps          | 2138112       |
| train/                      |               |
|    approx_kl                | 7199.493      |
|    approx_ln(kl)            | 8.881766      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.75          |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 10430         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0371        |
|    value_loss               | 0.543         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.9920013] |
| time/                       |              |
|    fps                      | 35           |
|    iterations               | 16           |
|    time_elapsed             | 916          |
|    total_timesteps          | 2140160      |
| train/                      |              |
|    approx_kl                | 18981.951    |
|    approx_ln(kl)            | 9.851244     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.76         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10440        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0369       |
|    value_loss               | 0.181        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4294094] |
| time/                       |              |
|    fps                      | 37           |
|    iterations               | 17           |
|    time_elapsed             | 930          |
|    total_timesteps          | 2142208      |
| train/                      |              |
|    approx_kl                | 12074.194    |
|    approx_ln(kl)            | 9.398826     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.77         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10450        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0365       |
|    value_loss               | 0.327        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.38128144] |
| time/                       |               |
|    fps                      | 39            |
|    iterations               | 18            |
|    time_elapsed             | 944           |
|    total_timesteps          | 2144256       |
| train/                      |               |
|    approx_kl                | 1019.0532     |
|    approx_ln(kl)            | 6.926629      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.78          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 10460         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0366        |
|    value_loss               | 0.584         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.093891] |
| time/                       |             |
|    fps                      | 40          |
|    iterations               | 19          |
|    time_elapsed             | 957         |
|    total_timesteps          | 2146304     |
| train/                      |             |
|    approx_kl                | 2074.9648   |
|    approx_ln(kl)            | 7.6376996   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.76        |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 10470       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.037       |
|    value_loss               | 0.603       |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.6014988] |
| time/                       |              |
|    fps                      | 38           |
|    iterations               | 20           |
|    time_elapsed             | 1064         |
|    total_timesteps          | 2148352      |
| train/                      |              |
|    approx_kl                | 2066.101     |
|    approx_ln(kl)            | 7.6334186    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.74         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10480        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0373       |
|    value_loss               | 2.31         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.59332526] |
| time/                       |               |
|    fps                      | 39            |
|    iterations               | 21            |
|    time_elapsed             | 1098          |
|    total_timesteps          | 2150400       |
| train/                      |               |
|    approx_kl                | 6507.873      |
|    approx_ln(kl)            | 8.780768      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.74          |
|    explained_variance       | 1             |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 10490         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0373        |
|    value_loss               | 0.485         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.57478833] |
| time/                       |               |
|    fps                      | 40            |
|    iterations               | 22            |
|    time_elapsed             | 1113          |
|    total_timesteps          | 2152448       |
| train/                      |               |
|    approx_kl                | 2989.6313     |
|    approx_ln(kl)            | 8.002906      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.73          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 10500         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0377        |
|    value_loss               | 0.814         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.21348639] |
| time/                       |               |
|    fps                      | 41            |
|    iterations               | 23            |
|    time_elapsed             | 1139          |
|    total_timesteps          | 2154496       |
| train/                      |               |
|    approx_kl                | 4447.63       |
|    approx_ln(kl)            | 8.400126      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.75          |
|    explained_variance       | 1             |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 10510         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0371        |
|    value_loss               | 0.494         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.137184] |
| time/                       |             |
|    fps                      | 42          |
|    iterations               | 24          |
|    time_elapsed             | 1153        |
|    total_timesteps          | 2156544     |
| train/                      |             |
|    approx_kl                | 2636.897    |
|    approx_ln(kl)            | 7.877358    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.73        |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 10520       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0375      |
|    value_loss               | 0.0451      |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.31397173] |
| time/                       |               |
|    fps                      | 43            |
|    iterations               | 25            |
|    time_elapsed             | 1167          |
|    total_timesteps          | 2158592       |
| train/                      |               |
|    approx_kl                | 2608.5996     |
|    approx_ln(kl)            | 7.866569      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.71          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 10530         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0379        |
|    value_loss               | 0.459         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.9632709] |
| time/                       |              |
|    fps                      | 45           |
|    iterations               | 26           |
|    time_elapsed             | 1181         |
|    total_timesteps          | 2160640      |
| train/                      |              |
|    approx_kl                | 5088.99      |
|    approx_ln(kl)            | 8.534835     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.72         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10540        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0377       |
|    value_loss               | 0.142        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.9111383] |
| time/                       |              |
|    fps                      | 46           |
|    iterations               | 27           |
|    time_elapsed             | 1194         |
|    total_timesteps          | 2162688      |
| train/                      |              |
|    approx_kl                | 1279.0614    |
|    approx_ln(kl)            | 7.153882     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.69         |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10550        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0383       |
|    value_loss               | 6.46         |
----------------------------------------------
----------------------------------------------
| reward                      | [-0.7772349] |
| time/                       |              |
|    fps                      | 47           |
|    iterations               | 28           |
|    time_elapsed             | 1208         |
|    total_timesteps          | 2164736      |
| train/                      |              |
|    approx_kl                | 2021.1736    |
|    approx_ln(kl)            | 7.6114335    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.68         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 10560        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0385       |
|    value_loss               | 4.26         |
----------------------------------------------
---------------------------------------------
| reward                      | [-1.216748] |
| time/                       |             |
|    fps                      | 48          |
|    iterations               | 29          |
|    time_elapsed             | 1222        |
|    total_timesteps          | 2166784     |
| train/                      |             |
|    approx_kl                | 4511.551    |
|    approx_ln(kl)            | 8.414396    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.68        |
|    explained_variance       | 0.996       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | inf         |
|    loss                     | inf         |
|    n_updates                | 10570       |
|    policy_gradient_loss     | inf         |
|    std                      | 0.0385      |
|    value_loss               | 8.78        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-5.0247025] |
| time/                       |              |
|    fps                      | 49           |
|    iterations               | 30           |
|    time_elapsed             | 1236         |
|    total_timesteps          | 2168832      |
| train/                      |              |
|    approx_kl                | 5155.5938    |
|    approx_ln(kl)            | 8.547837     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.67         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10580        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0386       |
|    value_loss               | 2.85         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.26399603] |
| time/                       |               |
|    fps                      | 50            |
|    iterations               | 31            |
|    time_elapsed             | 1249          |
|    total_timesteps          | 2170880       |
| train/                      |               |
|    approx_kl                | 3136.2478     |
|    approx_ln(kl)            | 8.050782      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.68          |
|    explained_variance       | 0.997         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 10590         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0386        |
|    value_loss               | 5.07          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0827212] |
| time/                       |              |
|    fps                      | 51           |
|    iterations               | 32           |
|    time_elapsed             | 1263         |
|    total_timesteps          | 2172928      |
| train/                      |              |
|    approx_kl                | 3209.9263    |
|    approx_ln(kl)            | 8.074003     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.68         |
|    explained_variance       | 0.991        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10600        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0384       |
|    value_loss               | 6.38         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-1.014621] |
| time/                       |             |
|    fps                      | 52          |
|    iterations               | 33          |
|    time_elapsed             | 1277        |
|    total_timesteps          | 2174976     |
| train/                      |             |
|    approx_kl                | 3346.0327   |
|    approx_ln(kl)            | 8.115531    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.69        |
|    explained_variance       | 0.994       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 10610       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0382      |
|    value_loss               | 5.67        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.832013] |
| time/                       |             |
|    fps                      | 53          |
|    iterations               | 34          |
|    time_elapsed             | 1291        |
|    total_timesteps          | 2177024     |
| train/                      |             |
|    approx_kl                | 2870.6948   |
|    approx_ln(kl)            | 7.9623094   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.69        |
|    explained_variance       | 0.99        |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 10620       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0382      |
|    value_loss               | 7.2         |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.3992443] |
| time/                       |              |
|    fps                      | 54           |
|    iterations               | 35           |
|    time_elapsed             | 1304         |
|    total_timesteps          | 2179072      |
| train/                      |              |
|    approx_kl                | 5575.782     |
|    approx_ln(kl)            | 8.626188     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.71         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10630        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0379       |
|    value_loss               | 3.29         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.5726762] |
| time/                       |              |
|    fps                      | 55           |
|    iterations               | 36           |
|    time_elapsed             | 1318         |
|    total_timesteps          | 2181120      |
| train/                      |              |
|    approx_kl                | 4357.075     |
|    approx_ln(kl)            | 8.379557     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.73         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10640        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0375       |
|    value_loss               | 4.85         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.2786672] |
| time/                       |              |
|    fps                      | 56           |
|    iterations               | 37           |
|    time_elapsed             | 1332         |
|    total_timesteps          | 2183168      |
| train/                      |              |
|    approx_kl                | 3755.6487    |
|    approx_ln(kl)            | 8.231016     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.74         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10650        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0373       |
|    value_loss               | 2.6          |
----------------------------------------------
----------------------------------------------
| reward                      | [-0.3283659] |
| time/                       |              |
|    fps                      | 57           |
|    iterations               | 38           |
|    time_elapsed             | 1346         |
|    total_timesteps          | 2185216      |
| train/                      |              |
|    approx_kl                | 2221.9282    |
|    approx_ln(kl)            | 7.7061305    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.75         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 10660        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0371       |
|    value_loss               | 4.15         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
--------------------------------------------
| reward                      | [-4.96793] |
| time/                       |            |
|    fps                      | 58         |
|    iterations               | 39         |
|    time_elapsed             | 1359       |
|    total_timesteps          | 2187264    |
| train/                      |            |
|    approx_kl                | 11401.067  |
|    approx_ln(kl)            | 9.341462   |
|    clip_range               | 0.2        |
|    entropy_loss             | 3.76       |
|    explained_variance       | 0.999      |
|    learning_rate            | 0.001      |
|    ln(loss)                 | inf        |
|    ln(policy_gradient_loss) | nan        |
|    loss                     | inf        |
|    n_updates                | 10670      |
|    policy_gradient_loss     | nan        |
|    std                      | 0.037      |
|    value_loss               | 1.74       |
--------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.843828] |
| time/                       |             |
|    fps                      | 59          |
|    iterations               | 40          |
|    time_elapsed             | 1373        |
|    total_timesteps          | 2189312     |
| train/                      |             |
|    approx_kl                | 4651.4053   |
|    approx_ln(kl)            | 8.444924    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.74        |
|    explained_variance       | 0.997       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 10680       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0373      |
|    value_loss               | 4.58        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-0.925829] |
| time/                       |             |
|    fps                      | 60          |
|    iterations               | 41          |
|    time_elapsed             | 1387        |
|    total_timesteps          | 2191360     |
| train/                      |             |
|    approx_kl                | 2264.0952   |
|    approx_ln(kl)            | 7.724931    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.73        |
|    explained_variance       | 1           |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 10690       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0376      |
|    value_loss               | 2.73        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.51465297] |
| time/                       |               |
|    fps                      | 61            |
|    iterations               | 42            |
|    time_elapsed             | 1401          |
|    total_timesteps          | 2193408       |
| train/                      |               |
|    approx_kl                | 4888.797      |
|    approx_ln(kl)            | 8.494701      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.7           |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 10700         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0382        |
|    value_loss               | 1.39          |
-----------------------------------------------
----------------------------------------------
| reward                      | [-1.5840058] |
| time/                       |              |
|    fps                      | 62           |
|    iterations               | 43           |
|    time_elapsed             | 1415         |
|    total_timesteps          | 2195456      |
| train/                      |              |
|    approx_kl                | 4344.585     |
|    approx_ln(kl)            | 8.376685     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.7          |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 10710        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0381       |
|    value_loss               | 1.99         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.9512784] |
| time/                       |              |
|    fps                      | 63           |
|    iterations               | 44           |
|    time_elapsed             | 1429         |
|    total_timesteps          | 2197504      |
| train/                      |              |
|    approx_kl                | 2145.8645    |
|    approx_ln(kl)            | 7.671298     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.71         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10720        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0378       |
|    value_loss               | 3.47         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.8493772] |
| time/                       |              |
|    fps                      | 63           |
|    iterations               | 45           |
|    time_elapsed             | 1444         |
|    total_timesteps          | 2199552      |
| train/                      |              |
|    approx_kl                | 3920.1926    |
|    approx_ln(kl)            | 8.273896     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.71         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10730        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.038        |
|    value_loss               | 3.58         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.4738715] |
| time/                       |              |
|    fps                      | 64           |
|    iterations               | 46           |
|    time_elapsed             | 1457         |
|    total_timesteps          | 2201600      |
| train/                      |              |
|    approx_kl                | 9322.56      |
|    approx_ln(kl)            | 9.140193     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.72         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10740        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0376       |
|    value_loss               | 1.01         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.84072465] |
| time/                       |               |
|    fps                      | 65            |
|    iterations               | 47            |
|    time_elapsed             | 1471          |
|    total_timesteps          | 2203648       |
| train/                      |               |
|    approx_kl                | 1623.467      |
|    approx_ln(kl)            | 7.392319      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.68          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 10750         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0385        |
|    value_loss               | 3.19          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.436262] |
| time/                       |             |
|    fps                      | 66          |
|    iterations               | 48          |
|    time_elapsed             | 1485        |
|    total_timesteps          | 2205696     |
| train/                      |             |
|    approx_kl                | 4656.289    |
|    approx_ln(kl)            | 8.445974    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.68        |
|    explained_variance       | 1           |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 10760       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0385      |
|    value_loss               | 1.85        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.3973892] |
| time/                       |              |
|    fps                      | 66           |
|    iterations               | 49           |
|    time_elapsed             | 1499         |
|    total_timesteps          | 2207744      |
| train/                      |              |
|    approx_kl                | 7496.164     |
|    approx_ln(kl)            | 8.922147     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.68         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10770        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0385       |
|    value_loss               | 1.05         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-------------------------------------
| reward             | [-0.7968583] |
| time/              |              |
|    fps             | 136          |
|    iterations      | 1            |
|    time_elapsed    | 15           |
|    total_timesteps | 2209792      |
-------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.1971161] |
| time/                       |              |
|    fps                      | 142          |
|    iterations               | 2            |
|    time_elapsed             | 28           |
|    total_timesteps          | 2211840      |
| train/                      |              |
|    approx_kl                | 45007.67     |
|    approx_ln(kl)            | 10.714588    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.68         |
|    explained_variance       | 0.989        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10790        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0383       |
|    value_loss               | 0.781        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.36853644] |
| time/                       |               |
|    fps                      | 144           |
|    iterations               | 3             |
|    time_elapsed             | 42            |
|    total_timesteps          | 2213888       |
| train/                      |               |
|    approx_kl                | 1836.4902     |
|    approx_ln(kl)            | 7.5156116     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.69          |
|    explained_variance       | 0.996         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 10800         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0383        |
|    value_loss               | 5.68          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.1971297] |
| time/                       |              |
|    fps                      | 143          |
|    iterations               | 4            |
|    time_elapsed             | 56           |
|    total_timesteps          | 2215936      |
| train/                      |              |
|    approx_kl                | 2066.9517    |
|    approx_ln(kl)            | 7.63383      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.68         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10810        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0384       |
|    value_loss               | 4.14         |
----------------------------------------------
----------------------------------------------
| reward                      | [-1.4930593] |
| time/                       |              |
|    fps                      | 144          |
|    iterations               | 5            |
|    time_elapsed             | 70           |
|    total_timesteps          | 2217984      |
| train/                      |              |
|    approx_kl                | 2416.7495    |
|    approx_ln(kl)            | 7.790179     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.69         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 10820        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0382       |
|    value_loss               | 3.77         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.9109132] |
| time/                       |              |
|    fps                      | 140          |
|    iterations               | 6            |
|    time_elapsed             | 87           |
|    total_timesteps          | 2220032      |
| train/                      |              |
|    approx_kl                | 3375.5122    |
|    approx_ln(kl)            | 8.124302     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.67         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10830        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0387       |
|    value_loss               | 3.47         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.1561716] |
| time/                       |              |
|    fps                      | 136          |
|    iterations               | 7            |
|    time_elapsed             | 104          |
|    total_timesteps          | 2222080      |
| train/                      |              |
|    approx_kl                | 6521.0547    |
|    approx_ln(kl)            | 8.782791     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.67         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10840        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0387       |
|    value_loss               | 2.02         |
----------------------------------------------
----------------------------------------------
| reward                      | [-2.6008086] |
| time/                       |              |
|    fps                      | 133          |
|    iterations               | 8            |
|    time_elapsed             | 122          |
|    total_timesteps          | 2224128      |
| train/                      |              |
|    approx_kl                | 4667.741     |
|    approx_ln(kl)            | 8.448431     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.66         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 10850        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0388       |
|    value_loss               | 2.37         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.7367008] |
| time/                       |              |
|    fps                      | 135          |
|    iterations               | 9            |
|    time_elapsed             | 136          |
|    total_timesteps          | 2226176      |
| train/                      |              |
|    approx_kl                | 3589.77      |
|    approx_ln(kl)            | 8.185843     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.68         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10860        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0384       |
|    value_loss               | 3.41         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.6704283] |
| time/                       |              |
|    fps                      | 136          |
|    iterations               | 10           |
|    time_elapsed             | 150          |
|    total_timesteps          | 2228224      |
| train/                      |              |
|    approx_kl                | 3080.451     |
|    approx_ln(kl)            | 8.032831     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.68         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10870        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0384       |
|    value_loss               | 4.49         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.978667] |
| time/                       |             |
|    fps                      | 137         |
|    iterations               | 11          |
|    time_elapsed             | 164         |
|    total_timesteps          | 2230272     |
| train/                      |             |
|    approx_kl                | 1913.9221   |
|    approx_ln(kl)            | 7.55691     |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.69        |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 10880       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0382      |
|    value_loss               | 2.22        |
---------------------------------------------
---------------------------------------------
| reward                      | [-5.021498] |
| time/                       |             |
|    fps                      | 137         |
|    iterations               | 12          |
|    time_elapsed             | 178         |
|    total_timesteps          | 2232320     |
| train/                      |             |
|    approx_kl                | 6597.079    |
|    approx_ln(kl)            | 8.794382    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.69        |
|    explained_variance       | 1           |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | inf         |
|    loss                     | inf         |
|    n_updates                | 10890       |
|    policy_gradient_loss     | inf         |
|    std                      | 0.0382      |
|    value_loss               | 1.09        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-5.485919] |
| time/                       |             |
|    fps                      | 138         |
|    iterations               | 13          |
|    time_elapsed             | 192         |
|    total_timesteps          | 2234368     |
| train/                      |             |
|    approx_kl                | 3403.617    |
|    approx_ln(kl)            | 8.132594    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.69        |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 10900       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0382      |
|    value_loss               | 2.1         |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.84294075] |
| time/                       |               |
|    fps                      | 138           |
|    iterations               | 14            |
|    time_elapsed             | 206           |
|    total_timesteps          | 2236416       |
| train/                      |               |
|    approx_kl                | 21985.244     |
|    approx_ln(kl)            | 9.998127      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.69          |
|    explained_variance       | 0.996         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 10910         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0382        |
|    value_loss               | 4.36          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.33179528] |
| time/                       |               |
|    fps                      | 139           |
|    iterations               | 15            |
|    time_elapsed             | 220           |
|    total_timesteps          | 2238464       |
| train/                      |               |
|    approx_kl                | 7514.347      |
|    approx_ln(kl)            | 8.924569      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.69          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 10920         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0381        |
|    value_loss               | 2.48          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.6032429] |
| time/                       |              |
|    fps                      | 101          |
|    iterations               | 16           |
|    time_elapsed             | 324          |
|    total_timesteps          | 2240512      |
| train/                      |              |
|    approx_kl                | 3817.5217    |
|    approx_ln(kl)            | 8.247356     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.7          |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10930        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.038        |
|    value_loss               | 3.35         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.49017552] |
| time/                       |               |
|    fps                      | 103           |
|    iterations               | 17            |
|    time_elapsed             | 337           |
|    total_timesteps          | 2242560       |
| train/                      |               |
|    approx_kl                | 2488.9302     |
|    approx_ln(kl)            | 7.819608      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.69          |
|    explained_variance       | 0.997         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 10940         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0382        |
|    value_loss               | 5.1           |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.7686818] |
| time/                       |              |
|    fps                      | 104          |
|    iterations               | 18           |
|    time_elapsed             | 351          |
|    total_timesteps          | 2244608      |
| train/                      |              |
|    approx_kl                | 6790.922     |
|    approx_ln(kl)            | 8.823342     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.69         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10950        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0383       |
|    value_loss               | 2.78         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.9403175] |
| time/                       |              |
|    fps                      | 106          |
|    iterations               | 19           |
|    time_elapsed             | 365          |
|    total_timesteps          | 2246656      |
| train/                      |              |
|    approx_kl                | 10356.26     |
|    approx_ln(kl)            | 9.245346     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.69         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 10960        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0383       |
|    value_loss               | 2.51         |
----------------------------------------------
----------------------------------------------
| reward                      | [-4.1587763] |
| time/                       |              |
|    fps                      | 107          |
|    iterations               | 20           |
|    time_elapsed             | 380          |
|    total_timesteps          | 2248704      |
| train/                      |              |
|    approx_kl                | 16614.203    |
|    approx_ln(kl)            | 9.718013     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.69         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 10970        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0382       |
|    value_loss               | 2.05         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.850801] |
| time/                       |             |
|    fps                      | 108         |
|    iterations               | 21          |
|    time_elapsed             | 396         |
|    total_timesteps          | 2250752     |
| train/                      |             |
|    approx_kl                | 1568.2177   |
|    approx_ln(kl)            | 7.357695    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.69        |
|    explained_variance       | 0.995       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 10980       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0384      |
|    value_loss               | 9.86        |
---------------------------------------------
----------------------------------------------
| reward                      | [-5.0289288] |
| time/                       |              |
|    fps                      | 109          |
|    iterations               | 22           |
|    time_elapsed             | 412          |
|    total_timesteps          | 2252800      |
| train/                      |              |
|    approx_kl                | 4127.4824    |
|    approx_ln(kl)            | 8.325423     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.66         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 10990        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0388       |
|    value_loss               | 2.49         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-5.2912064] |
| time/                       |              |
|    fps                      | 110          |
|    iterations               | 23           |
|    time_elapsed             | 426          |
|    total_timesteps          | 2254848      |
| train/                      |              |
|    approx_kl                | 3686.4653    |
|    approx_ln(kl)            | 8.212423     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.72         |
|    explained_variance       | 0.992        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11000        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0377       |
|    value_loss               | 14.8         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-0.616681] |
| time/                       |             |
|    fps                      | 92          |
|    iterations               | 24          |
|    time_elapsed             | 529         |
|    total_timesteps          | 2256896     |
| train/                      |             |
|    approx_kl                | 2242.2734   |
|    approx_ln(kl)            | 7.7152457   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.72        |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 11010       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0376      |
|    value_loss               | 1.96        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-1.050215] |
| time/                       |             |
|    fps                      | 94          |
|    iterations               | 25          |
|    time_elapsed             | 543         |
|    total_timesteps          | 2258944     |
| train/                      |             |
|    approx_kl                | 4139.04     |
|    approx_ln(kl)            | 8.328219    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.73        |
|    explained_variance       | 0.981       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 11020       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0375      |
|    value_loss               | 5.83        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.3453728] |
| time/                       |              |
|    fps                      | 95           |
|    iterations               | 26           |
|    time_elapsed             | 556          |
|    total_timesteps          | 2260992      |
| train/                      |              |
|    approx_kl                | 6420.096     |
|    approx_ln(kl)            | 8.767188     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.74         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11030        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0374       |
|    value_loss               | 2.85         |
----------------------------------------------
----------------------------------------------
| reward                      | [-1.8797982] |
| time/                       |              |
|    fps                      | 96           |
|    iterations               | 27           |
|    time_elapsed             | 570          |
|    total_timesteps          | 2263040      |
| train/                      |              |
|    approx_kl                | 31448.97     |
|    approx_ln(kl)            | 10.356122    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.73         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 11040        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0374       |
|    value_loss               | 1.28         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.573637] |
| time/                       |             |
|    fps                      | 98          |
|    iterations               | 28          |
|    time_elapsed             | 584         |
|    total_timesteps          | 2265088     |
| train/                      |             |
|    approx_kl                | 5886.323    |
|    approx_ln(kl)            | 8.680387    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.76        |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 11050       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0368      |
|    value_loss               | 4.12        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.8189297] |
| time/                       |              |
|    fps                      | 99           |
|    iterations               | 29           |
|    time_elapsed             | 598          |
|    total_timesteps          | 2267136      |
| train/                      |              |
|    approx_kl                | 17816.172    |
|    approx_ln(kl)            | 9.787862     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.77         |
|    explained_variance       | 0.949        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11060        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0368       |
|    value_loss               | 11.2         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5795753] |
| time/                       |              |
|    fps                      | 100          |
|    iterations               | 30           |
|    time_elapsed             | 612          |
|    total_timesteps          | 2269184      |
| train/                      |              |
|    approx_kl                | 4173.783     |
|    approx_ln(kl)            | 8.336578     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.77         |
|    explained_variance       | 0.959        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11070        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0367       |
|    value_loss               | 12.1         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.8438702] |
| time/                       |              |
|    fps                      | 101          |
|    iterations               | 31           |
|    time_elapsed             | 626          |
|    total_timesteps          | 2271232      |
| train/                      |              |
|    approx_kl                | 6144.512     |
|    approx_ln(kl)            | 8.723314     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.78         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11080        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0365       |
|    value_loss               | 14.1         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-5.022443] |
| time/                       |             |
|    fps                      | 102         |
|    iterations               | 32          |
|    time_elapsed             | 640         |
|    total_timesteps          | 2273280     |
| train/                      |             |
|    approx_kl                | 4968.0493   |
|    approx_ln(kl)            | 8.510782    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.81        |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 11090       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0361      |
|    value_loss               | 3.85        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
--------------------------------------------
| reward                      | [-4.10502] |
| time/                       |            |
|    fps                      | 103        |
|    iterations               | 33         |
|    time_elapsed             | 654        |
|    total_timesteps          | 2275328    |
| train/                      |            |
|    approx_kl                | 2555.6445  |
|    approx_ln(kl)            | 7.84606    |
|    clip_range               | 0.2        |
|    entropy_loss             | 3.81       |
|    explained_variance       | 0.998      |
|    learning_rate            | 0.001      |
|    ln(loss)                 | inf        |
|    ln(policy_gradient_loss) | nan        |
|    loss                     | inf        |
|    n_updates                | 11100      |
|    policy_gradient_loss     | nan        |
|    std                      | 0.0359     |
|    value_loss               | 2.68       |
--------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.36799234] |
| time/                       |               |
|    fps                      | 104           |
|    iterations               | 34            |
|    time_elapsed             | 668           |
|    total_timesteps          | 2277376       |
| train/                      |               |
|    approx_kl                | 1971.5067     |
|    approx_ln(kl)            | 7.5865536     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.82          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 11110         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0359        |
|    value_loss               | 1.49          |
-----------------------------------------------
----------------------------------------------
| reward                      | [-0.9109211] |
| time/                       |              |
|    fps                      | 105          |
|    iterations               | 35           |
|    time_elapsed             | 681          |
|    total_timesteps          | 2279424      |
| train/                      |              |
|    approx_kl                | 11443.838    |
|    approx_ln(kl)            | 9.345207     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.81         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 11120        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0361       |
|    value_loss               | 2.98         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.2010276] |
| time/                       |              |
|    fps                      | 105          |
|    iterations               | 36           |
|    time_elapsed             | 695          |
|    total_timesteps          | 2281472      |
| train/                      |              |
|    approx_kl                | 5639.845     |
|    approx_ln(kl)            | 8.637612     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.81         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11130        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.036        |
|    value_loss               | 2.87         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.3373715] |
| time/                       |              |
|    fps                      | 106          |
|    iterations               | 37           |
|    time_elapsed             | 709          |
|    total_timesteps          | 2283520      |
| train/                      |              |
|    approx_kl                | 3837.897     |
|    approx_ln(kl)            | 8.25268      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.81         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11140        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0362       |
|    value_loss               | 2.04         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.2732997] |
| time/                       |              |
|    fps                      | 107          |
|    iterations               | 38           |
|    time_elapsed             | 723          |
|    total_timesteps          | 2285568      |
| train/                      |              |
|    approx_kl                | 5906.048     |
|    approx_ln(kl)            | 8.683732     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.79         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11150        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0364       |
|    value_loss               | 1.26         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.764569] |
| time/                       |             |
|    fps                      | 108         |
|    iterations               | 39          |
|    time_elapsed             | 737         |
|    total_timesteps          | 2287616     |
| train/                      |             |
|    approx_kl                | 2659.747    |
|    approx_ln(kl)            | 7.8859863   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.79        |
|    explained_variance       | 0.996       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 11160       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0365      |
|    value_loss               | 2.23        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.0501933] |
| time/                       |              |
|    fps                      | 109          |
|    iterations               | 40           |
|    time_elapsed             | 751          |
|    total_timesteps          | 2289664      |
| train/                      |              |
|    approx_kl                | 8003.034     |
|    approx_ln(kl)            | 8.9875765    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.83         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11170        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0357       |
|    value_loss               | 1.39         |
----------------------------------------------
----------------------------------------------
| reward                      | [-4.2643123] |
| time/                       |              |
|    fps                      | 109          |
|    iterations               | 41           |
|    time_elapsed             | 765          |
|    total_timesteps          | 2291712      |
| train/                      |              |
|    approx_kl                | 9428.682     |
|    approx_ln(kl)            | 9.151511     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.82         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 11180        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0359       |
|    value_loss               | 1.04         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.7081949] |
| time/                       |              |
|    fps                      | 110          |
|    iterations               | 42           |
|    time_elapsed             | 778          |
|    total_timesteps          | 2293760      |
| train/                      |              |
|    approx_kl                | 2223.4312    |
|    approx_ln(kl)            | 7.7068067    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.82         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11190        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0358       |
|    value_loss               | 3.93         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0282959] |
| time/                       |              |
|    fps                      | 111          |
|    iterations               | 43           |
|    time_elapsed             | 792          |
|    total_timesteps          | 2295808      |
| train/                      |              |
|    approx_kl                | 9147.461     |
|    approx_ln(kl)            | 9.121232     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.84         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11200        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0356       |
|    value_loss               | 3.48         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.2860465] |
| time/                       |              |
|    fps                      | 111          |
|    iterations               | 44           |
|    time_elapsed             | 806          |
|    total_timesteps          | 2297856      |
| train/                      |              |
|    approx_kl                | 31627.816    |
|    approx_ln(kl)            | 10.361793    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.84         |
|    explained_variance       | 0.99         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11210        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0352       |
|    value_loss               | 2.68         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7728048] |
| time/                       |              |
|    fps                      | 112          |
|    iterations               | 45           |
|    time_elapsed             | 821          |
|    total_timesteps          | 2299904      |
| train/                      |              |
|    approx_kl                | 7054.6055    |
|    approx_ln(kl)            | 8.861436     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.86         |
|    explained_variance       | 0.98         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11220        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0352       |
|    value_loss               | 1.39         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.2761831] |
| time/                       |              |
|    fps                      | 112          |
|    iterations               | 46           |
|    time_elapsed             | 835          |
|    total_timesteps          | 2301952      |
| train/                      |              |
|    approx_kl                | 8723.15      |
|    approx_ln(kl)            | 9.073736     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.81         |
|    explained_variance       | 0.978        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11230        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0361       |
|    value_loss               | 2.08         |
----------------------------------------------
-----------------------------------------------
| reward                      | [-0.50517166] |
| time/                       |               |
|    fps                      | 113           |
|    iterations               | 47            |
|    time_elapsed             | 848           |
|    total_timesteps          | 2304000       |
| train/                      |               |
|    approx_kl                | 8991.787      |
|    approx_ln(kl)            | 9.104067      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.78          |
|    explained_variance       | 0.965         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 11240         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0366        |
|    value_loss               | 1.87          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6531398] |
| time/                       |              |
|    fps                      | 113          |
|    iterations               | 48           |
|    time_elapsed             | 862          |
|    total_timesteps          | 2306048      |
| train/                      |              |
|    approx_kl                | 10062.905    |
|    approx_ln(kl)            | 9.216611     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.77         |
|    explained_variance       | 0.977        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11250        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0368       |
|    value_loss               | 3            |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6607698] |
| time/                       |              |
|    fps                      | 114          |
|    iterations               | 49           |
|    time_elapsed             | 876          |
|    total_timesteps          | 2308096      |
| train/                      |              |
|    approx_kl                | 3558.0215    |
|    approx_ln(kl)            | 8.17696      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.79         |
|    explained_variance       | 0.98         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11260        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0365       |
|    value_loss               | 1.47         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-------------------------------------
| reward             | [-0.7261244] |
| time/              |              |
|    fps             | 162          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 2310144      |
-------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7223689] |
| time/                       |              |
|    fps                      | 154          |
|    iterations               | 2            |
|    time_elapsed             | 26           |
|    total_timesteps          | 2312192      |
| train/                      |              |
|    approx_kl                | 35449.223    |
|    approx_ln(kl)            | 10.475857    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.83         |
|    explained_variance       | 0.988        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11280        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0357       |
|    value_loss               | 2            |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6945343] |
| time/                       |              |
|    fps                      | 152          |
|    iterations               | 3            |
|    time_elapsed             | 40           |
|    total_timesteps          | 2314240      |
| train/                      |              |
|    approx_kl                | 17561.703    |
|    approx_ln(kl)            | 9.773476     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.83         |
|    explained_variance       | 0.985        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11290        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0356       |
|    value_loss               | 0.834        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5435941] |
| time/                       |              |
|    fps                      | 151          |
|    iterations               | 4            |
|    time_elapsed             | 54           |
|    total_timesteps          | 2316288      |
| train/                      |              |
|    approx_kl                | 10285.805    |
|    approx_ln(kl)            | 9.23852      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.82         |
|    explained_variance       | 0.988        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11300        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0358       |
|    value_loss               | 0.669        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.82016927] |
| time/                       |               |
|    fps                      | 150           |
|    iterations               | 5             |
|    time_elapsed             | 68            |
|    total_timesteps          | 2318336       |
| train/                      |               |
|    approx_kl                | 15922.182     |
|    approx_ln(kl)            | 9.675468      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.85          |
|    explained_variance       | 0.995         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 11310         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0353        |
|    value_loss               | 1.04          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6265048] |
| time/                       |              |
|    fps                      | 150          |
|    iterations               | 6            |
|    time_elapsed             | 81           |
|    total_timesteps          | 2320384      |
| train/                      |              |
|    approx_kl                | 7993.5146    |
|    approx_ln(kl)            | 8.986386     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.85         |
|    explained_variance       | 0.972        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11320        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0353       |
|    value_loss               | 1.15         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6353941] |
| time/                       |              |
|    fps                      | 150          |
|    iterations               | 7            |
|    time_elapsed             | 95           |
|    total_timesteps          | 2322432      |
| train/                      |              |
|    approx_kl                | 10387.199    |
|    approx_ln(kl)            | 9.248329     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.83         |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11330        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0357       |
|    value_loss               | 1.84         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.9475772] |
| time/                       |              |
|    fps                      | 150          |
|    iterations               | 8            |
|    time_elapsed             | 109          |
|    total_timesteps          | 2324480      |
| train/                      |              |
|    approx_kl                | 48555.375    |
|    approx_ln(kl)            | 10.790461    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.82         |
|    explained_variance       | 0.974        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11340        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0358       |
|    value_loss               | 1.69         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.74468786] |
| time/                       |               |
|    fps                      | 149           |
|    iterations               | 9             |
|    time_elapsed             | 123           |
|    total_timesteps          | 2326528       |
| train/                      |               |
|    approx_kl                | 2297.0027     |
|    approx_ln(kl)            | 7.7393603     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.83          |
|    explained_variance       | 0.852         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 11350         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0357        |
|    value_loss               | 14.1          |
-----------------------------------------------
-----------------------------------------------
| reward                      | [-0.70030123] |
| time/                       |               |
|    fps                      | 149           |
|    iterations               | 10            |
|    time_elapsed             | 136           |
|    total_timesteps          | 2328576       |
| train/                      |               |
|    approx_kl                | 40089.383     |
|    approx_ln(kl)            | 10.598866     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.83          |
|    explained_variance       | 0.923         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 11360         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0357        |
|    value_loss               | 7.34          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.46504885] |
| time/                       |               |
|    fps                      | 149           |
|    iterations               | 11            |
|    time_elapsed             | 150           |
|    total_timesteps          | 2330624       |
| train/                      |               |
|    approx_kl                | 43599.793     |
|    approx_ln(kl)            | 10.682808     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.85          |
|    explained_variance       | 0.985         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 11370         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0353        |
|    value_loss               | 0.384         |
-----------------------------------------------
-----------------------------------------------
| reward                      | [-0.68498874] |
| time/                       |               |
|    fps                      | 149           |
|    iterations               | 12            |
|    time_elapsed             | 164           |
|    total_timesteps          | 2332672       |
| train/                      |               |
|    approx_kl                | 54549.445     |
|    approx_ln(kl)            | 10.906863     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.85          |
|    explained_variance       | 0.992         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 11380         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0354        |
|    value_loss               | 0.287         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.63477236] |
| time/                       |               |
|    fps                      | 149           |
|    iterations               | 13            |
|    time_elapsed             | 178           |
|    total_timesteps          | 2334720       |
| train/                      |               |
|    approx_kl                | 12142.63      |
|    approx_ln(kl)            | 9.404478      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.88          |
|    explained_variance       | 0.991         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 11390         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0347        |
|    value_loss               | 0.373         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.59133637] |
| time/                       |               |
|    fps                      | 149           |
|    iterations               | 14            |
|    time_elapsed             | 191           |
|    total_timesteps          | 2336768       |
| train/                      |               |
|    approx_kl                | 27483.43      |
|    approx_ln(kl)            | 10.221338     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.85          |
|    explained_variance       | 0.957         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 11400         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0353        |
|    value_loss               | 0.437         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.1714813] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 15           |
|    time_elapsed             | 205          |
|    total_timesteps          | 2338816      |
| train/                      |              |
|    approx_kl                | 22575.443    |
|    approx_ln(kl)            | 10.024618    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.85         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11410        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0353       |
|    value_loss               | 0.16         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.9728268] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 16           |
|    time_elapsed             | 219          |
|    total_timesteps          | 2340864      |
| train/                      |              |
|    approx_kl                | 6244.2095    |
|    approx_ln(kl)            | 8.739409     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.86         |
|    explained_variance       | 0.984        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11420        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0351       |
|    value_loss               | 0.384        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6506972] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 17           |
|    time_elapsed             | 233          |
|    total_timesteps          | 2342912      |
| train/                      |              |
|    approx_kl                | 16291.046    |
|    approx_ln(kl)            | 9.698371     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.86         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11430        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0351       |
|    value_loss               | 0.204        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0757849] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 18           |
|    time_elapsed             | 247          |
|    total_timesteps          | 2344960      |
| train/                      |              |
|    approx_kl                | 16191.121    |
|    approx_ln(kl)            | 9.692219     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.86         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11440        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0351       |
|    value_loss               | 0.214        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7326406] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 19           |
|    time_elapsed             | 260          |
|    total_timesteps          | 2347008      |
| train/                      |              |
|    approx_kl                | 15085.285    |
|    approx_ln(kl)            | 9.621475     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.84         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11450        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0355       |
|    value_loss               | 1.07         |
----------------------------------------------
----------------------------------------------
| reward                      | [-0.4245768] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 20           |
|    time_elapsed             | 274          |
|    total_timesteps          | 2349056      |
| train/                      |              |
|    approx_kl                | 3630.0178    |
|    approx_ln(kl)            | 8.196993     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.82         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 11460        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0359       |
|    value_loss               | 1.61         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.73902583] |
| time/                       |               |
|    fps                      | 149           |
|    iterations               | 21            |
|    time_elapsed             | 288           |
|    total_timesteps          | 2351104       |
| train/                      |               |
|    approx_kl                | 29686.666     |
|    approx_ln(kl)            | 10.298453     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.79          |
|    explained_variance       | 0.997         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 11470         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0365        |
|    value_loss               | 0.656         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6364668] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 22           |
|    time_elapsed             | 302          |
|    total_timesteps          | 2353152      |
| train/                      |              |
|    approx_kl                | 11625.179    |
|    approx_ln(kl)            | 9.360929     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.82         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11480        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0357       |
|    value_loss               | 1.54         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6873391] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 23           |
|    time_elapsed             | 316          |
|    total_timesteps          | 2355200      |
| train/                      |              |
|    approx_kl                | 3659.1353    |
|    approx_ln(kl)            | 8.204982     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.83         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11490        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0357       |
|    value_loss               | 2.33         |
----------------------------------------------
----------------------------------------------
| reward                      | [-2.4648185] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 24           |
|    time_elapsed             | 332          |
|    total_timesteps          | 2357248      |
| train/                      |              |
|    approx_kl                | 6082.9463    |
|    approx_ln(kl)            | 8.713244     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.81         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 11500        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.036        |
|    value_loss               | 3.31         |
----------------------------------------------
-----------------------------------------------
| reward                      | [-0.62304515] |
| time/                       |               |
|    fps                      | 145           |
|    iterations               | 25            |
|    time_elapsed             | 352           |
|    total_timesteps          | 2359296       |
| train/                      |               |
|    approx_kl                | 12022.189     |
|    approx_ln(kl)            | 9.394509      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.84          |
|    explained_variance       | 0.996         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 11510         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0355        |
|    value_loss               | 4.75          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
--------------------------------------------
| reward                      | [-5.25363] |
| time/                       |            |
|    fps                      | 144        |
|    iterations               | 26         |
|    time_elapsed             | 368        |
|    total_timesteps          | 2361344    |
| train/                      |            |
|    approx_kl                | 10764.235  |
|    approx_ln(kl)            | 9.283984   |
|    clip_range               | 0.2        |
|    entropy_loss             | 3.82       |
|    explained_variance       | 0.99       |
|    learning_rate            | 0.001      |
|    ln(loss)                 | inf        |
|    ln(policy_gradient_loss) | nan        |
|    loss                     | inf        |
|    n_updates                | 11520      |
|    policy_gradient_loss     | nan        |
|    std                      | 0.0359     |
|    value_loss               | 4.3        |
--------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.42109674] |
| time/                       |               |
|    fps                      | 143           |
|    iterations               | 27            |
|    time_elapsed             | 385           |
|    total_timesteps          | 2363392       |
| train/                      |               |
|    approx_kl                | 1936.8213     |
|    approx_ln(kl)            | 7.5688033     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.82          |
|    explained_variance       | 0.935         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 11530         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0359        |
|    value_loss               | 24.4          |
-----------------------------------------------
-----------------------------------------------
| reward                      | [-0.72102034] |
| time/                       |               |
|    fps                      | 143           |
|    iterations               | 28            |
|    time_elapsed             | 400           |
|    total_timesteps          | 2365440       |
| train/                      |               |
|    approx_kl                | 10048.808     |
|    approx_ln(kl)            | 9.215209      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.86          |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 11540         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.035         |
|    value_loss               | 3.24          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.9353235] |
| time/                       |              |
|    fps                      | 142          |
|    iterations               | 29           |
|    time_elapsed             | 416          |
|    total_timesteps          | 2367488      |
| train/                      |              |
|    approx_kl                | 7122.163     |
|    approx_ln(kl)            | 8.870967     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.87         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11550        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0349       |
|    value_loss               | 6.21         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.5409136] |
| time/                       |              |
|    fps                      | 142          |
|    iterations               | 30           |
|    time_elapsed             | 432          |
|    total_timesteps          | 2369536      |
| train/                      |              |
|    approx_kl                | 18290.092    |
|    approx_ln(kl)            | 9.814115     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.86         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11560        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0352       |
|    value_loss               | 5.32         |
----------------------------------------------
----------------------------------------------
| reward                      | [-1.9716997] |
| time/                       |              |
|    fps                      | 141          |
|    iterations               | 31           |
|    time_elapsed             | 448          |
|    total_timesteps          | 2371584      |
| train/                      |              |
|    approx_kl                | 16251.314    |
|    approx_ln(kl)            | 9.69593      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.88         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 11570        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0348       |
|    value_loss               | 1.03         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.5963216] |
| time/                       |              |
|    fps                      | 141          |
|    iterations               | 32           |
|    time_elapsed             | 463          |
|    total_timesteps          | 2373632      |
| train/                      |              |
|    approx_kl                | 4541.425     |
|    approx_ln(kl)            | 8.420996     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.84         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11580        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0354       |
|    value_loss               | 2.15         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.0386755] |
| time/                       |              |
|    fps                      | 140          |
|    iterations               | 33           |
|    time_elapsed             | 479          |
|    total_timesteps          | 2375680      |
| train/                      |              |
|    approx_kl                | 20014.96     |
|    approx_ln(kl)            | 9.904235     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.84         |
|    explained_variance       | 0.992        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11590        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0355       |
|    value_loss               | 4.45         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.084334] |
| time/                       |             |
|    fps                      | 140         |
|    iterations               | 34          |
|    time_elapsed             | 495         |
|    total_timesteps          | 2377728     |
| train/                      |             |
|    approx_kl                | 16272.205   |
|    approx_ln(kl)            | 9.697214    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.83        |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 11600       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0357      |
|    value_loss               | 1.64        |
---------------------------------------------
----------------------------------------------
| reward                      | [-0.6669347] |
| time/                       |              |
|    fps                      | 140          |
|    iterations               | 35           |
|    time_elapsed             | 511          |
|    total_timesteps          | 2379776      |
| train/                      |              |
|    approx_kl                | 31690.582    |
|    approx_ln(kl)            | 10.363775    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.82         |
|    explained_variance       | 0.991        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 11610        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0357       |
|    value_loss               | 4.12         |
----------------------------------------------
----------------------------------------------
| reward                      | [-0.6044159] |
| time/                       |              |
|    fps                      | 139          |
|    iterations               | 36           |
|    time_elapsed             | 527          |
|    total_timesteps          | 2381824      |
| train/                      |              |
|    approx_kl                | 5589.3887    |
|    approx_ln(kl)            | 8.628625     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.83         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 11620        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0357       |
|    value_loss               | 2.1          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.3777772] |
| time/                       |              |
|    fps                      | 139          |
|    iterations               | 37           |
|    time_elapsed             | 544          |
|    total_timesteps          | 2383872      |
| train/                      |              |
|    approx_kl                | 13056.42     |
|    approx_ln(kl)            | 9.4770355    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.87         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11630        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0349       |
|    value_loss               | 1.75         |
----------------------------------------------
---------------------------------------------
| reward                      | [-0.909297] |
| time/                       |             |
|    fps                      | 123         |
|    iterations               | 38          |
|    time_elapsed             | 629         |
|    total_timesteps          | 2385920     |
| train/                      |             |
|    approx_kl                | 40179.92    |
|    approx_ln(kl)            | 10.601123   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.87        |
|    explained_variance       | 0.997       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | inf         |
|    loss                     | inf         |
|    n_updates                | 11640       |
|    policy_gradient_loss     | inf         |
|    std                      | 0.0349      |
|    value_loss               | 2.29        |
---------------------------------------------
----------------------------------------------
| reward                      | [-0.3224153] |
| time/                       |              |
|    fps                      | 108          |
|    iterations               | 39           |
|    time_elapsed             | 733          |
|    total_timesteps          | 2387968      |
| train/                      |              |
|    approx_kl                | 14505.954    |
|    approx_ln(kl)            | 9.5823145    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.87         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 11650        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.035        |
|    value_loss               | 2.8          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.65678257] |
| time/                       |               |
|    fps                      | 109           |
|    iterations               | 40            |
|    time_elapsed             | 747           |
|    total_timesteps          | 2390016       |
| train/                      |               |
|    approx_kl                | 4213.8535     |
|    approx_ln(kl)            | 8.346133      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.87          |
|    explained_variance       | 0.996         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 11660         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.035         |
|    value_loss               | 3.49          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.39355266] |
| time/                       |               |
|    fps                      | 110           |
|    iterations               | 41            |
|    time_elapsed             | 761           |
|    total_timesteps          | 2392064       |
| train/                      |               |
|    approx_kl                | 7890.329      |
|    approx_ln(kl)            | 8.973393      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.83          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 11670         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0358        |
|    value_loss               | 0.979         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.46867794] |
| time/                       |               |
|    fps                      | 110           |
|    iterations               | 42            |
|    time_elapsed             | 775           |
|    total_timesteps          | 2394112       |
| train/                      |               |
|    approx_kl                | 11465.747     |
|    approx_ln(kl)            | 9.347119      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.81          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 11680         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0361        |
|    value_loss               | 0.859         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.95980495] |
| time/                       |               |
|    fps                      | 111           |
|    iterations               | 43            |
|    time_elapsed             | 788           |
|    total_timesteps          | 2396160       |
| train/                      |               |
|    approx_kl                | 5190.868      |
|    approx_ln(kl)            | 8.554656      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.79          |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 11690         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0368        |
|    value_loss               | 0.849         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.2439532] |
| time/                       |              |
|    fps                      | 112          |
|    iterations               | 44           |
|    time_elapsed             | 802          |
|    total_timesteps          | 2398208      |
| train/                      |              |
|    approx_kl                | 8506.174     |
|    approx_ln(kl)            | 9.048548     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.74         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11700        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0376       |
|    value_loss               | 1.17         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.1617174] |
| time/                       |              |
|    fps                      | 112          |
|    iterations               | 45           |
|    time_elapsed             | 817          |
|    total_timesteps          | 2400256      |
| train/                      |              |
|    approx_kl                | 3980.8323    |
|    approx_ln(kl)            | 8.289247     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.72         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11710        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0378       |
|    value_loss               | 0.386        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.45209768] |
| time/                       |               |
|    fps                      | 113           |
|    iterations               | 46            |
|    time_elapsed             | 831           |
|    total_timesteps          | 2402304       |
| train/                      |               |
|    approx_kl                | 10327.203     |
|    approx_ln(kl)            | 9.242537      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.69          |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 11720         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0383        |
|    value_loss               | 1.18          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.336525] |
| time/                       |             |
|    fps                      | 113         |
|    iterations               | 47          |
|    time_elapsed             | 844         |
|    total_timesteps          | 2404352     |
| train/                      |             |
|    approx_kl                | 15054.839   |
|    approx_ln(kl)            | 9.619454    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.69        |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 11730       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0383      |
|    value_loss               | 0.62        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6452977] |
| time/                       |              |
|    fps                      | 114          |
|    iterations               | 48           |
|    time_elapsed             | 858          |
|    total_timesteps          | 2406400      |
| train/                      |              |
|    approx_kl                | 20250.02     |
|    approx_ln(kl)            | 9.915911     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.69         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11740        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0383       |
|    value_loss               | 1.02         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.67573196] |
| time/                       |               |
|    fps                      | 115           |
|    iterations               | 49            |
|    time_elapsed             | 872           |
|    total_timesteps          | 2408448       |
| train/                      |               |
|    approx_kl                | 4946.175      |
|    approx_ln(kl)            | 8.50637       |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.67          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 11750         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0388        |
|    value_loss               | 1.19          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-------------------------------------
| reward             | [-0.8764569] |
| time/              |              |
|    fps             | 155          |
|    iterations      | 1            |
|    time_elapsed    | 13           |
|    total_timesteps | 2410496      |
-------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0471045] |
| time/                       |              |
|    fps                      | 142          |
|    iterations               | 2            |
|    time_elapsed             | 28           |
|    total_timesteps          | 2412544      |
| train/                      |              |
|    approx_kl                | 10440.547    |
|    approx_ln(kl)            | 9.253452     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.67         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11770        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0387       |
|    value_loss               | 0.312        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.58943814] |
| time/                       |               |
|    fps                      | 88            |
|    iterations               | 3             |
|    time_elapsed             | 69            |
|    total_timesteps          | 2414592       |
| train/                      |               |
|    approx_kl                | 6931.5547     |
|    approx_ln(kl)            | 8.84384       |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.7           |
|    explained_variance       | 1             |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 11780         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0382        |
|    value_loss               | 0.435         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-0.663405] |
| time/                       |             |
|    fps                      | 96          |
|    iterations               | 4           |
|    time_elapsed             | 84          |
|    total_timesteps          | 2416640     |
| train/                      |             |
|    approx_kl                | 28191.732   |
|    approx_ln(kl)            | 10.246784   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.72        |
|    explained_variance       | 1           |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 11790       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0378      |
|    value_loss               | 0.253       |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0617684] |
| time/                       |              |
|    fps                      | 102          |
|    iterations               | 5            |
|    time_elapsed             | 99           |
|    total_timesteps          | 2418688      |
| train/                      |              |
|    approx_kl                | 8297.141     |
|    approx_ln(kl)            | 9.023666     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.72         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11800        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0378       |
|    value_loss               | 0.281        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.388967] |
| time/                       |             |
|    fps                      | 60          |
|    iterations               | 6           |
|    time_elapsed             | 203         |
|    total_timesteps          | 2420736     |
| train/                      |             |
|    approx_kl                | 8680.234    |
|    approx_ln(kl)            | 9.068804    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.71        |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 11810       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0379      |
|    value_loss               | 1.36        |
---------------------------------------------
----------------------------------------------
| reward                      | [-4.1944532] |
| time/                       |              |
|    fps                      | 66           |
|    iterations               | 7            |
|    time_elapsed             | 216          |
|    total_timesteps          | 2422784      |
| train/                      |              |
|    approx_kl                | 4191.468     |
|    approx_ln(kl)            | 8.340806     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.71         |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 11820        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0381       |
|    value_loss               | 5.92         |
----------------------------------------------
----------------------------------------------
| reward                      | [-2.9086316] |
| time/                       |              |
|    fps                      | 71           |
|    iterations               | 8            |
|    time_elapsed             | 230          |
|    total_timesteps          | 2424832      |
| train/                      |              |
|    approx_kl                | 4695.085     |
|    approx_ln(kl)            | 8.454271     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.72         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 11830        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0379       |
|    value_loss               | 3.3          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.42214832] |
| time/                       |               |
|    fps                      | 75            |
|    iterations               | 9             |
|    time_elapsed             | 244           |
|    total_timesteps          | 2426880       |
| train/                      |               |
|    approx_kl                | 3903.5198     |
|    approx_ln(kl)            | 8.269634      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.72          |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 11840         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0379        |
|    value_loss               | 2.51          |
-----------------------------------------------
-----------------------------------------------
| reward                      | [-0.83823097] |
| time/                       |               |
|    fps                      | 79            |
|    iterations               | 10            |
|    time_elapsed             | 257           |
|    total_timesteps          | 2428928       |
| train/                      |               |
|    approx_kl                | 17410.809     |
|    approx_ln(kl)            | 9.764847      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.73          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 11850         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0375        |
|    value_loss               | 1.38          |
-----------------------------------------------
----------------------------------------------
| reward                      | [-1.1166933] |
| time/                       |              |
|    fps                      | 82           |
|    iterations               | 11           |
|    time_elapsed             | 271          |
|    total_timesteps          | 2430976      |
| train/                      |              |
|    approx_kl                | 4538.3223    |
|    approx_ln(kl)            | 8.420313     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.73         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 11860        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0376       |
|    value_loss               | 2.24         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.9927189] |
| time/                       |              |
|    fps                      | 86           |
|    iterations               | 12           |
|    time_elapsed             | 285          |
|    total_timesteps          | 2433024      |
| train/                      |              |
|    approx_kl                | 3833.892     |
|    approx_ln(kl)            | 8.251636     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.74         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11870        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0375       |
|    value_loss               | 5.05         |
----------------------------------------------
---------------------------------------------
| reward                      | [-2.672557] |
| time/                       |             |
|    fps                      | 88          |
|    iterations               | 13          |
|    time_elapsed             | 299         |
|    total_timesteps          | 2435072     |
| train/                      |             |
|    approx_kl                | 7597.916    |
|    approx_ln(kl)            | 8.935629    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.74        |
|    explained_variance       | 0.997       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | inf         |
|    loss                     | inf         |
|    n_updates                | 11880       |
|    policy_gradient_loss     | inf         |
|    std                      | 0.0381      |
|    value_loss               | 4.1         |
---------------------------------------------
----------------------------------------------
| reward                      | [-3.3591084] |
| time/                       |              |
|    fps                      | 91           |
|    iterations               | 14           |
|    time_elapsed             | 312          |
|    total_timesteps          | 2437120      |
| train/                      |              |
|    approx_kl                | 1774.7888    |
|    approx_ln(kl)            | 7.4814367    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.66         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 11890        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.039        |
|    value_loss               | 5.68         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.7184005] |
| time/                       |              |
|    fps                      | 94           |
|    iterations               | 15           |
|    time_elapsed             | 326          |
|    total_timesteps          | 2439168      |
| train/                      |              |
|    approx_kl                | 4460.3726    |
|    approx_ln(kl)            | 8.4029875    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.66         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11900        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0389       |
|    value_loss               | 2.02         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.044679] |
| time/                       |             |
|    fps                      | 96          |
|    iterations               | 16          |
|    time_elapsed             | 340         |
|    total_timesteps          | 2441216     |
| train/                      |             |
|    approx_kl                | 3134.3506   |
|    approx_ln(kl)            | 8.050178    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.69        |
|    explained_variance       | 0.996       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 11910       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0384      |
|    value_loss               | 3.43        |
---------------------------------------------
----------------------------------------------
| reward                      | [-4.4272804] |
| time/                       |              |
|    fps                      | 98           |
|    iterations               | 17           |
|    time_elapsed             | 354          |
|    total_timesteps          | 2443264      |
| train/                      |              |
|    approx_kl                | 6631.8335    |
|    approx_ln(kl)            | 8.799637     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.69         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 11920        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0378       |
|    value_loss               | 1.81         |
----------------------------------------------
----------------------------------------------
| reward                      | [-4.7202296] |
| time/                       |              |
|    fps                      | 100          |
|    iterations               | 18           |
|    time_elapsed             | 367          |
|    total_timesteps          | 2445312      |
| train/                      |              |
|    approx_kl                | 6036.173     |
|    approx_ln(kl)            | 8.705525     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.71         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 11930        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0378       |
|    value_loss               | 1.69         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.9917574] |
| time/                       |              |
|    fps                      | 101          |
|    iterations               | 19           |
|    time_elapsed             | 381          |
|    total_timesteps          | 2447360      |
| train/                      |              |
|    approx_kl                | 6691.523     |
|    approx_ln(kl)            | 8.808597     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.74         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11940        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0375       |
|    value_loss               | 1.82         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.90953755] |
| time/                       |               |
|    fps                      | 103           |
|    iterations               | 20            |
|    time_elapsed             | 395           |
|    total_timesteps          | 2449408       |
| train/                      |               |
|    approx_kl                | 6700.4736     |
|    approx_ln(kl)            | 8.809934      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.72          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 11950         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0378        |
|    value_loss               | 2.04          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-1.114717] |
| time/                       |             |
|    fps                      | 105         |
|    iterations               | 21          |
|    time_elapsed             | 408         |
|    total_timesteps          | 2451456     |
| train/                      |             |
|    approx_kl                | 6601.839    |
|    approx_ln(kl)            | 8.795103    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.76        |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 11960       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0369      |
|    value_loss               | 2.82        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.9872087] |
| time/                       |              |
|    fps                      | 106          |
|    iterations               | 22           |
|    time_elapsed             | 422          |
|    total_timesteps          | 2453504      |
| train/                      |              |
|    approx_kl                | 14155.667    |
|    approx_ln(kl)            | 9.55787      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.75         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 11970        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0371       |
|    value_loss               | 2.25         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.331605] |
| time/                       |             |
|    fps                      | 107         |
|    iterations               | 23          |
|    time_elapsed             | 436         |
|    total_timesteps          | 2455552     |
| train/                      |             |
|    approx_kl                | 3214.3054   |
|    approx_ln(kl)            | 8.075367    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.78        |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 11980       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0367      |
|    value_loss               | 2.09        |
---------------------------------------------
----------------------------------------------
| reward                      | [-3.2173033] |
| time/                       |              |
|    fps                      | 109          |
|    iterations               | 24           |
|    time_elapsed             | 450          |
|    total_timesteps          | 2457600      |
| train/                      |              |
|    approx_kl                | 5943.2803    |
|    approx_ln(kl)            | 8.690017     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.78         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 11990        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0365       |
|    value_loss               | 1.79         |
----------------------------------------------
---------------------------------------------
| reward                      | [-3.358726] |
| time/                       |             |
|    fps                      | 110         |
|    iterations               | 25          |
|    time_elapsed             | 464         |
|    total_timesteps          | 2459648     |
| train/                      |             |
|    approx_kl                | 30149.21    |
|    approx_ln(kl)            | 10.313914   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.78        |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | inf         |
|    loss                     | inf         |
|    n_updates                | 12000       |
|    policy_gradient_loss     | inf         |
|    std                      | 0.0366      |
|    value_loss               | 1.69        |
---------------------------------------------
----------------------------------------------
| reward                      | [-3.7613974] |
| time/                       |              |
|    fps                      | 111          |
|    iterations               | 26           |
|    time_elapsed             | 477          |
|    total_timesteps          | 2461696      |
| train/                      |              |
|    approx_kl                | 2559.0894    |
|    approx_ln(kl)            | 7.847407     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.78         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 12010        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0367       |
|    value_loss               | 2.89         |
----------------------------------------------
----------------------------------------------
| reward                      | [-4.1446023] |
| time/                       |              |
|    fps                      | 112          |
|    iterations               | 27           |
|    time_elapsed             | 491          |
|    total_timesteps          | 2463744      |
| train/                      |              |
|    approx_kl                | 8551.84      |
|    approx_ln(kl)            | 9.053902     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.77         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 12020        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0368       |
|    value_loss               | 1.12         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.5514483] |
| time/                       |              |
|    fps                      | 113          |
|    iterations               | 28           |
|    time_elapsed             | 505          |
|    total_timesteps          | 2465792      |
| train/                      |              |
|    approx_kl                | 11955.273    |
|    approx_ln(kl)            | 9.388927     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.77         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 12030        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0368       |
|    value_loss               | 1.57         |
----------------------------------------------
----------------------------------------------
| reward                      | [-4.7061076] |
| time/                       |              |
|    fps                      | 114          |
|    iterations               | 29           |
|    time_elapsed             | 519          |
|    total_timesteps          | 2467840      |
| train/                      |              |
|    approx_kl                | 9052.299     |
|    approx_ln(kl)            | 9.110774     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.77         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 12040        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0367       |
|    value_loss               | 1.09         |
----------------------------------------------
-----------------------------------------------
| reward                      | [-0.45695373] |
| time/                       |               |
|    fps                      | 115           |
|    iterations               | 30            |
|    time_elapsed             | 532           |
|    total_timesteps          | 2469888       |
| train/                      |               |
|    approx_kl                | 1669.9476     |
|    approx_ln(kl)            | 7.4205475     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.81          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 12050         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0361        |
|    value_loss               | 2.48          |
-----------------------------------------------
----------------------------------------------
| reward                      | [-1.2779963] |
| time/                       |              |
|    fps                      | 116          |
|    iterations               | 31           |
|    time_elapsed             | 546          |
|    total_timesteps          | 2471936      |
| train/                      |              |
|    approx_kl                | 2065.817     |
|    approx_ln(kl)            | 7.633281     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.82         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 12060        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0359       |
|    value_loss               | 1.91         |
----------------------------------------------
----------------------------------------------
| reward                      | [-1.6641529] |
| time/                       |              |
|    fps                      | 116          |
|    iterations               | 32           |
|    time_elapsed             | 560          |
|    total_timesteps          | 2473984      |
| train/                      |              |
|    approx_kl                | 2542.9473    |
|    approx_ln(kl)            | 7.841079     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.84         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 12070        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0355       |
|    value_loss               | 0.946        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.4678156] |
| time/                       |              |
|    fps                      | 117          |
|    iterations               | 33           |
|    time_elapsed             | 574          |
|    total_timesteps          | 2476032      |
| train/                      |              |
|    approx_kl                | 5793.1694    |
|    approx_ln(kl)            | 8.664434     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.83         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 12080        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0357       |
|    value_loss               | 1.33         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.0264611] |
| time/                       |              |
|    fps                      | 118          |
|    iterations               | 34           |
|    time_elapsed             | 588          |
|    total_timesteps          | 2478080      |
| train/                      |              |
|    approx_kl                | 9603.333     |
|    approx_ln(kl)            | 9.169866     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.83         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 12090        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0356       |
|    value_loss               | 1.28         |
----------------------------------------------
---------------------------------------------
| reward                      | [-3.258551] |
| time/                       |             |
|    fps                      | 119         |
|    iterations               | 35          |
|    time_elapsed             | 601         |
|    total_timesteps          | 2480128     |
| train/                      |             |
|    approx_kl                | 6474.0044   |
|    approx_ln(kl)            | 8.77555     |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.85        |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | inf         |
|    loss                     | inf         |
|    n_updates                | 12100       |
|    policy_gradient_loss     | inf         |
|    std                      | 0.0354      |
|    value_loss               | 2.03        |
---------------------------------------------
----------------------------------------------
| reward                      | [-3.5301454] |
| time/                       |              |
|    fps                      | 119          |
|    iterations               | 36           |
|    time_elapsed             | 615          |
|    total_timesteps          | 2482176      |
| train/                      |              |
|    approx_kl                | 23650.844    |
|    approx_ln(kl)            | 10.071154    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.86         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 12110        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0353       |
|    value_loss               | 1.92         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.879424] |
| time/                       |             |
|    fps                      | 120         |
|    iterations               | 37          |
|    time_elapsed             | 629         |
|    total_timesteps          | 2484224     |
| train/                      |             |
|    approx_kl                | 3418.0085   |
|    approx_ln(kl)            | 8.136813    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.85        |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 12120       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0354      |
|    value_loss               | 2.36        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.2693357] |
| time/                       |              |
|    fps                      | 120          |
|    iterations               | 38           |
|    time_elapsed             | 643          |
|    total_timesteps          | 2486272      |
| train/                      |              |
|    approx_kl                | 6668.016     |
|    approx_ln(kl)            | 8.805078     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.86         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 12130        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0352       |
|    value_loss               | 1.14         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.3055763] |
| time/                       |              |
|    fps                      | 106          |
|    iterations               | 39           |
|    time_elapsed             | 747          |
|    total_timesteps          | 2488320      |
| train/                      |              |
|    approx_kl                | 11837.568    |
|    approx_ln(kl)            | 9.379033     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.85         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 12140        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0354       |
|    value_loss               | 1.97         |
----------------------------------------------
--------------------------------------------
| reward                      | [-4.17095] |
| time/                       |            |
|    fps                      | 104        |
|    iterations               | 40         |
|    time_elapsed             | 783        |
|    total_timesteps          | 2490368    |
| train/                      |            |
|    approx_kl                | 17414.316  |
|    approx_ln(kl)            | 9.765048   |
|    clip_range               | 0.2        |
|    entropy_loss             | 3.9        |
|    explained_variance       | 0.997      |
|    learning_rate            | 0.001      |
|    ln(loss)                 | inf        |
|    ln(policy_gradient_loss) | inf        |
|    loss                     | inf        |
|    n_updates                | 12150      |
|    policy_gradient_loss     | inf        |
|    std                      | 0.0345     |
|    value_loss               | 3.4        |
--------------------------------------------
----------------------------------------------
| reward                      | [-0.7256658] |
| time/                       |              |
|    fps                      | 105          |
|    iterations               | 41           |
|    time_elapsed             | 797          |
|    total_timesteps          | 2492416      |
| train/                      |              |
|    approx_kl                | 8325.363     |
|    approx_ln(kl)            | 9.027062     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.9          |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 12160        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0345       |
|    value_loss               | 2.99         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.34439906] |
| time/                       |               |
|    fps                      | 105           |
|    iterations               | 42            |
|    time_elapsed             | 811           |
|    total_timesteps          | 2494464       |
| train/                      |               |
|    approx_kl                | 14813.613     |
|    approx_ln(kl)            | 9.603302      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.9           |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 12170         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0345        |
|    value_loss               | 1.88          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5085092] |
| time/                       |              |
|    fps                      | 106          |
|    iterations               | 43           |
|    time_elapsed             | 825          |
|    total_timesteps          | 2496512      |
| train/                      |              |
|    approx_kl                | 15584.353    |
|    approx_ln(kl)            | 9.654022     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.88         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 12180        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0348       |
|    value_loss               | 1.91         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.3096483] |
| time/                       |              |
|    fps                      | 107          |
|    iterations               | 44           |
|    time_elapsed             | 839          |
|    total_timesteps          | 2498560      |
| train/                      |              |
|    approx_kl                | 19708.389    |
|    approx_ln(kl)            | 9.8888       |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.91         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 12190        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0343       |
|    value_loss               | 2.12         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-1.883535] |
| time/                       |             |
|    fps                      | 107         |
|    iterations               | 45          |
|    time_elapsed             | 853         |
|    total_timesteps          | 2500608     |
| train/                      |             |
|    approx_kl                | 10492.723   |
|    approx_ln(kl)            | 9.258437    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.94        |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 12200       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0338      |
|    value_loss               | 1.56        |
---------------------------------------------
----------------------------------------------
| reward                      | [-3.1937659] |
| time/                       |              |
|    fps                      | 108          |
|    iterations               | 46           |
|    time_elapsed             | 867          |
|    total_timesteps          | 2502656      |
| train/                      |              |
|    approx_kl                | 7770.007     |
|    approx_ln(kl)            | 8.958026     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.95         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 12210        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0337       |
|    value_loss               | 1.67         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.6292882] |
| time/                       |              |
|    fps                      | 109          |
|    iterations               | 47           |
|    time_elapsed             | 880          |
|    total_timesteps          | 2504704      |
| train/                      |              |
|    approx_kl                | 2216.899     |
|    approx_ln(kl)            | 7.7038646    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.97         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 12220        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0333       |
|    value_loss               | 3.35         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.767967] |
| time/                       |             |
|    fps                      | 109         |
|    iterations               | 48          |
|    time_elapsed             | 895         |
|    total_timesteps          | 2506752     |
| train/                      |             |
|    approx_kl                | 8036.7607   |
|    approx_ln(kl)            | 8.991781    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.93        |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 12230       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0339      |
|    value_loss               | 1.24        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.3840919] |
| time/                       |              |
|    fps                      | 110          |
|    iterations               | 49           |
|    time_elapsed             | 909          |
|    total_timesteps          | 2508800      |
| train/                      |              |
|    approx_kl                | 6625.305     |
|    approx_ln(kl)            | 8.798652     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.98         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 12240        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0331       |
|    value_loss               | 1.69         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-------------------------------------
| reward             | [-3.6518135] |
| time/              |              |
|    fps             | 161          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 2510848      |
-------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.44166875] |
| time/                       |               |
|    fps                      | 154           |
|    iterations               | 2             |
|    time_elapsed             | 26            |
|    total_timesteps          | 2512896       |
| train/                      |               |
|    approx_kl                | 3240.089      |
|    approx_ln(kl)            | 8.083356      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.99          |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 12260         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0332        |
|    value_loss               | 1.55          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.67813915] |
| time/                       |               |
|    fps                      | 152           |
|    iterations               | 3             |
|    time_elapsed             | 40            |
|    total_timesteps          | 2514944       |
| train/                      |               |
|    approx_kl                | 5415.129      |
|    approx_ln(kl)            | 8.596952      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.99          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 12270         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.033         |
|    value_loss               | 1.31          |
-----------------------------------------------
----------------------------------------------
| reward                      | [-1.3842748] |
| time/                       |              |
|    fps                      | 56           |
|    iterations               | 4            |
|    time_elapsed             | 143          |
|    total_timesteps          | 2516992      |
| train/                      |              |
|    approx_kl                | 2481.2761    |
|    approx_ln(kl)            | 7.8165283    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.98         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 12280        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0332       |
|    value_loss               | 1.37         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.3130469] |
| time/                       |              |
|    fps                      | 41           |
|    iterations               | 5            |
|    time_elapsed             | 247          |
|    total_timesteps          | 2519040      |
| train/                      |              |
|    approx_kl                | 9027.589     |
|    approx_ln(kl)            | 9.108041     |
|    clip_range               | 0.2          |
|    entropy_loss             | 4            |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 12290        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0329       |
|    value_loss               | 1.13         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.3004079] |
| time/                       |              |
|    fps                      | 35           |
|    iterations               | 6            |
|    time_elapsed             | 350          |
|    total_timesteps          | 2521088      |
| train/                      |              |
|    approx_kl                | 16206.771    |
|    approx_ln(kl)            | 9.693185     |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.01         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 12300        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0326       |
|    value_loss               | 1.72         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.4821653] |
| time/                       |              |
|    fps                      | 39           |
|    iterations               | 7            |
|    time_elapsed             | 364          |
|    total_timesteps          | 2523136      |
| train/                      |              |
|    approx_kl                | 17241.87     |
|    approx_ln(kl)            | 9.755096     |
|    clip_range               | 0.2          |
|    entropy_loss             | 4            |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 12310        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0329       |
|    value_loss               | 1.07         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0425808] |
| time/                       |              |
|    fps                      | 43           |
|    iterations               | 8            |
|    time_elapsed             | 378          |
|    total_timesteps          | 2525184      |
| train/                      |              |
|    approx_kl                | 2845.0566    |
|    approx_ln(kl)            | 7.953338     |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.01         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 12320        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0326       |
|    value_loss               | 1.24         |
----------------------------------------------
-----------------------------------------------
| reward                      | [-0.98423964] |
| time/                       |               |
|    fps                      | 47            |
|    iterations               | 9             |
|    time_elapsed             | 392           |
|    total_timesteps          | 2527232       |
| train/                      |               |
|    approx_kl                | 22175.912     |
|    approx_ln(kl)            | 10.006762     |
|    clip_range               | 0.2           |
|    entropy_loss             | 4             |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 12330         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0329        |
|    value_loss               | 0.93          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7352483] |
| time/                       |              |
|    fps                      | 50           |
|    iterations               | 10           |
|    time_elapsed             | 405          |
|    total_timesteps          | 2529280      |
| train/                      |              |
|    approx_kl                | 6221.2476    |
|    approx_ln(kl)            | 8.735725     |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.01         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 12340        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0327       |
|    value_loss               | 0.888        |
----------------------------------------------
-----------------------------------------------
| reward                      | [-0.86095285] |
| time/                       |               |
|    fps                      | 53            |
|    iterations               | 11            |
|    time_elapsed             | 419           |
|    total_timesteps          | 2531328       |
| train/                      |               |
|    approx_kl                | 4878.137      |
|    approx_ln(kl)            | 8.492518      |
|    clip_range               | 0.2           |
|    entropy_loss             | 4             |
|    explained_variance       | 0.964         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 12350         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.033         |
|    value_loss               | 4.97          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.36799234] |
| time/                       |               |
|    fps                      | 56            |
|    iterations               | 12            |
|    time_elapsed             | 435           |
|    total_timesteps          | 2533376       |
| train/                      |               |
|    approx_kl                | 7383.9277     |
|    approx_ln(kl)            | 8.907061      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.96          |
|    explained_variance       | 0.988         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 12360         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0337        |
|    value_loss               | 3.47          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5850241] |
| time/                       |              |
|    fps                      | 58           |
|    iterations               | 13           |
|    time_elapsed             | 456          |
|    total_timesteps          | 2535424      |
| train/                      |              |
|    approx_kl                | 5477.109     |
|    approx_ln(kl)            | 8.608333     |
|    clip_range               | 0.2          |
|    entropy_loss             | 4            |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 12370        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0329       |
|    value_loss               | 1.34         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-0.515841] |
| time/                       |             |
|    fps                      | 60          |
|    iterations               | 14          |
|    time_elapsed             | 470         |
|    total_timesteps          | 2537472     |
| train/                      |             |
|    approx_kl                | 3377.5408   |
|    approx_ln(kl)            | 8.124903    |
|    clip_range               | 0.2         |
|    entropy_loss             | 4           |
|    explained_variance       | 0.991       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 12380       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0329      |
|    value_loss               | 4.9         |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.70090866] |
| time/                       |               |
|    fps                      | 63            |
|    iterations               | 15            |
|    time_elapsed             | 483           |
|    total_timesteps          | 2539520       |
| train/                      |               |
|    approx_kl                | 6334.4956     |
|    approx_ln(kl)            | 8.753765      |
|    clip_range               | 0.2           |
|    entropy_loss             | 4.01          |
|    explained_variance       | 0.995         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 12390         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0327        |
|    value_loss               | 2.37          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7630625] |
| time/                       |              |
|    fps                      | 65           |
|    iterations               | 16           |
|    time_elapsed             | 497          |
|    total_timesteps          | 2541568      |
| train/                      |              |
|    approx_kl                | 4772.933     |
|    approx_ln(kl)            | 8.470716     |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.02         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 12400        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0325       |
|    value_loss               | 5.99         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7518512] |
| time/                       |              |
|    fps                      | 68           |
|    iterations               | 17           |
|    time_elapsed             | 511          |
|    total_timesteps          | 2543616      |
| train/                      |              |
|    approx_kl                | 12412.118    |
|    approx_ln(kl)            | 9.426429     |
|    clip_range               | 0.2          |
|    entropy_loss             | 4            |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 12410        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0328       |
|    value_loss               | 3.68         |
----------------------------------------------
----------------------------------------------
| reward                      | [-2.4918084] |
| time/                       |              |
|    fps                      | 70           |
|    iterations               | 18           |
|    time_elapsed             | 525          |
|    total_timesteps          | 2545664      |
| train/                      |              |
|    approx_kl                | 18496.992    |
|    approx_ln(kl)            | 9.825363     |
|    clip_range               | 0.2          |
|    entropy_loss             | 4            |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 12420        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0327       |
|    value_loss               | 1.29         |
----------------------------------------------
-----------------------------------------------
| reward                      | [-0.64385355] |
| time/                       |               |
|    fps                      | 72            |
|    iterations               | 19            |
|    time_elapsed             | 538           |
|    total_timesteps          | 2547712       |
| train/                      |               |
|    approx_kl                | 15018.533     |
|    approx_ln(kl)            | 9.617041      |
|    clip_range               | 0.2           |
|    entropy_loss             | 4.01          |
|    explained_variance       | 0.996         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 12430         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0326        |
|    value_loss               | 0.943         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.4170103] |
| time/                       |              |
|    fps                      | 74           |
|    iterations               | 20           |
|    time_elapsed             | 552          |
|    total_timesteps          | 2549760      |
| train/                      |              |
|    approx_kl                | 5150.8535    |
|    approx_ln(kl)            | 8.546918     |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.03         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 12440        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0324       |
|    value_loss               | 5.65         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.95209694] |
| time/                       |               |
|    fps                      | 75            |
|    iterations               | 21            |
|    time_elapsed             | 566           |
|    total_timesteps          | 2551808       |
| train/                      |               |
|    approx_kl                | 14950.418     |
|    approx_ln(kl)            | 9.612494      |
|    clip_range               | 0.2           |
|    entropy_loss             | 4.07          |
|    explained_variance       | 0.997         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 12450         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0317        |
|    value_loss               | 6.34          |
-----------------------------------------------
----------------------------------------------
| reward                      | [-0.8058791] |
| time/                       |              |
|    fps                      | 77           |
|    iterations               | 22           |
|    time_elapsed             | 580          |
|    total_timesteps          | 2553856      |
| train/                      |              |
|    approx_kl                | 16851.266    |
|    approx_ln(kl)            | 9.732181     |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.06         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 12460        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0318       |
|    value_loss               | 3.87         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.37561053] |
| time/                       |               |
|    fps                      | 79            |
|    iterations               | 23            |
|    time_elapsed             | 593           |
|    total_timesteps          | 2555904       |
| train/                      |               |
|    approx_kl                | 44563.89      |
|    approx_ln(kl)            | 10.7046795    |
|    clip_range               | 0.2           |
|    entropy_loss             | 4.09          |
|    explained_variance       | 0.987         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 12470         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0314        |
|    value_loss               | 2.15          |
-----------------------------------------------
----------------------------------------------
| reward                      | [-0.4735712] |
| time/                       |              |
|    fps                      | 80           |
|    iterations               | 24           |
|    time_elapsed             | 607          |
|    total_timesteps          | 2557952      |
| train/                      |              |
|    approx_kl                | 77842.195    |
|    approx_ln(kl)            | 11.262439    |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.1          |
|    explained_variance       | 0.988        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 12480        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0313       |
|    value_loss               | 1.9          |
----------------------------------------------
-----------------------------------------------
| reward                      | [-0.62092835] |
| time/                       |               |
|    fps                      | 82            |
|    iterations               | 25            |
|    time_elapsed             | 621           |
|    total_timesteps          | 2560000       |
| train/                      |               |
|    approx_kl                | 88048.06      |
|    approx_ln(kl)            | 11.385638     |
|    clip_range               | 0.2           |
|    entropy_loss             | 4.1           |
|    explained_variance       | 0.985         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 12490         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0313        |
|    value_loss               | 2.88          |
-----------------------------------------------
-----------------------------------------------
| reward                      | [-0.89669174] |
| time/                       |               |
|    fps                      | 83            |
|    iterations               | 26            |
|    time_elapsed             | 635           |
|    total_timesteps          | 2562048       |
| train/                      |               |
|    approx_kl                | 50396.996     |
|    approx_ln(kl)            | 10.827687     |
|    clip_range               | 0.2           |
|    entropy_loss             | 4.1           |
|    explained_variance       | 0.964         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 12500         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0312        |
|    value_loss               | 2.55          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6652596] |
| time/                       |              |
|    fps                      | 85           |
|    iterations               | 27           |
|    time_elapsed             | 649          |
|    total_timesteps          | 2564096      |
| train/                      |              |
|    approx_kl                | 74010.02     |
|    approx_ln(kl)            | 11.211956    |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.12         |
|    explained_variance       | 0.984        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 12510        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0309       |
|    value_loss               | 1.32         |
----------------------------------------------
----------------------------------------------
| reward                      | [-0.9024386] |
| time/                       |              |
|    fps                      | 86           |
|    iterations               | 28           |
|    time_elapsed             | 663          |
|    total_timesteps          | 2566144      |
| train/                      |              |
|    approx_kl                | 5845.6846    |
|    approx_ln(kl)            | 8.673459     |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.08         |
|    explained_variance       | 0.99         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 12520        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0315       |
|    value_loss               | 1.12         |
----------------------------------------------
----------------------------------------------
| reward                      | [-0.8979986] |
| time/                       |              |
|    fps                      | 87           |
|    iterations               | 29           |
|    time_elapsed             | 676          |
|    total_timesteps          | 2568192      |
| train/                      |              |
|    approx_kl                | 19119.412    |
|    approx_ln(kl)            | 9.858459     |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.06         |
|    explained_variance       | 0.963        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 12530        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0318       |
|    value_loss               | 1.1          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.68259484] |
| time/                       |               |
|    fps                      | 88            |
|    iterations               | 30            |
|    time_elapsed             | 690           |
|    total_timesteps          | 2570240       |
| train/                      |               |
|    approx_kl                | 128744.17     |
|    approx_ln(kl)            | 11.765583     |
|    clip_range               | 0.2           |
|    entropy_loss             | 4.05          |
|    explained_variance       | 0.961         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 12540         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.032         |
|    value_loss               | 0.776         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.87743545] |
| time/                       |               |
|    fps                      | 90            |
|    iterations               | 31            |
|    time_elapsed             | 704           |
|    total_timesteps          | 2572288       |
| train/                      |               |
|    approx_kl                | 54001.18      |
|    approx_ln(kl)            | 10.896761     |
|    clip_range               | 0.2           |
|    entropy_loss             | 4.06          |
|    explained_variance       | 0.993         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 12550         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0319        |
|    value_loss               | 2.21          |
-----------------------------------------------
-----------------------------------------------
| reward                      | [-0.87975055] |
| time/                       |               |
|    fps                      | 91            |
|    iterations               | 32            |
|    time_elapsed             | 718           |
|    total_timesteps          | 2574336       |
| train/                      |               |
|    approx_kl                | 8013.393      |
|    approx_ln(kl)            | 8.98887       |
|    clip_range               | 0.2           |
|    entropy_loss             | 4.04          |
|    explained_variance       | 0.99          |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 12560         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0321        |
|    value_loss               | 2.97          |
-----------------------------------------------
-----------------------------------------------
| reward                      | [-0.50125253] |
| time/                       |               |
|    fps                      | 92            |
|    iterations               | 33            |
|    time_elapsed             | 732           |
|    total_timesteps          | 2576384       |
| train/                      |               |
|    approx_kl                | 1360.3612     |
|    approx_ln(kl)            | 7.2155056     |
|    clip_range               | 0.2           |
|    entropy_loss             | 4.04          |
|    explained_variance       | 0.993         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 12570         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0322        |
|    value_loss               | 2.7           |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.87436736] |
| time/                       |               |
|    fps                      | 93            |
|    iterations               | 34            |
|    time_elapsed             | 746           |
|    total_timesteps          | 2578432       |
| train/                      |               |
|    approx_kl                | 6503.4443     |
|    approx_ln(kl)            | 8.780087      |
|    clip_range               | 0.2           |
|    entropy_loss             | 4.05          |
|    explained_variance       | 0.992         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 12580         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0319        |
|    value_loss               | 3.37          |
-----------------------------------------------
-----------------------------------------------
| reward                      | [-0.45312658] |
| time/                       |               |
|    fps                      | 94            |
|    iterations               | 35            |
|    time_elapsed             | 762           |
|    total_timesteps          | 2580480       |
| train/                      |               |
|    approx_kl                | 6303.0254     |
|    approx_ln(kl)            | 8.748785      |
|    clip_range               | 0.2           |
|    entropy_loss             | 4.03          |
|    explained_variance       | 0.996         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 12590         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0323        |
|    value_loss               | 1.22          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5702115] |
| time/                       |              |
|    fps                      | 93           |
|    iterations               | 36           |
|    time_elapsed             | 790          |
|    total_timesteps          | 2582528      |
| train/                      |              |
|    approx_kl                | 27286.781    |
|    approx_ln(kl)            | 10.214158    |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.03         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 12600        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0323       |
|    value_loss               | 0.766        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.1415045] |
| time/                       |              |
|    fps                      | 93           |
|    iterations               | 37           |
|    time_elapsed             | 807          |
|    total_timesteps          | 2584576      |
| train/                      |              |
|    approx_kl                | 8055.1265    |
|    approx_ln(kl)            | 8.994064     |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.03         |
|    explained_variance       | 0.888        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 12610        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0323       |
|    value_loss               | 1.64         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.47412434] |
| time/                       |               |
|    fps                      | 94            |
|    iterations               | 38            |
|    time_elapsed             | 823           |
|    total_timesteps          | 2586624       |
| train/                      |               |
|    approx_kl                | 6702.5635     |
|    approx_ln(kl)            | 8.8102455     |
|    clip_range               | 0.2           |
|    entropy_loss             | 4             |
|    explained_variance       | 0.995         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 12620         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0328        |
|    value_loss               | 3.18          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7861454] |
| time/                       |              |
|    fps                      | 95           |
|    iterations               | 39           |
|    time_elapsed             | 839          |
|    total_timesteps          | 2588672      |
| train/                      |              |
|    approx_kl                | 21027.422    |
|    approx_ln(kl)            | 9.953583     |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.02         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 12630        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0325       |
|    value_loss               | 2.62         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4900693] |
| time/                       |              |
|    fps                      | 95           |
|    iterations               | 40           |
|    time_elapsed             | 856          |
|    total_timesteps          | 2590720      |
| train/                      |              |
|    approx_kl                | 9468.956     |
|    approx_ln(kl)            | 9.155774     |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.02         |
|    explained_variance       | 0.891        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 12640        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0326       |
|    value_loss               | 1.01         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7334808] |
| time/                       |              |
|    fps                      | 96           |
|    iterations               | 41           |
|    time_elapsed             | 873          |
|    total_timesteps          | 2592768      |
| train/                      |              |
|    approx_kl                | 40120.13     |
|    approx_ln(kl)            | 10.599633    |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.01         |
|    explained_variance       | 0.967        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 12650        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0326       |
|    value_loss               | 0.486        |
----------------------------------------------
-----------------------------------------------
| reward                      | [-0.83046633] |
| time/                       |               |
|    fps                      | 96            |
|    iterations               | 42            |
|    time_elapsed             | 889           |
|    total_timesteps          | 2594816       |
| train/                      |               |
|    approx_kl                | 32801.465     |
|    approx_ln(kl)            | 10.398229     |
|    clip_range               | 0.2           |
|    entropy_loss             | 4.04          |
|    explained_variance       | 0.992         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 12660         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0322        |
|    value_loss               | 0.235         |
-----------------------------------------------
-----------------------------------------------
| reward                      | [-0.60198164] |
| time/                       |               |
|    fps                      | 97            |
|    iterations               | 43            |
|    time_elapsed             | 906           |
|    total_timesteps          | 2596864       |
| train/                      |               |
|    approx_kl                | 7459.2256     |
|    approx_ln(kl)            | 8.917207      |
|    clip_range               | 0.2           |
|    entropy_loss             | 4.03          |
|    explained_variance       | 0.964         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 12670         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0324        |
|    value_loss               | 4.88          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4313774] |
| time/                       |              |
|    fps                      | 97           |
|    iterations               | 44           |
|    time_elapsed             | 923          |
|    total_timesteps          | 2598912      |
| train/                      |              |
|    approx_kl                | 47078.848    |
|    approx_ln(kl)            | 10.759579    |
|    clip_range               | 0.2          |
|    entropy_loss             | 4.01         |
|    explained_variance       | 0.956        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 12680        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0327       |
|    value_loss               | 2.28         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.39152867] |
| time/                       |               |
|    fps                      | 98            |
|    iterations               | 45            |
|    time_elapsed             | 939           |
|    total_timesteps          | 2600960       |
| train/                      |               |
|    approx_kl                | 12247.781     |
|    approx_ln(kl)            | 9.4131        |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.99          |
|    explained_variance       | 0.991         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 12690         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.033         |
|    value_loss               | 1.71          |
-----------------------------------------------
----------------------------------------------
| reward                      | [-0.7167636] |
| time/                       |              |
|    fps                      | 98           |
|    iterations               | 46           |
|    time_elapsed             | 955          |
|    total_timesteps          | 2603008      |
| train/                      |              |
|    approx_kl                | 42114.695    |
|    approx_ln(kl)            | 10.648152    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.98         |
|    explained_variance       | 0.984        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 12700        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0332       |
|    value_loss               | 0.948        |
----------------------------------------------
-----------------------------------------------
| reward                      | [-0.48851326] |
| time/                       |               |
|    fps                      | 99            |
|    iterations               | 47            |
|    time_elapsed             | 971           |
|    total_timesteps          | 2605056       |
| train/                      |               |
|    approx_kl                | 22249.916     |
|    approx_ln(kl)            | 10.010094     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.95          |
|    explained_variance       | 0.99          |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 12710         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0336        |
|    value_loss               | 0.456         |
-----------------------------------------------
-----------------------------------------------
| reward                      | [-0.60942733] |
| time/                       |               |
|    fps                      | 99            |
|    iterations               | 48            |
|    time_elapsed             | 987           |
|    total_timesteps          | 2607104       |
| train/                      |               |
|    approx_kl                | 88922.13      |
|    approx_ln(kl)            | 11.395516     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.96          |
|    explained_variance       | 0.997         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 12720         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0336        |
|    value_loss               | 0.306         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7198185] |
| time/                       |              |
|    fps                      | 99           |
|    iterations               | 49           |
|    time_elapsed             | 1004         |
|    total_timesteps          | 2609152      |
| train/                      |              |
|    approx_kl                | 7707.6475    |
|    approx_ln(kl)            | 8.949968     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.95         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 12730        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0338       |
|    value_loss               | 0.277        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
--------------------------------------
| reward             | [-0.44436976] |
| time/              |               |
|    fps             | 141           |
|    iterations      | 1             |
|    time_elapsed    | 14            |
|    total_timesteps | 2611200       |
--------------------------------------
-----------------------------------------------
| reward                      | [-0.42572963] |
| time/                       |               |
|    fps                      | 132           |
|    iterations               | 2             |
|    time_elapsed             | 30            |
|    total_timesteps          | 2613248       |
| train/                      |               |
|    approx_kl                | 11402.127     |
|    approx_ln(kl)            | 9.341556      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.98          |
|    explained_variance       | 0.99          |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 12750         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0333        |
|    value_loss               | 2.21          |
-----------------------------------------------
----------------------------------------------
| reward                      | [-0.5999422] |
| time/                       |              |
|    fps                      | 137          |
|    iterations               | 3            |
|    time_elapsed             | 44           |
|    total_timesteps          | 2615296      |
| train/                      |              |
|    approx_kl                | 27854.312    |
|    approx_ln(kl)            | 10.234743    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.98         |
|    explained_variance       | 0.971        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 12760        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0332       |
|    value_loss               | 2.91         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7840156] |
| time/                       |              |
|    fps                      | 140          |
|    iterations               | 4            |
|    time_elapsed             | 58           |
|    total_timesteps          | 2617344      |
| train/                      |              |
|    approx_kl                | 123535.39    |
|    approx_ln(kl)            | 11.724283    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.99         |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 12770        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0331       |
|    value_loss               | 0.263        |
----------------------------------------------
----------------------------------------------
| reward                      | [-0.3766716] |
| time/                       |              |
|    fps                      | 141          |
|    iterations               | 5            |
|    time_elapsed             | 72           |
|    total_timesteps          | 2619392      |
| train/                      |              |
|    approx_kl                | 11068.129    |
|    approx_ln(kl)            | 9.311825     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.98         |
|    explained_variance       | 0.953        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 12780        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0333       |
|    value_loss               | 1.96         |
----------------------------------------------
-----------------------------------------------
| reward                      | [-0.52518463] |
| time/                       |               |
|    fps                      | 141           |
|    iterations               | 6             |
|    time_elapsed             | 86            |
|    total_timesteps          | 2621440       |
| train/                      |               |
|    approx_kl                | 26024.926     |
|    approx_ln(kl)            | 10.16681      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.98          |
|    explained_variance       | 0.984         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 12790         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0333        |
|    value_loss               | 6.89          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.40427172] |
| time/                       |               |
|    fps                      | 142           |
|    iterations               | 7             |
|    time_elapsed             | 100           |
|    total_timesteps          | 2623488       |
| train/                      |               |
|    approx_kl                | 18651.262     |
|    approx_ln(kl)            | 9.833669      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.96          |
|    explained_variance       | 0.989         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 12800         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0337        |
|    value_loss               | 0.365         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.53401554] |
| time/                       |               |
|    fps                      | 143           |
|    iterations               | 8             |
|    time_elapsed             | 114           |
|    total_timesteps          | 2625536       |
| train/                      |               |
|    approx_kl                | 13103.207     |
|    approx_ln(kl)            | 9.480613      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.95          |
|    explained_variance       | 0.983         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 12810         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.034         |
|    value_loss               | 0.488         |
-----------------------------------------------
-----------------------------------------------
| reward                      | [-0.72929555] |
| time/                       |               |
|    fps                      | 143           |
|    iterations               | 9             |
|    time_elapsed             | 128           |
|    total_timesteps          | 2627584       |
| train/                      |               |
|    approx_kl                | 60764.094     |
|    approx_ln(kl)            | 11.014754     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.98          |
|    explained_variance       | 0.996         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 12820         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0334        |
|    value_loss               | 3.42          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7272437] |
| time/                       |              |
|    fps                      | 144          |
|    iterations               | 10           |
|    time_elapsed             | 142          |
|    total_timesteps          | 2629632      |
| train/                      |              |
|    approx_kl                | 41291.72     |
|    approx_ln(kl)            | 10.628417    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.99         |
|    explained_variance       | 0.985        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 12830        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0333       |
|    value_loss               | 0.379        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5779044] |
| time/                       |              |
|    fps                      | 144          |
|    iterations               | 11           |
|    time_elapsed             | 156          |
|    total_timesteps          | 2631680      |
| train/                      |              |
|    approx_kl                | 54963.39     |
|    approx_ln(kl)            | 10.914423    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.98         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 12840        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0335       |
|    value_loss               | 0.248        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.53486466] |
| time/                       |               |
|    fps                      | 144           |
|    iterations               | 12            |
|    time_elapsed             | 170           |
|    total_timesteps          | 2633728       |
| train/                      |               |
|    approx_kl                | 7187.677      |
|    approx_ln(kl)            | 8.880123      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.98          |
|    explained_variance       | 0.983         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 12850         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0335        |
|    value_loss               | 2.84          |
-----------------------------------------------
-----------------------------------------------
| reward                      | [-0.73449284] |
| time/                       |               |
|    fps                      | 144           |
|    iterations               | 13            |
|    time_elapsed             | 183           |
|    total_timesteps          | 2635776       |
| train/                      |               |
|    approx_kl                | 23679.473     |
|    approx_ln(kl)            | 10.072364     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.99          |
|    explained_variance       | 0.995         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 12860         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0333        |
|    value_loss               | 0.238         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5294727] |
| time/                       |              |
|    fps                      | 143          |
|    iterations               | 14           |
|    time_elapsed             | 199          |
|    total_timesteps          | 2637824      |
| train/                      |              |
|    approx_kl                | 3224.6372    |
|    approx_ln(kl)            | 8.078576     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.96         |
|    explained_variance       | 0.984        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 12870        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0338       |
|    value_loss               | 2.3          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.54932815] |
| time/                       |               |
|    fps                      | 113           |
|    iterations               | 15            |
|    time_elapsed             | 270           |
|    total_timesteps          | 2639872       |
| train/                      |               |
|    approx_kl                | 26474.514     |
|    approx_ln(kl)            | 10.183938     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.91          |
|    explained_variance       | 0.991         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 12880         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0346        |
|    value_loss               | 7.94          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.57259953] |
| time/                       |               |
|    fps                      | 115           |
|    iterations               | 16            |
|    time_elapsed             | 284           |
|    total_timesteps          | 2641920       |
| train/                      |               |
|    approx_kl                | 32219.39      |
|    approx_ln(kl)            | 10.380323     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.91          |
|    explained_variance       | 0.987         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 12890         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0346        |
|    value_loss               | 1.58          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.54820067] |
| time/                       |               |
|    fps                      | 116           |
|    iterations               | 17            |
|    time_elapsed             | 297           |
|    total_timesteps          | 2643968       |
| train/                      |               |
|    approx_kl                | 10175.715     |
|    approx_ln(kl)            | 9.227759      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.92          |
|    explained_variance       | 0.983         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 12900         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0344        |
|    value_loss               | 2.03          |
-----------------------------------------------
----------------------------------------------
| reward                      | [-0.5567663] |
| time/                       |              |
|    fps                      | 118          |
|    iterations               | 18           |
|    time_elapsed             | 312          |
|    total_timesteps          | 2646016      |
| train/                      |              |
|    approx_kl                | 28462.346    |
|    approx_ln(kl)            | 10.256337    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.89         |
|    explained_variance       | 0.969        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 12910        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0349       |
|    value_loss               | 0.289        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.67860633] |
| time/                       |               |
|    fps                      | 119           |
|    iterations               | 19            |
|    time_elapsed             | 326           |
|    total_timesteps          | 2648064       |
| train/                      |               |
|    approx_kl                | 33409.92      |
|    approx_ln(kl)            | 10.416608     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.9           |
|    explained_variance       | 0.986         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 12920         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0348        |
|    value_loss               | 0.866         |
-----------------------------------------------
----------------------------------------------
| reward                      | [-0.5960695] |
| time/                       |              |
|    fps                      | 120          |
|    iterations               | 20           |
|    time_elapsed             | 340          |
|    total_timesteps          | 2650112      |
| train/                      |              |
|    approx_kl                | 24607.723    |
|    approx_ln(kl)            | 10.110816    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.87         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 12930        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0354       |
|    value_loss               | 0.21         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.70640105] |
| time/                       |               |
|    fps                      | 121           |
|    iterations               | 21            |
|    time_elapsed             | 355           |
|    total_timesteps          | 2652160       |
| train/                      |               |
|    approx_kl                | 26914.5       |
|    approx_ln(kl)            | 10.20042      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.87          |
|    explained_variance       | 0.994         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 12940         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0354        |
|    value_loss               | 0.26          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7067555] |
| time/                       |              |
|    fps                      | 121          |
|    iterations               | 22           |
|    time_elapsed             | 369          |
|    total_timesteps          | 2654208      |
| train/                      |              |
|    approx_kl                | 38158.6      |
|    approx_ln(kl)            | 10.549506    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.86         |
|    explained_variance       | 0.982        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 12950        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0356       |
|    value_loss               | 0.311        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7317522] |
| time/                       |              |
|    fps                      | 122          |
|    iterations               | 23           |
|    time_elapsed             | 383          |
|    total_timesteps          | 2656256      |
| train/                      |              |
|    approx_kl                | 38768.93     |
|    approx_ln(kl)            | 10.565374    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.83         |
|    explained_variance       | 0.992        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 12960        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0361       |
|    value_loss               | 0.123        |
----------------------------------------------
----------------------------------------------
| reward                      | [-1.9901525] |
| time/                       |              |
|    fps                      | 123          |
|    iterations               | 24           |
|    time_elapsed             | 398          |
|    total_timesteps          | 2658304      |
| train/                      |              |
|    approx_kl                | 7684.0864    |
|    approx_ln(kl)            | 8.946907     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.79         |
|    explained_variance       | 0.974        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 12970        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0368       |
|    value_loss               | 5.52         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
--------------------------------------------
| reward                      | [-0.96385] |
| time/                       |            |
|    fps                      | 124        |
|    iterations               | 25         |
|    time_elapsed             | 412        |
|    total_timesteps          | 2660352    |
| train/                      |            |
|    approx_kl                | 7980.7656  |
|    approx_ln(kl)            | 8.98479    |
|    clip_range               | 0.2        |
|    entropy_loss             | 3.78       |
|    explained_variance       | 0.984      |
|    learning_rate            | 0.001      |
|    ln(loss)                 | inf        |
|    ln(policy_gradient_loss) | nan        |
|    loss                     | inf        |
|    n_updates                | 12980      |
|    policy_gradient_loss     | nan        |
|    std                      | 0.037      |
|    value_loss               | 10.6       |
--------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.27773762] |
| time/                       |               |
|    fps                      | 124           |
|    iterations               | 26            |
|    time_elapsed             | 426           |
|    total_timesteps          | 2662400       |
| train/                      |               |
|    approx_kl                | 11345.742     |
|    approx_ln(kl)            | 9.336597      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.79          |
|    explained_variance       | 0.982         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 12990         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0366        |
|    value_loss               | 4.23          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5301906] |
| time/                       |              |
|    fps                      | 125          |
|    iterations               | 27           |
|    time_elapsed             | 440          |
|    total_timesteps          | 2664448      |
| train/                      |              |
|    approx_kl                | 3051.4102    |
|    approx_ln(kl)            | 8.023359     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.8          |
|    explained_variance       | 0.981        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13000        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0366       |
|    value_loss               | 5.94         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.58561826] |
| time/                       |               |
|    fps                      | 105           |
|    iterations               | 28            |
|    time_elapsed             | 543           |
|    total_timesteps          | 2666496       |
| train/                      |               |
|    approx_kl                | 20569.863     |
|    approx_ln(kl)            | 9.931582      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.84          |
|    explained_variance       | 0.97          |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 13010         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0356        |
|    value_loss               | 8.3           |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6195198] |
| time/                       |              |
|    fps                      | 91           |
|    iterations               | 29           |
|    time_elapsed             | 647          |
|    total_timesteps          | 2668544      |
| train/                      |              |
|    approx_kl                | 107391.64    |
|    approx_ln(kl)            | 11.584238    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.85         |
|    explained_variance       | 0.985        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13020        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0356       |
|    value_loss               | 8.94         |
----------------------------------------------
----------------------------------------------
| reward                      | [-1.7642349] |
| time/                       |              |
|    fps                      | 81           |
|    iterations               | 30           |
|    time_elapsed             | 750          |
|    total_timesteps          | 2670592      |
| train/                      |              |
|    approx_kl                | 11611.037    |
|    approx_ln(kl)            | 9.359712     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.86         |
|    explained_variance       | 0.95         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 13030        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0356       |
|    value_loss               | 13.6         |
----------------------------------------------
----------------------------------------------
| reward                      | [-0.8839406] |
| time/                       |              |
|    fps                      | 74           |
|    iterations               | 31           |
|    time_elapsed             | 853          |
|    total_timesteps          | 2672640      |
| train/                      |              |
|    approx_kl                | 5032.077     |
|    approx_ln(kl)            | 8.523588     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.85         |
|    explained_variance       | 0.971        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 13040        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0357       |
|    value_loss               | 20.1         |
----------------------------------------------
----------------------------------------------
| reward                      | [-0.5659206] |
| time/                       |              |
|    fps                      | 68           |
|    iterations               | 32           |
|    time_elapsed             | 955          |
|    total_timesteps          | 2674688      |
| train/                      |              |
|    approx_kl                | 18305.535    |
|    approx_ln(kl)            | 9.814959     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.86         |
|    explained_variance       | 0.981        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 13050        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0356       |
|    value_loss               | 11.5         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5892991] |
| time/                       |              |
|    fps                      | 63           |
|    iterations               | 33           |
|    time_elapsed             | 1070         |
|    total_timesteps          | 2676736      |
| train/                      |              |
|    approx_kl                | 10076.965    |
|    approx_ln(kl)            | 9.218007     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.86         |
|    explained_variance       | 0.979        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13060        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0355       |
|    value_loss               | 3.17         |
----------------------------------------------
-----------------------------------------------
| reward                      | [-0.24733874] |
| time/                       |               |
|    fps                      | 58            |
|    iterations               | 34            |
|    time_elapsed             | 1181          |
|    total_timesteps          | 2678784       |
| train/                      |               |
|    approx_kl                | 4508.878      |
|    approx_ln(kl)            | 8.413804      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.85          |
|    explained_variance       | 0.991         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 13070         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0356        |
|    value_loss               | 4.93          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.9796193] |
| time/                       |              |
|    fps                      | 55           |
|    iterations               | 35           |
|    time_elapsed             | 1284         |
|    total_timesteps          | 2680832      |
| train/                      |              |
|    approx_kl                | 45379.996    |
|    approx_ln(kl)            | 10.722827    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.85         |
|    explained_variance       | 0.988        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13080        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0357       |
|    value_loss               | 6.93         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5447395] |
| time/                       |              |
|    fps                      | 52           |
|    iterations               | 36           |
|    time_elapsed             | 1396         |
|    total_timesteps          | 2682880      |
| train/                      |              |
|    approx_kl                | 8225.146     |
|    approx_ln(kl)            | 9.014952     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.83         |
|    explained_variance       | 0.973        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13090        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.036        |
|    value_loss               | 9.33         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.4715321] |
| time/                       |              |
|    fps                      | 53           |
|    iterations               | 37           |
|    time_elapsed             | 1410         |
|    total_timesteps          | 2684928      |
| train/                      |              |
|    approx_kl                | 88765.016    |
|    approx_ln(kl)            | 11.393748    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.85         |
|    explained_variance       | 0.981        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13100        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0356       |
|    value_loss               | 2.35         |
----------------------------------------------
----------------------------------------------
| reward                      | [-0.6532396] |
| time/                       |              |
|    fps                      | 54           |
|    iterations               | 38           |
|    time_elapsed             | 1423         |
|    total_timesteps          | 2686976      |
| train/                      |              |
|    approx_kl                | 5527.9976    |
|    approx_ln(kl)            | 8.617581     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.88         |
|    explained_variance       | 0.97         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 13110        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0352       |
|    value_loss               | 13.2         |
----------------------------------------------
----------------------------------------------
| reward                      | [-0.7623593] |
| time/                       |              |
|    fps                      | 55           |
|    iterations               | 39           |
|    time_elapsed             | 1437         |
|    total_timesteps          | 2689024      |
| train/                      |              |
|    approx_kl                | 11014.739    |
|    approx_ln(kl)            | 9.30699      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.87         |
|    explained_variance       | 0.984        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 13120        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0352       |
|    value_loss               | 2.74         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5979906] |
| time/                       |              |
|    fps                      | 56           |
|    iterations               | 40           |
|    time_elapsed             | 1451         |
|    total_timesteps          | 2691072      |
| train/                      |              |
|    approx_kl                | 14549.676    |
|    approx_ln(kl)            | 9.585324     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.9          |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13130        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0347       |
|    value_loss               | 2.62         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.84648097] |
| time/                       |               |
|    fps                      | 57            |
|    iterations               | 41            |
|    time_elapsed             | 1465          |
|    total_timesteps          | 2693120       |
| train/                      |               |
|    approx_kl                | 5825.3984     |
|    approx_ln(kl)            | 8.669983      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.91          |
|    explained_variance       | 0.973         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 13140         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0346        |
|    value_loss               | 11.4          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.99484193] |
| time/                       |               |
|    fps                      | 58            |
|    iterations               | 42            |
|    time_elapsed             | 1478          |
|    total_timesteps          | 2695168       |
| train/                      |               |
|    approx_kl                | 18341.984     |
|    approx_ln(kl)            | 9.816948      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.89          |
|    explained_variance       | 0.992         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 13150         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.035         |
|    value_loss               | 1.94          |
-----------------------------------------------
-----------------------------------------------
| reward                      | [-0.94496435] |
| time/                       |               |
|    fps                      | 58            |
|    iterations               | 43            |
|    time_elapsed             | 1492          |
|    total_timesteps          | 2697216       |
| train/                      |               |
|    approx_kl                | 10691.988     |
|    approx_ln(kl)            | 9.27725       |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.9           |
|    explained_variance       | 0.994         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 13160         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0346        |
|    value_loss               | 1.62          |
-----------------------------------------------
----------------------------------------------
| reward                      | [-0.9136369] |
| time/                       |              |
|    fps                      | 59           |
|    iterations               | 44           |
|    time_elapsed             | 1506         |
|    total_timesteps          | 2699264      |
| train/                      |              |
|    approx_kl                | 23891.088    |
|    approx_ln(kl)            | 10.081261    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.84         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 13170        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0358       |
|    value_loss               | 4.53         |
----------------------------------------------
----------------------------------------------
| reward                      | [-0.9518089] |
| time/                       |              |
|    fps                      | 60           |
|    iterations               | 45           |
|    time_elapsed             | 1520         |
|    total_timesteps          | 2701312      |
| train/                      |              |
|    approx_kl                | 11198.08     |
|    approx_ln(kl)            | 9.323498     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.83         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 13180        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0361       |
|    value_loss               | 4.93         |
----------------------------------------------
-----------------------------------------------
| reward                      | [-0.83524245] |
| time/                       |               |
|    fps                      | 61            |
|    iterations               | 46            |
|    time_elapsed             | 1534          |
|    total_timesteps          | 2703360       |
| train/                      |               |
|    approx_kl                | 6043.7607     |
|    approx_ln(kl)            | 8.706781      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.83          |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 13190         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0361        |
|    value_loss               | 0.961         |
-----------------------------------------------
-----------------------------------------------
| reward                      | [-0.23909813] |
| time/                       |               |
|    fps                      | 62            |
|    iterations               | 47            |
|    time_elapsed             | 1548          |
|    total_timesteps          | 2705408       |
| train/                      |               |
|    approx_kl                | 30882.277     |
|    approx_ln(kl)            | 10.337937     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.82          |
|    explained_variance       | 0.99          |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 13200         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0362        |
|    value_loss               | 1.79          |
-----------------------------------------------
----------------------------------------------
| reward                      | [-1.4011328] |
| time/                       |              |
|    fps                      | 62           |
|    iterations               | 48           |
|    time_elapsed             | 1562         |
|    total_timesteps          | 2707456      |
| train/                      |              |
|    approx_kl                | 16143.002    |
|    approx_ln(kl)            | 9.689242     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.84         |
|    explained_variance       | 0.991        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 13210        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0357       |
|    value_loss               | 2.08         |
----------------------------------------------
----------------------------------------------
| reward                      | [-1.1326302] |
| time/                       |              |
|    fps                      | 63           |
|    iterations               | 49           |
|    time_elapsed             | 1576         |
|    total_timesteps          | 2709504      |
| train/                      |              |
|    approx_kl                | 31103.322    |
|    approx_ln(kl)            | 10.34507     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.83         |
|    explained_variance       | 0.984        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 13220        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0359       |
|    value_loss               | 2.45         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-------------------------------------
| reward             | [-1.1528671] |
| time/              |              |
|    fps             | 162          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 2711552      |
-------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.8912792] |
| time/                       |              |
|    fps                      | 152          |
|    iterations               | 2            |
|    time_elapsed             | 26           |
|    total_timesteps          | 2713600      |
| train/                      |              |
|    approx_kl                | 47732.227    |
|    approx_ln(kl)            | 10.773362    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.9          |
|    explained_variance       | 0.992        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13240        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0347       |
|    value_loss               | 0.633        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0169641] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 3            |
|    time_elapsed             | 41           |
|    total_timesteps          | 2715648      |
| train/                      |              |
|    approx_kl                | 22189.246    |
|    approx_ln(kl)            | 10.007363    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.88         |
|    explained_variance       | 0.984        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13250        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.035        |
|    value_loss               | 0.868        |
----------------------------------------------
----------------------------------------------
| reward                      | [-0.9734193] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 4            |
|    time_elapsed             | 54           |
|    total_timesteps          | 2717696      |
| train/                      |              |
|    approx_kl                | 25822.484    |
|    approx_ln(kl)            | 10.159001    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.88         |
|    explained_variance       | 0.985        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 13260        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.035        |
|    value_loss               | 0.783        |
----------------------------------------------
-----------------------------------------------
| reward                      | [-0.77538246] |
| time/                       |               |
|    fps                      | 149           |
|    iterations               | 5             |
|    time_elapsed             | 68            |
|    total_timesteps          | 2719744       |
| train/                      |               |
|    approx_kl                | 4813.442      |
|    approx_ln(kl)            | 8.479168      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.89          |
|    explained_variance       | 0.984         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 13270         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0348        |
|    value_loss               | 0.927         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6554173] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 6            |
|    time_elapsed             | 82           |
|    total_timesteps          | 2721792      |
| train/                      |              |
|    approx_kl                | 3054.5295    |
|    approx_ln(kl)            | 8.024381     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.88         |
|    explained_variance       | 0.985        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13280        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0349       |
|    value_loss               | 5.54         |
----------------------------------------------
----------------------------------------------
| reward                      | [-1.8424513] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 7            |
|    time_elapsed             | 95           |
|    total_timesteps          | 2723840      |
| train/                      |              |
|    approx_kl                | 13821.061    |
|    approx_ln(kl)            | 9.533949     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.87         |
|    explained_variance       | 0.985        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 13290        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.035        |
|    value_loss               | 4.91         |
----------------------------------------------
-----------------------------------------------
| reward                      | [-0.44301933] |
| time/                       |               |
|    fps                      | 149           |
|    iterations               | 8             |
|    time_elapsed             | 109           |
|    total_timesteps          | 2725888       |
| train/                      |               |
|    approx_kl                | 6796.9097     |
|    approx_ln(kl)            | 8.8242235     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.85          |
|    explained_variance       | 0.993         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 13300         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0355        |
|    value_loss               | 4.3           |
-----------------------------------------------
----------------------------------------------
| reward                      | [-1.1862537] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 9            |
|    time_elapsed             | 123          |
|    total_timesteps          | 2727936      |
| train/                      |              |
|    approx_kl                | 5556.809     |
|    approx_ln(kl)            | 8.622779     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.87         |
|    explained_variance       | 0.992        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 13310        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0351       |
|    value_loss               | 5.8          |
----------------------------------------------
----------------------------------------------
| reward                      | [-2.1974163] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 10           |
|    time_elapsed             | 137          |
|    total_timesteps          | 2729984      |
| train/                      |              |
|    approx_kl                | 1289.5974    |
|    approx_ln(kl)            | 7.1620855    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.87         |
|    explained_variance       | 0.978        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 13320        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0351       |
|    value_loss               | 10.5         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-1.437146] |
| time/                       |             |
|    fps                      | 149         |
|    iterations               | 11          |
|    time_elapsed             | 150         |
|    total_timesteps          | 2732032     |
| train/                      |             |
|    approx_kl                | 8673.189    |
|    approx_ln(kl)            | 9.067992    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.88        |
|    explained_variance       | 0.988       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 13330       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0349      |
|    value_loss               | 8.9         |
---------------------------------------------
----------------------------------------------
| reward                      | [-0.6045024] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 12           |
|    time_elapsed             | 164          |
|    total_timesteps          | 2734080      |
| train/                      |              |
|    approx_kl                | 15326.784    |
|    approx_ln(kl)            | 9.637357     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.89         |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 13340        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0348       |
|    value_loss               | 4.16         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.1376053] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 13           |
|    time_elapsed             | 178          |
|    total_timesteps          | 2736128      |
| train/                      |              |
|    approx_kl                | 28298.496    |
|    approx_ln(kl)            | 10.250564    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.88         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13350        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0349       |
|    value_loss               | 0.802        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.1059364] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 14           |
|    time_elapsed             | 191          |
|    total_timesteps          | 2738176      |
| train/                      |              |
|    approx_kl                | 19248.43     |
|    approx_ln(kl)            | 9.865185     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.86         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13360        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0355       |
|    value_loss               | 0.484        |
----------------------------------------------
----------------------------------------------
| reward                      | [-1.2595359] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 15           |
|    time_elapsed             | 205          |
|    total_timesteps          | 2740224      |
| train/                      |              |
|    approx_kl                | 12688.834    |
|    approx_ln(kl)            | 9.448478     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.87         |
|    explained_variance       | 0.979        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 13370        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0352       |
|    value_loss               | 5.96         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.1981504] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 16           |
|    time_elapsed             | 219          |
|    total_timesteps          | 2742272      |
| train/                      |              |
|    approx_kl                | 2709.6013    |
|    approx_ln(kl)            | 7.9045568    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.88         |
|    explained_variance       | 0.963        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13380        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0349       |
|    value_loss               | 4.15         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0704832] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 17           |
|    time_elapsed             | 233          |
|    total_timesteps          | 2744320      |
| train/                      |              |
|    approx_kl                | 7281.8105    |
|    approx_ln(kl)            | 8.893135     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.89         |
|    explained_variance       | 0.989        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13390        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0349       |
|    value_loss               | 2.3          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.3263073] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 18           |
|    time_elapsed             | 247          |
|    total_timesteps          | 2746368      |
| train/                      |              |
|    approx_kl                | 13139.209    |
|    approx_ln(kl)            | 9.483356     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.86         |
|    explained_variance       | 0.988        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13400        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0353       |
|    value_loss               | 1.05         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.77376443] |
| time/                       |               |
|    fps                      | 149           |
|    iterations               | 19            |
|    time_elapsed             | 260           |
|    total_timesteps          | 2748416       |
| train/                      |               |
|    approx_kl                | 2843.0293     |
|    approx_ln(kl)            | 7.9526253     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.85          |
|    explained_variance       | 0.973         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 13410         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0355        |
|    value_loss               | 2.89          |
-----------------------------------------------
----------------------------------------------
| reward                      | [-0.7970488] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 20           |
|    time_elapsed             | 274          |
|    total_timesteps          | 2750464      |
| train/                      |              |
|    approx_kl                | 6926.79      |
|    approx_ln(kl)            | 8.843152     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.84         |
|    explained_variance       | 0.984        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 13420        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0357       |
|    value_loss               | 6.65         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.80325305] |
| time/                       |               |
|    fps                      | 148           |
|    iterations               | 21            |
|    time_elapsed             | 288           |
|    total_timesteps          | 2752512       |
| train/                      |               |
|    approx_kl                | 3356.495      |
|    approx_ln(kl)            | 8.118652      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.84          |
|    explained_variance       | 0.991         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 13430         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0357        |
|    value_loss               | 8.64          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.0994265] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 22           |
|    time_elapsed             | 302          |
|    total_timesteps          | 2754560      |
| train/                      |              |
|    approx_kl                | 4493.8643    |
|    approx_ln(kl)            | 8.410468     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.84         |
|    explained_variance       | 0.988        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13440        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0355       |
|    value_loss               | 4            |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.7930372] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 23           |
|    time_elapsed             | 316          |
|    total_timesteps          | 2756608      |
| train/                      |              |
|    approx_kl                | 7683.705     |
|    approx_ln(kl)            | 8.946857     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.87         |
|    explained_variance       | 0.987        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13450        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.035        |
|    value_loss               | 2.22         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7719858] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 24           |
|    time_elapsed             | 329          |
|    total_timesteps          | 2758656      |
| train/                      |              |
|    approx_kl                | 3306.6138    |
|    approx_ln(kl)            | 8.10368      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.87         |
|    explained_variance       | 0.988        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13460        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0351       |
|    value_loss               | 9.43         |
----------------------------------------------
----------------------------------------------
| reward                      | [-2.3870943] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 25           |
|    time_elapsed             | 343          |
|    total_timesteps          | 2760704      |
| train/                      |              |
|    approx_kl                | 7413.879     |
|    approx_ln(kl)            | 8.911109     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.85         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 13470        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0356       |
|    value_loss               | 6.52         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.60420984] |
| time/                       |               |
|    fps                      | 149           |
|    iterations               | 26            |
|    time_elapsed             | 357           |
|    total_timesteps          | 2762752       |
| train/                      |               |
|    approx_kl                | 17457.35      |
|    approx_ln(kl)            | 9.767516      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.84          |
|    explained_variance       | 0.99          |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 13480         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0356        |
|    value_loss               | 4.57          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.5261501] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 27           |
|    time_elapsed             | 370          |
|    total_timesteps          | 2764800      |
| train/                      |              |
|    approx_kl                | 3945.8638    |
|    approx_ln(kl)            | 8.280423     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.83         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13490        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0357       |
|    value_loss               | 2.01         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.4447865] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 28           |
|    time_elapsed             | 384          |
|    total_timesteps          | 2766848      |
| train/                      |              |
|    approx_kl                | 5873.6924    |
|    approx_ln(kl)            | 8.678239     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.85         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13500        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0353       |
|    value_loss               | 2.77         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4658506] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 29           |
|    time_elapsed             | 398          |
|    total_timesteps          | 2768896      |
| train/                      |              |
|    approx_kl                | 24395.11     |
|    approx_ln(kl)            | 10.102138    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.88         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13510        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0349       |
|    value_loss               | 1.19         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6222072] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 30           |
|    time_elapsed             | 412          |
|    total_timesteps          | 2770944      |
| train/                      |              |
|    approx_kl                | 15977.505    |
|    approx_ln(kl)            | 9.678937     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.91         |
|    explained_variance       | 0.987        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13520        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0344       |
|    value_loss               | 2.2          |
----------------------------------------------
----------------------------------------------
| reward                      | [-0.8919658] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 31           |
|    time_elapsed             | 425          |
|    total_timesteps          | 2772992      |
| train/                      |              |
|    approx_kl                | 3460.9875    |
|    approx_ln(kl)            | 8.149309     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.9          |
|    explained_variance       | 0.969        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 13530        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0345       |
|    value_loss               | 0.579        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.8136931] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 32           |
|    time_elapsed             | 439          |
|    total_timesteps          | 2775040      |
| train/                      |              |
|    approx_kl                | 5251.387     |
|    approx_ln(kl)            | 8.566248     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.89         |
|    explained_variance       | 0.99         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13540        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0347       |
|    value_loss               | 0.348        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.51787806] |
| time/                       |               |
|    fps                      | 149           |
|    iterations               | 33            |
|    time_elapsed             | 453           |
|    total_timesteps          | 2777088       |
| train/                      |               |
|    approx_kl                | 29215.16      |
|    approx_ln(kl)            | 10.282443     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.89          |
|    explained_variance       | 0.996         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 13550         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0348        |
|    value_loss               | 0.537         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7894454] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 34           |
|    time_elapsed             | 467          |
|    total_timesteps          | 2779136      |
| train/                      |              |
|    approx_kl                | 13875.984    |
|    approx_ln(kl)            | 9.537915     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.89         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13560        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0345       |
|    value_loss               | 0.301        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.4472879] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 35           |
|    time_elapsed             | 481          |
|    total_timesteps          | 2781184      |
| train/                      |              |
|    approx_kl                | 10788.532    |
|    approx_ln(kl)            | 9.286239     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.92         |
|    explained_variance       | 0.987        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13570        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.034        |
|    value_loss               | 2.67         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.0151334] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 36           |
|    time_elapsed             | 494          |
|    total_timesteps          | 2783232      |
| train/                      |              |
|    approx_kl                | 16589.145    |
|    approx_ln(kl)            | 9.716504     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.92         |
|    explained_variance       | 0.99         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13580        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.034        |
|    value_loss               | 2.16         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.2015306] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 37           |
|    time_elapsed             | 508          |
|    total_timesteps          | 2785280      |
| train/                      |              |
|    approx_kl                | 4232.747     |
|    approx_ln(kl)            | 8.350607     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.92         |
|    explained_variance       | 0.989        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13590        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0342       |
|    value_loss               | 5.66         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-5.0572796] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 38           |
|    time_elapsed             | 522          |
|    total_timesteps          | 2787328      |
| train/                      |              |
|    approx_kl                | 9208.5       |
|    approx_ln(kl)            | 9.127882     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.88         |
|    explained_variance       | 0.99         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13600        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0349       |
|    value_loss               | 14.3         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.45254505] |
| time/                       |               |
|    fps                      | 148           |
|    iterations               | 39            |
|    time_elapsed             | 536           |
|    total_timesteps          | 2789376       |
| train/                      |               |
|    approx_kl                | 11612.357     |
|    approx_ln(kl)            | 9.359825      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.87          |
|    explained_variance       | 0.995         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 13610         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0349        |
|    value_loss               | 11.8          |
-----------------------------------------------
----------------------------------------------
| reward                      | [-1.2972877] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 40           |
|    time_elapsed             | 549          |
|    total_timesteps          | 2791424      |
| train/                      |              |
|    approx_kl                | 3011.9517    |
|    approx_ln(kl)            | 8.010344     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.87         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 13620        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0349       |
|    value_loss               | 11.1         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.5398831] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 41           |
|    time_elapsed             | 564          |
|    total_timesteps          | 2793472      |
| train/                      |              |
|    approx_kl                | 29215.52     |
|    approx_ln(kl)            | 10.282455    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.87         |
|    explained_variance       | 0.988        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13630        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0351       |
|    value_loss               | 0.992        |
----------------------------------------------
----------------------------------------------
| reward                      | [-0.6195935] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 42           |
|    time_elapsed             | 577          |
|    total_timesteps          | 2795520      |
| train/                      |              |
|    approx_kl                | 5569.042     |
|    approx_ln(kl)            | 8.624978     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.86         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 13640        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0352       |
|    value_loss               | 3.74         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.78003097] |
| time/                       |               |
|    fps                      | 148           |
|    iterations               | 43            |
|    time_elapsed             | 591           |
|    total_timesteps          | 2797568       |
| train/                      |               |
|    approx_kl                | 3369.5496     |
|    approx_ln(kl)            | 8.122535      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.87          |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 13650         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0349        |
|    value_loss               | 3             |
-----------------------------------------------
----------------------------------------------
| reward                      | [-1.4872606] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 44           |
|    time_elapsed             | 605          |
|    total_timesteps          | 2799616      |
| train/                      |              |
|    approx_kl                | 6546.9033    |
|    approx_ln(kl)            | 8.786747     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.86         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 13660        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0352       |
|    value_loss               | 1.47         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5481922] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 45           |
|    time_elapsed             | 618          |
|    total_timesteps          | 2801664      |
| train/                      |              |
|    approx_kl                | 1321.1909    |
|    approx_ln(kl)            | 7.186289     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.84         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13670        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0356       |
|    value_loss               | 1.35         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.82028276] |
| time/                       |               |
|    fps                      | 148           |
|    iterations               | 46            |
|    time_elapsed             | 632           |
|    total_timesteps          | 2803712       |
| train/                      |               |
|    approx_kl                | 6893.199      |
|    approx_ln(kl)            | 8.83829       |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.83          |
|    explained_variance       | 0.996         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 13680         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0356        |
|    value_loss               | 1.31          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.8920155] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 47           |
|    time_elapsed             | 646          |
|    total_timesteps          | 2805760      |
| train/                      |              |
|    approx_kl                | 14341.585    |
|    approx_ln(kl)            | 9.570919     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.81         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13690        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0361       |
|    value_loss               | 1.06         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6913842] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 48           |
|    time_elapsed             | 660          |
|    total_timesteps          | 2807808      |
| train/                      |              |
|    approx_kl                | 4801.7456    |
|    approx_ln(kl)            | 8.476735     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.79         |
|    explained_variance       | 0.985        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13700        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0364       |
|    value_loss               | 1.35         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.41733608] |
| time/                       |               |
|    fps                      | 148           |
|    iterations               | 49            |
|    time_elapsed             | 673           |
|    total_timesteps          | 2809856       |
| train/                      |               |
|    approx_kl                | 5318.2183     |
|    approx_ln(kl)            | 8.578894      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.8           |
|    explained_variance       | 0.982         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 13710         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0362        |
|    value_loss               | 2.6           |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
--------------------------------------
| reward             | [-0.51815295] |
| time/              |               |
|    fps             | 163           |
|    iterations      | 1             |
|    time_elapsed    | 12            |
|    total_timesteps | 2811904       |
--------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5487809] |
| time/                       |              |
|    fps                      | 156          |
|    iterations               | 2            |
|    time_elapsed             | 26           |
|    total_timesteps          | 2813952      |
| train/                      |              |
|    approx_kl                | 18391.707    |
|    approx_ln(kl)            | 9.819655     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.82         |
|    explained_variance       | 0.984        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13730        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.036        |
|    value_loss               | 1.07         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.8943674] |
| time/                       |              |
|    fps                      | 153          |
|    iterations               | 3            |
|    time_elapsed             | 39           |
|    total_timesteps          | 2816000      |
| train/                      |              |
|    approx_kl                | 10207.936    |
|    approx_ln(kl)            | 9.230921     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.83         |
|    explained_variance       | 0.981        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13740        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0358       |
|    value_loss               | 2.04         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5738949] |
| time/                       |              |
|    fps                      | 152          |
|    iterations               | 4            |
|    time_elapsed             | 53           |
|    total_timesteps          | 2818048      |
| train/                      |              |
|    approx_kl                | 16996.684    |
|    approx_ln(kl)            | 9.740773     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.79         |
|    explained_variance       | 0.988        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13750        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0365       |
|    value_loss               | 1.31         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7658286] |
| time/                       |              |
|    fps                      | 151          |
|    iterations               | 5            |
|    time_elapsed             | 67           |
|    total_timesteps          | 2820096      |
| train/                      |              |
|    approx_kl                | 2506.4714    |
|    approx_ln(kl)            | 7.826631     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.78         |
|    explained_variance       | 0.981        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13760        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0367       |
|    value_loss               | 2.22         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0616993] |
| time/                       |              |
|    fps                      | 151          |
|    iterations               | 6            |
|    time_elapsed             | 81           |
|    total_timesteps          | 2822144      |
| train/                      |              |
|    approx_kl                | 12110.362    |
|    approx_ln(kl)            | 9.401816     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.76         |
|    explained_variance       | 0.935        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13770        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0371       |
|    value_loss               | 1.75         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0290529] |
| time/                       |              |
|    fps                      | 150          |
|    iterations               | 7            |
|    time_elapsed             | 95           |
|    total_timesteps          | 2824192      |
| train/                      |              |
|    approx_kl                | 3264.4302    |
|    approx_ln(kl)            | 8.09084      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.75         |
|    explained_variance       | 0.972        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13780        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0372       |
|    value_loss               | 5.24         |
----------------------------------------------
---------------------------------------------
| reward                      | [-2.342204] |
| time/                       |             |
|    fps                      | 150         |
|    iterations               | 8           |
|    time_elapsed             | 108         |
|    total_timesteps          | 2826240     |
| train/                      |             |
|    approx_kl                | 3520.7864   |
|    approx_ln(kl)            | 8.16644     |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.77        |
|    explained_variance       | 0.99        |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | inf         |
|    loss                     | inf         |
|    n_updates                | 13790       |
|    policy_gradient_loss     | inf         |
|    std                      | 0.0361      |
|    value_loss               | 3.26        |
---------------------------------------------
----------------------------------------------
| reward                      | [-0.9608088] |
| time/                       |              |
|    fps                      | 150          |
|    iterations               | 9            |
|    time_elapsed             | 122          |
|    total_timesteps          | 2828288      |
| train/                      |              |
|    approx_kl                | 5208.1343    |
|    approx_ln(kl)            | 8.557977     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.81         |
|    explained_variance       | 0.991        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 13800        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0361       |
|    value_loss               | 1.34         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.9866753] |
| time/                       |              |
|    fps                      | 150          |
|    iterations               | 10           |
|    time_elapsed             | 136          |
|    total_timesteps          | 2830336      |
| train/                      |              |
|    approx_kl                | 35267.695    |
|    approx_ln(kl)            | 10.470723    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.8          |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13810        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0362       |
|    value_loss               | 0.706        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.48215193] |
| time/                       |               |
|    fps                      | 150           |
|    iterations               | 11            |
|    time_elapsed             | 149           |
|    total_timesteps          | 2832384       |
| train/                      |               |
|    approx_kl                | 52268.35      |
|    approx_ln(kl)            | 10.864146     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.8           |
|    explained_variance       | 0.941         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 13820         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0362        |
|    value_loss               | 0.307         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0596454] |
| time/                       |              |
|    fps                      | 150          |
|    iterations               | 12           |
|    time_elapsed             | 163          |
|    total_timesteps          | 2834432      |
| train/                      |              |
|    approx_kl                | 7077.8584    |
|    approx_ln(kl)            | 8.864727     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.79         |
|    explained_variance       | 0.967        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13830        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0364       |
|    value_loss               | 0.881        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0103145] |
| time/                       |              |
|    fps                      | 150          |
|    iterations               | 13           |
|    time_elapsed             | 177          |
|    total_timesteps          | 2836480      |
| train/                      |              |
|    approx_kl                | 10962.951    |
|    approx_ln(kl)            | 9.302277     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.78         |
|    explained_variance       | 0.972        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13840        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0365       |
|    value_loss               | 0.607        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.8873504] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 14           |
|    time_elapsed             | 191          |
|    total_timesteps          | 2838528      |
| train/                      |              |
|    approx_kl                | 17984.746    |
|    approx_ln(kl)            | 9.797279     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.78         |
|    explained_variance       | 0.965        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13850        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0366       |
|    value_loss               | 0.581        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.8310632] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 15           |
|    time_elapsed             | 205          |
|    total_timesteps          | 2840576      |
| train/                      |              |
|    approx_kl                | 7232.7314    |
|    approx_ln(kl)            | 8.886372     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.74         |
|    explained_variance       | 0.984        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13860        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0373       |
|    value_loss               | 2.02         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5539056] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 16           |
|    time_elapsed             | 220          |
|    total_timesteps          | 2842624      |
| train/                      |              |
|    approx_kl                | 2054.2363    |
|    approx_ln(kl)            | 7.6276593    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.7          |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13870        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.038        |
|    value_loss               | 0.297        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.9385532] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 17           |
|    time_elapsed             | 237          |
|    total_timesteps          | 2844672      |
| train/                      |              |
|    approx_kl                | 15773.441    |
|    approx_ln(kl)            | 9.666083     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.68         |
|    explained_variance       | 0.977        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13880        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0384       |
|    value_loss               | 1.29         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.82912505] |
| time/                       |               |
|    fps                      | 107           |
|    iterations               | 18            |
|    time_elapsed             | 342           |
|    total_timesteps          | 2846720       |
| train/                      |               |
|    approx_kl                | 5496.876      |
|    approx_ln(kl)            | 8.611936      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.71          |
|    explained_variance       | 0.958         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 13890         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0378        |
|    value_loss               | 1.01          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.9033421] |
| time/                       |              |
|    fps                      | 87           |
|    iterations               | 19           |
|    time_elapsed             | 446          |
|    total_timesteps          | 2848768      |
| train/                      |              |
|    approx_kl                | 2927.3105    |
|    approx_ln(kl)            | 7.9818397    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.69         |
|    explained_variance       | 0.794        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13900        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0384       |
|    value_loss               | 4.75         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.5477535] |
| time/                       |              |
|    fps                      | 74           |
|    iterations               | 20           |
|    time_elapsed             | 550          |
|    total_timesteps          | 2850816      |
| train/                      |              |
|    approx_kl                | 2488.8555    |
|    approx_ln(kl)            | 7.819578     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.66         |
|    explained_variance       | 0.898        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13910        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0387       |
|    value_loss               | 2.43         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.7603164] |
| time/                       |              |
|    fps                      | 65           |
|    iterations               | 21           |
|    time_elapsed             | 654          |
|    total_timesteps          | 2852864      |
| train/                      |              |
|    approx_kl                | 2379.149     |
|    approx_ln(kl)            | 7.774498     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.66         |
|    explained_variance       | 0.382        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13920        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0389       |
|    value_loss               | 9.53         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6810902] |
| time/                       |              |
|    fps                      | 61           |
|    iterations               | 22           |
|    time_elapsed             | 727          |
|    total_timesteps          | 2854912      |
| train/                      |              |
|    approx_kl                | 3271.7998    |
|    approx_ln(kl)            | 8.093096     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.69         |
|    explained_variance       | 0.891        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13930        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0381       |
|    value_loss               | 6.97         |
----------------------------------------------
-----------------------------------------------
| reward                      | [-0.93805283] |
| time/                       |               |
|    fps                      | 63            |
|    iterations               | 23            |
|    time_elapsed             | 741           |
|    total_timesteps          | 2856960       |
| train/                      |               |
|    approx_kl                | 12434.718     |
|    approx_ln(kl)            | 9.428247      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.71          |
|    explained_variance       | 0.976         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 13940         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.038         |
|    value_loss               | 1.2           |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0332971] |
| time/                       |              |
|    fps                      | 65           |
|    iterations               | 24           |
|    time_elapsed             | 754          |
|    total_timesteps          | 2859008      |
| train/                      |              |
|    approx_kl                | 16416.398    |
|    approx_ln(kl)            | 9.706036     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.68         |
|    explained_variance       | 0.978        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13950        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0386       |
|    value_loss               | 1.82         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.50824106] |
| time/                       |               |
|    fps                      | 66            |
|    iterations               | 25            |
|    time_elapsed             | 768           |
|    total_timesteps          | 2861056       |
| train/                      |               |
|    approx_kl                | 7658.634      |
|    approx_ln(kl)            | 8.943589      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.66          |
|    explained_variance       | 0.978         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 13960         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0389        |
|    value_loss               | 1.7           |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.9453394] |
| time/                       |              |
|    fps                      | 68           |
|    iterations               | 26           |
|    time_elapsed             | 782          |
|    total_timesteps          | 2863104      |
| train/                      |              |
|    approx_kl                | 4551.713     |
|    approx_ln(kl)            | 8.423259     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.67         |
|    explained_variance       | 0.989        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13970        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0387       |
|    value_loss               | 1.21         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0091441] |
| time/                       |              |
|    fps                      | 69           |
|    iterations               | 27           |
|    time_elapsed             | 795          |
|    total_timesteps          | 2865152      |
| train/                      |              |
|    approx_kl                | 33351.47     |
|    approx_ln(kl)            | 10.414857    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.67         |
|    explained_variance       | 0.937        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13980        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0387       |
|    value_loss               | 0.606        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5886228] |
| time/                       |              |
|    fps                      | 70           |
|    iterations               | 28           |
|    time_elapsed             | 809          |
|    total_timesteps          | 2867200      |
| train/                      |              |
|    approx_kl                | 16990.182    |
|    approx_ln(kl)            | 9.740391     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.67         |
|    explained_variance       | 0.978        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 13990        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0388       |
|    value_loss               | 0.402        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.73384804] |
| time/                       |               |
|    fps                      | 72            |
|    iterations               | 29            |
|    time_elapsed             | 822           |
|    total_timesteps          | 2869248       |
| train/                      |               |
|    approx_kl                | 6369.7246     |
|    approx_ln(kl)            | 8.759312      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.71          |
|    explained_variance       | 0.985         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 14000         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0379        |
|    value_loss               | 0.546         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.8898095] |
| time/                       |              |
|    fps                      | 73           |
|    iterations               | 30           |
|    time_elapsed             | 836          |
|    total_timesteps          | 2871296      |
| train/                      |              |
|    approx_kl                | 2760.0945    |
|    approx_ln(kl)            | 7.9230204    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.72         |
|    explained_variance       | 0.969        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14010        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0377       |
|    value_loss               | 1.26         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7172201] |
| time/                       |              |
|    fps                      | 74           |
|    iterations               | 31           |
|    time_elapsed             | 850          |
|    total_timesteps          | 2873344      |
| train/                      |              |
|    approx_kl                | 16085.48     |
|    approx_ln(kl)            | 9.685673     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.72         |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14020        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0378       |
|    value_loss               | 0.324        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.38772833] |
| time/                       |               |
|    fps                      | 75            |
|    iterations               | 32            |
|    time_elapsed             | 863           |
|    total_timesteps          | 2875392       |
| train/                      |               |
|    approx_kl                | 46961.203     |
|    approx_ln(kl)            | 10.757077     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.71          |
|    explained_variance       | 0.995         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 14030         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0379        |
|    value_loss               | 0.299         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.74124295] |
| time/                       |               |
|    fps                      | 77            |
|    iterations               | 33            |
|    time_elapsed             | 877           |
|    total_timesteps          | 2877440       |
| train/                      |               |
|    approx_kl                | 19737.273     |
|    approx_ln(kl)            | 9.8902645     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.73          |
|    explained_variance       | 0.994         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 14040         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0375        |
|    value_loss               | 0.249         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.1319667] |
| time/                       |              |
|    fps                      | 78           |
|    iterations               | 34           |
|    time_elapsed             | 890          |
|    total_timesteps          | 2879488      |
| train/                      |              |
|    approx_kl                | 4698.1885    |
|    approx_ln(kl)            | 8.454932     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.71         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14050        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0378       |
|    value_loss               | 0.276        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5985269] |
| time/                       |              |
|    fps                      | 79           |
|    iterations               | 35           |
|    time_elapsed             | 904          |
|    total_timesteps          | 2881536      |
| train/                      |              |
|    approx_kl                | 26396.56     |
|    approx_ln(kl)            | 10.180989    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.73         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14060        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0376       |
|    value_loss               | 0.158        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.9010517] |
| time/                       |              |
|    fps                      | 80           |
|    iterations               | 36           |
|    time_elapsed             | 918          |
|    total_timesteps          | 2883584      |
| train/                      |              |
|    approx_kl                | 10992.138    |
|    approx_ln(kl)            | 9.304935     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.75         |
|    explained_variance       | 0.988        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14070        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0371       |
|    value_loss               | 0.279        |
----------------------------------------------
----------------------------------------------
| reward                      | [-0.6309674] |
| time/                       |              |
|    fps                      | 81           |
|    iterations               | 37           |
|    time_elapsed             | 932          |
|    total_timesteps          | 2885632      |
| train/                      |              |
|    approx_kl                | 18259.867    |
|    approx_ln(kl)            | 9.812461     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.78         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 14080        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0366       |
|    value_loss               | 0.142        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.78256553] |
| time/                       |               |
|    fps                      | 82            |
|    iterations               | 38            |
|    time_elapsed             | 945           |
|    total_timesteps          | 2887680       |
| train/                      |               |
|    approx_kl                | 7349.5234     |
|    approx_ln(kl)            | 8.9023905     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.77          |
|    explained_variance       | 0.974         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 14090         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0368        |
|    value_loss               | 0.556         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.91224056] |
| time/                       |               |
|    fps                      | 83            |
|    iterations               | 39            |
|    time_elapsed             | 959           |
|    total_timesteps          | 2889728       |
| train/                      |               |
|    approx_kl                | 6930.4746     |
|    approx_ln(kl)            | 8.843683      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.78          |
|    explained_variance       | 0.986         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 14100         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0366        |
|    value_loss               | 0.352         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0834332] |
| time/                       |              |
|    fps                      | 84           |
|    iterations               | 40           |
|    time_elapsed             | 973          |
|    total_timesteps          | 2891776      |
| train/                      |              |
|    approx_kl                | 69118.12     |
|    approx_ln(kl)            | 11.143572    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.8          |
|    explained_variance       | 0.992        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14110        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0361       |
|    value_loss               | 0.732        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.8405327] |
| time/                       |              |
|    fps                      | 85           |
|    iterations               | 41           |
|    time_elapsed             | 986          |
|    total_timesteps          | 2893824      |
| train/                      |              |
|    approx_kl                | 18817.758    |
|    approx_ln(kl)            | 9.842556     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.8          |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14120        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0362       |
|    value_loss               | 0.384        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.51255774] |
| time/                       |               |
|    fps                      | 85            |
|    iterations               | 42            |
|    time_elapsed             | 1000          |
|    total_timesteps          | 2895872       |
| train/                      |               |
|    approx_kl                | 12223.106     |
|    approx_ln(kl)            | 9.411083      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.83          |
|    explained_variance       | 0.997         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 14130         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0356        |
|    value_loss               | 0.444         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.74190253] |
| time/                       |               |
|    fps                      | 86            |
|    iterations               | 43            |
|    time_elapsed             | 1014          |
|    total_timesteps          | 2897920       |
| train/                      |               |
|    approx_kl                | 5028.0596     |
|    approx_ln(kl)            | 8.522789      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.84          |
|    explained_variance       | 0.967         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 14140         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0355        |
|    value_loss               | 0.254         |
-----------------------------------------------
---------------------------------------------
| reward                      | [-1.076605] |
| time/                       |             |
|    fps                      | 87          |
|    iterations               | 44          |
|    time_elapsed             | 1028        |
|    total_timesteps          | 2899968     |
| train/                      |             |
|    approx_kl                | 9572.305    |
|    approx_ln(kl)            | 9.166629    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.83        |
|    explained_variance       | 0.954       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | inf         |
|    loss                     | inf         |
|    n_updates                | 14150       |
|    policy_gradient_loss     | inf         |
|    std                      | 0.0357      |
|    value_loss               | 1.64        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6973657] |
| time/                       |              |
|    fps                      | 88           |
|    iterations               | 45           |
|    time_elapsed             | 1042         |
|    total_timesteps          | 2902016      |
| train/                      |              |
|    approx_kl                | 5376.1377    |
|    approx_ln(kl)            | 8.5897255    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.83         |
|    explained_variance       | 0.955        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14160        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0357       |
|    value_loss               | 1.03         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.59770656] |
| time/                       |               |
|    fps                      | 89            |
|    iterations               | 46            |
|    time_elapsed             | 1056          |
|    total_timesteps          | 2904064       |
| train/                      |               |
|    approx_kl                | 2955.3662     |
|    approx_ln(kl)            | 7.991378      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.83          |
|    explained_variance       | 0.954         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 14170         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0357        |
|    value_loss               | 0.491         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.74535733] |
| time/                       |               |
|    fps                      | 89            |
|    iterations               | 47            |
|    time_elapsed             | 1070          |
|    total_timesteps          | 2906112       |
| train/                      |               |
|    approx_kl                | 62133.156     |
|    approx_ln(kl)            | 11.037035     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.82          |
|    explained_variance       | 0.962         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 14180         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0359        |
|    value_loss               | 0.783         |
-----------------------------------------------
----------------------------------------------
| reward                      | [-0.7618595] |
| time/                       |              |
|    fps                      | 90           |
|    iterations               | 48           |
|    time_elapsed             | 1084         |
|    total_timesteps          | 2908160      |
| train/                      |              |
|    approx_kl                | 17073.924    |
|    approx_ln(kl)            | 9.745308     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.82         |
|    explained_variance       | 0.972        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 14190        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0357       |
|    value_loss               | 0.577        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.86467683] |
| time/                       |               |
|    fps                      | 91            |
|    iterations               | 49            |
|    time_elapsed             | 1097          |
|    total_timesteps          | 2910208       |
| train/                      |               |
|    approx_kl                | 5827.201      |
|    approx_ln(kl)            | 8.670292      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.86          |
|    explained_variance       | 0.983         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 14200         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0352        |
|    value_loss               | 0.382         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
--------------------------------------
| reward             | [-0.81200224] |
| time/              |               |
|    fps             | 163           |
|    iterations      | 1             |
|    time_elapsed    | 12            |
|    total_timesteps | 2912256       |
--------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.8947282] |
| time/                       |              |
|    fps                      | 155          |
|    iterations               | 2            |
|    time_elapsed             | 26           |
|    total_timesteps          | 2914304      |
| train/                      |              |
|    approx_kl                | 8206.706     |
|    approx_ln(kl)            | 9.012707     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.84         |
|    explained_variance       | 0.992        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14220        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0356       |
|    value_loss               | 0.283        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.1482671] |
| time/                       |              |
|    fps                      | 153          |
|    iterations               | 3            |
|    time_elapsed             | 40           |
|    total_timesteps          | 2916352      |
| train/                      |              |
|    approx_kl                | 22381.418    |
|    approx_ln(kl)            | 10.015986    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.83         |
|    explained_variance       | 0.978        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14230        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0356       |
|    value_loss               | 0.51         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5544878] |
| time/                       |              |
|    fps                      | 152          |
|    iterations               | 4            |
|    time_elapsed             | 53           |
|    total_timesteps          | 2918400      |
| train/                      |              |
|    approx_kl                | 13574.293    |
|    approx_ln(kl)            | 9.515933     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.83         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14240        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0357       |
|    value_loss               | 0.258        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5004728] |
| time/                       |              |
|    fps                      | 151          |
|    iterations               | 5            |
|    time_elapsed             | 67           |
|    total_timesteps          | 2920448      |
| train/                      |              |
|    approx_kl                | 47520.58     |
|    approx_ln(kl)            | 10.768918    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.84         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14250        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0356       |
|    value_loss               | 0.301        |
----------------------------------------------
----------------------------------------------
| reward                      | [-1.2855445] |
| time/                       |              |
|    fps                      | 151          |
|    iterations               | 6            |
|    time_elapsed             | 81           |
|    total_timesteps          | 2922496      |
| train/                      |              |
|    approx_kl                | 74696.03     |
|    approx_ln(kl)            | 11.221182    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.84         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 14260        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0355       |
|    value_loss               | 0.162        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.63547325] |
| time/                       |               |
|    fps                      | 150           |
|    iterations               | 7             |
|    time_elapsed             | 94            |
|    total_timesteps          | 2924544       |
| train/                      |               |
|    approx_kl                | 41858.312     |
|    approx_ln(kl)            | 10.642046     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.86          |
|    explained_variance       | 0.993         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 14270         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.035         |
|    value_loss               | 0.253         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-0.777336] |
| time/                       |             |
|    fps                      | 150         |
|    iterations               | 8           |
|    time_elapsed             | 108         |
|    total_timesteps          | 2926592     |
| train/                      |             |
|    approx_kl                | 39881.344   |
|    approx_ln(kl)            | 10.593664   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.85        |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 14280       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0353      |
|    value_loss               | 0.23        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.4063078] |
| time/                       |              |
|    fps                      | 150          |
|    iterations               | 9            |
|    time_elapsed             | 122          |
|    total_timesteps          | 2928640      |
| train/                      |              |
|    approx_kl                | 25773.898    |
|    approx_ln(kl)            | 10.157118    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.84         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14290        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0354       |
|    value_loss               | 0.223        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0209489] |
| time/                       |              |
|    fps                      | 150          |
|    iterations               | 10           |
|    time_elapsed             | 136          |
|    total_timesteps          | 2930688      |
| train/                      |              |
|    approx_kl                | 61303.25     |
|    approx_ln(kl)            | 11.023588    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.85         |
|    explained_variance       | 0.985        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14300        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0354       |
|    value_loss               | 0.309        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.80227506] |
| time/                       |               |
|    fps                      | 150           |
|    iterations               | 11            |
|    time_elapsed             | 149           |
|    total_timesteps          | 2932736       |
| train/                      |               |
|    approx_kl                | 39481.098     |
|    approx_ln(kl)            | 10.583577     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.84          |
|    explained_variance       | 0.989         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 14310         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0354        |
|    value_loss               | 0.264         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.9719919] |
| time/                       |              |
|    fps                      | 150          |
|    iterations               | 12           |
|    time_elapsed             | 163          |
|    total_timesteps          | 2934784      |
| train/                      |              |
|    approx_kl                | 25643.611    |
|    approx_ln(kl)            | 10.15205     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.86         |
|    explained_variance       | 0.988        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14320        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.035        |
|    value_loss               | 1.69         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.6010655] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 13           |
|    time_elapsed             | 178          |
|    total_timesteps          | 2936832      |
| train/                      |              |
|    approx_kl                | 42163.895    |
|    approx_ln(kl)            | 10.64932     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.88         |
|    explained_variance       | 0.986        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14330        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0347       |
|    value_loss               | 1.26         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6478262] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 14           |
|    time_elapsed             | 197          |
|    total_timesteps          | 2938880      |
| train/                      |              |
|    approx_kl                | 17470.787    |
|    approx_ln(kl)            | 9.768286     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.84         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14340        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0355       |
|    value_loss               | 0.55         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0055418] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 15           |
|    time_elapsed             | 210          |
|    total_timesteps          | 2940928      |
| train/                      |              |
|    approx_kl                | 24009.51     |
|    approx_ln(kl)            | 10.0862055   |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.82         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14350        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0358       |
|    value_loss               | 0.521        |
----------------------------------------------
-----------------------------------------------
| reward                      | [-0.54599863] |
| time/                       |               |
|    fps                      | 145           |
|    iterations               | 16            |
|    time_elapsed             | 224           |
|    total_timesteps          | 2942976       |
| train/                      |               |
|    approx_kl                | 22108.465     |
|    approx_ln(kl)            | 10.0037155    |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.77          |
|    explained_variance       | 0.996         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 14360         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0369        |
|    value_loss               | 0.277         |
-----------------------------------------------
----------------------------------------------
| reward                      | [-0.9382774] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 17           |
|    time_elapsed             | 238          |
|    total_timesteps          | 2945024      |
| train/                      |              |
|    approx_kl                | 11342.749    |
|    approx_ln(kl)            | 9.336334     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.78         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 14370        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0366       |
|    value_loss               | 0.226        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.80006164] |
| time/                       |               |
|    fps                      | 146           |
|    iterations               | 18            |
|    time_elapsed             | 252           |
|    total_timesteps          | 2947072       |
| train/                      |               |
|    approx_kl                | 9332.253      |
|    approx_ln(kl)            | 9.141232      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.76          |
|    explained_variance       | 0.988         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 14380         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0369        |
|    value_loss               | 0.619         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.8457596] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 19           |
|    time_elapsed             | 265          |
|    total_timesteps          | 2949120      |
| train/                      |              |
|    approx_kl                | 25090.703    |
|    approx_ln(kl)            | 10.130253    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.73         |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14390        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0374       |
|    value_loss               | 0.23         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.65673715] |
| time/                       |               |
|    fps                      | 146           |
|    iterations               | 20            |
|    time_elapsed             | 279           |
|    total_timesteps          | 2951168       |
| train/                      |               |
|    approx_kl                | 11405.379     |
|    approx_ln(kl)            | 9.341841      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.73          |
|    explained_variance       | 0.957         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 14400         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0375        |
|    value_loss               | 0.754         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7475076] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 21           |
|    time_elapsed             | 293          |
|    total_timesteps          | 2953216      |
| train/                      |              |
|    approx_kl                | 18793.973    |
|    approx_ln(kl)            | 9.841291     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.73         |
|    explained_variance       | 0.992        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14410        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0375       |
|    value_loss               | 0.316        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.8565611] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 22           |
|    time_elapsed             | 307          |
|    total_timesteps          | 2955264      |
| train/                      |              |
|    approx_kl                | 33753.324    |
|    approx_ln(kl)            | 10.426834    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.77         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14420        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0368       |
|    value_loss               | 0.162        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.72120667] |
| time/                       |               |
|    fps                      | 146           |
|    iterations               | 23            |
|    time_elapsed             | 321           |
|    total_timesteps          | 2957312       |
| train/                      |               |
|    approx_kl                | 9695.227      |
|    approx_ln(kl)            | 9.179389      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.72          |
|    explained_variance       | 0.983         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 14430         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0377        |
|    value_loss               | 0.223         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.8500368] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 24           |
|    time_elapsed             | 335          |
|    total_timesteps          | 2959360      |
| train/                      |              |
|    approx_kl                | 14223.263    |
|    approx_ln(kl)            | 9.562634     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.74         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14440        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0373       |
|    value_loss               | 0.188        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5341392] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 25           |
|    time_elapsed             | 348          |
|    total_timesteps          | 2961408      |
| train/                      |              |
|    approx_kl                | 6991.2246    |
|    approx_ln(kl)            | 8.852411     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.75         |
|    explained_variance       | 0.982        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14450        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0372       |
|    value_loss               | 0.288        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.77786255] |
| time/                       |               |
|    fps                      | 146           |
|    iterations               | 26            |
|    time_elapsed             | 362           |
|    total_timesteps          | 2963456       |
| train/                      |               |
|    approx_kl                | 21224.938     |
|    approx_ln(kl)            | 9.962932      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.71          |
|    explained_variance       | 0.983         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 14460         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0376        |
|    value_loss               | 0.331         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7049901] |
| time/                       |              |
|    fps                      | 146          |
|    iterations               | 27           |
|    time_elapsed             | 376          |
|    total_timesteps          | 2965504      |
| train/                      |              |
|    approx_kl                | 3903.9976    |
|    approx_ln(kl)            | 8.269756     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.74         |
|    explained_variance       | 0.879        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14470        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0374       |
|    value_loss               | 0.694        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.80195427] |
| time/                       |               |
|    fps                      | 146           |
|    iterations               | 28            |
|    time_elapsed             | 392           |
|    total_timesteps          | 2967552       |
| train/                      |               |
|    approx_kl                | 5565.2695     |
|    approx_ln(kl)            | 8.624301      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.74          |
|    explained_variance       | 0.935         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 14480         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0372        |
|    value_loss               | 0.35          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.8021122] |
| time/                       |              |
|    fps                      | 144          |
|    iterations               | 29           |
|    time_elapsed             | 409          |
|    total_timesteps          | 2969600      |
| train/                      |              |
|    approx_kl                | 5141.6084    |
|    approx_ln(kl)            | 8.545121     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.74         |
|    explained_variance       | 0.972        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14490        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0372       |
|    value_loss               | 0.259        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5916603] |
| time/                       |              |
|    fps                      | 144          |
|    iterations               | 30           |
|    time_elapsed             | 425          |
|    total_timesteps          | 2971648      |
| train/                      |              |
|    approx_kl                | 23661.273    |
|    approx_ln(kl)            | 10.071595    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.73         |
|    explained_variance       | 0.948        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14500        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0376       |
|    value_loss               | 0.244        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6729686] |
| time/                       |              |
|    fps                      | 144          |
|    iterations               | 31           |
|    time_elapsed             | 439          |
|    total_timesteps          | 2973696      |
| train/                      |              |
|    approx_kl                | 8538.935     |
|    approx_ln(kl)            | 9.052392     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.71         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14510        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0379       |
|    value_loss               | 0.158        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.74974155] |
| time/                       |               |
|    fps                      | 144           |
|    iterations               | 32            |
|    time_elapsed             | 453           |
|    total_timesteps          | 2975744       |
| train/                      |               |
|    approx_kl                | 25273.855     |
|    approx_ln(kl)            | 10.137526     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.71          |
|    explained_variance       | 0.994         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 14520         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0379        |
|    value_loss               | 0.152         |
-----------------------------------------------
----------------------------------------------
| reward                      | [-0.6533005] |
| time/                       |              |
|    fps                      | 144          |
|    iterations               | 33           |
|    time_elapsed             | 467          |
|    total_timesteps          | 2977792      |
| train/                      |              |
|    approx_kl                | 39461.316    |
|    approx_ln(kl)            | 10.5830765   |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.72         |
|    explained_variance       | 0.989        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 14530        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0378       |
|    value_loss               | 0.137        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6837942] |
| time/                       |              |
|    fps                      | 144          |
|    iterations               | 34           |
|    time_elapsed             | 481          |
|    total_timesteps          | 2979840      |
| train/                      |              |
|    approx_kl                | 16472.871    |
|    approx_ln(kl)            | 9.70947      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.72         |
|    explained_variance       | 0.94         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14540        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0377       |
|    value_loss               | 0.333        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5963425] |
| time/                       |              |
|    fps                      | 144          |
|    iterations               | 35           |
|    time_elapsed             | 494          |
|    total_timesteps          | 2981888      |
| train/                      |              |
|    approx_kl                | 3221.726     |
|    approx_ln(kl)            | 8.077673     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.72         |
|    explained_variance       | 0.976        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14550        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0378       |
|    value_loss               | 0.383        |
----------------------------------------------
-----------------------------------------------
| reward                      | [-0.63942236] |
| time/                       |               |
|    fps                      | 144           |
|    iterations               | 36            |
|    time_elapsed             | 508           |
|    total_timesteps          | 2983936       |
| train/                      |               |
|    approx_kl                | 8368.959      |
|    approx_ln(kl)            | 9.032285      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.72          |
|    explained_variance       | 0.893         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 14560         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0377        |
|    value_loss               | 3.12          |
-----------------------------------------------
-----------------------------------------------
| reward                      | [-0.45315477] |
| time/                       |               |
|    fps                      | 144           |
|    iterations               | 37            |
|    time_elapsed             | 522           |
|    total_timesteps          | 2985984       |
| train/                      |               |
|    approx_kl                | 22903.26      |
|    approx_ln(kl)            | 10.039035     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.73          |
|    explained_variance       | 0.886         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 14570         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0376        |
|    value_loss               | 1.21          |
-----------------------------------------------
----------------------------------------------
| reward                      | [-1.0139723] |
| time/                       |              |
|    fps                      | 144          |
|    iterations               | 38           |
|    time_elapsed             | 536          |
|    total_timesteps          | 2988032      |
| train/                      |              |
|    approx_kl                | 2465.8296    |
|    approx_ln(kl)            | 7.8102837    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.72         |
|    explained_variance       | 0.96         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 14580        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0378       |
|    value_loss               | 3.76         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6909793] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 39           |
|    time_elapsed             | 550          |
|    total_timesteps          | 2990080      |
| train/                      |              |
|    approx_kl                | 18044.465    |
|    approx_ln(kl)            | 9.800594     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.69         |
|    explained_variance       | 0.858        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14590        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0383       |
|    value_loss               | 0.467        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7188331] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 40           |
|    time_elapsed             | 564          |
|    total_timesteps          | 2992128      |
| train/                      |              |
|    approx_kl                | 16067.34     |
|    approx_ln(kl)            | 9.684544     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.7          |
|    explained_variance       | 0.976        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14600        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0381       |
|    value_loss               | 0.965        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.76072407] |
| time/                       |               |
|    fps                      | 145           |
|    iterations               | 41            |
|    time_elapsed             | 578           |
|    total_timesteps          | 2994176       |
| train/                      |               |
|    approx_kl                | 21444.371     |
|    approx_ln(kl)            | 9.973217      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.69          |
|    explained_variance       | 0.866         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 14610         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0383        |
|    value_loss               | 0.362         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.92542136] |
| time/                       |               |
|    fps                      | 145           |
|    iterations               | 42            |
|    time_elapsed             | 592           |
|    total_timesteps          | 2996224       |
| train/                      |               |
|    approx_kl                | 13416.192     |
|    approx_ln(kl)            | 9.504218      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.64          |
|    explained_variance       | 0.959         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 14620         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0392        |
|    value_loss               | 0.385         |
-----------------------------------------------
-----------------------------------------------
| reward                      | [-0.69003785] |
| time/                       |               |
|    fps                      | 145           |
|    iterations               | 43            |
|    time_elapsed             | 606           |
|    total_timesteps          | 2998272       |
| train/                      |               |
|    approx_kl                | 7856.952      |
|    approx_ln(kl)            | 8.969154      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.6           |
|    explained_variance       | 0.982         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 14630         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.04          |
|    value_loss               | 0.221         |
-----------------------------------------------
-----------------------------------------------
| reward                      | [-0.60441715] |
| time/                       |               |
|    fps                      | 145           |
|    iterations               | 44            |
|    time_elapsed             | 620           |
|    total_timesteps          | 3000320       |
| train/                      |               |
|    approx_kl                | 13046.104     |
|    approx_ln(kl)            | 9.476245      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.62          |
|    explained_variance       | 0.991         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 14640         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0396        |
|    value_loss               | 0.192         |
-----------------------------------------------
-----------------------------------------------
| reward                      | [-0.63702404] |
| time/                       |               |
|    fps                      | 144           |
|    iterations               | 45            |
|    time_elapsed             | 635           |
|    total_timesteps          | 3002368       |
| train/                      |               |
|    approx_kl                | 17683.412     |
|    approx_ln(kl)            | 9.780382      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.62          |
|    explained_variance       | 0.96          |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 14650         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0396        |
|    value_loss               | 0.324         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.75329137] |
| time/                       |               |
|    fps                      | 143           |
|    iterations               | 46            |
|    time_elapsed             | 654           |
|    total_timesteps          | 3004416       |
| train/                      |               |
|    approx_kl                | 29917.207     |
|    approx_ln(kl)            | 10.30619      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.63          |
|    explained_variance       | 0.962         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 14660         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0394        |
|    value_loss               | 0.241         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.46103352] |
| time/                       |               |
|    fps                      | 142           |
|    iterations               | 47            |
|    time_elapsed             | 676           |
|    total_timesteps          | 3006464       |
| train/                      |               |
|    approx_kl                | 10043.699     |
|    approx_ln(kl)            | 9.214701      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.63          |
|    explained_variance       | 0.97          |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 14670         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0395        |
|    value_loss               | 0.583         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.55024964] |
| time/                       |               |
|    fps                      | 141           |
|    iterations               | 48            |
|    time_elapsed             | 692           |
|    total_timesteps          | 3008512       |
| train/                      |               |
|    approx_kl                | 23763.848     |
|    approx_ln(kl)            | 10.075921     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.67          |
|    explained_variance       | 0.968         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 14680         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0386        |
|    value_loss               | 0.341         |
-----------------------------------------------
---------------------------------------------
| reward                      | [-0.555921] |
| time/                       |             |
|    fps                      | 141         |
|    iterations               | 49          |
|    time_elapsed             | 707         |
|    total_timesteps          | 3010560     |
| train/                      |             |
|    approx_kl                | 33190.527   |
|    approx_ln(kl)            | 10.41002    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.68        |
|    explained_variance       | 0.979       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | inf         |
|    loss                     | inf         |
|    n_updates                | 14690       |
|    policy_gradient_loss     | inf         |
|    std                      | 0.0385      |
|    value_loss               | 0.257       |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-------------------------------------
| reward             | [-0.9545216] |
| time/              |              |
|    fps             | 163          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 3012608      |
-------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.78327036] |
| time/                       |               |
|    fps                      | 154           |
|    iterations               | 2             |
|    time_elapsed             | 26            |
|    total_timesteps          | 3014656       |
| train/                      |               |
|    approx_kl                | 13011.191     |
|    approx_ln(kl)            | 9.473565      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.68          |
|    explained_variance       | 0.959         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 14710         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0385        |
|    value_loss               | 0.357         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.68534905] |
| time/                       |               |
|    fps                      | 152           |
|    iterations               | 3             |
|    time_elapsed             | 40            |
|    total_timesteps          | 3016704       |
| train/                      |               |
|    approx_kl                | 25325.428     |
|    approx_ln(kl)            | 10.1395645    |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.67          |
|    explained_variance       | 0.977         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 14720         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0387        |
|    value_loss               | 0.332         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.63546765] |
| time/                       |               |
|    fps                      | 150           |
|    iterations               | 4             |
|    time_elapsed             | 54            |
|    total_timesteps          | 3018752       |
| train/                      |               |
|    approx_kl                | 22347.514     |
|    approx_ln(kl)            | 10.01447      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.66          |
|    explained_variance       | 0.991         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 14730         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0388        |
|    value_loss               | 0.968         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.73278385] |
| time/                       |               |
|    fps                      | 150           |
|    iterations               | 5             |
|    time_elapsed             | 68            |
|    total_timesteps          | 3020800       |
| train/                      |               |
|    approx_kl                | 26059.95      |
|    approx_ln(kl)            | 10.168155     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.63          |
|    explained_variance       | 0.994         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 14740         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0394        |
|    value_loss               | 2.14          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.8356811] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 6            |
|    time_elapsed             | 81           |
|    total_timesteps          | 3022848      |
| train/                      |              |
|    approx_kl                | 4853.3115    |
|    approx_ln(kl)            | 8.487416     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.62         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14750        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0398       |
|    value_loss               | 3.31         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5063742] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 7            |
|    time_elapsed             | 96           |
|    total_timesteps          | 3024896      |
| train/                      |              |
|    approx_kl                | 13121.244    |
|    approx_ln(kl)            | 9.481988     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.58         |
|    explained_variance       | 0.966        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14760        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0405       |
|    value_loss               | 0.836        |
----------------------------------------------
----------------------------------------------
| reward                      | [-0.8009587] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 8            |
|    time_elapsed             | 109          |
|    total_timesteps          | 3026944      |
| train/                      |              |
|    approx_kl                | 6742.3506    |
|    approx_ln(kl)            | 8.816164     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.55         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 14770        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.041        |
|    value_loss               | 2.15         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.69279647] |
| time/                       |               |
|    fps                      | 148           |
|    iterations               | 9             |
|    time_elapsed             | 124           |
|    total_timesteps          | 3028992       |
| train/                      |               |
|    approx_kl                | 2475.7046     |
|    approx_ln(kl)            | 7.8142805     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.55          |
|    explained_variance       | 0.997         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 14780         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.041         |
|    value_loss               | 2.29          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-1.967993] |
| time/                       |             |
|    fps                      | 148         |
|    iterations               | 10          |
|    time_elapsed             | 137         |
|    total_timesteps          | 3031040     |
| train/                      |             |
|    approx_kl                | 3315.2607   |
|    approx_ln(kl)            | 8.106292    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.56        |
|    explained_variance       | 0.995       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 14790       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0408      |
|    value_loss               | 2.47        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.2836291] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 11           |
|    time_elapsed             | 151          |
|    total_timesteps          | 3033088      |
| train/                      |              |
|    approx_kl                | 6474.9824    |
|    approx_ln(kl)            | 8.7757015    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.57         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14800        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0406       |
|    value_loss               | 3.17         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.2685113] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 12           |
|    time_elapsed             | 165          |
|    total_timesteps          | 3035136      |
| train/                      |              |
|    approx_kl                | 2195.6084    |
|    approx_ln(kl)            | 7.6942143    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.58         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14810        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0405       |
|    value_loss               | 2.88         |
----------------------------------------------
-----------------------------------------------
| reward                      | [-0.78513664] |
| time/                       |               |
|    fps                      | 148           |
|    iterations               | 13            |
|    time_elapsed             | 179           |
|    total_timesteps          | 3037184       |
| train/                      |               |
|    approx_kl                | 11065.752     |
|    approx_ln(kl)            | 9.31161       |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.55          |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 14820         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.041         |
|    value_loss               | 2.01          |
-----------------------------------------------
----------------------------------------------
| reward                      | [-1.9779018] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 14           |
|    time_elapsed             | 192          |
|    total_timesteps          | 3039232      |
| train/                      |              |
|    approx_kl                | 17135.023    |
|    approx_ln(kl)            | 9.748879     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.56         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 14830        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0408       |
|    value_loss               | 1.43         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0095478] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 15           |
|    time_elapsed             | 206          |
|    total_timesteps          | 3041280      |
| train/                      |              |
|    approx_kl                | 7303.456     |
|    approx_ln(kl)            | 8.896103     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.57         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14840        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0407       |
|    value_loss               | 1.95         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.7164195] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 16           |
|    time_elapsed             | 220          |
|    total_timesteps          | 3043328      |
| train/                      |              |
|    approx_kl                | 4205.261     |
|    approx_ln(kl)            | 8.344091     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.56         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14850        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0408       |
|    value_loss               | 1.02         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.35777447] |
| time/                       |               |
|    fps                      | 148           |
|    iterations               | 17            |
|    time_elapsed             | 234           |
|    total_timesteps          | 3045376       |
| train/                      |               |
|    approx_kl                | 3918.3477     |
|    approx_ln(kl)            | 8.273425      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.53          |
|    explained_variance       | 0.996         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 14860         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0415        |
|    value_loss               | 2.74          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.1952573] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 18           |
|    time_elapsed             | 248          |
|    total_timesteps          | 3047424      |
| train/                      |              |
|    approx_kl                | 14745.473    |
|    approx_ln(kl)            | 9.598691     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.56         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14870        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.041        |
|    value_loss               | 1.35         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-1.651767] |
| time/                       |             |
|    fps                      | 148         |
|    iterations               | 19          |
|    time_elapsed             | 262         |
|    total_timesteps          | 3049472     |
| train/                      |             |
|    approx_kl                | 28668.924   |
|    approx_ln(kl)            | 10.263569   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.58        |
|    explained_variance       | 0.934       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 14880       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0404      |
|    value_loss               | 2.26        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.021507] |
| time/                       |             |
|    fps                      | 148         |
|    iterations               | 20          |
|    time_elapsed             | 276         |
|    total_timesteps          | 3051520     |
| train/                      |             |
|    approx_kl                | 1493.133    |
|    approx_ln(kl)            | 7.308632    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.58        |
|    explained_variance       | 0.959       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 14890       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0405      |
|    value_loss               | 5.54        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.50553405] |
| time/                       |               |
|    fps                      | 148           |
|    iterations               | 21            |
|    time_elapsed             | 289           |
|    total_timesteps          | 3053568       |
| train/                      |               |
|    approx_kl                | 3432.1428     |
|    approx_ln(kl)            | 8.14094       |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.62          |
|    explained_variance       | 0.972         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 14900         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0397        |
|    value_loss               | 2.3           |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.66603065] |
| time/                       |               |
|    fps                      | 148           |
|    iterations               | 22            |
|    time_elapsed             | 303           |
|    total_timesteps          | 3055616       |
| train/                      |               |
|    approx_kl                | 4341.215      |
|    approx_ln(kl)            | 8.37591       |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.61          |
|    explained_variance       | 0.986         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 14910         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0399        |
|    value_loss               | 6.7           |
-----------------------------------------------
----------------------------------------------
| reward                      | [-2.7987628] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 23           |
|    time_elapsed             | 317          |
|    total_timesteps          | 3057664      |
| train/                      |              |
|    approx_kl                | 2066.3794    |
|    approx_ln(kl)            | 7.6335535    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.62         |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 14920        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.04         |
|    value_loss               | 4.33         |
----------------------------------------------
----------------------------------------------
| reward                      | [-2.4696178] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 24           |
|    time_elapsed             | 331          |
|    total_timesteps          | 3059712      |
| train/                      |              |
|    approx_kl                | 1755.1836    |
|    approx_ln(kl)            | 7.470329     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.61         |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 14930        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.04         |
|    value_loss               | 4.09         |
----------------------------------------------
-----------------------------------------------
| reward                      | [-0.59943366] |
| time/                       |               |
|    fps                      | 147           |
|    iterations               | 25            |
|    time_elapsed             | 346           |
|    total_timesteps          | 3061760       |
| train/                      |               |
|    approx_kl                | 8820.073      |
|    approx_ln(kl)            | 9.084785      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.59          |
|    explained_variance       | 0.979         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 14940         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0403        |
|    value_loss               | 1.63          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.3035724] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 26           |
|    time_elapsed             | 360          |
|    total_timesteps          | 3063808      |
| train/                      |              |
|    approx_kl                | 3288.3516    |
|    approx_ln(kl)            | 8.098142     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.6          |
|    explained_variance       | 0.96         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14950        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0401       |
|    value_loss               | 10.2         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0045805] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 27           |
|    time_elapsed             | 373          |
|    total_timesteps          | 3065856      |
| train/                      |              |
|    approx_kl                | 4074.4707    |
|    approx_ln(kl)            | 8.312496     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.57         |
|    explained_variance       | 0.963        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14960        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0414       |
|    value_loss               | 3.63         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5312258] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 28           |
|    time_elapsed             | 387          |
|    total_timesteps          | 3067904      |
| train/                      |              |
|    approx_kl                | 5702.573     |
|    approx_ln(kl)            | 8.648673     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.53         |
|    explained_variance       | 0.984        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14970        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0418       |
|    value_loss               | 3.53         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7976035] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 29           |
|    time_elapsed             | 401          |
|    total_timesteps          | 3069952      |
| train/                      |              |
|    approx_kl                | 2608.6106    |
|    approx_ln(kl)            | 7.866573     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.52         |
|    explained_variance       | 0.969        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14980        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0416       |
|    value_loss               | 9.58         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6225988] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 30           |
|    time_elapsed             | 415          |
|    total_timesteps          | 3072000      |
| train/                      |              |
|    approx_kl                | 1406.2135    |
|    approx_ln(kl)            | 7.248656     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.5          |
|    explained_variance       | 0.976        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 14990        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0422       |
|    value_loss               | 6.9          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.9657778] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 31           |
|    time_elapsed             | 429          |
|    total_timesteps          | 3074048      |
| train/                      |              |
|    approx_kl                | 2090.405     |
|    approx_ln(kl)            | 7.645113     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.5          |
|    explained_variance       | 0.992        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15000        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0422       |
|    value_loss               | 1.83         |
----------------------------------------------
-----------------------------------------------
| reward                      | [-0.55307186] |
| time/                       |               |
|    fps                      | 147           |
|    iterations               | 32            |
|    time_elapsed             | 443           |
|    total_timesteps          | 3076096       |
| train/                      |               |
|    approx_kl                | 1941.2183     |
|    approx_ln(kl)            | 7.571071      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.49          |
|    explained_variance       | 0.971         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | inf           |
|    loss                     | inf           |
|    n_updates                | 15010         |
|    policy_gradient_loss     | inf           |
|    std                      | 0.0425        |
|    value_loss               | 5.1           |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.2892029] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 33           |
|    time_elapsed             | 456          |
|    total_timesteps          | 3078144      |
| train/                      |              |
|    approx_kl                | 5752.0435    |
|    approx_ln(kl)            | 8.6573105    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.49         |
|    explained_variance       | 0.984        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15020        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0433       |
|    value_loss               | 2.8          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.60658914] |
| time/                       |               |
|    fps                      | 147           |
|    iterations               | 34            |
|    time_elapsed             | 470           |
|    total_timesteps          | 3080192       |
| train/                      |               |
|    approx_kl                | 2663.358      |
|    approx_ln(kl)            | 7.887343      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.46          |
|    explained_variance       | 0.99          |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 15030         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0432        |
|    value_loss               | 5.88          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0476958] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 35           |
|    time_elapsed             | 484          |
|    total_timesteps          | 3082240      |
| train/                      |              |
|    approx_kl                | 1529.3079    |
|    approx_ln(kl)            | 7.3325706    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.43         |
|    explained_variance       | 0.979        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15040        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0437       |
|    value_loss               | 6.47         |
----------------------------------------------
----------------------------------------------
| reward                      | [-0.6200489] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 36           |
|    time_elapsed             | 498          |
|    total_timesteps          | 3084288      |
| train/                      |              |
|    approx_kl                | 2480.3384    |
|    approx_ln(kl)            | 7.81615      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.43         |
|    explained_variance       | 0.978        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 15050        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0438       |
|    value_loss               | 5.85         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0264825] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 37           |
|    time_elapsed             | 512          |
|    total_timesteps          | 3086336      |
| train/                      |              |
|    approx_kl                | 4540.0815    |
|    approx_ln(kl)            | 8.4207       |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.43         |
|    explained_variance       | 0.99         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15060        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0438       |
|    value_loss               | 2.72         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6462869] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 38           |
|    time_elapsed             | 526          |
|    total_timesteps          | 3088384      |
| train/                      |              |
|    approx_kl                | 6754.337     |
|    approx_ln(kl)            | 8.81794      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.43         |
|    explained_variance       | 0.987        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15070        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0438       |
|    value_loss               | 4.08         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.1005844] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 39           |
|    time_elapsed             | 539          |
|    total_timesteps          | 3090432      |
| train/                      |              |
|    approx_kl                | 6733.811     |
|    approx_ln(kl)            | 8.814897     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.4          |
|    explained_variance       | 0.99         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15080        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0447       |
|    value_loss               | 2.04         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6428019] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 40           |
|    time_elapsed             | 553          |
|    total_timesteps          | 3092480      |
| train/                      |              |
|    approx_kl                | 3291.2559    |
|    approx_ln(kl)            | 8.099025     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.41         |
|    explained_variance       | 0.989        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15090        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0441       |
|    value_loss               | 1.4          |
----------------------------------------------
----------------------------------------------
| reward                      | [-2.2116747] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 41           |
|    time_elapsed             | 567          |
|    total_timesteps          | 3094528      |
| train/                      |              |
|    approx_kl                | 2669.3418    |
|    approx_ln(kl)            | 7.8895874    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.42         |
|    explained_variance       | 0.715        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 15100        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0439       |
|    value_loss               | 26.9         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.3563597] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 42           |
|    time_elapsed             | 581          |
|    total_timesteps          | 3096576      |
| train/                      |              |
|    approx_kl                | 751.9403     |
|    approx_ln(kl)            | 6.622657     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.43         |
|    explained_variance       | 0.925        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15110        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0438       |
|    value_loss               | 28.7         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.2585387] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 43           |
|    time_elapsed             | 594          |
|    total_timesteps          | 3098624      |
| train/                      |              |
|    approx_kl                | 5376.966     |
|    approx_ln(kl)            | 8.58988      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.43         |
|    explained_variance       | 0.91         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15120        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.044        |
|    value_loss               | 12.1         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.843526] |
| time/                       |             |
|    fps                      | 148         |
|    iterations               | 44          |
|    time_elapsed             | 608         |
|    total_timesteps          | 3100672     |
| train/                      |             |
|    approx_kl                | 3885.1973   |
|    approx_ln(kl)            | 8.264929    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.43        |
|    explained_variance       | 0.954       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 15130       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0438      |
|    value_loss               | 14.8        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.7965353] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 45           |
|    time_elapsed             | 622          |
|    total_timesteps          | 3102720      |
| train/                      |              |
|    approx_kl                | 2718.0798    |
|    approx_ln(kl)            | 7.907681     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.42         |
|    explained_variance       | 0.977        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15140        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.044        |
|    value_loss               | 5.89         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.0767884] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 46           |
|    time_elapsed             | 636          |
|    total_timesteps          | 3104768      |
| train/                      |              |
|    approx_kl                | 5286.331     |
|    approx_ln(kl)            | 8.57288      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.43         |
|    explained_variance       | 0.977        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15150        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0436       |
|    value_loss               | 4.54         |
----------------------------------------------
----------------------------------------------
| reward                      | [-2.8306775] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 47           |
|    time_elapsed             | 650          |
|    total_timesteps          | 3106816      |
| train/                      |              |
|    approx_kl                | 21464.918    |
|    approx_ln(kl)            | 9.974175     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.42         |
|    explained_variance       | 0.989        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 15160        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.044        |
|    value_loss               | 3.9          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.7307544] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 48           |
|    time_elapsed             | 663          |
|    total_timesteps          | 3108864      |
| train/                      |              |
|    approx_kl                | 3155.3984    |
|    approx_ln(kl)            | 8.05687      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.44         |
|    explained_variance       | 0.988        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15170        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0435       |
|    value_loss               | 2.29         |
----------------------------------------------
---------------------------------------------
| reward                      | [-0.913253] |
| time/                       |             |
|    fps                      | 148         |
|    iterations               | 49          |
|    time_elapsed             | 677         |
|    total_timesteps          | 3110912     |
| train/                      |             |
|    approx_kl                | 1850.6936   |
|    approx_ln(kl)            | 7.523316    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.46        |
|    explained_variance       | 0.987       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | inf         |
|    loss                     | inf         |
|    n_updates                | 15180       |
|    policy_gradient_loss     | inf         |
|    std                      | 0.0431      |
|    value_loss               | 2.27        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-------------------------------------
| reward             | [-1.7067442] |
| time/              |              |
|    fps             | 160          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 3112960      |
-------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.9291759] |
| time/                       |              |
|    fps                      | 153          |
|    iterations               | 2            |
|    time_elapsed             | 26           |
|    total_timesteps          | 3115008      |
| train/                      |              |
|    approx_kl                | 9861.041     |
|    approx_ln(kl)            | 9.196347     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.48         |
|    explained_variance       | 0.99         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15200        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0429       |
|    value_loss               | 1.54         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.409076] |
| time/                       |             |
|    fps                      | 152         |
|    iterations               | 3           |
|    time_elapsed             | 40          |
|    total_timesteps          | 3117056     |
| train/                      |             |
|    approx_kl                | 5644.4805   |
|    approx_ln(kl)            | 8.638433    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.49        |
|    explained_variance       | 0.973       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 15210       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0424      |
|    value_loss               | 3.62        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.3776498] |
| time/                       |              |
|    fps                      | 150          |
|    iterations               | 4            |
|    time_elapsed             | 54           |
|    total_timesteps          | 3119104      |
| train/                      |              |
|    approx_kl                | 1020.24695   |
|    approx_ln(kl)            | 6.9278       |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.48         |
|    explained_variance       | 0.974        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15220        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0427       |
|    value_loss               | 1.94         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.3948545] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 5            |
|    time_elapsed             | 69           |
|    total_timesteps          | 3121152      |
| train/                      |              |
|    approx_kl                | 2430.608     |
|    approx_ln(kl)            | 7.7958965    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.47         |
|    explained_variance       | 0.972        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15230        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.043        |
|    value_loss               | 1.21         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.2946928] |
| time/                       |              |
|    fps                      | 101          |
|    iterations               | 6            |
|    time_elapsed             | 120          |
|    total_timesteps          | 3123200      |
| train/                      |              |
|    approx_kl                | 7404.3887    |
|    approx_ln(kl)            | 8.909828     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.46         |
|    explained_variance       | 0.986        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15240        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.043        |
|    value_loss               | 1.85         |
----------------------------------------------
----------------------------------------------
| reward                      | [-2.5011177] |
| time/                       |              |
|    fps                      | 104          |
|    iterations               | 7            |
|    time_elapsed             | 136          |
|    total_timesteps          | 3125248      |
| train/                      |              |
|    approx_kl                | 3845.01      |
|    approx_ln(kl)            | 8.254532     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.47         |
|    explained_variance       | 0.979        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 15250        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0428       |
|    value_loss               | 2.79         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.3352737] |
| time/                       |              |
|    fps                      | 107          |
|    iterations               | 8            |
|    time_elapsed             | 152          |
|    total_timesteps          | 3127296      |
| train/                      |              |
|    approx_kl                | 2140.238     |
|    approx_ln(kl)            | 7.6686726    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.46         |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15260        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.043        |
|    value_loss               | 0.871        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.3189952] |
| time/                       |              |
|    fps                      | 109          |
|    iterations               | 9            |
|    time_elapsed             | 168          |
|    total_timesteps          | 3129344      |
| train/                      |              |
|    approx_kl                | 2618.7085    |
|    approx_ln(kl)            | 7.8704367    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.43         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15270        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0436       |
|    value_loss               | 0.979        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.52716064] |
| time/                       |               |
|    fps                      | 111           |
|    iterations               | 10            |
|    time_elapsed             | 183           |
|    total_timesteps          | 3131392       |
| train/                      |               |
|    approx_kl                | 2637.4297     |
|    approx_ln(kl)            | 7.87756       |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.43          |
|    explained_variance       | 0.995         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 15280         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0435        |
|    value_loss               | 0.791         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.6228908] |
| time/                       |              |
|    fps                      | 78           |
|    iterations               | 11           |
|    time_elapsed             | 287          |
|    total_timesteps          | 3133440      |
| train/                      |              |
|    approx_kl                | 2212.5566    |
|    approx_ln(kl)            | 7.701904     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.42         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15290        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0437       |
|    value_loss               | 0.87         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.4908133] |
| time/                       |              |
|    fps                      | 81           |
|    iterations               | 12           |
|    time_elapsed             | 300          |
|    total_timesteps          | 3135488      |
| train/                      |              |
|    approx_kl                | 1347.1664    |
|    approx_ln(kl)            | 7.2057586    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.42         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15300        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0439       |
|    value_loss               | 0.774        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.8512492] |
| time/                       |              |
|    fps                      | 84           |
|    iterations               | 13           |
|    time_elapsed             | 314          |
|    total_timesteps          | 3137536      |
| train/                      |              |
|    approx_kl                | 2820.7476    |
|    approx_ln(kl)            | 7.9447575    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.4          |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15310        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0443       |
|    value_loss               | 0.544        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.0672417] |
| time/                       |              |
|    fps                      | 87           |
|    iterations               | 14           |
|    time_elapsed             | 328          |
|    total_timesteps          | 3139584      |
| train/                      |              |
|    approx_kl                | 1227.3999    |
|    approx_ln(kl)            | 7.1126533    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.39         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15320        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0445       |
|    value_loss               | 0.811        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.3757946] |
| time/                       |              |
|    fps                      | 89           |
|    iterations               | 15           |
|    time_elapsed             | 342          |
|    total_timesteps          | 3141632      |
| train/                      |              |
|    approx_kl                | 1842.5883    |
|    approx_ln(kl)            | 7.5189266    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.4          |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15330        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0435       |
|    value_loss               | 0.707        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.6469646] |
| time/                       |              |
|    fps                      | 91           |
|    iterations               | 16           |
|    time_elapsed             | 356          |
|    total_timesteps          | 3143680      |
| train/                      |              |
|    approx_kl                | 1423.781     |
|    approx_ln(kl)            | 7.261071     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.46         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15340        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0428       |
|    value_loss               | 0.608        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.093927] |
| time/                       |             |
|    fps                      | 94          |
|    iterations               | 17          |
|    time_elapsed             | 369         |
|    total_timesteps          | 3145728     |
| train/                      |             |
|    approx_kl                | 693.8085    |
|    approx_ln(kl)            | 6.542196    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.46        |
|    explained_variance       | 0.995       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 15350       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0429      |
|    value_loss               | 0.81        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.5457635] |
| time/                       |              |
|    fps                      | 96           |
|    iterations               | 18           |
|    time_elapsed             | 383          |
|    total_timesteps          | 3147776      |
| train/                      |              |
|    approx_kl                | 1099.4414    |
|    approx_ln(kl)            | 7.0025578    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.45         |
|    explained_variance       | 0.988        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15360        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0432       |
|    value_loss               | 1.07         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.3913023] |
| time/                       |              |
|    fps                      | 79           |
|    iterations               | 19           |
|    time_elapsed             | 489          |
|    total_timesteps          | 3149824      |
| train/                      |              |
|    approx_kl                | 1895.0417    |
|    approx_ln(kl)            | 7.546996     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.46         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15370        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0428       |
|    value_loss               | 0.713        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.47192737] |
| time/                       |               |
|    fps                      | 81            |
|    iterations               | 20            |
|    time_elapsed             | 503           |
|    total_timesteps          | 3151872       |
| train/                      |               |
|    approx_kl                | 3390.489      |
|    approx_ln(kl)            | 8.12873       |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.49          |
|    explained_variance       | 0.997         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 15380         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0421        |
|    value_loss               | 1.1           |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.56123704] |
| time/                       |               |
|    fps                      | 83            |
|    iterations               | 21            |
|    time_elapsed             | 517           |
|    total_timesteps          | 3153920       |
| train/                      |               |
|    approx_kl                | 2691.3142     |
|    approx_ln(kl)            | 7.8977847     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.51          |
|    explained_variance       | 0.997         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 15390         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0417        |
|    value_loss               | 1.3           |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.4647571] |
| time/                       |              |
|    fps                      | 84           |
|    iterations               | 22           |
|    time_elapsed             | 530          |
|    total_timesteps          | 3155968      |
| train/                      |              |
|    approx_kl                | 3809.9092    |
|    approx_ln(kl)            | 8.24536      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.52         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15400        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0418       |
|    value_loss               | 0.735        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.5547452] |
| time/                       |              |
|    fps                      | 86           |
|    iterations               | 23           |
|    time_elapsed             | 544          |
|    total_timesteps          | 3158016      |
| train/                      |              |
|    approx_kl                | 3607.746     |
|    approx_ln(kl)            | 8.190839     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.52         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15410        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0416       |
|    value_loss               | 1.62         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.469278] |
| time/                       |             |
|    fps                      | 87          |
|    iterations               | 24          |
|    time_elapsed             | 558         |
|    total_timesteps          | 3160064     |
| train/                      |             |
|    approx_kl                | 2560.4893   |
|    approx_ln(kl)            | 7.847954    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.51        |
|    explained_variance       | 0.995       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 15420       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.042       |
|    value_loss               | 1.56        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.052628] |
| time/                       |             |
|    fps                      | 89          |
|    iterations               | 25          |
|    time_elapsed             | 572         |
|    total_timesteps          | 3162112     |
| train/                      |             |
|    approx_kl                | 1842.1329   |
|    approx_ln(kl)            | 7.5186796   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.48        |
|    explained_variance       | 0.997       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 15430       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0425      |
|    value_loss               | 1.74        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.067072] |
| time/                       |             |
|    fps                      | 90          |
|    iterations               | 26          |
|    time_elapsed             | 586         |
|    total_timesteps          | 3164160     |
| train/                      |             |
|    approx_kl                | 3812.5374   |
|    approx_ln(kl)            | 8.24605     |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.48        |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 15440       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0426      |
|    value_loss               | 0.888       |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.1314502] |
| time/                       |              |
|    fps                      | 92           |
|    iterations               | 27           |
|    time_elapsed             | 600          |
|    total_timesteps          | 3166208      |
| train/                      |              |
|    approx_kl                | 1648.9132    |
|    approx_ln(kl)            | 7.4078717    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.48         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15450        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0424       |
|    value_loss               | 1.1          |
----------------------------------------------
----------------------------------------------
| reward                      | [-3.0510066] |
| time/                       |              |
|    fps                      | 93           |
|    iterations               | 28           |
|    time_elapsed             | 613          |
|    total_timesteps          | 3168256      |
| train/                      |              |
|    approx_kl                | 7940.506     |
|    approx_ln(kl)            | 8.9797325    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.44         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 15460        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0434       |
|    value_loss               | 1.17         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.0198505] |
| time/                       |              |
|    fps                      | 94           |
|    iterations               | 29           |
|    time_elapsed             | 627          |
|    total_timesteps          | 3170304      |
| train/                      |              |
|    approx_kl                | 1220.8239    |
|    approx_ln(kl)            | 7.107281     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.41         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15470        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.044        |
|    value_loss               | 0.749        |
----------------------------------------------
---------------------------------------------
| reward                      | [-2.977728] |
| time/                       |             |
|    fps                      | 95          |
|    iterations               | 30          |
|    time_elapsed             | 641         |
|    total_timesteps          | 3172352     |
| train/                      |             |
|    approx_kl                | 1888.8416   |
|    approx_ln(kl)            | 7.543719    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.42        |
|    explained_variance       | 0.997       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | inf         |
|    loss                     | inf         |
|    n_updates                | 15480       |
|    policy_gradient_loss     | inf         |
|    std                      | 0.0437      |
|    value_loss               | 0.834       |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-0.603355] |
| time/                       |             |
|    fps                      | 96          |
|    iterations               | 31          |
|    time_elapsed             | 655         |
|    total_timesteps          | 3174400     |
| train/                      |             |
|    approx_kl                | 2434.0918   |
|    approx_ln(kl)            | 7.797329    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.45        |
|    explained_variance       | 0.996       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 15490       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0432      |
|    value_loss               | 0.724       |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.9747604] |
| time/                       |              |
|    fps                      | 97           |
|    iterations               | 32           |
|    time_elapsed             | 669          |
|    total_timesteps          | 3176448      |
| train/                      |              |
|    approx_kl                | 2246.5024    |
|    approx_ln(kl)            | 7.7171297    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.46         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15500        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0429       |
|    value_loss               | 1.45         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.6395602] |
| time/                       |              |
|    fps                      | 98           |
|    iterations               | 33           |
|    time_elapsed             | 683          |
|    total_timesteps          | 3178496      |
| train/                      |              |
|    approx_kl                | 12409.92     |
|    approx_ln(kl)            | 9.426251     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.47         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15510        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0429       |
|    value_loss               | 0.463        |
----------------------------------------------
----------------------------------------------
| reward                      | [-2.5592384] |
| time/                       |              |
|    fps                      | 99           |
|    iterations               | 34           |
|    time_elapsed             | 698          |
|    total_timesteps          | 3180544      |
| train/                      |              |
|    approx_kl                | 1529.9644    |
|    approx_ln(kl)            | 7.3329997    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.48         |
|    explained_variance       | 0.983        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 15520        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0425       |
|    value_loss               | 2.59         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.2503061] |
| time/                       |              |
|    fps                      | 100          |
|    iterations               | 35           |
|    time_elapsed             | 712          |
|    total_timesteps          | 3182592      |
| train/                      |              |
|    approx_kl                | 1493.9799    |
|    approx_ln(kl)            | 7.309199     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.47         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15530        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0428       |
|    value_loss               | 1.47         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.1286638] |
| time/                       |              |
|    fps                      | 101          |
|    iterations               | 36           |
|    time_elapsed             | 725          |
|    total_timesteps          | 3184640      |
| train/                      |              |
|    approx_kl                | 1323.3672    |
|    approx_ln(kl)            | 7.187935     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.52         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15540        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0416       |
|    value_loss               | 1.51         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
--------------------------------------------
| reward                      | [-3.41208] |
| time/                       |            |
|    fps                      | 102        |
|    iterations               | 37         |
|    time_elapsed             | 740        |
|    total_timesteps          | 3186688    |
| train/                      |            |
|    approx_kl                | 1815.6333  |
|    approx_ln(kl)            | 7.5041895  |
|    clip_range               | 0.2        |
|    entropy_loss             | 3.46       |
|    explained_variance       | 0.997      |
|    learning_rate            | 0.001      |
|    ln(loss)                 | inf        |
|    ln(policy_gradient_loss) | nan        |
|    loss                     | inf        |
|    n_updates                | 15550      |
|    policy_gradient_loss     | nan        |
|    std                      | 0.0431     |
|    value_loss               | 1.25       |
--------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.4177656] |
| time/                       |              |
|    fps                      | 103          |
|    iterations               | 38           |
|    time_elapsed             | 754          |
|    total_timesteps          | 3188736      |
| train/                      |              |
|    approx_kl                | 3049.0203    |
|    approx_ln(kl)            | 8.022575     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.44         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15560        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0434       |
|    value_loss               | 2.01         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.703476] |
| time/                       |             |
|    fps                      | 103         |
|    iterations               | 39          |
|    time_elapsed             | 768         |
|    total_timesteps          | 3190784     |
| train/                      |             |
|    approx_kl                | 1804.1875   |
|    approx_ln(kl)            | 7.4978657   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.42        |
|    explained_variance       | 0.997       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 15570       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0439      |
|    value_loss               | 1.35        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.4063246] |
| time/                       |              |
|    fps                      | 104          |
|    iterations               | 40           |
|    time_elapsed             | 782          |
|    total_timesteps          | 3192832      |
| train/                      |              |
|    approx_kl                | 1813.3953    |
|    approx_ln(kl)            | 7.5029564    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.39         |
|    explained_variance       | 0.987        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15580        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0444       |
|    value_loss               | 3.87         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.37373626] |
| time/                       |               |
|    fps                      | 105           |
|    iterations               | 41            |
|    time_elapsed             | 796           |
|    total_timesteps          | 3194880       |
| train/                      |               |
|    approx_kl                | 6554.4424     |
|    approx_ln(kl)            | 8.787898      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.38          |
|    explained_variance       | 0.995         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 15590         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0445        |
|    value_loss               | 1.53          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-0.769107] |
| time/                       |             |
|    fps                      | 106         |
|    iterations               | 42          |
|    time_elapsed             | 810         |
|    total_timesteps          | 3196928     |
| train/                      |             |
|    approx_kl                | 4520.8086   |
|    approx_ln(kl)            | 8.416446    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.4         |
|    explained_variance       | 0.997       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 15600       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0442      |
|    value_loss               | 0.779       |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.1912777] |
| time/                       |              |
|    fps                      | 106          |
|    iterations               | 43           |
|    time_elapsed             | 824          |
|    total_timesteps          | 3198976      |
| train/                      |              |
|    approx_kl                | 1946.5684    |
|    approx_ln(kl)            | 7.5738235    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.4          |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15610        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0441       |
|    value_loss               | 1.08         |
----------------------------------------------
----------------------------------------------
| reward                      | [-2.8173141] |
| time/                       |              |
|    fps                      | 107          |
|    iterations               | 44           |
|    time_elapsed             | 838          |
|    total_timesteps          | 3201024      |
| train/                      |              |
|    approx_kl                | 1835.6355    |
|    approx_ln(kl)            | 7.5151463    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.4          |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 15620        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0443       |
|    value_loss               | 0.97         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.3418002] |
| time/                       |              |
|    fps                      | 108          |
|    iterations               | 45           |
|    time_elapsed             | 851          |
|    total_timesteps          | 3203072      |
| train/                      |              |
|    approx_kl                | 2188.856     |
|    approx_ln(kl)            | 7.6911345    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.41         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15630        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.044        |
|    value_loss               | 1.06         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.4613554] |
| time/                       |              |
|    fps                      | 108          |
|    iterations               | 46           |
|    time_elapsed             | 865          |
|    total_timesteps          | 3205120      |
| train/                      |              |
|    approx_kl                | 5511.967     |
|    approx_ln(kl)            | 8.614676     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.41         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15640        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.044        |
|    value_loss               | 0.896        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.2565563] |
| time/                       |              |
|    fps                      | 109          |
|    iterations               | 47           |
|    time_elapsed             | 879          |
|    total_timesteps          | 3207168      |
| train/                      |              |
|    approx_kl                | 901.0367     |
|    approx_ln(kl)            | 6.803546     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.4          |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15650        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0443       |
|    value_loss               | 0.944        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.7079016] |
| time/                       |              |
|    fps                      | 110          |
|    iterations               | 48           |
|    time_elapsed             | 893          |
|    total_timesteps          | 3209216      |
| train/                      |              |
|    approx_kl                | 891.21936    |
|    approx_ln(kl)            | 6.7925906    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.37         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15660        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0451       |
|    value_loss               | 0.65         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.80055207] |
| time/                       |               |
|    fps                      | 110           |
|    iterations               | 49            |
|    time_elapsed             | 907           |
|    total_timesteps          | 3211264       |
| train/                      |               |
|    approx_kl                | 10643.332     |
|    approx_ln(kl)            | 9.272689      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.35          |
|    explained_variance       | 0.99          |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 15670         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0453        |
|    value_loss               | 2.43          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-------------------------------------
| reward             | [-2.5917745] |
| time/              |              |
|    fps             | 155          |
|    iterations      | 1            |
|    time_elapsed    | 13           |
|    total_timesteps | 3213312      |
-------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.0388556] |
| time/                       |              |
|    fps                      | 152          |
|    iterations               | 2            |
|    time_elapsed             | 26           |
|    total_timesteps          | 3215360      |
| train/                      |              |
|    approx_kl                | 3450.6355    |
|    approx_ln(kl)            | 8.146314     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.33         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15690        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0458       |
|    value_loss               | 3.06         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5794719] |
| time/                       |              |
|    fps                      | 151          |
|    iterations               | 3            |
|    time_elapsed             | 40           |
|    total_timesteps          | 3217408      |
| train/                      |              |
|    approx_kl                | 2383.188     |
|    approx_ln(kl)            | 7.7761946    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.33         |
|    explained_variance       | 0.972        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15700        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0459       |
|    value_loss               | 5.72         |
----------------------------------------------
----------------------------------------------
| reward                      | [-1.1176214] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 4            |
|    time_elapsed             | 54           |
|    total_timesteps          | 3219456      |
| train/                      |              |
|    approx_kl                | 3354.7393    |
|    approx_ln(kl)            | 8.11813      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.32         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 15710        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0459       |
|    value_loss               | 2.87         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.95247954] |
| time/                       |               |
|    fps                      | 149           |
|    iterations               | 5             |
|    time_elapsed             | 68            |
|    total_timesteps          | 3221504       |
| train/                      |               |
|    approx_kl                | 2497.3225     |
|    approx_ln(kl)            | 7.822974      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.34          |
|    explained_variance       | 0.996         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 15720         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0454        |
|    value_loss               | 1.51          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.59455377] |
| time/                       |               |
|    fps                      | 149           |
|    iterations               | 6             |
|    time_elapsed             | 82            |
|    total_timesteps          | 3223552       |
| train/                      |               |
|    approx_kl                | 5379.217      |
|    approx_ln(kl)            | 8.590298      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.32          |
|    explained_variance       | 0.991         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 15730         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0468        |
|    value_loss               | 2.6           |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.85694855] |
| time/                       |               |
|    fps                      | 149           |
|    iterations               | 7             |
|    time_elapsed             | 96            |
|    total_timesteps          | 3225600       |
| train/                      |               |
|    approx_kl                | 5439.448      |
|    approx_ln(kl)            | 8.601433      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.27          |
|    explained_variance       | 0.979         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 15740         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0473        |
|    value_loss               | 1.59          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.79305077] |
| time/                       |               |
|    fps                      | 149           |
|    iterations               | 8             |
|    time_elapsed             | 109           |
|    total_timesteps          | 3227648       |
| train/                      |               |
|    approx_kl                | 8277.469      |
|    approx_ln(kl)            | 9.021293      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.26          |
|    explained_variance       | 0.989         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 15750         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0472        |
|    value_loss               | 1.55          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.64309174] |
| time/                       |               |
|    fps                      | 149           |
|    iterations               | 9             |
|    time_elapsed             | 123           |
|    total_timesteps          | 3229696       |
| train/                      |               |
|    approx_kl                | 2873.7227     |
|    approx_ln(kl)            | 7.9633636     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.25          |
|    explained_variance       | 0.956         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 15760         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0476        |
|    value_loss               | 1.66          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-0.773791] |
| time/                       |             |
|    fps                      | 149         |
|    iterations               | 10          |
|    time_elapsed             | 137         |
|    total_timesteps          | 3231744     |
| train/                      |             |
|    approx_kl                | 3817.2373   |
|    approx_ln(kl)            | 8.247282    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.25        |
|    explained_variance       | 0.965       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 15770       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0476      |
|    value_loss               | 1.39        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.80647314] |
| time/                       |               |
|    fps                      | 149           |
|    iterations               | 11            |
|    time_elapsed             | 151           |
|    total_timesteps          | 3233792       |
| train/                      |               |
|    approx_kl                | 3930.3523     |
|    approx_ln(kl)            | 8.2764845     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.27          |
|    explained_variance       | 0.993         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 15780         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.047         |
|    value_loss               | 2.27          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.4334092] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 12           |
|    time_elapsed             | 164          |
|    total_timesteps          | 3235840      |
| train/                      |              |
|    approx_kl                | 3053.67      |
|    approx_ln(kl)            | 8.024099     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.26         |
|    explained_variance       | 0.928        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15790        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0475       |
|    value_loss               | 0.789        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.35004634] |
| time/                       |               |
|    fps                      | 149           |
|    iterations               | 13            |
|    time_elapsed             | 178           |
|    total_timesteps          | 3237888       |
| train/                      |               |
|    approx_kl                | 2611.639      |
|    approx_ln(kl)            | 7.8677335     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.22          |
|    explained_variance       | 0.997         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 15800         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0484        |
|    value_loss               | 3.86          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.96402836] |
| time/                       |               |
|    fps                      | 148           |
|    iterations               | 14            |
|    time_elapsed             | 192           |
|    total_timesteps          | 3239936       |
| train/                      |               |
|    approx_kl                | 2484.3655     |
|    approx_ln(kl)            | 7.8177724     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.25          |
|    explained_variance       | 0.943         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 15810         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0475        |
|    value_loss               | 27.1          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.030832] |
| time/                       |             |
|    fps                      | 148         |
|    iterations               | 15          |
|    time_elapsed             | 206         |
|    total_timesteps          | 3241984     |
| train/                      |             |
|    approx_kl                | 725.6533    |
|    approx_ln(kl)            | 6.5870724   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.23        |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 15820       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0483      |
|    value_loss               | 2.19        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.6559608] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 16           |
|    time_elapsed             | 220          |
|    total_timesteps          | 3244032      |
| train/                      |              |
|    approx_kl                | 889.8207     |
|    approx_ln(kl)            | 6.79102      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.21         |
|    explained_variance       | 0.92         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15830        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0486       |
|    value_loss               | 22.3         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.0301335] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 17           |
|    time_elapsed             | 234          |
|    total_timesteps          | 3246080      |
| train/                      |              |
|    approx_kl                | 5920.798     |
|    approx_ln(kl)            | 8.686227     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.22         |
|    explained_variance       | 0.98         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15840        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0483       |
|    value_loss               | 13.8         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.400802] |
| time/                       |             |
|    fps                      | 142         |
|    iterations               | 18          |
|    time_elapsed             | 258         |
|    total_timesteps          | 3248128     |
| train/                      |             |
|    approx_kl                | 807.90894   |
|    approx_ln(kl)            | 6.6944494   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.24        |
|    explained_variance       | 0.992       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 15850       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0479      |
|    value_loss               | 7.13        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.7242422] |
| time/                       |              |
|    fps                      | 142          |
|    iterations               | 19           |
|    time_elapsed             | 272          |
|    total_timesteps          | 3250176      |
| train/                      |              |
|    approx_kl                | 843.01904    |
|    approx_ln(kl)            | 6.7369895    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.27         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15860        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0471       |
|    value_loss               | 4.89         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.9809394] |
| time/                       |              |
|    fps                      | 143          |
|    iterations               | 20           |
|    time_elapsed             | 285          |
|    total_timesteps          | 3252224      |
| train/                      |              |
|    approx_kl                | 1328.3193    |
|    approx_ln(kl)            | 7.19167      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.26         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15870        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0474       |
|    value_loss               | 4.38         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.014138] |
| time/                       |             |
|    fps                      | 143         |
|    iterations               | 21          |
|    time_elapsed             | 299         |
|    total_timesteps          | 3254272     |
| train/                      |             |
|    approx_kl                | 823.09015   |
|    approx_ln(kl)            | 6.7130656   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.26        |
|    explained_variance       | 0.997       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 15880       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0474      |
|    value_loss               | 3.62        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.8608203] |
| time/                       |              |
|    fps                      | 143          |
|    iterations               | 22           |
|    time_elapsed             | 313          |
|    total_timesteps          | 3256320      |
| train/                      |              |
|    approx_kl                | 2795.245     |
|    approx_ln(kl)            | 7.935675     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.28         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15890        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0469       |
|    value_loss               | 3.44         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.8315144] |
| time/                       |              |
|    fps                      | 143          |
|    iterations               | 23           |
|    time_elapsed             | 327          |
|    total_timesteps          | 3258368      |
| train/                      |              |
|    approx_kl                | 2632.276     |
|    approx_ln(kl)            | 7.875604     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.27         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15900        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0472       |
|    value_loss               | 2.1          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.37508306] |
| time/                       |               |
|    fps                      | 144           |
|    iterations               | 24            |
|    time_elapsed             | 341           |
|    total_timesteps          | 3260416       |
| train/                      |               |
|    approx_kl                | 2300.2993     |
|    approx_ln(kl)            | 7.7407947     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.3           |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 15910         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0462        |
|    value_loss               | 1.79          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.2229671] |
| time/                       |              |
|    fps                      | 144          |
|    iterations               | 25           |
|    time_elapsed             | 354          |
|    total_timesteps          | 3262464      |
| train/                      |              |
|    approx_kl                | 4390.9243    |
|    approx_ln(kl)            | 8.387295     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.29         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15920        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0468       |
|    value_loss               | 2.66         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.3521285] |
| time/                       |              |
|    fps                      | 144          |
|    iterations               | 26           |
|    time_elapsed             | 368          |
|    total_timesteps          | 3264512      |
| train/                      |              |
|    approx_kl                | 718.2103     |
|    approx_ln(kl)            | 6.5767627    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.29         |
|    explained_variance       | 0.916        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15930        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0466       |
|    value_loss               | 58.3         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.9332957] |
| time/                       |              |
|    fps                      | 144          |
|    iterations               | 27           |
|    time_elapsed             | 382          |
|    total_timesteps          | 3266560      |
| train/                      |              |
|    approx_kl                | 1073.4159    |
|    approx_ln(kl)            | 6.9786015    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.28         |
|    explained_variance       | 0.918        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15940        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.047        |
|    value_loss               | 24.6         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.6861153] |
| time/                       |              |
|    fps                      | 144          |
|    iterations               | 28           |
|    time_elapsed             | 396          |
|    total_timesteps          | 3268608      |
| train/                      |              |
|    approx_kl                | 2236.3638    |
|    approx_ln(kl)            | 7.7126064    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.31         |
|    explained_variance       | 0.962        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15950        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.046        |
|    value_loss               | 8.81         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.090592] |
| time/                       |             |
|    fps                      | 144         |
|    iterations               | 29          |
|    time_elapsed             | 410         |
|    total_timesteps          | 3270656     |
| train/                      |             |
|    approx_kl                | 661.5748    |
|    approx_ln(kl)            | 6.494623    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.34        |
|    explained_variance       | 0.933       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 15960       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0454      |
|    value_loss               | 18.9        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.860511] |
| time/                       |             |
|    fps                      | 144         |
|    iterations               | 30          |
|    time_elapsed             | 424         |
|    total_timesteps          | 3272704     |
| train/                      |             |
|    approx_kl                | 1352.5527   |
|    approx_ln(kl)            | 7.209749    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.35        |
|    explained_variance       | 0.892       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 15970       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0453      |
|    value_loss               | 21          |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.6006765] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 31           |
|    time_elapsed             | 437          |
|    total_timesteps          | 3274752      |
| train/                      |              |
|    approx_kl                | 1063.2195    |
|    approx_ln(kl)            | 6.969057     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.35         |
|    explained_variance       | 0.886        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 15980        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0452       |
|    value_loss               | 22           |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.430921] |
| time/                       |             |
|    fps                      | 145         |
|    iterations               | 32          |
|    time_elapsed             | 451         |
|    total_timesteps          | 3276800     |
| train/                      |             |
|    approx_kl                | 914.5664    |
|    approx_ln(kl)            | 6.81845     |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.36        |
|    explained_variance       | 0.952       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 15990       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0451      |
|    value_loss               | 19.3        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.3445277] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 33           |
|    time_elapsed             | 465          |
|    total_timesteps          | 3278848      |
| train/                      |              |
|    approx_kl                | 3557.1248    |
|    approx_ln(kl)            | 8.176708     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.38         |
|    explained_variance       | 0.974        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16000        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0445       |
|    value_loss               | 9.61         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.61740094] |
| time/                       |               |
|    fps                      | 145           |
|    iterations               | 34            |
|    time_elapsed             | 480           |
|    total_timesteps          | 3280896       |
| train/                      |               |
|    approx_kl                | 852.2997      |
|    approx_ln(kl)            | 6.747938      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.38          |
|    explained_variance       | 0.987         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 16010         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0446        |
|    value_loss               | 9.13          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-1.073435] |
| time/                       |             |
|    fps                      | 145         |
|    iterations               | 35          |
|    time_elapsed             | 493         |
|    total_timesteps          | 3282944     |
| train/                      |             |
|    approx_kl                | 1332.9524   |
|    approx_ln(kl)            | 7.195152    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.37        |
|    explained_variance       | 0.988       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 16020       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.045       |
|    value_loss               | 8.03        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.3497376] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 36           |
|    time_elapsed             | 507          |
|    total_timesteps          | 3284992      |
| train/                      |              |
|    approx_kl                | 813.76105    |
|    approx_ln(kl)            | 6.701667     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.35         |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16030        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0456       |
|    value_loss               | 3.2          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.6674938] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 37           |
|    time_elapsed             | 521          |
|    total_timesteps          | 3287040      |
| train/                      |              |
|    approx_kl                | 6023.0776    |
|    approx_ln(kl)            | 8.703354     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.34         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16040        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0457       |
|    value_loss               | 2.82         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.4771175] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 38           |
|    time_elapsed             | 535          |
|    total_timesteps          | 3289088      |
| train/                      |              |
|    approx_kl                | 3211.2817    |
|    approx_ln(kl)            | 8.074426     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.35         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16050        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0452       |
|    value_loss               | 1.52         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.3676236] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 39           |
|    time_elapsed             | 549          |
|    total_timesteps          | 3291136      |
| train/                      |              |
|    approx_kl                | 1793.9673    |
|    approx_ln(kl)            | 7.4921846    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.37         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16060        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.045        |
|    value_loss               | 1.22         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.4996815] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 40           |
|    time_elapsed             | 563          |
|    total_timesteps          | 3293184      |
| train/                      |              |
|    approx_kl                | 1844.4221    |
|    approx_ln(kl)            | 7.5199213    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.37         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16070        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0449       |
|    value_loss               | 7.12         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
--------------------------------------------
| reward                      | [-3.90257] |
| time/                       |            |
|    fps                      | 145        |
|    iterations               | 41         |
|    time_elapsed             | 577        |
|    total_timesteps          | 3295232    |
| train/                      |            |
|    approx_kl                | 4628.536   |
|    approx_ln(kl)            | 8.439996   |
|    clip_range               | 0.2        |
|    entropy_loss             | 3.39       |
|    explained_variance       | 0.991      |
|    learning_rate            | 0.001      |
|    ln(loss)                 | inf        |
|    ln(policy_gradient_loss) | nan        |
|    loss                     | inf        |
|    n_updates                | 16080      |
|    policy_gradient_loss     | nan        |
|    std                      | 0.0449     |
|    value_loss               | 7.29       |
--------------------------------------------
----------------------------------------------
| reward                      | [-4.6117024] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 42           |
|    time_elapsed             | 591          |
|    total_timesteps          | 3297280      |
| train/                      |              |
|    approx_kl                | 353.33246    |
|    approx_ln(kl)            | 5.867409     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.4          |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 16090        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0443       |
|    value_loss               | 5.84         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.8536415] |
| time/                       |              |
|    fps                      | 144          |
|    iterations               | 43           |
|    time_elapsed             | 607          |
|    total_timesteps          | 3299328      |
| train/                      |              |
|    approx_kl                | 630.8401     |
|    approx_ln(kl)            | 6.4470525    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.4          |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16100        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0442       |
|    value_loss               | 7.04         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.54082894] |
| time/                       |               |
|    fps                      | 145           |
|    iterations               | 44            |
|    time_elapsed             | 621           |
|    total_timesteps          | 3301376       |
| train/                      |               |
|    approx_kl                | 919.01044     |
|    approx_ln(kl)            | 6.8232975     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.4           |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 16110         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0442        |
|    value_loss               | 5.01          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.2899389] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 45           |
|    time_elapsed             | 634          |
|    total_timesteps          | 3303424      |
| train/                      |              |
|    approx_kl                | 1030.7622    |
|    approx_ln(kl)            | 6.9380536    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.4          |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16120        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0444       |
|    value_loss               | 4.74         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.3868504] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 46           |
|    time_elapsed             | 648          |
|    total_timesteps          | 3305472      |
| train/                      |              |
|    approx_kl                | 4565.192     |
|    approx_ln(kl)            | 8.426216     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.38         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16130        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0446       |
|    value_loss               | 2.64         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.7669973] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 47           |
|    time_elapsed             | 662          |
|    total_timesteps          | 3307520      |
| train/                      |              |
|    approx_kl                | 1496.7281    |
|    approx_ln(kl)            | 7.3110366    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.38         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16140        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0448       |
|    value_loss               | 4.1          |
----------------------------------------------
----------------------------------------------
| reward                      | [-3.4057546] |
| time/                       |              |
|    fps                      | 145          |
|    iterations               | 48           |
|    time_elapsed             | 676          |
|    total_timesteps          | 3309568      |
| train/                      |              |
|    approx_kl                | 2466.5393    |
|    approx_ln(kl)            | 7.810571     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.36         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 16150        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0452       |
|    value_loss               | 6.37         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.871438] |
| time/                       |             |
|    fps                      | 131         |
|    iterations               | 49          |
|    time_elapsed             | 762         |
|    total_timesteps          | 3311616     |
| train/                      |             |
|    approx_kl                | 709.8556    |
|    approx_ln(kl)            | 6.5650616   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.36        |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 16160       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0452      |
|    value_loss               | 2.67        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
------------------------------------
| reward             | [-4.172429] |
| time/              |             |
|    fps             | 148         |
|    iterations      | 1           |
|    time_elapsed    | 13          |
|    total_timesteps | 3313664     |
------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.426024] |
| time/                       |             |
|    fps                      | 142         |
|    iterations               | 2           |
|    time_elapsed             | 28          |
|    total_timesteps          | 3315712     |
| train/                      |             |
|    approx_kl                | 2523.7993   |
|    approx_ln(kl)            | 7.833521    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.36        |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 16180       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0453      |
|    value_loss               | 2.85        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.6520967] |
| time/                       |              |
|    fps                      | 127          |
|    iterations               | 3            |
|    time_elapsed             | 48           |
|    total_timesteps          | 3317760      |
| train/                      |              |
|    approx_kl                | 2892.4412    |
|    approx_ln(kl)            | 7.9698563    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.36         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16190        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0451       |
|    value_loss               | 4.47         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.6447406] |
| time/                       |              |
|    fps                      | 123          |
|    iterations               | 4            |
|    time_elapsed             | 66           |
|    total_timesteps          | 3319808      |
| train/                      |              |
|    approx_kl                | 2923.2952    |
|    approx_ln(kl)            | 7.980467     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.36         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16200        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0452       |
|    value_loss               | 2.52         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.7838793] |
| time/                       |              |
|    fps                      | 126          |
|    iterations               | 5            |
|    time_elapsed             | 81           |
|    total_timesteps          | 3321856      |
| train/                      |              |
|    approx_kl                | 6129.1367    |
|    approx_ln(kl)            | 8.720809     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.34         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16210        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0461       |
|    value_loss               | 2.51         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.8789249] |
| time/                       |              |
|    fps                      | 101          |
|    iterations               | 6            |
|    time_elapsed             | 120          |
|    total_timesteps          | 3323904      |
| train/                      |              |
|    approx_kl                | 3130.9688    |
|    approx_ln(kl)            | 8.049098     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.32         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16220        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.046        |
|    value_loss               | 1.84         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.7010059] |
| time/                       |              |
|    fps                      | 105          |
|    iterations               | 7            |
|    time_elapsed             | 136          |
|    total_timesteps          | 3325952      |
| train/                      |              |
|    approx_kl                | 2695.919     |
|    approx_ln(kl)            | 7.8994946    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.38         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16230        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0447       |
|    value_loss               | 3.03         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.3561554] |
| time/                       |              |
|    fps                      | 105          |
|    iterations               | 8            |
|    time_elapsed             | 154          |
|    total_timesteps          | 3328000      |
| train/                      |              |
|    approx_kl                | 4394.2837    |
|    approx_ln(kl)            | 8.38806      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.37         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16240        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0451       |
|    value_loss               | 2.03         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.0738208] |
| time/                       |              |
|    fps                      | 108          |
|    iterations               | 9            |
|    time_elapsed             | 169          |
|    total_timesteps          | 3330048      |
| train/                      |              |
|    approx_kl                | 2727.5479    |
|    approx_ln(kl)            | 7.911158     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.36         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16250        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.045        |
|    value_loss               | 2.83         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.468504] |
| time/                       |             |
|    fps                      | 75          |
|    iterations               | 10          |
|    time_elapsed             | 273         |
|    total_timesteps          | 3332096     |
| train/                      |             |
|    approx_kl                | 1258.5264   |
|    approx_ln(kl)            | 7.1376967   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.38        |
|    explained_variance       | 0.996       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 16260       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0449      |
|    value_loss               | 5.89        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.4433126] |
| time/                       |              |
|    fps                      | 77           |
|    iterations               | 11           |
|    time_elapsed             | 289          |
|    total_timesteps          | 3334144      |
| train/                      |              |
|    approx_kl                | 2550.4893    |
|    approx_ln(kl)            | 7.8440404    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.37         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16270        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0451       |
|    value_loss               | 3.93         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.7457392] |
| time/                       |              |
|    fps                      | 80           |
|    iterations               | 12           |
|    time_elapsed             | 305          |
|    total_timesteps          | 3336192      |
| train/                      |              |
|    approx_kl                | 842.94434    |
|    approx_ln(kl)            | 6.736901     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.36         |
|    explained_variance       | 0.987        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16280        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0451       |
|    value_loss               | 15.5         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.294555] |
| time/                       |             |
|    fps                      | 82          |
|    iterations               | 13          |
|    time_elapsed             | 321         |
|    total_timesteps          | 3338240     |
| train/                      |             |
|    approx_kl                | 380.60443   |
|    approx_ln(kl)            | 5.9417605   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.37        |
|    explained_variance       | 0.993       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 16290       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0451      |
|    value_loss               | 6.38        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.507915] |
| time/                       |             |
|    fps                      | 84          |
|    iterations               | 14          |
|    time_elapsed             | 337         |
|    total_timesteps          | 3340288     |
| train/                      |             |
|    approx_kl                | 1077.1755   |
|    approx_ln(kl)            | 6.9820976   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.38        |
|    explained_variance       | 0.997       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 16300       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0448      |
|    value_loss               | 4.69        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.440352] |
| time/                       |             |
|    fps                      | 86          |
|    iterations               | 15          |
|    time_elapsed             | 353         |
|    total_timesteps          | 3342336     |
| train/                      |             |
|    approx_kl                | 1095.5415   |
|    approx_ln(kl)            | 6.999004    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.38        |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 16310       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0447      |
|    value_loss               | 6.04        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5707621] |
| time/                       |              |
|    fps                      | 88           |
|    iterations               | 16           |
|    time_elapsed             | 369          |
|    total_timesteps          | 3344384      |
| train/                      |              |
|    approx_kl                | 729.13025    |
|    approx_ln(kl)            | 6.591852     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.4          |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16320        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0439       |
|    value_loss               | 6.18         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.1315151] |
| time/                       |              |
|    fps                      | 90           |
|    iterations               | 17           |
|    time_elapsed             | 383          |
|    total_timesteps          | 3346432      |
| train/                      |              |
|    approx_kl                | 1560.023     |
|    approx_ln(kl)            | 7.3524556    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.42         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16330        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0439       |
|    value_loss               | 7.99         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.8661811] |
| time/                       |              |
|    fps                      | 79           |
|    iterations               | 18           |
|    time_elapsed             | 461          |
|    total_timesteps          | 3348480      |
| train/                      |              |
|    approx_kl                | 752.1101     |
|    approx_ln(kl)            | 6.622883     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.43         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16340        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0435       |
|    value_loss               | 5.57         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.9907758] |
| time/                       |              |
|    fps                      | 81           |
|    iterations               | 19           |
|    time_elapsed             | 477          |
|    total_timesteps          | 3350528      |
| train/                      |              |
|    approx_kl                | 3272.4802    |
|    approx_ln(kl)            | 8.093304     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.43         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16350        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0436       |
|    value_loss               | 4.13         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.4235275] |
| time/                       |              |
|    fps                      | 83           |
|    iterations               | 20           |
|    time_elapsed             | 493          |
|    total_timesteps          | 3352576      |
| train/                      |              |
|    approx_kl                | 1958.5723    |
|    approx_ln(kl)            | 7.5799713    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.41         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16360        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.044        |
|    value_loss               | 1.99         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.7231412] |
| time/                       |              |
|    fps                      | 84           |
|    iterations               | 21           |
|    time_elapsed             | 509          |
|    total_timesteps          | 3354624      |
| train/                      |              |
|    approx_kl                | 1589.4287    |
|    approx_ln(kl)            | 7.37113      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.4          |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16370        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0443       |
|    value_loss               | 2.15         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.5830657] |
| time/                       |              |
|    fps                      | 85           |
|    iterations               | 22           |
|    time_elapsed             | 526          |
|    total_timesteps          | 3356672      |
| train/                      |              |
|    approx_kl                | 1750.6687    |
|    approx_ln(kl)            | 7.467753     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.4          |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16380        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0443       |
|    value_loss               | 2.14         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.4054303] |
| time/                       |              |
|    fps                      | 74           |
|    iterations               | 23           |
|    time_elapsed             | 634          |
|    total_timesteps          | 3358720      |
| train/                      |              |
|    approx_kl                | 3551.534     |
|    approx_ln(kl)            | 8.175135     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.41         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16390        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0439       |
|    value_loss               | 4.82         |
----------------------------------------------
---------------------------------------------
| reward                      | [-3.905702] |
| time/                       |             |
|    fps                      | 75          |
|    iterations               | 24          |
|    time_elapsed             | 649         |
|    total_timesteps          | 3360768     |
| train/                      |             |
|    approx_kl                | 1855.0691   |
|    approx_ln(kl)            | 7.525677    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.42        |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | inf         |
|    loss                     | inf         |
|    n_updates                | 16400       |
|    policy_gradient_loss     | inf         |
|    std                      | 0.0437      |
|    value_loss               | 1.4         |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.9548597] |
| time/                       |              |
|    fps                      | 74           |
|    iterations               | 25           |
|    time_elapsed             | 686          |
|    total_timesteps          | 3362816      |
| train/                      |              |
|    approx_kl                | 924.8856     |
|    approx_ln(kl)            | 6.82967      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.41         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16410        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0441       |
|    value_loss               | 2.72         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.1420345] |
| time/                       |              |
|    fps                      | 75           |
|    iterations               | 26           |
|    time_elapsed             | 700          |
|    total_timesteps          | 3364864      |
| train/                      |              |
|    approx_kl                | 1059.019     |
|    approx_ln(kl)            | 6.9650984    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.39         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16420        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0446       |
|    value_loss               | 6.59         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.2403547] |
| time/                       |              |
|    fps                      | 77           |
|    iterations               | 27           |
|    time_elapsed             | 715          |
|    total_timesteps          | 3366912      |
| train/                      |              |
|    approx_kl                | 960.5117     |
|    approx_ln(kl)            | 6.867466     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.37         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16430        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.045        |
|    value_loss               | 2.92         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.0199347] |
| time/                       |              |
|    fps                      | 78           |
|    iterations               | 28           |
|    time_elapsed             | 729          |
|    total_timesteps          | 3368960      |
| train/                      |              |
|    approx_kl                | 1640.1106    |
|    approx_ln(kl)            | 7.402519     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.35         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16440        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0455       |
|    value_loss               | 3.41         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.8455513] |
| time/                       |              |
|    fps                      | 79           |
|    iterations               | 29           |
|    time_elapsed             | 743          |
|    total_timesteps          | 3371008      |
| train/                      |              |
|    approx_kl                | 1365.6653    |
|    approx_ln(kl)            | 7.219397     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.35         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16450        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0453       |
|    value_loss               | 1.61         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.5721762] |
| time/                       |              |
|    fps                      | 80           |
|    iterations               | 30           |
|    time_elapsed             | 759          |
|    total_timesteps          | 3373056      |
| train/                      |              |
|    approx_kl                | 1450.355     |
|    approx_ln(kl)            | 7.279564     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.36         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16460        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.045        |
|    value_loss               | 1.55         |
----------------------------------------------
----------------------------------------------
| reward                      | [-3.3085456] |
| time/                       |              |
|    fps                      | 81           |
|    iterations               | 31           |
|    time_elapsed             | 774          |
|    total_timesteps          | 3375104      |
| train/                      |              |
|    approx_kl                | 2066.9028    |
|    approx_ln(kl)            | 7.6338067    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.41         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 16470        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.044        |
|    value_loss               | 0.645        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.2448056] |
| time/                       |              |
|    fps                      | 82           |
|    iterations               | 32           |
|    time_elapsed             | 790          |
|    total_timesteps          | 3377152      |
| train/                      |              |
|    approx_kl                | 1003.08936   |
|    approx_ln(kl)            | 6.91084      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.42         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16480        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0437       |
|    value_loss               | 3.99         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.1504486] |
| time/                       |              |
|    fps                      | 83           |
|    iterations               | 33           |
|    time_elapsed             | 805          |
|    total_timesteps          | 3379200      |
| train/                      |              |
|    approx_kl                | 3246.777     |
|    approx_ln(kl)            | 8.085418     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.42         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16490        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0437       |
|    value_loss               | 2.26         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.034828] |
| time/                       |             |
|    fps                      | 76          |
|    iterations               | 34          |
|    time_elapsed             | 908         |
|    total_timesteps          | 3381248     |
| train/                      |             |
|    approx_kl                | 958.8081    |
|    approx_ln(kl)            | 6.865691    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.42        |
|    explained_variance       | 0.997       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 16500       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.044       |
|    value_loss               | 1.4         |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.131329] |
| time/                       |             |
|    fps                      | 77          |
|    iterations               | 35          |
|    time_elapsed             | 922         |
|    total_timesteps          | 3383296     |
| train/                      |             |
|    approx_kl                | 2587.865    |
|    approx_ln(kl)            | 7.8585887   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.38        |
|    explained_variance       | 0.995       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 16510       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0448      |
|    value_loss               | 2.19        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.2155533] |
| time/                       |              |
|    fps                      | 78           |
|    iterations               | 36           |
|    time_elapsed             | 936          |
|    total_timesteps          | 3385344      |
| train/                      |              |
|    approx_kl                | 1071.0004    |
|    approx_ln(kl)            | 6.9763484    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.38         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16520        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0449       |
|    value_loss               | 1.97         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
--------------------------------------------
| reward                      | [-0.76258] |
| time/                       |            |
|    fps                      | 79         |
|    iterations               | 37         |
|    time_elapsed             | 950        |
|    total_timesteps          | 3387392    |
| train/                      |            |
|    approx_kl                | 1185.2925  |
|    approx_ln(kl)            | 7.077745   |
|    clip_range               | 0.2        |
|    entropy_loss             | 3.36       |
|    explained_variance       | 0.998      |
|    learning_rate            | 0.001      |
|    ln(loss)                 | inf        |
|    ln(policy_gradient_loss) | nan        |
|    loss                     | inf        |
|    n_updates                | 16530      |
|    policy_gradient_loss     | nan        |
|    std                      | 0.0452     |
|    value_loss               | 1.99       |
--------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.7093307] |
| time/                       |              |
|    fps                      | 80           |
|    iterations               | 38           |
|    time_elapsed             | 964          |
|    total_timesteps          | 3389440      |
| train/                      |              |
|    approx_kl                | 1840.355     |
|    approx_ln(kl)            | 7.5177135    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.33         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16540        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0459       |
|    value_loss               | 1.92         |
----------------------------------------------
---------------------------------------------
| reward                      | [-2.567028] |
| time/                       |             |
|    fps                      | 81          |
|    iterations               | 39          |
|    time_elapsed             | 977         |
|    total_timesteps          | 3391488     |
| train/                      |             |
|    approx_kl                | 1733.626    |
|    approx_ln(kl)            | 7.4579706   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.34        |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | inf         |
|    loss                     | inf         |
|    n_updates                | 16550       |
|    policy_gradient_loss     | inf         |
|    std                      | 0.0457      |
|    value_loss               | 1.05        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.0928848] |
| time/                       |              |
|    fps                      | 82           |
|    iterations               | 40           |
|    time_elapsed             | 991          |
|    total_timesteps          | 3393536      |
| train/                      |              |
|    approx_kl                | 2419.6458    |
|    approx_ln(kl)            | 7.7913766    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.31         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16560        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0463       |
|    value_loss               | 1.28         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.974234] |
| time/                       |             |
|    fps                      | 83          |
|    iterations               | 41          |
|    time_elapsed             | 1005        |
|    total_timesteps          | 3395584     |
| train/                      |             |
|    approx_kl                | 616.3502    |
|    approx_ln(kl)            | 6.4238153   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.29        |
|    explained_variance       | 0.996       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 16570       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.047       |
|    value_loss               | 1.52        |
---------------------------------------------
---------------------------------------------
| reward                      | [-3.262143] |
| time/                       |             |
|    fps                      | 84          |
|    iterations               | 42          |
|    time_elapsed             | 1019        |
|    total_timesteps          | 3397632     |
| train/                      |             |
|    approx_kl                | 3025.5332   |
|    approx_ln(kl)            | 8.014843    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.25        |
|    explained_variance       | 0.997       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | inf         |
|    loss                     | inf         |
|    n_updates                | 16580       |
|    policy_gradient_loss     | inf         |
|    std                      | 0.048       |
|    value_loss               | 1.25        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.5558755] |
| time/                       |              |
|    fps                      | 85           |
|    iterations               | 43           |
|    time_elapsed             | 1033         |
|    total_timesteps          | 3399680      |
| train/                      |              |
|    approx_kl                | 1070.2725    |
|    approx_ln(kl)            | 6.9756684    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.26         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16590        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0475       |
|    value_loss               | 2.39         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.8312798] |
| time/                       |              |
|    fps                      | 86           |
|    iterations               | 44           |
|    time_elapsed             | 1046         |
|    total_timesteps          | 3401728      |
| train/                      |              |
|    approx_kl                | 2417.879     |
|    approx_ln(kl)            | 7.790646     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.27         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16600        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0479       |
|    value_loss               | 1.58         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
--------------------------------------------
| reward                      | [-4.20051] |
| time/                       |            |
|    fps                      | 86         |
|    iterations               | 45         |
|    time_elapsed             | 1060       |
|    total_timesteps          | 3403776    |
| train/                      |            |
|    approx_kl                | 371.5064   |
|    approx_ln(kl)            | 5.9175663  |
|    clip_range               | 0.2        |
|    entropy_loss             | 3.27       |
|    explained_variance       | 0.996      |
|    learning_rate            | 0.001      |
|    ln(loss)                 | inf        |
|    ln(policy_gradient_loss) | nan        |
|    loss                     | inf        |
|    n_updates                | 16610      |
|    policy_gradient_loss     | nan        |
|    std                      | 0.0474     |
|    value_loss               | 3.13       |
--------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.8692615] |
| time/                       |              |
|    fps                      | 87           |
|    iterations               | 46           |
|    time_elapsed             | 1074         |
|    total_timesteps          | 3405824      |
| train/                      |              |
|    approx_kl                | 947.22815    |
|    approx_ln(kl)            | 6.85354      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.28         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16620        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.047        |
|    value_loss               | 5.06         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4267297] |
| time/                       |              |
|    fps                      | 88           |
|    iterations               | 47           |
|    time_elapsed             | 1088         |
|    total_timesteps          | 3407872      |
| train/                      |              |
|    approx_kl                | 1026.5645    |
|    approx_ln(kl)            | 6.933973     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.28         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16630        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0471       |
|    value_loss               | 1.67         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.3440869] |
| time/                       |              |
|    fps                      | 81           |
|    iterations               | 48           |
|    time_elapsed             | 1202         |
|    total_timesteps          | 3409920      |
| train/                      |              |
|    approx_kl                | 2416.9536    |
|    approx_ln(kl)            | 7.790263     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.29         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16640        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0469       |
|    value_loss               | 2.37         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.3276906] |
| time/                       |              |
|    fps                      | 79           |
|    iterations               | 49           |
|    time_elapsed             | 1269         |
|    total_timesteps          | 3411968      |
| train/                      |              |
|    approx_kl                | 771.6089     |
|    approx_ln(kl)            | 6.648478     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.3          |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16650        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0466       |
|    value_loss               | 3.26         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-------------------------------------
| reward             | [-2.9150586] |
| time/              |              |
|    fps             | 158          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 3414016      |
-------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.6245086] |
| time/                       |              |
|    fps                      | 151          |
|    iterations               | 2            |
|    time_elapsed             | 26           |
|    total_timesteps          | 3416064      |
| train/                      |              |
|    approx_kl                | 1672.7858    |
|    approx_ln(kl)            | 7.4222455    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.24         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16670        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0478       |
|    value_loss               | 1.34         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.1108248] |
| time/                       |              |
|    fps                      | 150          |
|    iterations               | 3            |
|    time_elapsed             | 40           |
|    total_timesteps          | 3418112      |
| train/                      |              |
|    approx_kl                | 1663.4802    |
|    approx_ln(kl)            | 7.4166675    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.25         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16680        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0477       |
|    value_loss               | 1.1          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.5067303] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 4            |
|    time_elapsed             | 54           |
|    total_timesteps          | 3420160      |
| train/                      |              |
|    approx_kl                | 1334.7744    |
|    approx_ln(kl)            | 7.1965175    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.26         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16690        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0476       |
|    value_loss               | 1.15         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.6753297] |
| time/                       |              |
|    fps                      | 60           |
|    iterations               | 5            |
|    time_elapsed             | 170          |
|    total_timesteps          | 3422208      |
| train/                      |              |
|    approx_kl                | 1063.4819    |
|    approx_ln(kl)            | 6.9693036    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.27         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16700        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0473       |
|    value_loss               | 2.05         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.0538483] |
| time/                       |              |
|    fps                      | 60           |
|    iterations               | 6            |
|    time_elapsed             | 204          |
|    total_timesteps          | 3424256      |
| train/                      |              |
|    approx_kl                | 1136.2817    |
|    approx_ln(kl)            | 7.0355167    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.26         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16710        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0474       |
|    value_loss               | 0.781        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.986448] |
| time/                       |             |
|    fps                      | 64          |
|    iterations               | 7           |
|    time_elapsed             | 221         |
|    total_timesteps          | 3426304     |
| train/                      |             |
|    approx_kl                | 1269.7366   |
|    approx_ln(kl)            | 7.146565    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.28        |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 16720       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.047       |
|    value_loss               | 0.909       |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.8128667] |
| time/                       |              |
|    fps                      | 68           |
|    iterations               | 8            |
|    time_elapsed             | 238          |
|    total_timesteps          | 3428352      |
| train/                      |              |
|    approx_kl                | 729.0764     |
|    approx_ln(kl)            | 6.5917788    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.28         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16730        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.047        |
|    value_loss               | 0.891        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5717191] |
| time/                       |              |
|    fps                      | 72           |
|    iterations               | 9            |
|    time_elapsed             | 255          |
|    total_timesteps          | 3430400      |
| train/                      |              |
|    approx_kl                | 1779.3057    |
|    approx_ln(kl)            | 7.4839783    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.26         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16740        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0477       |
|    value_loss               | 1.22         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.9200664] |
| time/                       |              |
|    fps                      | 75           |
|    iterations               | 10           |
|    time_elapsed             | 272          |
|    total_timesteps          | 3432448      |
| train/                      |              |
|    approx_kl                | 2730.0906    |
|    approx_ln(kl)            | 7.9120903    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.24         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16750        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0481       |
|    value_loss               | 1.72         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.549023] |
| time/                       |             |
|    fps                      | 77          |
|    iterations               | 11          |
|    time_elapsed             | 289         |
|    total_timesteps          | 3434496     |
| train/                      |             |
|    approx_kl                | 1664.6528   |
|    approx_ln(kl)            | 7.4173717   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.25        |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 16760       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0477      |
|    value_loss               | 0.554       |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.1683805] |
| time/                       |              |
|    fps                      | 80           |
|    iterations               | 12           |
|    time_elapsed             | 305          |
|    total_timesteps          | 3436544      |
| train/                      |              |
|    approx_kl                | 699.4951     |
|    approx_ln(kl)            | 6.550359     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.24         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16770        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0477       |
|    value_loss               | 2.47         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.4239988] |
| time/                       |              |
|    fps                      | 82           |
|    iterations               | 13           |
|    time_elapsed             | 322          |
|    total_timesteps          | 3438592      |
| train/                      |              |
|    approx_kl                | 562.2381     |
|    approx_ln(kl)            | 6.3319254    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.24         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16780        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.048        |
|    value_loss               | 0.928        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.187294] |
| time/                       |             |
|    fps                      | 84          |
|    iterations               | 14          |
|    time_elapsed             | 338         |
|    total_timesteps          | 3440640     |
| train/                      |             |
|    approx_kl                | 321.4674    |
|    approx_ln(kl)            | 5.7728963   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.22        |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 16790       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0485      |
|    value_loss               | 2.12        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.181223] |
| time/                       |             |
|    fps                      | 86          |
|    iterations               | 15          |
|    time_elapsed             | 354         |
|    total_timesteps          | 3442688     |
| train/                      |             |
|    approx_kl                | 2340.3767   |
|    approx_ln(kl)            | 7.758067    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.2         |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 16800       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0493      |
|    value_loss               | 2.72        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.8166976] |
| time/                       |              |
|    fps                      | 88           |
|    iterations               | 16           |
|    time_elapsed             | 371          |
|    total_timesteps          | 3444736      |
| train/                      |              |
|    approx_kl                | 2543.227     |
|    approx_ln(kl)            | 7.841189     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.14         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16810        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0511       |
|    value_loss               | 1.5          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.1350684] |
| time/                       |              |
|    fps                      | 87           |
|    iterations               | 17           |
|    time_elapsed             | 396          |
|    total_timesteps          | 3446784      |
| train/                      |              |
|    approx_kl                | 1410.7112    |
|    approx_ln(kl)            | 7.251849     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.14         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16820        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0504       |
|    value_loss               | 3.12         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
--------------------------------------------
| reward                      | [-4.35631] |
| time/                       |            |
|    fps                      | 89         |
|    iterations               | 18         |
|    time_elapsed             | 410        |
|    total_timesteps          | 3448832    |
| train/                      |            |
|    approx_kl                | 547.79047  |
|    approx_ln(kl)            | 6.305893   |
|    clip_range               | 0.2        |
|    entropy_loss             | 3.15       |
|    explained_variance       | 0.998      |
|    learning_rate            | 0.001      |
|    ln(loss)                 | inf        |
|    ln(policy_gradient_loss) | nan        |
|    loss                     | inf        |
|    n_updates                | 16830      |
|    policy_gradient_loss     | nan        |
|    std                      | 0.05       |
|    value_loss               | 2.81       |
--------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5875172] |
| time/                       |              |
|    fps                      | 91           |
|    iterations               | 19           |
|    time_elapsed             | 424          |
|    total_timesteps          | 3450880      |
| train/                      |              |
|    approx_kl                | 624.17706    |
|    approx_ln(kl)            | 6.4364343    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.16         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16840        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0498       |
|    value_loss               | 2.62         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.5897821] |
| time/                       |              |
|    fps                      | 93           |
|    iterations               | 20           |
|    time_elapsed             | 439          |
|    total_timesteps          | 3452928      |
| train/                      |              |
|    approx_kl                | 900.3645     |
|    approx_ln(kl)            | 6.8027997    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.16         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16850        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0501       |
|    value_loss               | 2.8          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.4097142] |
| time/                       |              |
|    fps                      | 65           |
|    iterations               | 21           |
|    time_elapsed             | 653          |
|    total_timesteps          | 3454976      |
| train/                      |              |
|    approx_kl                | 1164.9248    |
|    approx_ln(kl)            | 7.060412     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.17         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16860        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0496       |
|    value_loss               | 1.88         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.3397372] |
| time/                       |              |
|    fps                      | 52           |
|    iterations               | 22           |
|    time_elapsed             | 859          |
|    total_timesteps          | 3457024      |
| train/                      |              |
|    approx_kl                | 1564.9117    |
|    approx_ln(kl)            | 7.3555846    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.14         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16870        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0506       |
|    value_loss               | 0.947        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.4470396] |
| time/                       |              |
|    fps                      | 47           |
|    iterations               | 23           |
|    time_elapsed             | 986          |
|    total_timesteps          | 3459072      |
| train/                      |              |
|    approx_kl                | 763.1196     |
|    approx_ln(kl)            | 6.637415     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.11         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16880        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0514       |
|    value_loss               | 1.87         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.8436108] |
| time/                       |              |
|    fps                      | 44           |
|    iterations               | 24           |
|    time_elapsed             | 1100         |
|    total_timesteps          | 3461120      |
| train/                      |              |
|    approx_kl                | 509.09784    |
|    approx_ln(kl)            | 6.2326403    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.11         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16890        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0512       |
|    value_loss               | 0.988        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.0274396] |
| time/                       |              |
|    fps                      | 42           |
|    iterations               | 25           |
|    time_elapsed             | 1212         |
|    total_timesteps          | 3463168      |
| train/                      |              |
|    approx_kl                | 3114.962     |
|    approx_ln(kl)            | 8.043972     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.11         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16900        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0513       |
|    value_loss               | 0.943        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.9434102] |
| time/                       |              |
|    fps                      | 43           |
|    iterations               | 26           |
|    time_elapsed             | 1225         |
|    total_timesteps          | 3465216      |
| train/                      |              |
|    approx_kl                | 633.73596    |
|    approx_ln(kl)            | 6.4516325    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.08         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16910        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.052        |
|    value_loss               | 3.13         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.3582516] |
| time/                       |              |
|    fps                      | 44           |
|    iterations               | 27           |
|    time_elapsed             | 1239         |
|    total_timesteps          | 3467264      |
| train/                      |              |
|    approx_kl                | 1718.085     |
|    approx_ln(kl)            | 7.4489655    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.1          |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16920        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0514       |
|    value_loss               | 1.11         |
----------------------------------------------
---------------------------------------------
| reward                      | [-4.213282] |
| time/                       |             |
|    fps                      | 45          |
|    iterations               | 28          |
|    time_elapsed             | 1253        |
|    total_timesteps          | 3469312     |
| train/                      |             |
|    approx_kl                | 686.2035    |
|    approx_ln(kl)            | 6.531174    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.09        |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | inf         |
|    loss                     | inf         |
|    n_updates                | 16930       |
|    policy_gradient_loss     | inf         |
|    std                      | 0.0517      |
|    value_loss               | 1.2         |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.041553] |
| time/                       |             |
|    fps                      | 46          |
|    iterations               | 29          |
|    time_elapsed             | 1267        |
|    total_timesteps          | 3471360     |
| train/                      |             |
|    approx_kl                | 803.7915    |
|    approx_ln(kl)            | 6.68934     |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.09        |
|    explained_variance       | 1           |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 16940       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0517      |
|    value_loss               | 0.693       |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.97572905] |
| time/                       |               |
|    fps                      | 47            |
|    iterations               | 30            |
|    time_elapsed             | 1281          |
|    total_timesteps          | 3473408       |
| train/                      |               |
|    approx_kl                | 1204.6316     |
|    approx_ln(kl)            | 7.0939293     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.09          |
|    explained_variance       | 0.999         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 16950         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0518        |
|    value_loss               | 1.61          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.6756575] |
| time/                       |              |
|    fps                      | 49           |
|    iterations               | 31           |
|    time_elapsed             | 1295         |
|    total_timesteps          | 3475456      |
| train/                      |              |
|    approx_kl                | 516.1307     |
|    approx_ln(kl)            | 6.24636      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.09         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16960        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0519       |
|    value_loss               | 0.665        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.1125782] |
| time/                       |              |
|    fps                      | 50           |
|    iterations               | 32           |
|    time_elapsed             | 1309         |
|    total_timesteps          | 3477504      |
| train/                      |              |
|    approx_kl                | 810.03827    |
|    approx_ln(kl)            | 6.6970816    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.08         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16970        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0521       |
|    value_loss               | 0.834        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.760354] |
| time/                       |             |
|    fps                      | 51          |
|    iterations               | 33          |
|    time_elapsed             | 1322        |
|    total_timesteps          | 3479552     |
| train/                      |             |
|    approx_kl                | 837.6059    |
|    approx_ln(kl)            | 6.730548    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.08        |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 16980       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0518      |
|    value_loss               | 1.46        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.5778885] |
| time/                       |              |
|    fps                      | 52           |
|    iterations               | 34           |
|    time_elapsed             | 1336         |
|    total_timesteps          | 3481600      |
| train/                      |              |
|    approx_kl                | 694.766      |
|    approx_ln(kl)            | 6.5435753    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.08         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 16990        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0519       |
|    value_loss               | 0.853        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.1981966] |
| time/                       |              |
|    fps                      | 53           |
|    iterations               | 35           |
|    time_elapsed             | 1350         |
|    total_timesteps          | 3483648      |
| train/                      |              |
|    approx_kl                | 580.3705     |
|    approx_ln(kl)            | 6.3636665    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.07         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17000        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0523       |
|    value_loss               | 2.67         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.198546] |
| time/                       |             |
|    fps                      | 54          |
|    iterations               | 36          |
|    time_elapsed             | 1364        |
|    total_timesteps          | 3485696     |
| train/                      |             |
|    approx_kl                | 611.0342    |
|    approx_ln(kl)            | 6.415153    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.08        |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 17010       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0519      |
|    value_loss               | 1.49        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.6686208] |
| time/                       |              |
|    fps                      | 54           |
|    iterations               | 37           |
|    time_elapsed             | 1378         |
|    total_timesteps          | 3487744      |
| train/                      |              |
|    approx_kl                | 680.1743     |
|    approx_ln(kl)            | 6.5223494    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.09         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17020        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0517       |
|    value_loss               | 1.88         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.969123] |
| time/                       |             |
|    fps                      | 55          |
|    iterations               | 38          |
|    time_elapsed             | 1392        |
|    total_timesteps          | 3489792     |
| train/                      |             |
|    approx_kl                | 2935.4392   |
|    approx_ln(kl)            | 7.9846125   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.13        |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 17030       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0506      |
|    value_loss               | 1.31        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.1483846] |
| time/                       |              |
|    fps                      | 56           |
|    iterations               | 39           |
|    time_elapsed             | 1405         |
|    total_timesteps          | 3491840      |
| train/                      |              |
|    approx_kl                | 1605.053     |
|    approx_ln(kl)            | 7.380912     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.14         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17040        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0499       |
|    value_loss               | 0.711        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4959836] |
| time/                       |              |
|    fps                      | 57           |
|    iterations               | 40           |
|    time_elapsed             | 1419         |
|    total_timesteps          | 3493888      |
| train/                      |              |
|    approx_kl                | 1185.1165    |
|    approx_ln(kl)            | 7.077596     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.16         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17050        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0499       |
|    value_loss               | 0.538        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.7785399] |
| time/                       |              |
|    fps                      | 58           |
|    iterations               | 41           |
|    time_elapsed             | 1433         |
|    total_timesteps          | 3495936      |
| train/                      |              |
|    approx_kl                | 1681.9169    |
|    approx_ln(kl)            | 7.4276896    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.15         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17060        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.05         |
|    value_loss               | 1.33         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.5504649] |
| time/                       |              |
|    fps                      | 59           |
|    iterations               | 42           |
|    time_elapsed             | 1446         |
|    total_timesteps          | 3497984      |
| train/                      |              |
|    approx_kl                | 2002.7949    |
|    approx_ln(kl)            | 7.6022987    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.17         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17070        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0503       |
|    value_loss               | 0.786        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.039727] |
| time/                       |             |
|    fps                      | 60          |
|    iterations               | 43          |
|    time_elapsed             | 1460        |
|    total_timesteps          | 3500032     |
| train/                      |             |
|    approx_kl                | 1676.2339   |
|    approx_ln(kl)            | 7.424305    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.17        |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 17080       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0496      |
|    value_loss               | 0.716       |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.6046982] |
| time/                       |              |
|    fps                      | 61           |
|    iterations               | 44           |
|    time_elapsed             | 1474         |
|    total_timesteps          | 3502080      |
| train/                      |              |
|    approx_kl                | 1367.2362    |
|    approx_ln(kl)            | 7.2205467    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.17         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17090        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0496       |
|    value_loss               | 1.57         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.0784376] |
| time/                       |              |
|    fps                      | 61           |
|    iterations               | 45           |
|    time_elapsed             | 1488         |
|    total_timesteps          | 3504128      |
| train/                      |              |
|    approx_kl                | 1436.9529    |
|    approx_ln(kl)            | 7.27028      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.16         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17100        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0499       |
|    value_loss               | 0.917        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.9565492] |
| time/                       |              |
|    fps                      | 62           |
|    iterations               | 46           |
|    time_elapsed             | 1502         |
|    total_timesteps          | 3506176      |
| train/                      |              |
|    approx_kl                | 688.1242     |
|    approx_ln(kl)            | 6.5339694    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.16         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17110        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0498       |
|    value_loss               | 1.39         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.6174295] |
| time/                       |              |
|    fps                      | 63           |
|    iterations               | 47           |
|    time_elapsed             | 1515         |
|    total_timesteps          | 3508224      |
| train/                      |              |
|    approx_kl                | 905.8108     |
|    approx_ln(kl)            | 6.8088303    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.15         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17120        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0502       |
|    value_loss               | 1.09         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.8808444] |
| time/                       |              |
|    fps                      | 64           |
|    iterations               | 48           |
|    time_elapsed             | 1529         |
|    total_timesteps          | 3510272      |
| train/                      |              |
|    approx_kl                | 657.3602     |
|    approx_ln(kl)            | 6.488232     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.12         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17130        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0508       |
|    value_loss               | 1.74         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.8780742] |
| time/                       |              |
|    fps                      | 65           |
|    iterations               | 49           |
|    time_elapsed             | 1543         |
|    total_timesteps          | 3512320      |
| train/                      |              |
|    approx_kl                | 629.9612     |
|    approx_ln(kl)            | 6.445658     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.03         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17140        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0533       |
|    value_loss               | 0.772        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-------------------------------------
| reward             | [-3.7444124] |
| time/              |              |
|    fps             | 162          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 3514368      |
-------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0304673] |
| time/                       |              |
|    fps                      | 155          |
|    iterations               | 2            |
|    time_elapsed             | 26           |
|    total_timesteps          | 3516416      |
| train/                      |              |
|    approx_kl                | 1682.6632    |
|    approx_ln(kl)            | 7.428133     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.06         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17160        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0524       |
|    value_loss               | 0.939        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.2172241] |
| time/                       |              |
|    fps                      | 152          |
|    iterations               | 3            |
|    time_elapsed             | 40           |
|    total_timesteps          | 3518464      |
| train/                      |              |
|    approx_kl                | 832.31647    |
|    approx_ln(kl)            | 6.7242126    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.05         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17170        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0528       |
|    value_loss               | 1.05         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.7963538] |
| time/                       |              |
|    fps                      | 151          |
|    iterations               | 4            |
|    time_elapsed             | 54           |
|    total_timesteps          | 3520512      |
| train/                      |              |
|    approx_kl                | 1800.8105    |
|    approx_ln(kl)            | 7.495992     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.06         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17180        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0523       |
|    value_loss               | 2.52         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.6187515] |
| time/                       |              |
|    fps                      | 150          |
|    iterations               | 5            |
|    time_elapsed             | 67           |
|    total_timesteps          | 3522560      |
| train/                      |              |
|    approx_kl                | 1358.0657    |
|    approx_ln(kl)            | 7.2138166    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.06         |
|    explained_variance       | 0.992        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17190        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0525       |
|    value_loss               | 5.82         |
----------------------------------------------
----------------------------------------------
| reward                      | [-2.0705013] |
| time/                       |              |
|    fps                      | 150          |
|    iterations               | 6            |
|    time_elapsed             | 81           |
|    total_timesteps          | 3524608      |
| train/                      |              |
|    approx_kl                | 402.70233    |
|    approx_ln(kl)            | 5.9981976    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.06         |
|    explained_variance       | 0.977        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 17200        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0525       |
|    value_loss               | 6.44         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.8797655] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 7            |
|    time_elapsed             | 95           |
|    total_timesteps          | 3526656      |
| train/                      |              |
|    approx_kl                | 865.09985    |
|    approx_ln(kl)            | 6.762845     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.06         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17210        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0524       |
|    value_loss               | 2.93         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.987096] |
| time/                       |             |
|    fps                      | 149         |
|    iterations               | 8           |
|    time_elapsed             | 109         |
|    total_timesteps          | 3528704     |
| train/                      |             |
|    approx_kl                | 321.9433    |
|    approx_ln(kl)            | 5.7743754   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.09        |
|    explained_variance       | 0.995       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 17220       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0514      |
|    value_loss               | 2.28        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.948858] |
| time/                       |             |
|    fps                      | 149         |
|    iterations               | 9           |
|    time_elapsed             | 123         |
|    total_timesteps          | 3530752     |
| train/                      |             |
|    approx_kl                | 947.55884   |
|    approx_ln(kl)            | 6.853889    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.09        |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 17230       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0517      |
|    value_loss               | 2.06        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.077023] |
| time/                       |             |
|    fps                      | 148         |
|    iterations               | 10          |
|    time_elapsed             | 138         |
|    total_timesteps          | 3532800     |
| train/                      |             |
|    approx_kl                | 506.2766    |
|    approx_ln(kl)            | 6.227083    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.1         |
|    explained_variance       | 0.997       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 17240       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0515      |
|    value_loss               | 1.17        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.298004] |
| time/                       |             |
|    fps                      | 148         |
|    iterations               | 11          |
|    time_elapsed             | 151         |
|    total_timesteps          | 3534848     |
| train/                      |             |
|    approx_kl                | 2708.4153   |
|    approx_ln(kl)            | 7.904119    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.12        |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 17250       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0508      |
|    value_loss               | 1.22        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.71642965] |
| time/                       |               |
|    fps                      | 148           |
|    iterations               | 12            |
|    time_elapsed             | 165           |
|    total_timesteps          | 3536896       |
| train/                      |               |
|    approx_kl                | 826.72296     |
|    approx_ln(kl)            | 6.7174697     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.07          |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 17260         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0524        |
|    value_loss               | 0.726         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.5046723] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 13           |
|    time_elapsed             | 179          |
|    total_timesteps          | 3538944      |
| train/                      |              |
|    approx_kl                | 444.4628     |
|    approx_ln(kl)            | 6.0968666    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.06         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17270        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0524       |
|    value_loss               | 0.638        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.5247982] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 14           |
|    time_elapsed             | 192          |
|    total_timesteps          | 3540992      |
| train/                      |              |
|    approx_kl                | 667.5215     |
|    approx_ln(kl)            | 6.5035715    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.06         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17280        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0524       |
|    value_loss               | 0.876        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
--------------------------------------------
| reward                      | [-3.08363] |
| time/                       |            |
|    fps                      | 148        |
|    iterations               | 15         |
|    time_elapsed             | 206        |
|    total_timesteps          | 3543040    |
| train/                      |            |
|    approx_kl                | 466.95154  |
|    approx_ln(kl)            | 6.1462255  |
|    clip_range               | 0.2        |
|    entropy_loss             | 3.08       |
|    explained_variance       | 0.999      |
|    learning_rate            | 0.001      |
|    ln(loss)                 | inf        |
|    ln(policy_gradient_loss) | nan        |
|    loss                     | inf        |
|    n_updates                | 17290      |
|    policy_gradient_loss     | nan        |
|    std                      | 0.052      |
|    value_loss               | 0.619      |
--------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.0904713] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 16           |
|    time_elapsed             | 220          |
|    total_timesteps          | 3545088      |
| train/                      |              |
|    approx_kl                | 650.61694    |
|    approx_ln(kl)            | 6.477921     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.08         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17300        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0519       |
|    value_loss               | 1.23         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.3437457] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 17           |
|    time_elapsed             | 235          |
|    total_timesteps          | 3547136      |
| train/                      |              |
|    approx_kl                | 1251.3032    |
|    approx_ln(kl)            | 7.131941     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.11         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17310        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0513       |
|    value_loss               | 0.617        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.355567] |
| time/                       |             |
|    fps                      | 147         |
|    iterations               | 18          |
|    time_elapsed             | 249         |
|    total_timesteps          | 3549184     |
| train/                      |             |
|    approx_kl                | 1293.95     |
|    approx_ln(kl)            | 7.165455    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.1         |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 17320       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0515      |
|    value_loss               | 0.817       |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.3061442] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 19           |
|    time_elapsed             | 262          |
|    total_timesteps          | 3551232      |
| train/                      |              |
|    approx_kl                | 564.5282     |
|    approx_ln(kl)            | 6.3359904    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.1          |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17330        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0514       |
|    value_loss               | 0.661        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.3668954] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 20           |
|    time_elapsed             | 276          |
|    total_timesteps          | 3553280      |
| train/                      |              |
|    approx_kl                | 562.7844     |
|    approx_ln(kl)            | 6.3328967    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.1          |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17340        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0514       |
|    value_loss               | 0.664        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.153994] |
| time/                       |             |
|    fps                      | 148         |
|    iterations               | 21          |
|    time_elapsed             | 290         |
|    total_timesteps          | 3555328     |
| train/                      |             |
|    approx_kl                | 921.04297   |
|    approx_ln(kl)            | 6.8255067   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.06        |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 17350       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0526      |
|    value_loss               | 0.776       |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-0.582946] |
| time/                       |             |
|    fps                      | 148         |
|    iterations               | 22          |
|    time_elapsed             | 304         |
|    total_timesteps          | 3557376     |
| train/                      |             |
|    approx_kl                | 319.76056   |
|    approx_ln(kl)            | 5.7675724   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.05        |
|    explained_variance       | 0.996       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 17360       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0527      |
|    value_loss               | 1.1         |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.4994793] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 23           |
|    time_elapsed             | 317          |
|    total_timesteps          | 3559424      |
| train/                      |              |
|    approx_kl                | 1076.7976    |
|    approx_ln(kl)            | 6.9817467    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.05         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17370        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0528       |
|    value_loss               | 1.33         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.3779855] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 24           |
|    time_elapsed             | 331          |
|    total_timesteps          | 3561472      |
| train/                      |              |
|    approx_kl                | 627.3905     |
|    approx_ln(kl)            | 6.4415693    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.07         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17380        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0524       |
|    value_loss               | 0.681        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.9423094] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 25           |
|    time_elapsed             | 345          |
|    total_timesteps          | 3563520      |
| train/                      |              |
|    approx_kl                | 743.093      |
|    approx_ln(kl)            | 6.6108212    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.08         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17390        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.052        |
|    value_loss               | 0.61         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.6639314] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 26           |
|    time_elapsed             | 359          |
|    total_timesteps          | 3565568      |
| train/                      |              |
|    approx_kl                | 639.1272     |
|    approx_ln(kl)            | 6.4601035    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.06         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17400        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0525       |
|    value_loss               | 0.5          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.9447732] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 27           |
|    time_elapsed             | 373          |
|    total_timesteps          | 3567616      |
| train/                      |              |
|    approx_kl                | 646.9816     |
|    approx_ln(kl)            | 6.4723177    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.09         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17410        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0519       |
|    value_loss               | 0.821        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.190992] |
| time/                       |             |
|    fps                      | 148         |
|    iterations               | 28          |
|    time_elapsed             | 387         |
|    total_timesteps          | 3569664     |
| train/                      |             |
|    approx_kl                | 1272.2043   |
|    approx_ln(kl)            | 7.148506    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.08        |
|    explained_variance       | 0.997       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 17420       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.052       |
|    value_loss               | 1.13        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.001049] |
| time/                       |             |
|    fps                      | 148         |
|    iterations               | 29          |
|    time_elapsed             | 400         |
|    total_timesteps          | 3571712     |
| train/                      |             |
|    approx_kl                | 916.87524   |
|    approx_ln(kl)            | 6.8209715   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.1         |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 17430       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0513      |
|    value_loss               | 0.742       |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.980156] |
| time/                       |             |
|    fps                      | 148         |
|    iterations               | 30          |
|    time_elapsed             | 414         |
|    total_timesteps          | 3573760     |
| train/                      |             |
|    approx_kl                | 624.9261    |
|    approx_ln(kl)            | 6.4376335   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.1         |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 17440       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.052       |
|    value_loss               | 0.963       |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.1379957] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 31           |
|    time_elapsed             | 428          |
|    total_timesteps          | 3575808      |
| train/                      |              |
|    approx_kl                | 418.97568    |
|    approx_ln(kl)            | 6.0378127    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.07         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17450        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0524       |
|    value_loss               | 0.702        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.4926813] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 32           |
|    time_elapsed             | 442          |
|    total_timesteps          | 3577856      |
| train/                      |              |
|    approx_kl                | 494.6848     |
|    approx_ln(kl)            | 6.203921     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.02         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17460        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0538       |
|    value_loss               | 0.763        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.8037737] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 33           |
|    time_elapsed             | 456          |
|    total_timesteps          | 3579904      |
| train/                      |              |
|    approx_kl                | 615.4884     |
|    approx_ln(kl)            | 6.422416     |
|    clip_range               | 0.2          |
|    entropy_loss             | 2.98         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17470        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.055        |
|    value_loss               | 1.14         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.0942101] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 34           |
|    time_elapsed             | 469          |
|    total_timesteps          | 3581952      |
| train/                      |              |
|    approx_kl                | 490.9358     |
|    approx_ln(kl)            | 6.1963134    |
|    clip_range               | 0.2          |
|    entropy_loss             | 2.94         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17480        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0563       |
|    value_loss               | 0.826        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.8391254] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 35           |
|    time_elapsed             | 483          |
|    total_timesteps          | 3584000      |
| train/                      |              |
|    approx_kl                | 412.64294    |
|    approx_ln(kl)            | 6.0225825    |
|    clip_range               | 0.2          |
|    entropy_loss             | 2.91         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17490        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0564       |
|    value_loss               | 1.8          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.6530674] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 36           |
|    time_elapsed             | 497          |
|    total_timesteps          | 3586048      |
| train/                      |              |
|    approx_kl                | 326.77405    |
|    approx_ln(kl)            | 5.789269     |
|    clip_range               | 0.2          |
|    entropy_loss             | 2.94         |
|    explained_variance       | 0.966        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17500        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0555       |
|    value_loss               | 7.81         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.3745337] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 37           |
|    time_elapsed             | 511          |
|    total_timesteps          | 3588096      |
| train/                      |              |
|    approx_kl                | 537.48645    |
|    approx_ln(kl)            | 6.2869034    |
|    clip_range               | 0.2          |
|    entropy_loss             | 2.96         |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17510        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0554       |
|    value_loss               | 5.53         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.8591995] |
| time/                       |              |
|    fps                      | 126          |
|    iterations               | 38           |
|    time_elapsed             | 614          |
|    total_timesteps          | 3590144      |
| train/                      |              |
|    approx_kl                | 196.59576    |
|    approx_ln(kl)            | 5.28115      |
|    clip_range               | 0.2          |
|    entropy_loss             | 2.97         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17520        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.055        |
|    value_loss               | 2.43         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.430601] |
| time/                       |             |
|    fps                      | 111         |
|    iterations               | 39          |
|    time_elapsed             | 718         |
|    total_timesteps          | 3592192     |
| train/                      |             |
|    approx_kl                | 235.0022    |
|    approx_ln(kl)            | 5.4595947   |
|    clip_range               | 0.2         |
|    entropy_loss             | 2.97        |
|    explained_variance       | 0.997       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 17530       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.055       |
|    value_loss               | 2.67        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.6474898] |
| time/                       |              |
|    fps                      | 99           |
|    iterations               | 40           |
|    time_elapsed             | 822          |
|    total_timesteps          | 3594240      |
| train/                      |              |
|    approx_kl                | 319.86816    |
|    approx_ln(kl)            | 5.767909     |
|    clip_range               | 0.2          |
|    entropy_loss             | 2.98         |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17540        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0545       |
|    value_loss               | 4.68         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.682944] |
| time/                       |             |
|    fps                      | 100         |
|    iterations               | 41          |
|    time_elapsed             | 836         |
|    total_timesteps          | 3596288     |
| train/                      |             |
|    approx_kl                | 183.47083   |
|    approx_ln(kl)            | 5.2120557   |
|    clip_range               | 0.2         |
|    entropy_loss             | 2.98        |
|    explained_variance       | 0.997       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 17550       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0544      |
|    value_loss               | 2.21        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.580069] |
| time/                       |             |
|    fps                      | 101         |
|    iterations               | 42          |
|    time_elapsed             | 850         |
|    total_timesteps          | 3598336     |
| train/                      |             |
|    approx_kl                | 619.3376    |
|    approx_ln(kl)            | 6.4286504   |
|    clip_range               | 0.2         |
|    entropy_loss             | 2.98        |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 17560       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0545      |
|    value_loss               | 2.46        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4646802] |
| time/                       |              |
|    fps                      | 101          |
|    iterations               | 43           |
|    time_elapsed             | 864          |
|    total_timesteps          | 3600384      |
| train/                      |              |
|    approx_kl                | 116.42772    |
|    approx_ln(kl)            | 4.757271     |
|    clip_range               | 0.2          |
|    entropy_loss             | 2.99         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17570        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0544       |
|    value_loss               | 2.92         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.2650095] |
| time/                       |              |
|    fps                      | 102          |
|    iterations               | 44           |
|    time_elapsed             | 878          |
|    total_timesteps          | 3602432      |
| train/                      |              |
|    approx_kl                | 141.81918    |
|    approx_ln(kl)            | 4.954553     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.02         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17580        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0537       |
|    value_loss               | 2.2          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.9430407] |
| time/                       |              |
|    fps                      | 103          |
|    iterations               | 45           |
|    time_elapsed             | 892          |
|    total_timesteps          | 3604480      |
| train/                      |              |
|    approx_kl                | 381.0803     |
|    approx_ln(kl)            | 5.9430103    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.02         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17590        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0535       |
|    value_loss               | 1.44         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.3044665] |
| time/                       |              |
|    fps                      | 103          |
|    iterations               | 46           |
|    time_elapsed             | 906          |
|    total_timesteps          | 3606528      |
| train/                      |              |
|    approx_kl                | 399.84006    |
|    approx_ln(kl)            | 5.9910645    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.03         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17600        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0533       |
|    value_loss               | 1.93         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.4107525] |
| time/                       |              |
|    fps                      | 104          |
|    iterations               | 47           |
|    time_elapsed             | 920          |
|    total_timesteps          | 3608576      |
| train/                      |              |
|    approx_kl                | 280.6186     |
|    approx_ln(kl)            | 5.6369963    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.03         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17610        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0532       |
|    value_loss               | 0.998        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.0005293] |
| time/                       |              |
|    fps                      | 105          |
|    iterations               | 48           |
|    time_elapsed             | 933          |
|    total_timesteps          | 3610624      |
| train/                      |              |
|    approx_kl                | 1032.8367    |
|    approx_ln(kl)            | 6.9400644    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.05         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17620        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0527       |
|    value_loss               | 0.7          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.825544] |
| time/                       |             |
|    fps                      | 105         |
|    iterations               | 49          |
|    time_elapsed             | 947         |
|    total_timesteps          | 3612672     |
| train/                      |             |
|    approx_kl                | 664.8966    |
|    approx_ln(kl)            | 6.4996314   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.05        |
|    explained_variance       | 0.995       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 17630       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0528      |
|    value_loss               | 1.69        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
------------------------------------
| reward             | [-2.730485] |
| time/              |             |
|    fps             | 159         |
|    iterations      | 1           |
|    time_elapsed    | 12          |
|    total_timesteps | 3614720     |
------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.5861614] |
| time/                       |              |
|    fps                      | 35           |
|    iterations               | 2            |
|    time_elapsed             | 116          |
|    total_timesteps          | 3616768      |
| train/                      |              |
|    approx_kl                | 589.86707    |
|    approx_ln(kl)            | 6.379897     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.02         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17650        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0538       |
|    value_loss               | 1.56         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.9087274] |
| time/                       |              |
|    fps                      | 47           |
|    iterations               | 3            |
|    time_elapsed             | 130          |
|    total_timesteps          | 3618816      |
| train/                      |              |
|    approx_kl                | 1505.5021    |
|    approx_ln(kl)            | 7.3168817    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.04         |
|    explained_variance       | 0.987        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17660        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0533       |
|    value_loss               | 2.82         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.7830522] |
| time/                       |              |
|    fps                      | 56           |
|    iterations               | 4            |
|    time_elapsed             | 144          |
|    total_timesteps          | 3620864      |
| train/                      |              |
|    approx_kl                | 486.82465    |
|    approx_ln(kl)            | 6.187904     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.06         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17670        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0526       |
|    value_loss               | 1.19         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.2092836] |
| time/                       |              |
|    fps                      | 64           |
|    iterations               | 5            |
|    time_elapsed             | 158          |
|    total_timesteps          | 3622912      |
| train/                      |              |
|    approx_kl                | 673.49677    |
|    approx_ln(kl)            | 6.512483     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.07         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17680        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0524       |
|    value_loss               | 1.57         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-1.654678] |
| time/                       |             |
|    fps                      | 71          |
|    iterations               | 6           |
|    time_elapsed             | 172         |
|    total_timesteps          | 3624960     |
| train/                      |             |
|    approx_kl                | 1696.1215   |
|    approx_ln(kl)            | 7.4360995   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.1         |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 17690       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0518      |
|    value_loss               | 0.976       |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.5566137] |
| time/                       |              |
|    fps                      | 77           |
|    iterations               | 7            |
|    time_elapsed             | 185          |
|    total_timesteps          | 3627008      |
| train/                      |              |
|    approx_kl                | 132.23773    |
|    approx_ln(kl)            | 4.884601     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.1          |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17700        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0518       |
|    value_loss               | 1.65         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.7208014] |
| time/                       |              |
|    fps                      | 82           |
|    iterations               | 8            |
|    time_elapsed             | 199          |
|    total_timesteps          | 3629056      |
| train/                      |              |
|    approx_kl                | 288.93964    |
|    approx_ln(kl)            | 5.666218     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.1          |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17710        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0516       |
|    value_loss               | 1.4          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.803591] |
| time/                       |             |
|    fps                      | 86          |
|    iterations               | 9           |
|    time_elapsed             | 214         |
|    total_timesteps          | 3631104     |
| train/                      |             |
|    approx_kl                | 904.4663    |
|    approx_ln(kl)            | 6.807345    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.11        |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 17720       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0516      |
|    value_loss               | 1.16        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.9021847] |
| time/                       |              |
|    fps                      | 89           |
|    iterations               | 10           |
|    time_elapsed             | 228          |
|    total_timesteps          | 3633152      |
| train/                      |              |
|    approx_kl                | 723.46484    |
|    approx_ln(kl)            | 6.584052     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.1          |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17730        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0518       |
|    value_loss               | 0.822        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.7927618] |
| time/                       |              |
|    fps                      | 93           |
|    iterations               | 11           |
|    time_elapsed             | 242          |
|    total_timesteps          | 3635200      |
| train/                      |              |
|    approx_kl                | 1081.1387    |
|    approx_ln(kl)            | 6.98577      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.06         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17740        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0529       |
|    value_loss               | 1.04         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.724782] |
| time/                       |             |
|    fps                      | 96          |
|    iterations               | 12          |
|    time_elapsed             | 255         |
|    total_timesteps          | 3637248     |
| train/                      |             |
|    approx_kl                | 892.36      |
|    approx_ln(kl)            | 6.7938695   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.04        |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 17750       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0536      |
|    value_loss               | 0.918       |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.599235] |
| time/                       |             |
|    fps                      | 98          |
|    iterations               | 13          |
|    time_elapsed             | 269         |
|    total_timesteps          | 3639296     |
| train/                      |             |
|    approx_kl                | 1184.9739   |
|    approx_ln(kl)            | 7.077476    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.08        |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 17760       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0522      |
|    value_loss               | 0.753       |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.5945458] |
| time/                       |              |
|    fps                      | 101          |
|    iterations               | 14           |
|    time_elapsed             | 283          |
|    total_timesteps          | 3641344      |
| train/                      |              |
|    approx_kl                | 392.95676    |
|    approx_ln(kl)            | 5.9736996    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.11         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17770        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0516       |
|    value_loss               | 1.03         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.56585073] |
| time/                       |               |
|    fps                      | 103           |
|    iterations               | 15            |
|    time_elapsed             | 297           |
|    total_timesteps          | 3643392       |
| train/                      |               |
|    approx_kl                | 332.71173     |
|    approx_ln(kl)            | 5.8072762     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.11          |
|    explained_variance       | 0.997         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 17780         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0517        |
|    value_loss               | 1.06          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.8270355] |
| time/                       |              |
|    fps                      | 105          |
|    iterations               | 16           |
|    time_elapsed             | 311          |
|    total_timesteps          | 3645440      |
| train/                      |              |
|    approx_kl                | 1245.332     |
|    approx_ln(kl)            | 7.1271577    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.1          |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17790        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.052        |
|    value_loss               | 0.775        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.2797735] |
| time/                       |              |
|    fps                      | 107          |
|    iterations               | 17           |
|    time_elapsed             | 325          |
|    total_timesteps          | 3647488      |
| train/                      |              |
|    approx_kl                | 563.1459     |
|    approx_ln(kl)            | 6.3335385    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.1          |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17800        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0517       |
|    value_loss               | 1.29         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.3733985] |
| time/                       |              |
|    fps                      | 108          |
|    iterations               | 18           |
|    time_elapsed             | 338          |
|    total_timesteps          | 3649536      |
| train/                      |              |
|    approx_kl                | 644.00146    |
|    approx_ln(kl)            | 6.467701     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.12         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17810        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0512       |
|    value_loss               | 1.89         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.4751506] |
| time/                       |              |
|    fps                      | 110          |
|    iterations               | 19           |
|    time_elapsed             | 352          |
|    total_timesteps          | 3651584      |
| train/                      |              |
|    approx_kl                | 246.32468    |
|    approx_ln(kl)            | 5.5066504    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.12         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17820        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0512       |
|    value_loss               | 1.37         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.0862179] |
| time/                       |              |
|    fps                      | 111          |
|    iterations               | 20           |
|    time_elapsed             | 366          |
|    total_timesteps          | 3653632      |
| train/                      |              |
|    approx_kl                | 1343.4521    |
|    approx_ln(kl)            | 7.2029977    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.12         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17830        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0513       |
|    value_loss               | 1.06         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.6324735] |
| time/                       |              |
|    fps                      | 113          |
|    iterations               | 21           |
|    time_elapsed             | 380          |
|    total_timesteps          | 3655680      |
| train/                      |              |
|    approx_kl                | 662.6492     |
|    approx_ln(kl)            | 6.496246     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.11         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17840        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0517       |
|    value_loss               | 0.924        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.6571305] |
| time/                       |              |
|    fps                      | 114          |
|    iterations               | 22           |
|    time_elapsed             | 394          |
|    total_timesteps          | 3657728      |
| train/                      |              |
|    approx_kl                | 732.13617    |
|    approx_ln(kl)            | 6.5959663    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.11         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17850        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0515       |
|    value_loss               | 0.804        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.8096237] |
| time/                       |              |
|    fps                      | 115          |
|    iterations               | 23           |
|    time_elapsed             | 408          |
|    total_timesteps          | 3659776      |
| train/                      |              |
|    approx_kl                | 1214.3569    |
|    approx_ln(kl)            | 7.10197      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.18         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17860        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0495       |
|    value_loss               | 0.659        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.9777954] |
| time/                       |              |
|    fps                      | 116          |
|    iterations               | 24           |
|    time_elapsed             | 422          |
|    total_timesteps          | 3661824      |
| train/                      |              |
|    approx_kl                | 579.92834    |
|    approx_ln(kl)            | 6.3629045    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.2          |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17870        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0494       |
|    value_loss               | 0.821        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5849068] |
| time/                       |              |
|    fps                      | 117          |
|    iterations               | 25           |
|    time_elapsed             | 435          |
|    total_timesteps          | 3663872      |
| train/                      |              |
|    approx_kl                | 356.94305    |
|    approx_ln(kl)            | 5.8775764    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.22         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17880        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0488       |
|    value_loss               | 0.852        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.3331507] |
| time/                       |              |
|    fps                      | 118          |
|    iterations               | 26           |
|    time_elapsed             | 450          |
|    total_timesteps          | 3665920      |
| train/                      |              |
|    approx_kl                | 661.58777    |
|    approx_ln(kl)            | 6.4946427    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.22         |
|    explained_variance       | 0.99         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17890        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.049        |
|    value_loss               | 1.21         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.2270253] |
| time/                       |              |
|    fps                      | 119          |
|    iterations               | 27           |
|    time_elapsed             | 464          |
|    total_timesteps          | 3667968      |
| train/                      |              |
|    approx_kl                | 1049.2052    |
|    approx_ln(kl)            | 6.955788     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.23         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17900        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0486       |
|    value_loss               | 0.445        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.5586503] |
| time/                       |              |
|    fps                      | 119          |
|    iterations               | 28           |
|    time_elapsed             | 478          |
|    total_timesteps          | 3670016      |
| train/                      |              |
|    approx_kl                | 1651.352     |
|    approx_ln(kl)            | 7.40935      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.17         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17910        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0502       |
|    value_loss               | 0.337        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.6854727] |
| time/                       |              |
|    fps                      | 120          |
|    iterations               | 29           |
|    time_elapsed             | 492          |
|    total_timesteps          | 3672064      |
| train/                      |              |
|    approx_kl                | 504.15552    |
|    approx_ln(kl)            | 6.2228847    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.16         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17920        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0507       |
|    value_loss               | 0.437        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.548966] |
| time/                       |             |
|    fps                      | 121         |
|    iterations               | 30          |
|    time_elapsed             | 506         |
|    total_timesteps          | 3674112     |
| train/                      |             |
|    approx_kl                | 664.21643   |
|    approx_ln(kl)            | 6.498608    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.17        |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 17930       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0501      |
|    value_loss               | 0.202       |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.234352] |
| time/                       |             |
|    fps                      | 122         |
|    iterations               | 31          |
|    time_elapsed             | 520         |
|    total_timesteps          | 3676160     |
| train/                      |             |
|    approx_kl                | 688.188     |
|    approx_ln(kl)            | 6.534062    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.19        |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 17940       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0495      |
|    value_loss               | 0.762       |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.3389695] |
| time/                       |              |
|    fps                      | 122          |
|    iterations               | 32           |
|    time_elapsed             | 533          |
|    total_timesteps          | 3678208      |
| train/                      |              |
|    approx_kl                | 227.13065    |
|    approx_ln(kl)            | 5.425525     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.19         |
|    explained_variance       | 0.983        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17950        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0495       |
|    value_loss               | 2.64         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.1586158] |
| time/                       |              |
|    fps                      | 123          |
|    iterations               | 33           |
|    time_elapsed             | 547          |
|    total_timesteps          | 3680256      |
| train/                      |              |
|    approx_kl                | 755.70905    |
|    approx_ln(kl)            | 6.6276565    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.21         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17960        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0492       |
|    value_loss               | 1.7          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.152041] |
| time/                       |             |
|    fps                      | 124         |
|    iterations               | 34          |
|    time_elapsed             | 561         |
|    total_timesteps          | 3682304     |
| train/                      |             |
|    approx_kl                | 560.1648    |
|    approx_ln(kl)            | 6.328231    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.18        |
|    explained_variance       | 0.968       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 17970       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.05        |
|    value_loss               | 7.31        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.141429] |
| time/                       |             |
|    fps                      | 124         |
|    iterations               | 35          |
|    time_elapsed             | 575         |
|    total_timesteps          | 3684352     |
| train/                      |             |
|    approx_kl                | 296.78848   |
|    approx_ln(kl)            | 5.69302     |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.18        |
|    explained_variance       | 0.987       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 17980       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.05        |
|    value_loss               | 1.9         |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.9150682] |
| time/                       |              |
|    fps                      | 125          |
|    iterations               | 36           |
|    time_elapsed             | 589          |
|    total_timesteps          | 3686400      |
| train/                      |              |
|    approx_kl                | 505.92734    |
|    approx_ln(kl)            | 6.226393     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.19         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 17990        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0499       |
|    value_loss               | 1.28         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0851549] |
| time/                       |              |
|    fps                      | 125          |
|    iterations               | 37           |
|    time_elapsed             | 602          |
|    total_timesteps          | 3688448      |
| train/                      |              |
|    approx_kl                | 406.00204    |
|    approx_ln(kl)            | 6.006358     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.2          |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18000        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0491       |
|    value_loss               | 1.38         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.2674234] |
| time/                       |              |
|    fps                      | 126          |
|    iterations               | 38           |
|    time_elapsed             | 616          |
|    total_timesteps          | 3690496      |
| train/                      |              |
|    approx_kl                | 729.6969     |
|    approx_ln(kl)            | 6.5926294    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.23         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18010        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0486       |
|    value_loss               | 0.989        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.1198714] |
| time/                       |              |
|    fps                      | 126          |
|    iterations               | 39           |
|    time_elapsed             | 631          |
|    total_timesteps          | 3692544      |
| train/                      |              |
|    approx_kl                | 335.8151     |
|    approx_ln(kl)            | 5.8165607    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.18         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18020        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.05         |
|    value_loss               | 1.13         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.1391482] |
| time/                       |              |
|    fps                      | 125          |
|    iterations               | 40           |
|    time_elapsed             | 655          |
|    total_timesteps          | 3694592      |
| train/                      |              |
|    approx_kl                | 1081.5754    |
|    approx_ln(kl)            | 6.986174     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.18         |
|    explained_variance       | 0.991        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18030        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0504       |
|    value_loss               | 1.02         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.5480063] |
| time/                       |              |
|    fps                      | 122          |
|    iterations               | 41           |
|    time_elapsed             | 686          |
|    total_timesteps          | 3696640      |
| train/                      |              |
|    approx_kl                | 826.45544    |
|    approx_ln(kl)            | 6.717146     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.18         |
|    explained_variance       | 0.982        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18040        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0496       |
|    value_loss               | 6.35         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.5217984] |
| time/                       |              |
|    fps                      | 122          |
|    iterations               | 42           |
|    time_elapsed             | 701          |
|    total_timesteps          | 3698688      |
| train/                      |              |
|    approx_kl                | 604.36145    |
|    approx_ln(kl)            | 6.4041724    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.19         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18050        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0498       |
|    value_loss               | 2.26         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.2067506] |
| time/                       |              |
|    fps                      | 122          |
|    iterations               | 43           |
|    time_elapsed             | 717          |
|    total_timesteps          | 3700736      |
| train/                      |              |
|    approx_kl                | 353.8911     |
|    approx_ln(kl)            | 5.8689895    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.18         |
|    explained_variance       | 0.992        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18060        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0501       |
|    value_loss               | 4.8          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.1738439] |
| time/                       |              |
|    fps                      | 109          |
|    iterations               | 44           |
|    time_elapsed             | 821          |
|    total_timesteps          | 3702784      |
| train/                      |              |
|    approx_kl                | 476.3836     |
|    approx_ln(kl)            | 6.1662235    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.18         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18070        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0498       |
|    value_loss               | 2.13         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.3703063] |
| time/                       |              |
|    fps                      | 110          |
|    iterations               | 45           |
|    time_elapsed             | 835          |
|    total_timesteps          | 3704832      |
| train/                      |              |
|    approx_kl                | 612.3014     |
|    approx_ln(kl)            | 6.417225     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.19         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18080        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0497       |
|    value_loss               | 1.12         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.43680432] |
| time/                       |               |
|    fps                      | 110           |
|    iterations               | 46            |
|    time_elapsed             | 850           |
|    total_timesteps          | 3706880       |
| train/                      |               |
|    approx_kl                | 345.39127     |
|    approx_ln(kl)            | 5.844678      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.21          |
|    explained_variance       | 0.995         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 18090         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0492        |
|    value_loss               | 2.67          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.7289956] |
| time/                       |              |
|    fps                      | 111          |
|    iterations               | 47           |
|    time_elapsed             | 864          |
|    total_timesteps          | 3708928      |
| train/                      |              |
|    approx_kl                | 779.88324    |
|    approx_ln(kl)            | 6.6591444    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.23         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18100        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0486       |
|    value_loss               | 2.21         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.4867053] |
| time/                       |              |
|    fps                      | 111          |
|    iterations               | 48           |
|    time_elapsed             | 878          |
|    total_timesteps          | 3710976      |
| train/                      |              |
|    approx_kl                | 563.4878     |
|    approx_ln(kl)            | 6.3341455    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.26         |
|    explained_variance       | 0.973        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18110        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.048        |
|    value_loss               | 9.13         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.9660273] |
| time/                       |              |
|    fps                      | 102          |
|    iterations               | 49           |
|    time_elapsed             | 981          |
|    total_timesteps          | 3713024      |
| train/                      |              |
|    approx_kl                | 300.27472    |
|    approx_ln(kl)            | 5.7046976    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.26         |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18120        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.048        |
|    value_loss               | 2.56         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-------------------------------------
| reward             | [-3.2767353] |
| time/              |              |
|    fps             | 161          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 3715072      |
-------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.8064277] |
| time/                       |              |
|    fps                      | 154          |
|    iterations               | 2            |
|    time_elapsed             | 26           |
|    total_timesteps          | 3717120      |
| train/                      |              |
|    approx_kl                | 320.22647    |
|    approx_ln(kl)            | 5.7690287    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.25         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18140        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0483       |
|    value_loss               | 1.76         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.4191852] |
| time/                       |              |
|    fps                      | 152          |
|    iterations               | 3            |
|    time_elapsed             | 40           |
|    total_timesteps          | 3719168      |
| train/                      |              |
|    approx_kl                | 526.12665    |
|    approx_ln(kl)            | 6.265542     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.26         |
|    explained_variance       | 0.986        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18150        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0481       |
|    value_loss               | 6.72         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-------------------------------------------
| reward                      | [-3.496]  |
| time/                       |           |
|    fps                      | 152       |
|    iterations               | 4         |
|    time_elapsed             | 53        |
|    total_timesteps          | 3721216   |
| train/                      |           |
|    approx_kl                | 824.89355 |
|    approx_ln(kl)            | 6.7152543 |
|    clip_range               | 0.2       |
|    entropy_loss             | 3.25      |
|    explained_variance       | 0.997     |
|    learning_rate            | 0.001     |
|    ln(loss)                 | inf       |
|    ln(policy_gradient_loss) | nan       |
|    loss                     | inf       |
|    n_updates                | 18160     |
|    policy_gradient_loss     | nan       |
|    std                      | 0.0484    |
|    value_loss               | 1.36      |
-------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.5634391] |
| time/                       |              |
|    fps                      | 151          |
|    iterations               | 5            |
|    time_elapsed             | 67           |
|    total_timesteps          | 3723264      |
| train/                      |              |
|    approx_kl                | 417.309      |
|    approx_ln(kl)            | 6.033827     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.26         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18170        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0484       |
|    value_loss               | 0.955        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.6677787] |
| time/                       |              |
|    fps                      | 151          |
|    iterations               | 6            |
|    time_elapsed             | 81           |
|    total_timesteps          | 3725312      |
| train/                      |              |
|    approx_kl                | 415.95764    |
|    approx_ln(kl)            | 6.0305834    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.25         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18180        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0485       |
|    value_loss               | 1.11         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.9082463] |
| time/                       |              |
|    fps                      | 150          |
|    iterations               | 7            |
|    time_elapsed             | 95           |
|    total_timesteps          | 3727360      |
| train/                      |              |
|    approx_kl                | 676.9448     |
|    approx_ln(kl)            | 6.5175896    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.24         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18190        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0497       |
|    value_loss               | 2.07         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.88241655] |
| time/                       |               |
|    fps                      | 150           |
|    iterations               | 8             |
|    time_elapsed             | 109           |
|    total_timesteps          | 3729408       |
| train/                      |               |
|    approx_kl                | 1765.3795     |
|    approx_ln(kl)            | 7.476121      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.2           |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 18200         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0501        |
|    value_loss               | 1.12          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.1233925] |
| time/                       |              |
|    fps                      | 150          |
|    iterations               | 9            |
|    time_elapsed             | 122          |
|    total_timesteps          | 3731456      |
| train/                      |              |
|    approx_kl                | 637.5666     |
|    approx_ln(kl)            | 6.457659     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.21         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18210        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0496       |
|    value_loss               | 0.755        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.8958284] |
| time/                       |              |
|    fps                      | 150          |
|    iterations               | 10           |
|    time_elapsed             | 136          |
|    total_timesteps          | 3733504      |
| train/                      |              |
|    approx_kl                | 407.28815    |
|    approx_ln(kl)            | 6.009521     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.21         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18220        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0498       |
|    value_loss               | 1.43         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.9311395] |
| time/                       |              |
|    fps                      | 150          |
|    iterations               | 11           |
|    time_elapsed             | 150          |
|    total_timesteps          | 3735552      |
| train/                      |              |
|    approx_kl                | 941.75903    |
|    approx_ln(kl)            | 6.847749     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.19         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18230        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.05         |
|    value_loss               | 1.78         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
--------------------------------------------
| reward                      | [-2.91746] |
| time/                       |            |
|    fps                      | 149        |
|    iterations               | 12         |
|    time_elapsed             | 163        |
|    total_timesteps          | 3737600    |
| train/                      |            |
|    approx_kl                | 324.43726  |
|    approx_ln(kl)            | 5.782092   |
|    clip_range               | 0.2        |
|    entropy_loss             | 3.2        |
|    explained_variance       | 0.994      |
|    learning_rate            | 0.001      |
|    ln(loss)                 | inf        |
|    ln(policy_gradient_loss) | nan        |
|    loss                     | inf        |
|    n_updates                | 18240      |
|    policy_gradient_loss     | nan        |
|    std                      | 0.0499     |
|    value_loss               | 2.37       |
--------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.3525121] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 13           |
|    time_elapsed             | 177          |
|    total_timesteps          | 3739648      |
| train/                      |              |
|    approx_kl                | 542.43317    |
|    approx_ln(kl)            | 6.296065     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.2          |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18250        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0499       |
|    value_loss               | 2.56         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.6355112] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 14           |
|    time_elapsed             | 191          |
|    total_timesteps          | 3741696      |
| train/                      |              |
|    approx_kl                | 612.78455    |
|    approx_ln(kl)            | 6.4180136    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.22         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18260        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0497       |
|    value_loss               | 1.9          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.7614505] |
| time/                       |              |
|    fps                      | 149          |
|    iterations               | 15           |
|    time_elapsed             | 205          |
|    total_timesteps          | 3743744      |
| train/                      |              |
|    approx_kl                | 606.8023     |
|    approx_ln(kl)            | 6.408203     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.19         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18270        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0504       |
|    value_loss               | 1.2          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.072293] |
| time/                       |             |
|    fps                      | 149         |
|    iterations               | 16          |
|    time_elapsed             | 218         |
|    total_timesteps          | 3745792     |
| train/                      |             |
|    approx_kl                | 482.1435    |
|    approx_ln(kl)            | 6.1782417   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.17        |
|    explained_variance       | 0.999       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 18280       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0507      |
|    value_loss               | 1.35        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
--------------------------------------------
| reward                      | [-3.71153] |
| time/                       |            |
|    fps                      | 149        |
|    iterations               | 17         |
|    time_elapsed             | 232        |
|    total_timesteps          | 3747840    |
| train/                      |            |
|    approx_kl                | 487.54077  |
|    approx_ln(kl)            | 6.189374   |
|    clip_range               | 0.2        |
|    entropy_loss             | 3.18       |
|    explained_variance       | 0.99       |
|    learning_rate            | 0.001      |
|    ln(loss)                 | inf        |
|    ln(policy_gradient_loss) | nan        |
|    loss                     | inf        |
|    n_updates                | 18290      |
|    policy_gradient_loss     | nan        |
|    std                      | 0.0506     |
|    value_loss               | 6.57       |
--------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.32167283] |
| time/                       |               |
|    fps                      | 149           |
|    iterations               | 18            |
|    time_elapsed             | 246           |
|    total_timesteps          | 3749888       |
| train/                      |               |
|    approx_kl                | 15611.589     |
|    approx_ln(kl)            | 9.655768      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.17          |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 18300         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0509        |
|    value_loss               | 2.41          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-1.847287] |
| time/                       |             |
|    fps                      | 112         |
|    iterations               | 19          |
|    time_elapsed             | 347         |
|    total_timesteps          | 3751936     |
| train/                      |             |
|    approx_kl                | 337.05637   |
|    approx_ln(kl)            | 5.82025     |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.16        |
|    explained_variance       | 0.973       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 18310       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0511      |
|    value_loss               | 6.75        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.5250444] |
| time/                       |              |
|    fps                      | 91           |
|    iterations               | 20           |
|    time_elapsed             | 450          |
|    total_timesteps          | 3753984      |
| train/                      |              |
|    approx_kl                | 639.39734    |
|    approx_ln(kl)            | 6.460526     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.18         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18320        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0504       |
|    value_loss               | 2.41         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.0228584] |
| time/                       |              |
|    fps                      | 78           |
|    iterations               | 21           |
|    time_elapsed             | 547          |
|    total_timesteps          | 3756032      |
| train/                      |              |
|    approx_kl                | 1258.6218    |
|    approx_ln(kl)            | 7.1377726    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.18         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18330        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0505       |
|    value_loss               | 1.85         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.4294055] |
| time/                       |              |
|    fps                      | 80           |
|    iterations               | 22           |
|    time_elapsed             | 561          |
|    total_timesteps          | 3758080      |
| train/                      |              |
|    approx_kl                | 754.00464    |
|    approx_ln(kl)            | 6.6253986    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.17         |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18340        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.051        |
|    value_loss               | 3.36         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.6324828] |
| time/                       |              |
|    fps                      | 81           |
|    iterations               | 23           |
|    time_elapsed             | 575          |
|    total_timesteps          | 3760128      |
| train/                      |              |
|    approx_kl                | 454.1673     |
|    approx_ln(kl)            | 6.1184654    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.16         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18350        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0512       |
|    value_loss               | 3.28         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.867965] |
| time/                       |             |
|    fps                      | 83          |
|    iterations               | 24          |
|    time_elapsed             | 589         |
|    total_timesteps          | 3762176     |
| train/                      |             |
|    approx_kl                | 957.4501    |
|    approx_ln(kl)            | 6.8642735   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.14        |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 18360       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0515      |
|    value_loss               | 1.63        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.8109746] |
| time/                       |              |
|    fps                      | 84           |
|    iterations               | 25           |
|    time_elapsed             | 602          |
|    total_timesteps          | 3764224      |
| train/                      |              |
|    approx_kl                | 498.66348    |
|    approx_ln(kl)            | 6.2119317    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.16         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18370        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.051        |
|    value_loss               | 1.77         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.497788] |
| time/                       |             |
|    fps                      | 86          |
|    iterations               | 26          |
|    time_elapsed             | 616         |
|    total_timesteps          | 3766272     |
| train/                      |             |
|    approx_kl                | 672.8408    |
|    approx_ln(kl)            | 6.511509    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.14        |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 18380       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0512      |
|    value_loss               | 1.52        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.7982826] |
| time/                       |              |
|    fps                      | 87           |
|    iterations               | 27           |
|    time_elapsed             | 631          |
|    total_timesteps          | 3768320      |
| train/                      |              |
|    approx_kl                | 386.45483    |
|    approx_ln(kl)            | 5.957015     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.17         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18390        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0504       |
|    value_loss               | 1.31         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.3369412] |
| time/                       |              |
|    fps                      | 88           |
|    iterations               | 28           |
|    time_elapsed             | 645          |
|    total_timesteps          | 3770368      |
| train/                      |              |
|    approx_kl                | 457.92215    |
|    approx_ln(kl)            | 6.126699     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.2          |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18400        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0498       |
|    value_loss               | 1.2          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.2433846] |
| time/                       |              |
|    fps                      | 90           |
|    iterations               | 29           |
|    time_elapsed             | 658          |
|    total_timesteps          | 3772416      |
| train/                      |              |
|    approx_kl                | 884.3794     |
|    approx_ln(kl)            | 6.7848864    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.2          |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18410        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0498       |
|    value_loss               | 3.34         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.1062856] |
| time/                       |              |
|    fps                      | 91           |
|    iterations               | 30           |
|    time_elapsed             | 672          |
|    total_timesteps          | 3774464      |
| train/                      |              |
|    approx_kl                | 768.0397     |
|    approx_ln(kl)            | 6.6438413    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.2          |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18420        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0503       |
|    value_loss               | 1.12         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.4233963] |
| time/                       |              |
|    fps                      | 92           |
|    iterations               | 31           |
|    time_elapsed             | 686          |
|    total_timesteps          | 3776512      |
| train/                      |              |
|    approx_kl                | 541.48145    |
|    approx_ln(kl)            | 6.2943087    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.22         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18430        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0492       |
|    value_loss               | 1.07         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.8107955] |
| time/                       |              |
|    fps                      | 93           |
|    iterations               | 32           |
|    time_elapsed             | 700          |
|    total_timesteps          | 3778560      |
| train/                      |              |
|    approx_kl                | 1917.2861    |
|    approx_ln(kl)            | 7.558666     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.26         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18440        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0485       |
|    value_loss               | 0.694        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.0966756] |
| time/                       |              |
|    fps                      | 94           |
|    iterations               | 33           |
|    time_elapsed             | 714          |
|    total_timesteps          | 3780608      |
| train/                      |              |
|    approx_kl                | 243.47586    |
|    approx_ln(kl)            | 5.495018     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.26         |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18450        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0486       |
|    value_loss               | 7.33         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.6570148] |
| time/                       |              |
|    fps                      | 95           |
|    iterations               | 34           |
|    time_elapsed             | 728          |
|    total_timesteps          | 3782656      |
| train/                      |              |
|    approx_kl                | 300.77374    |
|    approx_ln(kl)            | 5.7063584    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.27         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18460        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0483       |
|    value_loss               | 2.24         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.6437237] |
| time/                       |              |
|    fps                      | 96           |
|    iterations               | 35           |
|    time_elapsed             | 742          |
|    total_timesteps          | 3784704      |
| train/                      |              |
|    approx_kl                | 466.96085    |
|    approx_ln(kl)            | 6.1462455    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.26         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18470        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0484       |
|    value_loss               | 0.982        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.7933476] |
| time/                       |              |
|    fps                      | 97           |
|    iterations               | 36           |
|    time_elapsed             | 756          |
|    total_timesteps          | 3786752      |
| train/                      |              |
|    approx_kl                | 318.83133    |
|    approx_ln(kl)            | 5.7646623    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.23         |
|    explained_variance       | 0.991        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18480        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0495       |
|    value_loss               | 5.89         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.157216] |
| time/                       |             |
|    fps                      | 98          |
|    iterations               | 37          |
|    time_elapsed             | 769         |
|    total_timesteps          | 3788800     |
| train/                      |             |
|    approx_kl                | 394.03525   |
|    approx_ln(kl)            | 5.9764404   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.22        |
|    explained_variance       | 0.935       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 18490       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0496      |
|    value_loss               | 24.4        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.1443858] |
| time/                       |              |
|    fps                      | 99           |
|    iterations               | 38           |
|    time_elapsed             | 783          |
|    total_timesteps          | 3790848      |
| train/                      |              |
|    approx_kl                | 548.36646    |
|    approx_ln(kl)            | 6.306944     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.22         |
|    explained_variance       | 0.864        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18500        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0496       |
|    value_loss               | 10.3         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.40471125] |
| time/                       |               |
|    fps                      | 100           |
|    iterations               | 39            |
|    time_elapsed             | 797           |
|    total_timesteps          | 3792896       |
| train/                      |               |
|    approx_kl                | 483.7303      |
|    approx_ln(kl)            | 6.1815276     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.2           |
|    explained_variance       | 0.629         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 18510         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0502        |
|    value_loss               | 15.8          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.47372964] |
| time/                       |               |
|    fps                      | 101           |
|    iterations               | 40            |
|    time_elapsed             | 811           |
|    total_timesteps          | 3794944       |
| train/                      |               |
|    approx_kl                | 4765.6562     |
|    approx_ln(kl)            | 8.469191      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.19          |
|    explained_variance       | 0.939         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 18520         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0503        |
|    value_loss               | 12.8          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-0.610306] |
| time/                       |             |
|    fps                      | 101         |
|    iterations               | 41          |
|    time_elapsed             | 824         |
|    total_timesteps          | 3796992     |
| train/                      |             |
|    approx_kl                | 10371.608   |
|    approx_ln(kl)            | 9.246827    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.19        |
|    explained_variance       | 0.975       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 18530       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0505      |
|    value_loss               | 10.3        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.42667118] |
| time/                       |               |
|    fps                      | 102           |
|    iterations               | 42            |
|    time_elapsed             | 838           |
|    total_timesteps          | 3799040       |
| train/                      |               |
|    approx_kl                | 3692.436      |
|    approx_ln(kl)            | 8.214042      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.19          |
|    explained_variance       | 0.985         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 18540         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0504        |
|    value_loss               | 10            |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.5264394] |
| time/                       |              |
|    fps                      | 103          |
|    iterations               | 43           |
|    time_elapsed             | 852          |
|    total_timesteps          | 3801088      |
| train/                      |              |
|    approx_kl                | 940.0188     |
|    approx_ln(kl)            | 6.8459       |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.21         |
|    explained_variance       | 0.976        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18550        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0497       |
|    value_loss               | 82.8         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.0920548] |
| time/                       |              |
|    fps                      | 104          |
|    iterations               | 44           |
|    time_elapsed             | 866          |
|    total_timesteps          | 3803136      |
| train/                      |              |
|    approx_kl                | 501.86304    |
|    approx_ln(kl)            | 6.218327     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.2          |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18560        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0503       |
|    value_loss               | 5.6          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.38986248] |
| time/                       |               |
|    fps                      | 104           |
|    iterations               | 45            |
|    time_elapsed             | 880           |
|    total_timesteps          | 3805184       |
| train/                      |               |
|    approx_kl                | 1137.134      |
|    approx_ln(kl)            | 7.0362663     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.2           |
|    explained_variance       | 0.997         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 18570         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0504        |
|    value_loss               | 6.05          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.53806996] |
| time/                       |               |
|    fps                      | 105           |
|    iterations               | 46            |
|    time_elapsed             | 893           |
|    total_timesteps          | 3807232       |
| train/                      |               |
|    approx_kl                | 755.4841      |
|    approx_ln(kl)            | 6.627359      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.18          |
|    explained_variance       | 0.995         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 18580         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0507        |
|    value_loss               | 9.49          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.1104646] |
| time/                       |              |
|    fps                      | 106          |
|    iterations               | 47           |
|    time_elapsed             | 907          |
|    total_timesteps          | 3809280      |
| train/                      |              |
|    approx_kl                | 1867.6648    |
|    approx_ln(kl)            | 7.532444     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.19         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18590        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0504       |
|    value_loss               | 5.3          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4320374] |
| time/                       |              |
|    fps                      | 106          |
|    iterations               | 48           |
|    time_elapsed             | 921          |
|    total_timesteps          | 3811328      |
| train/                      |              |
|    approx_kl                | 5455.9805    |
|    approx_ln(kl)            | 8.604467     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.16         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18600        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0513       |
|    value_loss               | 1.62         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.6859193] |
| time/                       |              |
|    fps                      | 107          |
|    iterations               | 49           |
|    time_elapsed             | 935          |
|    total_timesteps          | 3813376      |
| train/                      |              |
|    approx_kl                | 7150.973     |
|    approx_ln(kl)            | 8.875004     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.16         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18610        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0509       |
|    value_loss               | 6.92         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-------------------------------------
| reward             | [-0.5365473] |
| time/              |              |
|    fps             | 163          |
|    iterations      | 1            |
|    time_elapsed    | 12           |
|    total_timesteps | 3815424      |
-------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.54040366] |
| time/                       |               |
|    fps                      | 156           |
|    iterations               | 2             |
|    time_elapsed             | 26            |
|    total_timesteps          | 3817472       |
| train/                      |               |
|    approx_kl                | 1232.7114     |
|    approx_ln(kl)            | 7.1169715     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.14          |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 18630         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0513        |
|    value_loss               | 6.13          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.2641096] |
| time/                       |              |
|    fps                      | 154          |
|    iterations               | 3            |
|    time_elapsed             | 39           |
|    total_timesteps          | 3819520      |
| train/                      |              |
|    approx_kl                | 6683.7974    |
|    approx_ln(kl)            | 8.807442     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.15         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18640        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.051        |
|    value_loss               | 4.1          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.7615876] |
| time/                       |              |
|    fps                      | 152          |
|    iterations               | 4            |
|    time_elapsed             | 53           |
|    total_timesteps          | 3821568      |
| train/                      |              |
|    approx_kl                | 4019.5269    |
|    approx_ln(kl)            | 8.29892      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.23         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18650        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0491       |
|    value_loss               | 1.3          |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5382301] |
| time/                       |              |
|    fps                      | 151          |
|    iterations               | 5            |
|    time_elapsed             | 67           |
|    total_timesteps          | 3823616      |
| train/                      |              |
|    approx_kl                | 3466.4417    |
|    approx_ln(kl)            | 8.150884     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.24         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18660        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0489       |
|    value_loss               | 2.64         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.5781658] |
| time/                       |              |
|    fps                      | 151          |
|    iterations               | 6            |
|    time_elapsed             | 81           |
|    total_timesteps          | 3825664      |
| train/                      |              |
|    approx_kl                | 3489.6997    |
|    approx_ln(kl)            | 8.157571     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.24         |
|    explained_variance       | 1            |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18670        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0489       |
|    value_loss               | 1.47         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.8452692] |
| time/                       |              |
|    fps                      | 150          |
|    iterations               | 7            |
|    time_elapsed             | 95           |
|    total_timesteps          | 3827712      |
| train/                      |              |
|    approx_kl                | 1218.9333    |
|    approx_ln(kl)            | 7.1057315    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.24         |
|    explained_variance       | 0.978        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18680        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0488       |
|    value_loss               | 18.1         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.335997] |
| time/                       |             |
|    fps                      | 150         |
|    iterations               | 8           |
|    time_elapsed             | 108         |
|    total_timesteps          | 3829760     |
| train/                      |             |
|    approx_kl                | 5258.3906   |
|    approx_ln(kl)            | 8.56758     |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.28        |
|    explained_variance       | 0.975       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 18690       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0477      |
|    value_loss               | 79          |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.531313] |
| time/                       |             |
|    fps                      | 149         |
|    iterations               | 9           |
|    time_elapsed             | 123         |
|    total_timesteps          | 3831808     |
| train/                      |             |
|    approx_kl                | 2601.0984   |
|    approx_ln(kl)            | 7.863689    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.3         |
|    explained_variance       | 0.991       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 18700       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0472      |
|    value_loss               | 11.5        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.6915874] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 10           |
|    time_elapsed             | 137          |
|    total_timesteps          | 3833856      |
| train/                      |              |
|    approx_kl                | 6243.6875    |
|    approx_ln(kl)            | 8.7393265    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.31         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18710        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0472       |
|    value_loss               | 7.58         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.8623905] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 11           |
|    time_elapsed             | 151          |
|    total_timesteps          | 3835904      |
| train/                      |              |
|    approx_kl                | 507.90503    |
|    approx_ln(kl)            | 6.2302947    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.28         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18720        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0481       |
|    value_loss               | 5.66         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5952657] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 12           |
|    time_elapsed             | 165          |
|    total_timesteps          | 3837952      |
| train/                      |              |
|    approx_kl                | 447.3786     |
|    approx_ln(kl)            | 6.103405     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.28         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18730        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0481       |
|    value_loss               | 6.1          |
----------------------------------------------
----------------------------------------------
| reward                      | [-1.0002426] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 13           |
|    time_elapsed             | 179          |
|    total_timesteps          | 3840000      |
| train/                      |              |
|    approx_kl                | 4275.15      |
|    approx_ln(kl)            | 8.360575     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.27         |
|    explained_variance       | 0.973        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 18740        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0481       |
|    value_loss               | 73.6         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.5735991] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 14           |
|    time_elapsed             | 193          |
|    total_timesteps          | 3842048      |
| train/                      |              |
|    approx_kl                | 1330.0239    |
|    approx_ln(kl)            | 7.192952     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.27         |
|    explained_variance       | 0.989        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18750        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0481       |
|    value_loss               | 74.7         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.6103072] |
| time/                       |              |
|    fps                      | 148          |
|    iterations               | 15           |
|    time_elapsed             | 207          |
|    total_timesteps          | 3844096      |
| train/                      |              |
|    approx_kl                | 3118.9214    |
|    approx_ln(kl)            | 8.045242     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.27         |
|    explained_variance       | 0.991        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18760        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0481       |
|    value_loss               | 81           |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.170482] |
| time/                       |             |
|    fps                      | 148         |
|    iterations               | 16          |
|    time_elapsed             | 220         |
|    total_timesteps          | 3846144     |
| train/                      |             |
|    approx_kl                | 1203.0807   |
|    approx_ln(kl)            | 7.092641    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.27        |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 18770       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0482      |
|    value_loss               | 5.88        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.6122026] |
| time/                       |              |
|    fps                      | 147          |
|    iterations               | 17           |
|    time_elapsed             | 235          |
|    total_timesteps          | 3848192      |
| train/                      |              |
|    approx_kl                | 1555.3877    |
|    approx_ln(kl)            | 7.34948      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.26         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18780        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0483       |
|    value_loss               | 4.96         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.8340786] |
| time/                       |              |
|    fps                      | 119          |
|    iterations               | 18           |
|    time_elapsed             | 307          |
|    total_timesteps          | 3850240      |
| train/                      |              |
|    approx_kl                | 1796.5496    |
|    approx_ln(kl)            | 7.4936233    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.26         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18790        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0485       |
|    value_loss               | 4.15         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.9202669] |
| time/                       |              |
|    fps                      | 121          |
|    iterations               | 19           |
|    time_elapsed             | 321          |
|    total_timesteps          | 3852288      |
| train/                      |              |
|    approx_kl                | 2076.57      |
|    approx_ln(kl)            | 7.638473     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.22         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18800        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0494       |
|    value_loss               | 3.36         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.3621063] |
| time/                       |              |
|    fps                      | 122          |
|    iterations               | 20           |
|    time_elapsed             | 335          |
|    total_timesteps          | 3854336      |
| train/                      |              |
|    approx_kl                | 10358.623    |
|    approx_ln(kl)            | 9.245575     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.24         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18810        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0487       |
|    value_loss               | 2.69         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.2432158] |
| time/                       |              |
|    fps                      | 123          |
|    iterations               | 21           |
|    time_elapsed             | 348          |
|    total_timesteps          | 3856384      |
| train/                      |              |
|    approx_kl                | 1960.7483    |
|    approx_ln(kl)            | 7.5810814    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.26         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18820        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0486       |
|    value_loss               | 3.16         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.871583] |
| time/                       |             |
|    fps                      | 124         |
|    iterations               | 22          |
|    time_elapsed             | 362         |
|    total_timesteps          | 3858432     |
| train/                      |             |
|    approx_kl                | 860.21484   |
|    approx_ln(kl)            | 6.757182    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.25        |
|    explained_variance       | 0.972       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 18830       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0487      |
|    value_loss               | 11.6        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5945185] |
| time/                       |              |
|    fps                      | 124          |
|    iterations               | 23           |
|    time_elapsed             | 376          |
|    total_timesteps          | 3860480      |
| train/                      |              |
|    approx_kl                | 1967.4121    |
|    approx_ln(kl)            | 7.5844746    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.27         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18840        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0483       |
|    value_loss               | 6.76         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-0.922601] |
| time/                       |             |
|    fps                      | 125         |
|    iterations               | 24          |
|    time_elapsed             | 390         |
|    total_timesteps          | 3862528     |
| train/                      |             |
|    approx_kl                | 2916.3872   |
|    approx_ln(kl)            | 7.978101    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.27        |
|    explained_variance       | 0.993       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 18850       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0482      |
|    value_loss               | 54.5        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4012376] |
| time/                       |              |
|    fps                      | 126          |
|    iterations               | 25           |
|    time_elapsed             | 404          |
|    total_timesteps          | 3864576      |
| train/                      |              |
|    approx_kl                | 6943.318     |
|    approx_ln(kl)            | 8.845535     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.28         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18860        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.048        |
|    value_loss               | 5.02         |
----------------------------------------------
----------------------------------------------
| reward                      | [-2.2793603] |
| time/                       |              |
|    fps                      | 127          |
|    iterations               | 26           |
|    time_elapsed             | 418          |
|    total_timesteps          | 3866624      |
| train/                      |              |
|    approx_kl                | 3107.2002    |
|    approx_ln(kl)            | 8.041477     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.28         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 18870        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0477       |
|    value_loss               | 4.66         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.9438884] |
| time/                       |              |
|    fps                      | 127          |
|    iterations               | 27           |
|    time_elapsed             | 432          |
|    total_timesteps          | 3868672      |
| train/                      |              |
|    approx_kl                | 3334.2532    |
|    approx_ln(kl)            | 8.112004     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.28         |
|    explained_variance       | 0.96         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18880        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0481       |
|    value_loss               | 23.2         |
----------------------------------------------
----------------------------------------------
| reward                      | [-2.4642494] |
| time/                       |              |
|    fps                      | 128          |
|    iterations               | 28           |
|    time_elapsed             | 446          |
|    total_timesteps          | 3870720      |
| train/                      |              |
|    approx_kl                | 4824.6133    |
|    approx_ln(kl)            | 8.481486     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.28         |
|    explained_variance       | 0.994        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 18890        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.048        |
|    value_loss               | 22.2         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.627292] |
| time/                       |             |
|    fps                      | 129         |
|    iterations               | 29          |
|    time_elapsed             | 459         |
|    total_timesteps          | 3872768     |
| train/                      |             |
|    approx_kl                | 638.7793    |
|    approx_ln(kl)            | 6.459559    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.3         |
|    explained_variance       | 0.993       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 18900       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0477      |
|    value_loss               | 12.8        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.40516046] |
| time/                       |               |
|    fps                      | 129           |
|    iterations               | 30            |
|    time_elapsed             | 473           |
|    total_timesteps          | 3874816       |
| train/                      |               |
|    approx_kl                | 8047.009      |
|    approx_ln(kl)            | 8.993055      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.31          |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 18910         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0474        |
|    value_loss               | 4.49          |
-----------------------------------------------
----------------------------------------------
| reward                      | [-3.2879782] |
| time/                       |              |
|    fps                      | 130          |
|    iterations               | 31           |
|    time_elapsed             | 488          |
|    total_timesteps          | 3876864      |
| train/                      |              |
|    approx_kl                | 4049.254     |
|    approx_ln(kl)            | 8.306288     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.35         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 18920        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0464       |
|    value_loss               | 3.28         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.49487355] |
| time/                       |               |
|    fps                      | 130           |
|    iterations               | 32            |
|    time_elapsed             | 502           |
|    total_timesteps          | 3878912       |
| train/                      |               |
|    approx_kl                | 5362.494      |
|    approx_ln(kl)            | 8.587185      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.37          |
|    explained_variance       | 0.99          |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 18930         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0456        |
|    value_loss               | 14.5          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-4.426386] |
| time/                       |             |
|    fps                      | 131         |
|    iterations               | 33          |
|    time_elapsed             | 515         |
|    total_timesteps          | 3880960     |
| train/                      |             |
|    approx_kl                | 477.83084   |
|    approx_ln(kl)            | 6.1692567   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.38        |
|    explained_variance       | 0.998       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 18940       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0454      |
|    value_loss               | 2.02        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.51197267] |
| time/                       |               |
|    fps                      | 131           |
|    iterations               | 34            |
|    time_elapsed             | 529           |
|    total_timesteps          | 3883008       |
| train/                      |               |
|    approx_kl                | 1124.3774     |
|    approx_ln(kl)            | 7.024985      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.37          |
|    explained_variance       | 0.987         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 18950         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0459        |
|    value_loss               | 26.1          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.35289922] |
| time/                       |               |
|    fps                      | 131           |
|    iterations               | 35            |
|    time_elapsed             | 543           |
|    total_timesteps          | 3885056       |
| train/                      |               |
|    approx_kl                | 1522.0117     |
|    approx_ln(kl)            | 7.3277884     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.37          |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 18960         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0458        |
|    value_loss               | 8.27          |
-----------------------------------------------
----------------------------------------------
| reward                      | [-1.8776945] |
| time/                       |              |
|    fps                      | 132          |
|    iterations               | 36           |
|    time_elapsed             | 556          |
|    total_timesteps          | 3887104      |
| train/                      |              |
|    approx_kl                | 5273.41      |
|    approx_ln(kl)            | 8.570433     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.37         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 18970        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0459       |
|    value_loss               | 15           |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.293994] |
| time/                       |             |
|    fps                      | 132         |
|    iterations               | 37          |
|    time_elapsed             | 571         |
|    total_timesteps          | 3889152     |
| train/                      |             |
|    approx_kl                | 4911.2397   |
|    approx_ln(kl)            | 8.499282    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.4         |
|    explained_variance       | 0.997       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 18980       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0451      |
|    value_loss               | 9.17        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.6125798] |
| time/                       |              |
|    fps                      | 132          |
|    iterations               | 38           |
|    time_elapsed             | 585          |
|    total_timesteps          | 3891200      |
| train/                      |              |
|    approx_kl                | 2394.601     |
|    approx_ln(kl)            | 7.780972     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.38         |
|    explained_variance       | 0.989        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 18990        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0457       |
|    value_loss               | 71.4         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.043175] |
| time/                       |             |
|    fps                      | 133         |
|    iterations               | 39          |
|    time_elapsed             | 598         |
|    total_timesteps          | 3893248     |
| train/                      |             |
|    approx_kl                | 1062.2256   |
|    approx_ln(kl)            | 6.9681215   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.37        |
|    explained_variance       | 0.997       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 19000       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0458      |
|    value_loss               | 4.84        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-2.886594] |
| time/                       |             |
|    fps                      | 133         |
|    iterations               | 40          |
|    time_elapsed             | 612         |
|    total_timesteps          | 3895296     |
| train/                      |             |
|    approx_kl                | 1189.0039   |
|    approx_ln(kl)            | 7.080871    |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.38        |
|    explained_variance       | 0.992       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 19010       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0455      |
|    value_loss               | 16.1        |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.6722753] |
| time/                       |              |
|    fps                      | 134          |
|    iterations               | 41           |
|    time_elapsed             | 626          |
|    total_timesteps          | 3897344      |
| train/                      |              |
|    approx_kl                | 7140.7188    |
|    approx_ln(kl)            | 8.873569     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.41         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 19020        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.045        |
|    value_loss               | 4.77         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.1011252] |
| time/                       |              |
|    fps                      | 134          |
|    iterations               | 42           |
|    time_elapsed             | 640          |
|    total_timesteps          | 3899392      |
| train/                      |              |
|    approx_kl                | 16131.498    |
|    approx_ln(kl)            | 9.688529     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.43         |
|    explained_variance       | 0.987        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 19030        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0445       |
|    value_loss               | 9.33         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.3846811] |
| time/                       |              |
|    fps                      | 133          |
|    iterations               | 43           |
|    time_elapsed             | 658          |
|    total_timesteps          | 3901440      |
| train/                      |              |
|    approx_kl                | 1728.8477    |
|    approx_ln(kl)            | 7.45521      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.41         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 19040        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.045        |
|    value_loss               | 6.39         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.4650596] |
| time/                       |              |
|    fps                      | 133          |
|    iterations               | 44           |
|    time_elapsed             | 674          |
|    total_timesteps          | 3903488      |
| train/                      |              |
|    approx_kl                | 4947.994     |
|    approx_ln(kl)            | 8.506738     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.42         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 19050        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0448       |
|    value_loss               | 5.07         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-4.1442795] |
| time/                       |              |
|    fps                      | 133          |
|    iterations               | 45           |
|    time_elapsed             | 690          |
|    total_timesteps          | 3905536      |
| train/                      |              |
|    approx_kl                | 621.7561     |
|    approx_ln(kl)            | 6.432548     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.42         |
|    explained_variance       | 0.996        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 19060        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0448       |
|    value_loss               | 5.59         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.8237387] |
| time/                       |              |
|    fps                      | 133          |
|    iterations               | 46           |
|    time_elapsed             | 705          |
|    total_timesteps          | 3907584      |
| train/                      |              |
|    approx_kl                | 11666.223    |
|    approx_ln(kl)            | 9.364453     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.45         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 19070        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.044        |
|    value_loss               | 3.34         |
----------------------------------------------
----------------------------------------------
| reward                      | [-1.3315803] |
| time/                       |              |
|    fps                      | 133          |
|    iterations               | 47           |
|    time_elapsed             | 722          |
|    total_timesteps          | 3909632      |
| train/                      |              |
|    approx_kl                | 5201.304     |
|    approx_ln(kl)            | 8.556664     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.44         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 19080        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0445       |
|    value_loss               | 3.15         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.9480408] |
| time/                       |              |
|    fps                      | 133          |
|    iterations               | 48           |
|    time_elapsed             | 738          |
|    total_timesteps          | 3911680      |
| train/                      |              |
|    approx_kl                | 1808.47      |
|    approx_ln(kl)            | 7.5002365    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.43         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 19090        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0446       |
|    value_loss               | 2.49         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.4451575] |
| time/                       |              |
|    fps                      | 132          |
|    iterations               | 49           |
|    time_elapsed             | 754          |
|    total_timesteps          | 3913728      |
| train/                      |              |
|    approx_kl                | 3743.434     |
|    approx_ln(kl)            | 8.227758     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.42         |
|    explained_variance       | 0.979        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 19100        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0449       |
|    value_loss               | 66           |
----------------------------------------------
-------------------------------------
| reward             | [-3.1335151] |
| time/              |              |
|    fps             | 137          |
|    iterations      | 1            |
|    time_elapsed    | 14           |
|    total_timesteps | 3915776      |
-------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.5223384] |
| time/                       |              |
|    fps                      | 131          |
|    iterations               | 2            |
|    time_elapsed             | 31           |
|    total_timesteps          | 3917824      |
| train/                      |              |
|    approx_kl                | 2142.578     |
|    approx_ln(kl)            | 7.669765     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.4          |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 19120        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0457       |
|    value_loss               | 3.18         |
----------------------------------------------
----------------------------------------------
| reward                      | [-2.7910862] |
| time/                       |              |
|    fps                      | 130          |
|    iterations               | 3            |
|    time_elapsed             | 46           |
|    total_timesteps          | 3919872      |
| train/                      |              |
|    approx_kl                | 2648.727     |
|    approx_ln(kl)            | 7.8818345    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.36         |
|    explained_variance       | 0.988        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 19130        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.046        |
|    value_loss               | 37.8         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.6546197] |
| time/                       |              |
|    fps                      | 131          |
|    iterations               | 4            |
|    time_elapsed             | 62           |
|    total_timesteps          | 3921920      |
| train/                      |              |
|    approx_kl                | 923.3405     |
|    approx_ln(kl)            | 6.827998     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.37         |
|    explained_variance       | 0.993        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 19140        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.046        |
|    value_loss               | 8.76         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.3556826] |
| time/                       |              |
|    fps                      | 131          |
|    iterations               | 5            |
|    time_elapsed             | 77           |
|    total_timesteps          | 3923968      |
| train/                      |              |
|    approx_kl                | 4418.82      |
|    approx_ln(kl)            | 8.393628     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.42         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 19150        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0448       |
|    value_loss               | 4.64         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.2985892] |
| time/                       |              |
|    fps                      | 130          |
|    iterations               | 6            |
|    time_elapsed             | 94           |
|    total_timesteps          | 3926016      |
| train/                      |              |
|    approx_kl                | 6070.713     |
|    approx_ln(kl)            | 8.711231     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.41         |
|    explained_variance       | 0.997        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 19160        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0454       |
|    value_loss               | 4.44         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
---------------------------------------------
| reward                      | [-3.976495] |
| time/                       |             |
|    fps                      | 130         |
|    iterations               | 7           |
|    time_elapsed             | 109         |
|    total_timesteps          | 3928064     |
| train/                      |             |
|    approx_kl                | 2934.9758   |
|    approx_ln(kl)            | 7.9844546   |
|    clip_range               | 0.2         |
|    entropy_loss             | 3.4         |
|    explained_variance       | 0.997       |
|    learning_rate            | 0.001       |
|    ln(loss)                 | inf         |
|    ln(policy_gradient_loss) | nan         |
|    loss                     | inf         |
|    n_updates                | 19170       |
|    policy_gradient_loss     | nan         |
|    std                      | 0.0453      |
|    value_loss               | 5           |
---------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.63821745] |
| time/                       |               |
|    fps                      | 131           |
|    iterations               | 8             |
|    time_elapsed             | 124           |
|    total_timesteps          | 3930112       |
| train/                      |               |
|    approx_kl                | 6730.1675     |
|    approx_ln(kl)            | 8.814355      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.43          |
|    explained_variance       | 0.995         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 19180         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0446        |
|    value_loss               | 5.09          |
-----------------------------------------------
----------------------------------------------
| reward                      | [-1.0496081] |
| time/                       |              |
|    fps                      | 129          |
|    iterations               | 9            |
|    time_elapsed             | 141          |
|    total_timesteps          | 3932160      |
| train/                      |              |
|    approx_kl                | 1992.3105    |
|    approx_ln(kl)            | 7.59705      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.44         |
|    explained_variance       | 0.995        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 19190        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0447       |
|    value_loss               | 5.48         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.3935978] |
| time/                       |              |
|    fps                      | 128          |
|    iterations               | 10           |
|    time_elapsed             | 158          |
|    total_timesteps          | 3934208      |
| train/                      |              |
|    approx_kl                | 1848.759     |
|    approx_ln(kl)            | 7.5222697    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.45         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 19200        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0442       |
|    value_loss               | 2.41         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.5511892] |
| time/                       |              |
|    fps                      | 128          |
|    iterations               | 11           |
|    time_elapsed             | 175          |
|    total_timesteps          | 3936256      |
| train/                      |              |
|    approx_kl                | 4853.413     |
|    approx_ln(kl)            | 8.487437     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.44         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 19210        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0445       |
|    value_loss               | 2.83         |
----------------------------------------------
----------------------------------------------
| reward                      | [-3.0630174] |
| time/                       |              |
|    fps                      | 127          |
|    iterations               | 12           |
|    time_elapsed             | 193          |
|    total_timesteps          | 3938304      |
| train/                      |              |
|    approx_kl                | 889.3114     |
|    approx_ln(kl)            | 6.790447     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.43         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 19220        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0447       |
|    value_loss               | 1.16         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-------------------------------------------
| reward                      | [-2.5678] |
| time/                       |           |
|    fps                      | 126       |
|    iterations               | 13        |
|    time_elapsed             | 210       |
|    total_timesteps          | 3940352   |
| train/                      |           |
|    approx_kl                | 4198.6562 |
|    approx_ln(kl)            | 8.34252   |
|    clip_range               | 0.2       |
|    entropy_loss             | 3.44      |
|    explained_variance       | 0.998     |
|    learning_rate            | 0.001     |
|    ln(loss)                 | inf       |
|    ln(policy_gradient_loss) | nan       |
|    loss                     | inf       |
|    n_updates                | 19230     |
|    policy_gradient_loss     | nan       |
|    std                      | 0.0441    |
|    value_loss               | 2.4       |
-------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-2.1397111] |
| time/                       |              |
|    fps                      | 128          |
|    iterations               | 14           |
|    time_elapsed             | 223          |
|    total_timesteps          | 3942400      |
| train/                      |              |
|    approx_kl                | 2134.023     |
|    approx_ln(kl)            | 7.6657643    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.46         |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 19240        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0438       |
|    value_loss               | 2.38         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-3.8872871] |
| time/                       |              |
|    fps                      | 129          |
|    iterations               | 15           |
|    time_elapsed             | 237          |
|    total_timesteps          | 3944448      |
| train/                      |              |
|    approx_kl                | 2232.296     |
|    approx_ln(kl)            | 7.710786     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.47         |
|    explained_variance       | 0.998        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 19250        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0436       |
|    value_loss               | 2.71         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.6835706] |
| time/                       |              |
|    fps                      | 130          |
|    iterations               | 16           |
|    time_elapsed             | 251          |
|    total_timesteps          | 3946496      |
| train/                      |              |
|    approx_kl                | 6598.9375    |
|    approx_ln(kl)            | 8.794664     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.5          |
|    explained_variance       | 0.999        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 19260        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.043        |
|    value_loss               | 3.46         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.2761637] |
| time/                       |              |
|    fps                      | 131          |
|    iterations               | 17           |
|    time_elapsed             | 265          |
|    total_timesteps          | 3948544      |
| train/                      |              |
|    approx_kl                | 251.32036    |
|    approx_ln(kl)            | 5.5267286    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.5          |
|    explained_variance       | 0.992        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 19270        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0429       |
|    value_loss               | 7.52         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.27389205] |
| time/                       |               |
|    fps                      | 132           |
|    iterations               | 18            |
|    time_elapsed             | 279           |
|    total_timesteps          | 3950592       |
| train/                      |               |
|    approx_kl                | 5899.3584     |
|    approx_ln(kl)            | 8.682599      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.52          |
|    explained_variance       | 0.994         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 19280         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0423        |
|    value_loss               | 8.39          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.97212046] |
| time/                       |               |
|    fps                      | 132           |
|    iterations               | 19            |
|    time_elapsed             | 293           |
|    total_timesteps          | 3952640       |
| train/                      |               |
|    approx_kl                | 22588.432     |
|    approx_ln(kl)            | 10.025193     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.57          |
|    explained_variance       | 0.998         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 19290         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0413        |
|    value_loss               | 2.95          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.80515134] |
| time/                       |               |
|    fps                      | 133           |
|    iterations               | 20            |
|    time_elapsed             | 306           |
|    total_timesteps          | 3954688       |
| train/                      |               |
|    approx_kl                | 2131.3716     |
|    approx_ln(kl)            | 7.664521      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.6           |
|    explained_variance       | 0.997         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 19300         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0407        |
|    value_loss               | 3.05          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7711048] |
| time/                       |              |
|    fps                      | 134          |
|    iterations               | 21           |
|    time_elapsed             | 320          |
|    total_timesteps          | 3956736      |
| train/                      |              |
|    approx_kl                | 2848.3342    |
|    approx_ln(kl)            | 7.9544897    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.6          |
|    explained_variance       | 0.983        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 19310        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.041        |
|    value_loss               | 7.93         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.41482022] |
| time/                       |               |
|    fps                      | 134           |
|    iterations               | 22            |
|    time_elapsed             | 334           |
|    total_timesteps          | 3958784       |
| train/                      |               |
|    approx_kl                | 7968.1787     |
|    approx_ln(kl)            | 8.9832115     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.58          |
|    explained_variance       | 0.966         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 19320         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0413        |
|    value_loss               | 5.94          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.45329913] |
| time/                       |               |
|    fps                      | 135           |
|    iterations               | 23            |
|    time_elapsed             | 348           |
|    total_timesteps          | 3960832       |
| train/                      |               |
|    approx_kl                | 4563.009      |
|    approx_ln(kl)            | 8.425737      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.59          |
|    explained_variance       | 0.838         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 19330         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.041         |
|    value_loss               | 2.1           |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5910044] |
| time/                       |              |
|    fps                      | 135          |
|    iterations               | 24           |
|    time_elapsed             | 362          |
|    total_timesteps          | 3962880      |
| train/                      |              |
|    approx_kl                | 3260.5234    |
|    approx_ln(kl)            | 8.0896435    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.6          |
|    explained_variance       | 0.9          |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 19340        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0407       |
|    value_loss               | 9.28         |
----------------------------------------------
----------------------------------------------
| reward                      | [-0.7626539] |
| time/                       |              |
|    fps                      | 136          |
|    iterations               | 25           |
|    time_elapsed             | 375          |
|    total_timesteps          | 3964928      |
| train/                      |              |
|    approx_kl                | 4318.6855    |
|    approx_ln(kl)            | 8.370707     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.6          |
|    explained_variance       | 0.967        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | inf          |
|    loss                     | inf          |
|    n_updates                | 19350        |
|    policy_gradient_loss     | inf          |
|    std                      | 0.0407       |
|    value_loss               | 3.16         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6815748] |
| time/                       |              |
|    fps                      | 136          |
|    iterations               | 26           |
|    time_elapsed             | 390          |
|    total_timesteps          | 3966976      |
| train/                      |              |
|    approx_kl                | 5532.088     |
|    approx_ln(kl)            | 8.61832      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.62         |
|    explained_variance       | 0.947        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 19360        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0406       |
|    value_loss               | 1.23         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.47397745] |
| time/                       |               |
|    fps                      | 136           |
|    iterations               | 27            |
|    time_elapsed             | 404           |
|    total_timesteps          | 3969024       |
| train/                      |               |
|    approx_kl                | 11229.291     |
|    approx_ln(kl)            | 9.326281      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.61          |
|    explained_variance       | 0.897         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 19370         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0407        |
|    value_loss               | 1.16          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5418377] |
| time/                       |              |
|    fps                      | 137          |
|    iterations               | 28           |
|    time_elapsed             | 417          |
|    total_timesteps          | 3971072      |
| train/                      |              |
|    approx_kl                | 17448.762    |
|    approx_ln(kl)            | 9.767024     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.62         |
|    explained_variance       | 0.844        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 19380        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0402       |
|    value_loss               | 5.46         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4948427] |
| time/                       |              |
|    fps                      | 137          |
|    iterations               | 29           |
|    time_elapsed             | 431          |
|    total_timesteps          | 3973120      |
| train/                      |              |
|    approx_kl                | 3854.813     |
|    approx_ln(kl)            | 8.257078     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.63         |
|    explained_variance       | 0.93         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 19390        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.04         |
|    value_loss               | 3.15         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.52267915] |
| time/                       |               |
|    fps                      | 137           |
|    iterations               | 30            |
|    time_elapsed             | 445           |
|    total_timesteps          | 3975168       |
| train/                      |               |
|    approx_kl                | 1760.0079     |
|    approx_ln(kl)            | 7.4730735     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.62          |
|    explained_variance       | 0.735         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 19400         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0402        |
|    value_loss               | 6.04          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-1.0542562] |
| time/                       |              |
|    fps                      | 138          |
|    iterations               | 31           |
|    time_elapsed             | 459          |
|    total_timesteps          | 3977216      |
| train/                      |              |
|    approx_kl                | 5169.273     |
|    approx_ln(kl)            | 8.5504875    |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.65         |
|    explained_variance       | 0.96         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 19410        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0395       |
|    value_loss               | 2.14         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.32712814] |
| time/                       |               |
|    fps                      | 138           |
|    iterations               | 32            |
|    time_elapsed             | 472           |
|    total_timesteps          | 3979264       |
| train/                      |               |
|    approx_kl                | 10557.707     |
|    approx_ln(kl)            | 9.264611      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.67          |
|    explained_variance       | 0.874         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 19420         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0394        |
|    value_loss               | 9.33          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.5417122] |
| time/                       |              |
|    fps                      | 138          |
|    iterations               | 33           |
|    time_elapsed             | 486          |
|    total_timesteps          | 3981312      |
| train/                      |              |
|    approx_kl                | 4245.848     |
|    approx_ln(kl)            | 8.353697     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.67         |
|    explained_variance       | 0.899        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 19430        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0392       |
|    value_loss               | 4.39         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.4181842] |
| time/                       |              |
|    fps                      | 138          |
|    iterations               | 34           |
|    time_elapsed             | 501          |
|    total_timesteps          | 3983360      |
| train/                      |              |
|    approx_kl                | 2939.3062    |
|    approx_ln(kl)            | 7.985929     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.7          |
|    explained_variance       | 0.7          |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 19440        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0387       |
|    value_loss               | 1.57         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.63436383] |
| time/                       |               |
|    fps                      | 118           |
|    iterations               | 35            |
|    time_elapsed             | 606           |
|    total_timesteps          | 3985408       |
| train/                      |               |
|    approx_kl                | 6569.5938     |
|    approx_ln(kl)            | 8.790207      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.72          |
|    explained_variance       | 0.827         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 19450         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0383        |
|    value_loss               | 8.35          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.53624624] |
| time/                       |               |
|    fps                      | 103           |
|    iterations               | 36            |
|    time_elapsed             | 708           |
|    total_timesteps          | 3987456       |
| train/                      |               |
|    approx_kl                | 5083.0186     |
|    approx_ln(kl)            | 8.533661      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.71          |
|    explained_variance       | 0.947         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 19460         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0386        |
|    value_loss               | 0.85          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7772703] |
| time/                       |              |
|    fps                      | 104          |
|    iterations               | 37           |
|    time_elapsed             | 725          |
|    total_timesteps          | 3989504      |
| train/                      |              |
|    approx_kl                | 37604.184    |
|    approx_ln(kl)            | 10.53487     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.65         |
|    explained_variance       | 0.94         |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 19470        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0394       |
|    value_loss               | 0.574        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6317394] |
| time/                       |              |
|    fps                      | 104          |
|    iterations               | 38           |
|    time_elapsed             | 741          |
|    total_timesteps          | 3991552      |
| train/                      |              |
|    approx_kl                | 12514.9      |
|    approx_ln(kl)            | 9.434675     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.64         |
|    explained_variance       | 0.979        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 19480        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0396       |
|    value_loss               | 0.555        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.23120311] |
| time/                       |               |
|    fps                      | 105           |
|    iterations               | 39            |
|    time_elapsed             | 757           |
|    total_timesteps          | 3993600       |
| train/                      |               |
|    approx_kl                | 7534.1265     |
|    approx_ln(kl)            | 8.927198      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.66          |
|    explained_variance       | 0.992         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 19490         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0391        |
|    value_loss               | 0.458         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.48560184] |
| time/                       |               |
|    fps                      | 105           |
|    iterations               | 40            |
|    time_elapsed             | 773           |
|    total_timesteps          | 3995648       |
| train/                      |               |
|    approx_kl                | 36681.35      |
|    approx_ln(kl)            | 10.510024     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.68          |
|    explained_variance       | 0.987         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 19500         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.039         |
|    value_loss               | 0.471         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.18884026] |
| time/                       |               |
|    fps                      | 106           |
|    iterations               | 41            |
|    time_elapsed             | 789           |
|    total_timesteps          | 3997696       |
| train/                      |               |
|    approx_kl                | 44845.27      |
|    approx_ln(kl)            | 10.710974     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.67          |
|    explained_variance       | 0.993         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 19510         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0392        |
|    value_loss               | 0.298         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.40958014] |
| time/                       |               |
|    fps                      | 106           |
|    iterations               | 42            |
|    time_elapsed             | 805           |
|    total_timesteps          | 3999744       |
| train/                      |               |
|    approx_kl                | 9881.361      |
|    approx_ln(kl)            | 9.198405      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.66          |
|    explained_variance       | 0.983         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 19520         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.04          |
|    value_loss               | 0.254         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.6140261] |
| time/                       |              |
|    fps                      | 107          |
|    iterations               | 43           |
|    time_elapsed             | 820          |
|    total_timesteps          | 4001792      |
| train/                      |              |
|    approx_kl                | 16980.844    |
|    approx_ln(kl)            | 9.739841     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.65         |
|    explained_variance       | 0.977        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 19530        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0399       |
|    value_loss               | 0.656        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7058457] |
| time/                       |              |
|    fps                      | 107          |
|    iterations               | 44           |
|    time_elapsed             | 837          |
|    total_timesteps          | 4003840      |
| train/                      |              |
|    approx_kl                | 4070.0283    |
|    approx_ln(kl)            | 8.311405     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.63         |
|    explained_variance       | 0.772        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 19540        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0404       |
|    value_loss               | 4.51         |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.53775346] |
| time/                       |               |
|    fps                      | 107           |
|    iterations               | 45            |
|    time_elapsed             | 854           |
|    total_timesteps          | 4005888       |
| train/                      |               |
|    approx_kl                | 1836.6775     |
|    approx_ln(kl)            | 7.5157137     |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.64          |
|    explained_variance       | 0.913         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 19550         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.04          |
|    value_loss               | 6.23          |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.8242217] |
| time/                       |              |
|    fps                      | 108          |
|    iterations               | 46           |
|    time_elapsed             | 870          |
|    total_timesteps          | 4007936      |
| train/                      |              |
|    approx_kl                | 8865.554     |
|    approx_ln(kl)            | 9.089929     |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.66         |
|    explained_variance       | 0.946        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 19560        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.0397       |
|    value_loss               | 0.631        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.61273056] |
| time/                       |               |
|    fps                      | 108           |
|    iterations               | 47            |
|    time_elapsed             | 885           |
|    total_timesteps          | 4009984       |
| train/                      |               |
|    approx_kl                | 7522.6694     |
|    approx_ln(kl)            | 8.925676      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.65          |
|    explained_variance       | 0.899         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 19570         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.04          |
|    value_loss               | 0.498         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
----------------------------------------------
| reward                      | [-0.7281041] |
| time/                       |              |
|    fps                      | 109          |
|    iterations               | 48           |
|    time_elapsed             | 901          |
|    total_timesteps          | 4012032      |
| train/                      |              |
|    approx_kl                | 5564.2095    |
|    approx_ln(kl)            | 8.62411      |
|    clip_range               | 0.2          |
|    entropy_loss             | 3.65         |
|    explained_variance       | 0.988        |
|    learning_rate            | 0.001        |
|    ln(loss)                 | inf          |
|    ln(policy_gradient_loss) | nan          |
|    loss                     | inf          |
|    n_updates                | 19580        |
|    policy_gradient_loss     | nan          |
|    std                      | 0.04         |
|    value_loss               | 0.396        |
----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
-----------------------------------------------
| reward                      | [-0.77318865] |
| time/                       |               |
|    fps                      | 109           |
|    iterations               | 49            |
|    time_elapsed             | 915           |
|    total_timesteps          | 4014080       |
| train/                      |               |
|    approx_kl                | 7913.968      |
|    approx_ln(kl)            | 8.976384      |
|    clip_range               | 0.2           |
|    entropy_loss             | 3.64          |
|    explained_variance       | 0.852         |
|    learning_rate            | 0.001         |
|    ln(loss)                 | inf           |
|    ln(policy_gradient_loss) | nan           |
|    loss                     | inf           |
|    n_updates                | 19590         |
|    policy_gradient_loss     | nan           |
|    std                      | 0.0403        |
|    value_loss               | 0.465         |
-----------------------------------------------
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/ppo_penalty/ppo_penalty.py:234: RuntimeWarning: invalid value encountered in multiply
  policy_loss = -th.mean(advantages * ratio - self.beta * approx_kl_div)
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.3769913613796234
Final reward: -0.3777678608894348
Final reward: -0.379637748003006
Final reward: -0.38342276215553284
Final reward: -0.390183687210083
Final reward: -0.40101444721221924
Final reward: -0.41672050952911377
Final reward: -0.43743276596069336
Final reward: -0.46226805448532104
Final reward: -0.48914894461631775
Final reward: -0.5148376822471619
Final reward: -0.5351858139038086
Final reward: -0.545606791973114
Final reward: -0.5519709587097168
Final reward: -0.5477274060249329
Final reward: -0.5163315534591675
Final reward: -0.5122866034507751
Final reward: -0.47847068309783936
Final reward: -0.4746367633342743
Final reward: -0.4378185272216797
Final reward: -0.4342096447944641
Final reward: -0.39351776242256165
Final reward: -0.4023510813713074
Final reward: -0.37015530467033386
Final reward: -0.38967669010162354
Final reward: -0.3569425344467163
Final reward: -0.3773600459098816
Final reward: -0.344883531332016
Final reward: -0.3655494451522827
Final reward: -0.3339316248893738
Final reward: -0.3543475270271301
Final reward: -0.32402998208999634
Final reward: -0.3438286781311035
Final reward: -0.3576880395412445
Final reward: -0.36887237429618835
Final reward: -0.39145100116729736
Final reward: -0.40088048577308655
Final reward: -0.4200868606567383
Final reward: -0.4284723997116089
Final reward: -0.4444267749786377
Final reward: -0.45358362793922424
Final reward: -0.4681815207004547
Final reward: -0.4754539430141449
Final reward: -0.4890390634536743
Final reward: -0.49571889638900757
Final reward: -0.5079429745674133
Final reward: -0.5139801502227783
Final reward: -0.5251849889755249
Final reward: -0.530738890171051
Final reward: -0.5391181707382202
Final reward: -0.5436736941337585
Final reward: -0.5471675992012024
Final reward: -0.5495681166648865
Final reward: -0.5517550110816956
Final reward: -0.5555896759033203
Final reward: -0.5573961138725281
Final reward: -0.5588957071304321
Final reward: -0.5600098371505737
Final reward: -0.5615233182907104
Final reward: -0.562621533870697
Final reward: -0.564109206199646
Final reward: -0.5651853084564209
Final reward: -0.5676299333572388
Final reward: -0.5687023997306824
Final reward: -0.571140706539154
Final reward: -0.5722094774246216
Final reward: -0.574641227722168
Final reward: -0.5757062435150146
Final reward: -0.5781312584877014
Final reward: -0.5791923999786377
Final reward: -0.5815877914428711
Final reward: -0.5826425552368164
Final reward: -0.5850459337234497
Final reward: -0.5860968232154846
Final reward: -0.588492751121521
Final reward: -0.5895393490791321
Final reward: -0.5919275283813477
Final reward: -0.5929701924324036
Final reward: -0.5953462719917297
Final reward: -0.5963839292526245
Final reward: -0.5987544059753418
Final reward: -0.5997880101203918
Final reward: -0.6021412014961243
Final reward: -0.6031696200370789
Final reward: -0.6055210828781128
Final reward: -0.6065452694892883
Final reward: -0.608885645866394
Final reward: -0.6099051237106323
Final reward: -0.6122390031814575
Final reward: -0.6132543087005615
Final reward: -0.6155802607536316
Final reward: -0.616591215133667
Final reward: -0.6188981533050537
Final reward: -0.6199040412902832
Final reward: -0.6222081184387207
Final reward: -0.6232093572616577
Final reward: -0.6255063414573669
Final reward: -0.6265032291412354
Final reward: -0.6287813186645508
Final reward: -0.6297509074211121
Final reward: -0.6318613290786743
Final reward: -0.6327810883522034
Final reward: -0.6349295377731323
Final reward: -0.6358383893966675
Final reward: -0.6379343271255493
Final reward: -0.6387984156608582
Final reward: -0.6406529545783997
Final reward: -0.6414524912834167
Final reward: -0.6433465480804443
Final reward: -0.6441208720207214
Final reward: -0.6459696292877197
Final reward: -0.646709680557251
Final reward: -0.6484450101852417
Final reward: -0.6491140127182007
Final reward: -0.6505089402198792
Final reward: -0.6510776877403259
Final reward: -0.6524960994720459
Final reward: -0.6530234217643738
Final reward: -0.6543639302253723
Final reward: -0.654856264591217
Final reward: -0.6562356948852539
Final reward: -0.656692385673523
Final reward: -0.6578028798103333
Final reward: -0.6581881046295166
Final reward: -0.6593376398086548
Final reward: -0.6596760749816895
Final reward: -0.6605094075202942
Final reward: -0.6607452630996704
Final reward: -0.6614771485328674
Final reward: -0.6616337299346924
Final reward: -0.6621494293212891
Final reward: -0.6621965765953064
Final reward: -0.6625148057937622
Final reward: -0.6624709963798523
Final reward: -0.6627273559570312
Final reward: -0.6626428365707397
Final reward: -0.66289883852005
Final reward: -0.662776529788971
Final reward: -0.6629188060760498
Final reward: -0.6627206802368164
Final reward: -0.66286301612854
Final reward: -0.6626647710800171
Final reward: -0.6628071665763855
Final reward: -0.662608802318573
Final reward: -0.662751317024231
Final reward: -0.6625528335571289
Final reward: -0.6626954078674316
Final reward: -0.6624968647956848
Final reward: -0.6626394987106323
Final reward: -0.662440836429596
Final reward: -0.6625835299491882
Final reward: -0.6623847484588623
Final reward: -0.6625275015830994
Final reward: -0.6623286604881287
Final reward: -0.6624714732170105
Final reward: -0.6622725129127502
Final reward: -0.6624154448509216
Final reward: -0.6622163653373718
Final reward: -0.6623592972755432
Final reward: -0.6621601581573486
Final reward: -0.6623032093048096
Final reward: -0.6621039509773254
Final reward: -0.6622470617294312
Final reward: -0.6620476841926575
Final reward: -0.662190854549408
Final reward: -0.6619914174079895
Final reward: -0.6621346473693848
Final reward: -0.6619350910186768
Final reward: -0.6620783805847168
Final reward: -0.661878764629364
Final reward: -0.6620221138000488
Final reward: -0.6618223786354065
Final reward: -0.6619657874107361
Final reward: -0.661765992641449
Final reward: -0.6619094610214233
Final reward: -0.6617095470428467
Final reward: -0.6618531346321106
Final reward: -0.6616531014442444
Final reward: -0.6617966890335083
Final reward: -0.6615965962409973
Final reward: -0.6617403030395508
Final reward: -0.6615400910377502
Final reward: -0.6616838574409485
Final reward: -0.6614835262298584
Final reward: -0.6616273522377014
Final reward: -0.6614269614219666
Final reward: -0.6615708470344543
Final reward: -0.6613703370094299
Final reward: -0.6615142822265625
Final reward: -0.6613137125968933
Final reward: -0.6614577174186707
Final reward: -0.6612570881843567
Final reward: -0.6614011526107788
Final reward: -0.6612004041671753
Final reward: -0.6613445281982422
Final reward: -0.6611436605453491
Final reward: -0.6612878441810608
Final reward: -0.6610869765281677
Final reward: -0.6612311601638794
Final reward: -0.6610301733016968
Final reward: -0.661174476146698
Final reward: -0.6609733700752258
Final reward: -0.6611177325248718
Final reward: -0.6609165668487549
Final reward: -0.6610609889030457
Final reward: -0.6608597636222839
Final reward: -0.6610041856765747
Final reward: -0.6608028411865234
Final reward: -0.6609473824501038
Final reward: -0.6607459783554077
Final reward: -0.660890519618988
Final reward: -0.6606890559196472
Final reward: -0.6608336567878723
Final reward: -0.6606321334838867
Final reward: -0.6607767939567566
Final reward: -0.6605751514434814
Final reward: -0.6607198715209961
Final reward: -0.6605181694030762
Final reward: -0.6606629490852356
Final reward: -0.6604611277580261
Final reward: -0.6606059670448303
Final reward: -0.6604040861129761
Final reward: -0.660548985004425
Final reward: -0.660347044467926
Final reward: -0.660491943359375
Final reward: -0.6602899432182312
Final reward: -0.660434901714325
Final reward: -0.6602327823638916
Final reward: -0.6603778600692749
Final reward: -0.6601756811141968
Final reward: -0.6603207588195801
Final reward: -0.6601185202598572
Final reward: -0.6602636575698853
Final reward: -0.6600612998008728
Final reward: -0.6602080464363098
Final reward: -0.6600103378295898
Final reward: -0.6601602435112
Final reward: -0.6599624752998352
Final reward: -0.6601124405860901
Final reward: -0.6599146127700806
Final reward: -0.6600751280784607
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.6599090099334717
Final reward: -0.6600906848907471
Final reward: -0.6599245667457581
Final reward: -0.6601061820983887
Final reward: -0.6599400639533997
Final reward: -0.6601216793060303
Final reward: -0.659955620765686
Final reward: -0.6601371765136719
Final reward: -0.6599711179733276
Final reward: -0.6601527333259583
Final reward: -0.659986674785614
Final reward: -0.6601682305335999
Final reward: -0.6600021719932556
Final reward: -0.6601837277412415
Final reward: -0.660017728805542
Final reward: -0.6601992249488831
Final reward: -0.6600332260131836
Final reward: -0.6602147817611694
Final reward: -0.66004878282547
Final reward: -0.660230278968811
Final reward: -0.6600642800331116
Final reward: -0.6602457761764526
Final reward: -0.660079836845398
Final reward: -0.6602612733840942
Final reward: -0.6600953340530396
Final reward: -0.6602767705917358
Final reward: -0.6601108908653259
Final reward: -0.6602923274040222
Final reward: -0.6601263880729675
Final reward: -0.6603078246116638
Final reward: -0.6601419448852539
Final reward: -0.6603233218193054
Final reward: -0.6601574420928955
Final reward: -0.660338819026947
Final reward: -0.6601729989051819
Final reward: -0.6603543162345886
Final reward: -0.6601884961128235
Final reward: -0.6603698134422302
Final reward: -0.6602039933204651
Final reward: -0.6603853106498718
Final reward: -0.6602195501327515
Final reward: -0.6604008674621582
Final reward: -0.6602350473403931
Final reward: -0.6604163646697998
Final reward: -0.6602506041526794
Final reward: -0.6604318618774414
Final reward: -0.660266101360321
Final reward: -0.660447359085083
Final reward: -0.6602815985679626
Final reward: -0.6604628562927246
Final reward: -0.660297155380249
Final reward: -0.6604783535003662
Final reward: -0.6603126525878906
Final reward: -0.6604938507080078
Final reward: -0.6603281497955322
Final reward: -0.6605093479156494
Final reward: -0.6603437066078186
Final reward: -0.660524845123291
Final reward: -0.6603592038154602
Final reward: -0.6605403423309326
Final reward: -0.6603747010231018
Final reward: -0.6605558395385742
Final reward: -0.6603902578353882
Final reward: -0.6605713367462158
Final reward: -0.6604057550430298
Final reward: -0.6605868339538574
Final reward: -0.6604212522506714
Final reward: -0.660602331161499
Final reward: -0.660436749458313
Final reward: -0.6606178283691406
Final reward: -0.6604523062705994
Final reward: -0.6606333255767822
Final reward: -0.660467803478241
Final reward: -0.6606488227844238
Final reward: -0.6604833006858826
Final reward: -0.6606643199920654
Final reward: -0.6604987978935242
Final reward: -0.660679817199707
Final reward: -0.6605143547058105
Final reward: -0.6606952548027039
Final reward: -0.6605298519134521
Final reward: -0.6607107520103455
Final reward: -0.6605453491210938
Final reward: -0.6607262492179871
Final reward: -0.6605608463287354
Final reward: -0.6607417464256287
Final reward: -0.660576343536377
Final reward: -0.6607572436332703
Final reward: -0.6605918407440186
Final reward: -0.6607727408409119
Final reward: -0.6606073975563049
Final reward: -0.6607882380485535
Final reward: -0.6606228947639465
Final reward: -0.6608036756515503
Final reward: -0.6606383919715881
Final reward: -0.6608191728591919
Final reward: -0.6606538891792297
Final reward: -0.6608346700668335
Final reward: -0.6606693863868713
Final reward: -0.6608501672744751
Final reward: -0.6606848835945129
Final reward: -0.6608656644821167
Final reward: -0.6607003808021545
Final reward: -0.6608811020851135
Final reward: -0.6607158780097961
Final reward: -0.6608965992927551
Final reward: -0.6607313752174377
Final reward: -0.6609120965003967
Final reward: -0.6607468724250793
Final reward: -0.6609275341033936
Final reward: -0.660762369632721
Final reward: -0.6609430313110352
Final reward: -0.6607778668403625
Final reward: -0.6609585285186768
Final reward: -0.6607933640480042
Final reward: -0.6609739661216736
Final reward: -0.6608088612556458
Final reward: -0.6609894633293152
Final reward: -0.6608243584632874
Final reward: -0.6610049605369568
Final reward: -0.660839855670929
Final reward: -0.6610203981399536
Final reward: -0.6608553528785706
Final reward: -0.6610358953475952
Final reward: -0.6608708500862122
Final reward: -0.6610513925552368
Final reward: -0.6608863472938538
Final reward: -0.6610668301582336
Final reward: -0.6609018445014954
Final reward: -0.6610823273658752
Final reward: -0.660917341709137
Final reward: -0.6610977649688721
Final reward: -0.6609328389167786
Final reward: -0.6611132621765137
Final reward: -0.6609483361244202
Final reward: -0.6611286997795105
Final reward: -0.6609638333320618
Final reward: -0.6611441969871521
Final reward: -0.6609792709350586
Final reward: -0.6611596345901489
Final reward: -0.6609947681427002
Final reward: -0.6611751317977905
Final reward: -0.6610102653503418
Final reward: -0.6611905694007874
Final reward: -0.6610257625579834
Final reward: -0.661206066608429
Final reward: -0.661041259765625
Final reward: -0.6612215042114258
Final reward: -0.6610566973686218
Final reward: -0.6612370014190674
Final reward: -0.6610721945762634
Final reward: -0.6612524390220642
Final reward: -0.661087691783905
Final reward: -0.6612679362297058
Final reward: -0.6611031889915466
Final reward: -0.6612833738327026
Final reward: -0.6611186265945435
Final reward: -0.6612988114356995
Final reward: -0.6611341238021851
Final reward: -0.6613143086433411
Final reward: -0.6611496210098267
Final reward: -0.6613297462463379
Final reward: -0.6611650586128235
Final reward: -0.6613451838493347
Final reward: -0.6611805558204651
Final reward: -0.6613606810569763
Final reward: -0.6611960530281067
Final reward: -0.6613761186599731
Final reward: -0.6612114906311035
Final reward: -0.66139155626297
Final reward: -0.6612269878387451
Final reward: -0.6614070534706116
Final reward: -0.6612424850463867
Final reward: -0.6614224910736084
Final reward: -0.6612579226493835
Final reward: -0.6614379286766052
Final reward: -0.6612734198570251
Final reward: -0.661453366279602
Final reward: -0.661288857460022
Final reward: -0.6614688038825989
Final reward: -0.6613043546676636
Final reward: -0.6614843010902405
Final reward: -0.6613197922706604
Final reward: -0.6614997386932373
Final reward: -0.661335289478302
Final reward: -0.6615151762962341
Final reward: -0.6613507866859436
Final reward: -0.661530613899231
Final reward: -0.6613662242889404
Final reward: -0.6615460515022278
Final reward: -0.6613816618919373
Final reward: -0.6615614891052246
Final reward: -0.6613971590995789
Final reward: -0.6615769267082214
Final reward: -0.6614125967025757
Final reward: -0.661592423915863
Final reward: -0.6614280939102173
Final reward: -0.6616078615188599
Final reward: -0.6614435315132141
Final reward: -0.6616232991218567
Final reward: -0.6614590287208557
Final reward: -0.6616387367248535
Final reward: -0.6614744663238525
Final reward: -0.6616541743278503
Final reward: -0.6614899039268494
Final reward: -0.6616696119308472
Final reward: -0.661505401134491
Final reward: -0.661685049533844
Final reward: -0.6615208387374878
Final reward: -0.6617004871368408
Final reward: -0.6615362763404846
Final reward: -0.6617159247398376
Final reward: -0.6615517735481262
Final reward: -0.6617313623428345
Final reward: -0.661567211151123
Final reward: -0.6617467403411865
Final reward: -0.6615826487541199
Final reward: -0.6617621779441833
Final reward: -0.6615981459617615
Final reward: -0.6617776155471802
Final reward: -0.6616135835647583
Final reward: -0.661793053150177
Final reward: -0.6616290211677551
Final reward: -0.6618084907531738
Final reward: -0.661644458770752
Final reward: -0.6618239283561707
Final reward: -0.6616598963737488
Final reward: -0.6618393659591675
Final reward: -0.6616753935813904
Final reward: -0.6618547439575195
Final reward: -0.6616908311843872
Final reward: -0.6618701815605164
Final reward: -0.661706268787384
Final reward: -0.6618856191635132
Final reward: -0.6617217063903809
Final reward: -0.66190105676651
Final reward: -0.6617371439933777
Final reward: -0.6619164347648621
Final reward: -0.6617525815963745
Final reward: -0.6619318723678589
Final reward: -0.6617680191993713
Final reward: -0.6619473099708557
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.6617834568023682
Final reward: -0.6619626879692078
Final reward: -0.661798894405365
Final reward: -0.6619781255722046
Final reward: -0.6618143320083618
Final reward: -0.6619935631752014
Final reward: -0.6618297696113586
Final reward: -0.6620089411735535
Final reward: -0.6618452072143555
Final reward: -0.6620243787765503
Final reward: -0.6618606448173523
Final reward: -0.6620397567749023
Final reward: -0.6618760824203491
Final reward: -0.6620551943778992
Final reward: -0.661891520023346
Final reward: -0.662070631980896
Final reward: -0.6619069576263428
Final reward: -0.5119789838790894
Final reward: -0.5125510096549988
Final reward: -0.5139307379722595
Final reward: -0.5167329907417297
Final reward: -0.5217694044113159
Final reward: -0.5299175381660461
Final reward: -0.5419003367424011
Final reward: -0.5579851269721985
Final reward: -0.5776605606079102
Final reward: -0.599388599395752
Final reward: -0.6205302476882935
Final reward: -0.6375138163566589
Final reward: -0.6462869048118591
Final reward: -0.6516685485839844
Final reward: -0.6480781435966492
Final reward: -0.6217702627182007
Final reward: -0.618415355682373
Final reward: -0.5907065272331238
Final reward: -0.587605357170105
Final reward: -0.5582876205444336
Final reward: -0.5554620027542114
Final reward: -0.524267315864563
Final reward: -0.5309297442436218
Final reward: -0.5069664120674133
Final reward: -0.5214142203330994
Final reward: -0.49714043736457825
Final reward: -0.5122517347335815
Final reward: -0.4882962703704834
Final reward: -0.5035529136657715
Final reward: -0.48041415214538574
Final reward: -0.49538660049438477
Final reward: -0.4734728932380676
Final reward: -0.4878196120262146
Final reward: -0.46730923652648926
Final reward: -0.4808652102947235
Final reward: -0.4619002044200897
Final reward: -0.47453823685646057
Final reward: -0.4571680724620819
Final reward: -0.46883684396743774
Final reward: -0.45729580521583557
Final reward: -0.46444523334503174
Final reward: -0.46159711480140686
Final reward: -0.44935497641563416
Final reward: -0.45101553201675415
Final reward: -0.4385002851486206
Final reward: -0.4404529929161072
Final reward: -0.43114587664604187
Final reward: -0.4307869076728821
Final reward: -0.42403289675712585
Final reward: -0.4210609793663025
Final reward: -0.4208105206489563
Final reward: -0.42426392436027527
Final reward: -0.42725253105163574
Final reward: -0.43218082189559937
Final reward: -0.43450573086738586
Final reward: -0.4366106390953064
Final reward: -0.4385403096675873
Final reward: -0.4401855766773224
Final reward: -0.44178199768066406
Final reward: -0.44441333413124084
Final reward: -0.44596970081329346
Final reward: -0.449363648891449
Final reward: -0.45090797543525696
Final reward: -0.4542786478996277
Final reward: -0.45581111311912537
Final reward: -0.4591587781906128
Final reward: -0.4606795012950897
Final reward: -0.46400442719459534
Final reward: -0.46551358699798584
Final reward: -0.46881601214408875
Final reward: -0.47031137347221375
Final reward: -0.4735795855522156
Final reward: -0.4750547707080841
Final reward: -0.47828054428100586
Final reward: -0.4797309935092926
Final reward: -0.4829077124595642
Final reward: -0.48433610796928406
Final reward: -0.487490177154541
Final reward: -0.4888294041156769
Final reward: -0.4910239279270172
Final reward: -0.4921862781047821
Final reward: -0.49487048387527466
Final reward: -0.49602532386779785
Final reward: -0.4986990988254547
Final reward: -0.49983280897140503
Final reward: -0.5023781061172485
Final reward: -0.5034593939781189
Final reward: -0.5059329271316528
Final reward: -0.5069771409034729
Final reward: -0.5094470381736755
Final reward: -0.5104565620422363
Final reward: -0.5126755833625793
Final reward: -0.5136217474937439
Final reward: -0.5159157514572144
Final reward: -0.5167973041534424
Final reward: -0.5185507535934448
Final reward: -0.5192722082138062
Final reward: -0.5207791924476624
Final reward: -0.5213566422462463
Final reward: -0.5224374532699585
Final reward: -0.5228117108345032
Final reward: -0.5234399437904358
Final reward: -0.5235938429832458
Final reward: -0.5240621566772461
Final reward: -0.5240549445152283
Final reward: -0.5243505239486694
Final reward: -0.5241686105728149
Final reward: -0.5242955684661865
Final reward: -0.5240150094032288
Final reward: -0.5241629481315613
Final reward: -0.523947536945343
Final reward: -0.5240919589996338
Final reward: -0.5238727927207947
Final reward: -0.5240715146064758
Final reward: -0.5238522887229919
Final reward: -0.5240510702133179
Final reward: -0.5238317847251892
Final reward: -0.5240305662155151
Final reward: -0.5238112211227417
Final reward: -0.5240100622177124
Final reward: -0.523790717124939
Final reward: -0.5239896178245544
Final reward: -0.5237701535224915
Final reward: -0.5239691138267517
Final reward: -0.523749589920044
Final reward: -0.523948609828949
Final reward: -0.5237290859222412
Final reward: -0.5239281058311462
Final reward: -0.5237085223197937
Final reward: -0.5239076018333435
Final reward: -0.5236879587173462
Final reward: -0.5238870978355408
Final reward: -0.5236673951148987
Final reward: -0.5238665342330933
Final reward: -0.5236467719078064
Final reward: -0.5238460302352905
Final reward: -0.5236262083053589
Final reward: -0.523825466632843
Final reward: -0.5236056447029114
Final reward: -0.5238049626350403
Final reward: -0.5235850214958191
Final reward: -0.5237843990325928
Final reward: -0.5235643982887268
Final reward: -0.5237638354301453
Final reward: -0.5235438346862793
Final reward: -0.5237432718276978
Final reward: -0.523523211479187
Final reward: -0.5237227082252502
Final reward: -0.5235025882720947
Final reward: -0.5237021446228027
Final reward: -0.5234819650650024
Final reward: -0.5236815214157104
Final reward: -0.5234613418579102
Final reward: -0.5236609578132629
Final reward: -0.5234407186508179
Final reward: -0.5236403942108154
Final reward: -0.5234200358390808
Final reward: -0.5236197710037231
Final reward: -0.5233994126319885
Final reward: -0.5235991477966309
Final reward: -0.5233787298202515
Final reward: -0.5235785841941833
Final reward: -0.5233581066131592
Final reward: -0.5235579609870911
Final reward: -0.5233374238014221
Final reward: -0.5235373377799988
Final reward: -0.5233167409896851
Final reward: -0.5235167145729065
Final reward: -0.523296058177948
Final reward: -0.5234960317611694
Final reward: -0.5232753753662109
Final reward: -0.5234754085540771
Final reward: -0.5232546925544739
Final reward: -0.5234547853469849
Final reward: -0.5232340097427368
Final reward: -0.5234341025352478
Final reward: -0.523213267326355
Final reward: -0.5234134793281555
Final reward: -0.5231925845146179
Final reward: -0.5233927965164185
Final reward: -0.5231718420982361
Final reward: -0.5233721137046814
Final reward: -0.523151159286499
Final reward: -0.5233514308929443
Final reward: -0.5231304168701172
Final reward: -0.5233307480812073
Final reward: -0.5231096744537354
Final reward: -0.5233100652694702
Final reward: -0.5230889320373535
Final reward: -0.5232893824577332
Final reward: -0.5230681896209717
Final reward: -0.5232788324356079
Final reward: -0.5230882167816162
Final reward: -0.5233191251754761
Final reward: -0.5231286287307739
Final reward: -0.5233594179153442
Final reward: -0.5231689810752869
Final reward: -0.5233997106552124
Final reward: -0.5232093334197998
Final reward: -0.5234399437904358
Final reward: -0.5232496857643127
Final reward: -0.5234801769256592
Final reward: -0.5232900381088257
Final reward: -0.5235204100608826
Final reward: -0.5233303308486938
Final reward: -0.523560643196106
Final reward: -0.523370623588562
Final reward: -0.5236008167266846
Final reward: -0.5234109163284302
Final reward: -0.5236409902572632
Final reward: -0.5234511494636536
Final reward: -0.5236811637878418
Final reward: -0.523491382598877
Final reward: -0.5237213373184204
Final reward: -0.5235316157341003
Final reward: -0.5237614512443542
Final reward: -0.5235718488693237
Final reward: -0.5238015651702881
Final reward: -0.5236120820045471
Final reward: -0.5238416194915771
Final reward: -0.5236522555351257
Final reward: -0.523881733417511
Final reward: -0.5236924290657043
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.5239217877388
Final reward: -0.5237308144569397
Final reward: -0.5239547491073608
Final reward: -0.5237603187561035
Final reward: -0.5239841938018799
Final reward: -0.5237807631492615
Final reward: -0.5239776372909546
Final reward: -0.523756206035614
Final reward: -0.5239531397819519
Final reward: -0.5237315893173218
Final reward: -0.5239285826683044
Final reward: -0.5237069725990295
Final reward: -0.5239039659500122
Final reward: -0.5236823558807373
Final reward: -0.5238794088363647
Final reward: -0.5236576795578003
Final reward: -0.5238548517227173
Final reward: -0.5236330628395081
Final reward: -0.523830235004425
Final reward: -0.523608386516571
Final reward: -0.5238056182861328
Final reward: -0.523583710193634
Final reward: -0.5237810611724854
Final reward: -0.523559033870697
Final reward: -0.5237564444541931
Final reward: -0.52353435754776
Final reward: -0.5237317681312561
Final reward: -0.523509681224823
Final reward: -0.5237071514129639
Final reward: -0.523485004901886
Final reward: -0.5236825346946716
Final reward: -0.5234602689743042
Final reward: -0.5236578583717346
Final reward: -0.5234355926513672
Final reward: -0.5236331820487976
Final reward: -0.5234108567237854
Final reward: -0.5236085057258606
Final reward: -0.5233861207962036
Final reward: -0.5235838294029236
Final reward: -0.5233613848686218
Final reward: -0.5235591530799866
Final reward: -0.52333664894104
Final reward: -0.5235344767570496
Final reward: -0.5233119130134583
Final reward: -0.5235098004341125
Final reward: -0.5232871174812317
Final reward: -0.5234850645065308
Final reward: -0.5232623219490051
Final reward: -0.523460328578949
Final reward: -0.5232375860214233
Final reward: -0.523435652256012
Final reward: -0.5232127904891968
Final reward: -0.5234109163284302
Final reward: -0.5231879949569702
Final reward: -0.5233861207962036
Final reward: -0.5231631994247437
Final reward: -0.5233613848686218
Final reward: -0.5231383442878723
Final reward: -0.52333664894104
Final reward: -0.5231135487556458
Final reward: -0.5233118534088135
Final reward: -0.5230886936187744
Final reward: -0.5232871174812317
Final reward: -0.5230638980865479
Final reward: -0.5232623219490051
Final reward: -0.5230390429496765
Final reward: -0.5232375264167786
Final reward: -0.5230141878128052
Final reward: -0.523212730884552
Final reward: -0.5229893326759338
Final reward: -0.5232012271881104
Final reward: -0.5230178833007812
Final reward: -0.5232563018798828
Final reward: -0.5230730772018433
Final reward: -0.5233113765716553
Final reward: -0.5231282711029053
Final reward: -0.5233664512634277
Final reward: -0.5231834053993225
Final reward: -0.5234214663505554
Final reward: -0.5232385396957397
Final reward: -0.5234764218330383
Final reward: -0.5232936143875122
Final reward: -0.5235313773155212
Final reward: -0.5233486890792847
Final reward: -0.5235862731933594
Final reward: -0.5234037637710571
Final reward: -0.5236411690711975
Final reward: -0.52345871925354
Final reward: -0.5236960649490356
Final reward: -0.5235137343406677
Final reward: -0.5237508416175842
Final reward: -0.5235686302185059
Final reward: -0.5238056778907776
Final reward: -0.5236235857009888
Final reward: -0.5238603949546814
Final reward: -0.5236632227897644
Final reward: -0.5238544940948486
Final reward: -0.5236268639564514
Final reward: -0.5238181352615356
Final reward: -0.5235904455184937
Final reward: -0.5237818360328674
Final reward: -0.5235539674758911
Final reward: -0.5237454771995544
Final reward: -0.5235175490379333
Final reward: -0.5237091183662415
Final reward: -0.5234810709953308
Final reward: -0.5236726999282837
Final reward: -0.5234445929527283
Final reward: -0.5236362814903259
Final reward: -0.523408055305481
Final reward: -0.5235998630523682
Final reward: -0.5233715772628784
Final reward: -0.5235634446144104
Final reward: -0.5233350396156311
Final reward: -0.5235269665718079
Final reward: -0.5232985019683838
Final reward: -0.5234904885292053
Final reward: -0.5232619047164917
Final reward: -0.5234540104866028
Final reward: -0.5232253074645996
Final reward: -0.5234174728393555
Final reward: -0.5231887102127075
Final reward: -0.5233809351921082
Final reward: -0.5231521129608154
Final reward: -0.5233488082885742
Final reward: -0.5231331586837769
Final reward: -0.523338794708252
Final reward: -0.5231230854988098
Final reward: -0.5233287215232849
Final reward: -0.5231130123138428
Final reward: -0.5233187079429626
Final reward: -0.5231029391288757
Final reward: -0.5233086347579956
Final reward: -0.5230928659439087
Final reward: -0.5232985615730286
Final reward: -0.5230827927589417
Final reward: -0.5232885479927063
Final reward: -0.5230727195739746
Final reward: -0.5232784748077393
Final reward: -0.5230626463890076
Final reward: -0.5232684016227722
Final reward: -0.5230525732040405
Final reward: -0.5232583284378052
Final reward: -0.5230425000190735
Final reward: -0.5232483148574829
Final reward: -0.5230324268341064
Final reward: -0.5232382416725159
Final reward: -0.5230222940444946
Final reward: -0.5232281684875488
Final reward: -0.5230122208595276
Final reward: -0.5232180953025818
Final reward: -0.5230021476745605
Final reward: -0.5232080221176147
Final reward: -0.5229920744895935
Final reward: -0.5231979489326477
Final reward: -0.5229819416999817
Final reward: -0.5231878757476807
Final reward: -0.5229718685150146
Final reward: -0.5231778025627136
Final reward: -0.5229617357254028
Final reward: -0.5231677293777466
Final reward: -0.5229516625404358
Final reward: -0.5231576561927795
Final reward: -0.5229415893554688
Final reward: -0.5231475830078125
Final reward: -0.5229314565658569
Final reward: -0.5231422781944275
Final reward: -0.522940456867218
Final reward: -0.5231606960296631
Final reward: -0.5229589343070984
Final reward: -0.5231791734695435
Final reward: -0.5229774117469788
Final reward: -0.523197591304779
Final reward: -0.5229958891868591
Final reward: -0.5232160687446594
Final reward: -0.5230144262313843
Final reward: -0.523234486579895
Final reward: -0.5230329036712646
Final reward: -0.5232529640197754
Final reward: -0.523051381111145
Final reward: -0.523271381855011
Final reward: -0.5230698585510254
Final reward: -0.5232897996902466
Final reward: -0.5230883359909058
Final reward: -0.523308277130127
Final reward: -0.5231068134307861
Final reward: -0.5233266949653625
Final reward: -0.5231252908706665
Final reward: -0.5233451128005981
Final reward: -0.5231437683105469
Final reward: -0.5233635306358337
Final reward: -0.5231622457504272
Final reward: -0.5233819484710693
Final reward: -0.5231806635856628
Final reward: -0.5234004259109497
Final reward: -0.5231991410255432
Final reward: -0.5234188437461853
Final reward: -0.5232176184654236
Final reward: -0.5234372019767761
Final reward: -0.523236095905304
Final reward: -0.5234556198120117
Final reward: -0.5232545137405396
Final reward: -0.5234740376472473
Final reward: -0.5232729911804199
Final reward: -0.5234924554824829
Final reward: -0.5232914090156555
Final reward: -0.5235108733177185
Final reward: -0.5233098864555359
Final reward: -0.5235292911529541
Final reward: -0.5233283042907715
Final reward: -0.5235476493835449
Final reward: -0.5233467817306519
Final reward: -0.5235660672187805
Final reward: -0.5233651995658875
Final reward: -0.5235844850540161
Final reward: -0.523383617401123
Final reward: -0.5236028432846069
Final reward: -0.5234020948410034
Final reward: -0.5236212611198425
Final reward: -0.523420512676239
Final reward: -0.5236396193504333
Final reward: -0.5234389305114746
Final reward: -0.523658037185669
Final reward: -0.5234573483467102
Final reward: -0.5236763954162598
Final reward: -0.5234757661819458
Final reward: -0.5236947536468506
Final reward: -0.5234941840171814
Final reward: -0.5237131714820862
Final reward: -0.5235126614570618
Final reward: -0.523731529712677
Final reward: -0.5235310196876526
Final reward: -0.5237498879432678
Final reward: -0.5235494375228882
Final reward: -0.5237682461738586
Final reward: -0.5235678553581238
Final reward: -0.5237866640090942
Final reward: -0.5235862731933594
Final reward: -0.5238050222396851
Final reward: -0.523604691028595
Final reward: -0.5238233804702759
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
/nas/ucb/mason/ethically-compliant-rl/stable_baselines3/stable_baselines3/common/vec_env/base_vec_env.py:234: UserWarning: You tried to call render() but no `render_mode` was passed to the env constructor.
  warnings.warn("You tried to call render() but no `render_mode` was passed to the env constructor.")
Final reward: -0.5236231088638306
Final reward: -0.5238417387008667
Final reward: -0.5236414670944214
Final reward: -0.5238600969314575
Final reward: -0.523659884929657
Final reward: -0.5238783955574036
Final reward: -0.5236783027648926
Final reward: -0.5238967537879944
Final reward: -0.5236966609954834
Final reward: -0.5239151120185852
Final reward: -0.523715078830719
Final reward: -0.523933470249176
Final reward: -0.5237308144569397
Final reward: -0.5239412784576416
Final reward: -0.523733377456665
Final reward: -0.5239438414573669
Final reward: -0.5237360000610352
Final reward: -0.5239464640617371
Final reward: -0.523727536201477
Final reward: -0.5239050388336182
Final reward: -0.5236639380455017
Final reward: -0.5238415598869324
Final reward: -0.5236002802848816
Final reward: -0.5237780809402466
Final reward: -0.5235366225242615
Final reward: -0.5237144827842712
Final reward: -0.5234729051589966
Final reward: -0.5236508846282959
Final reward: -0.5234090685844421
Final reward: -0.5235872268676758
Final reward: -0.5233452320098877
Final reward: -0.5235235095024109
Final reward: -0.5232813358306885
Final reward: -0.5234597325325012
Final reward: -0.5232174396514893
Final reward: -0.5233959555625916
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                   reward ‚ñÖ‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñÜ‚ñÉ‚ñá‚ñÜ‚ñÇ‚ñÜ‚ñÖ‚ñá‚ñà‚ñÖ‚ñá‚ñÅ‚ñà‚ñà‚ñà‚ñÇ‚ñÜ‚ñá‚ñÉ‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÑ‚ñÅ‚ñÉ‚ñá‚ñÉ‚ñÑ‚ñÇ‚ñÖ‚ñà
wandb:          train/approx_kl ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÅ‚ñÇ‚ñÅ‚ñÖ‚ñÇ‚ñÅ‚ñÉ‚ñÜ‚ñÖ‚ñà‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:      train/approx_ln(kl) ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÖ‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñá
wandb:         train/clip_range ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       train/entropy_loss ‚ñÅ‚ñÉ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà
wandb: train/explained_variance ‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:      train/learning_rate ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:          train/n_updates ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                train/std ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:         train/value_loss ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñá‚ñÖ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:                         reward -0.77319
wandb:                train/approx_kl 7913.96777
wandb:            train/approx_ln(kl) 8.97638
wandb:               train/clip_range 0.2
wandb:             train/entropy_loss 3.6351
wandb:       train/explained_variance 0.85216
wandb:            train/learning_rate 0.001
wandb:                 train/ln(loss) inf
wandb: train/ln(policy_gradient_loss) nan
wandb:                     train/loss inf
wandb:                train/n_updates 19590
wandb:     train/policy_gradient_loss nan
wandb:                      train/std 0.04034
wandb:               train/value_loss 0.46509
wandb: 
wandb: üöÄ View run ppo-KLpenalty-beta(dynamic)-parking at: https://wandb.ai/ecrl/PPO-Penalty-Report5/runs/nxgx8r5s
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20231119_174542-nxgx8r5s/logs
