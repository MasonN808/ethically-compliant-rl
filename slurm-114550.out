Running script with speed limit: 2
Running script with speed limit: 4
Running script with speed limit: 8
Running script with speed limit: 16
Running script with speed limit: 2
Running script with speed limit: 4
Running script with speed limit: 8
Running script with speed limit: 16
Running script with speed limit: 2
Running script with speed limit: 4
Running script with speed limit: 8
Running script with speed limit: 16
Running script with speed limit: 2
Running script with speed limit: 4
Running script with speed limit: 8
Running script with speed limit: 16
wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20231226_232325-pe0x81ie
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ppol-highway-parking
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/New-PPOL-SpeedLimit%3D16
wandb: üöÄ View run at https://wandb.ai/ecrl/New-PPOL-SpeedLimit%3D16/runs/pe0x81ie
wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.16.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20231227_072325-x8qpk88w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ppol-highway-parking
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/New-PPOL-SpeedLimit%3D2
wandb: üöÄ View run at https://wandb.ai/ecrl/New-PPOL-SpeedLimit%3D2/runs/x8qpk88w
wandb: wandb version 0.16.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20231226_232325-ra4x83v5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ppol-highway-parking
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/New-PPOL-SpeedLimit%3D16
wandb: üöÄ View run at https://wandb.ai/ecrl/New-PPOL-SpeedLimit%3D16/runs/ra4x83v5
wandb: wandb version 0.16.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20231226_232325-sxsfakct
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ppol-highway-parking
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/New-PPOL-SpeedLimit%3D8
wandb: üöÄ View run at https://wandb.ai/ecrl/New-PPOL-SpeedLimit%3D8/runs/sxsfakct
Using cpu device
-------------------------------------
| reward             | [-0.6664699] |
| time/              |              |
|    fps             | 134          |
|    iterations      | 1            |
|    time_elapsed    | 15           |
|    total_timesteps | 2048         |
-------------------------------------
Using cpu device
-------------------------------------
| reward             | [-0.5776406] |
| time/              |              |
|    fps             | 136          |
|    iterations      | 1            |
|    time_elapsed    | 14           |
|    total_timesteps | 2048         |
-------------------------------------
Using cpu device
--------------------------------------
| reward             | [-0.54846954] |
| time/              |               |
|    fps             | 127           |
|    iterations      | 1             |
|    time_elapsed    | 16            |
|    total_timesteps | 2048          |
--------------------------------------
Using cpu device
-------------------------------------
| reward             | [-0.5081297] |
| time/              |              |
|    fps             | 118          |
|    iterations      | 1            |
|    time_elapsed    | 17           |
|    total_timesteps | 2048         |
-------------------------------------
--------------------------------------------
| reward                   | [-0.41305873] |
| time/                    |               |
|    fps                   | 130           |
|    iterations            | 2             |
|    time_elapsed          | 31            |
|    total_timesteps       | 4096          |
| train/                   |               |
|    approx_kl             | 0.0059785284  |
|    clip_fraction         | 0.0539        |
|    clip_range            | 0.2           |
|    cost_value_loss       | 0.0796        |
|    entropy_loss          | -2.82         |
|    explained_variance    | -0.00353      |
|    lagrangian_multiplier | 0.048         |
|    learning_rate         | 0.0003        |
|    loss                  | 39.6          |
|    n_updates             | 10            |
|    policy_gradient_loss  | -0.00651      |
|    std                   | 0.987         |
|    value_loss            | 328           |
--------------------------------------------
--------------------------------------------
| reward                   | [-0.75121737] |
| time/                    |               |
|    fps                   | 127           |
|    iterations            | 2             |
|    time_elapsed          | 32            |
|    total_timesteps       | 4096          |
| train/                   |               |
|    approx_kl             | 0.0055308994  |
|    clip_fraction         | 0.0343        |
|    clip_range            | 0.2           |
|    cost_value_loss       | 1.05          |
|    entropy_loss          | -2.85         |
|    explained_variance    | -0.0126       |
|    lagrangian_multiplier | 0.0749        |
|    learning_rate         | 0.0003        |
|    loss                  | 53.7          |
|    n_updates             | 10            |
|    policy_gradient_loss  | -0.00685      |
|    std                   | 1.01          |
|    value_loss            | 594           |
--------------------------------------------
-------------------------------------------
| reward                   | [-0.5671545] |
| time/                    |              |
|    fps                   | 121          |
|    iterations            | 2            |
|    time_elapsed          | 33           |
|    total_timesteps       | 4096         |
| train/                   |              |
|    approx_kl             | 0.0052189147 |
|    clip_fraction         | 0.0341       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 160          |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.00649      |
|    lagrangian_multiplier | 0.0469       |
|    learning_rate         | 0.0003       |
|    loss                  | 69           |
|    n_updates             | 10           |
|    policy_gradient_loss  | -0.00368     |
|    std                   | 1            |
|    value_loss            | 351          |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.7222808] |
| time/                    |              |
|    fps                   | 115          |
|    iterations            | 2            |
|    time_elapsed          | 35           |
|    total_timesteps       | 4096         |
| train/                   |              |
|    approx_kl             | 0.0053668623 |
|    clip_fraction         | 0.0329       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0132       |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.0357       |
|    lagrangian_multiplier | 0.0571       |
|    learning_rate         | 0.0003       |
|    loss                  | 22.6         |
|    n_updates             | 10           |
|    policy_gradient_loss  | -0.00459     |
|    std                   | 0.987        |
|    value_loss            | 206          |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.7944461] |
| time/                    |              |
|    fps                   | 129          |
|    iterations            | 3            |
|    time_elapsed          | 47           |
|    total_timesteps       | 6144         |
| train/                   |              |
|    approx_kl             | 0.0074044433 |
|    clip_fraction         | 0.0619       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.203        |
|    entropy_loss          | -2.81        |
|    explained_variance    | -0.00653     |
|    lagrangian_multiplier | 0.0669       |
|    learning_rate         | 0.0003       |
|    loss                  | 58.7         |
|    n_updates             | 20           |
|    policy_gradient_loss  | -0.0103      |
|    std                   | 0.991        |
|    value_loss            | 592          |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.84098065] |
| time/                    |               |
|    fps                   | 127           |
|    iterations            | 3             |
|    time_elapsed          | 48            |
|    total_timesteps       | 6144          |
| train/                   |               |
|    approx_kl             | 0.0064018075  |
|    clip_fraction         | 0.0532        |
|    clip_range            | 0.2           |
|    cost_value_loss       | 1.86          |
|    entropy_loss          | -2.86         |
|    explained_variance    | 0.0424        |
|    lagrangian_multiplier | 0.0464        |
|    learning_rate         | 0.0003        |
|    loss                  | 145           |
|    n_updates             | 20            |
|    policy_gradient_loss  | -0.00762      |
|    std                   | 1.02          |
|    value_loss            | 1.19e+03      |
--------------------------------------------
-------------------------------------------
| reward                   | [-1.0248635] |
| time/                    |              |
|    fps                   | 123          |
|    iterations            | 3            |
|    time_elapsed          | 49           |
|    total_timesteps       | 6144         |
| train/                   |              |
|    approx_kl             | 0.0043541603 |
|    clip_fraction         | 0.0197       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 200          |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.000156     |
|    lagrangian_multiplier | 0.0548       |
|    learning_rate         | 0.0003       |
|    loss                  | 62           |
|    n_updates             | 20           |
|    policy_gradient_loss  | -0.00583     |
|    std                   | 0.993        |
|    value_loss            | 388          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.2216014] |
| time/                    |              |
|    fps                   | 113          |
|    iterations            | 3            |
|    time_elapsed          | 53           |
|    total_timesteps       | 6144         |
| train/                   |              |
|    approx_kl             | 0.0065331524 |
|    clip_fraction         | 0.0459       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0505       |
|    entropy_loss          | -2.81        |
|    explained_variance    | 0.0234       |
|    lagrangian_multiplier | 0.0571       |
|    learning_rate         | 0.0003       |
|    loss                  | 47.6         |
|    n_updates             | 20           |
|    policy_gradient_loss  | -0.00619     |
|    std                   | 0.982        |
|    value_loss            | 473          |
-------------------------------------------
------------------------------------------
| reward                   | [-0.77697]  |
| time/                    |             |
|    fps                   | 128         |
|    iterations            | 4           |
|    time_elapsed          | 63          |
|    total_timesteps       | 8192        |
| train/                   |             |
|    approx_kl             | 0.005070342 |
|    clip_fraction         | 0.0516      |
|    clip_range            | 0.2         |
|    cost_value_loss       | 0.0788      |
|    entropy_loss          | -2.82       |
|    explained_variance    | 0.00386     |
|    lagrangian_multiplier | 0.052       |
|    learning_rate         | 0.0003      |
|    loss                  | 48.9        |
|    n_updates             | 30          |
|    policy_gradient_loss  | -0.00541    |
|    std                   | 0.994       |
|    value_loss            | 430         |
------------------------------------------
-------------------------------------------
| reward                   | [-1.0260128] |
| time/                    |              |
|    fps                   | 127          |
|    iterations            | 4            |
|    time_elapsed          | 64           |
|    total_timesteps       | 8192         |
| train/                   |              |
|    approx_kl             | 0.0068597617 |
|    clip_fraction         | 0.0686       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 2.82         |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.0209       |
|    lagrangian_multiplier | 0.0479       |
|    learning_rate         | 0.0003       |
|    loss                  | 143          |
|    n_updates             | 30           |
|    policy_gradient_loss  | -0.00865     |
|    std                   | 1.01         |
|    value_loss            | 1.14e+03     |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.9258254] |
| time/                    |              |
|    fps                   | 124          |
|    iterations            | 4            |
|    time_elapsed          | 65           |
|    total_timesteps       | 8192         |
| train/                   |              |
|    approx_kl             | 0.007191219  |
|    clip_fraction         | 0.0575       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 235          |
|    entropy_loss          | -2.83        |
|    explained_variance    | -0.00557     |
|    lagrangian_multiplier | 0.0517       |
|    learning_rate         | 0.0003       |
|    loss                  | 116          |
|    n_updates             | 30           |
|    policy_gradient_loss  | -0.00596     |
|    std                   | 1            |
|    value_loss            | 890          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.2417932] |
| time/                    |              |
|    fps                   | 113          |
|    iterations            | 4            |
|    time_elapsed          | 72           |
|    total_timesteps       | 8192         |
| train/                   |              |
|    approx_kl             | 0.0048747463 |
|    clip_fraction         | 0.047        |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0205       |
|    entropy_loss          | -2.8         |
|    explained_variance    | -0.0121      |
|    lagrangian_multiplier | 0.0628       |
|    learning_rate         | 0.0003       |
|    loss                  | 70.2         |
|    n_updates             | 30           |
|    policy_gradient_loss  | -0.0067      |
|    std                   | 0.979        |
|    value_loss            | 752          |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.97198814] |
| time/                    |               |
|    fps                   | 128           |
|    iterations            | 5             |
|    time_elapsed          | 79            |
|    total_timesteps       | 10240         |
| train/                   |               |
|    approx_kl             | 0.0054490333  |
|    clip_fraction         | 0.047         |
|    clip_range            | 0.2           |
|    cost_value_loss       | 0.271         |
|    entropy_loss          | -2.82         |
|    explained_variance    | -0.0291       |
|    lagrangian_multiplier | 0.0499        |
|    learning_rate         | 0.0003        |
|    loss                  | 67.8          |
|    n_updates             | 40            |
|    policy_gradient_loss  | -0.00422      |
|    std                   | 0.986         |
|    value_loss            | 522           |
--------------------------------------------
-------------------------------------------
| reward                   | [-0.8009243] |
| time/                    |              |
|    fps                   | 127          |
|    iterations            | 5            |
|    time_elapsed          | 80           |
|    total_timesteps       | 10240        |
| train/                   |              |
|    approx_kl             | 0.0063618217 |
|    clip_fraction         | 0.0606       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 3.71         |
|    entropy_loss          | -2.86        |
|    explained_variance    | 0.0271       |
|    lagrangian_multiplier | 0.0552       |
|    learning_rate         | 0.0003       |
|    loss                  | 101          |
|    n_updates             | 40           |
|    policy_gradient_loss  | -0.00778     |
|    std                   | 1.01         |
|    value_loss            | 968          |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.72499466] |
| time/                    |               |
|    fps                   | 124           |
|    iterations            | 5             |
|    time_elapsed          | 82            |
|    total_timesteps       | 10240         |
| train/                   |               |
|    approx_kl             | 0.00622621    |
|    clip_fraction         | 0.0456        |
|    clip_range            | 0.2           |
|    cost_value_loss       | 260           |
|    entropy_loss          | -2.82         |
|    explained_variance    | -0.00922      |
|    lagrangian_multiplier | 0.0545        |
|    learning_rate         | 0.0003        |
|    loss                  | 96.9          |
|    n_updates             | 40            |
|    policy_gradient_loss  | -0.0079       |
|    std                   | 0.984         |
|    value_loss            | 620           |
--------------------------------------------
-------------------------------------------
| reward                   | [-1.7617426] |
| time/                    |              |
|    fps                   | 112          |
|    iterations            | 5            |
|    time_elapsed          | 90           |
|    total_timesteps       | 10240        |
| train/                   |              |
|    approx_kl             | 0.0053336695 |
|    clip_fraction         | 0.0348       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0512       |
|    entropy_loss          | -2.8         |
|    explained_variance    | -0.02        |
|    lagrangian_multiplier | 0.0908       |
|    learning_rate         | 0.0003       |
|    loss                  | 104          |
|    n_updates             | 40           |
|    policy_gradient_loss  | -0.00303     |
|    std                   | 0.986        |
|    value_loss            | 1.57e+03     |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.7736004] |
| time/                    |              |
|    fps                   | 128          |
|    iterations            | 6            |
|    time_elapsed          | 95           |
|    total_timesteps       | 12288        |
| train/                   |              |
|    approx_kl             | 0.0069019482 |
|    clip_fraction         | 0.0545       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.465        |
|    entropy_loss          | -2.82        |
|    explained_variance    | -0.00119     |
|    lagrangian_multiplier | 0.0631       |
|    learning_rate         | 0.0003       |
|    loss                  | 59.6         |
|    n_updates             | 50           |
|    policy_gradient_loss  | -0.0085      |
|    std                   | 0.997        |
|    value_loss            | 581          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.1836282] |
| time/                    |              |
|    fps                   | 127          |
|    iterations            | 6            |
|    time_elapsed          | 96           |
|    total_timesteps       | 12288        |
| train/                   |              |
|    approx_kl             | 0.004511345  |
|    clip_fraction         | 0.0309       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.16         |
|    entropy_loss          | -2.87        |
|    explained_variance    | -0.00597     |
|    lagrangian_multiplier | 0.0419       |
|    learning_rate         | 0.0003       |
|    loss                  | 39.9         |
|    n_updates             | 50           |
|    policy_gradient_loss  | -0.00376     |
|    std                   | 1.02         |
|    value_loss            | 291          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.7142885] |
| time/                    |              |
|    fps                   | 124          |
|    iterations            | 6            |
|    time_elapsed          | 98           |
|    total_timesteps       | 12288        |
| train/                   |              |
|    approx_kl             | 0.006570049  |
|    clip_fraction         | 0.0465       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 152          |
|    entropy_loss          | -2.78        |
|    explained_variance    | -0.0182      |
|    lagrangian_multiplier | 0.0695       |
|    learning_rate         | 0.0003       |
|    loss                  | 69.8         |
|    n_updates             | 50           |
|    policy_gradient_loss  | -0.00748     |
|    std                   | 0.964        |
|    value_loss            | 659          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.2427317] |
| time/                    |              |
|    fps                   | 112          |
|    iterations            | 6            |
|    time_elapsed          | 109          |
|    total_timesteps       | 12288        |
| train/                   |              |
|    approx_kl             | 0.0043467088 |
|    clip_fraction         | 0.0315       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.047        |
|    entropy_loss          | -2.8         |
|    explained_variance    | -0.0218      |
|    lagrangian_multiplier | 0.0946       |
|    learning_rate         | 0.0003       |
|    loss                  | 110          |
|    n_updates             | 50           |
|    policy_gradient_loss  | -0.00423     |
|    std                   | 0.976        |
|    value_loss            | 1.59e+03     |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.88917506] |
| time/                    |               |
|    fps                   | 127           |
|    iterations            | 7             |
|    time_elapsed          | 112           |
|    total_timesteps       | 14336         |
| train/                   |               |
|    approx_kl             | 0.007736983   |
|    clip_fraction         | 0.0629        |
|    clip_range            | 0.2           |
|    cost_value_loss       | 0.25          |
|    entropy_loss          | -2.83         |
|    explained_variance    | 0.00189       |
|    lagrangian_multiplier | 0.0642        |
|    learning_rate         | 0.0003        |
|    loss                  | 49.4          |
|    n_updates             | 60            |
|    policy_gradient_loss  | -0.00867      |
|    std                   | 0.994         |
|    value_loss            | 473           |
--------------------------------------------
-------------------------------------------
| reward                   | [-1.6347102] |
| time/                    |              |
|    fps                   | 127          |
|    iterations            | 7            |
|    time_elapsed          | 112          |
|    total_timesteps       | 14336        |
| train/                   |              |
|    approx_kl             | 0.004207916  |
|    clip_fraction         | 0.0266       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 1.59         |
|    entropy_loss          | -2.88        |
|    explained_variance    | -0.0207      |
|    lagrangian_multiplier | 0.056        |
|    learning_rate         | 0.0003       |
|    loss                  | 50.7         |
|    n_updates             | 60           |
|    policy_gradient_loss  | -0.00472     |
|    std                   | 1.03         |
|    value_loss            | 449          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.1530672] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 7            |
|    time_elapsed          | 114          |
|    total_timesteps       | 14336        |
| train/                   |              |
|    approx_kl             | 0.006265235  |
|    clip_fraction         | 0.0474       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 262          |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.00517      |
|    lagrangian_multiplier | 0.0506       |
|    learning_rate         | 0.0003       |
|    loss                  | 148          |
|    n_updates             | 60           |
|    policy_gradient_loss  | -0.00641     |
|    std                   | 0.947        |
|    value_loss            | 940          |
-------------------------------------------
srun: Job 114550 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 114550 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 114550 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 114550 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 114550 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 114550 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 114550 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 114550 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 114550 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 114550 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 114550 step creation temporarily disabled, retrying (Requested nodes are busy)
srun: Job 114550 step creation temporarily disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.6132374] |
| time/                    |              |
|    fps                   | 112          |
|    iterations            | 7            |
|    time_elapsed          | 127          |
|    total_timesteps       | 14336        |
| train/                   |              |
|    approx_kl             | 0.0050322977 |
|    clip_fraction         | 0.0398       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0246       |
|    entropy_loss          | -2.79        |
|    explained_variance    | -0.00287     |
|    lagrangian_multiplier | 0.0545       |
|    learning_rate         | 0.0003       |
|    loss                  | 81.3         |
|    n_updates             | 60           |
|    policy_gradient_loss  | -0.00527     |
|    std                   | 0.976        |
|    value_loss            | 823          |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.9503255] |
| time/                    |              |
|    fps                   | 127          |
|    iterations            | 8            |
|    time_elapsed          | 128          |
|    total_timesteps       | 16384        |
| train/                   |              |
|    approx_kl             | 0.006008149  |
|    clip_fraction         | 0.0456       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.17         |
|    entropy_loss          | -2.83        |
|    explained_variance    | -0.00778     |
|    lagrangian_multiplier | 0.0567       |
|    learning_rate         | 0.0003       |
|    loss                  | 61.8         |
|    n_updates             | 70           |
|    policy_gradient_loss  | -0.00806     |
|    std                   | 0.998        |
|    value_loss            | 525          |
-------------------------------------------
-------------------------------------------
| reward                   | [-2.0748725] |
| time/                    |              |
|    fps                   | 127          |
|    iterations            | 8            |
|    time_elapsed          | 128          |
|    total_timesteps       | 16384        |
| train/                   |              |
|    approx_kl             | 0.0046520014 |
|    clip_fraction         | 0.0321       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 5.55         |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.0535       |
|    lagrangian_multiplier | 0.0847       |
|    learning_rate         | 0.0003       |
|    loss                  | 38.2         |
|    n_updates             | 70           |
|    policy_gradient_loss  | -0.00478     |
|    std                   | 1.03         |
|    value_loss            | 492          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.7306067] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 8            |
|    time_elapsed          | 130          |
|    total_timesteps       | 16384        |
| train/                   |              |
|    approx_kl             | 0.005154918  |
|    clip_fraction         | 0.0352       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 258          |
|    entropy_loss          | -2.73        |
|    explained_variance    | -0.00444     |
|    lagrangian_multiplier | 0.0664       |
|    learning_rate         | 0.0003       |
|    loss                  | 139          |
|    n_updates             | 70           |
|    policy_gradient_loss  | -0.00484     |
|    std                   | 0.943        |
|    value_loss            | 1.31e+03     |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.9824454] |
| time/                    |              |
|    fps                   | 127          |
|    iterations            | 9            |
|    time_elapsed          | 144          |
|    total_timesteps       | 18432        |
| train/                   |              |
|    approx_kl             | 0.007975981  |
|    clip_fraction         | 0.0763       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.182        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0195       |
|    lagrangian_multiplier | 0.0483       |
|    learning_rate         | 0.0003       |
|    loss                  | 54.2         |
|    n_updates             | 80           |
|    policy_gradient_loss  | -0.00909     |
|    std                   | 1.01         |
|    value_loss            | 430          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.2585579] |
| time/                    |              |
|    fps                   | 127          |
|    iterations            | 9            |
|    time_elapsed          | 144          |
|    total_timesteps       | 18432        |
| train/                   |              |
|    approx_kl             | 0.005080082  |
|    clip_fraction         | 0.0426       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 6.57         |
|    entropy_loss          | -2.88        |
|    explained_variance    | -0.016       |
|    lagrangian_multiplier | 0.077        |
|    learning_rate         | 0.0003       |
|    loss                  | 48.8         |
|    n_updates             | 80           |
|    policy_gradient_loss  | -0.00679     |
|    std                   | 1.02         |
|    value_loss            | 613          |
-------------------------------------------
-------------------------------------------
| reward                   | [-2.0898755] |
| time/                    |              |
|    fps                   | 112          |
|    iterations            | 8            |
|    time_elapsed          | 145          |
|    total_timesteps       | 16384        |
| train/                   |              |
|    approx_kl             | 0.006745975  |
|    clip_fraction         | 0.0581       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0534       |
|    entropy_loss          | -2.79        |
|    explained_variance    | -0.000486    |
|    lagrangian_multiplier | 0.0668       |
|    learning_rate         | 0.0003       |
|    loss                  | 144          |
|    n_updates             | 70           |
|    policy_gradient_loss  | -0.00826     |
|    std                   | 0.975        |
|    value_loss            | 1.56e+03     |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.3444514] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 9            |
|    time_elapsed          | 146          |
|    total_timesteps       | 18432        |
| train/                   |              |
|    approx_kl             | 0.006169677  |
|    clip_fraction         | 0.055        |
|    clip_range            | 0.2          |
|    cost_value_loss       | 260          |
|    entropy_loss          | -2.71        |
|    explained_variance    | -0.0318      |
|    lagrangian_multiplier | 0.062        |
|    learning_rate         | 0.0003       |
|    loss                  | 101          |
|    n_updates             | 80           |
|    policy_gradient_loss  | -0.00765     |
|    std                   | 0.939        |
|    value_loss            | 721          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.1410947] |
| time/                    |              |
|    fps                   | 127          |
|    iterations            | 10           |
|    time_elapsed          | 160          |
|    total_timesteps       | 20480        |
| train/                   |              |
|    approx_kl             | 0.003975615  |
|    clip_fraction         | 0.0354       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.322        |
|    entropy_loss          | -2.87        |
|    explained_variance    | -0.00321     |
|    lagrangian_multiplier | 0.0656       |
|    learning_rate         | 0.0003       |
|    loss                  | 61.5         |
|    n_updates             | 90           |
|    policy_gradient_loss  | -0.00466     |
|    std                   | 1.02         |
|    value_loss            | 625          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.5801682] |
| time/                    |              |
|    fps                   | 127          |
|    iterations            | 10           |
|    time_elapsed          | 160          |
|    total_timesteps       | 20480        |
| train/                   |              |
|    approx_kl             | 0.005627757  |
|    clip_fraction         | 0.0671       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 4.84         |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.0866       |
|    lagrangian_multiplier | 0.0785       |
|    learning_rate         | 0.0003       |
|    loss                  | 48.8         |
|    n_updates             | 90           |
|    policy_gradient_loss  | -0.00755     |
|    std                   | 1.01         |
|    value_loss            | 564          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.5630597] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 10           |
|    time_elapsed          | 162          |
|    total_timesteps       | 20480        |
| train/                   |              |
|    approx_kl             | 0.0038818442 |
|    clip_fraction         | 0.0565       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 246          |
|    entropy_loss          | -2.73        |
|    explained_variance    | -0.0129      |
|    lagrangian_multiplier | 0.068        |
|    learning_rate         | 0.0003       |
|    loss                  | 163          |
|    n_updates             | 90           |
|    policy_gradient_loss  | -0.00856     |
|    std                   | 0.954        |
|    value_loss            | 1.45e+03     |
-------------------------------------------
------------------------------------------
| reward                   | [-2.742653] |
| time/                    |             |
|    fps                   | 112         |
|    iterations            | 9           |
|    time_elapsed          | 164         |
|    total_timesteps       | 18432       |
| train/                   |             |
|    approx_kl             | 0.006485201 |
|    clip_fraction         | 0.0548      |
|    clip_range            | 0.2         |
|    cost_value_loss       | 0.0321      |
|    entropy_loss          | -2.78       |
|    explained_variance    | -0.00799    |
|    lagrangian_multiplier | 0.0558      |
|    learning_rate         | 0.0003      |
|    loss                  | 105         |
|    n_updates             | 80          |
|    policy_gradient_loss  | -0.00637    |
|    std                   | 0.971       |
|    value_loss            | 965         |
------------------------------------------
-------------------------------------------
| reward                   | [-0.9554429] |
| time/                    |              |
|    fps                   | 127          |
|    iterations            | 11           |
|    time_elapsed          | 176          |
|    total_timesteps       | 22528        |
| train/                   |              |
|    approx_kl             | 0.0059374585 |
|    clip_fraction         | 0.0587       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.203        |
|    entropy_loss          | -2.89        |
|    explained_variance    | -0.0178      |
|    lagrangian_multiplier | 0.0456       |
|    learning_rate         | 0.0003       |
|    loss                  | 86.3         |
|    n_updates             | 100          |
|    policy_gradient_loss  | -0.0103      |
|    std                   | 1.03         |
|    value_loss            | 602          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.1440718] |
| time/                    |              |
|    fps                   | 127          |
|    iterations            | 11           |
|    time_elapsed          | 177          |
|    total_timesteps       | 22528        |
| train/                   |              |
|    approx_kl             | 0.00664254   |
|    clip_fraction         | 0.0565       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 2.71         |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0254       |
|    lagrangian_multiplier | 0.0603       |
|    learning_rate         | 0.0003       |
|    loss                  | 38.6         |
|    n_updates             | 100          |
|    policy_gradient_loss  | -0.00816     |
|    std                   | 1.01         |
|    value_loss            | 405          |
-------------------------------------------
-------------------------------------------
| reward                   | [-2.3486254] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 11           |
|    time_elapsed          | 178          |
|    total_timesteps       | 22528        |
| train/                   |              |
|    approx_kl             | 0.009610489  |
|    clip_fraction         | 0.105        |
|    clip_range            | 0.2          |
|    cost_value_loss       | 246          |
|    entropy_loss          | -2.74        |
|    explained_variance    | -0.00126     |
|    lagrangian_multiplier | 0.0533       |
|    learning_rate         | 0.0003       |
|    loss                  | 114          |
|    n_updates             | 100          |
|    policy_gradient_loss  | -0.0107      |
|    std                   | 0.952        |
|    value_loss            | 878          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.3575678] |
| time/                    |              |
|    fps                   | 112          |
|    iterations            | 10           |
|    time_elapsed          | 182          |
|    total_timesteps       | 20480        |
| train/                   |              |
|    approx_kl             | 0.007273853  |
|    clip_fraction         | 0.0684       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0718       |
|    entropy_loss          | -2.79        |
|    explained_variance    | -0.0247      |
|    lagrangian_multiplier | 0.0665       |
|    learning_rate         | 0.0003       |
|    loss                  | 142          |
|    n_updates             | 90           |
|    policy_gradient_loss  | -0.00801     |
|    std                   | 0.976        |
|    value_loss            | 1.45e+03     |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.0440867] |
| time/                    |              |
|    fps                   | 127          |
|    iterations            | 12           |
|    time_elapsed          | 192          |
|    total_timesteps       | 24576        |
| train/                   |              |
|    approx_kl             | 0.00652911   |
|    clip_fraction         | 0.0381       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.193        |
|    entropy_loss          | -2.9         |
|    explained_variance    | -0.0183      |
|    lagrangian_multiplier | 0.0683       |
|    learning_rate         | 0.0003       |
|    loss                  | 41.4         |
|    n_updates             | 110          |
|    policy_gradient_loss  | -0.00727     |
|    std                   | 1.03         |
|    value_loss            | 445          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.0512948] |
| time/                    |              |
|    fps                   | 127          |
|    iterations            | 12           |
|    time_elapsed          | 193          |
|    total_timesteps       | 24576        |
| train/                   |              |
|    approx_kl             | 0.0052055125 |
|    clip_fraction         | 0.0364       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 5.24         |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.007        |
|    lagrangian_multiplier | 0.0722       |
|    learning_rate         | 0.0003       |
|    loss                  | 30.9         |
|    n_updates             | 110          |
|    policy_gradient_loss  | -0.00672     |
|    std                   | 0.997        |
|    value_loss            | 332          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.3887742] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 12           |
|    time_elapsed          | 194          |
|    total_timesteps       | 24576        |
| train/                   |              |
|    approx_kl             | 0.0057843355 |
|    clip_fraction         | 0.0478       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 253          |
|    entropy_loss          | -2.74        |
|    explained_variance    | -0.0237      |
|    lagrangian_multiplier | 0.0559       |
|    learning_rate         | 0.0003       |
|    loss                  | 124          |
|    n_updates             | 110          |
|    policy_gradient_loss  | -0.0085      |
|    std                   | 0.951        |
|    value_loss            | 848          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.6235904] |
| time/                    |              |
|    fps                   | 112          |
|    iterations            | 11           |
|    time_elapsed          | 200          |
|    total_timesteps       | 22528        |
| train/                   |              |
|    approx_kl             | 0.006407641  |
|    clip_fraction         | 0.0651       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0654       |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.00576      |
|    lagrangian_multiplier | 0.0594       |
|    learning_rate         | 0.0003       |
|    loss                  | 184          |
|    n_updates             | 100          |
|    policy_gradient_loss  | -0.00894     |
|    std                   | 0.972        |
|    value_loss            | 1.46e+03     |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.4381056] |
| time/                    |              |
|    fps                   | 127          |
|    iterations            | 13           |
|    time_elapsed          | 208          |
|    total_timesteps       | 26624        |
| train/                   |              |
|    approx_kl             | 0.004479236  |
|    clip_fraction         | 0.0284       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.223        |
|    entropy_loss          | -2.89        |
|    explained_variance    | -0.000837    |
|    lagrangian_multiplier | 0.0611       |
|    learning_rate         | 0.0003       |
|    loss                  | 48.7         |
|    n_updates             | 120          |
|    policy_gradient_loss  | -0.00529     |
|    std                   | 1.02         |
|    value_loss            | 514          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.0160035] |
| time/                    |              |
|    fps                   | 127          |
|    iterations            | 13           |
|    time_elapsed          | 209          |
|    total_timesteps       | 26624        |
| train/                   |              |
|    approx_kl             | 0.0068427743 |
|    clip_fraction         | 0.0636       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 6.62         |
|    entropy_loss          | -2.82        |
|    explained_variance    | -0.00557     |
|    lagrangian_multiplier | 0.0805       |
|    learning_rate         | 0.0003       |
|    loss                  | 27.3         |
|    n_updates             | 120          |
|    policy_gradient_loss  | -0.00859     |
|    std                   | 0.986        |
|    value_loss            | 348          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.8326806] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 13           |
|    time_elapsed          | 210          |
|    total_timesteps       | 26624        |
| train/                   |              |
|    approx_kl             | 0.0053527183 |
|    clip_fraction         | 0.0428       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 218          |
|    entropy_loss          | -2.75        |
|    explained_variance    | -0.0169      |
|    lagrangian_multiplier | 0.059        |
|    learning_rate         | 0.0003       |
|    loss                  | 124          |
|    n_updates             | 120          |
|    policy_gradient_loss  | -0.00722     |
|    std                   | 0.957        |
|    value_loss            | 851          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.8290476] |
| time/                    |              |
|    fps                   | 112          |
|    iterations            | 12           |
|    time_elapsed          | 219          |
|    total_timesteps       | 24576        |
| train/                   |              |
|    approx_kl             | 0.0069684656 |
|    clip_fraction         | 0.0658       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0309       |
|    entropy_loss          | -2.78        |
|    explained_variance    | 0.0172       |
|    lagrangian_multiplier | 0.0473       |
|    learning_rate         | 0.0003       |
|    loss                  | 79           |
|    n_updates             | 110          |
|    policy_gradient_loss  | -0.00832     |
|    std                   | 0.969        |
|    value_loss            | 597          |
-------------------------------------------
-------------------------------------------
| reward                   | [-2.0213253] |
| time/                    |              |
|    fps                   | 127          |
|    iterations            | 14           |
|    time_elapsed          | 225          |
|    total_timesteps       | 28672        |
| train/                   |              |
|    approx_kl             | 0.0055183545 |
|    clip_fraction         | 0.0529       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 24.7         |
|    entropy_loss          | -2.8         |
|    explained_variance    | -0.0134      |
|    lagrangian_multiplier | 0.0654       |
|    learning_rate         | 0.0003       |
|    loss                  | 45.2         |
|    n_updates             | 130          |
|    policy_gradient_loss  | -0.00894     |
|    std                   | 0.982        |
|    value_loss            | 417          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.9397541] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 14           |
|    time_elapsed          | 226          |
|    total_timesteps       | 28672        |
| train/                   |              |
|    approx_kl             | 0.006001896  |
|    clip_fraction         | 0.0467       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 197          |
|    entropy_loss          | -2.76        |
|    explained_variance    | -0.016       |
|    lagrangian_multiplier | 0.0612       |
|    learning_rate         | 0.0003       |
|    loss                  | 88.7         |
|    n_updates             | 130          |
|    policy_gradient_loss  | -0.00702     |
|    std                   | 0.962        |
|    value_loss            | 668          |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.68876773] |
| time/                    |               |
|    fps                   | 126           |
|    iterations            | 14            |
|    time_elapsed          | 227           |
|    total_timesteps       | 28672         |
| train/                   |               |
|    approx_kl             | 0.005368452   |
|    clip_fraction         | 0.0541        |
|    clip_range            | 0.2           |
|    cost_value_loss       | 0.195         |
|    entropy_loss          | -2.88         |
|    explained_variance    | -0.0149       |
|    lagrangian_multiplier | 0.0529        |
|    learning_rate         | 0.0003        |
|    loss                  | 49.1          |
|    n_updates             | 130           |
|    policy_gradient_loss  | -0.00744      |
|    std                   | 1.02          |
|    value_loss            | 480           |
--------------------------------------------
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-0.7977352] |
| time/                    |              |
|    fps                   | 112          |
|    iterations            | 13           |
|    time_elapsed          | 237          |
|    total_timesteps       | 26624        |
| train/                   |              |
|    approx_kl             | 0.005438111  |
|    clip_fraction         | 0.0602       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0294       |
|    entropy_loss          | -2.77        |
|    explained_variance    | -0.00952     |
|    lagrangian_multiplier | 0.0647       |
|    learning_rate         | 0.0003       |
|    loss                  | 49.6         |
|    n_updates             | 120          |
|    policy_gradient_loss  | -0.0105      |
|    std                   | 0.97         |
|    value_loss            | 504          |
-------------------------------------------
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
--------------------------------------------
| reward                   | [-0.85236084] |
| time/                    |               |
|    fps                   | 127           |
|    iterations            | 15            |
|    time_elapsed          | 241           |
|    total_timesteps       | 30720         |
| train/                   |               |
|    approx_kl             | 0.007109224   |
|    clip_fraction         | 0.0471        |
|    clip_range            | 0.2           |
|    cost_value_loss       | 25.4          |
|    entropy_loss          | -2.79         |
|    explained_variance    | 0.00773       |
|    lagrangian_multiplier | 0.0757        |
|    learning_rate         | 0.0003        |
|    loss                  | 49.5          |
|    n_updates             | 140           |
|    policy_gradient_loss  | -0.00783      |
|    std                   | 0.976         |
|    value_loss            | 472           |
--------------------------------------------
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.7583984] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 15           |
|    time_elapsed          | 242          |
|    total_timesteps       | 30720        |
| train/                   |              |
|    approx_kl             | 0.007458849  |
|    clip_fraction         | 0.0634       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 226          |
|    entropy_loss          | -2.74        |
|    explained_variance    | -0.0375      |
|    lagrangian_multiplier | 0.0527       |
|    learning_rate         | 0.0003       |
|    loss                  | 106          |
|    n_updates             | 140          |
|    policy_gradient_loss  | -0.0109      |
|    std                   | 0.941        |
|    value_loss            | 791          |
-------------------------------------------
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.3976401] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 15           |
|    time_elapsed          | 244          |
|    total_timesteps       | 30720        |
| train/                   |              |
|    approx_kl             | 0.0043105283 |
|    clip_fraction         | 0.0428       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.102        |
|    entropy_loss          | -2.86        |
|    explained_variance    | -0.0186      |
|    lagrangian_multiplier | 0.0466       |
|    learning_rate         | 0.0003       |
|    loss                  | 50.9         |
|    n_updates             | 140          |
|    policy_gradient_loss  | -0.00711     |
|    std                   | 1.01         |
|    value_loss            | 395          |
-------------------------------------------
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.1507066] |
| time/                    |              |
|    fps                   | 112          |
|    iterations            | 14           |
|    time_elapsed          | 255          |
|    total_timesteps       | 28672        |
| train/                   |              |
|    approx_kl             | 0.0060684057 |
|    clip_fraction         | 0.0641       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0362       |
|    entropy_loss          | -2.78        |
|    explained_variance    | -0.0197      |
|    lagrangian_multiplier | 0.0647       |
|    learning_rate         | 0.0003       |
|    loss                  | 60.3         |
|    n_updates             | 130          |
|    policy_gradient_loss  | -0.00818     |
|    std                   | 0.974        |
|    value_loss            | 669          |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.44035313] |
| time/                    |               |
|    fps                   | 127           |
|    iterations            | 16            |
|    time_elapsed          | 257           |
|    total_timesteps       | 32768         |
| train/                   |               |
|    approx_kl             | 0.005947846   |
|    clip_fraction         | 0.0401        |
|    clip_range            | 0.2           |
|    cost_value_loss       | 13.9          |
|    entropy_loss          | -2.77         |
|    explained_variance    | 0.049         |
|    lagrangian_multiplier | 0.0664        |
|    learning_rate         | 0.0003        |
|    loss                  | 49.6          |
|    n_updates             | 150           |
|    policy_gradient_loss  | -0.00765      |
|    std                   | 0.967         |
|    value_loss            | 551           |
--------------------------------------------
-------------------------------------------
| reward                   | [-1.1275798] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 16           |
|    time_elapsed          | 258          |
|    total_timesteps       | 32768        |
| train/                   |              |
|    approx_kl             | 0.0047478345 |
|    clip_fraction         | 0.0463       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 264          |
|    entropy_loss          | -2.71        |
|    explained_variance    | -0.011       |
|    lagrangian_multiplier | 0.0507       |
|    learning_rate         | 0.0003       |
|    loss                  | 105          |
|    n_updates             | 150          |
|    policy_gradient_loss  | -0.00566     |
|    std                   | 0.933        |
|    value_loss            | 712          |
-------------------------------------------
-------------------------------------------
| reward                   | [-2.4348676] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 16           |
|    time_elapsed          | 261          |
|    total_timesteps       | 32768        |
| train/                   |              |
|    approx_kl             | 0.0075409743 |
|    clip_fraction         | 0.0663       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0963       |
|    entropy_loss          | -2.87        |
|    explained_variance    | -0.00111     |
|    lagrangian_multiplier | 0.0706       |
|    learning_rate         | 0.0003       |
|    loss                  | 93           |
|    n_updates             | 150          |
|    policy_gradient_loss  | -0.0107      |
|    std                   | 1.02         |
|    value_loss            | 857          |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.89021957] |
| time/                    |               |
|    fps                   | 112           |
|    iterations            | 15            |
|    time_elapsed          | 273           |
|    total_timesteps       | 30720         |
| train/                   |               |
|    approx_kl             | 0.0047969613  |
|    clip_fraction         | 0.0365        |
|    clip_range            | 0.2           |
|    cost_value_loss       | 0.0182        |
|    entropy_loss          | -2.78         |
|    explained_variance    | -0.0156       |
|    lagrangian_multiplier | 0.067         |
|    learning_rate         | 0.0003        |
|    loss                  | 25.8          |
|    n_updates             | 140           |
|    policy_gradient_loss  | -0.0059       |
|    std                   | 0.973         |
|    value_loss            | 260           |
--------------------------------------------
-------------------------------------------
| reward                   | [-1.8622932] |
| time/                    |              |
|    fps                   | 127          |
|    iterations            | 17           |
|    time_elapsed          | 273          |
|    total_timesteps       | 34816        |
| train/                   |              |
|    approx_kl             | 0.0065189986 |
|    clip_fraction         | 0.0545       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 21.3         |
|    entropy_loss          | -2.76        |
|    explained_variance    | 0.0502       |
|    lagrangian_multiplier | 0.066        |
|    learning_rate         | 0.0003       |
|    loss                  | 54.7         |
|    n_updates             | 160          |
|    policy_gradient_loss  | -0.0075      |
|    std                   | 0.962        |
|    value_loss            | 569          |
-------------------------------------------
------------------------------------------
| reward                   | [-1.447584] |
| time/                    |             |
|    fps                   | 126         |
|    iterations            | 17          |
|    time_elapsed          | 274         |
|    total_timesteps       | 34816       |
| train/                   |             |
|    approx_kl             | 0.005278604 |
|    clip_fraction         | 0.0313      |
|    clip_range            | 0.2         |
|    cost_value_loss       | 182         |
|    entropy_loss          | -2.71       |
|    explained_variance    | -0.0592     |
|    lagrangian_multiplier | 0.0577      |
|    learning_rate         | 0.0003      |
|    loss                  | 73.7        |
|    n_updates             | 160         |
|    policy_gradient_loss  | -0.00647    |
|    std                   | 0.945       |
|    value_loss            | 535         |
------------------------------------------
-------------------------------------------
| reward                   | [-1.5500747] |
| time/                    |              |
|    fps                   | 124          |
|    iterations            | 17           |
|    time_elapsed          | 279          |
|    total_timesteps       | 34816        |
| train/                   |              |
|    approx_kl             | 0.007664597  |
|    clip_fraction         | 0.0736       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.13         |
|    entropy_loss          | -2.9         |
|    explained_variance    | -0.0103      |
|    lagrangian_multiplier | 0.056        |
|    learning_rate         | 0.0003       |
|    loss                  | 128          |
|    n_updates             | 160          |
|    policy_gradient_loss  | -0.0131      |
|    std                   | 1.04         |
|    value_loss            | 1.05e+03     |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.0172037] |
| time/                    |              |
|    fps                   | 127          |
|    iterations            | 18           |
|    time_elapsed          | 290          |
|    total_timesteps       | 36864        |
| train/                   |              |
|    approx_kl             | 0.005501337  |
|    clip_fraction         | 0.064        |
|    clip_range            | 0.2          |
|    cost_value_loss       | 13.5         |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.0335       |
|    lagrangian_multiplier | 0.0759       |
|    learning_rate         | 0.0003       |
|    loss                  | 54.6         |
|    n_updates             | 170          |
|    policy_gradient_loss  | -0.00844     |
|    std                   | 0.95         |
|    value_loss            | 620          |
-------------------------------------------
------------------------------------------
| reward                   | [-2.016957] |
| time/                    |             |
|    fps                   | 126         |
|    iterations            | 18          |
|    time_elapsed          | 290         |
|    total_timesteps       | 36864       |
| train/                   |             |
|    approx_kl             | 0.006724237 |
|    clip_fraction         | 0.0569      |
|    clip_range            | 0.2         |
|    cost_value_loss       | 203         |
|    entropy_loss          | -2.71       |
|    explained_variance    | -0.011      |
|    lagrangian_multiplier | 0.0594      |
|    learning_rate         | 0.0003      |
|    loss                  | 81.4        |
|    n_updates             | 170         |
|    policy_gradient_loss  | -0.00799    |
|    std                   | 0.931       |
|    value_loss            | 572         |
------------------------------------------
-------------------------------------------
| reward                   | [-1.6317173] |
| time/                    |              |
|    fps                   | 112          |
|    iterations            | 16           |
|    time_elapsed          | 292          |
|    total_timesteps       | 32768        |
| train/                   |              |
|    approx_kl             | 0.0058284337 |
|    clip_fraction         | 0.047        |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0165       |
|    entropy_loss          | -2.78        |
|    explained_variance    | -0.00173     |
|    lagrangian_multiplier | 0.079        |
|    learning_rate         | 0.0003       |
|    loss                  | 45.9         |
|    n_updates             | 150          |
|    policy_gradient_loss  | -0.0081      |
|    std                   | 0.974        |
|    value_loss            | 497          |
-------------------------------------------
-------------------------------------------
| reward                   | [-2.1026244] |
| time/                    |              |
|    fps                   | 124          |
|    iterations            | 18           |
|    time_elapsed          | 295          |
|    total_timesteps       | 36864        |
| train/                   |              |
|    approx_kl             | 0.0057115606 |
|    clip_fraction         | 0.052        |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0529       |
|    entropy_loss          | -2.9         |
|    explained_variance    | 0.0206       |
|    lagrangian_multiplier | 0.0662       |
|    learning_rate         | 0.0003       |
|    loss                  | 58.6         |
|    n_updates             | 170          |
|    policy_gradient_loss  | -0.00536     |
|    std                   | 1.02         |
|    value_loss            | 625          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.2232383] |
| time/                    |              |
|    fps                   | 127          |
|    iterations            | 19           |
|    time_elapsed          | 306          |
|    total_timesteps       | 38912        |
| train/                   |              |
|    approx_kl             | 0.004806012  |
|    clip_fraction         | 0.0502       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 31.6         |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.0543       |
|    lagrangian_multiplier | 0.0769       |
|    learning_rate         | 0.0003       |
|    loss                  | 50           |
|    n_updates             | 180          |
|    policy_gradient_loss  | -0.00722     |
|    std                   | 0.952        |
|    value_loss            | 507          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.8696359] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 19           |
|    time_elapsed          | 306          |
|    total_timesteps       | 38912        |
| train/                   |              |
|    approx_kl             | 0.008677681  |
|    clip_fraction         | 0.0772       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 247          |
|    entropy_loss          | -2.69        |
|    explained_variance    | -0.013       |
|    lagrangian_multiplier | 0.0482       |
|    learning_rate         | 0.0003       |
|    loss                  | 101          |
|    n_updates             | 180          |
|    policy_gradient_loss  | -0.0129      |
|    std                   | 0.924        |
|    value_loss            | 538          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.7660508] |
| time/                    |              |
|    fps                   | 112          |
|    iterations            | 17           |
|    time_elapsed          | 310          |
|    total_timesteps       | 34816        |
| train/                   |              |
|    approx_kl             | 0.005856787  |
|    clip_fraction         | 0.0574       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0216       |
|    entropy_loss          | -2.79        |
|    explained_variance    | -0.00609     |
|    lagrangian_multiplier | 0.071        |
|    learning_rate         | 0.0003       |
|    loss                  | 79.7         |
|    n_updates             | 160          |
|    policy_gradient_loss  | -0.00728     |
|    std                   | 0.975        |
|    value_loss            | 940          |
-------------------------------------------
------------------------------------------
| reward                   | [-1.528568] |
| time/                    |             |
|    fps                   | 124         |
|    iterations            | 19          |
|    time_elapsed          | 312         |
|    total_timesteps       | 38912       |
| train/                   |             |
|    approx_kl             | 0.004849331 |
|    clip_fraction         | 0.0385      |
|    clip_range            | 0.2         |
|    cost_value_loss       | 0.124       |
|    entropy_loss          | -2.89       |
|    explained_variance    | 0.0194      |
|    lagrangian_multiplier | 0.0697      |
|    learning_rate         | 0.0003      |
|    loss                  | 59.5        |
|    n_updates             | 180         |
|    policy_gradient_loss  | -0.00489    |
|    std                   | 1.03        |
|    value_loss            | 715         |
------------------------------------------
------------------------------------------
| reward                   | [-0.479975] |
| time/                    |             |
|    fps                   | 127         |
|    iterations            | 20          |
|    time_elapsed          | 322         |
|    total_timesteps       | 40960       |
| train/                   |             |
|    approx_kl             | 0.006137724 |
|    clip_fraction         | 0.0558      |
|    clip_range            | 0.2         |
|    cost_value_loss       | 11.9        |
|    entropy_loss          | -2.73       |
|    explained_variance    | 0.0502      |
|    lagrangian_multiplier | 0.0582      |
|    learning_rate         | 0.0003      |
|    loss                  | 45.3        |
|    n_updates             | 190         |
|    policy_gradient_loss  | -0.00854    |
|    std                   | 0.948       |
|    value_loss            | 417         |
------------------------------------------
-------------------------------------------
| reward                   | [-1.5508639] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 20           |
|    time_elapsed          | 322          |
|    total_timesteps       | 40960        |
| train/                   |              |
|    approx_kl             | 0.0060266857 |
|    clip_fraction         | 0.0717       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 247          |
|    entropy_loss          | -2.69        |
|    explained_variance    | -0.00511     |
|    lagrangian_multiplier | 0.0567       |
|    learning_rate         | 0.0003       |
|    loss                  | 94.5         |
|    n_updates             | 190          |
|    policy_gradient_loss  | -0.00869     |
|    std                   | 0.929        |
|    value_loss            | 652          |
-------------------------------------------
-------------------------------------------
| reward                   | [-2.2146747] |
| time/                    |              |
|    fps                   | 124          |
|    iterations            | 20           |
|    time_elapsed          | 328          |
|    total_timesteps       | 40960        |
| train/                   |              |
|    approx_kl             | 0.0067304587 |
|    clip_fraction         | 0.0477       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.267        |
|    entropy_loss          | -2.89        |
|    explained_variance    | 0.00153      |
|    lagrangian_multiplier | 0.0654       |
|    learning_rate         | 0.0003       |
|    loss                  | 45.1         |
|    n_updates             | 190          |
|    policy_gradient_loss  | -0.00649     |
|    std                   | 1.02         |
|    value_loss            | 477          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.9935272] |
| time/                    |              |
|    fps                   | 112          |
|    iterations            | 18           |
|    time_elapsed          | 328          |
|    total_timesteps       | 36864        |
| train/                   |              |
|    approx_kl             | 0.006078097  |
|    clip_fraction         | 0.0629       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0137       |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.00415      |
|    lagrangian_multiplier | 0.0723       |
|    learning_rate         | 0.0003       |
|    loss                  | 39.9         |
|    n_updates             | 170          |
|    policy_gradient_loss  | -0.0078      |
|    std                   | 0.977        |
|    value_loss            | 459          |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.92998475] |
| time/                    |               |
|    fps                   | 127           |
|    iterations            | 21            |
|    time_elapsed          | 338           |
|    total_timesteps       | 43008         |
| train/                   |               |
|    approx_kl             | 0.008140823   |
|    clip_fraction         | 0.0673        |
|    clip_range            | 0.2           |
|    cost_value_loss       | 19.7          |
|    entropy_loss          | -2.73         |
|    explained_variance    | 0.0532        |
|    lagrangian_multiplier | 0.0609        |
|    learning_rate         | 0.0003        |
|    loss                  | 81.3          |
|    n_updates             | 200           |
|    policy_gradient_loss  | -0.00911      |
|    std                   | 0.946         |
|    value_loss            | 739           |
--------------------------------------------
-------------------------------------------
| reward                   | [-1.6809773] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 21           |
|    time_elapsed          | 339          |
|    total_timesteps       | 43008        |
| train/                   |              |
|    approx_kl             | 0.008219871  |
|    clip_fraction         | 0.0783       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 269          |
|    entropy_loss          | -2.68        |
|    explained_variance    | -0.0258      |
|    lagrangian_multiplier | 0.0545       |
|    learning_rate         | 0.0003       |
|    loss                  | 85.1         |
|    n_updates             | 200          |
|    policy_gradient_loss  | -0.0114      |
|    std                   | 0.922        |
|    value_loss            | 485          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.691389]  |
| time/                    |              |
|    fps                   | 124          |
|    iterations            | 21           |
|    time_elapsed          | 344          |
|    total_timesteps       | 43008        |
| train/                   |              |
|    approx_kl             | 0.0056136698 |
|    clip_fraction         | 0.0612       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.317        |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.015        |
|    lagrangian_multiplier | 0.0627       |
|    learning_rate         | 0.0003       |
|    loss                  | 45           |
|    n_updates             | 200          |
|    policy_gradient_loss  | -0.00628     |
|    std                   | 1.03         |
|    value_loss            | 451          |
-------------------------------------------
-------------------------------------------
| reward                   | [-2.0977342] |
| time/                    |              |
|    fps                   | 112          |
|    iterations            | 19           |
|    time_elapsed          | 347          |
|    total_timesteps       | 38912        |
| train/                   |              |
|    approx_kl             | 0.006379502  |
|    clip_fraction         | 0.0629       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0247       |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.0147       |
|    lagrangian_multiplier | 0.0645       |
|    learning_rate         | 0.0003       |
|    loss                  | 45           |
|    n_updates             | 180          |
|    policy_gradient_loss  | -0.00878     |
|    std                   | 0.976        |
|    value_loss            | 438          |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.7794588] |
| time/                    |              |
|    fps                   | 127          |
|    iterations            | 22           |
|    time_elapsed          | 354          |
|    total_timesteps       | 45056        |
| train/                   |              |
|    approx_kl             | 0.007228981  |
|    clip_fraction         | 0.0762       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 7.88         |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.0246       |
|    lagrangian_multiplier | 0.0609       |
|    learning_rate         | 0.0003       |
|    loss                  | 26.2         |
|    n_updates             | 210          |
|    policy_gradient_loss  | -0.013       |
|    std                   | 0.942        |
|    value_loss            | 260          |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.37884465] |
| time/                    |               |
|    fps                   | 126           |
|    iterations            | 22            |
|    time_elapsed          | 355           |
|    total_timesteps       | 45056         |
| train/                   |               |
|    approx_kl             | 0.007440546   |
|    clip_fraction         | 0.0709        |
|    clip_range            | 0.2           |
|    cost_value_loss       | 257           |
|    entropy_loss          | -2.66         |
|    explained_variance    | -0.0288       |
|    lagrangian_multiplier | 0.0527        |
|    learning_rate         | 0.0003        |
|    loss                  | 91.5          |
|    n_updates             | 210           |
|    policy_gradient_loss  | -0.00995      |
|    std                   | 0.907         |
|    value_loss            | 517           |
--------------------------------------------
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
--------------------------------------------
| reward                   | [-0.23865816] |
| time/                    |               |
|    fps                   | 125           |
|    iterations            | 22            |
|    time_elapsed          | 360           |
|    total_timesteps       | 45056         |
| train/                   |               |
|    approx_kl             | 0.0063493154  |
|    clip_fraction         | 0.0513        |
|    clip_range            | 0.2           |
|    cost_value_loss       | 0.175         |
|    entropy_loss          | -2.89         |
|    explained_variance    | 0.0347        |
|    lagrangian_multiplier | 0.0791        |
|    learning_rate         | 0.0003        |
|    loss                  | 41.6          |
|    n_updates             | 210           |
|    policy_gradient_loss  | -0.00753      |
|    std                   | 1.03          |
|    value_loss            | 518           |
--------------------------------------------
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.3105046] |
| time/                    |              |
|    fps                   | 112          |
|    iterations            | 20           |
|    time_elapsed          | 365          |
|    total_timesteps       | 40960        |
| train/                   |              |
|    approx_kl             | 0.0046646185 |
|    clip_fraction         | 0.0424       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0171       |
|    entropy_loss          | -2.79        |
|    explained_variance    | 0.000457     |
|    lagrangian_multiplier | 0.0903       |
|    learning_rate         | 0.0003       |
|    loss                  | 31.5         |
|    n_updates             | 190          |
|    policy_gradient_loss  | -0.00697     |
|    std                   | 0.979        |
|    value_loss            | 450          |
-------------------------------------------
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.3039237] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 23           |
|    time_elapsed          | 370          |
|    total_timesteps       | 47104        |
| train/                   |              |
|    approx_kl             | 0.0065410174 |
|    clip_fraction         | 0.0535       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 2.29         |
|    entropy_loss          | -2.71        |
|    explained_variance    | -0.0631      |
|    lagrangian_multiplier | 0.0691       |
|    learning_rate         | 0.0003       |
|    loss                  | 23.7         |
|    n_updates             | 220          |
|    policy_gradient_loss  | -0.00733     |
|    std                   | 0.94         |
|    value_loss            | 265          |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.61370075] |
| time/                    |               |
|    fps                   | 126           |
|    iterations            | 23            |
|    time_elapsed          | 371           |
|    total_timesteps       | 47104         |
| train/                   |               |
|    approx_kl             | 0.008152945   |
|    clip_fraction         | 0.0929        |
|    clip_range            | 0.2           |
|    cost_value_loss       | 259           |
|    entropy_loss          | -2.66         |
|    explained_variance    | -0.00399      |
|    lagrangian_multiplier | 0.048         |
|    learning_rate         | 0.0003        |
|    loss                  | 135           |
|    n_updates             | 220           |
|    policy_gradient_loss  | -0.0106       |
|    std                   | 0.917         |
|    value_loss            | 795           |
--------------------------------------------
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-0.6553342] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 23           |
|    time_elapsed          | 376          |
|    total_timesteps       | 47104        |
| train/                   |              |
|    approx_kl             | 0.0065108603 |
|    clip_fraction         | 0.0798       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.199        |
|    entropy_loss          | -2.9         |
|    explained_variance    | -0.00646     |
|    lagrangian_multiplier | 0.0764       |
|    learning_rate         | 0.0003       |
|    loss                  | 24.7         |
|    n_updates             | 220          |
|    policy_gradient_loss  | -0.0102      |
|    std                   | 1.04         |
|    value_loss            | 374          |
-------------------------------------------
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.1592475] |
| time/                    |              |
|    fps                   | 112          |
|    iterations            | 21           |
|    time_elapsed          | 383          |
|    total_timesteps       | 43008        |
| train/                   |              |
|    approx_kl             | 0.0048685735 |
|    clip_fraction         | 0.0482       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0441       |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.0113       |
|    lagrangian_multiplier | 0.0677       |
|    learning_rate         | 0.0003       |
|    loss                  | 35.2         |
|    n_updates             | 200          |
|    policy_gradient_loss  | -0.0082      |
|    std                   | 0.98         |
|    value_loss            | 360          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.418238]  |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 24           |
|    time_elapsed          | 387          |
|    total_timesteps       | 49152        |
| train/                   |              |
|    approx_kl             | 0.0051635345 |
|    clip_fraction         | 0.0434       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 5.05         |
|    entropy_loss          | -2.73        |
|    explained_variance    | 0.0396       |
|    lagrangian_multiplier | 0.0532       |
|    learning_rate         | 0.0003       |
|    loss                  | 61.6         |
|    n_updates             | 230          |
|    policy_gradient_loss  | -0.00787     |
|    std                   | 0.957        |
|    value_loss            | 546          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.2515635] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 24           |
|    time_elapsed          | 387          |
|    total_timesteps       | 49152        |
| train/                   |              |
|    approx_kl             | 0.0065097837 |
|    clip_fraction         | 0.0571       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 253          |
|    entropy_loss          | -2.67        |
|    explained_variance    | -0.0458      |
|    lagrangian_multiplier | 0.0628       |
|    learning_rate         | 0.0003       |
|    loss                  | 91.8         |
|    n_updates             | 230          |
|    policy_gradient_loss  | -0.00629     |
|    std                   | 0.923        |
|    value_loss            | 636          |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.6534808] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 24           |
|    time_elapsed          | 392          |
|    total_timesteps       | 49152        |
| train/                   |              |
|    approx_kl             | 0.004944248  |
|    clip_fraction         | 0.05         |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.096        |
|    entropy_loss          | -2.92        |
|    explained_variance    | 0.0294       |
|    lagrangian_multiplier | 0.0738       |
|    learning_rate         | 0.0003       |
|    loss                  | 63.7         |
|    n_updates             | 230          |
|    policy_gradient_loss  | -0.00523     |
|    std                   | 1.04         |
|    value_loss            | 742          |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.55725074] |
| time/                    |               |
|    fps                   | 112           |
|    iterations            | 22            |
|    time_elapsed          | 402           |
|    total_timesteps       | 45056         |
| train/                   |               |
|    approx_kl             | 0.0052976273  |
|    clip_fraction         | 0.0354        |
|    clip_range            | 0.2           |
|    cost_value_loss       | 0.0462        |
|    entropy_loss          | -2.79         |
|    explained_variance    | -0.014        |
|    lagrangian_multiplier | 0.0716        |
|    learning_rate         | 0.0003        |
|    loss                  | 35.1          |
|    n_updates             | 210           |
|    policy_gradient_loss  | -0.00745      |
|    std                   | 0.973         |
|    value_loss            | 395           |
--------------------------------------------
-------------------------------------------
| reward                   | [-0.7567779] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 25           |
|    time_elapsed          | 403          |
|    total_timesteps       | 51200        |
| train/                   |              |
|    approx_kl             | 0.009615544  |
|    clip_fraction         | 0.085        |
|    clip_range            | 0.2          |
|    cost_value_loss       | 264          |
|    entropy_loss          | -2.7         |
|    explained_variance    | -0.0351      |
|    lagrangian_multiplier | 0.0504       |
|    learning_rate         | 0.0003       |
|    loss                  | 106          |
|    n_updates             | 240          |
|    policy_gradient_loss  | -0.014       |
|    std                   | 0.938        |
|    value_loss            | 616          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.1167071] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 25           |
|    time_elapsed          | 403          |
|    total_timesteps       | 51200        |
| train/                   |              |
|    approx_kl             | 0.004965297  |
|    clip_fraction         | 0.045        |
|    clip_range            | 0.2          |
|    cost_value_loss       | 2.74         |
|    entropy_loss          | -2.74        |
|    explained_variance    | 0.0536       |
|    lagrangian_multiplier | 0.0566       |
|    learning_rate         | 0.0003       |
|    loss                  | 47           |
|    n_updates             | 240          |
|    policy_gradient_loss  | -0.00816     |
|    std                   | 0.954        |
|    value_loss            | 467          |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.61283207] |
| time/                    |               |
|    fps                   | 125           |
|    iterations            | 25            |
|    time_elapsed          | 408           |
|    total_timesteps       | 51200         |
| train/                   |               |
|    approx_kl             | 0.0048835236  |
|    clip_fraction         | 0.0411        |
|    clip_range            | 0.2           |
|    cost_value_loss       | 0.104         |
|    entropy_loss          | -2.9          |
|    explained_variance    | -0.0283       |
|    lagrangian_multiplier | 0.0602        |
|    learning_rate         | 0.0003        |
|    loss                  | 23.7          |
|    n_updates             | 240           |
|    policy_gradient_loss  | -0.00685      |
|    std                   | 1.03          |
|    value_loss            | 225           |
--------------------------------------------
-------------------------------------------
| reward                   | [-0.9008019] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 26           |
|    time_elapsed          | 419          |
|    total_timesteps       | 53248        |
| train/                   |              |
|    approx_kl             | 0.0071376474 |
|    clip_fraction         | 0.0754       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 227          |
|    entropy_loss          | -2.7         |
|    explained_variance    | -0.0419      |
|    lagrangian_multiplier | 0.0566       |
|    learning_rate         | 0.0003       |
|    loss                  | 89.5         |
|    n_updates             | 250          |
|    policy_gradient_loss  | -0.00943     |
|    std                   | 0.928        |
|    value_loss            | 622          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.6815364] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 26           |
|    time_elapsed          | 419          |
|    total_timesteps       | 53248        |
| train/                   |              |
|    approx_kl             | 0.0072251465 |
|    clip_fraction         | 0.0675       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 37.6         |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.0783       |
|    lagrangian_multiplier | 0.0604       |
|    learning_rate         | 0.0003       |
|    loss                  | 51.2         |
|    n_updates             | 250          |
|    policy_gradient_loss  | -0.0109      |
|    std                   | 0.928        |
|    value_loss            | 517          |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.44907317] |
| time/                    |               |
|    fps                   | 111           |
|    iterations            | 23            |
|    time_elapsed          | 421           |
|    total_timesteps       | 47104         |
| train/                   |               |
|    approx_kl             | 0.0062594106  |
|    clip_fraction         | 0.0666        |
|    clip_range            | 0.2           |
|    cost_value_loss       | 0.0401        |
|    entropy_loss          | -2.78         |
|    explained_variance    | -0.0321       |
|    lagrangian_multiplier | 0.0826        |
|    learning_rate         | 0.0003        |
|    loss                  | 25            |
|    n_updates             | 220           |
|    policy_gradient_loss  | -0.00808      |
|    std                   | 0.969         |
|    value_loss            | 303           |
--------------------------------------------
-------------------------------------------
| reward                   | [-0.8313408] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 26           |
|    time_elapsed          | 424          |
|    total_timesteps       | 53248        |
| train/                   |              |
|    approx_kl             | 0.0047292486 |
|    clip_fraction         | 0.0403       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0363       |
|    entropy_loss          | -2.88        |
|    explained_variance    | 0.0187       |
|    lagrangian_multiplier | 0.0677       |
|    learning_rate         | 0.0003       |
|    loss                  | 85.1         |
|    n_updates             | 250          |
|    policy_gradient_loss  | -0.00388     |
|    std                   | 1.02         |
|    value_loss            | 975          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.2013298] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 27           |
|    time_elapsed          | 435          |
|    total_timesteps       | 55296        |
| train/                   |              |
|    approx_kl             | 0.00636873   |
|    clip_fraction         | 0.0567       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 134          |
|    entropy_loss          | -2.68        |
|    explained_variance    | -0.0791      |
|    lagrangian_multiplier | 0.0533       |
|    learning_rate         | 0.0003       |
|    loss                  | 68.5         |
|    n_updates             | 260          |
|    policy_gradient_loss  | -0.00801     |
|    std                   | 0.917        |
|    value_loss            | 468          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.9824779] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 27           |
|    time_elapsed          | 435          |
|    total_timesteps       | 55296        |
| train/                   |              |
|    approx_kl             | 0.005974365  |
|    clip_fraction         | 0.0521       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 3.82         |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.0703       |
|    lagrangian_multiplier | 0.0607       |
|    learning_rate         | 0.0003       |
|    loss                  | 25.3         |
|    n_updates             | 260          |
|    policy_gradient_loss  | -0.0097      |
|    std                   | 0.944        |
|    value_loss            | 243          |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.9995062] |
| time/                    |              |
|    fps                   | 111          |
|    iterations            | 24           |
|    time_elapsed          | 440          |
|    total_timesteps       | 49152        |
| train/                   |              |
|    approx_kl             | 0.006526883  |
|    clip_fraction         | 0.0489       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0335       |
|    entropy_loss          | -2.77        |
|    explained_variance    | -0.0338      |
|    lagrangian_multiplier | 0.0687       |
|    learning_rate         | 0.0003       |
|    loss                  | 33.3         |
|    n_updates             | 230          |
|    policy_gradient_loss  | -0.00594     |
|    std                   | 0.968        |
|    value_loss            | 351          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.3741788] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 27           |
|    time_elapsed          | 441          |
|    total_timesteps       | 55296        |
| train/                   |              |
|    approx_kl             | 0.006003945  |
|    clip_fraction         | 0.0554       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0832       |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.00716      |
|    lagrangian_multiplier | 0.0715       |
|    learning_rate         | 0.0003       |
|    loss                  | 64.2         |
|    n_updates             | 260          |
|    policy_gradient_loss  | -0.00616     |
|    std                   | 1.01         |
|    value_loss            | 622          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.0462135] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 28           |
|    time_elapsed          | 451          |
|    total_timesteps       | 57344        |
| train/                   |              |
|    approx_kl             | 0.0061328365 |
|    clip_fraction         | 0.0758       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 30.2         |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.0324       |
|    lagrangian_multiplier | 0.0605       |
|    learning_rate         | 0.0003       |
|    loss                  | 63           |
|    n_updates             | 270          |
|    policy_gradient_loss  | -0.00965     |
|    std                   | 0.947        |
|    value_loss            | 561          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.7714299] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 28           |
|    time_elapsed          | 457          |
|    total_timesteps       | 57344        |
| train/                   |              |
|    approx_kl             | 0.0071933134 |
|    clip_fraction         | 0.0572       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0821       |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.00825      |
|    lagrangian_multiplier | 0.0663       |
|    learning_rate         | 0.0003       |
|    loss                  | 66.1         |
|    n_updates             | 270          |
|    policy_gradient_loss  | -0.00607     |
|    std                   | 0.994        |
|    value_loss            | 613          |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.9077452] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 28           |
|    time_elapsed          | 456          |
|    total_timesteps       | 57344        |
| train/                   |              |
|    approx_kl             | 0.009277847  |
|    clip_fraction         | 0.0764       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 256          |
|    entropy_loss          | -2.67        |
|    explained_variance    | -0.0586      |
|    lagrangian_multiplier | 0.0529       |
|    learning_rate         | 0.0003       |
|    loss                  | 75.6         |
|    n_updates             | 270          |
|    policy_gradient_loss  | -0.0107      |
|    std                   | 0.919        |
|    value_loss            | 370          |
-------------------------------------------
------------------------------------------
| reward                   | [-0.833646] |
| time/                    |             |
|    fps                   | 111         |
|    iterations            | 25          |
|    time_elapsed          | 458         |
|    total_timesteps       | 51200       |
| train/                   |             |
|    approx_kl             | 0.005984688 |
|    clip_fraction         | 0.0495      |
|    clip_range            | 0.2         |
|    cost_value_loss       | 0.0476      |
|    entropy_loss          | -2.77       |
|    explained_variance    | 0.0019      |
|    lagrangian_multiplier | 0.069       |
|    learning_rate         | 0.0003      |
|    loss                  | 35.1        |
|    n_updates             | 240         |
|    policy_gradient_loss  | -0.00803    |
|    std                   | 0.961       |
|    value_loss            | 333         |
------------------------------------------
-------------------------------------------
| reward                   | [-2.2062268] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 29           |
|    time_elapsed          | 467          |
|    total_timesteps       | 59392        |
| train/                   |              |
|    approx_kl             | 0.0060069384 |
|    clip_fraction         | 0.058        |
|    clip_range            | 0.2          |
|    cost_value_loss       | 6.75         |
|    entropy_loss          | -2.72        |
|    explained_variance    | 0.0369       |
|    lagrangian_multiplier | 0.0665       |
|    learning_rate         | 0.0003       |
|    loss                  | 41.9         |
|    n_updates             | 280          |
|    policy_gradient_loss  | -0.0073      |
|    std                   | 0.945        |
|    value_loss            | 476          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.2430922] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 29           |
|    time_elapsed          | 473          |
|    total_timesteps       | 59392        |
| train/                   |              |
|    approx_kl             | 0.0036003017 |
|    clip_fraction         | 0.037        |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.13         |
|    entropy_loss          | -2.84        |
|    explained_variance    | -0.00789     |
|    lagrangian_multiplier | 0.0716       |
|    learning_rate         | 0.0003       |
|    loss                  | 29.3         |
|    n_updates             | 280          |
|    policy_gradient_loss  | -0.00671     |
|    std                   | 1.01         |
|    value_loss            | 353          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.0762581] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 29           |
|    time_elapsed          | 472          |
|    total_timesteps       | 59392        |
| train/                   |              |
|    approx_kl             | 0.005810995  |
|    clip_fraction         | 0.0509       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 186          |
|    entropy_loss          | -2.66        |
|    explained_variance    | -0.0153      |
|    lagrangian_multiplier | 0.0493       |
|    learning_rate         | 0.0003       |
|    loss                  | 73           |
|    n_updates             | 280          |
|    policy_gradient_loss  | -0.00696     |
|    std                   | 0.914        |
|    value_loss            | 406          |
-------------------------------------------
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
--------------------------------------------
| reward                   | [-0.18276995] |
| time/                    |               |
|    fps                   | 111           |
|    iterations            | 26            |
|    time_elapsed          | 476           |
|    total_timesteps       | 53248         |
| train/                   |               |
|    approx_kl             | 0.008963917   |
|    clip_fraction         | 0.0966        |
|    clip_range            | 0.2           |
|    cost_value_loss       | 0.0321        |
|    entropy_loss          | -2.73         |
|    explained_variance    | 0.0205        |
|    lagrangian_multiplier | 0.066         |
|    learning_rate         | 0.0003        |
|    loss                  | 35            |
|    n_updates             | 250           |
|    policy_gradient_loss  | -0.0123       |
|    std                   | 0.942         |
|    value_loss            | 365           |
--------------------------------------------
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.2915953] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 30           |
|    time_elapsed          | 484          |
|    total_timesteps       | 61440        |
| train/                   |              |
|    approx_kl             | 0.007001249  |
|    clip_fraction         | 0.0686       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 3.47         |
|    entropy_loss          | -2.7         |
|    explained_variance    | 0.0373       |
|    lagrangian_multiplier | 0.072        |
|    learning_rate         | 0.0003       |
|    loss                  | 65.4         |
|    n_updates             | 290          |
|    policy_gradient_loss  | -0.00824     |
|    std                   | 0.933        |
|    value_loss            | 675          |
-------------------------------------------
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-0.7209793] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 30           |
|    time_elapsed          | 489          |
|    total_timesteps       | 61440        |
| train/                   |              |
|    approx_kl             | 0.007283469  |
|    clip_fraction         | 0.0556       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.105        |
|    entropy_loss          | -2.84        |
|    explained_variance    | 0.00539      |
|    lagrangian_multiplier | 0.0556       |
|    learning_rate         | 0.0003       |
|    loss                  | 27.1         |
|    n_updates             | 290          |
|    policy_gradient_loss  | -0.007       |
|    std                   | 1            |
|    value_loss            | 237          |
-------------------------------------------
------------------------------------------
| reward                   | [-1.06832]  |
| time/                    |             |
|    fps                   | 125         |
|    iterations            | 30          |
|    time_elapsed          | 488         |
|    total_timesteps       | 61440       |
| train/                   |             |
|    approx_kl             | 0.007520586 |
|    clip_fraction         | 0.0648      |
|    clip_range            | 0.2         |
|    cost_value_loss       | 266         |
|    entropy_loss          | -2.65       |
|    explained_variance    | -0.0395     |
|    lagrangian_multiplier | 0.0542      |
|    learning_rate         | 0.0003      |
|    loss                  | 75.8        |
|    n_updates             | 290         |
|    policy_gradient_loss  | -0.00841    |
|    std                   | 0.906       |
|    value_loss            | 389         |
------------------------------------------
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-0.9433281] |
| time/                    |              |
|    fps                   | 111          |
|    iterations            | 27           |
|    time_elapsed          | 494          |
|    total_timesteps       | 55296        |
| train/                   |              |
|    approx_kl             | 0.00537196   |
|    clip_fraction         | 0.0537       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0154       |
|    entropy_loss          | -2.71        |
|    explained_variance    | -0.00465     |
|    lagrangian_multiplier | 0.0833       |
|    learning_rate         | 0.0003       |
|    loss                  | 37.7         |
|    n_updates             | 260          |
|    policy_gradient_loss  | -0.00812     |
|    std                   | 0.937        |
|    value_loss            | 460          |
-------------------------------------------
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
--------------------------------------------
| reward                   | [-0.37111494] |
| time/                    |               |
|    fps                   | 126           |
|    iterations            | 31            |
|    time_elapsed          | 500           |
|    total_timesteps       | 63488         |
| train/                   |               |
|    approx_kl             | 0.007586462   |
|    clip_fraction         | 0.0668        |
|    clip_range            | 0.2           |
|    cost_value_loss       | 6.15          |
|    entropy_loss          | -2.68         |
|    explained_variance    | 0.0276        |
|    lagrangian_multiplier | 0.0604        |
|    learning_rate         | 0.0003        |
|    loss                  | 65.9          |
|    n_updates             | 300           |
|    policy_gradient_loss  | -0.0102       |
|    std                   | 0.93          |
|    value_loss            | 661           |
--------------------------------------------
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-0.6814623] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 31           |
|    time_elapsed          | 505          |
|    total_timesteps       | 63488        |
| train/                   |              |
|    approx_kl             | 0.0039585596 |
|    clip_fraction         | 0.0371       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.035        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.0277       |
|    lagrangian_multiplier | 0.0572       |
|    learning_rate         | 0.0003       |
|    loss                  | 22.9         |
|    n_updates             | 300          |
|    policy_gradient_loss  | -0.00412     |
|    std                   | 1.02         |
|    value_loss            | 217          |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.8665656] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 31           |
|    time_elapsed          | 504          |
|    total_timesteps       | 63488        |
| train/                   |              |
|    approx_kl             | 0.00720461   |
|    clip_fraction         | 0.0614       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 197          |
|    entropy_loss          | -2.66        |
|    explained_variance    | -0.094       |
|    lagrangian_multiplier | 0.0632       |
|    learning_rate         | 0.0003       |
|    loss                  | 53.1         |
|    n_updates             | 300          |
|    policy_gradient_loss  | -0.00822     |
|    std                   | 0.92         |
|    value_loss            | 346          |
-------------------------------------------
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.0887339] |
| time/                    |              |
|    fps                   | 111          |
|    iterations            | 28           |
|    time_elapsed          | 513          |
|    total_timesteps       | 57344        |
| train/                   |              |
|    approx_kl             | 0.006647261  |
|    clip_fraction         | 0.065        |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0362       |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.0123       |
|    lagrangian_multiplier | 0.0765       |
|    learning_rate         | 0.0003       |
|    loss                  | 41.5         |
|    n_updates             | 270          |
|    policy_gradient_loss  | -0.00756     |
|    std                   | 0.938        |
|    value_loss            | 452          |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.54790485] |
| time/                    |               |
|    fps                   | 126           |
|    iterations            | 32            |
|    time_elapsed          | 516           |
|    total_timesteps       | 65536         |
| train/                   |               |
|    approx_kl             | 0.005341435   |
|    clip_fraction         | 0.0542        |
|    clip_range            | 0.2           |
|    cost_value_loss       | 4.45          |
|    entropy_loss          | -2.69         |
|    explained_variance    | 0.0665        |
|    lagrangian_multiplier | 0.0551        |
|    learning_rate         | 0.0003        |
|    loss                  | 49.5          |
|    n_updates             | 310           |
|    policy_gradient_loss  | -0.00677      |
|    std                   | 0.943         |
|    value_loss            | 525           |
--------------------------------------------
------------------------------------------
| reward                   | [-0.95935]  |
| time/                    |             |
|    fps                   | 125         |
|    iterations            | 32          |
|    time_elapsed          | 521         |
|    total_timesteps       | 65536       |
| train/                   |             |
|    approx_kl             | 0.005330055 |
|    clip_fraction         | 0.0371      |
|    clip_range            | 0.2         |
|    cost_value_loss       | 0.074       |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.0304      |
|    lagrangian_multiplier | 0.0602      |
|    learning_rate         | 0.0003      |
|    loss                  | 23          |
|    n_updates             | 310         |
|    policy_gradient_loss  | -0.00409    |
|    std                   | 1.01        |
|    value_loss            | 271         |
------------------------------------------
-------------------------------------------
| reward                   | [-1.1976442] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 32           |
|    time_elapsed          | 520          |
|    total_timesteps       | 65536        |
| train/                   |              |
|    approx_kl             | 0.0068983203 |
|    clip_fraction         | 0.0814       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 156          |
|    entropy_loss          | -2.66        |
|    explained_variance    | -0.0386      |
|    lagrangian_multiplier | 0.0508       |
|    learning_rate         | 0.0003       |
|    loss                  | 64           |
|    n_updates             | 310          |
|    policy_gradient_loss  | -0.00726     |
|    std                   | 0.914        |
|    value_loss            | 428          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.0364724] |
| time/                    |              |
|    fps                   | 111          |
|    iterations            | 29           |
|    time_elapsed          | 531          |
|    total_timesteps       | 59392        |
| train/                   |              |
|    approx_kl             | 0.0072449227 |
|    clip_fraction         | 0.0965       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0355       |
|    entropy_loss          | -2.72        |
|    explained_variance    | -0.0221      |
|    lagrangian_multiplier | 0.0849       |
|    learning_rate         | 0.0003       |
|    loss                  | 31.5         |
|    n_updates             | 280          |
|    policy_gradient_loss  | -0.00833     |
|    std                   | 0.948        |
|    value_loss            | 406          |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.43501762] |
| time/                    |               |
|    fps                   | 126           |
|    iterations            | 33            |
|    time_elapsed          | 532           |
|    total_timesteps       | 67584         |
| train/                   |               |
|    approx_kl             | 0.0074085305  |
|    clip_fraction         | 0.0736        |
|    clip_range            | 0.2           |
|    cost_value_loss       | 1.42          |
|    entropy_loss          | -2.7          |
|    explained_variance    | 0.0946        |
|    lagrangian_multiplier | 0.0797        |
|    learning_rate         | 0.0003        |
|    loss                  | 24.2          |
|    n_updates             | 320           |
|    policy_gradient_loss  | -0.00955      |
|    std                   | 0.936         |
|    value_loss            | 290           |
--------------------------------------------
-------------------------------------------
| reward                   | [-1.1005728] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 33           |
|    time_elapsed          | 537          |
|    total_timesteps       | 67584        |
| train/                   |              |
|    approx_kl             | 0.007531416  |
|    clip_fraction         | 0.0638       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0606       |
|    entropy_loss          | -2.87        |
|    explained_variance    | 0.0237       |
|    lagrangian_multiplier | 0.0619       |
|    learning_rate         | 0.0003       |
|    loss                  | 45.8         |
|    n_updates             | 320          |
|    policy_gradient_loss  | -0.00482     |
|    std                   | 1.02         |
|    value_loss            | 420          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.2188622] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 33           |
|    time_elapsed          | 536          |
|    total_timesteps       | 67584        |
| train/                   |              |
|    approx_kl             | 0.009007424  |
|    clip_fraction         | 0.0826       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 267          |
|    entropy_loss          | -2.65        |
|    explained_variance    | -0.032       |
|    lagrangian_multiplier | 0.0558       |
|    learning_rate         | 0.0003       |
|    loss                  | 69.7         |
|    n_updates             | 320          |
|    policy_gradient_loss  | -0.00941     |
|    std                   | 0.904        |
|    value_loss            | 382          |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.7902435] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 34           |
|    time_elapsed          | 548          |
|    total_timesteps       | 69632        |
| train/                   |              |
|    approx_kl             | 0.0064990874 |
|    clip_fraction         | 0.0694       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 8.44         |
|    entropy_loss          | -2.71        |
|    explained_variance    | 0.0399       |
|    lagrangian_multiplier | 0.07         |
|    learning_rate         | 0.0003       |
|    loss                  | 43.3         |
|    n_updates             | 330          |
|    policy_gradient_loss  | -0.00936     |
|    std                   | 0.952        |
|    value_loss            | 499          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.4781247] |
| time/                    |              |
|    fps                   | 111          |
|    iterations            | 30           |
|    time_elapsed          | 550          |
|    total_timesteps       | 61440        |
| train/                   |              |
|    approx_kl             | 0.009132414  |
|    clip_fraction         | 0.0875       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0356       |
|    entropy_loss          | -2.75        |
|    explained_variance    | -0.0193      |
|    lagrangian_multiplier | 0.0822       |
|    learning_rate         | 0.0003       |
|    loss                  | 24.1         |
|    n_updates             | 290          |
|    policy_gradient_loss  | -0.0116      |
|    std                   | 0.96         |
|    value_loss            | 298          |
-------------------------------------------
------------------------------------------
| reward                   | [-1.845677] |
| time/                    |             |
|    fps                   | 125         |
|    iterations            | 34          |
|    time_elapsed          | 553         |
|    total_timesteps       | 69632       |
| train/                   |             |
|    approx_kl             | 0.003324946 |
|    clip_fraction         | 0.0234      |
|    clip_range            | 0.2         |
|    cost_value_loss       | 0.0283      |
|    entropy_loss          | -2.86       |
|    explained_variance    | 0.000926    |
|    lagrangian_multiplier | 0.0806      |
|    learning_rate         | 0.0003      |
|    loss                  | 23.2        |
|    n_updates             | 330         |
|    policy_gradient_loss  | -0.00386    |
|    std                   | 1.01        |
|    value_loss            | 278         |
------------------------------------------
-------------------------------------------
| reward                   | [-1.5190394] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 34           |
|    time_elapsed          | 552          |
|    total_timesteps       | 69632        |
| train/                   |              |
|    approx_kl             | 0.0067406115 |
|    clip_fraction         | 0.0675       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 169          |
|    entropy_loss          | -2.64        |
|    explained_variance    | -0.00955     |
|    lagrangian_multiplier | 0.0497       |
|    learning_rate         | 0.0003       |
|    loss                  | 61.5         |
|    n_updates             | 330          |
|    policy_gradient_loss  | -0.00861     |
|    std                   | 0.905        |
|    value_loss            | 307          |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.88344157] |
| time/                    |               |
|    fps                   | 126           |
|    iterations            | 35            |
|    time_elapsed          | 564           |
|    total_timesteps       | 71680         |
| train/                   |               |
|    approx_kl             | 0.008681398   |
|    clip_fraction         | 0.0673        |
|    clip_range            | 0.2           |
|    cost_value_loss       | 6.4           |
|    entropy_loss          | -2.71         |
|    explained_variance    | 0.046         |
|    lagrangian_multiplier | 0.0654        |
|    learning_rate         | 0.0003        |
|    loss                  | 61            |
|    n_updates             | 340           |
|    policy_gradient_loss  | -0.00881      |
|    std                   | 0.935         |
|    value_loss            | 635           |
--------------------------------------------
--------------------------------------------
| reward                   | [-0.96494603] |
| time/                    |               |
|    fps                   | 111           |
|    iterations            | 31            |
|    time_elapsed          | 568           |
|    total_timesteps       | 63488         |
| train/                   |               |
|    approx_kl             | 0.0054060263  |
|    clip_fraction         | 0.0647        |
|    clip_range            | 0.2           |
|    cost_value_loss       | 0.0204        |
|    entropy_loss          | -2.76         |
|    explained_variance    | -0.0381       |
|    lagrangian_multiplier | 0.0897        |
|    learning_rate         | 0.0003        |
|    loss                  | 39.3          |
|    n_updates             | 300           |
|    policy_gradient_loss  | -0.00821      |
|    std                   | 0.958         |
|    value_loss            | 486           |
--------------------------------------------
-------------------------------------------
| reward                   | [-0.8207719] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 35           |
|    time_elapsed          | 568          |
|    total_timesteps       | 71680        |
| train/                   |              |
|    approx_kl             | 0.0086358    |
|    clip_fraction         | 0.0707       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 221          |
|    entropy_loss          | -2.63        |
|    explained_variance    | -0.0215      |
|    lagrangian_multiplier | 0.0469       |
|    learning_rate         | 0.0003       |
|    loss                  | 69           |
|    n_updates             | 340          |
|    policy_gradient_loss  | -0.0085      |
|    std                   | 0.901        |
|    value_loss            | 327          |
-------------------------------------------
-------------------------------------------
| reward                   | [-2.4838457] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 35           |
|    time_elapsed          | 571          |
|    total_timesteps       | 71680        |
| train/                   |              |
|    approx_kl             | 0.0036614197 |
|    clip_fraction         | 0.0353       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0977       |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.00604      |
|    lagrangian_multiplier | 0.0727       |
|    learning_rate         | 0.0003       |
|    loss                  | 31.1         |
|    n_updates             | 340          |
|    policy_gradient_loss  | -0.0056      |
|    std                   | 1.01         |
|    value_loss            | 365          |
-------------------------------------------
------------------------------------------
| reward                   | [-1.054155] |
| time/                    |             |
|    fps                   | 126         |
|    iterations            | 36          |
|    time_elapsed          | 581         |
|    total_timesteps       | 73728       |
| train/                   |             |
|    approx_kl             | 0.008732943 |
|    clip_fraction         | 0.108       |
|    clip_range            | 0.2         |
|    cost_value_loss       | 4.45        |
|    entropy_loss          | -2.68       |
|    explained_variance    | 0.102       |
|    lagrangian_multiplier | 0.0851      |
|    learning_rate         | 0.0003      |
|    loss                  | 29.3        |
|    n_updates             | 350         |
|    policy_gradient_loss  | -0.014      |
|    std                   | 0.923       |
|    value_loss            | 400         |
------------------------------------------
-------------------------------------------
| reward                   | [-1.4441336] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 36           |
|    time_elapsed          | 584          |
|    total_timesteps       | 73728        |
| train/                   |              |
|    approx_kl             | 0.0062356815 |
|    clip_fraction         | 0.05         |
|    clip_range            | 0.2          |
|    cost_value_loss       | 123          |
|    entropy_loss          | -2.64        |
|    explained_variance    | 0.021        |
|    lagrangian_multiplier | 0.0521       |
|    learning_rate         | 0.0003       |
|    loss                  | 60           |
|    n_updates             | 350          |
|    policy_gradient_loss  | -0.00887     |
|    std                   | 0.911        |
|    value_loss            | 377          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.4547527] |
| time/                    |              |
|    fps                   | 111          |
|    iterations            | 32           |
|    time_elapsed          | 587          |
|    total_timesteps       | 65536        |
| train/                   |              |
|    approx_kl             | 0.006365762  |
|    clip_fraction         | 0.0553       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.02         |
|    entropy_loss          | -2.75        |
|    explained_variance    | -0.0563      |
|    lagrangian_multiplier | 0.0884       |
|    learning_rate         | 0.0003       |
|    loss                  | 27.9         |
|    n_updates             | 310          |
|    policy_gradient_loss  | -0.00711     |
|    std                   | 0.953        |
|    value_loss            | 361          |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.8179728] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 36           |
|    time_elapsed          | 588          |
|    total_timesteps       | 73728        |
| train/                   |              |
|    approx_kl             | 0.0064622206 |
|    clip_fraction         | 0.0413       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.142        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.0111       |
|    lagrangian_multiplier | 0.099        |
|    learning_rate         | 0.0003       |
|    loss                  | 93.8         |
|    n_updates             | 350          |
|    policy_gradient_loss  | -0.00718     |
|    std                   | 0.993        |
|    value_loss            | 1.4e+03      |
-------------------------------------------
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.2676166] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 37           |
|    time_elapsed          | 597          |
|    total_timesteps       | 75776        |
| train/                   |              |
|    approx_kl             | 0.004953638  |
|    clip_fraction         | 0.0435       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 1.22         |
|    entropy_loss          | -2.67        |
|    explained_variance    | -0.0989      |
|    lagrangian_multiplier | 0.0594       |
|    learning_rate         | 0.0003       |
|    loss                  | 35.2         |
|    n_updates             | 360          |
|    policy_gradient_loss  | -0.0063      |
|    std                   | 0.926        |
|    value_loss            | 351          |
-------------------------------------------
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.6970232] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 37           |
|    time_elapsed          | 601          |
|    total_timesteps       | 75776        |
| train/                   |              |
|    approx_kl             | 0.0058982335 |
|    clip_fraction         | 0.061        |
|    clip_range            | 0.2          |
|    cost_value_loss       | 137          |
|    entropy_loss          | -2.67        |
|    explained_variance    | -0.00449     |
|    lagrangian_multiplier | 0.054        |
|    learning_rate         | 0.0003       |
|    loss                  | 52.5         |
|    n_updates             | 360          |
|    policy_gradient_loss  | -0.00779     |
|    std                   | 0.924        |
|    value_loss            | 311          |
-------------------------------------------
-------------------------------------------
| reward                   | [-2.1920466] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 37           |
|    time_elapsed          | 604          |
|    total_timesteps       | 75776        |
| train/                   |              |
|    approx_kl             | 0.0057003973 |
|    clip_fraction         | 0.0502       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.124        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.00299      |
|    lagrangian_multiplier | 0.0775       |
|    learning_rate         | 0.0003       |
|    loss                  | 71.9         |
|    n_updates             | 360          |
|    policy_gradient_loss  | -0.00765     |
|    std                   | 1.01         |
|    value_loss            | 858          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.4242097] |
| time/                    |              |
|    fps                   | 111          |
|    iterations            | 33           |
|    time_elapsed          | 605          |
|    total_timesteps       | 67584        |
| train/                   |              |
|    approx_kl             | 0.007615978  |
|    clip_fraction         | 0.0833       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0224       |
|    entropy_loss          | -2.74        |
|    explained_variance    | -0.0214      |
|    lagrangian_multiplier | 0.0851       |
|    learning_rate         | 0.0003       |
|    loss                  | 21.2         |
|    n_updates             | 320          |
|    policy_gradient_loss  | -0.0105      |
|    std                   | 0.949        |
|    value_loss            | 264          |
-------------------------------------------
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.8528898] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 38           |
|    time_elapsed          | 613          |
|    total_timesteps       | 77824        |
| train/                   |              |
|    approx_kl             | 0.0066341683 |
|    clip_fraction         | 0.053        |
|    clip_range            | 0.2          |
|    cost_value_loss       | 1.87         |
|    entropy_loss          | -2.64        |
|    explained_variance    | -0.0252      |
|    lagrangian_multiplier | 0.0782       |
|    learning_rate         | 0.0003       |
|    loss                  | 24.1         |
|    n_updates             | 370          |
|    policy_gradient_loss  | -0.00923     |
|    std                   | 0.902        |
|    value_loss            | 315          |
-------------------------------------------
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.8464777] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 38           |
|    time_elapsed          | 617          |
|    total_timesteps       | 77824        |
| train/                   |              |
|    approx_kl             | 0.009779115  |
|    clip_fraction         | 0.123        |
|    clip_range            | 0.2          |
|    cost_value_loss       | 268          |
|    entropy_loss          | -2.68        |
|    explained_variance    | 0.00408      |
|    lagrangian_multiplier | 0.0486       |
|    learning_rate         | 0.0003       |
|    loss                  | 76.2         |
|    n_updates             | 370          |
|    policy_gradient_loss  | -0.0128      |
|    std                   | 0.923        |
|    value_loss            | 362          |
-------------------------------------------
------------------------------------------
| reward                   | [-3.720284] |
| time/                    |             |
|    fps                   | 125         |
|    iterations            | 38          |
|    time_elapsed          | 621         |
|    total_timesteps       | 77824       |
| train/                   |             |
|    approx_kl             | 0.008975544 |
|    clip_fraction         | 0.0719      |
|    clip_range            | 0.2         |
|    cost_value_loss       | 0.137       |
|    entropy_loss          | -2.85       |
|    explained_variance    | -0.000328   |
|    lagrangian_multiplier | 0.0602      |
|    learning_rate         | 0.0003      |
|    loss                  | 93.2        |
|    n_updates             | 370         |
|    policy_gradient_loss  | -0.00934    |
|    std                   | 1.02        |
|    value_loss            | 1.16e+03    |
------------------------------------------
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.5986376] |
| time/                    |              |
|    fps                   | 111          |
|    iterations            | 34           |
|    time_elapsed          | 624          |
|    total_timesteps       | 69632        |
| train/                   |              |
|    approx_kl             | 0.007903293  |
|    clip_fraction         | 0.0737       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0324       |
|    entropy_loss          | -2.73        |
|    explained_variance    | -0.007       |
|    lagrangian_multiplier | 0.0772       |
|    learning_rate         | 0.0003       |
|    loss                  | 26.2         |
|    n_updates             | 330          |
|    policy_gradient_loss  | -0.00935     |
|    std                   | 0.946        |
|    value_loss            | 302          |
-------------------------------------------
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.7207878] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 39           |
|    time_elapsed          | 629          |
|    total_timesteps       | 79872        |
| train/                   |              |
|    approx_kl             | 0.0076819966 |
|    clip_fraction         | 0.0866       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 12.6         |
|    entropy_loss          | -2.6         |
|    explained_variance    | -0.0401      |
|    lagrangian_multiplier | 0.0775       |
|    learning_rate         | 0.0003       |
|    loss                  | 38.4         |
|    n_updates             | 380          |
|    policy_gradient_loss  | -0.0108      |
|    std                   | 0.892        |
|    value_loss            | 422          |
-------------------------------------------
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.1102971] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 39           |
|    time_elapsed          | 633          |
|    total_timesteps       | 79872        |
| train/                   |              |
|    approx_kl             | 0.008205013  |
|    clip_fraction         | 0.0985       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 253          |
|    entropy_loss          | -2.68        |
|    explained_variance    | -0.0066      |
|    lagrangian_multiplier | 0.0544       |
|    learning_rate         | 0.0003       |
|    loss                  | 78.3         |
|    n_updates             | 380          |
|    policy_gradient_loss  | -0.0117      |
|    std                   | 0.925        |
|    value_loss            | 441          |
-------------------------------------------
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-2.078842]  |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 39           |
|    time_elapsed          | 637          |
|    total_timesteps       | 79872        |
| train/                   |              |
|    approx_kl             | 0.0058567137 |
|    clip_fraction         | 0.0575       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.208        |
|    entropy_loss          | -2.86        |
|    explained_variance    | 4.08e-05     |
|    lagrangian_multiplier | 0.0612       |
|    learning_rate         | 0.0003       |
|    loss                  | 103          |
|    n_updates             | 380          |
|    policy_gradient_loss  | -0.00887     |
|    std                   | 1.02         |
|    value_loss            | 1.18e+03     |
-------------------------------------------
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| reward                   | [-1.28108]  |
| time/                    |             |
|    fps                   | 111         |
|    iterations            | 35          |
|    time_elapsed          | 642         |
|    total_timesteps       | 71680       |
| train/                   |             |
|    approx_kl             | 0.006477077 |
|    clip_fraction         | 0.0729      |
|    clip_range            | 0.2         |
|    cost_value_loss       | 0.0225      |
|    entropy_loss          | -2.73       |
|    explained_variance    | -0.0672     |
|    lagrangian_multiplier | 0.0856      |
|    learning_rate         | 0.0003      |
|    loss                  | 18.5        |
|    n_updates             | 340         |
|    policy_gradient_loss  | -0.0087     |
|    std                   | 0.953       |
|    value_loss            | 269         |
------------------------------------------
-------------------------------------------
| reward                   | [-2.1222608] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 40           |
|    time_elapsed          | 646          |
|    total_timesteps       | 81920        |
| train/                   |              |
|    approx_kl             | 0.00762349   |
|    clip_fraction         | 0.0782       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 133          |
|    entropy_loss          | -2.59        |
|    explained_variance    | 0.0492       |
|    lagrangian_multiplier | 0.0789       |
|    learning_rate         | 0.0003       |
|    loss                  | 158          |
|    n_updates             | 390          |
|    policy_gradient_loss  | -0.0125      |
|    std                   | 0.89         |
|    value_loss            | 1.78e+03     |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.6479045] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 40           |
|    time_elapsed          | 649          |
|    total_timesteps       | 81920        |
| train/                   |              |
|    approx_kl             | 0.009440448  |
|    clip_fraction         | 0.0853       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 222          |
|    entropy_loss          | -2.67        |
|    explained_variance    | -0.026       |
|    lagrangian_multiplier | 0.0534       |
|    learning_rate         | 0.0003       |
|    loss                  | 66.8         |
|    n_updates             | 390          |
|    policy_gradient_loss  | -0.00794     |
|    std                   | 0.92         |
|    value_loss            | 390          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.7680198] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 40           |
|    time_elapsed          | 653          |
|    total_timesteps       | 81920        |
| train/                   |              |
|    approx_kl             | 0.004348647  |
|    clip_fraction         | 0.035        |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.134        |
|    entropy_loss          | -2.85        |
|    explained_variance    | 0.00879      |
|    lagrangian_multiplier | 0.0915       |
|    learning_rate         | 0.0003       |
|    loss                  | 66.1         |
|    n_updates             | 390          |
|    policy_gradient_loss  | -0.00492     |
|    std                   | 1.01         |
|    value_loss            | 949          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.0677954] |
| time/                    |              |
|    fps                   | 111          |
|    iterations            | 36           |
|    time_elapsed          | 661          |
|    total_timesteps       | 73728        |
| train/                   |              |
|    approx_kl             | 0.0061923126 |
|    clip_fraction         | 0.0596       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0503       |
|    entropy_loss          | -2.75        |
|    explained_variance    | 0.00646      |
|    lagrangian_multiplier | 0.0785       |
|    learning_rate         | 0.0003       |
|    loss                  | 30.7         |
|    n_updates             | 350          |
|    policy_gradient_loss  | -0.00853     |
|    std                   | 0.96         |
|    value_loss            | 342          |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.9807664] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 41           |
|    time_elapsed          | 662          |
|    total_timesteps       | 83968        |
| train/                   |              |
|    approx_kl             | 0.009253822  |
|    clip_fraction         | 0.0934       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 38.7         |
|    entropy_loss          | -2.58        |
|    explained_variance    | -0.0253      |
|    lagrangian_multiplier | 0.0789       |
|    learning_rate         | 0.0003       |
|    loss                  | 81.7         |
|    n_updates             | 400          |
|    policy_gradient_loss  | -0.012       |
|    std                   | 0.883        |
|    value_loss            | 868          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.1425012] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 41           |
|    time_elapsed          | 665          |
|    total_timesteps       | 83968        |
| train/                   |              |
|    approx_kl             | 0.008292975  |
|    clip_fraction         | 0.0947       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 228          |
|    entropy_loss          | -2.66        |
|    explained_variance    | -0.0657      |
|    lagrangian_multiplier | 0.0496       |
|    learning_rate         | 0.0003       |
|    loss                  | 62.1         |
|    n_updates             | 400          |
|    policy_gradient_loss  | -0.0086      |
|    std                   | 0.916        |
|    value_loss            | 307          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.360085]  |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 41           |
|    time_elapsed          | 669          |
|    total_timesteps       | 83968        |
| train/                   |              |
|    approx_kl             | 0.0052954513 |
|    clip_fraction         | 0.0431       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0338       |
|    entropy_loss          | -2.83        |
|    explained_variance    | -0.00579     |
|    lagrangian_multiplier | 0.0676       |
|    learning_rate         | 0.0003       |
|    loss                  | 48.4         |
|    n_updates             | 400          |
|    policy_gradient_loss  | -0.00612     |
|    std                   | 1            |
|    value_loss            | 485          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.7230469] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 42           |
|    time_elapsed          | 678          |
|    total_timesteps       | 86016        |
| train/                   |              |
|    approx_kl             | 0.00579027   |
|    clip_fraction         | 0.0601       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 7.41         |
|    entropy_loss          | -2.56        |
|    explained_variance    | -0.0354      |
|    lagrangian_multiplier | 0.0786       |
|    learning_rate         | 0.0003       |
|    loss                  | 36.8         |
|    n_updates             | 410          |
|    policy_gradient_loss  | -0.00625     |
|    std                   | 0.876        |
|    value_loss            | 435          |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.84973294] |
| time/                    |               |
|    fps                   | 111           |
|    iterations            | 37            |
|    time_elapsed          | 679           |
|    total_timesteps       | 75776         |
| train/                   |               |
|    approx_kl             | 0.009607114   |
|    clip_fraction         | 0.0937        |
|    clip_range            | 0.2           |
|    cost_value_loss       | 0.0449        |
|    entropy_loss          | -2.76         |
|    explained_variance    | -0.00785      |
|    lagrangian_multiplier | 0.0816        |
|    learning_rate         | 0.0003        |
|    loss                  | 23.1          |
|    n_updates             | 360           |
|    policy_gradient_loss  | -0.00954      |
|    std                   | 0.962         |
|    value_loss            | 302           |
--------------------------------------------
-------------------------------------------
| reward                   | [-1.9550464] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 42           |
|    time_elapsed          | 681          |
|    total_timesteps       | 86016        |
| train/                   |              |
|    approx_kl             | 0.00901423   |
|    clip_fraction         | 0.104        |
|    clip_range            | 0.2          |
|    cost_value_loss       | 269          |
|    entropy_loss          | -2.65        |
|    explained_variance    | -0.046       |
|    lagrangian_multiplier | 0.0468       |
|    learning_rate         | 0.0003       |
|    loss                  | 74.7         |
|    n_updates             | 410          |
|    policy_gradient_loss  | -0.0069      |
|    std                   | 0.904        |
|    value_loss            | 318          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.2681324] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 42           |
|    time_elapsed          | 685          |
|    total_timesteps       | 86016        |
| train/                   |              |
|    approx_kl             | 0.005341625  |
|    clip_fraction         | 0.0527       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0868       |
|    entropy_loss          | -2.82        |
|    explained_variance    | -0.00297     |
|    lagrangian_multiplier | 0.0628       |
|    learning_rate         | 0.0003       |
|    loss                  | 113          |
|    n_updates             | 410          |
|    policy_gradient_loss  | -0.00654     |
|    std                   | 1            |
|    value_loss            | 1.27e+03     |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.1843659] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 43           |
|    time_elapsed          | 694          |
|    total_timesteps       | 88064        |
| train/                   |              |
|    approx_kl             | 0.0065644532 |
|    clip_fraction         | 0.0672       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 1            |
|    entropy_loss          | -2.54        |
|    explained_variance    | -0.0957      |
|    lagrangian_multiplier | 0.0656       |
|    learning_rate         | 0.0003       |
|    loss                  | 42.1         |
|    n_updates             | 420          |
|    policy_gradient_loss  | -0.00817     |
|    std                   | 0.858        |
|    value_loss            | 468          |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.9579045] |
| time/                    |              |
|    fps                   | 111          |
|    iterations            | 38           |
|    time_elapsed          | 697          |
|    total_timesteps       | 77824        |
| train/                   |              |
|    approx_kl             | 0.009362267  |
|    clip_fraction         | 0.088        |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0281       |
|    entropy_loss          | -2.75        |
|    explained_variance    | -0.019       |
|    lagrangian_multiplier | 0.0807       |
|    learning_rate         | 0.0003       |
|    loss                  | 17           |
|    n_updates             | 370          |
|    policy_gradient_loss  | -0.0111      |
|    std                   | 0.955        |
|    value_loss            | 205          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.1470113] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 43           |
|    time_elapsed          | 697          |
|    total_timesteps       | 88064        |
| train/                   |              |
|    approx_kl             | 0.0052703233 |
|    clip_fraction         | 0.0598       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 90.4         |
|    entropy_loss          | -2.64        |
|    explained_variance    | -0.0432      |
|    lagrangian_multiplier | 0.0613       |
|    learning_rate         | 0.0003       |
|    loss                  | 41.3         |
|    n_updates             | 420          |
|    policy_gradient_loss  | -0.00696     |
|    std                   | 0.909        |
|    value_loss            | 328          |
-------------------------------------------
-------------------------------------------
| reward                   | [-2.5289025] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 43           |
|    time_elapsed          | 702          |
|    total_timesteps       | 88064        |
| train/                   |              |
|    approx_kl             | 0.008113518  |
|    clip_fraction         | 0.0772       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.126        |
|    entropy_loss          | -2.83        |
|    explained_variance    | 0.00499      |
|    lagrangian_multiplier | 0.0599       |
|    learning_rate         | 0.0003       |
|    loss                  | 91.1         |
|    n_updates             | 420          |
|    policy_gradient_loss  | -0.011       |
|    std                   | 1.01         |
|    value_loss            | 914          |
-------------------------------------------
-------------------------------------------
| reward                   | [-3.390088]  |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 44           |
|    time_elapsed          | 710          |
|    total_timesteps       | 90112        |
| train/                   |              |
|    approx_kl             | 0.0076173902 |
|    clip_fraction         | 0.0834       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 22.3         |
|    entropy_loss          | -2.5         |
|    explained_variance    | 0.00169      |
|    lagrangian_multiplier | 0.0656       |
|    learning_rate         | 0.0003       |
|    loss                  | 39           |
|    n_updates             | 430          |
|    policy_gradient_loss  | -0.0104      |
|    std                   | 0.844        |
|    value_loss            | 417          |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.6283492] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 44           |
|    time_elapsed          | 713          |
|    total_timesteps       | 90112        |
| train/                   |              |
|    approx_kl             | 0.012069348  |
|    clip_fraction         | 0.137        |
|    clip_range            | 0.2          |
|    cost_value_loss       | 262          |
|    entropy_loss          | -2.63        |
|    explained_variance    | 0.0037       |
|    lagrangian_multiplier | 0.0491       |
|    learning_rate         | 0.0003       |
|    loss                  | 73.6         |
|    n_updates             | 430          |
|    policy_gradient_loss  | -0.0123      |
|    std                   | 0.898        |
|    value_loss            | 340          |
-------------------------------------------
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.1389632] |
| time/                    |              |
|    fps                   | 111          |
|    iterations            | 39           |
|    time_elapsed          | 716          |
|    total_timesteps       | 79872        |
| train/                   |              |
|    approx_kl             | 0.0072712656 |
|    clip_fraction         | 0.0733       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0528       |
|    entropy_loss          | -2.75        |
|    explained_variance    | -0.0107      |
|    lagrangian_multiplier | 0.0721       |
|    learning_rate         | 0.0003       |
|    loss                  | 18.7         |
|    n_updates             | 380          |
|    policy_gradient_loss  | -0.00721     |
|    std                   | 0.956        |
|    value_loss            | 224          |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.45632502] |
| time/                    |               |
|    fps                   | 125           |
|    iterations            | 44            |
|    time_elapsed          | 718           |
|    total_timesteps       | 90112         |
| train/                   |               |
|    approx_kl             | 0.0072180433  |
|    clip_fraction         | 0.0637        |
|    clip_range            | 0.2           |
|    cost_value_loss       | 0.0797        |
|    entropy_loss          | -2.83         |
|    explained_variance    | -0.0102       |
|    lagrangian_multiplier | 0.0639        |
|    learning_rate         | 0.0003        |
|    loss                  | 35.6          |
|    n_updates             | 430           |
|    policy_gradient_loss  | -0.00841      |
|    std                   | 0.998         |
|    value_loss            | 411           |
--------------------------------------------
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.356126]  |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 45           |
|    time_elapsed          | 726          |
|    total_timesteps       | 92160        |
| train/                   |              |
|    approx_kl             | 0.0068858536 |
|    clip_fraction         | 0.0899       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 39.7         |
|    entropy_loss          | -2.48        |
|    explained_variance    | 0.00922      |
|    lagrangian_multiplier | 0.0628       |
|    learning_rate         | 0.0003       |
|    loss                  | 124          |
|    n_updates             | 440          |
|    policy_gradient_loss  | -0.0106      |
|    std                   | 0.84         |
|    value_loss            | 1.02e+03     |
-------------------------------------------
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
--------------------------------------------
| reward                   | [-0.62574726] |
| time/                    |               |
|    fps                   | 126           |
|    iterations            | 45            |
|    time_elapsed          | 729           |
|    total_timesteps       | 92160         |
| train/                   |               |
|    approx_kl             | 0.007873327   |
|    clip_fraction         | 0.0788        |
|    clip_range            | 0.2           |
|    cost_value_loss       | 106           |
|    entropy_loss          | -2.62         |
|    explained_variance    | 0.0135        |
|    lagrangian_multiplier | 0.0553        |
|    learning_rate         | 0.0003        |
|    loss                  | 65.3          |
|    n_updates             | 440           |
|    policy_gradient_loss  | -0.00957      |
|    std                   | 0.897         |
|    value_loss            | 468           |
--------------------------------------------
-------------------------------------------
| reward                   | [-0.7615768] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 45           |
|    time_elapsed          | 734          |
|    total_timesteps       | 92160        |
| train/                   |              |
|    approx_kl             | 0.0051828194 |
|    clip_fraction         | 0.0442       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0372       |
|    entropy_loss          | -2.82        |
|    explained_variance    | -0.0111      |
|    lagrangian_multiplier | 0.0651       |
|    learning_rate         | 0.0003       |
|    loss                  | 47.9         |
|    n_updates             | 440          |
|    policy_gradient_loss  | -0.00493     |
|    std                   | 0.989        |
|    value_loss            | 487          |
-------------------------------------------
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.1406811] |
| time/                    |              |
|    fps                   | 111          |
|    iterations            | 40           |
|    time_elapsed          | 734          |
|    total_timesteps       | 81920        |
| train/                   |              |
|    approx_kl             | 0.005823753  |
|    clip_fraction         | 0.0542       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0433       |
|    entropy_loss          | -2.74        |
|    explained_variance    | -0.0424      |
|    lagrangian_multiplier | 0.086        |
|    learning_rate         | 0.0003       |
|    loss                  | 21.3         |
|    n_updates             | 390          |
|    policy_gradient_loss  | -0.00748     |
|    std                   | 0.953        |
|    value_loss            | 259          |
-------------------------------------------
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.4649684] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 46           |
|    time_elapsed          | 742          |
|    total_timesteps       | 94208        |
| train/                   |              |
|    approx_kl             | 0.0068323845 |
|    clip_fraction         | 0.0692       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 32.2         |
|    entropy_loss          | -2.48        |
|    explained_variance    | 0.0154       |
|    lagrangian_multiplier | 0.0773       |
|    learning_rate         | 0.0003       |
|    loss                  | 62.9         |
|    n_updates             | 450          |
|    policy_gradient_loss  | -0.00768     |
|    std                   | 0.841        |
|    value_loss            | 905          |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.43940654] |
| time/                    |               |
|    fps                   | 126           |
|    iterations            | 46            |
|    time_elapsed          | 745           |
|    total_timesteps       | 94208         |
| train/                   |               |
|    approx_kl             | 0.0082682045  |
|    clip_fraction         | 0.0896        |
|    clip_range            | 0.2           |
|    cost_value_loss       | 154           |
|    entropy_loss          | -2.61         |
|    explained_variance    | -0.116        |
|    lagrangian_multiplier | 0.0589        |
|    learning_rate         | 0.0003        |
|    loss                  | 47.2          |
|    n_updates             | 450           |
|    policy_gradient_loss  | -0.00845      |
|    std                   | 0.892         |
|    value_loss            | 286           |
--------------------------------------------
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.0691812] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 46           |
|    time_elapsed          | 750          |
|    total_timesteps       | 94208        |
| train/                   |              |
|    approx_kl             | 0.0065277144 |
|    clip_fraction         | 0.0641       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0725       |
|    entropy_loss          | -2.8         |
|    explained_variance    | -0.0112      |
|    lagrangian_multiplier | 0.0656       |
|    learning_rate         | 0.0003       |
|    loss                  | 42.8         |
|    n_updates             | 450          |
|    policy_gradient_loss  | -0.00657     |
|    std                   | 0.98         |
|    value_loss            | 405          |
-------------------------------------------
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
--------------------------------------------
| reward                   | [-0.50739825] |
| time/                    |               |
|    fps                   | 111           |
|    iterations            | 41            |
|    time_elapsed          | 753           |
|    total_timesteps       | 83968         |
| train/                   |               |
|    approx_kl             | 0.0076743145  |
|    clip_fraction         | 0.0861        |
|    clip_range            | 0.2           |
|    cost_value_loss       | 0.0422        |
|    entropy_loss          | -2.74         |
|    explained_variance    | 0.0129        |
|    lagrangian_multiplier | 0.0821        |
|    learning_rate         | 0.0003        |
|    loss                  | 20.5          |
|    n_updates             | 400           |
|    policy_gradient_loss  | -0.00981      |
|    std                   | 0.95          |
|    value_loss            | 255           |
--------------------------------------------
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.3624682] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 47           |
|    time_elapsed          | 758          |
|    total_timesteps       | 96256        |
| train/                   |              |
|    approx_kl             | 0.00566897   |
|    clip_fraction         | 0.0519       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 1.44         |
|    entropy_loss          | -2.47        |
|    explained_variance    | -0.0527      |
|    lagrangian_multiplier | 0.0589       |
|    learning_rate         | 0.0003       |
|    loss                  | 44.6         |
|    n_updates             | 460          |
|    policy_gradient_loss  | -0.00695     |
|    std                   | 0.828        |
|    value_loss            | 417          |
-------------------------------------------
--------------------------------------------
| reward                   | [-0.40048325] |
| time/                    |               |
|    fps                   | 126           |
|    iterations            | 47            |
|    time_elapsed          | 761           |
|    total_timesteps       | 96256         |
| train/                   |               |
|    approx_kl             | 0.006587542   |
|    clip_fraction         | 0.0635        |
|    clip_range            | 0.2           |
|    cost_value_loss       | 211           |
|    entropy_loss          | -2.61         |
|    explained_variance    | -0.0799       |
|    lagrangian_multiplier | 0.0521        |
|    learning_rate         | 0.0003        |
|    loss                  | 59.1          |
|    n_updates             | 460           |
|    policy_gradient_loss  | -0.00709      |
|    std                   | 0.894         |
|    value_loss            | 290           |
--------------------------------------------
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-1.0102507] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 47           |
|    time_elapsed          | 766          |
|    total_timesteps       | 96256        |
| train/                   |              |
|    approx_kl             | 0.008047651  |
|    clip_fraction         | 0.0811       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.141        |
|    entropy_loss          | -2.8         |
|    explained_variance    | 0.016        |
|    lagrangian_multiplier | 0.0507       |
|    learning_rate         | 0.0003       |
|    loss                  | 49.4         |
|    n_updates             | 460          |
|    policy_gradient_loss  | -0.00916     |
|    std                   | 0.992        |
|    value_loss            | 366          |
-------------------------------------------
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
------------------------------------------
| reward                   | [-0.774947] |
| time/                    |             |
|    fps                   | 111         |
|    iterations            | 42          |
|    time_elapsed          | 772         |
|    total_timesteps       | 86016       |
| train/                   |             |
|    approx_kl             | 0.011615949 |
|    clip_fraction         | 0.0902      |
|    clip_range            | 0.2         |
|    cost_value_loss       | 0.0493      |
|    entropy_loss          | -2.73       |
|    explained_variance    | 0.00586     |
|    lagrangian_multiplier | 0.0699      |
|    learning_rate         | 0.0003      |
|    loss                  | 14          |
|    n_updates             | 410         |
|    policy_gradient_loss  | -0.00887    |
|    std                   | 0.948       |
|    value_loss            | 164         |
------------------------------------------
-------------------------------------------
| reward                   | [-1.4829153] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 48           |
|    time_elapsed          | 774          |
|    total_timesteps       | 98304        |
| train/                   |              |
|    approx_kl             | 0.008200569  |
|    clip_fraction         | 0.0707       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.739        |
|    entropy_loss          | -2.44        |
|    explained_variance    | -0.061       |
|    lagrangian_multiplier | 0.0785       |
|    learning_rate         | 0.0003       |
|    loss                  | 26.6         |
|    n_updates             | 470          |
|    policy_gradient_loss  | -0.00855     |
|    std                   | 0.821        |
|    value_loss            | 343          |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.7594929] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 48           |
|    time_elapsed          | 777          |
|    total_timesteps       | 98304        |
| train/                   |              |
|    approx_kl             | 0.008069737  |
|    clip_fraction         | 0.0917       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 198          |
|    entropy_loss          | -2.61        |
|    explained_variance    | -0.0387      |
|    lagrangian_multiplier | 0.0536       |
|    learning_rate         | 0.0003       |
|    loss                  | 53           |
|    n_updates             | 470          |
|    policy_gradient_loss  | -0.011       |
|    std                   | 0.892        |
|    value_loss            | 257          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.2906116] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 48           |
|    time_elapsed          | 782          |
|    total_timesteps       | 98304        |
| train/                   |              |
|    approx_kl             | 0.005376295  |
|    clip_fraction         | 0.0433       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.089        |
|    entropy_loss          | -2.81        |
|    explained_variance    | -0.00959     |
|    lagrangian_multiplier | 0.0618       |
|    learning_rate         | 0.0003       |
|    loss                  | 34.7         |
|    n_updates             | 470          |
|    policy_gradient_loss  | -0.00672     |
|    std                   | 0.984        |
|    value_loss            | 341          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.1617675] |
| time/                    |              |
|    fps                   | 111          |
|    iterations            | 43           |
|    time_elapsed          | 790          |
|    total_timesteps       | 88064        |
| train/                   |              |
|    approx_kl             | 0.008657019  |
|    clip_fraction         | 0.0998       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.034        |
|    entropy_loss          | -2.73        |
|    explained_variance    | -0.00142     |
|    lagrangian_multiplier | 0.0743       |
|    learning_rate         | 0.0003       |
|    loss                  | 19.4         |
|    n_updates             | 420          |
|    policy_gradient_loss  | -0.0107      |
|    std                   | 0.945        |
|    value_loss            | 209          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.3333948] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 49           |
|    time_elapsed          | 791          |
|    total_timesteps       | 100352       |
| train/                   |              |
|    approx_kl             | 0.008089777  |
|    clip_fraction         | 0.0905       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 1.79         |
|    entropy_loss          | -2.42        |
|    explained_variance    | -0.0996      |
|    lagrangian_multiplier | 0.0551       |
|    learning_rate         | 0.0003       |
|    loss                  | 47.6         |
|    n_updates             | 480          |
|    policy_gradient_loss  | -0.00972     |
|    std                   | 0.812        |
|    value_loss            | 448          |
-------------------------------------------
-------------------------------------------
| reward                   | [-0.9967109] |
| time/                    |              |
|    fps                   | 126          |
|    iterations            | 49           |
|    time_elapsed          | 793          |
|    total_timesteps       | 100352       |
| train/                   |              |
|    approx_kl             | 0.008371924  |
|    clip_fraction         | 0.116        |
|    clip_range            | 0.2          |
|    cost_value_loss       | 246          |
|    entropy_loss          | -2.62        |
|    explained_variance    | -0.0517      |
|    lagrangian_multiplier | 0.0448       |
|    learning_rate         | 0.0003       |
|    loss                  | 57.5         |
|    n_updates             | 480          |
|    policy_gradient_loss  | -0.00953     |
|    std                   | 0.905        |
|    value_loss            | 231          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.1208721] |
| time/                    |              |
|    fps                   | 125          |
|    iterations            | 49           |
|    time_elapsed          | 798          |
|    total_timesteps       | 100352       |
| train/                   |              |
|    approx_kl             | 0.006215959  |
|    clip_fraction         | 0.0443       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.0309       |
|    entropy_loss          | -2.81        |
|    explained_variance    | -0.0615      |
|    lagrangian_multiplier | 0.0726       |
|    learning_rate         | 0.0003       |
|    loss                  | 18.1         |
|    n_updates             | 480          |
|    policy_gradient_loss  | -0.00398     |
|    std                   | 0.996        |
|    value_loss            | 217          |
-------------------------------------------
Directory created: PPOL_New/models/New-PPOL-SpeedLimit=8/model_epoch(0)_timesteps(100000)
------------------------------------
| reward             | [-1.337045] |
| time/              |             |
|    fps             | 134         |
|    iterations      | 1           |
|    time_elapsed    | 15          |
|    total_timesteps | 102400      |
------------------------------------
--------------------------------------------
| reward                   | [-0.43577296] |
| time/                    |               |
|    fps                   | 111           |
|    iterations            | 44            |
|    time_elapsed          | 809           |
|    total_timesteps       | 90112         |
| train/                   |               |
|    approx_kl             | 0.009233543   |
|    clip_fraction         | 0.103         |
|    clip_range            | 0.2           |
|    cost_value_loss       | 0.0323        |
|    entropy_loss          | -2.73         |
|    explained_variance    | -0.0527       |
|    lagrangian_multiplier | 0.0752        |
|    learning_rate         | 0.0003        |
|    loss                  | 13.8          |
|    n_updates             | 430           |
|    policy_gradient_loss  | -0.011        |
|    std                   | 0.944         |
|    value_loss            | 162           |
--------------------------------------------
Directory created: PPOL_New/models/New-PPOL-SpeedLimit=2/model_epoch(0)_timesteps(100000)
-------------------------------------
| reward             | [-0.8896571] |
| time/              |              |
|    fps             | 136          |
|    iterations      | 1            |
|    time_elapsed    | 15           |
|    total_timesteps | 102400       |
-------------------------------------
Directory created: PPOL_New/models/New-PPOL-SpeedLimit=16/model_epoch(0)_timesteps(100000)
-------------------------------------
| reward             | [-0.5989772] |
| time/              |              |
|    fps             | 134          |
|    iterations      | 1            |
|    time_elapsed    | 15           |
|    total_timesteps | 102400       |
-------------------------------------
-------------------------------------------
| reward                   | [-1.1576478] |
| time/                    |              |
|    fps                   | 130          |
|    iterations            | 2            |
|    time_elapsed          | 31           |
|    total_timesteps       | 104448       |
| train/                   |              |
|    approx_kl             | 0.0057862825 |
|    clip_fraction         | 0.0432       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 4.4          |
|    entropy_loss          | -2.4         |
|    explained_variance    | -0.0352      |
|    lagrangian_multiplier | 0.0799       |
|    learning_rate         | 0.0003       |
|    loss                  | 36.2         |
|    n_updates             | 500          |
|    policy_gradient_loss  | -0.00637     |
|    std                   | 0.807        |
|    value_loss            | 448          |
-------------------------------------------
-------------------------------------------
| reward                   | [-1.0155379] |
| time/                    |              |
|    fps                   | 129          |
|    iterations            | 2            |
|    time_elapsed          | 31           |
|    total_timesteps       | 104448       |
| train/                   |              |
|    approx_kl             | 0.006924877  |
|    clip_fraction         | 0.0729       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 137          |
|    entropy_loss          | -2.65        |
|    explained_variance    | -0.00528     |
|    lagrangian_multiplier | 0.0485       |
|    learning_rate         | 0.0003       |
|    loss                  | 35.2         |
|    n_updates             | 500          |
|    policy_gradient_loss  | -0.00884     |
|    std                   | 0.916        |
|    value_loss            | 121          |
-------------------------------------------
------------------------------------------
| reward                   | [-0.593026] |
| time/                    |             |
|    fps                   | 111         |
|    iterations            | 45          |
|    time_elapsed          | 827         |
|    total_timesteps       | 92160       |
| train/                   |             |
|    approx_kl             | 0.009138667 |
|    clip_fraction         | 0.108       |
|    clip_range            | 0.2         |
|    cost_value_loss       | 0.0257      |
|    entropy_loss          | -2.72       |
|    explained_variance    | -0.0334     |
|    lagrangian_multiplier | 0.0852      |
|    learning_rate         | 0.0003      |
|    loss                  | 11.2        |
|    n_updates             | 440         |
|    policy_gradient_loss  | -0.0107     |
|    std                   | 0.945       |
|    value_loss            | 137         |
------------------------------------------
-------------------------------------------
| reward                   | [-1.5863683] |
| time/                    |              |
|    fps                   | 122          |
|    iterations            | 2            |
|    time_elapsed          | 33           |
|    total_timesteps       | 104448       |
| train/                   |              |
|    approx_kl             | 0.004705659  |
|    clip_fraction         | 0.0338       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.114        |
|    entropy_loss          | -2.83        |
|    explained_variance    | -0.0427      |
|    lagrangian_multiplier | 0.0604       |
|    learning_rate         | 0.0003       |
|    loss                  | 28.3         |
|    n_updates             | 500          |
|    policy_gradient_loss  | -0.00461     |
|    std                   | 1            |
|    value_loss            | 273          |
-------------------------------------------
srun: Job 114550 step creation still disabled, retrying (Requested nodes are busy)
-------------------------------------------
| reward                   | [-0.9017932] |
| time/                    |              |
|    fps                   | 129          |
|    iterations            | 3            |
|    time_elapsed          | 47           |
|    total_timesteps       | 106496       |
| train/                   |              |
|    approx_kl             | 0.0074617714 |
|    clip_fraction         | 0.0865       |
|    clip_range            | 0.2          |
|    cost_value_loss       | 0.624        |
|    entropy_loss          | -2.39        |
|    explained_variance    | -0.084       |
|    lagrangian_multiplier | 0.0623       |
|    learning_rate         | 0.0003       |
|    loss                  | 30.1         |
|    n_updates             | 510          |
|    policy_gradient_loss  | -0.00842     |
|    std                   | 0.801        |
|    value_loss            | 308          |
-------------------------------------------
slurmstepd: error: *** STEP 114550.3 ON gail.ist.berkeley.edu CANCELLED AT 2023-12-26T23:37:26 ***
slurmstepd: error: *** STEP 114550.2 ON dqn.ist.berkeley.edu CANCELLED AT 2023-12-26T23:37:26 ***
slurmstepd: error: *** STEP 114550.1 ON ddpg.ist.berkeley.edu CANCELLED AT 2023-12-26T23:37:26 ***
slurmstepd: error: *** STEP 114550.0 ON airl.ist.berkeley.edu CANCELLED AT 2023-12-27T07:37:26 ***
slurmstepd: error: *** JOB 114550 ON airl.ist.berkeley.edu CANCELLED AT 2023-12-27T07:37:26 ***
