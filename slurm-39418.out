Traceback (most recent call last):
  File "/nas/ucb/mason/ethically-compliant-rl/CPO/train_cpo_custom_2.py", line 54, in <module>
    class MyCfg(TrainCfg):
  File "/usr/lib/python3.9/dataclasses.py", line 1021, in dataclass
    return wrap(cls)
  File "/usr/lib/python3.9/dataclasses.py", line 1013, in wrap
    return _process_class(cls, init, repr, eq, order, unsafe_hash, frozen)
  File "/usr/lib/python3.9/dataclasses.py", line 863, in _process_class
    cls_fields = [_get_field(cls, name, type)
  File "/usr/lib/python3.9/dataclasses.py", line 863, in <listcomp>
    cls_fields = [_get_field(cls, name, type)
  File "/usr/lib/python3.9/dataclasses.py", line 747, in _get_field
    raise ValueError(f'mutable default {type(f.default)} for field '
ValueError: mutable default <class 'list'> for field cost_limit is not allowed: use default_factory
srun: error: gan.ist.berkeley.edu: task 0: Exited with exit code 1
wandb: Currently logged in as: mason-nakamura1 (ecrl). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.8 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.14.2
wandb: Run data is saved locally in /nas/ucb/mason/ethically-compliant-rl/wandb/run-20230811_110431-71ae5bb4-3998-4c26-a870-d368ae240847
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cpo_lr0.0005_step_per_epoch20000-e4a8
wandb: ‚≠êÔ∏è View project at https://wandb.ai/ecrl/2-constraints-absolute
wandb: üöÄ View run at https://wandb.ai/ecrl/2-constraints-absolute/runs/71ae5bb4-3998-4c26-a870-d368ae240847
[32;1mLogging data to logs/2-constraints-absolute/parking-v0-cost-10/cpo_lr0.0005_step_per_epoch20000-e4a8/progress.txt[0m
[36;1mSaving config:
[0m
{
    "action_bound_method":	"clip",
    "action_scaling":	true,
    "backtrack_coeff":	0.8,
    "batch_size":	99999,
    "buffer_size":	100000,
    "cost_limit":	10,
    "damping_coeff":	0.1,
    "deterministic_eval":	true,
    "device":	"cpu",
    "env_config_file":	"configs/ParkingEnv/env-kinematicsGoalConstraints.txt",
    "episode_per_collect":	20,
    "epoch":	300,
    "gae_lambda":	0.95,
    "gamma":	0.99,
    "group":	null,
    "hidden_sizes":	[
        128,
        128
    ],
    "l2_reg":	0.001,
    "last_layer_scale":	false,
    "logdir":	"logs",
    "lr":	0.0005,
    "max_backtracks":	100,
    "max_batchsize":	99999,
    "name":	"cpo_lr0.0005_step_per_epoch20000-e4a8",
    "norm_adv":	true,
    "optim_critic_iters":	10,
    "prefix":	"cpo",
    "project":	"2-constraints-absolute",
    "render":	null,
    "render_mode":	null,
    "repeat_per_collect":	4,
    "resume":	false,
    "rew_norm":	false,
    "reward_threshold":	10000,
    "save_ckpt":	true,
    "save_interval":	4,
    "seed":	10,
    "step_per_epoch":	20000,
    "suffix":	"",
    "target_kl":	0.01,
    "task":	"parking-v0",
    "testing_num":	2,
    "thread":	320,
    "training_num":	20,
    "unbounded":	false,
    "use_default_cfg":	false,
    "verbose":	true,
    "worker":	"ShmemVectorEnv"
}
Epoch #1:   0%|          | 0/20000 [00:00<?, ?it/s]Epoch #1:  50%|#####     | 10000/20000 [00:21<00:21, 471.25it/s]/nas/ucb/mason/ethically-compliant-rl/FSRL/fsrl/utils/logger/logger_util.py:79: RuntimeWarning: invalid value encountered in scalar add
  self.mean += (x - self.mean) / self.count
/nas/ucb/mason/ethically-compliant-rl/FSRL/fsrl/utils/logger/logger_util.py:79: RuntimeWarning: invalid value encountered in scalar subtract
  self.mean += (x - self.mean) / self.count
/nas/ucb/mason/ethically-compliant-rl/FSRL/fsrl/utils/logger/logger_util.py:80: RuntimeWarning: invalid value encountered in scalar subtract
  self.vars += (x - prev_mean) * (x - self.mean)
Epoch #1:  50%|#####     | 10000/20000 [00:40<00:21, 471.25it/s]Epoch #1:  50%|#####     | 10000/20000 [00:43<00:21, 471.25it/s, cost=840, length=500, rew=-589]Epoch #1: 100%|##########| 20000/20000 [01:04<00:00, 291.06it/s, cost=840, length=500, rew=-589]Epoch #1: 100%|##########| 20000/20000 [01:19<00:00, 291.06it/s, cost=0, length=500, rew=-337]  Epoch #1: 100%|##########| 20000/20000 [01:19<00:00, 252.84it/s, cost=0, length=500, rew=-337]
-------------------------------------------------
|              loss/cost_loss |             420 |
|                loss/entropy |           -14.4 |
|                     loss/kl |        2.68e+09 |
|                loss/optim_A |             nan |
|                loss/optim_B |             nan |
|                loss/optim_C |             nan |
|                loss/optim_Q |             nan |
|                loss/optim_R |             nan |
|                loss/optim_S |             nan |
|             loss/optim_case |           0.625 |
|              loss/optim_lam |             nan |
|               loss/optim_nu |             nan |
|               loss/rew_loss |         0.00165 |
|              loss/step_size |           0.564 |
|                    loss/vf0 |             215 |
|                    loss/vf1 |            4.33 |
|               loss/vf_total |             219 |
|                   test/cost |               0 |
|                 test/length |             500 |
|                 test/reward |            -358 |
|                  train/cost |             420 |
|                train/length |             500 |
|                train/reward |            -463 |
|             update/cum_cost |        1.68e+04 |
|             update/duration |            87.4 |
|             update/env_step |           2e+04 |
|              update/episode |              30 |
|       update/gradient_steps |               6 |
|      update/remaining_epoch |             299 |
|           update/test_speed |             120 |
|            update/test_time |            8.31 |
| update/train_collector_time |            42.5 |
|     update/train_model_time |            36.6 |
|          update/train_speed |             253 |
-------------------------------------------------
Epoch: 1
{'duration': 87.43891310691833, 'test_time': 8.31486439704895, 'test_speed': 120.26654341529762, 'train_collector_time': 42.50932002067566, 'train_model_time': 36.614728689193726, 'train_speed': 252.76765188464552, 'remaining_epoch': 299, 'best_reward': -358.245502187242, 'best_cost': 0.0}
Epoch #2:   0%|          | 0/20000 [00:00<?, ?it/s]Epoch #2:  50%|#####     | 10000/20000 [00:21<00:21, 472.05it/s]Epoch #2:  50%|#####     | 10000/20000 [00:32<00:21, 472.05it/s]Epoch #2:  50%|#####     | 10000/20000 [00:35<00:21, 472.05it/s, cost=0, length=500, rew=-316]Epoch #2: 100%|##########| 20000/20000 [00:56<00:00, 338.02it/s, cost=0, length=500, rew=-316]Epoch #2: 100%|##########| 20000/20000 [01:10<00:00, 338.02it/s, cost=0, length=500, rew=-318]Epoch #2: 100%|##########| 20000/20000 [01:10<00:00, 282.34it/s, cost=0, length=500, rew=-318]
-------------------------------------------------
|              loss/cost_loss |        7.99e-10 |
|                loss/entropy |           -20.2 |
|                     loss/kl |               0 |
|                loss/optim_A |             nan |
|                loss/optim_B |             nan |
|                loss/optim_C |             nan |
|                loss/optim_Q |             nan |
|                loss/optim_R |             nan |
|                loss/optim_S |             nan |
|             loss/optim_case |               0 |
|              loss/optim_lam |               0 |
|               loss/optim_nu |             nan |
|               loss/rew_loss |        1.12e-07 |
|              loss/step_size |               1 |
|                    loss/vf0 |            43.8 |
|                    loss/vf1 |           0.121 |
|               loss/vf_total |            43.9 |
|                   test/cost |               0 |
|                 test/length |             500 |
|                 test/reward |            -405 |
|                  train/cost |               0 |
|            train/cost_limit |              10 |
|                train/length |             500 |
|                train/reward |            -317 |
|             update/cum_cost |        1.68e+04 |
|             update/duration |             167 |
|             update/env_step |           4e+04 |
|              update/episode |              70 |
|       update/gradient_steps |              14 |
|      update/remaining_epoch |             298 |
|           update/test_speed |             121 |
|            update/test_time |            16.6 |
| update/train_collector_time |            84.8 |
|     update/train_model_time |            65.2 |
|          update/train_speed |             267 |
-------------------------------------------------
Epoch: 2
{'duration': 166.57500505447388, 'test_time': 16.586684226989746, 'test_speed': 120.57865047829227, 'train_collector_time': 84.78245830535889, 'train_model_time': 65.20586252212524, 'train_speed': 266.6874312567831, 'remaining_epoch': 298, 'best_reward': -358.245502187242, 'best_cost': 0.0}
Epoch #3:   0%|          | 0/20000 [00:00<?, ?it/s]Epoch #3:  50%|#####     | 10000/20000 [00:21<00:21, 474.68it/s]Epoch #3:  50%|#####     | 10000/20000 [00:33<00:21, 474.68it/s]Epoch #3:  50%|#####     | 10000/20000 [00:35<00:21, 474.68it/s, cost=0, length=500, rew=-347]Epoch #3: 100%|##########| 20000/20000 [00:56<00:00, 341.48it/s, cost=0, length=500, rew=-347]Epoch #3: 100%|##########| 20000/20000 [01:10<00:00, 341.48it/s, cost=0, length=500, rew=-320]Epoch #3: 100%|##########| 20000/20000 [01:10<00:00, 282.25it/s, cost=0, length=500, rew=-320]
-------------------------------------------------
|              loss/cost_loss |        5.36e-10 |
|                loss/entropy |           -20.2 |
|                     loss/kl |               0 |
|                loss/optim_A |             nan |
|                loss/optim_B |             nan |
|                loss/optim_C |             nan |
|                loss/optim_Q |             nan |
|                loss/optim_R |             nan |
|                loss/optim_S |             nan |
|             loss/optim_case |               0 |
|              loss/optim_lam |               0 |
|               loss/optim_nu |             nan |
|               loss/rew_loss |        6.13e-08 |
|              loss/step_size |               1 |
|                    loss/vf0 |            10.8 |
|                    loss/vf1 |           0.102 |
|               loss/vf_total |            10.9 |
|                   test/cost |               0 |
|                 test/length |             500 |
|                 test/reward |            -315 |
|                  train/cost |               0 |
|            train/cost_limit |              10 |
|                train/length |             500 |
|                train/reward |            -334 |
|             update/cum_cost |        1.68e+04 |
|             update/duration |             246 |
|             update/env_step |           6e+04 |
|              update/episode |             110 |
|       update/gradient_steps |              22 |
|      update/remaining_epoch |             297 |
|           update/test_speed |             121 |
|            update/test_time |            24.8 |
| update/train_collector_time |             127 |
|     update/train_model_time |              94 |
|          update/train_speed |             272 |
-------------------------------------------------
Epoch: 3
{'duration': 245.67405724525452, 'test_time': 24.80070972442627, 'test_speed': 120.96428018934047, 'train_collector_time': 126.84896564483643, 'train_model_time': 94.02438187599182, 'train_speed': 271.6488914278896, 'remaining_epoch': 297, 'best_reward': -315.28695314027175, 'best_cost': 0.0}
slurmstepd: error: *** JOB 39418 ON gan.ist.berkeley.edu CANCELLED AT 2023-08-11T11:10:01 ***
